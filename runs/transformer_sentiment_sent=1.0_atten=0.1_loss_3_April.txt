to_write_filename: runs/transformer_sentiment_sent=1.0_atten=0.1_loss_3_April.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 0.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-04-03 17:54:29.904622: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-03 17:54:35.556721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 35b6:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-03 17:54:35.556769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-04-03 17:54:56.786605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-03 17:54:56.786656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-04-03 17:54:56.786671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-04-03 17:54:56.786931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 35b6:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7835707.
Parameter count without word embeddings: 2035207.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 8855.284984588623
train_cost_avg: 1.0364331676718894
train_count_sent: 8544.0
train_total_correct_sent: 4195.0
train_accuracy_sent: 0.4909878277153558
train_count_tok: 163566.0
train_total_correct_tok: 53702.0
train_accuracy_tok: 0.3283200665174914
train_label=O_precision_sent: 0.28846153846153844
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.050561797752808994
train_label=N_precision_sent: 0.47035175879396984
train_label=N_recall_sent: 0.565558912386707
train_label=N_f-score_sent: 0.5135802469135803
train_label=P_precision_sent: 0.5167876588021778
train_label=P_recall_sent: 0.6310249307479224
train_label=P_f-score_sent: 0.5682215016213519
train_precision_macro_sent: 0.4252003186858954
train_recall_macro_sent: 0.40809773424684687
train_f-score_macro_sent: 0.377454515429247
train_precision_micro_sent: 0.4909878277153558
train_recall_micro_sent: 0.4909878277153558
train_f-score_micro_sent: 0.4909878277153558
train_label=O_precision_tok: 0.7695504271521899
train_label=O_recall_tok: 0.32019268659477107
train_label=O_f-score_tok: 0.4522247778061731
train_label=N_precision_tok: 0.0888630804694786
train_label=N_recall_tok: 0.355583720602732
train_label=N_f-score_tok: 0.14219143754135516
train_label=P_precision_tok: 0.16067564864815723
train_label=P_recall_tok: 0.3532397969380821
train_label=P_f-score_tok: 0.22088082383523294
train_precision_macro_tok: 0.3396963854232753
train_recall_macro_tok: 0.3430054013785284
train_f-score_macro_tok: 0.2717656797275871
train_precision_micro_tok: 0.3283200665174914
train_recall_micro_tok: 0.3283200665174914
train_f-score_micro_tok: 0.3283200665174914
train_time: 51.46075677871704
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2885    0.0277    0.0506      1624
           N     0.4704    0.5656    0.5136      3310
           P     0.5168    0.6310    0.5682      3610

   micro avg     0.4910    0.4910    0.4910      8544
   macro avg     0.4252    0.4081    0.3775      8544
weighted avg     0.4554    0.4910    0.4487      8544

F1-macro sent:  0.377454515429247
F1-micro sent:  0.4909878277153558
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7696    0.3202    0.4522    124347
           N     0.0889    0.3556    0.1422     14202
           P     0.1607    0.3532    0.2209     25017

   micro avg     0.3283    0.3283    0.3283    163566
   macro avg     0.3397    0.3430    0.2718    163566
weighted avg     0.6173    0.3283    0.3899    163566

F1-macro tok:  0.2717656797275871
F1-micro tok:  0.3283200665174914
**************************************************
dev_cost_sum: 1011.8783836364746
dev_cost_avg: 0.9190539360912576
dev_count_sent: 1101.0
dev_total_correct_sent: 630.0
dev_accuracy_sent: 0.5722070844686649
dev_count_tok: 21274.0
dev_total_correct_tok: 7773.0
dev_accuracy_tok: 0.3653755758202501
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5
dev_label=N_recall_sent: 0.9228971962616822
dev_label=N_f-score_sent: 0.6486042692939245
dev_label=P_precision_sent: 0.7564935064935064
dev_label=P_recall_sent: 0.5247747747747747
dev_label=P_f-score_sent: 0.6196808510638298
dev_precision_macro_sent: 0.641053391053391
dev_recall_macro_sent: 0.48546853183020183
dev_f-score_macro_sent: 0.42850883322269967
dev_precision_micro_sent: 0.5722070844686649
dev_recall_micro_sent: 0.5722070844686649
dev_f-score_micro_sent: 0.5722070844686649
dev_label=O_precision_tok: 0.7846174752004348
dev_label=O_recall_tok: 0.35630978093181115
dev_label=O_f-score_tok: 0.4900695976913937
dev_label=N_precision_tok: 0.1090874953060458
dev_label=N_recall_tok: 0.31287022078621435
dev_label=N_f-score_tok: 0.16177084783516638
dev_label=P_precision_tok: 0.16509488881127024
dev_label=P_recall_tok: 0.4414694894146949
dev_label=P_f-score_tok: 0.24031861706635035
dev_precision_macro_tok: 0.35293328643925026
dev_recall_macro_tok: 0.3702164970442401
dev_f-score_macro_tok: 0.2973863541976368
dev_precision_micro_tok: 0.3653755758202501
dev_recall_micro_tok: 0.3653755758202501
dev_f-score_micro_tok: 0.36537557582025004
dev_time: 2.290208578109741
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5000    0.9229    0.6486       428
           P     0.7565    0.5248    0.6197       444

   micro avg     0.5722    0.5722    0.5722      1101
   macro avg     0.6411    0.4855    0.4285      1101
weighted avg     0.6381    0.5722    0.5056      1101

F1-macro sent:  0.42850883322269967
F1-micro sent:  0.5722070844686649
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7846    0.3563    0.4901     16205
           N     0.1091    0.3129    0.1618      1857
           P     0.1651    0.4415    0.2403      3212

   micro avg     0.3654    0.3654    0.3654     21274
   macro avg     0.3529    0.3702    0.2974     21274
weighted avg     0.6321    0.3654    0.4237     21274

F1-macro tok:  0.2973863541976368
F1-micro tok:  0.36537557582025004
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 8013.920215606689
train_cost_avg: 0.9379588267329927
train_count_sent: 8544.0
train_total_correct_sent: 4886.0
train_accuracy_sent: 0.5718632958801498
train_count_tok: 163566.0
train_total_correct_tok: 63798.0
train_accuracy_tok: 0.39004438575254025
train_label=O_precision_sent: 0.358974358974359
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.048248133256748996
train_label=N_precision_sent: 0.5393925553779402
train_label=N_recall_sent: 0.713595166163142
train_label=N_f-score_sent: 0.6143841851996359
train_label=P_precision_sent: 0.6131422924901185
train_label=P_recall_sent: 0.6875346260387811
train_label=P_f-score_sent: 0.6482110211543483
train_precision_macro_sent: 0.5038364022808058
train_recall_macro_sent: 0.4756639537224801
train_f-score_macro_sent: 0.43694777987024436
train_precision_micro_sent: 0.5718632958801498
train_recall_micro_sent: 0.5718632958801498
train_f-score_micro_sent: 0.5718632958801498
train_label=O_precision_tok: 0.7691420915704694
train_label=O_recall_tok: 0.39705019019357124
train_label=O_f-score_tok: 0.523735268221791
train_label=N_precision_tok: 0.10194746134503237
train_label=N_recall_tok: 0.2683424869736657
train_label=N_f-score_tok: 0.14775899503722084
train_label=P_precision_tok: 0.17122900972690466
train_label=P_recall_tok: 0.4243114682016229
train_label=P_f-score_tok: 0.24399494310998734
train_precision_macro_tok: 0.34743952088080216
train_recall_macro_tok: 0.3632347151229533
train_f-score_macro_tok: 0.30516306878966637
train_precision_micro_tok: 0.39004438575254025
train_recall_micro_tok: 0.39004438575254025
train_f-score_micro_tok: 0.3900443857525402
train_time: 44.9039032459259
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3590    0.0259    0.0482      1624
           N     0.5394    0.7136    0.6144      3310
           P     0.6131    0.6875    0.6482      3610

   micro avg     0.5719    0.5719    0.5719      8544
   macro avg     0.5038    0.4757    0.4369      8544
weighted avg     0.5363    0.5719    0.5211      8544

F1-macro sent:  0.43694777987024436
F1-micro sent:  0.5718632958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7691    0.3971    0.5237    124347
           N     0.1019    0.2683    0.1478     14202
           P     0.1712    0.4243    0.2440     25017

   micro avg     0.3900    0.3900    0.3900    163566
   macro avg     0.3474    0.3632    0.3052    163566
weighted avg     0.6198    0.3900    0.4483    163566

F1-macro tok:  0.30516306878966637
F1-micro tok:  0.3900443857525402
**************************************************
dev_cost_sum: 984.1256523132324
dev_cost_avg: 0.8938470956523455
dev_count_sent: 1101.0
dev_total_correct_sent: 648.0
dev_accuracy_sent: 0.5885558583106267
dev_count_tok: 21274.0
dev_total_correct_tok: 8396.0
dev_accuracy_tok: 0.39466014853812165
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6594594594594595
dev_label=N_recall_sent: 0.5700934579439252
dev_label=N_f-score_sent: 0.6115288220551378
dev_label=P_precision_sent: 0.5523415977961432
dev_label=P_recall_sent: 0.9031531531531531
dev_label=P_f-score_sent: 0.6854700854700855
dev_precision_macro_sent: 0.6039336857518676
dev_recall_macro_sent: 0.4954490159261004
dev_f-score_macro_sent: 0.4408799777220829
dev_precision_micro_sent: 0.5885558583106267
dev_recall_micro_sent: 0.5885558583106267
dev_f-score_micro_sent: 0.5885558583106267
dev_label=O_precision_tok: 0.7755474452554745
dev_label=O_recall_tok: 0.3933970996605986
dev_label=O_f-score_tok: 0.5220061412487206
dev_label=N_precision_tok: 0.12017586712261846
dev_label=N_recall_tok: 0.2649434571890145
dev_label=N_f-score_tok: 0.16535036128381783
dev_label=P_precision_tok: 0.17064732142857142
dev_label=P_recall_tok: 0.476027397260274
dev_label=P_f-score_tok: 0.251232336510023
dev_precision_macro_tok: 0.35545687793555486
dev_recall_macro_tok: 0.3781226513699624
dev_f-score_macro_tok: 0.3128629463475205
dev_precision_micro_tok: 0.39466014853812165
dev_recall_micro_tok: 0.39466014853812165
dev_f-score_micro_tok: 0.39466014853812165
dev_time: 2.0230114459991455
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6595    0.5701    0.6115       428
           P     0.5523    0.9032    0.6855       444

   micro avg     0.5886    0.5886    0.5886      1101
   macro avg     0.6039    0.4954    0.4409      1101
weighted avg     0.6039    0.5886    0.5195      1101

F1-macro sent:  0.4408799777220829
F1-micro sent:  0.5885558583106267
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7755    0.3934    0.5220     16205
           N     0.1202    0.2649    0.1654      1857
           P     0.1706    0.4760    0.2512      3212

   micro avg     0.3947    0.3947    0.3947     21274
   macro avg     0.3555    0.3781    0.3129     21274
weighted avg     0.6270    0.3947    0.4500     21274

F1-macro tok:  0.3128629463475205
F1-micro tok:  0.39466014853812165
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 7752.846380233765
train_cost_avg: 0.9074024321434649
train_count_sent: 8544.0
train_total_correct_sent: 5092.0
train_accuracy_sent: 0.5959737827715356
train_count_tok: 163566.0
train_total_correct_tok: 65568.0
train_accuracy_tok: 0.4008657055867356
train_label=O_precision_sent: 0.3472222222222222
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.056561085972850686
train_label=N_precision_sent: 0.5741147741147741
train_label=N_recall_sent: 0.7102719033232628
train_label=N_f-score_sent: 0.6349763673193789
train_label=P_precision_sent: 0.6250871080139373
train_label=P_recall_sent: 0.7454293628808865
train_label=P_f-score_sent: 0.6799747315224258
train_precision_macro_sent: 0.5154747014503113
train_recall_macro_sent: 0.49549648118135026
train_f-score_macro_sent: 0.4571707282715518
train_precision_micro_sent: 0.5959737827715356
train_recall_micro_sent: 0.5959737827715356
train_f-score_micro_sent: 0.5959737827715356
train_label=O_precision_tok: 0.7708711159472857
train_label=O_recall_tok: 0.41019887894360135
train_label=O_f-score_tok: 0.5354643991286775
train_label=N_precision_tok: 0.10601858085364212
train_label=N_recall_tok: 0.2772144768342487
train_label=N_f-score_tok: 0.15337865477141244
train_label=P_precision_tok: 0.17629391168710487
train_label=P_recall_tok: 0.42467122356797377
train_label=P_f-score_tok: 0.24915572232645403
train_precision_macro_tok: 0.3510612028293443
train_recall_macro_tok: 0.3706948597819413
train_f-score_macro_tok: 0.3126662587421813
train_precision_micro_tok: 0.4008657055867356
train_recall_micro_tok: 0.4008657055867356
train_f-score_micro_tok: 0.40086570558673557
train_time: 44.769201040267944
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3472    0.0308    0.0566      1624
           N     0.5741    0.7103    0.6350      3310
           P     0.6251    0.7454    0.6800      3610

   micro avg     0.5960    0.5960    0.5960      8544
   macro avg     0.5155    0.4955    0.4572      8544
weighted avg     0.5525    0.5960    0.5440      8544

F1-macro sent:  0.4571707282715518
F1-micro sent:  0.5959737827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7709    0.4102    0.5355    124347
           N     0.1060    0.2772    0.1534     14202
           P     0.1763    0.4247    0.2492     25017

   micro avg     0.4009    0.4009    0.4009    163566
   macro avg     0.3511    0.3707    0.3127    163566
weighted avg     0.6222    0.4009    0.4585    163566

F1-macro tok:  0.3126662587421813
F1-micro tok:  0.40086570558673557
**************************************************
dev_cost_sum: 1010.7571783065796
dev_cost_avg: 0.9180355842929878
dev_count_sent: 1101.0
dev_total_correct_sent: 649.0
dev_accuracy_sent: 0.5894641235240691
dev_count_tok: 21274.0
dev_total_correct_tok: 8540.0
dev_accuracy_tok: 0.40142897433486885
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04201680672268907
dev_label=N_precision_sent: 0.6780626780626781
dev_label=N_recall_sent: 0.5560747663551402
dev_label=N_f-score_sent: 0.6110397946084725
dev_label=P_precision_sent: 0.5479082321187584
dev_label=P_recall_sent: 0.9144144144144144
dev_label=P_f-score_sent: 0.6852320675105485
dev_precision_macro_sent: 0.593842155245664
dev_recall_macro_sent: 0.4974410806349752
dev_f-score_macro_sent: 0.44609622294723666
dev_precision_micro_sent: 0.5894641235240691
dev_recall_micro_sent: 0.5894641235240691
dev_f-score_micro_sent: 0.5894641235240691
dev_label=O_precision_tok: 0.7590661294145532
dev_label=O_recall_tok: 0.3952483801295896
dev_label=O_f-score_tok: 0.5198230734894291
dev_label=N_precision_tok: 0.11954848640328374
dev_label=N_recall_tok: 0.1254711900915455
dev_label=N_f-score_tok: 0.12243825538623226
dev_label=P_precision_tok: 0.17470377514466795
dev_label=P_recall_tok: 0.5921544209215442
dev_label=P_f-score_tok: 0.2698063692460458
dev_precision_macro_tok: 0.351106130320835
dev_recall_macro_tok: 0.37095799704755983
dev_f-score_macro_tok: 0.30402256604056904
dev_precision_micro_tok: 0.40142897433486885
dev_recall_micro_tok: 0.40142897433486885
dev_f-score_micro_tok: 0.40142897433486885
dev_time: 2.043980598449707
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0218    0.0420       229
           N     0.6781    0.5561    0.6110       428
           P     0.5479    0.9144    0.6852       444

   micro avg     0.5895    0.5895    0.5895      1101
   macro avg     0.5938    0.4974    0.4461      1101
weighted avg     0.6001    0.5895    0.5226      1101

F1-macro sent:  0.44609622294723666
F1-micro sent:  0.5894641235240691
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7591    0.3952    0.5198     16205
           N     0.1195    0.1255    0.1224      1857
           P     0.1747    0.5922    0.2698      3212

   micro avg     0.4014    0.4014    0.4014     21274
   macro avg     0.3511    0.3710    0.3040     21274
weighted avg     0.6150    0.4014    0.4474     21274

F1-macro tok:  0.30402256604056904
F1-micro tok:  0.40142897433486885
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 7590.1242961883545
train_cost_avg: 0.8883572444040677
train_count_sent: 8544.0
train_total_correct_sent: 5199.0
train_accuracy_sent: 0.608497191011236
train_count_tok: 163566.0
train_total_correct_tok: 64696.0
train_accuracy_tok: 0.3955345242898891
train_label=O_precision_sent: 0.41509433962264153
train_label=O_recall_sent: 0.027093596059113302
train_label=O_f-score_sent: 0.05086705202312139
train_label=N_precision_sent: 0.5679590017825312
train_label=N_recall_sent: 0.7700906344410876
train_label=N_f-score_sent: 0.6537573736855603
train_label=P_precision_sent: 0.659746835443038
train_label=P_recall_sent: 0.7218836565096953
train_label=P_f-score_sent: 0.6894179894179895
train_precision_macro_sent: 0.5476000589494036
train_recall_macro_sent: 0.5063559623366322
train_f-score_macro_sent: 0.4646808050422237
train_precision_micro_sent: 0.608497191011236
train_recall_micro_sent: 0.608497191011236
train_f-score_micro_sent: 0.608497191011236
train_label=O_precision_tok: 0.7720978243608068
train_label=O_recall_tok: 0.3909945555582362
train_label=O_f-score_tok: 0.5191093173604104
train_label=N_precision_tok: 0.11012398064045614
train_label=N_recall_tok: 0.23391071680045064
train_label=N_f-score_tok: 0.1497475658131987
train_label=P_precision_tok: 0.18110180320885985
train_label=P_recall_tok: 0.5098532997561658
train_label=P_f-score_tok: 0.2672687460056366
train_precision_macro_tok: 0.3544412027367076
train_recall_macro_tok: 0.3782528573716175
train_f-score_macro_tok: 0.3120418763930819
train_precision_micro_tok: 0.3955345242898891
train_recall_micro_tok: 0.3955345242898891
train_f-score_micro_tok: 0.3955345242898891
train_time: 62.129658699035645
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4151    0.0271    0.0509      1624
           N     0.5680    0.7701    0.6538      3310
           P     0.6597    0.7219    0.6894      3610

   micro avg     0.6085    0.6085    0.6085      8544
   macro avg     0.5476    0.5064    0.4647      8544
weighted avg     0.5777    0.6085    0.5542      8544

F1-macro sent:  0.4646808050422237
F1-micro sent:  0.608497191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7721    0.3910    0.5191    124347
           N     0.1101    0.2339    0.1497     14202
           P     0.1811    0.5099    0.2673     25017

   micro avg     0.3955    0.3955    0.3955    163566
   macro avg     0.3544    0.3783    0.3120    163566
weighted avg     0.6242    0.3955    0.4485    163566

F1-macro tok:  0.3120418763930819
F1-micro tok:  0.3955345242898891
**************************************************
dev_cost_sum: 959.4447889328003
dev_cost_avg: 0.8714303260061764
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 8250.0
dev_accuracy_tok: 0.3877973112719752
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6607142857142857
dev_label=N_recall_sent: 0.6915887850467289
dev_label=N_f-score_sent: 0.6757990867579908
dev_label=P_precision_sent: 0.5978428351309707
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7099725526075024
dev_precision_macro_sent: 0.669519040281752
dev_recall_macro_sent: 0.5261876985339419
dev_f-score_macro_sent: 0.47050757077562216
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.7823273015453704
dev_label=O_recall_tok: 0.36550447392780006
dev_label=O_f-score_tok: 0.49823351278600264
dev_label=N_precision_tok: 0.1208767361111111
dev_label=N_recall_tok: 0.2999461497038234
dev_label=N_f-score_tok: 0.1723124516627997
dev_label=P_precision_tok: 0.19461242440901594
dev_label=P_recall_tok: 0.5510585305105853
dev_label=P_f-score_tok: 0.28764117981636467
dev_precision_macro_tok: 0.3659388206884992
dev_recall_macro_tok: 0.4055030513807362
dev_f-score_macro_tok: 0.3193957147550557
dev_precision_micro_tok: 0.3877973112719752
dev_recall_micro_tok: 0.3877973112719752
dev_f-score_micro_tok: 0.3877973112719752
dev_time: 4.356875658035278
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6607    0.6916    0.6758       428
           P     0.5978    0.8739    0.7100       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.6695    0.5262    0.4705      1101
weighted avg     0.6539    0.6240    0.5544      1101

F1-macro sent:  0.47050757077562216
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7823    0.3655    0.4982     16205
           N     0.1209    0.2999    0.1723      1857
           P     0.1946    0.5511    0.2876      3212

   micro avg     0.3878    0.3878    0.3878     21274
   macro avg     0.3659    0.4055    0.3194     21274
weighted avg     0.6359    0.3878    0.4380     21274

F1-macro tok:  0.3193957147550557
F1-micro tok:  0.3877973112719752
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 7381.344806671143
train_cost_avg: 0.863921442728364
train_count_sent: 8544.0
train_total_correct_sent: 5375.0
train_accuracy_sent: 0.6290964419475655
train_count_tok: 163566.0
train_total_correct_tok: 59822.0
train_accuracy_tok: 0.36573615543572624
train_label=O_precision_sent: 0.42953020134228187
train_label=O_recall_sent: 0.03940886699507389
train_label=O_f-score_sent: 0.0721940214326001
train_label=N_precision_sent: 0.5929912963811269
train_label=N_recall_sent: 0.7821752265861027
train_label=N_f-score_sent: 0.6745700885878061
train_label=P_precision_sent: 0.6756018863241499
train_label=P_recall_sent: 0.754016620498615
train_label=P_f-score_sent: 0.7126587249640006
train_precision_macro_sent: 0.5660411280158528
train_recall_macro_sent: 0.5252002380265971
train_f-score_macro_sent: 0.48647427832813567
train_precision_micro_sent: 0.6290964419475655
train_recall_micro_sent: 0.6290964419475655
train_f-score_micro_sent: 0.6290964419475655
train_label=O_precision_tok: 0.7638427268227141
train_label=O_recall_tok: 0.34746314748244833
train_label=O_f-score_tok: 0.4776492308372626
train_label=N_precision_tok: 0.10228802153432032
train_label=N_recall_tok: 0.21405435854105057
train_label=N_f-score_tok: 0.13842721187559767
train_label=P_precision_tok: 0.1756683315649181
train_label=P_recall_tok: 0.5426709837310629
train_label=P_f-score_tok: 0.2654180392770213
train_precision_macro_tok: 0.3472663599739842
train_recall_macro_tok: 0.36806282991818734
train_f-score_macro_tok: 0.29383149399662717
train_precision_micro_tok: 0.36573615543572624
train_recall_micro_tok: 0.36573615543572624
train_f-score_micro_tok: 0.36573615543572624
train_time: 86.2306740283966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4295    0.0394    0.0722      1624
           N     0.5930    0.7822    0.6746      3310
           P     0.6756    0.7540    0.7127      3610

   micro avg     0.6291    0.6291    0.6291      8544
   macro avg     0.5660    0.5252    0.4865      8544
weighted avg     0.5968    0.6291    0.5762      8544

F1-macro sent:  0.48647427832813567
F1-micro sent:  0.6290964419475655
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7638    0.3475    0.4776    124347
           N     0.1023    0.2141    0.1384     14202
           P     0.1757    0.5427    0.2654     25017

   micro avg     0.3657    0.3657    0.3657    163566
   macro avg     0.3473    0.3681    0.2938    163566
weighted avg     0.6164    0.3657    0.4157    163566

F1-macro tok:  0.29383149399662717
F1-micro tok:  0.36573615543572624
**************************************************
dev_cost_sum: 954.4582920074463
dev_cost_avg: 0.8669012643119404
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 7916.0
dev_accuracy_tok: 0.3720973958822976
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.6149532710280374
dev_label=N_recall_sent: 0.7686915887850467
dev_label=N_f-score_sent: 0.6832814122533749
dev_label=P_precision_sent: 0.6397849462365591
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7125748502994012
dev_precision_macro_sent: 0.6682460724215322
dev_recall_macro_sent: 0.532982172067182
dev_f-score_macro_sent: 0.48216305798172704
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.7549578918772073
dev_label=O_recall_tok: 0.3429805615550756
dev_label=O_f-score_tok: 0.47167649679636786
dev_label=N_precision_tok: 0.11629995509654244
dev_label=N_recall_tok: 0.13947226709746904
dev_label=N_f-score_tok: 0.1268364348677767
dev_label=P_precision_tok: 0.17963200684638425
dev_label=P_recall_tok: 0.6534869240348692
dev_label=P_f-score_tok: 0.2818017050412835
dev_precision_macro_tok: 0.35029661794004463
dev_recall_macro_tok: 0.37864658422913794
dev_f-score_macro_tok: 0.29343821223514266
dev_precision_micro_tok: 0.3720973958822976
dev_recall_micro_tok: 0.3720973958822976
dev_f-score_micro_tok: 0.3720973958822976
dev_time: 6.89520525932312
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.6150    0.7687    0.6833       428
           P     0.6398    0.8041    0.7126       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.6682    0.5330    0.4822      1101
weighted avg     0.6531    0.6285    0.5635      1101

F1-macro sent:  0.48216305798172704
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7550    0.3430    0.4717     16205
           N     0.1163    0.1395    0.1268      1857
           P     0.1796    0.6535    0.2818      3212

   micro avg     0.3721    0.3721    0.3721     21274
   macro avg     0.3503    0.3786    0.2934     21274
weighted avg     0.6123    0.3721    0.4129     21274

F1-macro tok:  0.29343821223514266
F1-micro tok:  0.3720973958822976
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 7263.592433929443
train_cost_avg: 0.8501395638962363
train_count_sent: 8544.0
train_total_correct_sent: 5400.0
train_accuracy_sent: 0.6320224719101124
train_count_tok: 163566.0
train_total_correct_tok: 58020.0
train_accuracy_tok: 0.35471919592091267
train_label=O_precision_sent: 0.46710526315789475
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.07995495495495497
train_label=N_precision_sent: 0.6076923076923076
train_label=N_recall_sent: 0.7637462235649547
train_label=N_f-score_sent: 0.6768406961178045
train_label=P_precision_sent: 0.6618620037807184
train_label=P_recall_sent: 0.7759002770083102
train_label=P_f-score_sent: 0.7143585819943892
train_precision_macro_sent: 0.5788865248769736
train_recall_macro_sent: 0.5277885707986417
train_f-score_macro_sent: 0.49038474435571616
train_precision_micro_sent: 0.6320224719101124
train_recall_micro_sent: 0.6320224719101124
train_f-score_micro_sent: 0.6320224719101124
train_label=O_precision_tok: 0.762006142020084
train_label=O_recall_tok: 0.32525915381955334
train_label=O_f-score_tok: 0.4559135179006222
train_label=N_precision_tok: 0.10727111248407152
train_label=N_recall_tok: 0.19560625264047318
train_label=N_f-score_tok: 0.13855707124865957
train_label=P_precision_tok: 0.17492197843767732
train_label=P_recall_tok: 0.5914777950993324
train_label=P_f-score_tok: 0.26999607696448286
train_precision_macro_tok: 0.3480664109806109
train_recall_macro_tok: 0.37078106718645304
train_f-score_macro_tok: 0.28815555537125487
train_precision_micro_tok: 0.35471919592091267
train_recall_micro_tok: 0.35471919592091267
train_f-score_micro_tok: 0.35471919592091267
train_time: 124.6819212436676
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4671    0.0437    0.0800      1624
           N     0.6077    0.7637    0.6768      3310
           P     0.6619    0.7759    0.7144      3610

   micro avg     0.6320    0.6320    0.6320      8544
   macro avg     0.5789    0.5278    0.4904      8544
weighted avg     0.6039    0.6320    0.5792      8544

F1-macro sent:  0.49038474435571616
F1-micro sent:  0.6320224719101124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7620    0.3253    0.4559    124347
           N     0.1073    0.1956    0.1386     14202
           P     0.1749    0.5915    0.2700     25017

   micro avg     0.3547    0.3547    0.3547    163566
   macro avg     0.3481    0.3708    0.2882    163566
weighted avg     0.6154    0.3547    0.3999    163566

F1-macro tok:  0.28815555537125487
F1-micro tok:  0.35471919592091267
**************************************************
dev_cost_sum: 948.2419815063477
dev_cost_avg: 0.8612552057278362
dev_count_sent: 1101.0
dev_total_correct_sent: 629.0
dev_accuracy_sent: 0.5712988192552225
dev_count_tok: 21274.0
dev_total_correct_tok: 6342.0
dev_accuracy_tok: 0.29811036946507474
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.697986577181208
dev_label=N_recall_sent: 0.48598130841121495
dev_label=N_f-score_sent: 0.5730027548209367
dev_label=P_precision_sent: 0.523153942428035
dev_label=P_recall_sent: 0.9414414414414415
dev_label=P_f-score_sent: 0.672566371681416
dev_precision_macro_sent: 0.6570468398697477
dev_recall_macro_sent: 0.4801743955112931
dev_f-score_macro_sent: 0.423773399821242
dev_precision_micro_sent: 0.5712988192552225
dev_recall_micro_sent: 0.5712988192552225
dev_f-score_micro_sent: 0.5712988192552225
dev_label=O_precision_tok: 0.7627811860940695
dev_label=O_recall_tok: 0.23017587164455414
dev_label=O_f-score_tok: 0.3536383029153828
dev_label=N_precision_tok: 0.12380250552689757
dev_label=N_recall_tok: 0.27140549273021003
dev_label=N_f-score_tok: 0.1700404858299595
dev_label=P_precision_tok: 0.171201169495655
dev_label=P_recall_tok: 0.6562889165628891
dev_label=P_f-score_tok: 0.2715619967793881
dev_precision_macro_tok: 0.35259495370554067
dev_recall_macro_tok: 0.3859567603125511
dev_f-score_macro_tok: 0.2650802618415768
dev_precision_micro_tok: 0.29811036946507474
dev_recall_micro_tok: 0.29811036946507474
dev_f-score_micro_tok: 0.29811036946507474
dev_time: 7.379188537597656
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6980    0.4860    0.5730       428
           P     0.5232    0.9414    0.6726       444

   micro avg     0.5713    0.5713    0.5713      1101
   macro avg     0.6570    0.4802    0.4238      1101
weighted avg     0.6383    0.5713    0.4993      1101

F1-macro sent:  0.423773399821242
F1-micro sent:  0.5712988192552225
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7628    0.2302    0.3536     16205
           N     0.1238    0.2714    0.1700      1857
           P     0.1712    0.6563    0.2716      3212

   micro avg     0.2981    0.2981    0.2981     21274
   macro avg     0.3526    0.3860    0.2651     21274
weighted avg     0.6177    0.2981    0.3252     21274

F1-macro tok:  0.2650802618415768
F1-micro tok:  0.29811036946507474
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 7160.387966156006
train_cost_avg: 0.8380603892972853
train_count_sent: 8544.0
train_total_correct_sent: 5420.0
train_accuracy_sent: 0.6343632958801498
train_count_tok: 163566.0
train_total_correct_tok: 60258.0
train_accuracy_tok: 0.3684017460841495
train_label=O_precision_sent: 0.4968944099378882
train_label=O_recall_sent: 0.04926108374384237
train_label=O_f-score_sent: 0.0896358543417367
train_label=N_precision_sent: 0.5900841080123949
train_label=N_recall_sent: 0.8054380664652568
train_label=N_f-score_sent: 0.6811446090955544
train_label=P_precision_sent: 0.6918499353169469
train_label=P_recall_sent: 0.7407202216066482
train_label=P_f-score_sent: 0.7154515050167224
train_precision_macro_sent: 0.5929428177557433
train_recall_macro_sent: 0.5318064572719158
train_f-score_macro_sent: 0.49541065615133784
train_precision_micro_sent: 0.6343632958801498
train_recall_micro_sent: 0.6343632958801498
train_f-score_micro_sent: 0.6343632958801498
train_label=O_precision_tok: 0.7619228642521426
train_label=O_recall_tok: 0.35460445366595095
train_label=O_f-score_tok: 0.48396709454008635
train_label=N_precision_tok: 0.10164880191431475
train_label=N_recall_tok: 0.2183495282354598
train_label=N_f-score_tok: 0.13871927352434632
train_label=P_precision_tok: 0.1737401412478221
train_label=P_recall_tok: 0.5221649278490627
train_label=P_f-score_tok: 0.26072811464612194
train_precision_macro_tok: 0.3457706024714265
train_recall_macro_tok: 0.36503963658349114
train_f-score_macro_tok: 0.29447149423685154
train_precision_micro_tok: 0.3684017460841495
train_recall_micro_tok: 0.3684017460841495
train_f-score_micro_tok: 0.3684017460841495
train_time: 124.8292326927185
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4969    0.0493    0.0896      1624
           N     0.5901    0.8054    0.6811      3310
           P     0.6918    0.7407    0.7155      3610

   micro avg     0.6344    0.6344    0.6344      8544
   macro avg     0.5929    0.5318    0.4954      8544
weighted avg     0.6154    0.6344    0.5832      8544

F1-macro sent:  0.49541065615133784
F1-micro sent:  0.6343632958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7619    0.3546    0.4840    124347
           N     0.1016    0.2183    0.1387     14202
           P     0.1737    0.5222    0.2607     25017

   micro avg     0.3684    0.3684    0.3684    163566
   macro avg     0.3458    0.3650    0.2945    163566
weighted avg     0.6146    0.3684    0.4198    163566

F1-macro tok:  0.29447149423685154
F1-micro tok:  0.3684017460841495
**************************************************
dev_cost_sum: 955.1386880874634
dev_cost_avg: 0.8675192444027824
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 7895.0
dev_accuracy_tok: 0.37111027545360536
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09716599190283401
dev_label=N_precision_sent: 0.6942355889724311
dev_label=N_recall_sent: 0.647196261682243
dev_label=N_f-score_sent: 0.6698911729141476
dev_label=P_precision_sent: 0.5921052631578947
dev_label=P_recall_sent: 0.9121621621621622
dev_label=P_f-score_sent: 0.7180851063829786
dev_precision_macro_sent: 0.6510025062656641
dev_recall_macro_sent: 0.5372533901897653
dev_f-score_macro_sent: 0.49504742373332006
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.7642232683254876
dev_label=O_recall_tok: 0.35063252082690527
dev_label=O_f-score_tok: 0.48071065989847717
dev_label=N_precision_tok: 0.12561735022546705
dev_label=N_recall_tok: 0.3150242326332795
dev_label=N_f-score_tok: 0.17961314092723368
dev_label=P_precision_tok: 0.1773034197342627
dev_label=P_recall_tok: 0.5068493150684932
dev_label=P_f-score_tok: 0.26270776182023564
dev_precision_macro_tok: 0.3557146794284058
dev_recall_macro_tok: 0.39083535617622595
dev_f-score_macro_tok: 0.3076771875486488
dev_precision_micro_tok: 0.37111027545360536
dev_recall_micro_tok: 0.37111027545360536
dev_f-score_micro_tok: 0.37111027545360536
dev_time: 7.16739559173584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0524    0.0972       229
           N     0.6942    0.6472    0.6699       428
           P     0.5921    0.9122    0.7181       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.6510    0.5373    0.4950      1101
weighted avg     0.6473    0.6303    0.5702      1101

F1-macro sent:  0.49504742373332006
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7642    0.3506    0.4807     16205
           N     0.1256    0.3150    0.1796      1857
           P     0.1773    0.5068    0.2627      3212

   micro avg     0.3711    0.3711    0.3711     21274
   macro avg     0.3557    0.3908    0.3077     21274
weighted avg     0.6199    0.3711    0.4215     21274

F1-macro tok:  0.3076771875486488
F1-micro tok:  0.37111027545360536
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 7113.996255874634
train_cost_avg: 0.8326306479254019
train_count_sent: 8544.0
train_total_correct_sent: 5494.0
train_accuracy_sent: 0.6430243445692884
train_count_tok: 163566.0
train_total_correct_tok: 58661.0
train_accuracy_tok: 0.3586381032732964
train_label=O_precision_sent: 0.39705882352941174
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11392405063291139
train_label=N_precision_sent: 0.6082236082236082
train_label=N_recall_sent: 0.7954682779456194
train_label=N_f-score_sent: 0.6893572457127897
train_label=P_precision_sent: 0.6981993406036013
train_label=P_recall_sent: 0.7626038781163434
train_label=P_f-score_sent: 0.728981861511982
train_precision_macro_sent: 0.5678272574522071
train_recall_macro_sent: 0.5415248730387167
train_f-score_macro_sent: 0.510754385952561
train_precision_micro_sent: 0.6430243445692884
train_recall_micro_sent: 0.6430243445692884
train_f-score_micro_sent: 0.6430243445692884
train_label=O_precision_tok: 0.7605584513657377
train_label=O_recall_tok: 0.3320787795443396
train_label=O_f-score_tok: 0.4623040752351097
train_label=N_precision_tok: 0.11525979815270497
train_label=N_recall_tok: 0.2275735811857485
train_label=N_f-score_tok: 0.15301943517269134
train_label=P_precision_tok: 0.17402009060468782
train_label=P_recall_tok: 0.5650557620817844
train_label=P_f-score_tok: 0.2660919161592109
train_precision_macro_tok: 0.3499461133743768
train_recall_macro_tok: 0.3749027076039575
train_f-score_macro_tok: 0.29380514218900394
train_precision_micro_tok: 0.3586381032732964
train_recall_micro_tok: 0.3586381032732964
train_f-score_micro_tok: 0.3586381032732964
train_time: 124.97447848320007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3971    0.0665    0.1139      1624
           N     0.6082    0.7955    0.6894      3310
           P     0.6982    0.7626    0.7290      3610

   micro avg     0.6430    0.6430    0.6430      8544
   macro avg     0.5678    0.5415    0.5108      8544
weighted avg     0.6061    0.6430    0.5967      8544

F1-macro sent:  0.510754385952561
F1-micro sent:  0.6430243445692884
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7606    0.3321    0.4623    124347
           N     0.1153    0.2276    0.1530     14202
           P     0.1740    0.5651    0.2661     25017

   micro avg     0.3586    0.3586    0.3586    163566
   macro avg     0.3499    0.3749    0.2938    163566
weighted avg     0.6148    0.3586    0.4054    163566

F1-macro tok:  0.29380514218900394
F1-micro tok:  0.3586381032732964
**************************************************
dev_cost_sum: 941.1060314178467
dev_cost_avg: 0.8547738704975901
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 7817.0
dev_accuracy_tok: 0.3674438281470339
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.5850556438791733
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.6963103122043519
dev_label=P_precision_sent: 0.7010752688172043
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7172717271727174
dev_precision_macro_sent: 0.666805542327364
dev_recall_macro_sent: 0.5386271264939183
dev_f-score_macro_sent: 0.48531830691100053
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.7604944980301589
dev_label=O_recall_tok: 0.34544893551373035
dev_label=O_f-score_tok: 0.4750912331324791
dev_label=N_precision_tok: 0.12938596491228072
dev_label=N_recall_tok: 0.2859450726978998
dev_label=N_f-score_tok: 0.17815802717664822
dev_label=P_precision_tok: 0.17208685900703435
dev_label=P_recall_tok: 0.5255292652552926
dev_label=P_f-score_tok: 0.2592734812994394
dev_precision_macro_tok: 0.3539891073164913
dev_recall_macro_tok: 0.38564109115564094
dev_f-score_macro_tok: 0.3041742472028556
dev_precision_micro_tok: 0.3674438281470339
dev_recall_micro_tok: 0.3674438281470339
dev_f-score_micro_tok: 0.3674438281470339
dev_time: 7.112450838088989
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.5851    0.8598    0.6963       428
           P     0.7011    0.7342    0.7173       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.6668    0.5386    0.4853      1101
weighted avg     0.6587    0.6349    0.5687      1101

F1-macro sent:  0.48531830691100053
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7605    0.3454    0.4751     16205
           N     0.1294    0.2859    0.1782      1857
           P     0.1721    0.5255    0.2593      3212

   micro avg     0.3674    0.3674    0.3674     21274
   macro avg     0.3540    0.3856    0.3042     21274
weighted avg     0.6166    0.3674    0.4166     21274

F1-macro tok:  0.3041742472028556
F1-micro tok:  0.3674438281470339
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 6983.978412628174
train_cost_avg: 0.8174132037252076
train_count_sent: 8544.0
train_total_correct_sent: 5538.0
train_accuracy_sent: 0.6481741573033708
train_count_tok: 163566.0
train_total_correct_tok: 63582.0
train_accuracy_tok: 0.38872381790836724
train_label=O_precision_sent: 0.46113989637305697
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.09796367638965328
train_label=N_precision_sent: 0.6026578073089701
train_label=N_recall_sent: 0.8220543806646525
train_label=N_f-score_sent: 0.6954632587859425
train_label=P_precision_sent: 0.7111574556830031
train_label=P_recall_sent: 0.7556786703601108
train_label=P_f-score_sent: 0.7327424120333065
train_precision_macro_sent: 0.5916517197883434
train_recall_macro_sent: 0.544178668896596
train_f-score_macro_sent: 0.5087231157363008
train_precision_micro_sent: 0.6481741573033708
train_recall_micro_sent: 0.6481741573033708
train_f-score_micro_sent: 0.6481741573033708
train_label=O_precision_tok: 0.7621708536313561
train_label=O_recall_tok: 0.3850112990261124
train_label=O_f-score_tok: 0.5115916243234435
train_label=N_precision_tok: 0.11225708392139833
train_label=N_recall_tok: 0.2912265878045346
train_label=N_f-score_tok: 0.16204991576225367
train_label=P_precision_tok: 0.1810571446454278
train_label=P_recall_tok: 0.4625254826717832
train_label=P_f-score_tok: 0.2602417767781839
train_precision_macro_tok: 0.35182836073272744
train_recall_macro_tok: 0.3795877898341434
train_f-score_macro_tok: 0.31129443895462705
train_precision_micro_tok: 0.38872381790836724
train_recall_micro_tok: 0.38872381790836724
train_f-score_micro_tok: 0.38872381790836724
train_time: 124.31182765960693
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4611    0.0548    0.0980      1624
           N     0.6027    0.8221    0.6955      3310
           P     0.7112    0.7557    0.7327      3610

   micro avg     0.6482    0.6482    0.6482      8544
   macro avg     0.5917    0.5442    0.5087      8544
weighted avg     0.6216    0.6482    0.5976      8544

F1-macro sent:  0.5087231157363008
F1-micro sent:  0.6481741573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7622    0.3850    0.5116    124347
           N     0.1123    0.2912    0.1620     14202
           P     0.1811    0.4625    0.2602     25017

   micro avg     0.3887    0.3887    0.3887    163566
   macro avg     0.3518    0.3796    0.3113    163566
weighted avg     0.6169    0.3887    0.4428    163566

F1-macro tok:  0.31129443895462705
F1-micro tok:  0.38872381790836724
**************************************************
dev_cost_sum: 915.1873779296875
dev_cost_avg: 0.8312328591550295
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 8327.0
dev_accuracy_tok: 0.39141675284384697
dev_label=O_precision_sent: 0.9
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07531380753138077
dev_label=N_precision_sent: 0.6292947558770343
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.709480122324159
dev_label=P_precision_sent: 0.6617100371747212
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7250509164969451
dev_precision_macro_sent: 0.7303349310172519
dev_recall_macro_sent: 0.5513957413316676
dev_f-score_macro_sent: 0.5032816154508283
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.7498458882998397
dev_label=O_recall_tok: 0.3753162604134526
dev_label=O_f-score_tok: 0.50024675111038
dev_label=N_precision_tok: 0.13708459214501512
dev_label=N_recall_tok: 0.19547657512116318
dev_label=N_f-score_tok: 0.1611542730299667
dev_label=P_precision_tok: 0.17898240608654303
dev_label=P_recall_tok: 0.5859277708592777
dev_label=P_f-score_tok: 0.274204123260727
dev_precision_macro_tok: 0.35530429551046594
dev_recall_macro_tok: 0.3855735354646312
dev_f-score_macro_tok: 0.3118683824670246
dev_precision_micro_tok: 0.39141675284384697
dev_recall_micro_tok: 0.39141675284384697
dev_f-score_micro_tok: 0.39141675284384697
dev_time: 7.182472467422485
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9000    0.0393    0.0753       229
           N     0.6293    0.8131    0.7095       428
           P     0.6617    0.8018    0.7251       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7303    0.5514    0.5033      1101
weighted avg     0.6987    0.6476    0.5839      1101

F1-macro sent:  0.5032816154508283
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7498    0.3753    0.5002     16205
           N     0.1371    0.1955    0.1612      1857
           P     0.1790    0.5859    0.2742      3212

   micro avg     0.3914    0.3914    0.3914     21274
   macro avg     0.3553    0.3856    0.3119     21274
weighted avg     0.6102    0.3914    0.4365     21274

F1-macro tok:  0.3118683824670246
F1-micro tok:  0.39141675284384697
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 6943.890630722046
train_cost_avg: 0.8127212816856327
train_count_sent: 8544.0
train_total_correct_sent: 5535.0
train_accuracy_sent: 0.6478230337078652
train_count_tok: 163566.0
train_total_correct_tok: 58402.0
train_accuracy_tok: 0.35705464460829267
train_label=O_precision_sent: 0.45588235294117646
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.10175054704595185
train_label=N_precision_sent: 0.6189332051898125
train_label=N_recall_sent: 0.7782477341389729
train_label=N_f-score_sent: 0.6895074946466808
train_label=P_precision_sent: 0.6859741503111536
train_label=P_recall_sent: 0.7939058171745152
train_label=P_f-score_sent: 0.7360041088854647
train_precision_macro_sent: 0.5869299028140476
train_recall_macro_sent: 0.5431398537219017
train_f-score_macro_sent: 0.5090873835260324
train_precision_micro_sent: 0.6478230337078652
train_recall_micro_sent: 0.6478230337078652
train_f-score_micro_sent: 0.6478230337078652
train_label=O_precision_tok: 0.7528977588276393
train_label=O_recall_tok: 0.33797357395031646
train_label=O_f-score_tok: 0.4665253155423331
train_label=N_precision_tok: 0.10355029585798817
train_label=N_recall_tok: 0.18729756372341924
train_label=N_f-score_tok: 0.1333667585861118
train_label=P_precision_tok: 0.16714802763865025
train_label=P_recall_tok: 0.5482671783187433
train_label=P_f-score_tok: 0.25619186372296315
train_precision_macro_tok: 0.3411986941080926
train_recall_macro_tok: 0.35784610533082634
train_f-score_macro_tok: 0.285361312617136
train_precision_micro_tok: 0.35705464460829267
train_recall_micro_tok: 0.35705464460829267
train_f-score_micro_tok: 0.3570546446082927
train_time: 124.48142838478088
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4559    0.0573    0.1018      1624
           N     0.6189    0.7782    0.6895      3310
           P     0.6860    0.7939    0.7360      3610

   micro avg     0.6478    0.6478    0.6478      8544
   macro avg     0.5869    0.5431    0.5091      8544
weighted avg     0.6163    0.6478    0.5974      8544

F1-macro sent:  0.5090873835260324
F1-micro sent:  0.6478230337078652
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7529    0.3380    0.4665    124347
           N     0.1036    0.1873    0.1334     14202
           P     0.1671    0.5483    0.2562     25017

   micro avg     0.3571    0.3571    0.3571    163566
   macro avg     0.3412    0.3578    0.2854    163566
weighted avg     0.6069    0.3571    0.4054    163566

F1-macro tok:  0.285361312617136
F1-micro tok:  0.3570546446082927
**************************************************
dev_cost_sum: 916.170804977417
dev_cost_avg: 0.8321260717324405
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 7813.0
dev_accuracy_tok: 0.3672558052082354
dev_label=O_precision_sent: 0.45454545454545453
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0796812749003984
dev_label=N_precision_sent: 0.6211849192100538
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7025380710659898
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7204968944099379
dev_precision_macro_sent: 0.5807990134740583
dev_recall_macro_sent: 0.5452877070025991
dev_f-score_macro_sent: 0.5009054134587754
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.7482589631158112
dev_label=O_recall_tok: 0.3580376427028695
dev_label=O_f-score_tok: 0.48432739262907465
dev_label=N_precision_tok: 0.11442006269592477
dev_label=N_recall_tok: 0.2358642972536349
dev_label=N_f-score_tok: 0.154089709762533
dev_label=P_precision_tok: 0.16229880313660752
dev_label=P_recall_tok: 0.4897260273972603
dev_label=P_f-score_tok: 0.24380037197768137
dev_precision_macro_tok: 0.34165927631611454
dev_recall_macro_tok: 0.3612093224512549
dev_f-score_macro_tok: 0.29407249145642966
dev_precision_micro_tok: 0.3672558052082354
dev_recall_micro_tok: 0.3672558052082354
dev_f-score_micro_tok: 0.3672558052082354
dev_time: 7.124600648880005
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.0437    0.0797       229
           N     0.6212    0.8084    0.7025       428
           P     0.6667    0.7838    0.7205       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.5808    0.5453    0.5009      1101
weighted avg     0.6049    0.6394    0.5802      1101

F1-macro sent:  0.5009054134587754
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7483    0.3580    0.4843     16205
           N     0.1144    0.2359    0.1541      1857
           P     0.1623    0.4897    0.2438      3212

   micro avg     0.3673    0.3673    0.3673     21274
   macro avg     0.3417    0.3612    0.2941     21274
weighted avg     0.6045    0.3673    0.4192     21274

F1-macro tok:  0.29407249145642966
F1-micro tok:  0.3672558052082354
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 6838.470458984375
train_cost_avg: 0.8003827784391825
train_count_sent: 8544.0
train_total_correct_sent: 5603.0
train_accuracy_sent: 0.6557818352059925
train_count_tok: 163566.0
train_total_correct_tok: 53141.0
train_accuracy_tok: 0.3248902583666532
train_label=O_precision_sent: 0.522633744855967
train_label=O_recall_sent: 0.07820197044334976
train_label=O_f-score_sent: 0.13604713444027852
train_label=N_precision_sent: 0.6315273351311596
train_label=N_recall_sent: 0.7782477341389729
train_label=N_f-score_sent: 0.6972526728921369
train_label=P_precision_sent: 0.6868782567503553
train_label=P_recall_sent: 0.8033240997229917
train_label=P_f-score_sent: 0.7405515832482126
train_precision_macro_sent: 0.6136797789124939
train_recall_macro_sent: 0.5532579347684381
train_f-score_macro_sent: 0.5246171301935426
train_precision_micro_sent: 0.6557818352059925
train_recall_micro_sent: 0.6557818352059925
train_f-score_micro_sent: 0.6557818352059925
train_label=O_precision_tok: 0.745123482628715
train_label=O_recall_tok: 0.2863116922804732
train_label=O_f-score_tok: 0.4136713008418203
train_label=N_precision_tok: 0.10258566323313012
train_label=N_recall_tok: 0.1718067877763695
train_label=N_f-score_tok: 0.12846500118461582
train_label=P_precision_tok: 0.16411778132846383
train_label=P_recall_tok: 0.6035495862813287
train_label=P_f-score_tok: 0.2580628621237759
train_precision_macro_tok: 0.3372756423967696
train_recall_macro_tok: 0.35388935544605715
train_f-score_macro_tok: 0.2667330547167373
train_precision_micro_tok: 0.3248902583666532
train_recall_micro_tok: 0.3248902583666532
train_f-score_micro_tok: 0.3248902583666532
train_time: 124.82594227790833
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5226    0.0782    0.1360      1624
           N     0.6315    0.7782    0.6973      3310
           P     0.6869    0.8033    0.7406      3610

   micro avg     0.6558    0.6558    0.6558      8544
   macro avg     0.6137    0.5533    0.5246      8544
weighted avg     0.6342    0.6558    0.6089      8544

F1-macro sent:  0.5246171301935426
F1-micro sent:  0.6557818352059925
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7451    0.2863    0.4137    124347
           N     0.1026    0.1718    0.1285     14202
           P     0.1641    0.6035    0.2581     25017

   micro avg     0.3249    0.3249    0.3249    163566
   macro avg     0.3373    0.3539    0.2667    163566
weighted avg     0.6005    0.3249    0.3651    163566

F1-macro tok:  0.2667330547167373
F1-micro tok:  0.3248902583666532
**************************************************
dev_cost_sum: 950.0806579589844
dev_cost_avg: 0.8629252115885416
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 6505.0
dev_accuracy_tok: 0.30577230422111495
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0737704918032787
dev_label=N_precision_sent: 0.6774193548387096
dev_label=N_recall_sent: 0.6869158878504673
dev_label=N_f-score_sent: 0.6821345707656613
dev_label=P_precision_sent: 0.6058282208588958
dev_label=P_recall_sent: 0.8896396396396397
dev_label=P_f-score_sent: 0.7208029197080292
dev_precision_macro_sent: 0.6277491918992019
dev_recall_macro_sent: 0.5386189458445917
dev_f-score_macro_sent: 0.4922359940923231
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.7210101357155128
dev_label=O_recall_tok: 0.2589941376118482
dev_label=O_f-score_tok: 0.38109506946336147
dev_label=N_precision_tok: 0.11223551057957681
dev_label=N_recall_tok: 0.13139472267097468
dev_label=N_f-score_tok: 0.12106177127263706
dev_label=P_precision_tok: 0.15543339106860457
dev_label=P_recall_tok: 0.6425902864259029
dev_label=P_f-score_tok: 0.2503183554666182
dev_precision_macro_tok: 0.32955967912123135
dev_recall_macro_tok: 0.3443263822362419
dev_f-score_macro_tok: 0.25082506540087224
dev_precision_micro_tok: 0.30577230422111495
dev_recall_micro_tok: 0.30577230422111495
dev_f-score_micro_tok: 0.30577230422111495
dev_time: 7.117211103439331
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0393    0.0738       229
           N     0.6774    0.6869    0.6821       428
           P     0.6058    0.8896    0.7208       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.6277    0.5386    0.4922      1101
weighted avg     0.6324    0.6340    0.5712      1101

F1-macro sent:  0.4922359940923231
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7210    0.2590    0.3811     16205
           N     0.1122    0.1314    0.1211      1857
           P     0.1554    0.6426    0.2503      3212

   micro avg     0.3058    0.3058    0.3058     21274
   macro avg     0.3296    0.3443    0.2508     21274
weighted avg     0.5825    0.3058    0.3387     21274

F1-macro tok:  0.25082506540087224
F1-micro tok:  0.30577230422111495
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 6802.12851524353
train_cost_avg: 0.7961292737878664
train_count_sent: 8544.0
train_total_correct_sent: 5626.0
train_accuracy_sent: 0.6584737827715356
train_count_tok: 163566.0
train_total_correct_tok: 57109.0
train_accuracy_tok: 0.34914957876331265
train_label=O_precision_sent: 0.4775641025641026
train_label=O_recall_sent: 0.0917487684729064
train_label=O_f-score_sent: 0.15392561983471073
train_label=N_precision_sent: 0.6395233366434955
train_label=N_recall_sent: 0.7782477341389729
train_label=N_f-score_sent: 0.7020986644862359
train_label=P_precision_sent: 0.6900570884871551
train_label=P_recall_sent: 0.803601108033241
train_label=P_f-score_sent: 0.7425134374200153
train_precision_macro_sent: 0.6023815092315844
train_recall_macro_sent: 0.5578658702150401
train_f-score_macro_sent: 0.5328459072469873
train_precision_micro_sent: 0.6584737827715356
train_recall_micro_sent: 0.6584737827715356
train_f-score_micro_sent: 0.6584737827715356
train_label=O_precision_tok: 0.7460840123525692
train_label=O_recall_tok: 0.32252486992046453
train_label=O_f-score_tok: 0.45036243479823246
train_label=N_precision_tok: 0.10977025794144481
train_label=N_recall_tok: 0.1863821996901845
train_label=N_f-score_tok: 0.1381668232592129
train_label=P_precision_tok: 0.16753016406450558
train_label=P_recall_tok: 0.5738897549666226
train_label=P_f-score_tok: 0.2593505848349365
train_precision_macro_tok: 0.34112814478617315
train_recall_macro_tok: 0.3609322748590906
train_f-score_macro_tok: 0.28262661429746067
train_precision_micro_tok: 0.34914957876331265
train_recall_micro_tok: 0.34914957876331265
train_f-score_micro_tok: 0.34914957876331265
train_time: 125.43448042869568
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4776    0.0917    0.1539      1624
           N     0.6395    0.7782    0.7021      3310
           P     0.6901    0.8036    0.7425      3610

   micro avg     0.6585    0.6585    0.6585      8544
   macro avg     0.6024    0.5579    0.5328      8544
weighted avg     0.6301    0.6585    0.6150      8544

F1-macro sent:  0.5328459072469873
F1-micro sent:  0.6584737827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7461    0.3225    0.4504    124347
           N     0.1098    0.1864    0.1382     14202
           P     0.1675    0.5739    0.2594     25017

   micro avg     0.3491    0.3491    0.3491    163566
   macro avg     0.3411    0.3609    0.2826    163566
weighted avg     0.6023    0.3491    0.3940    163566

F1-macro tok:  0.28262661429746067
F1-micro tok:  0.34914957876331265
**************************************************
dev_cost_sum: 911.6819009780884
dev_cost_avg: 0.8280489563833682
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 5897.0
dev_accuracy_tok: 0.2771928175237379
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.5746951219512195
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.6955719557195572
dev_label=P_precision_sent: 0.7227272727272728
dev_label=P_recall_sent: 0.7162162162162162
dev_label=P_f-score_sent: 0.7194570135746606
dev_precision_macro_sent: 0.6991407982261642
dev_recall_macro_sent: 0.5381748622066135
dev_f-score_macro_sent: 0.483072334494084
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.7198004771199306
dev_label=O_recall_tok: 0.20481332921937673
dev_label=O_f-score_tok: 0.31888931591083786
dev_label=N_precision_tok: 0.10921985815602837
dev_label=N_recall_tok: 0.16585891222401722
dev_label=N_f-score_tok: 0.13170836005986744
dev_label=P_precision_tok: 0.16398179585349995
dev_label=P_recall_tok: 0.7067247820672479
dev_label=P_f-score_tok: 0.26619759601289944
dev_precision_macro_tok: 0.3310007103764863
dev_recall_macro_tok: 0.3591323411702139
dev_f-score_macro_tok: 0.23893175732786828
dev_precision_micro_tok: 0.2771928175237379
dev_recall_micro_tok: 0.2771928175237379
dev_f-score_micro_tok: 0.2771928175237379
dev_time: 7.147000074386597
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.5747    0.8808    0.6956       428
           P     0.7227    0.7162    0.7195       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.6991    0.5382    0.4831      1101
weighted avg     0.6813    0.6349    0.5676      1101

F1-macro sent:  0.483072334494084
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7198    0.2048    0.3189     16205
           N     0.1092    0.1659    0.1317      1857
           P     0.1640    0.7067    0.2662      3212

   micro avg     0.2772    0.2772    0.2772     21274
   macro avg     0.3310    0.3591    0.2389     21274
weighted avg     0.5826    0.2772    0.2946     21274

F1-macro tok:  0.23893175732786828
F1-micro tok:  0.2771928175237379
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 6759.738569259644
train_cost_avg: 0.7911679037054826
train_count_sent: 8544.0
train_total_correct_sent: 5675.0
train_accuracy_sent: 0.6642088014981273
train_count_tok: 163566.0
train_total_correct_tok: 53205.0
train_accuracy_tok: 0.32528153772788965
train_label=O_precision_sent: 0.49122807017543857
train_label=O_recall_sent: 0.06896551724137931
train_label=O_f-score_sent: 0.12095032397408208
train_label=N_precision_sent: 0.6264447526583449
train_label=N_recall_sent: 0.8187311178247734
train_label=N_f-score_sent: 0.7097957045573597
train_label=P_precision_sent: 0.7150375939849624
train_label=P_recall_sent: 0.7903047091412743
train_label=P_f-score_sent: 0.7507894736842105
train_precision_macro_sent: 0.6109034722729153
train_recall_macro_sent: 0.5593337814024757
train_f-score_macro_sent: 0.5271785007385508
train_precision_micro_sent: 0.6642088014981273
train_recall_micro_sent: 0.6642088014981273
train_f-score_micro_sent: 0.6642088014981273
train_label=O_precision_tok: 0.7380197062963507
train_label=O_recall_tok: 0.28250782085615256
train_label=O_f-score_tok: 0.40860502715968966
train_label=N_precision_tok: 0.09752483876590552
train_label=N_recall_tok: 0.15758343895226024
train_label=N_f-score_tok: 0.12048452220726784
train_label=P_precision_tok: 0.17026628968275298
train_label=P_recall_tok: 0.6330894991405844
train_label=P_f-score_tok: 0.26835880578806465
train_precision_macro_tok: 0.3352702782483364
train_recall_macro_tok: 0.35772691964966574
train_f-score_macro_tok: 0.2658161183850074
train_precision_micro_tok: 0.32528153772788965
train_recall_micro_tok: 0.32528153772788965
train_f-score_micro_tok: 0.32528153772788965
train_time: 124.91307640075684
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4912    0.0690    0.1210      1624
           N     0.6264    0.8187    0.7098      3310
           P     0.7150    0.7903    0.7508      3610

   micro avg     0.6642    0.6642    0.6642      8544
   macro avg     0.6109    0.5593    0.5272      8544
weighted avg     0.6382    0.6642    0.6152      8544

F1-macro sent:  0.5271785007385508
F1-micro sent:  0.6642088014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7380    0.2825    0.4086    124347
           N     0.0975    0.1576    0.1205     14202
           P     0.1703    0.6331    0.2684     25017

   micro avg     0.3253    0.3253    0.3253    163566
   macro avg     0.3353    0.3577    0.2658    163566
weighted avg     0.5956    0.3253    0.3621    163566

F1-macro tok:  0.2658161183850074
F1-micro tok:  0.32528153772788965
**************************************************
dev_cost_sum: 895.6274881362915
dev_cost_avg: 0.8134672916769223
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 6650.0
dev_accuracy_tok: 0.31258813575256184
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09716599190283401
dev_label=N_precision_sent: 0.6142131979695431
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7124631992149166
dev_label=P_precision_sent: 0.7012195121951219
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7371794871794871
dev_precision_macro_sent: 0.6606997922771106
dev_recall_macro_sent: 0.5591865382911377
dev_f-score_macro_sent: 0.515602892765746
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.7281603288797533
dev_label=O_recall_tok: 0.2623264424560321
dev_label=O_f-score_tok: 0.3857006759515493
dev_label=N_precision_tok: 0.12533692722371967
dev_label=N_recall_tok: 0.20032310177705978
dev_label=N_f-score_tok: 0.15419689119170985
dev_label=P_precision_tok: 0.16257619505935195
dev_label=P_recall_tok: 0.6310709838107098
dev_label=P_f-score_tok: 0.2585459183673469
dev_precision_macro_tok: 0.3386911503876083
dev_recall_macro_tok: 0.3645735093479339
dev_f-score_macro_tok: 0.2661478285035353
dev_precision_micro_tok: 0.31258813575256184
dev_recall_micro_tok: 0.31258813575256184
dev_f-score_micro_tok: 0.31258813575256184
dev_time: 7.195618391036987
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0524    0.0972       229
           N     0.6142    0.8481    0.7125       428
           P     0.7012    0.7770    0.7372       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6607    0.5592    0.5156      1101
weighted avg     0.6602    0.6540    0.5945      1101

F1-macro sent:  0.515602892765746
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7282    0.2623    0.3857     16205
           N     0.1253    0.2003    0.1542      1857
           P     0.1626    0.6311    0.2585      3212

   micro avg     0.3126    0.3126    0.3126     21274
   macro avg     0.3387    0.3646    0.2661     21274
weighted avg     0.5901    0.3126    0.3463     21274

F1-macro tok:  0.2661478285035353
F1-micro tok:  0.31258813575256184
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 6674.029334068298
train_cost_avg: 0.7811363920960087
train_count_sent: 8544.0
train_total_correct_sent: 5705.0
train_accuracy_sent: 0.6677200374531835
train_count_tok: 163566.0
train_total_correct_tok: 54949.0
train_accuracy_tok: 0.3359439003215827
train_label=O_precision_sent: 0.5236051502145923
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.1313947226709747
train_label=N_precision_sent: 0.6409638554216868
train_label=N_recall_sent: 0.8036253776435045
train_label=N_f-score_sent: 0.71313672922252
train_label=P_precision_sent: 0.7024753664984379
train_label=P_recall_sent: 0.8096952908587257
train_label=P_f-score_sent: 0.7522841333161755
train_precision_macro_sent: 0.6223481240449057
train_recall_macro_sent: 0.5628146070705299
train_f-score_macro_sent: 0.5322718617365568
train_precision_micro_sent: 0.6677200374531835
train_recall_micro_sent: 0.6677200374531835
train_f-score_micro_sent: 0.6677200374531835
train_label=O_precision_tok: 0.7426839382330872
train_label=O_recall_tok: 0.3024680933195011
train_label=O_f-score_tok: 0.42986702021269907
train_label=N_precision_tok: 0.10961035019159995
train_label=N_recall_tok: 0.20342205323193915
train_label=N_f-score_tok: 0.14245913360783058
train_label=P_precision_tok: 0.1669111786246491
train_label=P_recall_tok: 0.5775672542670983
train_label=P_f-score_tok: 0.25897978204760536
train_precision_macro_tok: 0.3397351556831121
train_recall_macro_tok: 0.3611524669395128
train_f-score_macro_tok: 0.27710197862271163
train_precision_micro_tok: 0.3359439003215827
train_recall_micro_tok: 0.3359439003215827
train_f-score_micro_tok: 0.3359439003215827
train_time: 125.65038990974426
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5236    0.0751    0.1314      1624
           N     0.6410    0.8036    0.7131      3310
           P     0.7025    0.8097    0.7523      3610

   micro avg     0.6677    0.6677    0.6677      8544
   macro avg     0.6223    0.5628    0.5323      8544
weighted avg     0.6446    0.6677    0.6191      8544

F1-macro sent:  0.5322718617365568
F1-micro sent:  0.6677200374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7427    0.3025    0.4299    124347
           N     0.1096    0.2034    0.1425     14202
           P     0.1669    0.5776    0.2590     25017

   micro avg     0.3359    0.3359    0.3359    163566
   macro avg     0.3397    0.3612    0.2771    163566
weighted avg     0.5997    0.3359    0.3788    163566

F1-macro tok:  0.27710197862271163
F1-micro tok:  0.3359439003215827
**************************************************
dev_cost_sum: 892.0281314849854
dev_cost_avg: 0.8101981212397688
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 6545.0
dev_accuracy_tok: 0.30765253360910033
dev_label=O_precision_sent: 0.3888888888888889
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10566037735849056
dev_label=N_precision_sent: 0.6385321100917432
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7153134635149023
dev_label=P_precision_sent: 0.6923076923076923
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7468879668049794
dev_precision_macro_sent: 0.5732428970961081
dev_recall_macro_sent: 0.5616767647131277
dev_f-score_macro_sent: 0.5226206025594574
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.7175025588536336
dev_label=O_recall_tok: 0.25954952175254553
dev_label=O_f-score_tok: 0.38120270086554586
dev_label=N_precision_tok: 0.10361340879407924
dev_label=N_recall_tok: 0.12816370490037696
dev_label=N_f-score_tok: 0.11458834857968224
dev_label=P_precision_tok: 0.1601982462828822
dev_label=P_recall_tok: 0.6541095890410958
dev_label=P_f-score_tok: 0.25736510075335334
dev_precision_macro_tok: 0.327104737976865
dev_recall_macro_tok: 0.34727427189800614
dev_f-score_macro_tok: 0.25105205006619385
dev_precision_micro_tok: 0.30765253360910033
dev_recall_micro_tok: 0.30765253360910033
dev_f-score_micro_tok: 0.30765253360910033
dev_time: 7.12339186668396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3889    0.0611    0.1057       229
           N     0.6385    0.8131    0.7153       428
           P     0.6923    0.8108    0.7469       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.5732    0.5617    0.5226      1101
weighted avg     0.6083    0.6558    0.6012      1101

F1-macro sent:  0.5226206025594574
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7175    0.2595    0.3812     16205
           N     0.1036    0.1282    0.1146      1857
           P     0.1602    0.6541    0.2574      3212

   micro avg     0.3077    0.3077    0.3077     21274
   macro avg     0.3271    0.3473    0.2511     21274
weighted avg     0.5798    0.3077    0.3392     21274

F1-macro tok:  0.25105205006619385
F1-micro tok:  0.30765253360910033
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 6626.438396453857
train_cost_avg: 0.7755662917197866
train_count_sent: 8544.0
train_total_correct_sent: 5714.0
train_accuracy_sent: 0.6687734082397003
train_count_tok: 163566.0
train_total_correct_tok: 58920.0
train_accuracy_tok: 0.3602215619383001
train_label=O_precision_sent: 0.47416413373860183
train_label=O_recall_sent: 0.0960591133004926
train_label=O_f-score_sent: 0.1597542242703533
train_label=N_precision_sent: 0.6265417999086341
train_label=N_recall_sent: 0.8287009063444108
train_label=N_f-score_sent: 0.713579604578564
train_label=P_precision_sent: 0.7336460776648424
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7560091311937692
train_precision_macro_sent: 0.6114506704373595
train_recall_macro_sent: 0.5681794709989013
train_f-score_macro_sent: 0.5431143200142289
train_precision_micro_sent: 0.6687734082397003
train_recall_micro_sent: 0.6687734082397003
train_f-score_micro_sent: 0.6687734082397003
train_label=O_precision_tok: 0.7402532345269558
train_label=O_recall_tok: 0.34463235944574455
train_label=O_f-score_tok: 0.4703080586924791
train_label=N_precision_tok: 0.0964190867814615
train_label=N_recall_tok: 0.158498802985495
train_label=N_f-score_tok: 0.11989986151059977
train_label=P_precision_tok: 0.167802353970047
train_label=P_recall_tok: 0.552224487348603
train_label=P_f-score_tok: 0.25739198479682524
train_precision_macro_tok: 0.3348248917594881
train_recall_macro_tok: 0.3517852165932808
train_f-score_macro_tok: 0.2825333016666347
train_precision_micro_tok: 0.3602215619383001
train_recall_micro_tok: 0.3602215619383001
train_f-score_micro_tok: 0.3602215619383002
train_time: 124.41921281814575
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4742    0.0961    0.1598      1624
           N     0.6265    0.8287    0.7136      3310
           P     0.7336    0.7798    0.7560      3610

   micro avg     0.6688    0.6688    0.6688      8544
   macro avg     0.6115    0.5682    0.5431      8544
weighted avg     0.6428    0.6688    0.6262      8544

F1-macro sent:  0.5431143200142289
F1-micro sent:  0.6687734082397003
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7403    0.3446    0.4703    124347
           N     0.0964    0.1585    0.1199     14202
           P     0.1678    0.5522    0.2574     25017

   micro avg     0.3602    0.3602    0.3602    163566
   macro avg     0.3348    0.3518    0.2825    163566
weighted avg     0.5968    0.3602    0.4073    163566

F1-macro tok:  0.2825333016666347
F1-micro tok:  0.3602215619383002
**************************************************
dev_cost_sum: 901.1240978240967
dev_cost_avg: 0.8184596710482258
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 8973.0
dev_accuracy_tok: 0.4217824574598101
dev_label=O_precision_sent: 0.4827586206896552
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10852713178294573
dev_label=N_precision_sent: 0.5644699140401146
dev_label=N_recall_sent: 0.9205607476635514
dev_label=N_f-score_sent: 0.6998223801065718
dev_label=P_precision_sent: 0.7647058823529411
dev_label=P_recall_sent: 0.6441441441441441
dev_label=P_f-score_sent: 0.6992665036674817
dev_precision_macro_sent: 0.6039781390275704
dev_recall_macro_sent: 0.5419467543289116
dev_f-score_macro_sent: 0.5025386718523331
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.7442827442827443
dev_label=O_recall_tok: 0.44183893859919776
dev_label=O_f-score_tok: 0.5545014520813165
dev_label=N_precision_tok: 0.11608570514870482
dev_label=N_recall_tok: 0.19547657512116318
dev_label=N_f-score_tok: 0.1456661316211878
dev_label=P_precision_tok: 0.17004808256127596
dev_label=P_recall_tok: 0.45143212951432127
dev_label=P_f-score_tok: 0.24703978192350284
dev_precision_macro_tok: 0.3434721773309084
dev_recall_macro_tok: 0.3629158810782274
dev_f-score_macro_tok: 0.3157357885420024
dev_precision_micro_tok: 0.4217824574598101
dev_recall_micro_tok: 0.4217824574598101
dev_f-score_micro_tok: 0.4217824574598101
dev_time: 7.2606048583984375
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4828    0.0611    0.1085       229
           N     0.5645    0.9206    0.6998       428
           P     0.7647    0.6441    0.6993       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.6040    0.5419    0.5025      1101
weighted avg     0.6282    0.6303    0.5766      1101

F1-macro sent:  0.5025386718523331
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7443    0.4418    0.5545     16205
           N     0.1161    0.1955    0.1457      1857
           P     0.1700    0.4514    0.2470      3212

   micro avg     0.4218    0.4218    0.4218     21274
   macro avg     0.3435    0.3629    0.3157     21274
weighted avg     0.6027    0.4218    0.4724     21274

F1-macro tok:  0.3157357885420024
F1-micro tok:  0.4217824574598101
**************************************************
Best epoch: 13
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 6549.210383415222
train_cost_avg: 0.7665274325158266
train_count_sent: 8544.0
train_total_correct_sent: 5746.0
train_accuracy_sent: 0.6725187265917603
train_count_tok: 163566.0
train_total_correct_tok: 55085.0
train_accuracy_tok: 0.3367753689642102
train_label=O_precision_sent: 0.5067567567567568
train_label=O_recall_sent: 0.09236453201970443
train_label=O_f-score_sent: 0.15625
train_label=N_precision_sent: 0.6377083822493543
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.7176641564275333
train_label=P_precision_sent: 0.7219854600150414
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.757994472956968
train_precision_macro_sent: 0.6221501996737175
train_recall_macro_sent: 0.5702307573947453
train_f-score_macro_sent: 0.5439695431281671
train_precision_micro_sent: 0.6725187265917603
train_recall_micro_sent: 0.6725187265917603
train_f-score_micro_sent: 0.6725187265917603
train_label=O_precision_tok: 0.7393249450768924
train_label=O_recall_tok: 0.29769918051903144
train_label=O_f-score_tok: 0.42447697185480776
train_label=N_precision_tok: 0.10108842901854534
train_label=N_recall_tok: 0.15237290522461625
train_label=N_f-score_tok: 0.12154230672021119
train_label=P_precision_tok: 0.1726916352658841
train_label=P_recall_tok: 0.6356877323420075
train_label=P_f-score_tok: 0.27160008880842995
train_precision_macro_tok: 0.3377016697871073
train_recall_macro_tok: 0.36191993936188505
train_f-score_macro_tok: 0.2725397891278163
train_precision_micro_tok: 0.3367753689642102
train_recall_micro_tok: 0.3367753689642102
train_f-score_micro_tok: 0.3367753689642102
train_time: 125.06231832504272
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5068    0.0924    0.1562      1624
           N     0.6377    0.8205    0.7177      3310
           P     0.7220    0.7978    0.7580      3610

   micro avg     0.6725    0.6725    0.6725      8544
   macro avg     0.6222    0.5702    0.5440      8544
weighted avg     0.6484    0.6725    0.6280      8544

F1-macro sent:  0.5439695431281671
F1-micro sent:  0.6725187265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7393    0.2977    0.4245    124347
           N     0.1011    0.1524    0.1215     14202
           P     0.1727    0.6357    0.2716     25017

   micro avg     0.3368    0.3368    0.3368    163566
   macro avg     0.3377    0.3619    0.2725    163566
weighted avg     0.5972    0.3368    0.3748    163566

F1-macro tok:  0.2725397891278163
F1-micro tok:  0.3367753689642102
**************************************************
dev_cost_sum: 905.9082851409912
dev_cost_avg: 0.8228049819627531
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 7658.0
dev_accuracy_tok: 0.35996991632979225
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12549019607843137
dev_label=N_precision_sent: 0.659877800407332
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.705114254624592
dev_label=P_precision_sent: 0.660958904109589
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7509727626459143
dev_precision_macro_sent: 0.6454071066338455
dev_recall_macro_sent: 0.5654159035989832
dev_f-score_macro_sent: 0.5271924044496459
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.7325982996811902
dev_label=O_recall_tok: 0.34032705954952175
dev_label=O_f-score_tok: 0.4647537184511018
dev_label=N_precision_tok: 0.11671270718232044
dev_label=N_recall_tok: 0.1820140010770059
dev_label=N_f-score_tok: 0.14222596254996844
dev_label=P_precision_tok: 0.1663594470046083
dev_label=P_recall_tok: 0.5619551681195517
dev_label=P_f-score_tok: 0.2567202389418291
dev_precision_macro_tok: 0.33855681795603965
dev_recall_macro_tok: 0.3614320762486931
dev_f-score_macro_tok: 0.2878999733142998
dev_precision_micro_tok: 0.35996991632979225
dev_recall_micro_tok: 0.35996991632979225
dev_f-score_micro_tok: 0.35996991632979225
dev_time: 7.1198248863220215
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0699    0.1255       229
           N     0.6599    0.7570    0.7051       428
           P     0.6610    0.8694    0.7510       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.6454    0.5654    0.5272      1101
weighted avg     0.6511    0.6594    0.6031      1101

F1-macro sent:  0.5271924044496459
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7326    0.3403    0.4648     16205
           N     0.1167    0.1820    0.1422      1857
           P     0.1664    0.5620    0.2567      3212

   micro avg     0.3600    0.3600    0.3600     21274
   macro avg     0.3386    0.3614    0.2879     21274
weighted avg     0.5933    0.3600    0.4052     21274

F1-macro tok:  0.2878999733142998
F1-micro tok:  0.35996991632979225
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 6522.586178779602
train_cost_avg: 0.7634113036961144
train_count_sent: 8544.0
train_total_correct_sent: 5844.0
train_accuracy_sent: 0.6839887640449438
train_count_tok: 163566.0
train_total_correct_tok: 67863.0
train_accuracy_tok: 0.4148967389310737
train_label=O_precision_sent: 0.4693396226415094
train_label=O_recall_sent: 0.12253694581280788
train_label=O_f-score_sent: 0.19433593750000003
train_label=N_precision_sent: 0.6531874405328258
train_label=N_recall_sent: 0.829607250755287
train_label=N_f-score_sent: 0.7309023156774022
train_label=P_precision_sent: 0.7402962206332993
train_label=P_recall_sent: 0.8030470914127423
train_label=P_f-score_sent: 0.7703959606696783
train_precision_macro_sent: 0.6209410946025449
train_recall_macro_sent: 0.585063762660279
train_f-score_macro_sent: 0.5652114046156935
train_precision_micro_sent: 0.6839887640449438
train_recall_micro_sent: 0.6839887640449438
train_f-score_micro_sent: 0.6839887640449438
train_label=O_precision_tok: 0.7570651244943308
train_label=O_recall_tok: 0.4274248675078611
train_label=O_f-score_tok: 0.5463760145154741
train_label=N_precision_tok: 0.10425275167294401
train_label=N_recall_tok: 0.20074637375017604
train_label=N_f-score_tok: 0.13723555320224315
train_label=P_precision_tok: 0.17970158297356661
train_label=P_recall_tok: 0.4741975456689451
train_label=P_f-score_tok: 0.2606336233412426
train_precision_macro_tok: 0.3470064863802805
train_recall_macro_tok: 0.3674562623089941
train_f-score_macro_tok: 0.3147483970196533
train_precision_micro_tok: 0.4148967389310737
train_recall_micro_tok: 0.4148967389310737
train_f-score_micro_tok: 0.4148967389310737
train_time: 126.22667455673218
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4693    0.1225    0.1943      1624
           N     0.6532    0.8296    0.7309      3310
           P     0.7403    0.8030    0.7704      3610

   micro avg     0.6840    0.6840    0.6840      8544
   macro avg     0.6209    0.5851    0.5652      8544
weighted avg     0.6550    0.6840    0.6456      8544

F1-macro sent:  0.5652114046156935
F1-micro sent:  0.6839887640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7571    0.4274    0.5464    124347
           N     0.1043    0.2007    0.1372     14202
           P     0.1797    0.4742    0.2606     25017

   micro avg     0.4149    0.4149    0.4149    163566
   macro avg     0.3470    0.3675    0.3147    163566
weighted avg     0.6121    0.4149    0.4671    163566

F1-macro tok:  0.3147483970196533
F1-micro tok:  0.4148967389310737
**************************************************
dev_cost_sum: 897.8500347137451
dev_cost_avg: 0.8154859534184787
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 10008.0
dev_accuracy_tok: 0.4704333928739306
dev_label=O_precision_sent: 0.390625
dev_label=O_recall_sent: 0.1091703056768559
dev_label=O_f-score_sent: 0.1706484641638225
dev_label=N_precision_sent: 0.6747967479674797
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7217391304347825
dev_label=P_precision_sent: 0.6825688073394496
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7522750252780586
dev_precision_macro_sent: 0.5826635184356431
dev_recall_macro_sent: 0.574236359364711
dev_f-score_macro_sent: 0.5482208732922212
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.7628875695033456
dev_label=O_recall_tok: 0.49953717988275226
dev_label=O_f-score_tok: 0.6037440334128878
dev_label=N_precision_tok: 0.1159785691774346
dev_label=N_recall_tok: 0.1981690899299946
dev_label=N_f-score_tok: 0.1463220675944334
dev_label=P_precision_tok: 0.20627503337783712
dev_label=P_recall_tok: 0.48100871731008715
dev_label=P_f-score_tok: 0.2887310783031209
dev_precision_macro_tok: 0.3617137240195391
dev_recall_macro_tok: 0.39290499570761134
dev_f-score_macro_tok: 0.3462657264368141
dev_precision_micro_tok: 0.4704333928739306
dev_recall_micro_tok: 0.4704333928739306
dev_f-score_micro_tok: 0.47043339287393054
dev_time: 7.073348760604858
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3906    0.1092    0.1706       229
           N     0.6748    0.7757    0.7217       428
           P     0.6826    0.8378    0.7523       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5827    0.5742    0.5482      1101
weighted avg     0.6188    0.6621    0.6194      1101

F1-macro sent:  0.5482208732922212
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7629    0.4995    0.6037     16205
           N     0.1160    0.1982    0.1463      1857
           P     0.2063    0.4810    0.2887      3212

   micro avg     0.4704    0.4704    0.4704     21274
   macro avg     0.3617    0.3929    0.3463     21274
weighted avg     0.6224    0.4704    0.5163     21274

F1-macro tok:  0.3462657264368141
F1-micro tok:  0.47043339287393054
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 6377.562069892883
train_cost_avg: 0.7464375081803468
train_count_sent: 8544.0
train_total_correct_sent: 5823.0
train_accuracy_sent: 0.6815308988764045
train_count_tok: 163566.0
train_total_correct_tok: 72106.0
train_accuracy_tok: 0.44083733783304596
train_label=O_precision_sent: 0.4525862068965517
train_label=O_recall_sent: 0.12931034482758622
train_label=O_f-score_sent: 0.20114942528735635
train_label=N_precision_sent: 0.6443621208613105
train_label=N_recall_sent: 0.840785498489426
train_label=N_f-score_sent: 0.7295844802726439
train_label=P_precision_sent: 0.7524594522733316
train_label=P_recall_sent: 0.7839335180055401
train_label=P_f-score_sent: 0.7678741012074346
train_precision_macro_sent: 0.6164692600103979
train_recall_macro_sent: 0.5846764537741841
train_f-score_macro_sent: 0.5662026689224783
train_precision_micro_sent: 0.6815308988764045
train_recall_micro_sent: 0.6815308988764045
train_f-score_micro_sent: 0.6815308988764045
train_label=O_precision_tok: 0.7615140356494824
train_label=O_recall_tok: 0.4590138885538051
train_label=O_f-score_tok: 0.5727775854369566
train_label=N_precision_tok: 0.10922202973288747
train_label=N_recall_tok: 0.19088860723841714
train_label=N_f-score_tok: 0.13894369986930785
train_label=P_precision_tok: 0.1930932860972207
train_label=P_recall_tok: 0.49238517807890636
train_label=P_f-score_tok: 0.27740119355928383
train_precision_macro_tok: 0.35460978382653024
train_recall_macro_tok: 0.3807625579570429
train_f-score_macro_tok: 0.32970749295518276
train_precision_micro_tok: 0.44083733783304596
train_recall_micro_tok: 0.44083733783304596
train_f-score_micro_tok: 0.44083733783304596
train_time: 127.93608736991882
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4526    0.1293    0.2011      1624
           N     0.6444    0.8408    0.7296      3310
           P     0.7525    0.7839    0.7679      3610

   micro avg     0.6815    0.6815    0.6815      8544
   macro avg     0.6165    0.5847    0.5662      8544
weighted avg     0.6536    0.6815    0.6453      8544

F1-macro sent:  0.5662026689224783
F1-micro sent:  0.6815308988764045
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7615    0.4590    0.5728    124347
           N     0.1092    0.1909    0.1389     14202
           P     0.1931    0.4924    0.2774     25017

   micro avg     0.4408    0.4408    0.4408    163566
   macro avg     0.3546    0.3808    0.3297    163566
weighted avg     0.6179    0.4408    0.4899    163566

F1-macro tok:  0.32970749295518276
F1-micro tok:  0.44083733783304596
**************************************************
dev_cost_sum: 909.0116329193115
dev_cost_avg: 0.825623644795015
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 7853.0
dev_accuracy_tok: 0.36913603459622074
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04201680672268907
dev_label=N_precision_sent: 0.6528599605522682
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7080213903743315
dev_label=P_precision_sent: 0.6598290598290598
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7502429543245869
dev_precision_macro_sent: 0.6227481919789613
dev_recall_macro_sent: 0.5548559721620163
dev_f-score_macro_sent: 0.5000937171405359
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.7431679490581056
dev_label=O_recall_tok: 0.3456957729095958
dev_label=O_f-score_tok: 0.47188645074337704
dev_label=N_precision_tok: 0.1282642089093702
dev_label=N_recall_tok: 0.17985998922994076
dev_label=N_f-score_tok: 0.14974221026675635
dev_label=P_precision_tok: 0.17220625224577793
dev_label=P_recall_tok: 0.5968244084682441
dev_label=P_f-score_tok: 0.26728945900725043
dev_precision_macro_tok: 0.34787947007108455
dev_recall_macro_tok: 0.3741267235359269
dev_f-score_macro_tok: 0.2963060400057946
dev_precision_micro_tok: 0.36913603459622074
dev_recall_micro_tok: 0.36913603459622074
dev_f-score_micro_tok: 0.36913603459622074
dev_time: 7.218321323394775
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0218    0.0420       229
           N     0.6529    0.7734    0.7080       428
           P     0.6598    0.8694    0.7502       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6227    0.5549    0.5001      1101
weighted avg     0.6354    0.6558    0.5865      1101

F1-macro sent:  0.5000937171405359
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7432    0.3457    0.4719     16205
           N     0.1283    0.1799    0.1497      1857
           P     0.1722    0.5968    0.2673      3212

   micro avg     0.3691    0.3691    0.3691     21274
   macro avg     0.3479    0.3741    0.2963     21274
weighted avg     0.6033    0.3691    0.4129     21274

F1-macro tok:  0.2963060400057946
F1-micro tok:  0.36913603459622074
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 6393.842693328857
train_cost_avg: 0.7483430118596509
train_count_sent: 8544.0
train_total_correct_sent: 5832.0
train_accuracy_sent: 0.6825842696629213
train_count_tok: 163566.0
train_total_correct_tok: 63508.0
train_accuracy_tok: 0.38827140114693764
train_label=O_precision_sent: 0.43151969981238275
train_label=O_recall_sent: 0.1416256157635468
train_label=O_f-score_sent: 0.21325915623551228
train_label=N_precision_sent: 0.6623730492940302
train_label=N_recall_sent: 0.8078549848942598
train_label=N_f-score_sent: 0.7279161562542533
train_label=P_precision_sent: 0.7367891293407146
train_label=P_recall_sent: 0.8110803324099723
train_label=P_f-score_sent: 0.7721518987341772
train_precision_macro_sent: 0.6102272928157092
train_recall_macro_sent: 0.5868536443559264
train_f-score_macro_sent: 0.571109070407981
train_precision_micro_sent: 0.6825842696629213
train_recall_micro_sent: 0.6825842696629213
train_f-score_micro_sent: 0.6825842696629213
train_label=O_precision_tok: 0.755688429217841
train_label=O_recall_tok: 0.37606054026233043
train_label=O_f-score_tok: 0.5022042990543798
train_label=N_precision_tok: 0.11187254474028809
train_label=N_recall_tok: 0.18046753978312913
train_label=N_f-score_tok: 0.1381224401810735
train_label=P_precision_tok: 0.1800421448156799
train_label=P_recall_tok: 0.5669344845505057
train_label=P_f-score_tok: 0.2732939600936479
train_precision_macro_tok: 0.34920103959126964
train_recall_macro_tok: 0.37448752153198833
train_f-score_macro_tok: 0.3045402331097004
train_precision_micro_tok: 0.38827140114693764
train_recall_micro_tok: 0.38827140114693764
train_f-score_micro_tok: 0.38827140114693764
train_time: 126.61010718345642
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4315    0.1416    0.2133      1624
           N     0.6624    0.8079    0.7279      3310
           P     0.7368    0.8111    0.7722      3610

   micro avg     0.6826    0.6826    0.6826      8544
   macro avg     0.6102    0.5869    0.5711      8544
weighted avg     0.6499    0.6826    0.6488      8544

F1-macro sent:  0.571109070407981
F1-micro sent:  0.6825842696629213
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7557    0.3761    0.5022    124347
           N     0.1119    0.1805    0.1381     14202
           P     0.1800    0.5669    0.2733     25017

   micro avg     0.3883    0.3883    0.3883    163566
   macro avg     0.3492    0.3745    0.3045    163566
weighted avg     0.6117    0.3883    0.4356    163566

F1-macro tok:  0.3045402331097004
F1-micro tok:  0.38827140114693764
**************************************************
dev_cost_sum: 881.9072351455688
dev_cost_avg: 0.8010056631658209
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 6623.0
dev_accuracy_tok: 0.31131898091567173
dev_label=O_precision_sent: 0.3902439024390244
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.11851851851851851
dev_label=N_precision_sent: 0.6155234657039711
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.6945010183299389
dev_label=P_precision_sent: 0.6936758893280632
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7389473684210527
dev_precision_macro_sent: 0.5664810858236863
dev_recall_macro_sent: 0.5523795027121151
dev_f-score_macro_sent: 0.5173223017565034
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.7438692098092643
dev_label=O_recall_tok: 0.2526997840172786
dev_label=O_f-score_tok: 0.3772455089820359
dev_label=N_precision_tok: 0.1261237440507668
dev_label=N_recall_tok: 0.2568659127625202
dev_label=N_f-score_tok: 0.16917893243482884
dev_label=P_precision_tok: 0.17110202719612913
dev_label=P_recall_tok: 0.6385429638854296
dev_label=P_f-score_tok: 0.26988617672215276
dev_precision_macro_tok: 0.3470316603520534
dev_recall_macro_tok: 0.3827028868884095
dev_f-score_macro_tok: 0.2721035393796725
dev_precision_micro_tok: 0.31131898091567173
dev_recall_micro_tok: 0.31131898091567173
dev_f-score_micro_tok: 0.31131898091567173
dev_time: 7.208090305328369
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3902    0.0699    0.1185       229
           N     0.6155    0.7967    0.6945       428
           P     0.6937    0.7905    0.7389       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.5665    0.5524    0.5173      1101
weighted avg     0.6002    0.6431    0.5926      1101

F1-macro sent:  0.5173223017565034
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7439    0.2527    0.3772     16205
           N     0.1261    0.2569    0.1692      1857
           P     0.1711    0.6385    0.2699      3212

   micro avg     0.3113    0.3113    0.3113     21274
   macro avg     0.3470    0.3827    0.2721     21274
weighted avg     0.6035    0.3113    0.3429     21274

F1-macro tok:  0.2721035393796725
F1-micro tok:  0.31131898091567173
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 6397.747317314148
train_cost_avg: 0.7488000137305885
train_count_sent: 8544.0
train_total_correct_sent: 5835.0
train_accuracy_sent: 0.682935393258427
train_count_tok: 163566.0
train_total_correct_tok: 56241.0
train_accuracy_tok: 0.3438428524265434
train_label=O_precision_sent: 0.4710526315789474
train_label=O_recall_sent: 0.1102216748768473
train_label=O_f-score_sent: 0.17864271457085829
train_label=N_precision_sent: 0.6572057744066553
train_label=N_recall_sent: 0.8114803625377643
train_label=N_f-score_sent: 0.7262403677166418
train_label=P_precision_sent: 0.7284768211920529
train_label=P_recall_sent: 0.8227146814404432
train_label=P_f-score_sent: 0.7727331858982697
train_precision_macro_sent: 0.6189117423925519
train_recall_macro_sent: 0.5814722396183516
train_f-score_macro_sent: 0.5592054227285899
train_precision_micro_sent: 0.682935393258427
train_recall_micro_sent: 0.682935393258427
train_f-score_micro_sent: 0.682935393258427
train_label=O_precision_tok: 0.7450885512435885
train_label=O_recall_tok: 0.30957723145713206
train_label=O_f-score_tok: 0.43741335818012406
train_label=N_precision_tok: 0.10933892969569779
train_label=N_recall_tok: 0.1834248697366568
train_label=N_f-score_tok: 0.13700791542851132
train_label=P_precision_tok: 0.1719083518779236
train_label=P_recall_tok: 0.6052284446576328
train_label=P_f-score_tok: 0.26776193044662355
train_precision_macro_tok: 0.34211194427240327
train_recall_macro_tok: 0.36607684861714057
train_f-score_macro_tok: 0.2807277346850863
train_precision_micro_tok: 0.3438428524265434
train_recall_micro_tok: 0.3438428524265434
train_f-score_micro_tok: 0.3438428524265434
train_time: 125.96323776245117
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4711    0.1102    0.1786      1624
           N     0.6572    0.8115    0.7262      3310
           P     0.7285    0.8227    0.7727      3610

   micro avg     0.6829    0.6829    0.6829      8544
   macro avg     0.6189    0.5815    0.5592      8544
weighted avg     0.6519    0.6829    0.6418      8544

F1-macro sent:  0.5592054227285899
F1-micro sent:  0.682935393258427
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7451    0.3096    0.4374    124347
           N     0.1093    0.1834    0.1370     14202
           P     0.1719    0.6052    0.2678     25017

   micro avg     0.3438    0.3438    0.3438    163566
   macro avg     0.3421    0.3661    0.2807    163566
weighted avg     0.6022    0.3438    0.3854    163566

F1-macro tok:  0.2807277346850863
F1-micro tok:  0.3438428524265434
**************************************************
dev_cost_sum: 982.258955001831
dev_cost_avg: 0.8921516394203733
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 6538.0
dev_accuracy_tok: 0.30732349346620286
dev_label=O_precision_sent: 0.44680851063829785
dev_label=O_recall_sent: 0.09170305676855896
dev_label=O_f-score_sent: 0.15217391304347827
dev_label=N_precision_sent: 0.6981981981981982
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.7110091743119266
dev_label=P_precision_sent: 0.6409836065573771
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.7419354838709676
dev_precision_macro_sent: 0.595330105131291
dev_recall_macro_sent: 0.5655442509399168
dev_f-score_macro_sent: 0.5350395237421242
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.7318149717514124
dev_label=O_recall_tok: 0.25578525146559705
dev_label=O_f-score_tok: 0.3790754035392565
dev_label=N_precision_tok: 0.12749905695963787
dev_label=N_recall_tok: 0.1820140010770059
dev_label=N_f-score_tok: 0.14995563442768411
dev_label=P_precision_tok: 0.15857705069835634
dev_label=P_recall_tok: 0.6397882938978829
dev_label=P_f-score_tok: 0.2541586791169377
dev_precision_macro_tok: 0.33929702646980225
dev_recall_macro_tok: 0.35919584881349537
dev_f-score_macro_tok: 0.2610632390279594
dev_precision_micro_tok: 0.30732349346620286
dev_recall_micro_tok: 0.30732349346620286
dev_f-score_micro_tok: 0.30732349346620286
dev_time: 7.337871789932251
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4468    0.0917    0.1522       229
           N     0.6982    0.7243    0.7110       428
           P     0.6410    0.8806    0.7419       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.5953    0.5655    0.5350      1101
weighted avg     0.6228    0.6558    0.6072      1101

F1-macro sent:  0.5350395237421242
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7318    0.2558    0.3791     16205
           N     0.1275    0.1820    0.1500      1857
           P     0.1586    0.6398    0.2542      3212

   micro avg     0.3073    0.3073    0.3073     21274
   macro avg     0.3393    0.3592    0.2611     21274
weighted avg     0.5925    0.3073    0.3402     21274

F1-macro tok:  0.2610632390279594
F1-micro tok:  0.30732349346620286
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 6358.463480949402
train_cost_avg: 0.7442021864407071
train_count_sent: 8544.0
train_total_correct_sent: 5894.0
train_accuracy_sent: 0.6898408239700374
train_count_tok: 163566.0
train_total_correct_tok: 53397.0
train_accuracy_tok: 0.326455375811599
train_label=O_precision_sent: 0.5013698630136987
train_label=O_recall_sent: 0.11268472906403941
train_label=O_f-score_sent: 0.18401206636500755
train_label=N_precision_sent: 0.6593855016802689
train_label=N_recall_sent: 0.8299093655589124
train_label=N_f-score_sent: 0.7348849652220439
train_label=P_precision_sent: 0.7385995514577622
train_label=P_recall_sent: 0.8210526315789474
train_label=P_f-score_sent: 0.7776465958284139
train_precision_macro_sent: 0.6331183053839099
train_recall_macro_sent: 0.5878822420672997
train_f-score_macro_sent: 0.5655145424718219
train_precision_micro_sent: 0.6898408239700374
train_recall_micro_sent: 0.6898408239700374
train_f-score_micro_sent: 0.6898408239700374
train_label=O_precision_tok: 0.7391993658343242
train_label=O_recall_tok: 0.2849686763653325
train_label=O_f-score_tok: 0.41135566854728245
train_label=N_precision_tok: 0.10879354070700274
train_label=N_recall_tok: 0.14800732291226587
train_label=N_f-score_tok: 0.12540643737135698
train_label=P_precision_tok: 0.1646799850479711
train_label=P_recall_tok: 0.6339689011472199
train_label=P_f-score_tok: 0.2614465279208737
train_precision_macro_tok: 0.33755763052976606
train_recall_macro_tok: 0.35564830014160614
train_f-score_macro_tok: 0.26606954461317106
train_precision_micro_tok: 0.326455375811599
train_recall_micro_tok: 0.326455375811599
train_f-score_micro_tok: 0.326455375811599
train_time: 126.64293217658997
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5014    0.1127    0.1840      1624
           N     0.6594    0.8299    0.7349      3310
           P     0.7386    0.8211    0.7776      3610

   micro avg     0.6898    0.6898    0.6898      8544
   macro avg     0.6331    0.5879    0.5655      8544
weighted avg     0.6628    0.6898    0.6482      8544

F1-macro sent:  0.5655145424718219
F1-micro sent:  0.6898408239700374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7392    0.2850    0.4114    124347
           N     0.1088    0.1480    0.1254     14202
           P     0.1647    0.6340    0.2614     25017

   micro avg     0.3265    0.3265    0.3265    163566
   macro avg     0.3376    0.3556    0.2661    163566
weighted avg     0.5966    0.3265    0.3636    163566

F1-macro tok:  0.26606954461317106
F1-micro tok:  0.326455375811599
**************************************************
dev_cost_sum: 983.3424301147461
dev_cost_avg: 0.8931357221750645
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 6931.0
dev_accuracy_tok: 0.32579674720315877
dev_label=O_precision_sent: 0.5588235294117647
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14448669201520914
dev_label=N_precision_sent: 0.7222222222222222
dev_label=N_recall_sent: 0.6074766355140186
dev_label=N_f-score_sent: 0.6598984771573604
dev_label=P_precision_sent: 0.5827439886845828
dev_label=P_recall_sent: 0.9279279279279279
dev_label=P_f-score_sent: 0.7158992180712425
dev_precision_macro_sent: 0.6212632467728566
dev_recall_macro_sent: 0.5394579985854523
dev_f-score_macro_sent: 0.506761462414604
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.7364843503003478
dev_label=O_recall_tok: 0.2875038568343104
dev_label=O_f-score_tok: 0.41356353468554435
dev_label=N_precision_tok: 0.11027985591576614
dev_label=N_recall_tok: 0.2143241787829833
dev_label=N_f-score_tok: 0.1456275155506769
dev_label=P_precision_tok: 0.16527030602345885
dev_label=P_recall_tok: 0.5834371108343711
dev_label=P_f-score_tok: 0.2575767988454402
dev_precision_macro_tok: 0.33734483741319093
dev_recall_macro_tok: 0.3617550488172216
dev_f-score_macro_tok: 0.27225594969388717
dev_precision_micro_tok: 0.32579674720315877
dev_recall_micro_tok: 0.32579674720315877
dev_f-score_micro_tok: 0.32579674720315877
dev_time: 6.933574914932251
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5588    0.0830    0.1445       229
           N     0.7222    0.6075    0.6599       428
           P     0.5827    0.9279    0.7159       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.6213    0.5395    0.5068      1101
weighted avg     0.6320    0.6276    0.5753      1101

F1-macro sent:  0.506761462414604
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7365    0.2875    0.4136     16205
           N     0.1103    0.2143    0.1456      1857
           P     0.1653    0.5834    0.2576      3212

   micro avg     0.3258    0.3258    0.3258     21274
   macro avg     0.3373    0.3618    0.2723     21274
weighted avg     0.5956    0.3258    0.3666     21274

F1-macro tok:  0.27225594969388717
F1-micro tok:  0.32579674720315877
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 6149.0831298828125
train_cost_avg: 0.7196960592091307
train_count_sent: 8544.0
train_total_correct_sent: 6012.0
train_accuracy_sent: 0.7036516853932584
train_count_tok: 163566.0
train_total_correct_tok: 59180.0
train_accuracy_tok: 0.3618111343433232
train_label=O_precision_sent: 0.550761421319797
train_label=O_recall_sent: 0.1336206896551724
train_label=O_f-score_sent: 0.21506442021803768
train_label=N_precision_sent: 0.6748540856031129
train_label=N_recall_sent: 0.8383685800604229
train_label=N_f-score_sent: 0.747776879547292
train_label=P_precision_sent: 0.7478949975235265
train_label=P_recall_sent: 0.8365650969529086
train_label=P_f-score_sent: 0.7897489539748954
train_precision_macro_sent: 0.6578368348154787
train_recall_macro_sent: 0.602851455556168
train_f-score_macro_sent: 0.5841967512467418
train_precision_micro_sent: 0.7036516853932584
train_recall_micro_sent: 0.7036516853932584
train_f-score_micro_sent: 0.7036516853932584
train_label=O_precision_tok: 0.751808482956024
train_label=O_recall_tok: 0.3485246929962122
train_label=O_f-score_tok: 0.47626269286562045
train_label=N_precision_tok: 0.09161136971377637
train_label=N_recall_tok: 0.19539501478664978
train_label=N_f-score_tok: 0.12473872294518239
train_label=P_precision_tok: 0.17277535369562344
train_label=P_recall_tok: 0.5223248191229963
train_label=P_f-score_tok: 0.2596599998012857
train_precision_macro_tok: 0.3387317354551413
train_recall_macro_tok: 0.35541484230195275
train_f-score_macro_tok: 0.2868871385373628
train_precision_micro_tok: 0.3618111343433232
train_recall_micro_tok: 0.3618111343433232
train_f-score_micro_tok: 0.3618111343433231
train_time: 126.16182971000671
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5508    0.1336    0.2151      1624
           N     0.6749    0.8384    0.7478      3310
           P     0.7479    0.8366    0.7897      3610

   micro avg     0.7037    0.7037    0.7037      8544
   macro avg     0.6578    0.6029    0.5842      8544
weighted avg     0.6821    0.7037    0.6643      8544

F1-macro sent:  0.5841967512467418
F1-micro sent:  0.7036516853932584
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7518    0.3485    0.4763    124347
           N     0.0916    0.1954    0.1247     14202
           P     0.1728    0.5223    0.2597     25017

   micro avg     0.3618    0.3618    0.3618    163566
   macro avg     0.3387    0.3554    0.2869    163566
weighted avg     0.6059    0.3618    0.4126    163566

F1-macro tok:  0.2868871385373628
F1-micro tok:  0.3618111343433231
**************************************************
dev_cost_sum: 886.2420778274536
dev_cost_avg: 0.8049428499795219
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 6906.0
dev_accuracy_tok: 0.32462160383566796
dev_label=O_precision_sent: 0.4722222222222222
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.12830188679245283
dev_label=N_precision_sent: 0.658252427184466
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7189819724284199
dev_label=P_precision_sent: 0.6672727272727272
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.738430583501006
dev_precision_macro_sent: 0.5992491255598051
dev_recall_macro_sent: 0.5642894864010645
dev_f-score_macro_sent: 0.5285714809072929
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.7297751949839425
dev_label=O_recall_tok: 0.29447701326751
dev_label=O_f-score_tok: 0.41962715441435106
dev_label=N_precision_tok: 0.09764414135151891
dev_label=N_recall_tok: 0.16962843295638125
dev_label=N_f-score_tok: 0.12394255361007278
dev_label=P_precision_tok: 0.15805022156573117
dev_label=P_recall_tok: 0.5663138231631383
dev_label=P_f-score_tok: 0.24712995041097752
dev_precision_macro_tok: 0.3284898526337308
dev_recall_macro_tok: 0.34347308979567653
dev_f-score_macro_tok: 0.26356655281180047
dev_precision_micro_tok: 0.32462160383566796
dev_recall_micro_tok: 0.32462160383566796
dev_f-score_micro_tok: 0.32462160383566796
dev_time: 7.291337013244629
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4722    0.0742    0.1283       229
           N     0.6583    0.7921    0.7190       428
           P     0.6673    0.8266    0.7384       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.5992    0.5643    0.5286      1101
weighted avg     0.6232    0.6567    0.6040      1101

F1-macro sent:  0.5285714809072929
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7298    0.2945    0.4196     16205
           N     0.0976    0.1696    0.1239      1857
           P     0.1581    0.5663    0.2471      3212

   micro avg     0.3246    0.3246    0.3246     21274
   macro avg     0.3285    0.3435    0.2636     21274
weighted avg     0.5883    0.3246    0.3678     21274

F1-macro tok:  0.26356655281180047
F1-micro tok:  0.32462160383566796
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.810000
train_cost_sum: 6188.988845825195
train_cost_avg: 0.7243666720301024
train_count_sent: 8544.0
train_total_correct_sent: 5924.0
train_accuracy_sent: 0.6933520599250936
train_count_tok: 163566.0
train_total_correct_tok: 57817.0
train_accuracy_tok: 0.3534781066969908
train_label=O_precision_sent: 0.5188916876574308
train_label=O_recall_sent: 0.1268472906403941
train_label=O_f-score_sent: 0.20385947550717468
train_label=N_precision_sent: 0.6618380432201377
train_label=N_recall_sent: 0.8419939577039275
train_label=N_f-score_sent: 0.7411248504188273
train_label=P_precision_sent: 0.7446646341463414
train_label=P_recall_sent: 0.8119113573407202
train_label=P_f-score_sent: 0.7768354094884707
train_precision_macro_sent: 0.6417981216746367
train_recall_macro_sent: 0.5935842018950139
train_f-score_macro_sent: 0.5739399118048242
train_precision_micro_sent: 0.6933520599250936
train_recall_micro_sent: 0.6933520599250936
train_f-score_micro_sent: 0.6933520599250936
train_label=O_precision_tok: 0.7446448904070595
train_label=O_recall_tok: 0.33659838998930414
train_label=O_f-score_tok: 0.4636260419262829
train_label=N_precision_tok: 0.10027426081076005
train_label=N_recall_tok: 0.18793127728488945
train_label=N_f-score_tok: 0.13077243440554645
train_label=P_precision_tok: 0.16463754474182882
train_label=P_recall_tok: 0.5313586761002518
train_label=P_f-score_tok: 0.25138523799617996
train_precision_macro_tok: 0.33651889865321616
train_recall_macro_tok: 0.3519627811248151
train_f-score_macro_tok: 0.2819279047760031
train_precision_micro_tok: 0.3534781066969908
train_recall_micro_tok: 0.3534781066969908
train_f-score_micro_tok: 0.3534781066969908
train_time: 126.44427275657654
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5189    0.1268    0.2039      1624
           N     0.6618    0.8420    0.7411      3310
           P     0.7447    0.8119    0.7768      3610

   micro avg     0.6934    0.6934    0.6934      8544
   macro avg     0.6418    0.5936    0.5739      8544
weighted avg     0.6697    0.6934    0.6541      8544

F1-macro sent:  0.5739399118048242
F1-micro sent:  0.6933520599250936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7446    0.3366    0.4636    124347
           N     0.1003    0.1879    0.1308     14202
           P     0.1646    0.5314    0.2514     25017

   micro avg     0.3535    0.3535    0.3535    163566
   macro avg     0.3365    0.3520    0.2819    163566
weighted avg     0.6000    0.3535    0.4023    163566

F1-macro tok:  0.2819279047760031
F1-micro tok:  0.3534781066969908
**************************************************
dev_cost_sum: 911.6334552764893
dev_cost_avg: 0.8280049548378648
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 7874.0
dev_accuracy_tok: 0.37012315502491305
dev_label=O_precision_sent: 0.5405405405405406
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.15037593984962405
dev_label=N_precision_sent: 0.6518518518518519
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7272727272727273
dev_label=P_precision_sent: 0.6851145038167938
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7417355371900827
dev_precision_macro_sent: 0.6258356320697288
dev_recall_macro_sent: 0.5727749032140331
dev_f-score_macro_sent: 0.5397947347708113
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.7489566207158215
dev_label=O_recall_tok: 0.3654427645788337
dev_label=O_f-score_tok: 0.4912076974120769
dev_label=N_precision_tok: 0.11435997400909681
dev_label=N_recall_tok: 0.284329563812601
dev_label=N_f-score_tok: 0.16311399443929564
dev_label=P_precision_tok: 0.16274285714285713
dev_label=P_recall_tok: 0.44333748443337484
dev_label=P_f-score_tok: 0.23808727637518812
dev_precision_macro_tok: 0.3420198172892585
dev_recall_macro_tok: 0.36436993760826986
dev_f-score_macro_tok: 0.29746965607552023
dev_precision_micro_tok: 0.37012315502491305
dev_recall_micro_tok: 0.37012315502491305
dev_f-score_micro_tok: 0.37012315502491305
dev_time: 7.203340530395508
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5405    0.0873    0.1504       229
           N     0.6519    0.8224    0.7273       428
           P     0.6851    0.8086    0.7417       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6258    0.5728    0.5398      1101
weighted avg     0.6421    0.6639    0.6131      1101

F1-macro sent:  0.5397947347708113
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7490    0.3654    0.4912     16205
           N     0.1144    0.2843    0.1631      1857
           P     0.1627    0.4433    0.2381      3212

   micro avg     0.3701    0.3701    0.3701     21274
   macro avg     0.3420    0.3644    0.2975     21274
weighted avg     0.6051    0.3701    0.4244     21274

F1-macro tok:  0.29746965607552023
F1-micro tok:  0.37012315502491305
**************************************************
Best epoch: 16
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 6113.053112983704
train_cost_avg: 0.7154790628492163
train_count_sent: 8544.0
train_total_correct_sent: 5972.0
train_accuracy_sent: 0.6989700374531835
train_count_tok: 163566.0
train_total_correct_tok: 66098.0
train_accuracy_tok: 0.40410598779697493
train_label=O_precision_sent: 0.5273224043715847
train_label=O_recall_sent: 0.1188423645320197
train_label=O_f-score_sent: 0.19396984924623115
train_label=N_precision_sent: 0.6748660496833901
train_label=N_recall_sent: 0.8371601208459214
train_label=N_f-score_sent: 0.7473031283710895
train_label=P_precision_sent: 0.7387033398821218
train_label=P_recall_sent: 0.8332409972299168
train_label=P_f-score_sent: 0.7831293933871387
train_precision_macro_sent: 0.6469639313123655
train_recall_macro_sent: 0.5964144942026194
train_f-score_macro_sent: 0.5748007903348198
train_precision_micro_sent: 0.6989700374531835
train_recall_micro_sent: 0.6989700374531835
train_f-score_micro_sent: 0.6989700374531835
train_label=O_precision_tok: 0.7569347464977142
train_label=O_recall_tok: 0.4140992545055369
train_label=O_f-score_tok: 0.5353322174514227
train_label=N_precision_tok: 0.10286240374958151
train_label=N_recall_tok: 0.25961132234896495
train_label=N_f-score_tok: 0.14734444311233666
train_label=P_precision_tok: 0.1829131418041712
train_label=P_recall_tok: 0.436463205020586
train_label=P_f-score_tok: 0.257791103975824
train_precision_macro_tok: 0.347570097350489
train_recall_macro_tok: 0.37005792729169595
train_f-score_macro_tok: 0.3134892548465278
train_precision_micro_tok: 0.40410598779697493
train_recall_micro_tok: 0.40410598779697493
train_f-score_micro_tok: 0.40410598779697493
train_time: 127.04383730888367
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5273    0.1188    0.1940      1624
           N     0.6749    0.8372    0.7473      3310
           P     0.7387    0.8332    0.7831      3610

   micro avg     0.6990    0.6990    0.6990      8544
   macro avg     0.6470    0.5964    0.5748      8544
weighted avg     0.6738    0.6990    0.6573      8544

F1-macro sent:  0.5748007903348198
F1-micro sent:  0.6989700374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7569    0.4141    0.5353    124347
           N     0.1029    0.2596    0.1473     14202
           P     0.1829    0.4365    0.2578     25017

   micro avg     0.4041    0.4041    0.4041    163566
   macro avg     0.3476    0.3701    0.3135    163566
weighted avg     0.6123    0.4041    0.4592    163566

F1-macro tok:  0.3134892548465278
F1-micro tok:  0.40410598779697493
**************************************************
dev_cost_sum: 891.0885486602783
dev_cost_avg: 0.8093447308449394
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 7951.0
dev_accuracy_tok: 0.3737425965967848
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11811023622047244
dev_label=N_precision_sent: 0.66600790513834
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.7216274089935761
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7495069033530573
dev_precision_macro_sent: 0.6442248572683354
dev_recall_macro_sent: 0.5695804056106876
dev_f-score_macro_sent: 0.5297481828557019
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.7568134171907757
dev_label=O_recall_tok: 0.3564331996297439
dev_label=O_f-score_tok: 0.4846247430465243
dev_label=N_precision_tok: 0.11305022299786698
dev_label=N_recall_tok: 0.3139472267097469
dev_label=N_f-score_tok: 0.16623895067008837
dev_label=P_precision_tok: 0.1876252209781968
dev_label=P_recall_tok: 0.49564134495641343
dev_label=P_f-score_tok: 0.27220654868769767
dev_precision_macro_tok: 0.35249628705561314
dev_recall_macro_tok: 0.3886739237653014
dev_f-score_macro_tok: 0.3076900808014368
dev_precision_micro_tok: 0.3737425965967848
dev_recall_micro_tok: 0.3737425965967848
dev_f-score_micro_tok: 0.3737425965967848
dev_time: 7.003551721572876
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0655    0.1181       229
           N     0.6660    0.7874    0.7216       428
           P     0.6667    0.8559    0.7495       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6442    0.5696    0.5297      1101
weighted avg     0.6525    0.6649    0.6073      1101

F1-macro sent:  0.5297481828557019
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7568    0.3564    0.4846     16205
           N     0.1131    0.3139    0.1662      1857
           P     0.1876    0.4956    0.2722      3212

   micro avg     0.3737    0.3737    0.3737     21274
   macro avg     0.3525    0.3887    0.3077     21274
weighted avg     0.6147    0.3737    0.4248     21274

F1-macro tok:  0.3076900808014368
F1-micro tok:  0.3737425965967848
**************************************************
Best epoch: 16
**************************************************

test0_cost_sum: 897.8500347137451
test0_cost_avg: 0.8154859534184787
test0_count_sent: 1101.0
test0_total_correct_sent: 729.0
test0_accuracy_sent: 0.662125340599455
test0_count_tok: 21274.0
test0_total_correct_tok: 10008.0
test0_accuracy_tok: 0.4704333928739306
test0_label=O_precision_sent: 0.390625
test0_label=O_recall_sent: 0.1091703056768559
test0_label=O_f-score_sent: 0.1706484641638225
test0_label=N_precision_sent: 0.6747967479674797
test0_label=N_recall_sent: 0.7757009345794392
test0_label=N_f-score_sent: 0.7217391304347825
test0_label=P_precision_sent: 0.6825688073394496
test0_label=P_recall_sent: 0.8378378378378378
test0_label=P_f-score_sent: 0.7522750252780586
test0_precision_macro_sent: 0.5826635184356431
test0_recall_macro_sent: 0.574236359364711
test0_f-score_macro_sent: 0.5482208732922212
test0_precision_micro_sent: 0.662125340599455
test0_recall_micro_sent: 0.662125340599455
test0_f-score_micro_sent: 0.662125340599455
test0_label=O_precision_tok: 0.7628875695033456
test0_label=O_recall_tok: 0.49953717988275226
test0_label=O_f-score_tok: 0.6037440334128878
test0_label=N_precision_tok: 0.1159785691774346
test0_label=N_recall_tok: 0.1981690899299946
test0_label=N_f-score_tok: 0.1463220675944334
test0_label=P_precision_tok: 0.20627503337783712
test0_label=P_recall_tok: 0.48100871731008715
test0_label=P_f-score_tok: 0.2887310783031209
test0_precision_macro_tok: 0.3617137240195391
test0_recall_macro_tok: 0.39290499570761134
test0_f-score_macro_tok: 0.3462657264368141
test0_precision_micro_tok: 0.4704333928739306
test0_recall_micro_tok: 0.4704333928739306
test0_f-score_micro_tok: 0.47043339287393054
test0_time: 7.301867961883545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3906    0.1092    0.1706       229
           N     0.6748    0.7757    0.7217       428
           P     0.6826    0.8378    0.7523       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5827    0.5742    0.5482      1101
weighted avg     0.6188    0.6621    0.6194      1101

F1-macro sent:  0.5482208732922212
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7629    0.4995    0.6037     16205
           N     0.1160    0.1982    0.1463      1857
           P     0.2063    0.4810    0.2887      3212

   micro avg     0.4704    0.4704    0.4704     21274
   macro avg     0.3617    0.3929    0.3463     21274
weighted avg     0.6224    0.4704    0.5163     21274

F1-macro tok:  0.3462657264368141
F1-micro tok:  0.47043339287393054
**************************************************
test1_cost_sum: 1670.3136739730835
test1_cost_avg: 0.7557980425217572
test1_count_sent: 2210.0
test1_total_correct_sent: 1524.0
test1_accuracy_sent: 0.6895927601809955
test1_count_tok: 42405.0
test1_total_correct_tok: 20158.0
test1_accuracy_tok: 0.47536847069921
test1_label=O_precision_sent: 0.3875968992248062
test1_label=O_recall_sent: 0.12853470437017994
test1_label=O_f-score_sent: 0.19305019305019308
test1_label=N_precision_sent: 0.7034825870646766
test1_label=N_recall_sent: 0.7752192982456141
test1_label=N_f-score_sent: 0.7376108502869066
test1_label=P_precision_sent: 0.7128252788104089
test1_label=P_recall_sent: 0.8437843784378438
test1_label=P_f-score_sent: 0.7727959697732999
test1_precision_macro_sent: 0.6013015883666305
test1_recall_macro_sent: 0.5825127936845459
test1_f-score_macro_sent: 0.5678190043701332
test1_precision_micro_sent: 0.6895927601809955
test1_recall_micro_sent: 0.6895927601809955
test1_f-score_micro_sent: 0.6895927601809955
test1_label=O_precision_tok: 0.7607586045422617
test1_label=O_recall_tok: 0.5077192324520282
test1_label=O_f-score_tok: 0.6090004310910352
test1_label=N_precision_tok: 0.1106201930944199
test1_label=N_recall_tok: 0.1797872340425532
test1_label=N_f-score_tok: 0.1369668726572789
test1_label=P_precision_tok: 0.2166142312069081
test1_label=P_recall_tok: 0.4868361666917406
test1_label=P_f-score_tok: 0.29982395997405725
test1_precision_macro_tok: 0.36266434294786326
test1_recall_macro_tok: 0.39144754439544066
test1_f-score_macro_tok: 0.34859708790745714
test1_precision_micro_tok: 0.47536847069921
test1_recall_micro_tok: 0.47536847069921
test1_f-score_micro_tok: 0.47536847069921
test1_time: 14.439401388168335
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3876    0.1285    0.1931       389
           N     0.7035    0.7752    0.7376       912
           P     0.7128    0.8438    0.7728       909

   micro avg     0.6896    0.6896    0.6896      2210
   macro avg     0.6013    0.5825    0.5678      2210
weighted avg     0.6517    0.6896    0.6562      2210

F1-macro sent:  0.5678190043701332
F1-micro sent:  0.6895927601809955
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7608    0.5077    0.6090     31998
           N     0.1106    0.1798    0.1370      3760
           P     0.2166    0.4868    0.2998      6647

   micro avg     0.4754    0.4754    0.4754     42405
   macro avg     0.3627    0.3914    0.3486     42405
weighted avg     0.6178    0.4754    0.5187     42405

F1-macro tok:  0.34859708790745714
F1-micro tok:  0.47536847069921
**************************************************
