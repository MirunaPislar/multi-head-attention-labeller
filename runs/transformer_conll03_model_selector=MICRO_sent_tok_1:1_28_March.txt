to_write_filename: runs/transformer_conll03_model_selector=MICRO_sent_tok_1:1_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_micro_sent:dev_f-score_micro_tok:high
model_selector_ratio: 1:1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'PER': 4, 'ORG': 3, 'LOC': 1, 'O': 0, 'MISC': 2}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
n_preloaded_embeddings: 19871
Parameter count: 9797652.
Parameter count without word embeddings: 3230652.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 451928.0822753906
train_cost_avg: 32.186317375926976
train_count_sent: 14041.0
train_total_correct_sent: 11765.0
train_accuracy_sent: 0.8379032832419343
train_count_tok: 203621.0
train_total_correct_tok: 186731.0
train_accuracy_tok: 0.9170517775671468
train_label=0_precision_sent: 0.6640746500777605
train_label=0_recall_sent: 0.44035751117222416
train_label=0_f-score_sent: 0.5295576684580405
train_label=1_precision_sent: 0.8655878467635403
train_label=1_recall_sent: 0.9417894358605821
train_label=1_f-score_sent: 0.9020822577869557
train_precision_macro_sent: 0.7648312484206503
train_recall_macro_sent: 0.6910734735164031
train_f-score_macro_sent: 0.7158199631224982
train_precision_micro_sent: 0.8379032832419343
train_recall_micro_sent: 0.8379032832419343
train_f-score_micro_sent: 0.8379032832419343
train_label=O_precision_tok: 0.9473450849538708
train_label=O_recall_tok: 0.9827689912606589
train_label=O_f-score_tok: 0.9647319658347251
train_label=LOC_precision_tok: 0.6957953015112973
train_label=LOC_recall_tok: 0.5604435338074003
train_label=LOC_f-score_tok: 0.6208277703604808
train_label=MISC_precision_tok: 0.6138538078836586
train_label=MISC_recall_tok: 0.34922708469409974
train_label=MISC_f-score_tok: 0.4451845684152096
train_label=ORG_precision_tok: 0.6774151774151774
train_label=ORG_recall_tok: 0.5217955112219451
train_label=ORG_f-score_tok: 0.5895080858736688
train_label=PER_precision_tok: 0.8040059902658181
train_label=PER_recall_tok: 0.7719266714593818
train_label=PER_f-score_tok: 0.787639831285531
train_precision_macro_tok: 0.7476830724059644
train_recall_macro_tok: 0.6372323584886972
train_f-score_macro_tok: 0.681578444353923
train_precision_micro_tok: 0.9170517775671468
train_recall_micro_tok: 0.9170517775671468
train_f-score_micro_tok: 0.9170517775671468
train_time: 383.41140580177307
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6641    0.4404    0.5296      2909
           1     0.8656    0.9418    0.9021     11132

   micro avg     0.8379    0.8379    0.8379     14041
   macro avg     0.7648    0.6911    0.7158     14041
weighted avg     0.8238    0.8379    0.8249     14041

F1-macro sent:  0.7158199631224982
F1-micro sent:  0.8379032832419343
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9473    0.9828    0.9647    169578
         LOC     0.6958    0.5604    0.6208      8297
        MISC     0.6139    0.3492    0.4452      4593
         ORG     0.6774    0.5218    0.5895     10025
         PER     0.8040    0.7719    0.7876     11128

   micro avg     0.9171    0.9171    0.9171    203621
   macro avg     0.7477    0.6372    0.6816    203621
weighted avg     0.9084    0.9171    0.9108    203621

F1-macro tok:  0.681578444353923
F1-micro tok:  0.9170517775671468
**************************************************
dev_cost_sum: 102185.13380432129
dev_cost_avg: 31.441579632098858
dev_count_sent: 3250.0
dev_total_correct_sent: 2955.0
dev_accuracy_sent: 0.9092307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 49754.0
dev_accuracy_tok: 0.9686928079124645
dev_label=0_precision_sent: 0.9227053140096618
dev_label=0_recall_sent: 0.5922480620155038
dev_label=0_f-score_sent: 0.7214353163361662
dev_label=1_precision_sent: 0.9072637517630465
dev_label=1_recall_sent: 0.9877159309021113
dev_label=1_f-score_sent: 0.9457820253629846
dev_precision_macro_sent: 0.9149845328863542
dev_recall_macro_sent: 0.7899819964588075
dev_f-score_macro_sent: 0.8336086708495754
dev_precision_micro_sent: 0.9092307692307692
dev_recall_micro_sent: 0.9092307692307692
dev_f-score_micro_sent: 0.9092307692307692
dev_label=O_precision_tok: 0.9829257037378865
dev_label=O_recall_tok: 0.9962814845997334
dev_label=O_f-score_tok: 0.9895585314579728
dev_label=LOC_precision_tok: 0.9169262720664589
dev_label=LOC_recall_tok: 0.8433619866284623
dev_label=LOC_f-score_tok: 0.8786069651741294
dev_label=MISC_precision_tok: 0.8581560283687943
dev_label=MISC_recall_tok: 0.667981072555205
dev_label=MISC_f-score_tok: 0.751219512195122
dev_label=ORG_precision_tok: 0.8637698179682912
dev_label=ORG_recall_tok: 0.7031548757170172
dev_label=ORG_f-score_tok: 0.7752305665349143
dev_label=PER_precision_tok: 0.9013505578391074
dev_label=PER_recall_tok: 0.9749126706891077
dev_label=PER_f-score_tok: 0.936689549961861
dev_precision_macro_tok: 0.9046256759961077
dev_recall_macro_tok: 0.8371384180379051
dev_f-score_macro_tok: 0.8662610250648
dev_precision_micro_tok: 0.9686928079124645
dev_recall_micro_tok: 0.9686928079124645
dev_f-score_micro_tok: 0.9686928079124645
dev_time: 45.304731130599976
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9227    0.5922    0.7214       645
           1     0.9073    0.9877    0.9458      2605

   micro avg     0.9092    0.9092    0.9092      3250
   macro avg     0.9150    0.7900    0.8336      3250
weighted avg     0.9103    0.9092    0.9013      3250

F1-macro sent:  0.8336086708495754
F1-micro sent:  0.9092307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9829    0.9963    0.9896     42759
         LOC     0.9169    0.8434    0.8786      2094
        MISC     0.8582    0.6680    0.7512      1268
         ORG     0.8638    0.7032    0.7752      2092
         PER     0.9014    0.9749    0.9367      3149

   micro avg     0.9687    0.9687    0.9687     51362
   macro avg     0.9046    0.8371    0.8663     51362
weighted avg     0.9673    0.9687    0.9672     51362

F1-macro tok:  0.8662610250648
F1-micro tok:  0.9686928079124645
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 384248.3101196289
train_cost_avg: 27.366164099396688
train_count_sent: 14041.0
train_total_correct_sent: 12614.0
train_accuracy_sent: 0.8983690620326188
train_count_tok: 203621.0
train_total_correct_tok: 196113.0
train_accuracy_tok: 0.963127575250097
train_label=0_precision_sent: 0.7834736036725325
train_label=0_recall_sent: 0.7040220006875215
train_label=0_f-score_sent: 0.7416259279377151
train_label=1_precision_sent: 0.9246521396692046
train_label=1_recall_sent: 0.9491555874955084
train_label=1_f-score_sent: 0.9367436499844851
train_precision_macro_sent: 0.8540628716708685
train_recall_macro_sent: 0.826588794091515
train_f-score_macro_sent: 0.8391847889611002
train_precision_micro_sent: 0.8983690620326188
train_recall_micro_sent: 0.8983690620326188
train_f-score_micro_sent: 0.8983690620326188
train_label=O_precision_tok: 0.9875042552442217
train_label=O_recall_tok: 0.9921628984891908
train_label=O_f-score_tok: 0.9898280954005813
train_label=LOC_precision_tok: 0.8399615523248829
train_label=LOC_recall_tok: 0.8425937085693624
train_label=LOC_f-score_tok: 0.8412755716004814
train_label=MISC_precision_tok: 0.7664593053395542
train_label=MISC_recall_tok: 0.6438057914217287
train_label=MISC_f-score_tok: 0.6997988403739203
train_label=ORG_precision_tok: 0.788023703087639
train_label=ORG_recall_tok: 0.7561097256857855
train_label=ORG_f-score_tok: 0.7717369171248217
train_label=PER_precision_tok: 0.9032596347111771
train_label=PER_recall_tok: 0.9288281811646297
train_label=PER_f-score_tok: 0.9158654911169198
train_precision_macro_tok: 0.857041690141495
train_recall_macro_tok: 0.8327000610661394
train_f-score_macro_tok: 0.8437009831233448
train_precision_micro_tok: 0.963127575250097
train_recall_micro_tok: 0.963127575250097
train_f-score_micro_tok: 0.963127575250097
train_time: 420.3131196498871
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7835    0.7040    0.7416      2909
           1     0.9247    0.9492    0.9367     11132

   micro avg     0.8984    0.8984    0.8984     14041
   macro avg     0.8541    0.8266    0.8392     14041
weighted avg     0.8954    0.8984    0.8963     14041

F1-macro sent:  0.8391847889611002
F1-micro sent:  0.8983690620326188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9875    0.9922    0.9898    169578
         LOC     0.8400    0.8426    0.8413      8297
        MISC     0.7665    0.6438    0.6998      4593
         ORG     0.7880    0.7561    0.7717     10025
         PER     0.9033    0.9288    0.9159     11128

   micro avg     0.9631    0.9631    0.9631    203621
   macro avg     0.8570    0.8327    0.8437    203621
weighted avg     0.9621    0.9631    0.9625    203621

F1-macro tok:  0.8437009831233448
F1-micro tok:  0.963127575250097
**************************************************
dev_cost_sum: 99024.60838317871
dev_cost_avg: 30.469110271747297
dev_count_sent: 3250.0
dev_total_correct_sent: 3026.0
dev_accuracy_sent: 0.931076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50135.0
dev_accuracy_tok: 0.9761107433511156
dev_label=0_precision_sent: 0.7840755735492577
dev_label=0_recall_sent: 0.9007751937984496
dev_label=0_f-score_sent: 0.8383838383838383
dev_label=1_precision_sent: 0.9744918294141092
dev_label=1_recall_sent: 0.9385796545105566
dev_label=1_f-score_sent: 0.9561986703167774
dev_precision_macro_sent: 0.8792837014816834
dev_recall_macro_sent: 0.9196774241545032
dev_f-score_macro_sent: 0.8972912543503079
dev_precision_micro_sent: 0.931076923076923
dev_recall_micro_sent: 0.931076923076923
dev_f-score_micro_sent: 0.931076923076923
dev_label=O_precision_tok: 0.9915868465823021
dev_label=O_recall_tok: 0.995065366355621
dev_label=O_f-score_tok: 0.9933230611196713
dev_label=LOC_precision_tok: 0.9383812010443864
dev_label=LOC_recall_tok: 0.8581661891117478
dev_label=LOC_f-score_tok: 0.8964829134447493
dev_label=MISC_precision_tok: 0.9073514602215509
dev_label=MISC_recall_tok: 0.7105678233438486
dev_label=MISC_f-score_tok: 0.7969924812030076
dev_label=ORG_precision_tok: 0.8051601423487544
dev_label=ORG_recall_tok: 0.8652007648183556
dev_label=ORG_f-score_tok: 0.8341013824884793
dev_label=PER_precision_tok: 0.9338792841977556
dev_label=PER_recall_tok: 0.9777707208637663
dev_label=PER_f-score_tok: 0.9553211293825629
dev_precision_macro_tok: 0.9152717868789498
dev_recall_macro_tok: 0.8813541728986678
dev_f-score_macro_tok: 0.895244193527694
dev_precision_micro_tok: 0.9761107433511156
dev_recall_micro_tok: 0.9761107433511156
dev_f-score_micro_tok: 0.9761107433511156
dev_time: 43.00158452987671
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7841    0.9008    0.8384       645
           1     0.9745    0.9386    0.9562      2605

   micro avg     0.9311    0.9311    0.9311      3250
   macro avg     0.8793    0.9197    0.8973      3250
weighted avg     0.9367    0.9311    0.9328      3250

F1-macro sent:  0.8972912543503079
F1-micro sent:  0.931076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9916    0.9951    0.9933     42759
         LOC     0.9384    0.8582    0.8965      2094
        MISC     0.9074    0.7106    0.7970      1268
         ORG     0.8052    0.8652    0.8341      2092
         PER     0.9339    0.9778    0.9553      3149

   micro avg     0.9761    0.9761    0.9761     51362
   macro avg     0.9153    0.8814    0.8952     51362
weighted avg     0.9762    0.9761    0.9757     51362

F1-macro tok:  0.895244193527694
F1-micro tok:  0.9761107433511156
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 371839.443359375
train_cost_avg: 26.482404626406595
train_count_sent: 14041.0
train_total_correct_sent: 12867.0
train_accuracy_sent: 0.9163877216722456
train_count_tok: 203621.0
train_total_correct_tok: 197314.0
train_accuracy_tok: 0.9690257881063348
train_label=0_precision_sent: 0.8094898323225116
train_label=0_recall_sent: 0.7799931247851495
train_label=0_f-score_sent: 0.794467787114846
train_label=1_precision_sent: 0.9430503648336003
train_label=1_recall_sent: 0.9520301832554797
train_label=1_f-score_sent: 0.9475189986589182
train_precision_macro_sent: 0.8762700985780559
train_recall_macro_sent: 0.8660116540203147
train_f-score_macro_sent: 0.870993392886882
train_precision_micro_sent: 0.9163877216722456
train_recall_micro_sent: 0.9163877216722456
train_f-score_micro_sent: 0.9163877216722456
train_label=O_precision_tok: 0.9899385854074226
train_label=O_recall_tok: 0.9933069148120629
train_label=O_f-score_tok: 0.9916198897369405
train_label=LOC_precision_tok: 0.8650240384615384
train_label=LOC_recall_tok: 0.867421959744486
train_label=LOC_f-score_tok: 0.8662213395919842
train_label=MISC_precision_tok: 0.7824165029469549
train_label=MISC_recall_tok: 0.6936642717178315
train_label=MISC_f-score_tok: 0.7353721869590307
train_label=ORG_precision_tok: 0.8220260699989737
train_label=ORG_recall_tok: 0.7989027431421446
train_label=ORG_f-score_tok: 0.8102994738972077
train_label=PER_precision_tok: 0.924808048715912
train_label=PER_recall_tok: 0.9416786484543493
train_label=PER_f-score_tok: 0.9331671045015362
train_precision_macro_tok: 0.8768426491061602
train_recall_macro_tok: 0.858994907574175
train_f-score_macro_tok: 0.8673359989373399
train_precision_micro_tok: 0.9690257881063348
train_recall_micro_tok: 0.9690257881063348
train_f-score_micro_tok: 0.9690257881063348
train_time: 418.83103346824646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8095    0.7800    0.7945      2909
           1     0.9431    0.9520    0.9475     11132

   micro avg     0.9164    0.9164    0.9164     14041
   macro avg     0.8763    0.8660    0.8710     14041
weighted avg     0.9154    0.9164    0.9158     14041

F1-macro sent:  0.870993392886882
F1-micro sent:  0.9163877216722456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9899    0.9933    0.9916    169578
         LOC     0.8650    0.8674    0.8662      8297
        MISC     0.7824    0.6937    0.7354      4593
         ORG     0.8220    0.7989    0.8103     10025
         PER     0.9248    0.9417    0.9332     11128

   micro avg     0.9690    0.9690    0.9690    203621
   macro avg     0.8768    0.8590    0.8673    203621
weighted avg     0.9683    0.9690    0.9686    203621

F1-macro tok:  0.8673359989373399
F1-micro tok:  0.9690257881063348
**************************************************
dev_cost_sum: 96819.60231781006
dev_cost_avg: 29.79064686701848
dev_count_sent: 3250.0
dev_total_correct_sent: 2878.0
dev_accuracy_sent: 0.8855384615384615
dev_count_tok: 51362.0
dev_total_correct_tok: 50330.0
dev_accuracy_tok: 0.9799073244811339
dev_label=0_precision_sent: 0.989247311827957
dev_label=0_recall_sent: 0.42790697674418604
dev_label=0_f-score_sent: 0.5974025974025974
dev_label=1_precision_sent: 0.875799394143386
dev_label=1_recall_sent: 0.9988483685220729
dev_label=1_f-score_sent: 0.9332855093256814
dev_precision_macro_sent: 0.9325233529856716
dev_recall_macro_sent: 0.7133776726331295
dev_f-score_macro_sent: 0.7653440533641394
dev_precision_micro_sent: 0.8855384615384615
dev_recall_micro_sent: 0.8855384615384615
dev_f-score_micro_sent: 0.8855384615384615
dev_label=O_precision_tok: 0.9923370755112498
dev_label=O_recall_tok: 0.9963984190462827
dev_label=O_f-score_tok: 0.9943636002940731
dev_label=LOC_precision_tok: 0.9212034383954155
dev_label=LOC_recall_tok: 0.9212034383954155
dev_label=LOC_f-score_tok: 0.9212034383954156
dev_label=MISC_precision_tok: 0.9144230769230769
dev_label=MISC_recall_tok: 0.75
dev_label=MISC_f-score_tok: 0.8240901213171576
dev_label=ORG_precision_tok: 0.8480113636363636
dev_label=ORG_recall_tok: 0.8561185468451242
dev_label=ORG_f-score_tok: 0.852045670789724
dev_label=PER_precision_tok: 0.9597737272155877
dev_label=PER_recall_tok: 0.9698316926008257
dev_label=PER_f-score_tok: 0.9647764966040121
dev_precision_macro_tok: 0.9271497363363388
dev_recall_macro_tok: 0.8987104193775297
dev_f-score_macro_tok: 0.9112958654800766
dev_precision_micro_tok: 0.9799073244811339
dev_recall_micro_tok: 0.9799073244811339
dev_f-score_micro_tok: 0.9799073244811339
dev_time: 44.83106517791748
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9892    0.4279    0.5974       645
           1     0.8758    0.9988    0.9333      2605

   micro avg     0.8855    0.8855    0.8855      3250
   macro avg     0.9325    0.7134    0.7653      3250
weighted avg     0.8983    0.8855    0.8666      3250

F1-macro sent:  0.7653440533641394
F1-micro sent:  0.8855384615384615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9923    0.9964    0.9944     42759
         LOC     0.9212    0.9212    0.9212      2094
        MISC     0.9144    0.7500    0.8241      1268
         ORG     0.8480    0.8561    0.8520      2092
         PER     0.9598    0.9698    0.9648      3149

   micro avg     0.9799    0.9799    0.9799     51362
   macro avg     0.9271    0.8987    0.9113     51362
weighted avg     0.9796    0.9799    0.9796     51362

F1-macro tok:  0.9112958654800766
F1-micro tok:  0.9799073244811339
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362086.74237060547
train_cost_avg: 25.787817275878176
train_count_sent: 14041.0
train_total_correct_sent: 13048.0
train_accuracy_sent: 0.9292785414144292
train_count_tok: 203621.0
train_total_correct_tok: 198263.0
train_accuracy_tok: 0.9736864075905727
train_label=0_precision_sent: 0.8377997179125529
train_label=0_recall_sent: 0.8167755242351323
train_label=0_f-score_sent: 0.8271540469973889
train_label=1_precision_sent: 0.9524319500223115
train_label=1_recall_sent: 0.9586776859504132
train_label=1_f-score_sent: 0.955544612078614
train_precision_macro_sent: 0.8951158339674322
train_recall_macro_sent: 0.8877266050927728
train_f-score_macro_sent: 0.8913493295380015
train_precision_micro_sent: 0.9292785414144292
train_recall_micro_sent: 0.9292785414144292
train_f-score_micro_sent: 0.9292785414144292
train_label=O_precision_tok: 0.9912271933486603
train_label=O_recall_tok: 0.9941089056363444
train_label=O_f-score_tok: 0.9926659580920303
train_label=LOC_precision_tok: 0.8900926929095944
train_label=LOC_recall_tok: 0.8911654814993372
train_label=LOC_f-score_tok: 0.8906287641532161
train_label=MISC_precision_tok: 0.8106807794082271
train_label=MISC_recall_tok: 0.733725234051818
train_label=MISC_f-score_tok: 0.7702857142857144
train_label=ORG_precision_tok: 0.8525227714665848
train_label=ORG_recall_tok: 0.8309226932668329
train_label=ORG_f-score_tok: 0.8415841584158414
train_label=PER_precision_tok: 0.9359257622624835
train_label=PER_recall_tok: 0.9516534867002157
train_label=PER_f-score_tok: 0.9437241010560087
train_precision_macro_tok: 0.8960898398791102
train_recall_macro_tok: 0.8803151602309096
train_f-score_macro_tok: 0.8877777392005622
train_precision_micro_tok: 0.9736864075905727
train_recall_micro_tok: 0.9736864075905727
train_f-score_micro_tok: 0.9736864075905727
train_time: 368.0613307952881
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8378    0.8168    0.8272      2909
           1     0.9524    0.9587    0.9555     11132

   micro avg     0.9293    0.9293    0.9293     14041
   macro avg     0.8951    0.8877    0.8913     14041
weighted avg     0.9287    0.9293    0.9289     14041

F1-macro sent:  0.8913493295380015
F1-micro sent:  0.9292785414144292
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9912    0.9941    0.9927    169578
         LOC     0.8901    0.8912    0.8906      8297
        MISC     0.8107    0.7337    0.7703      4593
         ORG     0.8525    0.8309    0.8416     10025
         PER     0.9359    0.9517    0.9437     11128

   micro avg     0.9737    0.9737    0.9737    203621
   macro avg     0.8961    0.8803    0.8878    203621
weighted avg     0.9732    0.9737    0.9734    203621

F1-macro tok:  0.8877777392005622
F1-micro tok:  0.9736864075905727
**************************************************
dev_cost_sum: 94547.76319885254
dev_cost_avg: 29.09161944580078
dev_count_sent: 3250.0
dev_total_correct_sent: 3127.0
dev_accuracy_sent: 0.9621538461538461
dev_count_tok: 51362.0
dev_total_correct_tok: 50449.0
dev_accuracy_tok: 0.9822242124527861
dev_label=0_precision_sent: 0.9223300970873787
dev_label=0_recall_sent: 0.8837209302325582
dev_label=0_f-score_sent: 0.9026128266033254
dev_label=1_precision_sent: 0.9715045592705167
dev_label=1_recall_sent: 0.9815738963531669
dev_label=1_f-score_sent: 0.9765132709566544
dev_precision_macro_sent: 0.9469173281789477
dev_recall_macro_sent: 0.9326474132928626
dev_f-score_macro_sent: 0.93956304877999
dev_precision_micro_sent: 0.9621538461538461
dev_recall_micro_sent: 0.9621538461538461
dev_f-score_micro_sent: 0.9621538461538461
dev_label=O_precision_tok: 0.9940723453908985
dev_label=O_recall_tok: 0.996187937042494
dev_label=O_f-score_tok: 0.9951290168089804
dev_label=LOC_precision_tok: 0.935064935064935
dev_label=LOC_recall_tok: 0.9283667621776505
dev_label=LOC_f-score_tok: 0.931703810208483
dev_label=MISC_precision_tok: 0.8570287539936102
dev_label=MISC_recall_tok: 0.8462145110410094
dev_label=MISC_f-score_tok: 0.8515873015873017
dev_label=ORG_precision_tok: 0.9057971014492754
dev_label=ORG_recall_tok: 0.8365200764818356
dev_label=ORG_f-score_tok: 0.8697813121272365
dev_label=PER_precision_tok: 0.9498307171437366
dev_label=PER_recall_tok: 0.9799936487773896
dev_label=PER_f-score_tok: 0.9646764613941856
dev_precision_macro_tok: 0.9283587706084913
dev_recall_macro_tok: 0.9174565871040758
dev_f-score_macro_tok: 0.9225755804252375
dev_precision_micro_tok: 0.9822242124527861
dev_recall_micro_tok: 0.9822242124527861
dev_f-score_micro_tok: 0.9822242124527861
dev_time: 33.23871636390686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9223    0.8837    0.9026       645
           1     0.9715    0.9816    0.9765      2605

   micro avg     0.9622    0.9622    0.9622      3250
   macro avg     0.9469    0.9326    0.9396      3250
weighted avg     0.9617    0.9622    0.9618      3250

F1-macro sent:  0.93956304877999
F1-micro sent:  0.9621538461538461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9941    0.9962    0.9951     42759
         LOC     0.9351    0.9284    0.9317      2094
        MISC     0.8570    0.8462    0.8516      1268
         ORG     0.9058    0.8365    0.8698      2092
         PER     0.9498    0.9800    0.9647      3149

   micro avg     0.9822    0.9822    0.9822     51362
   macro avg     0.9284    0.9175    0.9226     51362
weighted avg     0.9820    0.9822    0.9820     51362

F1-macro tok:  0.9225755804252375
F1-micro tok:  0.9822242124527861
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 354747.93728637695
train_cost_avg: 25.265147588232814
train_count_sent: 14041.0
train_total_correct_sent: 13256.0
train_accuracy_sent: 0.944092301118154
train_count_tok: 203621.0
train_total_correct_tok: 198793.0
train_accuracy_tok: 0.9762892825396202
train_label=0_precision_sent: 0.8659545141281875
train_label=0_recall_sent: 0.8638707459608113
train_label=0_f-score_sent: 0.8649113749784891
train_label=1_precision_sent: 0.9644492324266092
train_label=1_recall_sent: 0.9650556952928494
train_label=1_f-score_sent: 0.9647523685510304
train_precision_macro_sent: 0.9152018732773983
train_recall_macro_sent: 0.9144632206268304
train_f-score_macro_sent: 0.9148318717647598
train_precision_micro_sent: 0.944092301118154
train_recall_micro_sent: 0.944092301118154
train_f-score_micro_sent: 0.944092301118154
train_label=O_precision_tok: 0.9920363715497315
train_label=O_recall_tok: 0.9946396348582953
train_label=O_f-score_tok: 0.9933362975962969
train_label=LOC_precision_tok: 0.899182888728671
train_label=LOC_recall_tok: 0.9018922502109196
train_label=LOC_f-score_tok: 0.9005355316204345
train_label=MISC_precision_tok: 0.835799522673031
train_label=MISC_recall_tok: 0.7624646200740257
train_label=MISC_f-score_tok: 0.7974496185813503
train_label=ORG_precision_tok: 0.8602956063980562
train_label=ORG_recall_tok: 0.8476807980049875
train_label=ORG_f-score_tok: 0.853941616841682
train_label=PER_precision_tok: 0.9494111349036403
train_label=PER_recall_tok: 0.956236520488857
train_label=PER_f-score_tok: 0.9528116045845273
train_precision_macro_tok: 0.907345104850626
train_recall_macro_tok: 0.8925827647274168
train_f-score_macro_tok: 0.8996149338448582
train_precision_micro_tok: 0.9762892825396202
train_recall_micro_tok: 0.9762892825396202
train_f-score_micro_tok: 0.9762892825396202
train_time: 330.4629783630371
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8660    0.8639    0.8649      2909
           1     0.9644    0.9651    0.9648     11132

   micro avg     0.9441    0.9441    0.9441     14041
   macro avg     0.9152    0.9145    0.9148     14041
weighted avg     0.9440    0.9441    0.9441     14041

F1-macro sent:  0.9148318717647598
F1-micro sent:  0.944092301118154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9920    0.9946    0.9933    169578
         LOC     0.8992    0.9019    0.9005      8297
        MISC     0.8358    0.7625    0.7974      4593
         ORG     0.8603    0.8477    0.8539     10025
         PER     0.9494    0.9562    0.9528     11128

   micro avg     0.9763    0.9763    0.9763    203621
   macro avg     0.9073    0.8926    0.8996    203621
weighted avg     0.9759    0.9763    0.9761    203621

F1-macro tok:  0.8996149338448582
F1-micro tok:  0.9762892825396202
**************************************************
dev_cost_sum: 93108.97830200195
dev_cost_avg: 28.648916400615985
dev_count_sent: 3250.0
dev_total_correct_sent: 3158.0
dev_accuracy_sent: 0.9716923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50461.0
dev_accuracy_tok: 0.9824578482146333
dev_label=0_precision_sent: 0.9133034379671151
dev_label=0_recall_sent: 0.9472868217054263
dev_label=0_f-score_sent: 0.9299847792998477
dev_label=1_precision_sent: 0.9868268113134444
dev_label=1_recall_sent: 0.9777351247600767
dev_label=1_f-score_sent: 0.9822599305823371
dev_precision_macro_sent: 0.9500651246402798
dev_recall_macro_sent: 0.9625109732327515
dev_f-score_macro_sent: 0.9561223549410924
dev_precision_micro_sent: 0.9716923076923077
dev_recall_micro_sent: 0.9716923076923077
dev_f-score_micro_sent: 0.9716923076923077
dev_label=O_precision_tok: 0.9946507825274469
dev_label=O_recall_tok: 0.9958371337028462
dev_label=O_f-score_tok: 0.9952436045764238
dev_label=LOC_precision_tok: 0.932001902044698
dev_label=LOC_recall_tok: 0.936007640878701
dev_label=LOC_f-score_tok: 0.9340004765308555
dev_label=MISC_precision_tok: 0.8114754098360656
dev_label=MISC_recall_tok: 0.8588328075709779
dev_label=MISC_f-score_tok: 0.8344827586206897
dev_label=ORG_precision_tok: 0.934154175588865
dev_label=ORG_recall_tok: 0.8341300191204589
dev_label=ORG_f-score_tok: 0.8813131313131313
dev_label=PER_precision_tok: 0.9527631985180611
dev_label=PER_recall_tok: 0.9799936487773896
dev_label=PER_f-score_tok: 0.9661865998747653
dev_precision_macro_tok: 0.9250090937030274
dev_recall_macro_tok: 0.9209602500100746
dev_f-score_macro_tok: 0.9222453141831732
dev_precision_micro_tok: 0.9824578482146333
dev_recall_micro_tok: 0.9824578482146333
dev_f-score_micro_tok: 0.9824578482146333
dev_time: 34.391191720962524
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9133    0.9473    0.9300       645
           1     0.9868    0.9777    0.9823      2605

   micro avg     0.9717    0.9717    0.9717      3250
   macro avg     0.9501    0.9625    0.9561      3250
weighted avg     0.9722    0.9717    0.9719      3250

F1-macro sent:  0.9561223549410924
F1-micro sent:  0.9716923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9958    0.9952     42759
         LOC     0.9320    0.9360    0.9340      2094
        MISC     0.8115    0.8588    0.8345      1268
         ORG     0.9342    0.8341    0.8813      2092
         PER     0.9528    0.9800    0.9662      3149

   micro avg     0.9825    0.9825    0.9825     51362
   macro avg     0.9250    0.9210    0.9222     51362
weighted avg     0.9825    0.9825    0.9824     51362

F1-macro tok:  0.9222453141831732
F1-micro tok:  0.9824578482146333
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 348797.6756591797
train_cost_avg: 24.84136996361938
train_count_sent: 14041.0
train_total_correct_sent: 13337.0
train_accuracy_sent: 0.9498611210027775
train_count_tok: 203621.0
train_total_correct_tok: 199213.0
train_accuracy_tok: 0.9783519381596201
train_label=0_precision_sent: 0.8782161234991424
train_label=0_recall_sent: 0.8800275008594018
train_label=0_f-score_sent: 0.8791208791208791
train_label=1_precision_sent: 0.9686320330756786
train_label=1_recall_sent: 0.9681099532878189
train_label=1_f-score_sent: 0.968370922814269
train_precision_macro_sent: 0.9234240782874105
train_recall_macro_sent: 0.9240687270736103
train_f-score_macro_sent: 0.923745900967574
train_precision_micro_sent: 0.9498611210027775
train_recall_micro_sent: 0.9498611210027775
train_f-score_micro_sent: 0.9498611210027775
train_label=O_precision_tok: 0.9928276819703575
train_label=O_recall_tok: 0.9950583212445011
train_label=O_f-score_tok: 0.9939417500890919
train_label=LOC_precision_tok: 0.9089701798865145
train_label=LOC_recall_tok: 0.907436422803423
train_label=LOC_f-score_tok: 0.9082026537997587
train_label=MISC_precision_tok: 0.8420195439739414
train_label=MISC_recall_tok: 0.787938166775528
train_label=MISC_f-score_tok: 0.8140816556067934
train_label=ORG_precision_tok: 0.877749619868221
train_label=ORG_recall_tok: 0.8637406483790524
train_label=ORG_f-score_tok: 0.8706887883358471
train_label=PER_precision_tok: 0.9509629101283881
train_label=PER_recall_tok: 0.9584831056793673
train_label=PER_f-score_tok: 0.9547081990691013
train_precision_macro_tok: 0.9145059871654844
train_recall_macro_tok: 0.9025313329763744
train_f-score_macro_tok: 0.9083246093801185
train_precision_micro_tok: 0.9783519381596201
train_recall_micro_tok: 0.9783519381596201
train_f-score_micro_tok: 0.9783519381596202
train_time: 254.58815264701843
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8782    0.8800    0.8791      2909
           1     0.9686    0.9681    0.9684     11132

   micro avg     0.9499    0.9499    0.9499     14041
   macro avg     0.9234    0.9241    0.9237     14041
weighted avg     0.9499    0.9499    0.9499     14041

F1-macro sent:  0.923745900967574
F1-micro sent:  0.9498611210027775
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9928    0.9951    0.9939    169578
         LOC     0.9090    0.9074    0.9082      8297
        MISC     0.8420    0.7879    0.8141      4593
         ORG     0.8777    0.8637    0.8707     10025
         PER     0.9510    0.9585    0.9547     11128

   micro avg     0.9784    0.9784    0.9784    203621
   macro avg     0.9145    0.9025    0.9083    203621
weighted avg     0.9781    0.9784    0.9782    203621

F1-macro tok:  0.9083246093801185
F1-micro tok:  0.9783519381596202
**************************************************
dev_cost_sum: 91680.11544036865
dev_cost_avg: 28.2092662893442
dev_count_sent: 3250.0
dev_total_correct_sent: 3165.0
dev_accuracy_sent: 0.9738461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50559.0
dev_accuracy_tok: 0.9843658736030528
dev_label=0_precision_sent: 0.9191616766467066
dev_label=0_recall_sent: 0.951937984496124
dev_label=0_f-score_sent: 0.9352627570449352
dev_label=1_precision_sent: 0.987993803253292
dev_label=1_recall_sent: 0.9792706333973129
dev_label=1_f-score_sent: 0.9836128783497206
dev_precision_macro_sent: 0.9535777399499993
dev_recall_macro_sent: 0.9656043089467184
dev_f-score_macro_sent: 0.9594378176973279
dev_precision_micro_sent: 0.9738461538461538
dev_recall_micro_sent: 0.9738461538461538
dev_f-score_micro_sent: 0.9738461538461538
dev_label=O_precision_tok: 0.9941220376935995
dev_label=O_recall_tok: 0.9967492223859304
dev_label=O_f-score_tok: 0.9954338966028657
dev_label=LOC_precision_tok: 0.9487427466150871
dev_label=LOC_recall_tok: 0.9369627507163324
dev_label=LOC_f-score_tok: 0.9428159538683326
dev_label=MISC_precision_tok: 0.9144620811287478
dev_label=MISC_recall_tok: 0.8178233438485805
dev_label=MISC_f-score_tok: 0.8634471273938386
dev_label=ORG_precision_tok: 0.9060501721593703
dev_label=ORG_recall_tok: 0.8804971319311663
dev_label=ORG_f-score_tok: 0.893090909090909
dev_label=PER_precision_tok: 0.9517665130568357
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9675202998126172
dev_precision_macro_tok: 0.9430287101307281
dev_recall_macro_tok: 0.9231673662451222
dev_f-score_macro_tok: 0.9324616373537126
dev_precision_micro_tok: 0.9843658736030528
dev_recall_micro_tok: 0.9843658736030528
dev_f-score_micro_tok: 0.9843658736030528
dev_time: 23.47666645050049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9192    0.9519    0.9353       645
           1     0.9880    0.9793    0.9836      2605

   micro avg     0.9738    0.9738    0.9738      3250
   macro avg     0.9536    0.9656    0.9594      3250
weighted avg     0.9743    0.9738    0.9740      3250

F1-macro sent:  0.9594378176973279
F1-micro sent:  0.9738461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9941    0.9967    0.9954     42759
         LOC     0.9487    0.9370    0.9428      2094
        MISC     0.9145    0.8178    0.8634      1268
         ORG     0.9061    0.8805    0.8931      2092
         PER     0.9518    0.9838    0.9675      3149

   micro avg     0.9844    0.9844    0.9844     51362
   macro avg     0.9430    0.9232    0.9325     51362
weighted avg     0.9841    0.9844    0.9842     51362

F1-macro tok:  0.9324616373537126
F1-micro tok:  0.9843658736030528
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 343365.6043395996
train_cost_avg: 24.454497851976328
train_count_sent: 14041.0
train_total_correct_sent: 13430.0
train_accuracy_sent: 0.9564845808703084
train_count_tok: 203621.0
train_total_correct_tok: 199676.0
train_accuracy_tok: 0.9806257704264295
train_label=0_precision_sent: 0.893223819301848
train_label=0_recall_sent: 0.8972155379855621
train_label=0_f-score_sent: 0.8952152289487224
train_label=1_precision_sent: 0.9731090925442936
train_label=1_recall_sent: 0.9719726913402803
train_label=1_f-score_sent: 0.9725405599748327
train_precision_macro_sent: 0.9331664559230708
train_recall_macro_sent: 0.9345941146629212
train_f-score_macro_sent: 0.9338778944617776
train_precision_micro_sent: 0.9564845808703084
train_recall_micro_sent: 0.9564845808703084
train_f-score_micro_sent: 0.9564845808703084
train_label=O_precision_tok: 0.9937062854720581
train_label=O_recall_tok: 0.9953118918727665
train_label=O_f-score_tok: 0.9945084406210413
train_label=LOC_precision_tok: 0.9187138728323699
train_label=LOC_recall_tok: 0.9194889719175605
train_label=LOC_f-score_tok: 0.9191012589603036
train_label=MISC_precision_tok: 0.8590369853454292
train_label=MISC_recall_tok: 0.8040496407576747
train_label=MISC_f-score_tok: 0.8306342780026991
train_label=ORG_precision_tok: 0.8886647841871722
train_label=ORG_recall_tok: 0.879002493765586
train_label=ORG_f-score_tok: 0.8838072313324307
train_label=PER_precision_tok: 0.9563555555555555
train_label=PER_recall_tok: 0.9668404025880661
train_label=PER_f-score_tok: 0.9615693985164001
train_precision_macro_tok: 0.9232954966785171
train_recall_macro_tok: 0.9129386801803306
train_f-score_macro_tok: 0.917924121486575
train_precision_micro_tok: 0.9806257704264295
train_recall_micro_tok: 0.9806257704264295
train_f-score_micro_tok: 0.9806257704264295
train_time: 242.55247402191162
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8932    0.8972    0.8952      2909
           1     0.9731    0.9720    0.9725     11132

   micro avg     0.9565    0.9565    0.9565     14041
   macro avg     0.9332    0.9346    0.9339     14041
weighted avg     0.9566    0.9565    0.9565     14041

F1-macro sent:  0.9338778944617776
F1-micro sent:  0.9564845808703084
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9937    0.9953    0.9945    169578
         LOC     0.9187    0.9195    0.9191      8297
        MISC     0.8590    0.8040    0.8306      4593
         ORG     0.8887    0.8790    0.8838     10025
         PER     0.9564    0.9668    0.9616     11128

   micro avg     0.9806    0.9806    0.9806    203621
   macro avg     0.9233    0.9129    0.9179    203621
weighted avg     0.9804    0.9806    0.9805    203621

F1-macro tok:  0.917924121486575
F1-micro tok:  0.9806257704264295
**************************************************
dev_cost_sum: 90830.12438964844
dev_cost_avg: 27.94773058143029
dev_count_sent: 3250.0
dev_total_correct_sent: 3091.0
dev_accuracy_sent: 0.951076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50636.0
dev_accuracy_tok: 0.9858650364082395
dev_label=0_precision_sent: 0.8115384615384615
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.8884210526315789
dev_label=1_precision_sent: 0.9951417004048583
dev_label=1_recall_sent: 0.9435700575815739
dev_label=1_f-score_sent: 0.9686699507389162
dev_precision_macro_sent: 0.9033400809716599
dev_recall_macro_sent: 0.9624827032093916
dev_f-score_macro_sent: 0.9285455016852475
dev_precision_micro_sent: 0.951076923076923
dev_recall_micro_sent: 0.951076923076923
dev_f-score_micro_sent: 0.951076923076923
dev_label=O_precision_tok: 0.9942627921078409
dev_label=O_recall_tok: 0.9970298650576487
dev_label=O_f-score_tok: 0.9956444060394456
dev_label=LOC_precision_tok: 0.9472182596291013
dev_label=LOC_recall_tok: 0.9512893982808023
dev_label=LOC_f-score_tok: 0.9492494639027876
dev_label=MISC_precision_tok: 0.8988095238095238
dev_label=MISC_recall_tok: 0.833596214511041
dev_label=MISC_f-score_tok: 0.8649754500818331
dev_label=ORG_precision_tok: 0.9152872444011685
dev_label=ORG_recall_tok: 0.8986615678776291
dev_label=ORG_f-score_tok: 0.9068982151471299
dev_label=PER_precision_tok: 0.975880672802285
dev_label=PER_recall_tok: 0.9765004763416958
dev_label=PER_f-score_tok: 0.9761904761904763
dev_precision_macro_tok: 0.9462916985499839
dev_recall_macro_tok: 0.9314155044137633
dev_f-score_macro_tok: 0.9385916022723345
dev_precision_micro_tok: 0.9858650364082395
dev_recall_micro_tok: 0.9858650364082395
dev_f-score_micro_tok: 0.9858650364082395
dev_time: 24.37409734725952
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8115    0.9814    0.8884       645
           1     0.9951    0.9436    0.9687      2605

   micro avg     0.9511    0.9511    0.9511      3250
   macro avg     0.9033    0.9625    0.9285      3250
weighted avg     0.9587    0.9511    0.9527      3250

F1-macro sent:  0.9285455016852475
F1-micro sent:  0.951076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9943    0.9970    0.9956     42759
         LOC     0.9472    0.9513    0.9492      2094
        MISC     0.8988    0.8336    0.8650      1268
         ORG     0.9153    0.8987    0.9069      2092
         PER     0.9759    0.9765    0.9762      3149

   micro avg     0.9859    0.9859    0.9859     51362
   macro avg     0.9463    0.9314    0.9386     51362
weighted avg     0.9856    0.9859    0.9857     51362

F1-macro tok:  0.9385916022723345
F1-micro tok:  0.9858650364082395
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 338772.78967285156
train_cost_avg: 24.127397597952537
train_count_sent: 14041.0
train_total_correct_sent: 13487.0
train_accuracy_sent: 0.9605441207891176
train_count_tok: 203621.0
train_total_correct_tok: 199933.0
train_accuracy_tok: 0.9818879192224771
train_label=0_precision_sent: 0.9056148811574234
train_label=0_recall_sent: 0.903746992093503
train_label=0_f-score_sent: 0.9046799724707503
train_label=1_precision_sent: 0.9748608367750045
train_label=1_recall_sent: 0.9753862738052461
train_label=1_f-score_sent: 0.9751234845083071
train_precision_macro_sent: 0.9402378589662139
train_recall_macro_sent: 0.9395666329493746
train_f-score_macro_sent: 0.9399017284895287
train_precision_micro_sent: 0.9605441207891176
train_recall_micro_sent: 0.9605441207891176
train_f-score_micro_sent: 0.9605441207891177
train_label=O_precision_tok: 0.9941176816953324
train_label=O_recall_tok: 0.9956008444491621
train_label=O_f-score_tok: 0.9948587102875882
train_label=LOC_precision_tok: 0.9250574156895927
train_label=LOC_recall_tok: 0.9223815837049536
train_label=LOC_f-score_tok: 0.923717561858781
train_label=MISC_precision_tok: 0.8655077767612077
train_label=MISC_recall_tok: 0.8238623993032876
train_label=MISC_f-score_tok: 0.8441717791411044
train_label=ORG_precision_tok: 0.8964580398470517
train_label=ORG_recall_tok: 0.8886783042394015
train_label=ORG_f-score_tok: 0.8925512197565497
train_label=PER_precision_tok: 0.9596680646024806
train_label=PER_recall_tok: 0.9664809489575845
train_label=PER_f-score_tok: 0.9630624580255205
train_precision_macro_tok: 0.9281617957191332
train_recall_macro_tok: 0.9194008161308778
train_f-score_macro_tok: 0.9236723458139087
train_precision_micro_tok: 0.9818879192224771
train_recall_micro_tok: 0.9818879192224771
train_f-score_micro_tok: 0.9818879192224771
train_time: 242.81299829483032
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9056    0.9037    0.9047      2909
           1     0.9749    0.9754    0.9751     11132

   micro avg     0.9605    0.9605    0.9605     14041
   macro avg     0.9402    0.9396    0.9399     14041
weighted avg     0.9605    0.9605    0.9605     14041

F1-macro sent:  0.9399017284895287
F1-micro sent:  0.9605441207891177
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9941    0.9956    0.9949    169578
         LOC     0.9251    0.9224    0.9237      8297
        MISC     0.8655    0.8239    0.8442      4593
         ORG     0.8965    0.8887    0.8926     10025
         PER     0.9597    0.9665    0.9631     11128

   micro avg     0.9819    0.9819    0.9819    203621
   macro avg     0.9282    0.9194    0.9237    203621
weighted avg     0.9817    0.9819    0.9818    203621

F1-macro tok:  0.9236723458139087
F1-micro tok:  0.9818879192224771
**************************************************
dev_cost_sum: 89723.4694442749
dev_cost_avg: 27.6072213674692
dev_count_sent: 3250.0
dev_total_correct_sent: 3143.0
dev_accuracy_sent: 0.9670769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50662.0
dev_accuracy_tok: 0.9863712472255753
dev_label=0_precision_sent: 0.9944852941176471
dev_label=0_recall_sent: 0.8387596899224806
dev_label=0_f-score_sent: 0.9100084104289319
dev_label=1_precision_sent: 0.9615668883961567
dev_label=1_recall_sent: 0.9988483685220729
dev_label=1_f-score_sent: 0.9798531350028242
dev_precision_macro_sent: 0.9780260912569019
dev_recall_macro_sent: 0.9188040292222768
dev_f-score_macro_sent: 0.944930772715878
dev_precision_micro_sent: 0.9670769230769231
dev_recall_micro_sent: 0.9670769230769231
dev_f-score_micro_sent: 0.9670769230769231
dev_label=O_precision_tok: 0.9957230999345611
dev_label=O_recall_tok: 0.9963984190462827
dev_label=O_f-score_tok: 0.9960606450255416
dev_label=LOC_precision_tok: 0.9488151658767773
dev_label=LOC_recall_tok: 0.956064947468959
dev_label=LOC_f-score_tok: 0.9524262607040913
dev_label=MISC_precision_tok: 0.9034138218151541
dev_label=MISC_recall_tok: 0.8556782334384858
dev_label=MISC_f-score_tok: 0.8788983394086676
dev_label=ORG_precision_tok: 0.9166666666666666
dev_label=ORG_recall_tok: 0.8938814531548758
dev_label=ORG_f-score_tok: 0.9051306873184899
dev_label=PER_precision_tok: 0.9618367980142725
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9730069052102951
dev_precision_macro_tok: 0.9452911104614863
dev_recall_macro_tok: 0.9372925115426479
dev_f-score_macro_tok: 0.9411045675334171
dev_precision_micro_tok: 0.9863712472255753
dev_recall_micro_tok: 0.9863712472255753
dev_f-score_micro_tok: 0.9863712472255753
dev_time: 34.57182955741882
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9945    0.8388    0.9100       645
           1     0.9616    0.9988    0.9799      2605

   micro avg     0.9671    0.9671    0.9671      3250
   macro avg     0.9780    0.9188    0.9449      3250
weighted avg     0.9681    0.9671    0.9660      3250

F1-macro sent:  0.944930772715878
F1-micro sent:  0.9670769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9964    0.9961     42759
         LOC     0.9488    0.9561    0.9524      2094
        MISC     0.9034    0.8557    0.8789      1268
         ORG     0.9167    0.8939    0.9051      2092
         PER     0.9618    0.9844    0.9730      3149

   micro avg     0.9864    0.9864    0.9864     51362
   macro avg     0.9453    0.9373    0.9411     51362
weighted avg     0.9862    0.9864    0.9863     51362

F1-macro tok:  0.9411045675334171
F1-micro tok:  0.9863712472255753
**************************************************
Best epoch: 5
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 334298.78036499023
train_cost_avg: 23.808758661419432
train_count_sent: 14041.0
train_total_correct_sent: 13522.0
train_accuracy_sent: 0.9630368207392636
train_count_tok: 203621.0
train_total_correct_tok: 200295.0
train_accuracy_tok: 0.9836657319235246
train_label=0_precision_sent: 0.9089664613278576
train_label=0_recall_sent: 0.9130285321416294
train_label=0_f-score_sent: 0.9109929686160178
train_label=1_precision_sent: 0.9772461552297869
train_label=1_recall_sent: 0.976104922745239
train_label=1_f-score_sent: 0.9766752056087367
train_precision_macro_sent: 0.9431063082788222
train_recall_macro_sent: 0.9445667274434342
train_f-score_macro_sent: 0.9438340871123772
train_precision_micro_sent: 0.9630368207392636
train_recall_micro_sent: 0.9630368207392636
train_f-score_micro_sent: 0.9630368207392636
train_label=O_precision_tok: 0.9946357491108652
train_label=O_recall_tok: 0.9961020887143379
train_label=O_f-score_tok: 0.9953683788736792
train_label=LOC_precision_tok: 0.930006013229104
train_label=LOC_recall_tok: 0.9320236229962637
train_label=LOC_f-score_tok: 0.9310137250180592
train_label=MISC_precision_tok: 0.883146581294306
train_label=MISC_recall_tok: 0.8408447637709558
train_label=MISC_f-score_tok: 0.8614766897167075
train_label=ORG_precision_tok: 0.9077311773623042
train_label=ORG_recall_tok: 0.8959600997506234
train_label=ORG_f-score_tok: 0.9018072289156627
train_label=PER_precision_tok: 0.963514719000892
train_label=PER_recall_tok: 0.9706146657081236
train_label=PER_f-score_tok: 0.967051660846987
train_precision_macro_tok: 0.9358068479994943
train_recall_macro_tok: 0.927109048188061
train_f-score_macro_tok: 0.9313435366742191
train_precision_micro_tok: 0.9836657319235246
train_recall_micro_tok: 0.9836657319235246
train_f-score_micro_tok: 0.9836657319235246
train_time: 476.76588106155396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9090    0.9130    0.9110      2909
           1     0.9772    0.9761    0.9767     11132

   micro avg     0.9630    0.9630    0.9630     14041
   macro avg     0.9431    0.9446    0.9438     14041
weighted avg     0.9631    0.9630    0.9631     14041

F1-macro sent:  0.9438340871123772
F1-micro sent:  0.9630368207392636
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9961    0.9954    169578
         LOC     0.9300    0.9320    0.9310      8297
        MISC     0.8831    0.8408    0.8615      4593
         ORG     0.9077    0.8960    0.9018     10025
         PER     0.9635    0.9706    0.9671     11128

   micro avg     0.9837    0.9837    0.9837    203621
   macro avg     0.9358    0.9271    0.9313    203621
weighted avg     0.9835    0.9837    0.9836    203621

F1-macro tok:  0.9313435366742191
F1-micro tok:  0.9836657319235246
**************************************************
dev_cost_sum: 89008.47130584717
dev_cost_avg: 27.387221940260666
dev_count_sent: 3250.0
dev_total_correct_sent: 3181.0
dev_accuracy_sent: 0.9787692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50642.0
dev_accuracy_tok: 0.9859818542891632
dev_label=0_precision_sent: 0.9235294117647059
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9479245283018868
dev_label=1_precision_sent: 0.9933852140077821
dev_label=1_recall_sent: 0.9800383877159309
dev_label=1_f-score_sent: 0.9866666666666667
dev_precision_macro_sent: 0.958457312886244
dev_recall_macro_sent: 0.976840899284322
dev_f-score_macro_sent: 0.9672955974842767
dev_precision_micro_sent: 0.9787692307692307
dev_recall_micro_sent: 0.9787692307692307
dev_f-score_micro_sent: 0.9787692307692307
dev_label=O_precision_tok: 0.9947054158697579
dev_label=O_recall_tok: 0.9973806683972964
dev_label=O_f-score_tok: 0.9960412457814161
dev_label=LOC_precision_tok: 0.9594924353343094
dev_label=LOC_recall_tok: 0.938872970391595
dev_label=LOC_f-score_tok: 0.9490707216992517
dev_label=MISC_precision_tok: 0.8580246913580247
dev_label=MISC_recall_tok: 0.8769716088328076
dev_label=MISC_f-score_tok: 0.8673946957878315
dev_label=ORG_precision_tok: 0.9349385245901639
dev_label=ORG_recall_tok: 0.8723709369024857
dev_label=ORG_f-score_tok: 0.9025717111770525
dev_label=PER_precision_tok: 0.9689752428705735
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9753943217665615
dev_precision_macro_tok: 0.9432272620045661
dev_recall_macro_tok: 0.9334990400169361
dev_f-score_macro_tok: 0.9380945392424227
dev_precision_micro_tok: 0.9859818542891632
dev_recall_micro_tok: 0.9859818542891632
dev_f-score_micro_tok: 0.9859818542891632
dev_time: 54.452659606933594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9235    0.9736    0.9479       645
           1     0.9934    0.9800    0.9867      2605

   micro avg     0.9788    0.9788    0.9788      3250
   macro avg     0.9585    0.9768    0.9673      3250
weighted avg     0.9795    0.9788    0.9790      3250

F1-macro sent:  0.9672955974842767
F1-micro sent:  0.9787692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9974    0.9960     42759
         LOC     0.9595    0.9389    0.9491      2094
        MISC     0.8580    0.8770    0.8674      1268
         ORG     0.9349    0.8724    0.9026      2092
         PER     0.9690    0.9819    0.9754      3149

   micro avg     0.9860    0.9860    0.9860     51362
   macro avg     0.9432    0.9335    0.9381     51362
weighted avg     0.9859    0.9860    0.9859     51362

F1-macro tok:  0.9380945392424227
F1-micro tok:  0.9859818542891632
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 330922.1033630371
train_cost_avg: 23.56827173015007
train_count_sent: 14041.0
train_total_correct_sent: 13596.0
train_accuracy_sent: 0.9683071006338579
train_count_tok: 203621.0
train_total_correct_tok: 200377.0
train_accuracy_tok: 0.9840684408779056
train_label=0_precision_sent: 0.9239504473503097
train_label=0_recall_sent: 0.9229975936748024
train_label=0_f-score_sent: 0.9234737747205505
train_label=1_precision_sent: 0.9798832510103278
train_label=1_recall_sent: 0.9801473230326986
train_label=1_f-score_sent: 0.9800152692324965
train_precision_macro_sent: 0.9519168491803187
train_recall_macro_sent: 0.9515724583537505
train_f-score_macro_sent: 0.9517445219765235
train_precision_micro_sent: 0.9683071006338579
train_recall_micro_sent: 0.9683071006338579
train_f-score_micro_sent: 0.9683071006338579
train_label=O_precision_tok: 0.9948053477825549
train_label=O_recall_tok: 0.9960490157921429
train_label=O_f-score_tok: 0.9954267933334905
train_label=LOC_precision_tok: 0.9340725563456671
train_label=LOC_recall_tok: 0.9340725563456671
train_label=LOC_f-score_tok: 0.9340725563456671
train_label=MISC_precision_tok: 0.8842582106455266
train_label=MISC_recall_tok: 0.849989113868931
train_label=MISC_f-score_tok: 0.866785079928952
train_label=ORG_precision_tok: 0.907472593784572
train_label=ORG_recall_tok: 0.9000498753117206
train_label=ORG_f-score_tok: 0.9037459935897436
train_label=PER_precision_tok: 0.9656406585540444
train_label=PER_recall_tok: 0.9698058950395398
train_label=PER_f-score_tok: 0.9677187948350072
train_precision_macro_tok: 0.9372498734224731
train_recall_macro_tok: 0.9299932912716002
train_f-score_macro_tok: 0.933549843606572
train_precision_micro_tok: 0.9840684408779056
train_recall_micro_tok: 0.9840684408779056
train_f-score_micro_tok: 0.9840684408779056
train_time: 504.358571767807
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9240    0.9230    0.9235      2909
           1     0.9799    0.9801    0.9800     11132

   micro avg     0.9683    0.9683    0.9683     14041
   macro avg     0.9519    0.9516    0.9517     14041
weighted avg     0.9683    0.9683    0.9683     14041

F1-macro sent:  0.9517445219765235
F1-micro sent:  0.9683071006338579
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9948    0.9960    0.9954    169578
         LOC     0.9341    0.9341    0.9341      8297
        MISC     0.8843    0.8500    0.8668      4593
         ORG     0.9075    0.9000    0.9037     10025
         PER     0.9656    0.9698    0.9677     11128

   micro avg     0.9841    0.9841    0.9841    203621
   macro avg     0.9372    0.9300    0.9335    203621
weighted avg     0.9839    0.9841    0.9840    203621

F1-macro tok:  0.933549843606572
F1-micro tok:  0.9840684408779056
**************************************************
dev_cost_sum: 88256.9208984375
dev_cost_avg: 27.155975661057692
dev_count_sent: 3250.0
dev_total_correct_sent: 3160.0
dev_accuracy_sent: 0.9723076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50704.0
dev_accuracy_tok: 0.9871889723920408
dev_label=0_precision_sent: 0.9946524064171123
dev_label=0_recall_sent: 0.8651162790697674
dev_label=0_f-score_sent: 0.9253731343283582
dev_label=1_precision_sent: 0.9676459650427668
dev_label=1_recall_sent: 0.9988483685220729
dev_label=1_f-score_sent: 0.982999622213827
dev_precision_macro_sent: 0.9811491857299395
dev_recall_macro_sent: 0.9319823237959202
dev_f-score_macro_sent: 0.9541863782710927
dev_precision_micro_sent: 0.9723076923076923
dev_recall_micro_sent: 0.9723076923076923
dev_f-score_micro_sent: 0.9723076923076923
dev_label=O_precision_tok: 0.9960487246031189
dev_label=O_recall_tok: 0.9963282583783531
dev_label=O_f-score_tok: 0.9961884718812113
dev_label=LOC_precision_tok: 0.9565425023877746
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9565425023877746
dev_label=MISC_precision_tok: 0.8779714738510301
dev_label=MISC_recall_tok: 0.8738170347003155
dev_label=MISC_f-score_tok: 0.8758893280632412
dev_label=ORG_precision_tok: 0.9287804878048781
dev_label=ORG_recall_tok: 0.9101338432122371
dev_label=ORG_f-score_tok: 0.9193626267503622
dev_label=PER_precision_tok: 0.9692307692307692
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9747395011051468
dev_precision_macro_tok: 0.9457147915755142
dev_recall_macro_tok: 0.9434265697173174
dev_f-score_macro_tok: 0.9445444860375473
dev_precision_micro_tok: 0.9871889723920408
dev_recall_micro_tok: 0.9871889723920408
dev_f-score_micro_tok: 0.9871889723920408
dev_time: 53.88842725753784
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9947    0.8651    0.9254       645
           1     0.9676    0.9988    0.9830      2605

   micro avg     0.9723    0.9723    0.9723      3250
   macro avg     0.9811    0.9320    0.9542      3250
weighted avg     0.9730    0.9723    0.9716      3250

F1-macro sent:  0.9541863782710927
F1-micro sent:  0.9723076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9963    0.9962     42759
         LOC     0.9565    0.9565    0.9565      2094
        MISC     0.8780    0.8738    0.8759      1268
         ORG     0.9288    0.9101    0.9194      2092
         PER     0.9692    0.9803    0.9747      3149

   micro avg     0.9872    0.9872    0.9872     51362
   macro avg     0.9457    0.9434    0.9445     51362
weighted avg     0.9871    0.9872    0.9872     51362

F1-macro tok:  0.9445444860375473
F1-micro tok:  0.9871889723920408
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 327405.0051879883
train_cost_avg: 23.317784003132846
train_count_sent: 14041.0
train_total_correct_sent: 13657.0
train_accuracy_sent: 0.9726515205469696
train_count_tok: 203621.0
train_total_correct_tok: 200615.0
train_accuracy_tok: 0.9852372790625721
train_label=0_precision_sent: 0.9363982025578984
train_label=0_recall_sent: 0.9312478514953593
train_label=0_f-score_sent: 0.9338159255429164
train_label=1_precision_sent: 0.982059562253319
train_label=1_recall_sent: 0.9834710743801653
train_label=1_f-score_sent: 0.9827648114901257
train_precision_macro_sent: 0.9592288824056088
train_recall_macro_sent: 0.9573594629377623
train_f-score_macro_sent: 0.958290368516521
train_precision_micro_sent: 0.9726515205469696
train_recall_micro_sent: 0.9726515205469696
train_f-score_micro_sent: 0.9726515205469696
train_label=O_precision_tok: 0.9951936952590752
train_label=O_recall_tok: 0.9963615563339584
train_label=O_f-score_tok: 0.9957772833758161
train_label=LOC_precision_tok: 0.9395034948180284
train_label=LOC_recall_tok: 0.9396167289381704
train_label=LOC_f-score_tok: 0.9395601084664055
train_label=MISC_precision_tok: 0.8927601809954752
train_label=MISC_recall_tok: 0.8591334639669062
train_label=MISC_f-score_tok: 0.8756240985243537
train_label=ORG_precision_tok: 0.9129866210642793
train_label=ORG_recall_tok: 0.9053366583541147
train_label=ORG_f-score_tok: 0.909145547430632
train_label=PER_precision_tok: 0.9687974966472955
train_label=PER_recall_tok: 0.9737598849748382
train_label=PER_f-score_tok: 0.9712723524402814
train_precision_macro_tok: 0.9418482977568307
train_recall_macro_tok: 0.9348416585135976
train_f-score_macro_tok: 0.9382758780474978
train_precision_micro_tok: 0.9852372790625721
train_recall_micro_tok: 0.9852372790625721
train_f-score_micro_tok: 0.9852372790625721
train_time: 503.54687213897705
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9364    0.9312    0.9338      2909
           1     0.9821    0.9835    0.9828     11132

   micro avg     0.9727    0.9727    0.9727     14041
   macro avg     0.9592    0.9574    0.9583     14041
weighted avg     0.9726    0.9727    0.9726     14041

F1-macro sent:  0.958290368516521
F1-micro sent:  0.9726515205469696
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9964    0.9958    169578
         LOC     0.9395    0.9396    0.9396      8297
        MISC     0.8928    0.8591    0.8756      4593
         ORG     0.9130    0.9053    0.9091     10025
         PER     0.9688    0.9738    0.9713     11128

   micro avg     0.9852    0.9852    0.9852    203621
   macro avg     0.9418    0.9348    0.9383    203621
weighted avg     0.9851    0.9852    0.9852    203621

F1-macro tok:  0.9382758780474978
F1-micro tok:  0.9852372790625721
**************************************************
dev_cost_sum: 87555.89421081543
dev_cost_avg: 26.940275141789364
dev_count_sent: 3250.0
dev_total_correct_sent: 3191.0
dev_accuracy_sent: 0.9818461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50725.0
dev_accuracy_tok: 0.9875978349752735
dev_label=0_precision_sent: 0.9771986970684039
dev_label=0_recall_sent: 0.9302325581395349
dev_label=0_f-score_sent: 0.9531374106433678
dev_label=1_precision_sent: 0.9829286798179059
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9887426063728297
dev_precision_macro_sent: 0.9800636884431548
dev_recall_macro_sent: 0.9624291389546042
dev_f-score_macro_sent: 0.9709400085080988
dev_precision_micro_sent: 0.9818461538461538
dev_recall_micro_sent: 0.9818461538461538
dev_f-score_micro_sent: 0.9818461538461538
dev_label=O_precision_tok: 0.9959335343195681
dev_label=O_recall_tok: 0.9966322879393812
dev_label=O_f-score_tok: 0.9962827886099032
dev_label=LOC_precision_tok: 0.9569995222169135
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9567709577262957
dev_label=MISC_precision_tok: 0.8861267040898155
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8787276341948311
dev_label=ORG_precision_tok: 0.9292292777508483
dev_label=ORG_recall_tok: 0.9163479923518164
dev_label=ORG_f-score_tok: 0.9227436823104693
dev_label=PER_precision_tok: 0.973186119873817
dev_label=PER_recall_tok: 0.979676087646872
dev_label=PER_f-score_tok: 0.976420319670834
dev_precision_macro_tok: 0.9482950316501924
dev_recall_macro_tok: 0.9441299948853581
dev_f-score_macro_tok: 0.9461890765024666
dev_precision_micro_tok: 0.9875978349752735
dev_recall_micro_tok: 0.9875978349752735
dev_f-score_micro_tok: 0.9875978349752735
dev_time: 55.313249349594116
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9772    0.9302    0.9531       645
           1     0.9829    0.9946    0.9887      2605

   micro avg     0.9818    0.9818    0.9818      3250
   macro avg     0.9801    0.9624    0.9709      3250
weighted avg     0.9818    0.9818    0.9817      3250

F1-macro sent:  0.9709400085080988
F1-micro sent:  0.9818461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9966    0.9963     42759
         LOC     0.9570    0.9565    0.9568      2094
        MISC     0.8861    0.8715    0.8787      1268
         ORG     0.9292    0.9163    0.9227      2092
         PER     0.9732    0.9797    0.9764      3149

   micro avg     0.9876    0.9876    0.9876     51362
   macro avg     0.9483    0.9441    0.9462     51362
weighted avg     0.9875    0.9876    0.9876     51362

F1-macro tok:  0.9461890765024666
F1-micro tok:  0.9875978349752735
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 324533.53106689453
train_cost_avg: 23.113277620318676
train_count_sent: 14041.0
train_total_correct_sent: 13692.0
train_accuracy_sent: 0.9751442204971156
train_count_tok: 203621.0
train_total_correct_tok: 200837.0
train_accuracy_tok: 0.9863275398902863
train_label=0_precision_sent: 0.942294402211472
train_label=0_recall_sent: 0.9374355448607768
train_label=0_f-score_sent: 0.9398586937790797
train_label=1_precision_sent: 0.9836727370592985
train_label=1_recall_sent: 0.98499820337765
train_label=1_f-score_sent: 0.9843350240136451
train_precision_macro_sent: 0.9629835696353852
train_recall_macro_sent: 0.9612168741192134
train_f-score_macro_sent: 0.9620968588963624
train_precision_micro_sent: 0.9751442204971156
train_recall_micro_sent: 0.9751442204971156
train_f-score_micro_sent: 0.9751442204971156
train_label=O_precision_tok: 0.9955111514308941
train_label=O_recall_tok: 0.9965443630659637
train_label=O_f-score_tok: 0.996027489302512
train_label=LOC_precision_tok: 0.9409922928709056
train_label=LOC_recall_tok: 0.9417861877787151
train_label=LOC_f-score_tok: 0.9413890729474128
train_label=MISC_precision_tok: 0.905877054717406
train_label=MISC_recall_tok: 0.8758981058131939
train_label=MISC_f-score_tok: 0.8906353774629178
train_label=ORG_precision_tok: 0.9194651116026543
train_label=ORG_recall_tok: 0.9122194513715711
train_label=ORG_f-score_tok: 0.9158279505282659
train_label=PER_precision_tok: 0.9719935576234788
train_label=PER_recall_tok: 0.9761861969805895
train_label=PER_f-score_tok: 0.9740853658536586
train_precision_macro_tok: 0.9467678336490678
train_recall_macro_tok: 0.9405268610020068
train_f-score_macro_tok: 0.9435930512189534
train_precision_micro_tok: 0.9863275398902863
train_recall_micro_tok: 0.9863275398902863
train_f-score_micro_tok: 0.9863275398902863
train_time: 501.4119002819061
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9423    0.9374    0.9399      2909
           1     0.9837    0.9850    0.9843     11132

   micro avg     0.9751    0.9751    0.9751     14041
   macro avg     0.9630    0.9612    0.9621     14041
weighted avg     0.9751    0.9751    0.9751     14041

F1-macro sent:  0.9620968588963624
F1-micro sent:  0.9751442204971156
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9965    0.9960    169578
         LOC     0.9410    0.9418    0.9414      8297
        MISC     0.9059    0.8759    0.8906      4593
         ORG     0.9195    0.9122    0.9158     10025
         PER     0.9720    0.9762    0.9741     11128

   micro avg     0.9863    0.9863    0.9863    203621
   macro avg     0.9468    0.9405    0.9436    203621
weighted avg     0.9862    0.9863    0.9863    203621

F1-macro tok:  0.9435930512189534
F1-micro tok:  0.9863275398902863
**************************************************
dev_cost_sum: 87161.99873352051
dev_cost_avg: 26.819076533390927
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50719.0
dev_accuracy_tok: 0.9874810170943499
dev_label=0_precision_sent: 0.9840764331210191
dev_label=0_recall_sent: 0.958139534883721
dev_label=0_f-score_sent: 0.9709347996857817
dev_label=1_precision_sent: 0.9897025171624714
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9929213698105989
dev_precision_macro_sent: 0.9868894751417452
dev_recall_macro_sent: 0.9771503816453153
dev_f-score_macro_sent: 0.9819280847481903
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9958887149898386
dev_label=O_recall_tok: 0.9970532519469585
dev_label=O_f-score_tok: 0.9964706432311145
dev_label=LOC_precision_tok: 0.9443144595226953
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9539116048215551
dev_label=MISC_precision_tok: 0.9102244389027432
dev_label=MISC_recall_tok: 0.863564668769716
dev_label=MISC_f-score_tok: 0.8862808579522461
dev_label=ORG_precision_tok: 0.9448101265822785
dev_label=ORG_recall_tok: 0.8919694072657743
dev_label=ORG_f-score_tok: 0.9176297024834029
dev_label=PER_precision_tok: 0.9595429277331686
dev_label=PER_recall_tok: 0.9866624325182598
dev_label=PER_f-score_tok: 0.9729137310161265
dev_precision_macro_tok: 0.9509561335461448
dev_recall_macro_tok: 0.9405911173341437
dev_f-score_macro_tok: 0.9454413079008891
dev_precision_micro_tok: 0.9874810170943499
dev_recall_micro_tok: 0.9874810170943499
dev_f-score_micro_tok: 0.9874810170943499
dev_time: 55.55046606063843
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9841    0.9581    0.9709       645
           1     0.9897    0.9962    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9869    0.9772    0.9819      3250
weighted avg     0.9886    0.9886    0.9886      3250

F1-macro sent:  0.9819280847481903
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9971    0.9965     42759
         LOC     0.9443    0.9637    0.9539      2094
        MISC     0.9102    0.8636    0.8863      1268
         ORG     0.9448    0.8920    0.9176      2092
         PER     0.9595    0.9867    0.9729      3149

   micro avg     0.9875    0.9875    0.9875     51362
   macro avg     0.9510    0.9406    0.9454     51362
weighted avg     0.9874    0.9875    0.9874     51362

F1-macro tok:  0.9454413079008891
F1-micro tok:  0.9874810170943499
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 321779.9653015137
train_cost_avg: 22.91716867043043
train_count_sent: 14041.0
train_total_correct_sent: 13688.0
train_accuracy_sent: 0.9748593405028132
train_count_tok: 203621.0
train_total_correct_tok: 201007.0
train_accuracy_tok: 0.9871624243079054
train_label=0_precision_sent: 0.9370725034199726
train_label=0_recall_sent: 0.9419044345135785
train_label=0_f-score_sent: 0.9394822561289218
train_label=1_precision_sent: 0.9847980570297742
train_label=1_recall_sent: 0.9834710743801653
train_label=1_f-score_sent: 0.9841341183873432
train_precision_macro_sent: 0.9609352802248734
train_recall_macro_sent: 0.9626877544468719
train_f-score_macro_sent: 0.9618081872581326
train_precision_micro_sent: 0.9748593405028132
train_recall_micro_sent: 0.9748593405028132
train_f-score_micro_sent: 0.9748593405028132
train_label=O_precision_tok: 0.9957283086459033
train_label=O_recall_tok: 0.9965738480227389
train_label=O_f-score_tok: 0.9961508989095197
train_label=LOC_precision_tok: 0.9485817742908872
train_label=LOC_recall_tok: 0.9472098348800772
train_label=LOC_f-score_tok: 0.9478953081654807
train_label=MISC_precision_tok: 0.9116456834532374
train_label=MISC_recall_tok: 0.8828652296973656
train_label=MISC_f-score_tok: 0.897024665413118
train_label=ORG_precision_tok: 0.9251598721023181
train_label=ORG_recall_tok: 0.9235910224438902
train_label=ORG_f-score_tok: 0.9243747816103429
train_label=PER_precision_tok: 0.9712314034773257
train_label=PER_recall_tok: 0.9738497483824586
train_label=PER_f-score_tok: 0.9725388136049538
train_precision_macro_tok: 0.9504694083939343
train_recall_macro_tok: 0.9448179366853061
train_f-score_macro_tok: 0.9475968935406829
train_precision_micro_tok: 0.9871624243079054
train_recall_micro_tok: 0.9871624243079054
train_f-score_micro_tok: 0.9871624243079054
train_time: 504.42697405815125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9371    0.9419    0.9395      2909
           1     0.9848    0.9835    0.9841     11132

   micro avg     0.9749    0.9749    0.9749     14041
   macro avg     0.9609    0.9627    0.9618     14041
weighted avg     0.9749    0.9749    0.9749     14041

F1-macro sent:  0.9618081872581326
F1-micro sent:  0.9748593405028132
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9966    0.9962    169578
         LOC     0.9486    0.9472    0.9479      8297
        MISC     0.9116    0.8829    0.8970      4593
         ORG     0.9252    0.9236    0.9244     10025
         PER     0.9712    0.9738    0.9725     11128

   micro avg     0.9872    0.9872    0.9872    203621
   macro avg     0.9505    0.9448    0.9476    203621
weighted avg     0.9871    0.9872    0.9871    203621

F1-macro tok:  0.9475968935406829
F1-micro tok:  0.9871624243079054
**************************************************
dev_cost_sum: 86597.51320648193
dev_cost_avg: 26.645388678917517
dev_count_sent: 3250.0
dev_total_correct_sent: 3178.0
dev_accuracy_sent: 0.9778461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50713.0
dev_accuracy_tok: 0.9873641992134262
dev_label=0_precision_sent: 0.9864176570458404
dev_label=0_recall_sent: 0.9007751937984496
dev_label=0_f-score_sent: 0.9416531604538088
dev_label=1_precision_sent: 0.9759488913942127
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9863273832130649
dev_precision_macro_sent: 0.9811832742200266
dev_recall_macro_sent: 0.9488520882619887
dev_f-score_macro_sent: 0.9639902718334368
dev_precision_micro_sent: 0.9778461538461538
dev_recall_micro_sent: 0.9778461538461538
dev_f-score_micro_sent: 0.9778461538461538
dev_label=O_precision_tok: 0.9956805977118842
dev_label=O_recall_tok: 0.9973338946186767
dev_label=O_f-score_tok: 0.9965065604224843
dev_label=LOC_precision_tok: 0.9311610830656264
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.949684062719401
dev_label=MISC_precision_tok: 0.9203389830508475
dev_label=MISC_recall_tok: 0.8564668769716088
dev_label=MISC_f-score_tok: 0.8872549019607843
dev_label=ORG_precision_tok: 0.9482846902201741
dev_label=ORG_recall_tok: 0.8852772466539197
dev_label=ORG_f-score_tok: 0.9156983930778739
dev_label=PER_precision_tok: 0.9630434782608696
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9737792432092951
dev_precision_macro_tok: 0.9517017664618803
dev_recall_macro_tok: 0.9385588028512682
dev_f-score_macro_tok: 0.9445846322779676
dev_precision_micro_tok: 0.9873641992134262
dev_recall_micro_tok: 0.9873641992134262
dev_f-score_micro_tok: 0.9873641992134262
dev_time: 54.75745677947998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9864    0.9008    0.9417       645
           1     0.9759    0.9969    0.9863      2605

   micro avg     0.9778    0.9778    0.9778      3250
   macro avg     0.9812    0.9489    0.9640      3250
weighted avg     0.9780    0.9778    0.9775      3250

F1-macro sent:  0.9639902718334368
F1-micro sent:  0.9778461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9973    0.9965     42759
         LOC     0.9312    0.9690    0.9497      2094
        MISC     0.9203    0.8565    0.8873      1268
         ORG     0.9483    0.8853    0.9157      2092
         PER     0.9630    0.9848    0.9738      3149

   micro avg     0.9874    0.9874    0.9874     51362
   macro avg     0.9517    0.9386    0.9446     51362
weighted avg     0.9873    0.9874    0.9872     51362

F1-macro tok:  0.9445846322779676
F1-micro tok:  0.9873641992134262
**************************************************
Best epoch: 11
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 319089.60189819336
train_cost_avg: 22.725560992678112
train_count_sent: 14041.0
train_total_correct_sent: 13751.0
train_accuracy_sent: 0.979346200413076
train_count_tok: 203621.0
train_total_correct_tok: 201281.0
train_accuracy_tok: 0.9885080615457148
train_label=0_precision_sent: 0.9492281303602058
train_label=0_recall_sent: 0.9511859745617051
train_label=0_f-score_sent: 0.950206043956044
train_label=1_precision_sent: 0.9872371022829408
train_label=1_recall_sent: 0.986704994610133
train_label=1_f-score_sent: 0.9869709767274688
train_precision_macro_sent: 0.9682326163215733
train_recall_macro_sent: 0.968945484585919
train_f-score_macro_sent: 0.9685885103417564
train_precision_micro_sent: 0.979346200413076
train_recall_micro_sent: 0.979346200413076
train_f-score_micro_sent: 0.979346200413076
train_label=O_precision_tok: 0.9962056714606398
train_label=O_recall_tok: 0.9970809892792697
train_label=O_f-score_tok: 0.9966431381795141
train_label=LOC_precision_tok: 0.9510371442354076
train_label=LOC_recall_tok: 0.9504640231408943
train_label=LOC_f-score_tok: 0.9507504973174996
train_label=MISC_precision_tok: 0.9178419520931274
train_label=MISC_recall_tok: 0.8926627476594818
train_label=MISC_f-score_tok: 0.9050772626931568
train_label=ORG_precision_tok: 0.9336340852130326
train_label=ORG_recall_tok: 0.9289775561097257
train_label=ORG_f-score_tok: 0.9313
train_label=PER_precision_tok: 0.9766129032258064
train_label=PER_recall_tok: 0.9794212796549245
train_label=PER_f-score_tok: 0.9780150753768845
train_precision_macro_tok: 0.9550663512456028
train_recall_macro_tok: 0.9497213191688593
train_f-score_macro_tok: 0.9523571947134111
train_precision_micro_tok: 0.9885080615457148
train_recall_micro_tok: 0.9885080615457148
train_f-score_micro_tok: 0.9885080615457148
train_time: 506.65084314346313
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9492    0.9512    0.9502      2909
           1     0.9872    0.9867    0.9870     11132

   micro avg     0.9793    0.9793    0.9793     14041
   macro avg     0.9682    0.9689    0.9686     14041
weighted avg     0.9794    0.9793    0.9794     14041

F1-macro sent:  0.9685885103417564
F1-micro sent:  0.979346200413076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9971    0.9966    169578
         LOC     0.9510    0.9505    0.9508      8297
        MISC     0.9178    0.8927    0.9051      4593
         ORG     0.9336    0.9290    0.9313     10025
         PER     0.9766    0.9794    0.9780     11128

   micro avg     0.9885    0.9885    0.9885    203621
   macro avg     0.9551    0.9497    0.9524    203621
weighted avg     0.9884    0.9885    0.9885    203621

F1-macro tok:  0.9523571947134111
F1-micro tok:  0.9885080615457148
**************************************************
dev_cost_sum: 86008.35726165771
dev_cost_avg: 26.464109926663912
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50770.0
dev_accuracy_tok: 0.9884739690822009
dev_label=0_precision_sent: 0.9840764331210191
dev_label=0_recall_sent: 0.958139534883721
dev_label=0_f-score_sent: 0.9709347996857817
dev_label=1_precision_sent: 0.9897025171624714
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9929213698105989
dev_precision_macro_sent: 0.9868894751417452
dev_recall_macro_sent: 0.9771503816453153
dev_f-score_macro_sent: 0.9819280847481903
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.995749748954952
dev_label=O_recall_tok: 0.9971935732828177
dev_label=O_f-score_tok: 0.9964711381163824
dev_label=LOC_precision_tok: 0.9586305278174037
dev_label=LOC_recall_tok: 0.9627507163323782
dev_label=LOC_f-score_tok: 0.9606862044317369
dev_label=MISC_precision_tok: 0.9107438016528926
dev_label=MISC_recall_tok: 0.8690851735015773
dev_label=MISC_f-score_tok: 0.8894269572235676
dev_label=ORG_precision_tok: 0.9323017408123792
dev_label=ORG_recall_tok: 0.9216061185468452
dev_label=ORG_f-score_tok: 0.926923076923077
dev_label=PER_precision_tok: 0.9762658227848101
dev_label=PER_recall_tok: 0.979676087646872
dev_label=PER_f-score_tok: 0.9779679822475827
dev_precision_macro_tok: 0.9547383284044875
dev_recall_macro_tok: 0.946062333862098
dev_f-score_macro_tok: 0.9502950717884693
dev_precision_micro_tok: 0.9884739690822009
dev_recall_micro_tok: 0.9884739690822009
dev_f-score_micro_tok: 0.9884739690822009
dev_time: 54.13210654258728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9841    0.9581    0.9709       645
           1     0.9897    0.9962    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9869    0.9772    0.9819      3250
weighted avg     0.9886    0.9886    0.9886      3250

F1-macro sent:  0.9819280847481903
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9972    0.9965     42759
         LOC     0.9586    0.9628    0.9607      2094
        MISC     0.9107    0.8691    0.8894      1268
         ORG     0.9323    0.9216    0.9269      2092
         PER     0.9763    0.9797    0.9780      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9547    0.9461    0.9503     51362
weighted avg     0.9884    0.9885    0.9884     51362

F1-macro tok:  0.9502950717884693
F1-micro tok:  0.9884739690822009
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 316885.88064575195
train_cost_avg: 22.568611968218214
train_count_sent: 14041.0
train_total_correct_sent: 13750.0
train_accuracy_sent: 0.9792749804145003
train_count_tok: 203621.0
train_total_correct_tok: 201297.0
train_accuracy_tok: 0.9885866389026672
train_label=0_precision_sent: 0.9470628415300546
train_label=0_recall_sent: 0.9532485390168443
train_label=0_f-score_sent: 0.9501456227514133
train_label=1_precision_sent: 0.9877620804463241
train_label=1_recall_sent: 0.9860761767876393
train_label=1_f-score_sent: 0.9869184086311531
train_precision_macro_sent: 0.9674124609881893
train_recall_macro_sent: 0.9696623579022418
train_f-score_macro_sent: 0.9685320156912832
train_precision_micro_sent: 0.9792749804145003
train_recall_micro_sent: 0.9792749804145003
train_f-score_micro_sent: 0.9792749804145003
train_label=O_precision_tok: 0.9962587418767564
train_label=O_recall_tok: 0.9971458561841748
train_label=O_f-score_tok: 0.996702101636571
train_label=LOC_precision_tok: 0.9507033786220993
train_label=LOC_recall_tok: 0.9529950584548632
train_label=LOC_f-score_tok: 0.9518478391717828
train_label=MISC_precision_tok: 0.9153036074389425
train_label=MISC_recall_tok: 0.8893969083387764
train_label=MISC_f-score_tok: 0.9021643109540637
train_label=ORG_precision_tok: 0.9354838709677419
train_label=ORG_recall_tok: 0.9285785536159601
train_label=ORG_f-score_tok: 0.9320184221065276
train_label=PER_precision_tok: 0.9767941940686319
train_label=PER_recall_tok: 0.9796908698777858
train_label=PER_f-score_tok: 0.9782403876351563
train_precision_macro_tok: 0.9549087585948344
train_recall_macro_tok: 0.9495614492943121
train_f-score_macro_tok: 0.9521946123008203
train_precision_micro_tok: 0.9885866389026672
train_recall_micro_tok: 0.9885866389026672
train_f-score_micro_tok: 0.9885866389026672
train_time: 424.1626536846161
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9471    0.9532    0.9501      2909
           1     0.9878    0.9861    0.9869     11132

   micro avg     0.9793    0.9793    0.9793     14041
   macro avg     0.9674    0.9697    0.9685     14041
weighted avg     0.9793    0.9793    0.9793     14041

F1-macro sent:  0.9685320156912832
F1-micro sent:  0.9792749804145003
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9971    0.9967    169578
         LOC     0.9507    0.9530    0.9518      8297
        MISC     0.9153    0.8894    0.9022      4593
         ORG     0.9355    0.9286    0.9320     10025
         PER     0.9768    0.9797    0.9782     11128

   micro avg     0.9886    0.9886    0.9886    203621
   macro avg     0.9549    0.9496    0.9522    203621
weighted avg     0.9885    0.9886    0.9885    203621

F1-macro tok:  0.9521946123008203
F1-micro tok:  0.9885866389026672
**************************************************
dev_cost_sum: 85732.09627532959
dev_cost_avg: 26.379106546255258
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50760.0
dev_accuracy_tok: 0.9882792726139947
dev_label=0_precision_sent: 0.982839313572543
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.979782270606532
dev_label=1_precision_sent: 0.9942506707550786
dev_label=1_recall_sent: 0.9957773512476008
dev_label=1_f-score_sent: 0.9950134253931722
dev_precision_macro_sent: 0.9885449921638108
dev_recall_macro_sent: 0.9862607686470561
dev_f-score_macro_sent: 0.9873978479998521
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9959826225066567
dev_label=O_recall_tok: 0.9972637339507472
dev_label=O_f-score_tok: 0.996622766526825
dev_label=LOC_precision_tok: 0.9466042154566745
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9557815086308821
dev_label=MISC_precision_tok: 0.9161727349703641
dev_label=MISC_recall_tok: 0.8533123028391167
dev_label=MISC_f-score_tok: 0.8836259697835852
dev_label=ORG_precision_tok: 0.9278499278499278
dev_label=ORG_recall_tok: 0.9220841300191205
dev_label=ORG_f-score_tok: 0.92495804363462
dev_label=PER_precision_tok: 0.9787503964478275
dev_label=PER_recall_tok: 0.9799936487773896
dev_label=PER_f-score_tok: 0.9793716280545858
dev_precision_macro_tok: 0.9530719794462901
dev_recall_macro_tok: 0.943558461302566
dev_f-score_macro_tok: 0.9480719833260997
dev_precision_micro_tok: 0.9882792726139947
dev_recall_micro_tok: 0.9882792726139947
dev_f-score_micro_tok: 0.9882792726139947
dev_time: 45.1485698223114
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9828    0.9767    0.9798       645
           1     0.9943    0.9958    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9885    0.9863    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9873978479998521
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9973    0.9966     42759
         LOC     0.9466    0.9651    0.9558      2094
        MISC     0.9162    0.8533    0.8836      1268
         ORG     0.9278    0.9221    0.9250      2092
         PER     0.9788    0.9800    0.9794      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9531    0.9436    0.9481     51362
weighted avg     0.9882    0.9883    0.9882     51362

F1-macro tok:  0.9480719833260997
F1-micro tok:  0.9882792726139947
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 314827.00302124023
train_cost_avg: 22.421978706733157
train_count_sent: 14041.0
train_total_correct_sent: 13775.0
train_accuracy_sent: 0.9810554803788903
train_count_tok: 203621.0
train_total_correct_tok: 201407.0
train_accuracy_tok: 0.9891268582317148
train_label=0_precision_sent: 0.9521040027369141
train_label=0_recall_sent: 0.9566861464420763
train_label=0_f-score_sent: 0.9543895747599451
train_label=1_precision_sent: 0.9886670264436049
train_label=1_recall_sent: 0.9874236435501258
train_label=1_f-score_sent: 0.9880449438202247
train_precision_macro_sent: 0.9703855145902596
train_recall_macro_sent: 0.972054894996101
train_f-score_macro_sent: 0.971217259290085
train_precision_micro_sent: 0.9810554803788903
train_recall_micro_sent: 0.9810554803788903
train_f-score_micro_sent: 0.9810554803788903
train_label=O_precision_tok: 0.9963709416110427
train_label=O_recall_tok: 0.9973286629161802
train_label=O_f-score_tok: 0.99684957223144
train_label=LOC_precision_tok: 0.9531868923298523
train_label=LOC_recall_tok: 0.95709292515367
train_label=LOC_f-score_tok: 0.9551359153235506
train_label=MISC_precision_tok: 0.9228015215931976
train_label=MISC_recall_tok: 0.8978880905726105
train_label=MISC_f-score_tok: 0.910174354447142
train_label=ORG_precision_tok: 0.9389850986709626
train_label=ORG_recall_tok: 0.9302743142144638
train_label=ORG_f-score_tok: 0.934609410231999
train_label=PER_precision_tok: 0.9769465374955149
train_label=PER_recall_tok: 0.9787023723939612
train_label=PER_f-score_tok: 0.9778236667265218
train_precision_macro_tok: 0.9576581983401141
train_recall_macro_tok: 0.9522572730501772
train_f-score_macro_tok: 0.9549185837921307
train_precision_micro_tok: 0.9891268582317148
train_recall_micro_tok: 0.9891268582317148
train_f-score_micro_tok: 0.9891268582317148
train_time: 416.6332983970642
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9521    0.9567    0.9544      2909
           1     0.9887    0.9874    0.9880     11132

   micro avg     0.9811    0.9811    0.9811     14041
   macro avg     0.9704    0.9721    0.9712     14041
weighted avg     0.9811    0.9811    0.9811     14041

F1-macro sent:  0.971217259290085
F1-micro sent:  0.9810554803788903
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9973    0.9968    169578
         LOC     0.9532    0.9571    0.9551      8297
        MISC     0.9228    0.8979    0.9102      4593
         ORG     0.9390    0.9303    0.9346     10025
         PER     0.9769    0.9787    0.9778     11128

   micro avg     0.9891    0.9891    0.9891    203621
   macro avg     0.9577    0.9523    0.9549    203621
weighted avg     0.9891    0.9891    0.9891    203621

F1-macro tok:  0.9549185837921307
F1-micro tok:  0.9891268582317148
**************************************************
dev_cost_sum: 85226.74393463135
dev_cost_avg: 26.223613518348106
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50771.0
dev_accuracy_tok: 0.9884934387290214
dev_label=0_precision_sent: 0.9797191887675507
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9766718506998445
dev_label=1_precision_sent: 0.9934840935224224
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9942462600690449
dev_precision_macro_sent: 0.9866016411449865
dev_recall_macro_sent: 0.984326503890848
dev_f-score_macro_sent: 0.9854590553844447
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9963320328014391
dev_label=O_recall_tok: 0.9973572815079866
dev_label=O_f-score_tok: 0.996844393539188
dev_label=LOC_precision_tok: 0.9442638179284719
dev_label=LOC_recall_tok: 0.9708691499522445
dev_label=LOC_f-score_tok: 0.9573816811867201
dev_label=MISC_precision_tok: 0.9025764895330113
dev_label=MISC_recall_tok: 0.8840694006309149
dev_label=MISC_f-score_tok: 0.8932270916334661
dev_label=ORG_precision_tok: 0.9512937595129376
dev_label=ORG_recall_tok: 0.8962715105162524
dev_label=ORG_f-score_tok: 0.9229633275904504
dev_label=PER_precision_tok: 0.9696210460382085
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9763481551561023
dev_precision_macro_tok: 0.9528174291628136
dev_recall_macro_tok: 0.9463473205379929
dev_f-score_macro_tok: 0.9493529298211854
dev_precision_micro_tok: 0.9884934387290214
dev_recall_micro_tok: 0.9884934387290214
dev_f-score_micro_tok: 0.9884934387290213
dev_time: 45.212642192840576
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9797    0.9736    0.9767       645
           1     0.9935    0.9950    0.9942      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9866    0.9843    0.9855      3250
weighted avg     0.9908    0.9908    0.9908      3250

F1-macro sent:  0.9854590553844447
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9974    0.9968     42759
         LOC     0.9443    0.9709    0.9574      2094
        MISC     0.9026    0.8841    0.8932      1268
         ORG     0.9513    0.8963    0.9230      2092
         PER     0.9696    0.9832    0.9763      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9528    0.9463    0.9494     51362
weighted avg     0.9884    0.9885    0.9884     51362

F1-macro tok:  0.9493529298211854
F1-micro tok:  0.9884934387290213
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 312796.9892272949
train_cost_avg: 22.27740112721992
train_count_sent: 14041.0
train_total_correct_sent: 13776.0
train_accuracy_sent: 0.981126700377466
train_count_tok: 203621.0
train_total_correct_tok: 201509.0
train_accuracy_tok: 0.9896277888822862
train_label=0_precision_sent: 0.9508867667121419
train_label=0_recall_sent: 0.9584049501546923
train_label=0_f-score_sent: 0.9546310563259716
train_label=1_precision_sent: 0.9891079305067962
train_label=1_recall_sent: 0.9870643190801294
train_label=1_f-score_sent: 0.9880850681174408
train_precision_macro_sent: 0.9699973486094691
train_recall_macro_sent: 0.9727346346174108
train_f-score_macro_sent: 0.9713580622217062
train_precision_micro_sent: 0.981126700377466
train_recall_micro_sent: 0.981126700377466
train_f-score_micro_sent: 0.981126700377466
train_label=O_precision_tok: 0.9965764523561197
train_label=O_recall_tok: 0.9973345599075352
train_label=O_f-score_tok: 0.9969553620112885
train_label=LOC_precision_tok: 0.9525179856115108
train_label=LOC_recall_tok: 0.9574545016270941
train_label=LOC_f-score_tok: 0.9549798641582016
train_label=MISC_precision_tok: 0.9292611722434314
train_label=MISC_recall_tok: 0.9009362072719356
train_label=MISC_f-score_tok: 0.9148795047534822
train_label=ORG_precision_tok: 0.942261427425822
train_label=ORG_recall_tok: 0.9376558603491272
train_label=ORG_f-score_tok: 0.9399530023498825
train_label=PER_precision_tok: 0.9781067743382683
train_label=PER_recall_tok: 0.9796010064701653
train_label=PER_f-score_tok: 0.9788533201634266
train_precision_macro_tok: 0.9597447623950306
train_recall_macro_tok: 0.9545964271251716
train_f-score_macro_tok: 0.9571242106872562
train_precision_micro_tok: 0.9896277888822862
train_recall_micro_tok: 0.9896277888822862
train_f-score_micro_tok: 0.9896277888822862
train_time: 363.670729637146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9509    0.9584    0.9546      2909
           1     0.9891    0.9871    0.9881     11132

   micro avg     0.9811    0.9811    0.9811     14041
   macro avg     0.9700    0.9727    0.9714     14041
weighted avg     0.9812    0.9811    0.9812     14041

F1-macro sent:  0.9713580622217062
F1-micro sent:  0.981126700377466
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9973    0.9970    169578
         LOC     0.9525    0.9575    0.9550      8297
        MISC     0.9293    0.9009    0.9149      4593
         ORG     0.9423    0.9377    0.9400     10025
         PER     0.9781    0.9796    0.9789     11128

   micro avg     0.9896    0.9896    0.9896    203621
   macro avg     0.9597    0.9546    0.9571    203621
weighted avg     0.9896    0.9896    0.9896    203621

F1-macro tok:  0.9571242106872562
F1-micro tok:  0.9896277888822862
**************************************************
dev_cost_sum: 84897.62185668945
dev_cost_avg: 26.122345186673677
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50797.0
dev_accuracy_tok: 0.9889996495463572
dev_label=0_precision_sent: 0.9904
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.9748031496062992
dev_label=1_precision_sent: 0.9900952380952381
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.9938814531548757
dev_precision_macro_sent: 0.990247619047619
dev_recall_macro_sent: 0.978693329762383
dev_f-score_macro_sent: 0.9843423013805874
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.995913697286695
dev_label=O_recall_tok: 0.9974742159545359
dev_label=O_f-score_tok: 0.9966933457965765
dev_label=LOC_precision_tok: 0.9667469879518072
dev_label=LOC_recall_tok: 0.9579751671442216
dev_label=LOC_f-score_tok: 0.9623410889901655
dev_label=MISC_precision_tok: 0.9143556280587276
dev_label=MISC_recall_tok: 0.8840694006309149
dev_label=MISC_f-score_tok: 0.8989574979951884
dev_label=ORG_precision_tok: 0.942014742014742
dev_label=ORG_recall_tok: 0.9163479923518164
dev_label=ORG_f-score_tok: 0.9290041192149262
dev_label=PER_precision_tok: 0.969375
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.977161757757127
dev_precision_macro_tok: 0.9576812110623945
dev_recall_macro_tok: 0.948188280589432
dev_f-score_macro_tok: 0.9528315619507968
dev_precision_micro_tok: 0.9889996495463572
dev_recall_micro_tok: 0.9889996495463572
dev_f-score_micro_tok: 0.9889996495463572
dev_time: 33.65027952194214
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9904    0.9597    0.9748       645
           1     0.9901    0.9977    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9902    0.9787    0.9843      3250
weighted avg     0.9902    0.9902    0.9901      3250

F1-macro sent:  0.9843423013805874
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9975    0.9967     42759
         LOC     0.9667    0.9580    0.9623      2094
        MISC     0.9144    0.8841    0.8990      1268
         ORG     0.9420    0.9163    0.9290      2092
         PER     0.9694    0.9851    0.9772      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9577    0.9482    0.9528     51362
weighted avg     0.9889    0.9890    0.9889     51362

F1-macro tok:  0.9528315619507968
F1-micro tok:  0.9889996495463572
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 310894.5579223633
train_cost_avg: 22.141909972392515
train_count_sent: 14041.0
train_total_correct_sent: 13813.0
train_accuracy_sent: 0.9837618403247632
train_count_tok: 203621.0
train_total_correct_tok: 201681.0
train_accuracy_tok: 0.9904724954695243
train_label=0_precision_sent: 0.9630397236614853
train_label=0_recall_sent: 0.9584049501546923
train_label=0_f-score_sent: 0.9607167470709855
train_label=1_precision_sent: 0.9891440875650458
train_label=1_recall_sent: 0.9903880704275961
train_label=1_f-score_sent: 0.9897656881228117
train_precision_macro_sent: 0.9760919056132655
train_recall_macro_sent: 0.9743965102911443
train_f-score_macro_sent: 0.9752412175968986
train_precision_micro_sent: 0.9837618403247632
train_recall_micro_sent: 0.9837618403247632
train_f-score_micro_sent: 0.9837618403247631
train_label=O_precision_tok: 0.9969584079977365
train_label=O_recall_tok: 0.9973699418556652
train_label=O_f-score_tok: 0.9971641324662613
train_label=LOC_precision_tok: 0.9588313413014609
train_label=LOC_recall_tok: 0.9572134506448113
train_label=LOC_f-score_tok: 0.958021712907117
train_label=MISC_precision_tok: 0.9287925696594427
train_label=MISC_recall_tok: 0.914435009797518
train_label=MISC_f-score_tok: 0.9215578716401536
train_label=ORG_precision_tok: 0.9466733366683342
train_label=ORG_recall_tok: 0.9438403990024937
train_label=ORG_f-score_tok: 0.9452547452547452
train_label=PER_precision_tok: 0.9795936632954444
train_label=PER_recall_tok: 0.9835549964054637
train_label=PER_f-score_tok: 0.9815703331689163
train_precision_macro_tok: 0.9621698637844837
train_recall_macro_tok: 0.9592827595411905
train_f-score_macro_tok: 0.9607137590874387
train_precision_micro_tok: 0.9904724954695243
train_recall_micro_tok: 0.9904724954695243
train_f-score_micro_tok: 0.9904724954695243
train_time: 329.21204233169556
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9630    0.9584    0.9607      2909
           1     0.9891    0.9904    0.9898     11132

   micro avg     0.9838    0.9838    0.9838     14041
   macro avg     0.9761    0.9744    0.9752     14041
weighted avg     0.9837    0.9838    0.9837     14041

F1-macro sent:  0.9752412175968986
F1-micro sent:  0.9837618403247631
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9974    0.9972    169578
         LOC     0.9588    0.9572    0.9580      8297
        MISC     0.9288    0.9144    0.9216      4593
         ORG     0.9467    0.9438    0.9453     10025
         PER     0.9796    0.9836    0.9816     11128

   micro avg     0.9905    0.9905    0.9905    203621
   macro avg     0.9622    0.9593    0.9607    203621
weighted avg     0.9904    0.9905    0.9905    203621

F1-macro tok:  0.9607137590874387
F1-micro tok:  0.9904724954695243
**************************************************
dev_cost_sum: 84514.07237243652
dev_cost_avg: 26.0043299607497
dev_count_sent: 3250.0
dev_total_correct_sent: 3208.0
dev_accuracy_sent: 0.9870769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50786.0
dev_accuracy_tok: 0.9887854834313305
dev_label=0_precision_sent: 0.9547511312217195
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9678899082568808
dev_label=1_precision_sent: 0.9953614224971009
dev_label=1_recall_sent: 0.9884836852207294
dev_label=1_f-score_sent: 0.9919106317411402
dev_precision_macro_sent: 0.9750562768594102
dev_recall_macro_sent: 0.9849395170289693
dev_f-score_macro_sent: 0.9799002699990105
dev_precision_micro_sent: 0.9870769230769231
dev_recall_micro_sent: 0.9870769230769231
dev_f-score_micro_sent: 0.9870769230769231
dev_label=O_precision_tok: 0.9959380909027242
dev_label=O_recall_tok: 0.9977548586262541
dev_label=O_f-score_tok: 0.99684564699285
dev_label=LOC_precision_tok: 0.9594465648854962
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9599045346062053
dev_label=MISC_precision_tok: 0.9092382495948136
dev_label=MISC_recall_tok: 0.8848580441640379
dev_label=MISC_f-score_tok: 0.896882494004796
dev_label=ORG_precision_tok: 0.9464732366183092
dev_label=ORG_recall_tok: 0.904397705544933
dev_label=ORG_f-score_tok: 0.9249572231728185
dev_label=PER_precision_tok: 0.9693366708385481
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9765169424743892
dev_precision_macro_tok: 0.9560865625679783
dev_recall_macro_tok: 0.9462355864834253
dev_f-score_macro_tok: 0.9510213682502118
dev_precision_micro_tok: 0.9887854834313305
dev_recall_micro_tok: 0.9887854834313305
dev_f-score_micro_tok: 0.9887854834313305
dev_time: 34.361682176589966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9548    0.9814    0.9679       645
           1     0.9954    0.9885    0.9919      2605

   micro avg     0.9871    0.9871    0.9871      3250
   macro avg     0.9751    0.9849    0.9799      3250
weighted avg     0.9873    0.9871    0.9871      3250

F1-macro sent:  0.9799002699990105
F1-micro sent:  0.9870769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9978    0.9968     42759
         LOC     0.9594    0.9604    0.9599      2094
        MISC     0.9092    0.8849    0.8969      1268
         ORG     0.9465    0.9044    0.9250      2092
         PER     0.9693    0.9838    0.9765      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9561    0.9462    0.9510     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9510213682502118
F1-micro tok:  0.9887854834313305
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 308953.03704833984
train_cost_avg: 22.003634858510065
train_count_sent: 14041.0
train_total_correct_sent: 13814.0
train_accuracy_sent: 0.9838330603233388
train_count_tok: 203621.0
train_total_correct_tok: 201720.0
train_accuracy_tok: 0.9906640277770957
train_label=0_precision_sent: 0.9605082417582418
train_label=0_recall_sent: 0.9614987968374011
train_label=0_f-score_sent: 0.9610032640439787
train_label=1_precision_sent: 0.989936202713631
train_label=1_recall_sent: 0.9896694214876033
train_label=1_f-score_sent: 0.9898027941242532
train_precision_macro_sent: 0.9752222222359364
train_recall_macro_sent: 0.9755841091625022
train_f-score_macro_sent: 0.975403029084116
train_precision_micro_sent: 0.9838330603233388
train_recall_micro_sent: 0.9838330603233388
train_f-score_micro_sent: 0.9838330603233388
train_label=O_precision_tok: 0.9970058997919454
train_label=O_recall_tok: 0.9975291606222505
train_label=O_f-score_tok: 0.9972674615690726
train_label=LOC_precision_tok: 0.9591664659118285
train_label=LOC_recall_tok: 0.9597444859587803
train_label=LOC_f-score_tok: 0.9594553888788481
train_label=MISC_precision_tok: 0.9313247673903412
train_label=MISC_recall_tok: 0.9153059002830394
train_label=MISC_f-score_tok: 0.9232458548369386
train_label=ORG_precision_tok: 0.9473
train_label=ORG_recall_tok: 0.9449376558603492
train_label=ORG_f-score_tok: 0.9461173533083646
train_label=PER_precision_tok: 0.9805171485006284
train_label=PER_recall_tok: 0.9813982746225737
train_label=PER_f-score_tok: 0.9809575136980149
train_precision_macro_tok: 0.9630628563189487
train_recall_macro_tok: 0.9597830954693987
train_f-score_macro_tok: 0.9614087144582477
train_precision_micro_tok: 0.9906640277770957
train_recall_micro_tok: 0.9906640277770957
train_f-score_micro_tok: 0.9906640277770957
train_time: 327.1981348991394
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9605    0.9615    0.9610      2909
           1     0.9899    0.9897    0.9898     11132

   micro avg     0.9838    0.9838    0.9838     14041
   macro avg     0.9752    0.9756    0.9754     14041
weighted avg     0.9838    0.9838    0.9838     14041

F1-macro sent:  0.975403029084116
F1-micro sent:  0.9838330603233388
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9975    0.9973    169578
         LOC     0.9592    0.9597    0.9595      8297
        MISC     0.9313    0.9153    0.9232      4593
         ORG     0.9473    0.9449    0.9461     10025
         PER     0.9805    0.9814    0.9810     11128

   micro avg     0.9907    0.9907    0.9907    203621
   macro avg     0.9631    0.9598    0.9614    203621
weighted avg     0.9906    0.9907    0.9906    203621

F1-macro tok:  0.9614087144582477
F1-micro tok:  0.9906640277770957
**************************************************
dev_cost_sum: 84261.73726272583
dev_cost_avg: 25.926688388531023
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50787.0
dev_accuracy_tok: 0.9888049530781512
dev_label=0_precision_sent: 0.9752321981424149
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.975987606506584
dev_label=1_precision_sent: 0.9942396313364056
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.994048761758495
dev_precision_macro_sent: 0.9847359147394102
dev_recall_macro_sent: 0.9853010757487837
dev_f-score_macro_sent: 0.9850181841325395
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9964479341933071
dev_label=O_recall_tok: 0.9972169601721275
dev_label=O_f-score_tok: 0.9968322988626667
dev_label=LOC_precision_tok: 0.961038961038961
dev_label=LOC_recall_tok: 0.9541547277936963
dev_label=LOC_f-score_tok: 0.9575844716031632
dev_label=MISC_precision_tok: 0.9332220367278798
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.9067315490673155
dev_label=ORG_precision_tok: 0.9179245283018868
dev_label=ORG_recall_tok: 0.9302103250478011
dev_label=ORG_f-score_tok: 0.9240265906932573
dev_label=PER_precision_tok: 0.9722659943271352
dev_label=PER_recall_tok: 0.979676087646872
dev_label=PER_f-score_tok: 0.97595697564062
dev_precision_macro_tok: 0.9561798909178341
dev_recall_macro_tok: 0.9485923141384085
dev_f-score_macro_tok: 0.9522263771734046
dev_precision_micro_tok: 0.9888049530781512
dev_recall_micro_tok: 0.9888049530781512
dev_f-score_micro_tok: 0.9888049530781512
dev_time: 34.94092512130737
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9752    0.9767    0.9760       645
           1     0.9942    0.9939    0.9940      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9847    0.9853    0.9850      3250
weighted avg     0.9905    0.9905    0.9905      3250

F1-macro sent:  0.9850181841325395
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9972    0.9968     42759
         LOC     0.9610    0.9542    0.9576      2094
        MISC     0.9332    0.8817    0.9067      1268
         ORG     0.9179    0.9302    0.9240      2092
         PER     0.9723    0.9797    0.9760      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9562    0.9486    0.9522     51362
weighted avg     0.9888    0.9888    0.9888     51362

F1-macro tok:  0.9522263771734046
F1-micro tok:  0.9888049530781512
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 307169.0564880371
train_cost_avg: 21.876579765546406
train_count_sent: 14041.0
train_total_correct_sent: 13831.0
train_accuracy_sent: 0.985043800299124
train_count_tok: 203621.0
train_total_correct_tok: 201914.0
train_accuracy_tok: 0.9916167782301433
train_label=0_precision_sent: 0.9613675213675213
train_label=0_recall_sent: 0.9666552079752492
train_label=0_f-score_sent: 0.964004113815564
train_label=1_precision_sent: 0.9912738395106153
train_label=1_recall_sent: 0.9898490837226015
train_label=1_f-score_sent: 0.9905609492988133
train_precision_macro_sent: 0.9763206804390683
train_recall_macro_sent: 0.9782521458489253
train_f-score_macro_sent: 0.9772825315571887
train_precision_micro_sent: 0.985043800299124
train_recall_micro_sent: 0.985043800299124
train_f-score_micro_sent: 0.985043800299124
train_label=O_precision_tok: 0.9973120814863717
train_label=O_recall_tok: 0.9977237613369658
train_label=O_f-score_tok: 0.9975178789361665
train_label=LOC_precision_tok: 0.9628468033775633
train_label=LOC_recall_tok: 0.9620344702904664
train_label=LOC_f-score_tok: 0.9624404654247302
train_label=MISC_precision_tok: 0.9432420494699647
train_label=MISC_recall_tok: 0.9298933159155236
train_label=MISC_f-score_tok: 0.9365201184080693
train_label=ORG_precision_tok: 0.9519
train_label=ORG_recall_tok: 0.9495261845386533
train_label=ORG_f-score_tok: 0.9507116104868913
train_label=PER_precision_tok: 0.9816225907664724
train_label=PER_recall_tok: 0.9840043134435658
train_label=PER_f-score_tok: 0.9828120091549611
train_precision_macro_tok: 0.9673847050200746
train_recall_macro_tok: 0.964636409105035
train_f-score_macro_tok: 0.9660004164821636
train_precision_micro_tok: 0.9916167782301433
train_recall_micro_tok: 0.9916167782301433
train_f-score_micro_tok: 0.9916167782301433
train_time: 328.6790568828583
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9614    0.9667    0.9640      2909
           1     0.9913    0.9898    0.9906     11132

   micro avg     0.9850    0.9850    0.9850     14041
   macro avg     0.9763    0.9783    0.9773     14041
weighted avg     0.9851    0.9850    0.9851     14041

F1-macro sent:  0.9772825315571887
F1-micro sent:  0.985043800299124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9973    0.9977    0.9975    169578
         LOC     0.9628    0.9620    0.9624      8297
        MISC     0.9432    0.9299    0.9365      4593
         ORG     0.9519    0.9495    0.9507     10025
         PER     0.9816    0.9840    0.9828     11128

   micro avg     0.9916    0.9916    0.9916    203621
   macro avg     0.9674    0.9646    0.9660    203621
weighted avg     0.9916    0.9916    0.9916    203621

F1-macro tok:  0.9660004164821636
F1-micro tok:  0.9916167782301433
**************************************************
dev_cost_sum: 84097.51021957397
dev_cost_avg: 25.876156990638147
dev_count_sent: 3250.0
dev_total_correct_sent: 3187.0
dev_accuracy_sent: 0.9806153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50771.0
dev_accuracy_tok: 0.9884934387290214
dev_label=0_precision_sent: 0.9217391304347826
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9528089887640449
dev_label=1_precision_sent: 0.996484375
dev_label=1_recall_sent: 0.9792706333973129
dev_label=1_f-score_sent: 0.9878025169409487
dev_precision_macro_sent: 0.9591117527173914
dev_recall_macro_sent: 0.98265857251261
dev_f-score_macro_sent: 0.9703057528524968
dev_precision_micro_sent: 0.9806153846153847
dev_recall_micro_sent: 0.9806153846153847
dev_f-score_micro_sent: 0.9806153846153847
dev_label=O_precision_tok: 0.9960999532928538
dev_label=O_recall_tok: 0.9975209897331556
dev_label=O_f-score_tok: 0.9968099650615221
dev_label=LOC_precision_tok: 0.9472947761194029
dev_label=LOC_recall_tok: 0.9699140401146131
dev_label=LOC_f-score_tok: 0.9584709768758848
dev_label=MISC_precision_tok: 0.9133278822567457
dev_label=MISC_recall_tok: 0.8809148264984227
dev_label=MISC_f-score_tok: 0.8968285828984343
dev_label=ORG_precision_tok: 0.9530851606323304
dev_label=ORG_recall_tok: 0.8934034416826003
dev_label=ORG_f-score_tok: 0.9222797927461139
dev_label=PER_precision_tok: 0.9648413192283759
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9746974697469747
dev_precision_macro_tok: 0.9549298183059417
dev_recall_macro_tok: 0.9453020727527892
dev_f-score_macro_tok: 0.9498173574657859
dev_precision_micro_tok: 0.9884934387290214
dev_recall_micro_tok: 0.9884934387290214
dev_f-score_micro_tok: 0.9884934387290213
dev_time: 34.685070753097534
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9217    0.9860    0.9528       645
           1     0.9965    0.9793    0.9878      2605

   micro avg     0.9806    0.9806    0.9806      3250
   macro avg     0.9591    0.9827    0.9703      3250
weighted avg     0.9817    0.9806    0.9809      3250

F1-macro sent:  0.9703057528524968
F1-micro sent:  0.9806153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9975    0.9968     42759
         LOC     0.9473    0.9699    0.9585      2094
        MISC     0.9133    0.8809    0.8968      1268
         ORG     0.9531    0.8934    0.9223      2092
         PER     0.9648    0.9848    0.9747      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9549    0.9453    0.9498     51362
weighted avg     0.9884    0.9885    0.9884     51362

F1-macro tok:  0.9498173574657859
F1-micro tok:  0.9884934387290213
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 305519.45010375977
train_cost_avg: 21.759094801207876
train_count_sent: 14041.0
train_total_correct_sent: 13831.0
train_accuracy_sent: 0.985043800299124
train_count_tok: 203621.0
train_total_correct_tok: 201963.0
train_accuracy_tok: 0.9918574213858099
train_label=0_precision_sent: 0.9642242862057103
train_label=0_recall_sent: 0.9635613612925404
train_label=0_f-score_sent: 0.9638927097661624
train_label=1_precision_sent: 0.9904796119992815
train_label=1_recall_sent: 0.9906575637800934
train_label=1_f-score_sent: 0.9905685798976017
train_precision_macro_sent: 0.9773519491024959
train_recall_macro_sent: 0.9771094625363169
train_f-score_macro_sent: 0.977230644831882
train_precision_micro_sent: 0.985043800299124
train_recall_micro_sent: 0.985043800299124
train_f-score_micro_sent: 0.985043800299124
train_label=O_precision_tok: 0.9973947742235897
train_label=O_recall_tok: 0.9978711861208411
train_label=O_f-score_tok: 0.9976329232955131
train_label=LOC_precision_tok: 0.9654216867469879
train_label=LOC_recall_tok: 0.9657707605158491
train_label=LOC_f-score_tok: 0.9655961920829066
train_label=MISC_precision_tok: 0.9450331125827814
train_label=MISC_recall_tok: 0.9320705421293273
train_label=MISC_f-score_tok: 0.9385070700427491
train_label=ORG_precision_tok: 0.9522713628176906
train_label=ORG_recall_tok: 0.9493266832917706
train_label=ORG_f-score_tok: 0.9507967430940607
train_label=PER_precision_tok: 0.9817741066618783
train_label=PER_recall_tok: 0.9826563623292596
train_label=PER_f-score_tok: 0.9822150363783347
train_precision_macro_tok: 0.9683790086065857
train_recall_macro_tok: 0.9655391068774095
train_f-score_macro_tok: 0.9669495929787129
train_precision_micro_tok: 0.9918574213858099
train_recall_micro_tok: 0.9918574213858099
train_f-score_micro_tok: 0.9918574213858099
train_time: 328.74700689315796
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9642    0.9636    0.9639      2909
           1     0.9905    0.9907    0.9906     11132

   micro avg     0.9850    0.9850    0.9850     14041
   macro avg     0.9774    0.9771    0.9772     14041
weighted avg     0.9850    0.9850    0.9850     14041

F1-macro sent:  0.977230644831882
F1-micro sent:  0.985043800299124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9974    0.9979    0.9976    169578
         LOC     0.9654    0.9658    0.9656      8297
        MISC     0.9450    0.9321    0.9385      4593
         ORG     0.9523    0.9493    0.9508     10025
         PER     0.9818    0.9827    0.9822     11128

   micro avg     0.9919    0.9919    0.9919    203621
   macro avg     0.9684    0.9655    0.9669    203621
weighted avg     0.9918    0.9919    0.9918    203621

F1-macro tok:  0.9669495929787129
F1-micro tok:  0.9918574213858099
**************************************************
dev_cost_sum: 83720.74756240845
dev_cost_avg: 25.7602300192026
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50835.0
dev_accuracy_tok: 0.9897394961255402
dev_label=0_precision_sent: 0.9707692307692307
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9745173745173744
dev_label=1_precision_sent: 0.9946153846153846
dev_label=1_recall_sent: 0.9927063339731286
dev_label=1_f-score_sent: 0.9936599423631123
dev_precision_macro_sent: 0.9826923076923076
dev_recall_macro_sent: 0.9855004538082697
dev_f-score_macro_sent: 0.9840886584402433
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9966115953543804
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9970076678511315
dev_label=LOC_precision_tok: 0.9632458233890214
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9634757698734782
dev_label=MISC_precision_tok: 0.9243421052631579
dev_label=MISC_recall_tok: 0.886435331230284
dev_label=MISC_f-score_tok: 0.9049919484702094
dev_label=ORG_precision_tok: 0.9333972208912314
dev_label=ORG_recall_tok: 0.9311663479923518
dev_label=ORG_f-score_tok: 0.9322804498683894
dev_label=PER_precision_tok: 0.9766635130873541
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9800632911392404
dev_precision_macro_tok: 0.9588520515970289
dev_recall_macro_tok: 0.952439676378467
dev_f-score_macro_tok: 0.9555638254404897
dev_precision_micro_tok: 0.9897394961255402
dev_recall_micro_tok: 0.9897394961255402
dev_f-score_micro_tok: 0.9897394961255402
dev_time: 34.85763692855835
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9708    0.9783    0.9745       645
           1     0.9946    0.9927    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9827    0.9855    0.9841      3250
weighted avg     0.9899    0.9898    0.9899      3250

F1-macro sent:  0.9840886584402433
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9974    0.9970     42759
         LOC     0.9632    0.9637    0.9635      2094
        MISC     0.9243    0.8864    0.9050      1268
         ORG     0.9334    0.9312    0.9323      2092
         PER     0.9767    0.9835    0.9801      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9589    0.9524    0.9556     51362
weighted avg     0.9897    0.9897    0.9897     51362

F1-macro tok:  0.9555638254404897
F1-micro tok:  0.9897394961255402
**************************************************
Best epoch: 14
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 304108.41317749023
train_cost_avg: 21.65860075332884
train_count_sent: 14041.0
train_total_correct_sent: 13859.0
train_accuracy_sent: 0.9870379602592408
train_count_tok: 203621.0
train_total_correct_tok: 202097.0
train_accuracy_tok: 0.9925155067502861
train_label=0_precision_sent: 0.9690402476780186
train_label=0_recall_sent: 0.9683740116878653
train_label=0_f-score_sent: 0.968707015130674
train_label=1_precision_sent: 0.9917370217352255
train_label=1_recall_sent: 0.9919151994250809
train_label=1_f-score_sent: 0.9918261025779216
train_precision_macro_sent: 0.980388634706622
train_recall_macro_sent: 0.9801446055564731
train_f-score_macro_sent: 0.9802665588542978
train_precision_micro_sent: 0.9870379602592408
train_recall_micro_sent: 0.9870379602592408
train_f-score_micro_sent: 0.9870379602592408
train_label=O_precision_tok: 0.9975478782663028
train_label=O_recall_tok: 0.9979655379825213
train_label=O_f-score_tok: 0.9977566644164526
train_label=LOC_precision_tok: 0.9677808615904429
train_label=LOC_recall_tok: 0.9666144389538387
train_label=LOC_f-score_tok: 0.9671972986010612
train_label=MISC_precision_tok: 0.9472289688672996
train_label=MISC_recall_tok: 0.9340300457217505
train_label=MISC_f-score_tok: 0.940583205437404
train_label=ORG_precision_tok: 0.9591081783643272
train_label=ORG_recall_tok: 0.9569077306733167
train_label=ORG_f-score_tok: 0.9580066909671944
train_label=PER_precision_tok: 0.9826967903890981
train_label=PER_recall_tok: 0.9849928109273903
train_label=PER_f-score_tok: 0.9838434610896688
train_precision_macro_tok: 0.9708725354954941
train_recall_macro_tok: 0.9681021128517635
train_f-score_macro_tok: 0.9694774641023562
train_precision_micro_tok: 0.9925155067502861
train_recall_micro_tok: 0.9925155067502861
train_f-score_micro_tok: 0.9925155067502861
train_time: 291.4089198112488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9690    0.9684    0.9687      2909
           1     0.9917    0.9919    0.9918     11132

   micro avg     0.9870    0.9870    0.9870     14041
   macro avg     0.9804    0.9801    0.9803     14041
weighted avg     0.9870    0.9870    0.9870     14041

F1-macro sent:  0.9802665588542978
F1-micro sent:  0.9870379602592408
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9975    0.9980    0.9978    169578
         LOC     0.9678    0.9666    0.9672      8297
        MISC     0.9472    0.9340    0.9406      4593
         ORG     0.9591    0.9569    0.9580     10025
         PER     0.9827    0.9850    0.9838     11128

   micro avg     0.9925    0.9925    0.9925    203621
   macro avg     0.9709    0.9681    0.9695    203621
weighted avg     0.9925    0.9925    0.9925    203621

F1-macro tok:  0.9694774641023562
F1-micro tok:  0.9925155067502861
**************************************************
dev_cost_sum: 83543.51895523071
dev_cost_avg: 25.70569814007099
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50781.0
dev_accuracy_tok: 0.9886881351972275
dev_label=0_precision_sent: 0.9767080745341615
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9759503491078355
dev_label=1_precision_sent: 0.9938603223330775
dev_label=1_recall_sent: 0.9942418426103646
dev_label=1_f-score_sent: 0.9940510458645174
dev_precision_macro_sent: 0.9852841984336196
dev_recall_macro_sent: 0.9847178205299885
dev_f-score_macro_sent: 0.9850006974861765
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9961004996964461
dev_label=O_recall_tok: 0.9976613110690147
dev_label=O_f-score_tok: 0.99688029444412
dev_label=LOC_precision_tok: 0.9490892106492294
dev_label=LOC_recall_tok: 0.9703915950334289
dev_label=LOC_f-score_tok: 0.9596221959858323
dev_label=MISC_precision_tok: 0.9024583663758922
dev_label=MISC_recall_tok: 0.8974763406940063
dev_label=MISC_f-score_tok: 0.8999604586793198
dev_label=ORG_precision_tok: 0.9523321373654536
dev_label=ORG_recall_tok: 0.8881453154875717
dev_label=ORG_f-score_tok: 0.9191194657432601
dev_label=PER_precision_tok: 0.9720389569588439
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9772583701831965
dev_precision_macro_tok: 0.9544038342091732
dev_recall_macro_tok: 0.9472417400211104
dev_f-score_macro_tok: 0.9505681570071458
dev_precision_micro_tok: 0.9886881351972275
dev_recall_micro_tok: 0.9886881351972275
dev_f-score_micro_tok: 0.9886881351972275
dev_time: 14.761462211608887
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9767    0.9752    0.9760       645
           1     0.9939    0.9942    0.9941      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9853    0.9847    0.9850      3250
weighted avg     0.9905    0.9905    0.9905      3250

F1-macro sent:  0.9850006974861765
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9977    0.9969     42759
         LOC     0.9491    0.9704    0.9596      2094
        MISC     0.9025    0.8975    0.9000      1268
         ORG     0.9523    0.8881    0.9191      2092
         PER     0.9720    0.9825    0.9773      3149

   micro avg     0.9887    0.9887    0.9887     51362
   macro avg     0.9544    0.9472    0.9506     51362
weighted avg     0.9886    0.9887    0.9886     51362

F1-macro tok:  0.9505681570071458
F1-micro tok:  0.9886881351972275
**************************************************
Best epoch: 14
**************************************************

test0_cost_sum: 85732.0962524414
test0_cost_avg: 26.37910653921274
test0_count_sent: 3250.0
test0_total_correct_sent: 3224.0
test0_accuracy_sent: 0.992
test0_count_tok: 51362.0
test0_total_correct_tok: 50760.0
test0_accuracy_tok: 0.9882792726139947
test0_label=0_precision_sent: 0.982839313572543
test0_label=0_recall_sent: 0.9767441860465116
test0_label=0_f-score_sent: 0.979782270606532
test0_label=1_precision_sent: 0.9942506707550786
test0_label=1_recall_sent: 0.9957773512476008
test0_label=1_f-score_sent: 0.9950134253931722
test0_precision_macro_sent: 0.9885449921638108
test0_recall_macro_sent: 0.9862607686470561
test0_f-score_macro_sent: 0.9873978479998521
test0_precision_micro_sent: 0.992
test0_recall_micro_sent: 0.992
test0_f-score_micro_sent: 0.992
test0_label=O_precision_tok: 0.9959826225066567
test0_label=O_recall_tok: 0.9972637339507472
test0_label=O_f-score_tok: 0.996622766526825
test0_label=LOC_precision_tok: 0.9466042154566745
test0_label=LOC_recall_tok: 0.9651384909264565
test0_label=LOC_f-score_tok: 0.9557815086308821
test0_label=MISC_precision_tok: 0.9161727349703641
test0_label=MISC_recall_tok: 0.8533123028391167
test0_label=MISC_f-score_tok: 0.8836259697835852
test0_label=ORG_precision_tok: 0.9278499278499278
test0_label=ORG_recall_tok: 0.9220841300191205
test0_label=ORG_f-score_tok: 0.92495804363462
test0_label=PER_precision_tok: 0.9787503964478275
test0_label=PER_recall_tok: 0.9799936487773896
test0_label=PER_f-score_tok: 0.9793716280545858
test0_precision_macro_tok: 0.9530719794462901
test0_recall_macro_tok: 0.943558461302566
test0_f-score_macro_tok: 0.9480719833260997
test0_precision_micro_tok: 0.9882792726139947
test0_recall_micro_tok: 0.9882792726139947
test0_f-score_micro_tok: 0.9882792726139947
test0_time: 11.063440322875977
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9828    0.9767    0.9798       645
           1     0.9943    0.9958    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9885    0.9863    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9873978479998521
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9973    0.9966     42759
         LOC     0.9466    0.9651    0.9558      2094
        MISC     0.9162    0.8533    0.8836      1268
         ORG     0.9278    0.9221    0.9250      2092
         PER     0.9788    0.9800    0.9794      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9531    0.9436    0.9481     51362
weighted avg     0.9882    0.9883    0.9882     51362

F1-macro tok:  0.9480719833260997
F1-micro tok:  0.9882792726139947
**************************************************
test1_cost_sum: 75332.78750610352
test1_cost_avg: 21.816619607907185
test1_count_sent: 3453.0
test1_total_correct_sent: 3349.0
test1_accuracy_sent: 0.9698812626701419
test1_count_tok: 46435.0
test1_total_correct_tok: 45411.0
test1_accuracy_tok: 0.9779476687843222
test1_label=0_precision_sent: 0.9568567026194145
test1_label=0_recall_sent: 0.890961262553802
test1_label=0_f-score_sent: 0.9227340267459139
test1_label=1_precision_sent: 0.9728958630527818
test1_label=1_recall_sent: 0.9898403483309144
test1_label=1_f-score_sent: 0.981294964028777
test1_precision_macro_sent: 0.9648762828360982
test1_recall_macro_sent: 0.9404008054423583
test1_f-score_macro_sent: 0.9520144953873455
test1_precision_micro_sent: 0.9698812626701419
test1_recall_micro_sent: 0.9698812626701419
test1_f-score_micro_sent: 0.9698812626701419
test1_label=O_precision_tok: 0.9945820028267811
test1_label=O_recall_tok: 0.991545547060512
test1_label=O_f-score_tok: 0.9930614538279606
test1_label=LOC_precision_tok: 0.898041185334003
test1_label=LOC_recall_tok: 0.9288311688311688
test1_label=LOC_f-score_tok: 0.91317671092952
test1_label=MISC_precision_tok: 0.7745098039215687
test1_label=MISC_recall_tok: 0.7745098039215687
test1_label=MISC_f-score_tok: 0.7745098039215687
test1_label=ORG_precision_tok: 0.8660714285714286
test1_label=ORG_recall_tok: 0.8938301282051282
test1_label=ORG_f-score_tok: 0.8797318611987383
test1_label=PER_precision_tok: 0.9774052478134111
test1_label=PER_recall_tok: 0.9671835557158313
test1_label=PER_f-score_tok: 0.9722675367047309
test1_precision_macro_tok: 0.9021219336934385
test1_recall_macro_tok: 0.9111800407468417
test1_f-score_macro_tok: 0.9065494733165036
test1_precision_micro_tok: 0.9779476687843222
test1_recall_micro_tok: 0.9779476687843222
test1_f-score_micro_tok: 0.9779476687843222
test1_time: 6.464186429977417
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9569    0.8910    0.9227       697
           1     0.9729    0.9898    0.9813      2756

   micro avg     0.9699    0.9699    0.9699      3453
   macro avg     0.9649    0.9404    0.9520      3453
weighted avg     0.9697    0.9699    0.9695      3453

F1-macro sent:  0.9520144953873455
F1-micro sent:  0.9698812626701419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9915    0.9931     38323
         LOC     0.8980    0.9288    0.9132      1925
        MISC     0.7745    0.7745    0.7745       918
         ORG     0.8661    0.8938    0.8797      2496
         PER     0.9774    0.9672    0.9723      2773

   micro avg     0.9779    0.9779    0.9779     46435
   macro avg     0.9021    0.9112    0.9065     46435
weighted avg     0.9783    0.9779    0.9781     46435

F1-macro tok:  0.9065494733165036
F1-micro tok:  0.9779476687843222
**************************************************
