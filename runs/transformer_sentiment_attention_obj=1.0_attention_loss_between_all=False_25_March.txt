to_write_filename: runs/transformer_sentiment_attention_obj=1.0_attention_loss_between_all=False_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 1.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'O': 0, 'N': 1}
{'P': 2, 'O': 0, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 429384.8184814453
train_cost_avg: 50.2557137735774
train_count_sent: 8544.0
train_total_correct_sent: 4209.0
train_accuracy_sent: 0.492626404494382
train_count_tok: 163566.0
train_total_correct_tok: 126264.0
train_accuracy_tok: 0.7719452697993471
train_label=O_precision_sent: 0.19519519519519518
train_label=O_recall_sent: 0.04002463054187192
train_label=O_f-score_sent: 0.06642820643842616
train_label=N_precision_sent: 0.48711622807017546
train_label=N_recall_sent: 0.536858006042296
train_label=N_f-score_sent: 0.5107789594711124
train_label=P_precision_sent: 0.5187376725838264
train_label=P_recall_sent: 0.6556786703601108
train_label=P_f-score_sent: 0.5792242750520005
train_precision_macro_sent: 0.400349698616399
train_recall_macro_sent: 0.4108537689814263
train_f-score_macro_sent: 0.38547714698717966
train_precision_micro_sent: 0.492626404494382
train_recall_micro_sent: 0.492626404494382
train_f-score_micro_sent: 0.492626404494382
train_label=O_precision_tok: 0.8017126091703056
train_label=O_recall_tok: 0.9449283054677636
train_label=O_f-score_tok: 0.8674489769551913
train_label=N_precision_tok: 0.507752545027408
train_label=N_recall_tok: 0.22827770736515984
train_label=N_f-score_tok: 0.31495604021955603
train_label=P_precision_tok: 0.5200075322474343
train_label=P_recall_tok: 0.22076987648399088
train_label=P_f-score_tok: 0.3099500533138784
train_precision_macro_tok: 0.6098242288150493
train_recall_macro_tok: 0.4646586297723048
train_f-score_macro_tok: 0.4974516901628752
train_precision_micro_tok: 0.7719452697993471
train_recall_micro_tok: 0.7719452697993471
train_f-score_micro_tok: 0.7719452697993471
train_time: 98.02878618240356
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1952    0.0400    0.0664      1624
           N     0.4871    0.5369    0.5108      3310
           P     0.5187    0.6557    0.5792      3610

   micro avg     0.4926    0.4926    0.4926      8544
   macro avg     0.4003    0.4109    0.3855      8544
weighted avg     0.4450    0.4926    0.4552      8544

F1-macro sent:  0.38547714698717966
F1-micro sent:  0.492626404494382
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8017    0.9449    0.8674    124347
           N     0.5078    0.2283    0.3150     14202
           P     0.5200    0.2208    0.3100     25017

   micro avg     0.7719    0.7719    0.7719    163566
   macro avg     0.6098    0.4647    0.4975    163566
weighted avg     0.7331    0.7719    0.7342    163566

F1-macro tok:  0.4974516901628752
F1-micro tok:  0.7719452697993471
**************************************************
dev_cost_sum: 50725.38317871094
dev_cost_avg: 46.07210097975562
dev_count_sent: 1101.0
dev_total_correct_sent: 545.0
dev_accuracy_sent: 0.4950045413260672
dev_count_tok: 21274.0
dev_total_correct_tok: 17511.0
dev_accuracy_tok: 0.8231174203252797
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7569444444444444
dev_label=N_recall_sent: 0.2546728971962617
dev_label=N_f-score_sent: 0.38111888111888115
dev_label=P_precision_sent: 0.4555903866248694
dev_label=P_recall_sent: 0.9819819819819819
dev_label=P_f-score_sent: 0.622412562455389
dev_precision_macro_sent: 0.4041782770231046
dev_recall_macro_sent: 0.41221829305941454
dev_f-score_macro_sent: 0.3345104811914234
dev_precision_micro_sent: 0.4950045413260672
dev_recall_micro_sent: 0.4950045413260672
dev_f-score_micro_sent: 0.4950045413260672
dev_label=O_precision_tok: 0.8391301995997187
dev_label=O_recall_tok: 0.9572971305152731
dev_label=O_f-score_tok: 0.8943272224143894
dev_label=N_precision_tok: 0.6664
dev_label=N_recall_tok: 0.44857296715131934
dev_label=N_f-score_tok: 0.5362085613131639
dev_label=P_precision_tok: 0.7579700715679896
dev_label=P_recall_tok: 0.36270236612702367
dev_label=P_f-score_tok: 0.4906296062328911
dev_precision_macro_tok: 0.7545000903892362
dev_recall_macro_tok: 0.589524154597872
dev_f-score_macro_tok: 0.6403884633201482
dev_precision_micro_tok: 0.8231174203252797
dev_recall_micro_tok: 0.8231174203252797
dev_f-score_micro_tok: 0.8231174203252796
dev_time: 5.5333921909332275
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7569    0.2547    0.3811       428
           P     0.4556    0.9820    0.6224       444

   micro avg     0.4950    0.4950    0.4950      1101
   macro avg     0.4042    0.4122    0.3345      1101
weighted avg     0.4780    0.4950    0.3992      1101

F1-macro sent:  0.3345104811914234
F1-micro sent:  0.4950045413260672
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8391    0.9573    0.8943     16205
           N     0.6664    0.4486    0.5362      1857
           P     0.7580    0.3627    0.4906      3212

   micro avg     0.8231    0.8231    0.8231     21274
   macro avg     0.7545    0.5895    0.6404     21274
weighted avg     0.8118    0.8231    0.8021     21274

F1-macro tok:  0.6403884633201482
F1-micro tok:  0.8231174203252796
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378945.17126464844
train_cost_avg: 44.35219701131185
train_count_sent: 8544.0
train_total_correct_sent: 4906.0
train_accuracy_sent: 0.5742041198501873
train_count_tok: 163566.0
train_total_correct_tok: 132559.0
train_accuracy_tok: 0.8104312632209628
train_label=O_precision_sent: 0.23529411764705882
train_label=O_recall_sent: 0.014778325123152709
train_label=O_f-score_sent: 0.027809965237543453
train_label=N_precision_sent: 0.559077079107505
train_label=N_recall_sent: 0.6661631419939577
train_label=N_f-score_sent: 0.6079404466501239
train_label=P_precision_sent: 0.595153401511783
train_label=P_recall_sent: 0.7415512465373961
train_label=P_f-score_sent: 0.6603354711396152
train_precision_macro_sent: 0.4631748660887823
train_recall_macro_sent: 0.47416423788483547
train_f-score_macro_sent: 0.43202862767576083
train_precision_micro_sent: 0.5742041198501873
train_recall_micro_sent: 0.5742041198501873
train_f-score_micro_sent: 0.5742041198501873
train_label=O_precision_tok: 0.8366198585798227
train_label=O_recall_tok: 0.9457968427062977
train_label=O_f-score_tok: 0.8878646841888714
train_label=N_precision_tok: 0.6282608695652174
train_label=N_recall_tok: 0.4069849316997606
train_label=N_f-score_tok: 0.49397487394239803
train_label=P_precision_tok: 0.6650232018561485
train_label=P_recall_tok: 0.3666306911300316
train_label=P_f-score_tok: 0.47267386430982505
train_precision_macro_tok: 0.7099679766670629
train_recall_macro_tok: 0.57313748851203
train_f-score_macro_tok: 0.6181711408136982
train_precision_micro_tok: 0.8104312632209628
train_recall_micro_tok: 0.8104312632209628
train_f-score_micro_tok: 0.8104312632209628
train_time: 96.07293391227722
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2353    0.0148    0.0278      1624
           N     0.5591    0.6662    0.6079      3310
           P     0.5952    0.7416    0.6603      3610

   micro avg     0.5742    0.5742    0.5742      8544
   macro avg     0.4632    0.4742    0.4320      8544
weighted avg     0.5128    0.5742    0.5198      8544

F1-macro sent:  0.43202862767576083
F1-micro sent:  0.5742041198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8366    0.9458    0.8879    124347
           N     0.6283    0.4070    0.4940     14202
           P     0.6650    0.3666    0.4727     25017

   micro avg     0.8104    0.8104    0.8104    163566
   macro avg     0.7100    0.5731    0.6182    163566
weighted avg     0.7923    0.8104    0.7902    163566

F1-macro tok:  0.6181711408136982
F1-micro tok:  0.8104312632209628
**************************************************
dev_cost_sum: 49079.61962890625
dev_cost_avg: 44.577311197916664
dev_count_sent: 1101.0
dev_total_correct_sent: 669.0
dev_accuracy_sent: 0.6076294277929155
dev_count_tok: 21274.0
dev_total_correct_tok: 17764.0
dev_accuracy_tok: 0.8350098712042869
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5709624796084829
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.6724303554274735
dev_label=P_precision_sent: 0.6536885245901639
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.6845493562231759
dev_precision_macro_sent: 0.408217001399549
dev_recall_macro_sent: 0.5120751592714209
dev_f-score_macro_sent: 0.45232657055021647
dev_precision_micro_sent: 0.6076294277929155
dev_recall_micro_sent: 0.6076294277929155
dev_f-score_micro_sent: 0.6076294277929155
dev_label=O_precision_tok: 0.8412418510206263
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.9016867607892552
dev_label=N_precision_tok: 0.7176274018379282
dev_label=N_recall_tok: 0.46257404415724285
dev_label=N_f-score_tok: 0.5625409299279632
dev_label=P_precision_tok: 0.8525311812179017
dev_label=P_recall_tok: 0.3617683686176837
dev_label=P_f-score_tok: 0.5079781420765027
dev_precision_macro_tok: 0.803800144692152
dev_recall_macro_tok: 0.5986108978508214
dev_f-score_macro_tok: 0.6574019442645738
dev_precision_micro_tok: 0.8350098712042869
dev_recall_micro_tok: 0.8350098712042869
dev_f-score_micro_tok: 0.8350098712042869
dev_time: 5.105837345123291
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5710    0.8178    0.6724       428
           P     0.6537    0.7185    0.6845       444

   micro avg     0.6076    0.6076    0.6076      1101
   macro avg     0.4082    0.5121    0.4523      1101
weighted avg     0.4856    0.6076    0.5375      1101

F1-macro sent:  0.45232657055021647
F1-micro sent:  0.6076294277929155
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8412    0.9715    0.9017     16205
           N     0.7176    0.4626    0.5625      1857
           P     0.8525    0.3618    0.5080      3212

   micro avg     0.8350    0.8350    0.8350     21274
   macro avg     0.8038    0.5986    0.6574     21274
weighted avg     0.8322    0.8350    0.8126     21274

F1-macro tok:  0.6574019442645738
F1-micro tok:  0.8350098712042869
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368784.98876953125
train_cost_avg: 43.16303707508558
train_count_sent: 8544.0
train_total_correct_sent: 5034.0
train_accuracy_sent: 0.589185393258427
train_count_tok: 163566.0
train_total_correct_tok: 135464.0
train_accuracy_tok: 0.8281916779770857
train_label=O_precision_sent: 0.2711864406779661
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.019013666072489603
train_label=N_precision_sent: 0.5548037889039242
train_label=N_recall_sent: 0.743202416918429
train_label=N_f-score_sent: 0.6353305785123967
train_label=P_precision_sent: 0.6314490249321155
train_label=P_recall_sent: 0.7085872576177286
train_label=P_f-score_sent: 0.6677979376060568
train_precision_macro_sent: 0.48581308483800195
train_recall_macro_sent: 0.487213963761642
train_f-score_macro_sent: 0.4407140607303144
train_precision_micro_sent: 0.589185393258427
train_recall_micro_sent: 0.589185393258427
train_f-score_micro_sent: 0.589185393258427
train_label=O_precision_tok: 0.8518793737825554
train_label=O_recall_tok: 0.9495926721191504
train_label=O_f-score_tok: 0.8980859988515233
train_label=N_precision_tok: 0.6609392898052692
train_label=N_recall_tok: 0.44690888607238416
train_label=N_f-score_tok: 0.5332493173703003
train_label=P_precision_tok: 0.718947436983
train_label=P_recall_tok: 0.44121997042011435
train_label=P_f-score_tok: 0.5468417141441665
train_precision_macro_tok: 0.7439220335236082
train_recall_macro_tok: 0.6125738428705496
train_f-score_macro_tok: 0.65939234345533
train_precision_micro_tok: 0.8281916779770857
train_recall_micro_tok: 0.8281916779770857
train_f-score_micro_tok: 0.8281916779770857
train_time: 121.64712047576904
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2712    0.0099    0.0190      1624
           N     0.5548    0.7432    0.6353      3310
           P     0.6314    0.7086    0.6678      3610

   micro avg     0.5892    0.5892    0.5892      8544
   macro avg     0.4858    0.4872    0.4407      8544
weighted avg     0.5333    0.5892    0.5319      8544

F1-macro sent:  0.4407140607303144
F1-micro sent:  0.589185393258427
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8519    0.9496    0.8981    124347
           N     0.6609    0.4469    0.5332     14202
           P     0.7189    0.4412    0.5468     25017

   micro avg     0.8282    0.8282    0.8282    163566
   macro avg     0.7439    0.6126    0.6594    163566
weighted avg     0.8150    0.8282    0.8127    163566

F1-macro tok:  0.65939234345533
F1-micro tok:  0.8281916779770857
**************************************************
dev_cost_sum: 48111.315673828125
dev_cost_avg: 43.697834399480584
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18225.0
dev_accuracy_tok: 0.856679514900818
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5972461273666093
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.6878097125867195
dev_label=P_precision_sent: 0.653179190751445
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.70404984423676
dev_precision_macro_sent: 0.4168084393726848
dev_recall_macro_sent: 0.5247537256883051
dev_f-score_macro_sent: 0.4639531856078265
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8728846910665092
dev_label=O_recall_tok: 0.9580993520518358
dev_label=O_f-score_tok: 0.913509060955519
dev_label=N_precision_tok: 0.7445319335083115
dev_label=N_recall_tok: 0.45826602046311254
dev_label=N_f-score_tok: 0.5673333333333334
dev_label=P_precision_tok: 0.78839590443686
dev_label=P_recall_tok: 0.5753424657534246
dev_label=P_f-score_tok: 0.6652267818574513
dev_precision_macro_tok: 0.8019375096705602
dev_recall_macro_tok: 0.6639026127561243
dev_f-score_macro_tok: 0.7153563920487679
dev_precision_micro_tok: 0.856679514900818
dev_recall_micro_tok: 0.856679514900818
dev_f-score_micro_tok: 0.8566795149008181
dev_time: 8.40926742553711
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5972    0.8107    0.6878       428
           P     0.6532    0.7635    0.7040       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4168    0.5248    0.4640      1101
weighted avg     0.4956    0.6231    0.5513      1101

F1-macro sent:  0.4639531856078265
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8729    0.9581    0.9135     16205
           N     0.7445    0.4583    0.5673      1857
           P     0.7884    0.5753    0.6652      3212

   micro avg     0.8567    0.8567    0.8567     21274
   macro avg     0.8019    0.6639    0.7154     21274
weighted avg     0.8489    0.8567    0.8458     21274

F1-macro tok:  0.7153563920487679
F1-micro tok:  0.8566795149008181
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361974.07263183594
train_cost_avg: 42.365879287433984
train_count_sent: 8544.0
train_total_correct_sent: 5128.0
train_accuracy_sent: 0.600187265917603
train_count_tok: 163566.0
train_total_correct_tok: 137701.0
train_accuracy_tok: 0.8418681144003033
train_label=O_precision_sent: 0.24719101123595505
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.02568593111500292
train_label=N_precision_sent: 0.576017130620985
train_label=N_recall_sent: 0.7314199395770393
train_label=N_f-score_sent: 0.6444828963130573
train_label=P_precision_sent: 0.6314675446848542
train_label=P_recall_sent: 0.7437673130193906
train_label=P_f-score_sent: 0.6830323073009412
train_precision_macro_sent: 0.48489189551393147
train_recall_macro_sent: 0.4962446835419955
train_f-score_macro_sent: 0.4510670449096672
train_precision_micro_sent: 0.600187265917603
train_recall_micro_sent: 0.600187265917603
train_f-score_micro_sent: 0.600187265917603
train_label=O_precision_tok: 0.8633630021650228
train_label=O_recall_tok: 0.9524717122246616
train_label=O_f-score_tok: 0.9057309351197577
train_label=N_precision_tok: 0.6814769730168391
train_label=N_recall_tok: 0.4730319673285453
train_label=N_f-score_tok: 0.5584372402327515
train_label=P_precision_tok: 0.759121437647486
train_label=P_recall_tok: 0.5014989806931287
train_label=P_f-score_tok: 0.6039861351819757
train_precision_macro_tok: 0.7679871376097825
train_recall_macro_tok: 0.6423342200821119
train_f-score_macro_tok: 0.6893847701781617
train_precision_micro_tok: 0.8418681144003033
train_recall_micro_tok: 0.8418681144003033
train_f-score_micro_tok: 0.8418681144003033
train_time: 147.12863540649414
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2472    0.0135    0.0257      1624
           N     0.5760    0.7314    0.6445      3310
           P     0.6315    0.7438    0.6830      3610

   micro avg     0.6002    0.6002    0.6002      8544
   macro avg     0.4849    0.4962    0.4511      8544
weighted avg     0.5369    0.6002    0.5432      8544

F1-macro sent:  0.4510670449096672
F1-micro sent:  0.600187265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8634    0.9525    0.9057    124347
           N     0.6815    0.4730    0.5584     14202
           P     0.7591    0.5015    0.6040     25017

   micro avg     0.8419    0.8419    0.8419    163566
   macro avg     0.7680    0.6423    0.6894    163566
weighted avg     0.8316    0.8419    0.8294    163566

F1-macro tok:  0.6893847701781617
F1-micro tok:  0.8418681144003033
**************************************************
dev_cost_sum: 47468.70056152344
dev_cost_avg: 43.11416944734191
dev_count_sent: 1101.0
dev_total_correct_sent: 636.0
dev_accuracy_sent: 0.5776566757493188
dev_count_tok: 21274.0
dev_total_correct_tok: 18383.0
dev_accuracy_tok: 0.86410642098336
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7152317880794702
dev_label=N_recall_sent: 0.5046728971962616
dev_label=N_f-score_sent: 0.5917808219178082
dev_label=P_precision_sent: 0.5256570713391739
dev_label=P_recall_sent: 0.9459459459459459
dev_label=P_f-score_sent: 0.6757843925985518
dev_precision_macro_sent: 0.41362961980621477
dev_recall_macro_sent: 0.48353961438073584
dev_f-score_macro_sent: 0.42252173817212
dev_precision_micro_sent: 0.5776566757493188
dev_recall_micro_sent: 0.5776566757493188
dev_f-score_micro_sent: 0.5776566757493188
dev_label=O_precision_tok: 0.8709945210028225
dev_label=O_recall_tok: 0.9711817340327059
dev_label=O_f-score_tok: 0.9183637742895489
dev_label=N_precision_tok: 0.7947976878612717
dev_label=N_recall_tok: 0.44426494345718903
dev_label=N_f-score_tok: 0.5699481865284974
dev_label=P_precision_tok: 0.8398707891093677
dev_label=P_recall_tok: 0.5666251556662516
dev_label=P_f-score_tok: 0.676705707380554
dev_precision_macro_tok: 0.8352209993244873
dev_recall_macro_tok: 0.6606906110520488
dev_f-score_macro_tok: 0.7216725560662001
dev_precision_micro_tok: 0.86410642098336
dev_recall_micro_tok: 0.86410642098336
dev_f-score_micro_tok: 0.86410642098336
dev_time: 8.344889879226685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7152    0.5047    0.5918       428
           P     0.5257    0.9459    0.6758       444

   micro avg     0.5777    0.5777    0.5777      1101
   macro avg     0.4136    0.4835    0.4225      1101
weighted avg     0.4900    0.5777    0.5026      1101

F1-macro sent:  0.42252173817212
F1-micro sent:  0.5776566757493188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8710    0.9712    0.9184     16205
           N     0.7948    0.4443    0.5699      1857
           P     0.8399    0.5666    0.6767      3212

   micro avg     0.8641    0.8641    0.8641     21274
   macro avg     0.8352    0.6607    0.7217     21274
weighted avg     0.8596    0.8641    0.8515     21274

F1-macro tok:  0.7216725560662001
F1-micro tok:  0.86410642098336
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 356528.4411621094
train_cost_avg: 41.72851605361767
train_count_sent: 8544.0
train_total_correct_sent: 5236.0
train_accuracy_sent: 0.6128277153558053
train_count_tok: 163566.0
train_total_correct_tok: 139162.0
train_accuracy_tok: 0.850800288568529
train_label=O_precision_sent: 0.3939393939393939
train_label=O_recall_sent: 0.01600985221674877
train_label=O_f-score_sent: 0.03076923076923077
train_label=N_precision_sent: 0.5839829907866761
train_label=N_recall_sent: 0.7468277945619335
train_label=N_f-score_sent: 0.6554421317778072
train_label=P_precision_sent: 0.6449941107184923
train_label=P_recall_sent: 0.7584487534626039
train_label=P_f-score_sent: 0.6971355824315723
train_precision_macro_sent: 0.5409721651481875
train_recall_macro_sent: 0.5070954667470954
train_f-score_macro_sent: 0.4611156483262034
train_precision_micro_sent: 0.6128277153558053
train_recall_micro_sent: 0.6128277153558053
train_f-score_micro_sent: 0.6128277153558053
train_label=O_precision_tok: 0.8698160388394947
train_label=O_recall_tok: 0.9567018102567815
train_label=O_f-score_tok: 0.9111923864963714
train_label=N_precision_tok: 0.7015738498789347
train_label=N_recall_tok: 0.4896493451626531
train_label=N_f-score_tok: 0.5767603881562579
train_label=P_precision_tok: 0.7843775909037072
train_label=P_recall_tok: 0.5294399808130471
train_label=P_f-score_tok: 0.6321743073288308
train_precision_macro_tok: 0.7852558265407122
train_recall_macro_tok: 0.6585970454108273
train_f-score_macro_tok: 0.7067090273271533
train_precision_micro_tok: 0.850800288568529
train_recall_micro_tok: 0.850800288568529
train_f-score_micro_tok: 0.850800288568529
train_time: 146.40787506103516
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3939    0.0160    0.0308      1624
           N     0.5840    0.7468    0.6554      3310
           P     0.6450    0.7584    0.6971      3610

   micro avg     0.6128    0.6128    0.6128      8544
   macro avg     0.5410    0.5071    0.4611      8544
weighted avg     0.5736    0.6128    0.5543      8544

F1-macro sent:  0.4611156483262034
F1-micro sent:  0.6128277153558053
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8698    0.9567    0.9112    124347
           N     0.7016    0.4896    0.5768     14202
           P     0.7844    0.5294    0.6322     25017

   micro avg     0.8508    0.8508    0.8508    163566
   macro avg     0.7853    0.6586    0.7067    163566
weighted avg     0.8421    0.8508    0.8395    163566

F1-macro tok:  0.7067090273271533
F1-micro tok:  0.850800288568529
**************************************************
dev_cost_sum: 46795.26190185547
dev_cost_avg: 42.50250853937826
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18515.0
dev_accuracy_tok: 0.8703111779637116
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.6156716417910447
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.6846473029045642
dev_label=P_precision_sent: 0.6323268206039077
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7070506454816287
dev_precision_macro_sent: 0.5826661541316508
dev_recall_macro_sent: 0.5257322171373512
dev_f-score_macro_sent: 0.4667853190147338
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8850914045645509
dev_label=O_recall_tok: 0.9620487503856834
dev_label=O_f-score_tok: 0.9219669416600136
dev_label=N_precision_tok: 0.7197452229299363
dev_label=N_recall_tok: 0.5476575121163166
dev_label=N_f-score_tok: 0.6220183486238532
dev_label=P_precision_tok: 0.8491321762349799
dev_label=P_recall_tok: 0.5940224159402242
dev_label=P_f-score_tok: 0.6990291262135923
dev_precision_macro_tok: 0.8179896012431557
dev_recall_macro_tok: 0.7012428928140748
dev_f-score_macro_tok: 0.7476714721658198
dev_precision_micro_tok: 0.8703111779637116
dev_recall_micro_tok: 0.8703111779637116
dev_f-score_micro_tok: 0.8703111779637116
dev_time: 8.382436990737915
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6157    0.7710    0.6846       428
           P     0.6323    0.8018    0.7071       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.5827    0.5257    0.4668      1101
weighted avg     0.5983    0.6240    0.5531      1101

F1-macro sent:  0.4667853190147338
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8851    0.9620    0.9220     16205
           N     0.7197    0.5477    0.6220      1857
           P     0.8491    0.5940    0.6990      3212

   micro avg     0.8703    0.8703    0.8703     21274
   macro avg     0.8180    0.7012    0.7477     21274
weighted avg     0.8652    0.8703    0.8621     21274

F1-macro tok:  0.7476714721658198
F1-micro tok:  0.8703111779637116
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351722.3771972656
train_cost_avg: 41.166008567095695
train_count_sent: 8544.0
train_total_correct_sent: 5342.0
train_accuracy_sent: 0.6252340823970037
train_count_tok: 163566.0
train_total_correct_tok: 140235.0
train_accuracy_tok: 0.8573603316092586
train_label=O_precision_sent: 0.37037037037037035
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.04618937644341801
train_label=N_precision_sent: 0.5949487729330474
train_label=N_recall_sent: 0.7543806646525679
train_label=N_f-score_sent: 0.6652457706140935
train_label=P_precision_sent: 0.6617126680820948
train_label=P_recall_sent: 0.7770083102493075
train_label=P_f-score_sent: 0.7147407313033507
train_precision_macro_sent: 0.5423439371285043
train_recall_macro_sent: 0.5186731722579322
train_f-score_macro_sent: 0.4753919594536207
train_precision_micro_sent: 0.6252340823970037
train_recall_micro_sent: 0.6252340823970037
train_f-score_micro_sent: 0.6252340823970037
train_label=O_precision_tok: 0.8754379135850525
train_label=O_recall_tok: 0.9585836409402719
train_label=O_f-score_tok: 0.9151260633234038
train_label=N_precision_tok: 0.7085747961889794
train_label=N_recall_tok: 0.5079566258273482
train_label=N_f-score_tok: 0.5917237419513596
train_label=P_precision_tok: 0.8024146737868586
train_label=P_recall_tok: 0.5525842427149539
train_label=P_f-score_tok: 0.6544679843768494
train_precision_macro_tok: 0.7954757945202968
train_recall_macro_tok: 0.673041503160858
train_f-score_macro_tok: 0.7204392632172043
train_precision_micro_tok: 0.8573603316092586
train_recall_micro_tok: 0.8573603316092586
train_f-score_micro_tok: 0.8573603316092586
train_time: 114.87653851509094
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3704    0.0246    0.0462      1624
           N     0.5949    0.7544    0.6652      3310
           P     0.6617    0.7770    0.7147      3610

   micro avg     0.6252    0.6252    0.6252      8544
   macro avg     0.5423    0.5187    0.4754      8544
weighted avg     0.5805    0.6252    0.5685      8544

F1-macro sent:  0.4753919594536207
F1-micro sent:  0.6252340823970037
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8754    0.9586    0.9151    124347
           N     0.7086    0.5080    0.5917     14202
           P     0.8024    0.5526    0.6545     25017

   micro avg     0.8574    0.8574    0.8574    163566
   macro avg     0.7955    0.6730    0.7204    163566
weighted avg     0.8498    0.8574    0.8472    163566

F1-macro tok:  0.7204392632172043
F1-micro tok:  0.8573603316092586
**************************************************
dev_cost_sum: 46366.20556640625
dev_cost_avg: 42.1128115952827
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18596.0
dev_accuracy_tok: 0.8741186424743819
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6075085324232082
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7021696252465485
dev_label=P_precision_sent: 0.6737864077669903
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7236704900938478
dev_precision_macro_sent: 0.4270983133967328
dev_recall_macro_sent: 0.5377690774887037
dev_f-score_macro_sent: 0.4752800384467988
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8784444444444445
dev_label=O_recall_tok: 0.9757482258562172
dev_label=O_f-score_tok: 0.9245431954392633
dev_label=N_precision_tok: 0.8027444253859348
dev_label=N_recall_tok: 0.5040387722132472
dev_label=N_f-score_tok: 0.6192523982798545
dev_label=P_precision_tok: 0.8766603415559773
dev_label=P_recall_tok: 0.5753424657534246
dev_label=P_f-score_tok: 0.6947368421052632
dev_precision_macro_tok: 0.8526164037954521
dev_recall_macro_tok: 0.6850431546076297
dev_f-score_macro_tok: 0.7461774786081269
dev_precision_micro_tok: 0.8741186424743819
dev_recall_micro_tok: 0.8741186424743819
dev_f-score_micro_tok: 0.8741186424743819
dev_time: 5.068451881408691
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6075    0.8318    0.7022       428
           P     0.6738    0.7815    0.7237       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.4271    0.5378    0.4753      1101
weighted avg     0.5079    0.6385    0.5648      1101

F1-macro sent:  0.4752800384467988
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8784    0.9757    0.9245     16205
           N     0.8027    0.5040    0.6193      1857
           P     0.8767    0.5753    0.6947      3212

   micro avg     0.8741    0.8741    0.8741     21274
   macro avg     0.8526    0.6850    0.7462     21274
weighted avg     0.8716    0.8741    0.8632     21274

F1-macro tok:  0.7461774786081269
F1-micro tok:  0.8741186424743819
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347799.69134521484
train_cost_avg: 40.70689271362533
train_count_sent: 8544.0
train_total_correct_sent: 5305.0
train_accuracy_sent: 0.6209035580524345
train_count_tok: 163566.0
train_total_correct_tok: 141080.0
train_accuracy_tok: 0.8625264419255836
train_label=O_precision_sent: 0.3979591836734694
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.045296167247386755
train_label=N_precision_sent: 0.5894613583138173
train_label=N_recall_sent: 0.7604229607250755
train_label=N_f-score_sent: 0.6641160949868072
train_label=P_precision_sent: 0.6582854406130269
train_label=P_recall_sent: 0.7614958448753463
train_label=P_f-score_sent: 0.7061392242486515
train_precision_macro_sent: 0.5485686608667711
train_recall_macro_sent: 0.5153111946418484
train_f-score_macro_sent: 0.47185049549428176
train_precision_micro_sent: 0.6209035580524345
train_recall_micro_sent: 0.6209035580524345
train_f-score_micro_sent: 0.6209035580524345
train_label=O_precision_tok: 0.8785567313345091
train_label=O_recall_tok: 0.9614546390343153
train_label=O_f-score_tok: 0.9181382882727213
train_label=N_precision_tok: 0.7222546161321671
train_label=N_recall_tok: 0.5233065765385158
train_label=N_f-score_tok: 0.6068920463824923
train_label=P_precision_tok: 0.819609211444522
train_label=P_recall_tok: 0.5633769037054803
train_label=P_f-score_tok: 0.6677563783668539
train_precision_macro_tok: 0.8068068529703994
train_recall_macro_tok: 0.6827127064261038
train_f-score_macro_tok: 0.730928904340689
train_precision_micro_tok: 0.8625264419255836
train_recall_micro_tok: 0.8625264419255836
train_f-score_micro_tok: 0.8625264419255836
train_time: 95.16672229766846
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3980    0.0240    0.0453      1624
           N     0.5895    0.7604    0.6641      3310
           P     0.6583    0.7615    0.7061      3610

   micro avg     0.6209    0.6209    0.6209      8544
   macro avg     0.5486    0.5153    0.4719      8544
weighted avg     0.5821    0.6209    0.5642      8544

F1-macro sent:  0.47185049549428176
F1-micro sent:  0.6209035580524345
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8786    0.9615    0.9181    124347
           N     0.7223    0.5233    0.6069     14202
           P     0.8196    0.5634    0.6678     25017

   micro avg     0.8625    0.8625    0.8625    163566
   macro avg     0.8068    0.6827    0.7309    163566
weighted avg     0.8560    0.8625    0.8528    163566

F1-macro tok:  0.730928904340689
F1-micro tok:  0.8625264419255836
**************************************************
dev_cost_sum: 46001.77648925781
dev_cost_avg: 41.78181334174188
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18682.0
dev_accuracy_tok: 0.8781611356585504
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6073298429319371
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.6953046953046953
dev_label=P_precision_sent: 0.6641221374045801
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.71900826446281
dev_precision_macro_sent: 0.6738173267788391
dev_recall_macro_sent: 0.5366561108715131
dev_f-score_macro_sent: 0.48002134424295956
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8856982298398427
dev_label=O_recall_tok: 0.9726010490589324
dev_label=O_f-score_tok: 0.9271176470588235
dev_label=N_precision_tok: 0.8101811906816221
dev_label=N_recall_tok: 0.505654281098546
dev_label=N_f-score_tok: 0.6226790450928382
dev_label=P_precision_tok: 0.8543103448275862
dev_label=P_recall_tok: 0.6170610211706102
dev_label=P_f-score_tok: 0.7165582067968186
dev_precision_macro_tok: 0.8500632551163504
dev_recall_macro_tok: 0.6984387837760296
dev_f-score_macro_tok: 0.7554516329828268
dev_precision_micro_tok: 0.8781611356585504
dev_recall_micro_tok: 0.8781611356585504
dev_f-score_micro_tok: 0.8781611356585504
dev_time: 5.090594530105591
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6073    0.8131    0.6953       428
           P     0.6641    0.7838    0.7190       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.6738    0.5367    0.4800      1101
weighted avg     0.6599    0.6349    0.5656      1101

F1-macro sent:  0.48002134424295956
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8857    0.9726    0.9271     16205
           N     0.8102    0.5057    0.6227      1857
           P     0.8543    0.6171    0.7166      3212

   micro avg     0.8782    0.8782    0.8782     21274
   macro avg     0.8501    0.6984    0.7555     21274
weighted avg     0.8744    0.8782    0.8688     21274

F1-macro tok:  0.7554516329828268
F1-micro tok:  0.8781611356585504
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 344124.38513183594
train_cost_avg: 40.27673046955009
train_count_sent: 8544.0
train_total_correct_sent: 5449.0
train_accuracy_sent: 0.6377574906367042
train_count_tok: 163566.0
train_total_correct_tok: 141600.0
train_accuracy_tok: 0.8657055867356297
train_label=O_precision_sent: 0.43846153846153846
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.06499429874572406
train_label=N_precision_sent: 0.6000456829602558
train_label=N_recall_sent: 0.793655589123867
train_label=N_f-score_sent: 0.6834027055150884
train_label=P_precision_sent: 0.6850842418235877
train_label=P_recall_sent: 0.7659279778393352
train_label=P_f-score_sent: 0.7232539890138635
train_precision_macro_sent: 0.5745304877484606
train_recall_macro_sent: 0.5315606963768966
train_f-score_macro_sent: 0.49055033109155866
train_precision_micro_sent: 0.6377574906367042
train_recall_micro_sent: 0.6377574906367042
train_f-score_micro_sent: 0.6377574906367042
train_label=O_precision_tok: 0.8809098198456661
train_label=O_recall_tok: 0.9630308732820253
train_label=O_f-score_tok: 0.9201416902945222
train_label=N_precision_tok: 0.7284317484662577
train_label=N_recall_tok: 0.5350654837346852
train_label=N_f-score_tok: 0.61695217991394
train_label=P_precision_tok: 0.8287874382087816
train_label=P_recall_tok: 0.5696526362073789
train_label=P_f-score_tok: 0.6752108405192835
train_precision_macro_tok: 0.8127096688402352
train_recall_macro_tok: 0.6892496644080298
train_f-score_macro_tok: 0.7374349035759152
train_precision_micro_tok: 0.8657055867356297
train_recall_micro_tok: 0.8657055867356297
train_f-score_micro_tok: 0.8657055867356297
train_time: 94.91586446762085
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4385    0.0351    0.0650      1624
           N     0.6000    0.7937    0.6834      3310
           P     0.6851    0.7659    0.7233      3610

   micro avg     0.6378    0.6378    0.6378      8544
   macro avg     0.5745    0.5316    0.4906      8544
weighted avg     0.6053    0.6378    0.5827      8544

F1-macro sent:  0.49055033109155866
F1-micro sent:  0.6377574906367042
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8809    0.9630    0.9201    124347
           N     0.7284    0.5351    0.6170     14202
           P     0.8288    0.5697    0.6752     25017

   micro avg     0.8657    0.8657    0.8657    163566
   macro avg     0.8127    0.6892    0.7374    163566
weighted avg     0.8597    0.8657    0.8564    163566

F1-macro tok:  0.7374349035759152
F1-micro tok:  0.8657055867356297
**************************************************
dev_cost_sum: 45506.66613769531
dev_cost_avg: 41.33212183260246
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18762.0
dev_accuracy_tok: 0.881921594434521
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6068376068376068
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.700888450148075
dev_label=P_precision_sent: 0.6640471512770137
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.7093389296956978
dev_precision_macro_sent: 0.6617234908001116
dev_recall_macro_sent: 0.537511524911027
dev_f-score_macro_sent: 0.4842000870665683
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8891142663962136
dev_label=O_recall_tok: 0.9737735266892934
dev_label=O_f-score_tok: 0.9295202191264393
dev_label=N_precision_tok: 0.7596785975164354
dev_label=N_recall_tok: 0.5600430802369413
dev_label=N_f-score_tok: 0.6447613143211407
dev_label=P_precision_tok: 0.9003245248029671
dev_label=P_recall_tok: 0.6046077210460772
dev_label=P_f-score_tok: 0.7234121810392996
dev_precision_macro_tok: 0.8497057962385387
dev_recall_macro_tok: 0.712808109324104
dev_f-score_macro_tok: 0.7658979048289599
dev_precision_micro_tok: 0.881921594434521
dev_recall_micro_tok: 0.881921594434521
dev_f-score_micro_tok: 0.881921594434521
dev_time: 5.115453243255615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6068    0.8294    0.7009       428
           P     0.6640    0.7613    0.7093       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.6617    0.5375    0.4842      1101
weighted avg     0.6523    0.6340    0.5673      1101

F1-macro sent:  0.4842000870665683
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8891    0.9738    0.9295     16205
           N     0.7597    0.5600    0.6448      1857
           P     0.9003    0.6046    0.7234      3212

   micro avg     0.8819    0.8819    0.8819     21274
   macro avg     0.8497    0.7128    0.7659     21274
weighted avg     0.8795    0.8819    0.8735     21274

F1-macro tok:  0.7658979048289599
F1-micro tok:  0.881921594434521
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 340522.8919067383
train_cost_avg: 39.85520738608828
train_count_sent: 8544.0
train_total_correct_sent: 5384.0
train_accuracy_sent: 0.6301498127340824
train_count_tok: 163566.0
train_total_correct_tok: 142351.0
train_accuracy_tok: 0.8702970054901386
train_label=O_precision_sent: 0.4394904458598726
train_label=O_recall_sent: 0.042487684729064036
train_label=O_f-score_sent: 0.07748455923638405
train_label=N_precision_sent: 0.6005240590757503
train_label=N_recall_sent: 0.7616314199395771
train_label=N_f-score_sent: 0.6715503462972829
train_label=P_precision_sent: 0.6669849606111243
train_label=P_recall_sent: 0.7739612188365651
train_label=P_f-score_sent: 0.7165021156558533
train_precision_macro_sent: 0.5689998218489157
train_recall_macro_sent: 0.5260267745017354
train_f-score_macro_sent: 0.48851234039650676
train_precision_micro_sent: 0.6301498127340824
train_recall_micro_sent: 0.6301498127340824
train_f-score_micro_sent: 0.6301498127340824
train_label=O_precision_tok: 0.8846743860166679
train_label=O_recall_tok: 0.9646634016100107
train_label=O_f-score_tok: 0.9229390198394226
train_label=N_precision_tok: 0.7349215352618642
train_label=N_recall_tok: 0.5473876918743839
train_label=N_f-score_tok: 0.6274414850686036
train_label=P_precision_tok: 0.8405563857914703
train_label=P_recall_tok: 0.5845624975016989
train_label=P_f-score_tok: 0.689567370034186
train_precision_macro_tok: 0.8200507690233341
train_recall_macro_tok: 0.6988711969953645
train_f-score_macro_tok: 0.746649291647404
train_precision_micro_tok: 0.8702970054901386
train_recall_micro_tok: 0.8702970054901386
train_f-score_micro_tok: 0.8702970054901386
train_time: 95.56092190742493
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4395    0.0425    0.0775      1624
           N     0.6005    0.7616    0.6716      3310
           P     0.6670    0.7740    0.7165      3610

   micro avg     0.6301    0.6301    0.6301      8544
   macro avg     0.5690    0.5260    0.4885      8544
weighted avg     0.5980    0.6301    0.5776      8544

F1-macro sent:  0.48851234039650676
F1-micro sent:  0.6301498127340824
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9647    0.9229    124347
           N     0.7349    0.5474    0.6274     14202
           P     0.8406    0.5846    0.6896     25017

   micro avg     0.8703    0.8703    0.8703    163566
   macro avg     0.8201    0.6989    0.7466    163566
weighted avg     0.8649    0.8703    0.8616    163566

F1-macro tok:  0.746649291647404
F1-micro tok:  0.8702970054901386
**************************************************
dev_cost_sum: 45123.95642089844
dev_cost_avg: 40.9845199099895
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18813.0
dev_accuracy_tok: 0.8843188869042024
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.6652542372881356
dev_label=N_recall_sent: 0.7336448598130841
dev_label=N_f-score_sent: 0.6977777777777778
dev_label=P_precision_sent: 0.6213592233009708
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7231638418079096
dev_precision_macro_sent: 0.7015984262569749
dev_recall_macro_sent: 0.5459370115738724
dev_f-score_macro_sent: 0.4986472065285625
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8937801760863391
dev_label=O_recall_tok: 0.9709966059858068
dev_label=O_f-score_tok: 0.9307897071872228
dev_label=N_precision_tok: 0.7498248072880168
dev_label=N_recall_tok: 0.57619816908993
dev_label=N_f-score_tok: 0.6516443361753959
dev_label=P_precision_tok: 0.8956289027653881
dev_label=P_recall_tok: 0.6251556662515566
dev_label=P_f-score_tok: 0.7363403006967364
dev_precision_macro_tok: 0.8464112953799147
dev_recall_macro_tok: 0.7241168137757645
dev_f-score_macro_tok: 0.7729247813531183
dev_precision_micro_tok: 0.8843188869042024
dev_recall_micro_tok: 0.8843188869042024
dev_f-score_micro_tok: 0.8843188869042024
dev_time: 5.176734209060669
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.6653    0.7336    0.6978       428
           P     0.6214    0.8649    0.7232       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7016    0.5459    0.4986      1101
weighted avg     0.6794    0.6421    0.5785      1101

F1-macro sent:  0.4986472065285625
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8938    0.9710    0.9308     16205
           N     0.7498    0.5762    0.6516      1857
           P     0.8956    0.6252    0.7363      3212

   micro avg     0.8843    0.8843    0.8843     21274
   macro avg     0.8464    0.7241    0.7729     21274
weighted avg     0.8815    0.8843    0.8771     21274

F1-macro tok:  0.7729247813531183
F1-micro tok:  0.8843188869042024
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336997.2813720703
train_cost_avg: 39.442565703659916
train_count_sent: 8544.0
train_total_correct_sent: 5441.0
train_accuracy_sent: 0.6368211610486891
train_count_tok: 163566.0
train_total_correct_tok: 143010.0
train_accuracy_tok: 0.87432596016287
train_label=O_precision_sent: 0.4840764331210191
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.08534531162268388
train_label=N_precision_sent: 0.6098665395614872
train_label=N_recall_sent: 0.7731117824773414
train_label=N_f-score_sent: 0.6818545163868904
train_label=P_precision_sent: 0.6695299451204964
train_label=P_recall_sent: 0.7772853185595567
train_label=P_f-score_sent: 0.719394949365466
train_precision_macro_sent: 0.5878243059343342
train_recall_macro_sent: 0.5323983768645161
train_f-score_macro_sent: 0.49553159245834677
train_precision_micro_sent: 0.6368211610486891
train_recall_micro_sent: 0.6368211610486891
train_f-score_micro_sent: 0.6368211610486891
train_label=O_precision_tok: 0.8877379764149199
train_label=O_recall_tok: 0.9656123589632238
train_label=O_f-score_tok: 0.9250390983120315
train_label=N_precision_tok: 0.7522720884474843
train_label=N_recall_tok: 0.5653429094493734
train_label=N_f-score_tok: 0.6455477386934674
train_label=P_precision_tok: 0.8453339380882187
train_label=P_recall_tok: 0.5959947235879602
train_label=P_f-score_tok: 0.699097409447896
train_precision_macro_tok: 0.828448000983541
train_recall_macro_tok: 0.7089833306668525
train_f-score_macro_tok: 0.756561415484465
train_precision_micro_tok: 0.87432596016287
train_recall_micro_tok: 0.87432596016287
train_f-score_micro_tok: 0.87432596016287
train_time: 94.56488871574402
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4841    0.0468    0.0853      1624
           N     0.6099    0.7731    0.6819      3310
           P     0.6695    0.7773    0.7194      3610

   micro avg     0.6368    0.6368    0.6368      8544
   macro avg     0.5878    0.5324    0.4955      8544
weighted avg     0.6112    0.6368    0.5843      8544

F1-macro sent:  0.49553159245834677
F1-micro sent:  0.6368211610486891
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8877    0.9656    0.9250    124347
           N     0.7523    0.5653    0.6455     14202
           P     0.8453    0.5960    0.6991     25017

   micro avg     0.8743    0.8743    0.8743    163566
   macro avg     0.8284    0.7090    0.7566    163566
weighted avg     0.8695    0.8743    0.8662    163566

F1-macro tok:  0.756561415484465
F1-micro tok:  0.87432596016287
**************************************************
dev_cost_sum: 44904.48767089844
dev_cost_avg: 40.785184078926825
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18814.0
dev_accuracy_tok: 0.884365892638902
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04219409282700421
dev_label=N_precision_sent: 0.6373831775700934
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7082035306334372
dev_label=P_precision_sent: 0.6487455197132617
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.722554890219561
dev_precision_macro_sent: 0.6370428990944518
dev_recall_macro_sent: 0.5446261161377678
dev_f-score_macro_sent: 0.49098417122666743
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.882714341063818
dev_label=O_recall_tok: 0.9841406973156434
dev_label=O_f-score_tok: 0.930672268907563
dev_label=N_precision_tok: 0.8279475982532751
dev_label=N_recall_tok: 0.5105008077544426
dev_label=N_f-score_tok: 0.631578947368421
dev_label=P_precision_tok: 0.930164888457808
dev_label=P_recall_tok: 0.5971357409713575
dev_label=P_f-score_tok: 0.7273416761471369
dev_precision_macro_tok: 0.8802756092583003
dev_recall_macro_tok: 0.6972590820138144
dev_f-score_macro_tok: 0.763197630807707
dev_precision_micro_tok: 0.884365892638902
dev_recall_micro_tok: 0.884365892638902
dev_f-score_micro_tok: 0.884365892638902
dev_time: 5.091537237167358
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0218    0.0422       229
           N     0.6374    0.7967    0.7082       428
           P     0.6487    0.8153    0.7226       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6370    0.5446    0.4910      1101
weighted avg     0.6394    0.6431    0.5755      1101

F1-macro sent:  0.49098417122666743
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8827    0.9841    0.9307     16205
           N     0.8279    0.5105    0.6316      1857
           P     0.9302    0.5971    0.7273      3212

   micro avg     0.8844    0.8844    0.8844     21274
   macro avg     0.8803    0.6973    0.7632     21274
weighted avg     0.8851    0.8844    0.8739     21274

F1-macro tok:  0.763197630807707
F1-micro tok:  0.884365892638902
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 334507.21185302734
train_cost_avg: 39.151124982798144
train_count_sent: 8544.0
train_total_correct_sent: 5456.0
train_accuracy_sent: 0.6385767790262172
train_count_tok: 163566.0
train_total_correct_tok: 143211.0
train_accuracy_tok: 0.8755548219067533
train_label=O_precision_sent: 0.36666666666666664
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.0944206008583691
train_label=N_precision_sent: 0.6128339694656488
train_label=N_recall_sent: 0.7761329305135952
train_label=N_f-score_sent: 0.6848840309250868
train_label=P_precision_sent: 0.6806906614785992
train_label=P_recall_sent: 0.7753462603878116
train_label=P_f-score_sent: 0.724941724941725
train_precision_macro_sent: 0.5533970992036382
train_recall_macro_sent: 0.5352221276732112
train_f-score_macro_sent: 0.501415452241727
train_precision_micro_sent: 0.6385767790262172
train_recall_micro_sent: 0.6385767790262172
train_f-score_micro_sent: 0.6385767790262172
train_label=O_precision_tok: 0.8888091715976332
train_label=O_recall_tok: 0.9663843920641431
train_label=O_f-score_tok: 0.9259748716032163
train_label=N_precision_tok: 0.7466790524849047
train_label=N_recall_tok: 0.5659766230108435
train_label=N_f-score_tok: 0.6438899347138223
train_label=P_precision_tok: 0.8525651951593659
train_label=P_recall_tok: 0.5998321141623696
train_label=P_f-score_tok: 0.7042094889483316
train_precision_macro_tok: 0.8293511397473012
train_recall_macro_tok: 0.7107310430791186
train_f-score_macro_tok: 0.7580247650884567
train_precision_micro_tok: 0.8755548219067533
train_recall_micro_tok: 0.8755548219067533
train_f-score_micro_tok: 0.8755548219067533
train_time: 94.78452920913696
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3667    0.0542    0.0944      1624
           N     0.6128    0.7761    0.6849      3310
           P     0.6807    0.7753    0.7249      3610

   micro avg     0.6386    0.6386    0.6386      8544
   macro avg     0.5534    0.5352    0.5014      8544
weighted avg     0.5947    0.6386    0.5896      8544

F1-macro sent:  0.501415452241727
F1-micro sent:  0.6385767790262172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8888    0.9664    0.9260    124347
           N     0.7467    0.5660    0.6439     14202
           P     0.8526    0.5998    0.7042     25017

   micro avg     0.8756    0.8756    0.8756    163566
   macro avg     0.8294    0.7107    0.7580    163566
weighted avg     0.8709    0.8756    0.8676    163566

F1-macro tok:  0.7580247650884567
F1-micro tok:  0.8755548219067533
**************************************************
dev_cost_sum: 44485.56872558594
dev_cost_avg: 40.40469457364754
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18930.0
dev_accuracy_tok: 0.8898185578640594
dev_label=O_precision_sent: 0.2727272727272727
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025
dev_label=N_precision_sent: 0.6402321083172147
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7005291005291006
dev_label=P_precision_sent: 0.6404886561954625
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7217305801376598
dev_precision_macro_sent: 0.5178160124133165
dev_recall_macro_sent: 0.5376804997463692
dev_f-score_macro_sent: 0.4824198935555868
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.896057550696726
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.9344044419504417
dev_label=N_precision_tok: 0.784570596797671
dev_label=N_recall_tok: 0.5805061927840603
dev_label=N_f-score_tok: 0.6672856700711854
dev_label=P_precision_tok: 0.9051647373107747
dev_label=P_recall_tok: 0.6329389788293898
dev_label=P_f-score_tok: 0.7449615243679003
dev_precision_macro_tok: 0.861930961601724
dev_recall_macro_tok: 0.7298751209708106
dev_f-score_macro_tok: 0.7822172121298424
dev_precision_micro_tok: 0.8898185578640594
dev_recall_micro_tok: 0.8898185578640594
dev_f-score_micro_tok: 0.8898185578640594
dev_time: 5.060205698013306
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2727    0.0131    0.0250       229
           N     0.6402    0.7734    0.7005       428
           P     0.6405    0.8266    0.7217       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.5178    0.5377    0.4824      1101
weighted avg     0.5639    0.6367    0.5686      1101

F1-macro sent:  0.4824198935555868
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9762    0.9344     16205
           N     0.7846    0.5805    0.6673      1857
           P     0.9052    0.6329    0.7450      3212

   micro avg     0.8898    0.8898    0.8898     21274
   macro avg     0.8619    0.7299    0.7822     21274
weighted avg     0.8877    0.8898    0.8825     21274

F1-macro tok:  0.7822172121298424
F1-micro tok:  0.8898185578640594
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 331589.81719970703
train_cost_avg: 38.80966961607058
train_count_sent: 8544.0
train_total_correct_sent: 5503.0
train_accuracy_sent: 0.6440777153558053
train_count_tok: 163566.0
train_total_correct_tok: 143717.0
train_accuracy_tok: 0.8786483743565289
train_label=O_precision_sent: 0.4891304347826087
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.052447552447552455
train_label=N_precision_sent: 0.6059283088235294
train_label=N_recall_sent: 0.7966767371601209
train_label=N_f-score_sent: 0.6883320281910729
train_label=P_precision_sent: 0.6880487804878048
train_label=P_recall_sent: 0.7814404432132964
train_label=P_f-score_sent: 0.7317769130998703
train_precision_macro_sent: 0.594369174697981
train_recall_macro_sent: 0.535275513326443
train_f-score_macro_sent: 0.49085216457949854
train_precision_micro_sent: 0.6440777153558053
train_recall_micro_sent: 0.6440777153558053
train_f-score_micro_sent: 0.6440777153558053
train_label=O_precision_tok: 0.8914755677397844
train_label=O_recall_tok: 0.9675987357957972
train_label=O_f-score_tok: 0.9279786512000988
train_label=N_precision_tok: 0.7532894736842105
train_label=N_recall_tok: 0.5804816223067174
train_label=N_f-score_tok: 0.6556907659269864
train_label=P_precision_tok: 0.8582998244322365
train_label=P_recall_tok: 0.6057880641164008
train_label=P_f-score_tok: 0.7102685475933824
train_precision_macro_tok: 0.8343549552854105
train_recall_macro_tok: 0.7179561407396385
train_f-score_macro_tok: 0.7646459882401558
train_precision_micro_tok: 0.8786483743565289
train_recall_micro_tok: 0.8786483743565289
train_f-score_micro_tok: 0.8786483743565289
train_time: 95.40875768661499
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4891    0.0277    0.0524      1624
           N     0.6059    0.7967    0.6883      3310
           P     0.6880    0.7814    0.7318      3610

   micro avg     0.6441    0.6441    0.6441      8544
   macro avg     0.5944    0.5353    0.4909      8544
weighted avg     0.6184    0.6441    0.5858      8544

F1-macro sent:  0.49085216457949854
F1-micro sent:  0.6440777153558053
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8915    0.9676    0.9280    124347
           N     0.7533    0.5805    0.6557     14202
           P     0.8583    0.6058    0.7103     25017

   micro avg     0.8786    0.8786    0.8786    163566
   macro avg     0.8344    0.7180    0.7646    163566
weighted avg     0.8744    0.8786    0.8710    163566

F1-macro tok:  0.7646459882401558
F1-micro tok:  0.8786483743565289
**************************************************
dev_cost_sum: 44158.9326171875
dev_cost_avg: 40.10802235893506
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 18954.0
dev_accuracy_tok: 0.8909466954968506
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6196943972835314
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7177974434611604
dev_label=P_precision_sent: 0.6797642436149313
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7261280167890871
dev_precision_macro_sent: 0.6553751025217097
dev_recall_macro_sent: 0.5469388806837282
dev_f-score_macro_sent: 0.48705561318686413
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.8974504571006757
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.9347646084693636
dev_label=N_precision_tok: 0.7821710999281093
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.6699507389162562
dev_label=P_precision_tok: 0.9071302816901409
dev_label=P_recall_tok: 0.6416562889165629
dev_label=P_f-score_tok: 0.7516411378555798
dev_precision_macro_tok: 0.8622506129063087
dev_recall_macro_tok: 0.7342879239105796
dev_f-score_macro_tok: 0.7854521617470667
dev_precision_micro_tok: 0.8909466954968506
dev_recall_micro_tok: 0.8909466954968506
dev_f-score_micro_tok: 0.8909466954968506
dev_time: 5.105564594268799
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6197    0.8528    0.7178       428
           P     0.6798    0.7793    0.7261       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.6554    0.5469    0.4871      1101
weighted avg     0.6537    0.6476    0.5754      1101

F1-macro sent:  0.48705561318686413
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8975    0.9753    0.9348     16205
           N     0.7822    0.5859    0.6700      1857
           P     0.9071    0.6417    0.7516      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8623    0.7343    0.7855     21274
weighted avg     0.8888    0.8909    0.8840     21274

F1-macro tok:  0.7854521617470667
F1-micro tok:  0.8909466954968506
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 329115.9803466797
train_cost_avg: 38.52012878589416
train_count_sent: 8544.0
train_total_correct_sent: 5531.0
train_accuracy_sent: 0.6473548689138576
train_count_tok: 163566.0
train_total_correct_tok: 143933.0
train_accuracy_tok: 0.8799689422007019
train_label=O_precision_sent: 0.45751633986928103
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07878446820483963
train_label=N_precision_sent: 0.6131919905771496
train_label=N_recall_sent: 0.786404833836858
train_label=N_f-score_sent: 0.6890800794176042
train_label=P_precision_sent: 0.6893391220453449
train_label=P_recall_sent: 0.7916897506925208
train_label=P_f-score_sent: 0.7369778236204227
train_precision_macro_sent: 0.5866824841639252
train_recall_macro_sent: 0.5403993442684136
train_f-score_macro_sent: 0.5016141237476223
train_precision_micro_sent: 0.6473548689138576
train_recall_micro_sent: 0.6473548689138576
train_f-score_micro_sent: 0.6473548689138576
train_label=O_precision_tok: 0.8929814794195152
train_label=O_recall_tok: 0.9674378955664391
train_label=O_f-score_tok: 0.9287197659247592
train_label=N_precision_tok: 0.7550686426038731
train_label=N_recall_tok: 0.5847767920011266
train_label=N_f-score_tok: 0.6591008293321694
train_label=P_precision_tok: 0.8587273134662783
train_label=P_recall_tok: 0.6127833073510013
train_label=P_f-score_tok: 0.7152021274114161
train_precision_macro_tok: 0.8355924784965555
train_recall_macro_tok: 0.721665998306189
train_f-score_macro_tok: 0.7676742408894482
train_precision_micro_tok: 0.8799689422007019
train_recall_micro_tok: 0.8799689422007019
train_f-score_micro_tok: 0.8799689422007019
train_time: 96.048104763031
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4575    0.0431    0.0788      1624
           N     0.6132    0.7864    0.6891      3310
           P     0.6893    0.7917    0.7370      3610

   micro avg     0.6474    0.6474    0.6474      8544
   macro avg     0.5867    0.5404    0.5016      8544
weighted avg     0.6158    0.6474    0.5933      8544

F1-macro sent:  0.5016141237476223
F1-micro sent:  0.6473548689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8930    0.9674    0.9287    124347
           N     0.7551    0.5848    0.6591     14202
           P     0.8587    0.6128    0.7152     25017

   micro avg     0.8800    0.8800    0.8800    163566
   macro avg     0.8356    0.7217    0.7677    163566
weighted avg     0.8758    0.8800    0.8727    163566

F1-macro tok:  0.7676742408894482
F1-micro tok:  0.8799689422007019
**************************************************
dev_cost_sum: 43945.17687988281
dev_cost_avg: 39.913875458567496
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18966.0
dev_accuracy_tok: 0.8915107643132462
dev_label=O_precision_sent: 0.4473684210526316
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.1273408239700375
dev_label=N_precision_sent: 0.6475095785440613
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7115789473684212
dev_label=P_precision_sent: 0.66728280961183
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.732994923857868
dev_precision_macro_sent: 0.5873869364028409
dev_recall_macro_sent: 0.5590061656971831
dev_f-score_macro_sent: 0.5239715650654423
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.897197322137751
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9348822086252253
dev_label=N_precision_tok: 0.8196850393700787
dev_label=N_recall_tok: 0.5605815831987075
dev_label=N_f-score_tok: 0.6658138791173648
dev_label=P_precision_tok: 0.8877207737594617
dev_label=P_recall_tok: 0.6572229140722291
dev_label=P_f-score_tok: 0.7552772808586762
dev_precision_macro_tok: 0.8682010450890972
dev_recall_macro_tok: 0.7312253806083623
dev_f-score_macro_tok: 0.7853244562004221
dev_precision_micro_tok: 0.8915107643132462
dev_recall_micro_tok: 0.8915107643132462
dev_f-score_micro_tok: 0.8915107643132462
dev_time: 5.1076555252075195
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4474    0.0742    0.1273       229
           N     0.6475    0.7897    0.7116       428
           P     0.6673    0.8131    0.7330       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.5874    0.5590    0.5240      1101
weighted avg     0.6139    0.6503    0.5987      1101

F1-macro sent:  0.5239715650654423
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9759    0.9349     16205
           N     0.8197    0.5606    0.6658      1857
           P     0.8877    0.6572    0.7553      3212

   micro avg     0.8915    0.8915    0.8915     21274
   macro avg     0.8682    0.7312    0.7853     21274
weighted avg     0.8890    0.8915    0.8843     21274

F1-macro tok:  0.7853244562004221
F1-micro tok:  0.8915107643132462
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 326842.46075439453
train_cost_avg: 38.254033327995614
train_count_sent: 8544.0
train_total_correct_sent: 5594.0
train_accuracy_sent: 0.6547284644194756
train_count_tok: 163566.0
train_total_correct_tok: 144383.0
train_accuracy_tok: 0.8827201252093956
train_label=O_precision_sent: 0.424
train_label=O_recall_sent: 0.06527093596059114
train_label=O_f-score_sent: 0.11312700106723586
train_label=N_precision_sent: 0.628578360019408
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.6972551130247577
train_label=P_precision_sent: 0.6943911792905082
train_label=P_recall_sent: 0.8024930747922437
train_label=P_f-score_sent: 0.7445386790028271
train_precision_macro_sent: 0.582323179769972
train_recall_macro_sent: 0.5501811556487294
train_f-score_macro_sent: 0.5183069310316069
train_precision_micro_sent: 0.6547284644194756
train_recall_micro_sent: 0.6547284644194756
train_f-score_micro_sent: 0.6547284644194756
train_label=O_precision_tok: 0.8951761557900996
train_label=O_recall_tok: 0.9685557351604783
train_label=O_f-score_tok: 0.9304213807568554
train_label=N_precision_tok: 0.7637203405180221
train_label=N_recall_tok: 0.5937896070975919
train_label=N_f-score_tok: 0.6681191570274125
train_label=P_precision_tok: 0.8626000889679716
train_label=P_recall_tok: 0.6200983331334693
train_label=P_f-score_tok: 0.7215181042301342
train_precision_macro_tok: 0.8404988617586978
train_recall_macro_tok: 0.727481225130513
train_f-score_macro_tok: 0.7733528806714673
train_precision_micro_tok: 0.8827201252093956
train_recall_micro_tok: 0.8827201252093956
train_f-score_micro_tok: 0.8827201252093956
train_time: 108.04334473609924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4240    0.0653    0.1131      1624
           N     0.6286    0.7828    0.6973      3310
           P     0.6944    0.8025    0.7445      3610

   micro avg     0.6547    0.6547    0.6547      8544
   macro avg     0.5823    0.5502    0.5183      8544
weighted avg     0.6175    0.6547    0.6062      8544

F1-macro sent:  0.5183069310316069
F1-micro sent:  0.6547284644194756
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8952    0.9686    0.9304    124347
           N     0.7637    0.5938    0.6681     14202
           P     0.8626    0.6201    0.7215     25017

   micro avg     0.8827    0.8827    0.8827    163566
   macro avg     0.8405    0.7275    0.7734    163566
weighted avg     0.8788    0.8827    0.8757    163566

F1-macro tok:  0.7733528806714673
F1-micro tok:  0.8827201252093956
**************************************************
dev_cost_sum: 43758.3740234375
dev_cost_avg: 39.74420892228656
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18994.0
dev_accuracy_tok: 0.892826924884836
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.5781710914454278
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.708860759493671
dev_label=P_precision_sent: 0.7333333333333333
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7129629629629628
dev_precision_macro_sent: 0.7705014749262538
dev_recall_macro_sent: 0.5408939936140688
dev_f-score_macro_sent: 0.4825619304740503
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8965575716466
dev_label=O_recall_tok: 0.9787719839555693
dev_label=O_f-score_tok: 0.9358626386594288
dev_label=N_precision_tok: 0.8069120961682945
dev_label=N_recall_tok: 0.5783521809369951
dev_label=N_f-score_tok: 0.6737766624843162
dev_label=P_precision_tok: 0.9142984014209592
dev_label=P_recall_tok: 0.6410336239103362
dev_label=P_f-score_tok: 0.7536603221083455
dev_precision_macro_tok: 0.8725893564119512
dev_recall_macro_tok: 0.7327192629343001
dev_f-score_macro_tok: 0.7877665410840301
dev_precision_micro_tok: 0.892826924884836
dev_recall_micro_tok: 0.892826924884836
dev_f-score_micro_tok: 0.892826924884836
dev_time: 8.264421701431274
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.5782    0.9159    0.7089       428
           P     0.7333    0.6937    0.7130       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.7705    0.5409    0.4826      1101
weighted avg     0.7285    0.6385    0.5685      1101

F1-macro sent:  0.4825619304740503
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9788    0.9359     16205
           N     0.8069    0.5784    0.6738      1857
           P     0.9143    0.6410    0.7537      3212

   micro avg     0.8928    0.8928    0.8928     21274
   macro avg     0.8726    0.7327    0.7878     21274
weighted avg     0.8914    0.8928    0.8855     21274

F1-macro tok:  0.7877665410840301
F1-micro tok:  0.892826924884836
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 324727.6350097656
train_cost_avg: 38.006511588221635
train_count_sent: 8544.0
train_total_correct_sent: 5566.0
train_accuracy_sent: 0.6514513108614233
train_count_tok: 163566.0
train_total_correct_tok: 144746.0
train_accuracy_tok: 0.8849394128364085
train_label=O_precision_sent: 0.44966442953020136
train_label=O_recall_sent: 0.04125615763546798
train_label=O_f-score_sent: 0.07557811618725324
train_label=N_precision_sent: 0.6052747252747253
train_label=N_recall_sent: 0.83202416918429
train_label=N_f-score_sent: 0.7007633587786259
train_label=P_precision_sent: 0.7139141742522757
train_label=P_recall_sent: 0.760387811634349
train_label=P_f-score_sent: 0.7364185110663983
train_precision_macro_sent: 0.5896177763524008
train_recall_macro_sent: 0.544556046151369
train_f-score_macro_sent: 0.5042533286774259
train_precision_micro_sent: 0.6514513108614233
train_recall_micro_sent: 0.6514513108614233
train_f-score_micro_sent: 0.6514513108614233
train_label=O_precision_tok: 0.8964778836073253
train_label=O_recall_tok: 0.9696253226857101
train_label=O_f-score_tok: 0.9316179879462216
train_label=N_precision_tok: 0.7727025063567018
train_label=N_recall_tok: 0.5991409660611181
train_label=N_f-score_tok: 0.6749424922662013
train_label=P_precision_tok: 0.8674491999335585
train_label=P_recall_tok: 0.6262541471799177
train_label=P_f-score_tok: 0.7273782441153257
train_precision_macro_tok: 0.8455431966325285
train_recall_macro_tok: 0.7316734786422486
train_f-score_macro_tok: 0.7779795747759163
train_precision_micro_tok: 0.8849394128364085
train_recall_micro_tok: 0.8849394128364085
train_f-score_micro_tok: 0.8849394128364085
train_time: 145.43384718894958
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4497    0.0413    0.0756      1624
           N     0.6053    0.8320    0.7008      3310
           P     0.7139    0.7604    0.7364      3610

   micro avg     0.6515    0.6515    0.6515      8544
   macro avg     0.5896    0.5446    0.5043      8544
weighted avg     0.6216    0.6515    0.5970      8544

F1-macro sent:  0.5042533286774259
F1-micro sent:  0.6514513108614233
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8965    0.9696    0.9316    124347
           N     0.7727    0.5991    0.6749     14202
           P     0.8674    0.6263    0.7274     25017

   micro avg     0.8849    0.8849    0.8849    163566
   macro avg     0.8455    0.7317    0.7780    163566
weighted avg     0.8813    0.8849    0.8781    163566

F1-macro tok:  0.7779795747759163
F1-micro tok:  0.8849394128364085
**************************************************
dev_cost_sum: 43497.20812988281
dev_cost_avg: 39.507001026233254
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 18977.0
dev_accuracy_tok: 0.8920278273949421
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09876543209876543
dev_label=N_precision_sent: 0.6353982300884956
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7230614300100704
dev_label=P_precision_sent: 0.6819923371647509
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7370600414078674
dev_precision_macro_sent: 0.7248444747987012
dev_recall_macro_sent: 0.5643295317518882
dev_f-score_macro_sent: 0.5196289678389011
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9010517891848634
dev_label=O_recall_tok: 0.9727244677568652
dev_label=O_f-score_tok: 0.9355173744028012
dev_label=N_precision_tok: 0.7641196013289037
dev_label=N_recall_tok: 0.6192784060312332
dev_label=N_f-score_tok: 0.6841165972635337
dev_label=P_precision_tok: 0.9072527472527473
dev_label=P_recall_tok: 0.6425902864259029
dev_label=P_f-score_tok: 0.7523236741388737
dev_precision_macro_tok: 0.8574747125888381
dev_recall_macro_tok: 0.7448643867380004
dev_f-score_macro_tok: 0.7906525486017362
dev_precision_micro_tok: 0.8920278273949421
dev_recall_micro_tok: 0.8920278273949421
dev_f-score_micro_tok: 0.8920278273949421
dev_time: 8.299087047576904
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0524    0.0988       229
           N     0.6354    0.8388    0.7231       428
           P     0.6820    0.8018    0.7371       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7248    0.5643    0.5196      1101
weighted avg     0.7003    0.6603    0.5989      1101

F1-macro sent:  0.5196289678389011
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9011    0.9727    0.9355     16205
           N     0.7641    0.6193    0.6841      1857
           P     0.9073    0.6426    0.7523      3212

   micro avg     0.8920    0.8920    0.8920     21274
   macro avg     0.8575    0.7449    0.7907     21274
weighted avg     0.8900    0.8920    0.8859     21274

F1-macro tok:  0.7906525486017362
F1-micro tok:  0.8920278273949421
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 322405.65411376953
train_cost_avg: 37.7347441612558
train_count_sent: 8544.0
train_total_correct_sent: 5616.0
train_accuracy_sent: 0.6573033707865169
train_count_tok: 163566.0
train_total_correct_tok: 145032.0
train_accuracy_tok: 0.8866879424819339
train_label=O_precision_sent: 0.3940677966101695
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.1
train_label=N_precision_sent: 0.6264168401572981
train_label=N_recall_sent: 0.8181268882175227
train_label=N_f-score_sent: 0.7095506353989257
train_label=P_precision_sent: 0.7063989962358845
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7412771560236998
train_precision_macro_sent: 0.575627877667784
train_recall_macro_sent: 0.55172376380718
train_f-score_macro_sent: 0.5169425971408752
train_precision_micro_sent: 0.6573033707865169
train_recall_micro_sent: 0.6573033707865169
train_f-score_micro_sent: 0.6573033707865169
train_label=O_precision_tok: 0.8991866278635923
train_label=O_recall_tok: 0.9690623818829566
train_label=O_f-score_tok: 0.9328177676625754
train_label=N_precision_tok: 0.7692170818505338
train_label=N_recall_tok: 0.6087874947190537
train_label=N_f-score_tok: 0.6796635484631712
train_label=P_precision_tok: 0.8673291111596418
train_label=P_recall_tok: 0.6350081944277891
train_label=P_f-score_tok: 0.733205640043385
train_precision_macro_tok: 0.8452442736245893
train_recall_macro_tok: 0.7376193570099331
train_f-score_macro_tok: 0.7818956520563772
train_precision_micro_tok: 0.8866879424819339
train_recall_micro_tok: 0.8866879424819339
train_f-score_micro_tok: 0.8866879424819339
train_time: 145.28999090194702
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3941    0.0573    0.1000      1624
           N     0.6264    0.8181    0.7096      3310
           P     0.7064    0.7798    0.7413      3610

   micro avg     0.6573    0.6573    0.6573      8544
   macro avg     0.5756    0.5517    0.5169      8544
weighted avg     0.6160    0.6573    0.6071      8544

F1-macro sent:  0.5169425971408752
F1-micro sent:  0.6573033707865169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9691    0.9328    124347
           N     0.7692    0.6088    0.6797     14202
           P     0.8673    0.6350    0.7332     25017

   micro avg     0.8867    0.8867    0.8867    163566
   macro avg     0.8452    0.7376    0.7819    163566
weighted avg     0.8830    0.8867    0.8803    163566

F1-macro tok:  0.7818956520563772
F1-micro tok:  0.8866879424819339
**************************************************
dev_cost_sum: 43408.22570800781
dev_cost_avg: 39.426181387836344
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04219409282700421
dev_label=N_precision_sent: 0.6344086021505376
dev_label=N_recall_sent: 0.8271028037383178
dev_label=N_f-score_sent: 0.718052738336714
dev_label=P_precision_sent: 0.6654205607476635
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7272727272727273
dev_precision_macro_sent: 0.641609720966067
dev_recall_macro_sent: 0.5502462222251636
dev_f-score_macro_sent: 0.49583985281214854
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8983954187220049
dev_label=O_recall_tok: 0.9777846343721074
dev_label=O_f-score_tok: 0.9364103776372554
dev_label=N_precision_tok: 0.8014492753623188
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.683348779734322
dev_label=P_precision_tok: 0.9149313247673904
dev_label=P_recall_tok: 0.6429016189290162
dev_label=P_f-score_tok: 0.7551654781495702
dev_precision_macro_tok: 0.8715920062839047
dev_recall_macro_tok: 0.73875684300488
dev_f-score_macro_tok: 0.7916415451737159
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 8.452744483947754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0218    0.0422       229
           N     0.6344    0.8271    0.7181       428
           P     0.6654    0.8018    0.7273       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.6416    0.5502    0.4958      1101
weighted avg     0.6450    0.6494    0.5812      1101

F1-macro sent:  0.49583985281214854
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8984    0.9778    0.9364     16205
           N     0.8014    0.5956    0.6833      1857
           P     0.9149    0.6429    0.7552      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8716    0.7388    0.7916     21274
weighted avg     0.8924    0.8939    0.8870     21274

F1-macro tok:  0.7916415451737159
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 320395.5959472656
train_cost_avg: 37.4994845443897
train_count_sent: 8544.0
train_total_correct_sent: 5633.0
train_accuracy_sent: 0.6592930711610487
train_count_tok: 163566.0
train_total_correct_tok: 145289.0
train_accuracy_tok: 0.888259173666899
train_label=O_precision_sent: 0.5174418604651163
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.09910913140311804
train_label=N_precision_sent: 0.6299455105425255
train_label=N_recall_sent: 0.8033232628398792
train_label=N_f-score_sent: 0.7061479219227194
train_label=P_precision_sent: 0.6950132498193207
train_label=P_recall_sent: 0.7991689750692521
train_label=P_f-score_sent: 0.7434608942146631
train_precision_macro_sent: 0.6141335402756541
train_recall_macro_sent: 0.5524317311913853
train_f-score_macro_sent: 0.5162393158468336
train_precision_micro_sent: 0.6592930711610487
train_recall_micro_sent: 0.6592930711610487
train_f-score_micro_sent: 0.6592930711610487
train_label=O_precision_tok: 0.900597416175043
train_label=O_recall_tok: 0.9698585410182795
train_label=O_f-score_tok: 0.9339456432933085
train_label=N_precision_tok: 0.7730898776812621
train_label=N_recall_tok: 0.6141388536825799
train_label=N_f-score_tok: 0.6845079265421441
train_label=P_precision_tok: 0.869054098182214
train_label=P_recall_tok: 0.6382859655434304
train_label=P_f-score_tok: 0.7360051623608582
train_precision_macro_tok: 0.8475804640128398
train_recall_macro_tok: 0.74076112008143
train_f-score_macro_tok: 0.7848195773987703
train_precision_micro_tok: 0.888259173666899
train_recall_micro_tok: 0.888259173666899
train_f-score_micro_tok: 0.888259173666899
train_time: 145.066739320755
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5174    0.0548    0.0991      1624
           N     0.6299    0.8033    0.7061      3310
           P     0.6950    0.7992    0.7435      3610

   micro avg     0.6593    0.6593    0.6593      8544
   macro avg     0.6141    0.5524    0.5162      8544
weighted avg     0.6361    0.6593    0.6065      8544

F1-macro sent:  0.5162393158468336
F1-micro sent:  0.6592930711610487
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9006    0.9699    0.9339    124347
           N     0.7731    0.6141    0.6845     14202
           P     0.8691    0.6383    0.7360     25017

   micro avg     0.8883    0.8883    0.8883    163566
   macro avg     0.8476    0.7408    0.7848    163566
weighted avg     0.8847    0.8883    0.8820    163566

F1-macro tok:  0.7848195773987703
F1-micro tok:  0.888259173666899
**************************************************
dev_cost_sum: 43189.03759765625
dev_cost_avg: 39.22710045200386
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19039.0
dev_accuracy_tok: 0.8949421829463194
dev_label=O_precision_sent: 0.6470588235294118
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08943089430894309
dev_label=N_precision_sent: 0.6094771241830066
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7173076923076923
dev_label=P_precision_sent: 0.7055084745762712
dev_label=P_recall_sent: 0.75
dev_label=P_f-score_sent: 0.7270742358078602
dev_precision_macro_sent: 0.6540148074295632
dev_recall_macro_sent: 0.5565100872002068
dev_f-score_macro_sent: 0.5112709408081653
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8971709300355751
dev_label=O_recall_tok: 0.9804381363776612
dev_label=O_f-score_tok: 0.93695818835879
dev_label=N_precision_tok: 0.8165137614678899
dev_label=N_recall_tok: 0.5751211631663974
dev_label=N_f-score_tok: 0.6748815165876778
dev_label=P_precision_tok: 0.9229065130704475
dev_label=P_recall_tok: 0.6485056039850561
dev_label=P_f-score_tok: 0.7617480343755715
dev_precision_macro_tok: 0.8788637348579709
dev_recall_macro_tok: 0.7346883011763715
dev_f-score_macro_tok: 0.7911959131073464
dev_precision_micro_tok: 0.8949421829463194
dev_recall_micro_tok: 0.8949421829463194
dev_f-score_micro_tok: 0.8949421829463194
dev_time: 8.392194271087646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6471    0.0480    0.0894       229
           N     0.6095    0.8715    0.7173       428
           P     0.7055    0.7500    0.7271       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6540    0.5565    0.5113      1101
weighted avg     0.6560    0.6512    0.5907      1101

F1-macro sent:  0.5112709408081653
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9804    0.9370     16205
           N     0.8165    0.5751    0.6749      1857
           P     0.9229    0.6485    0.7617      3212

   micro avg     0.8949    0.8949    0.8949     21274
   macro avg     0.8789    0.7347    0.7912     21274
weighted avg     0.8940    0.8949    0.8876     21274

F1-macro tok:  0.7911959131073464
F1-micro tok:  0.8949421829463194
**************************************************
Best epoch: 12
**************************************************

EPOCH: 17
Learning rate: 0.900000
train_cost_sum: 318152.0178222656
train_cost_avg: 37.23689347170712
train_count_sent: 8544.0
train_total_correct_sent: 5672.0
train_accuracy_sent: 0.6638576779026217
train_count_tok: 163566.0
train_total_correct_tok: 145603.0
train_accuracy_tok: 0.8901788880329653
train_label=O_precision_sent: 0.46443514644351463
train_label=O_recall_sent: 0.06834975369458128
train_label=O_f-score_sent: 0.11916264090177135
train_label=N_precision_sent: 0.6451135241855873
train_label=N_recall_sent: 0.7897280966767372
train_label=N_f-score_sent: 0.7101331160010866
train_label=P_precision_sent: 0.692922642840348
train_label=P_recall_sent: 0.8163434903047091
train_label=P_f-score_sent: 0.7495866717537837
train_precision_macro_sent: 0.6008237711564833
train_recall_macro_sent: 0.5581404468920091
train_f-score_macro_sent: 0.5262941428855472
train_precision_micro_sent: 0.6638576779026217
train_recall_micro_sent: 0.6638576779026217
train_f-score_micro_sent: 0.6638576779026217
train_label=O_precision_tok: 0.9026855435848675
train_label=O_recall_tok: 0.9696172806742422
train_label=O_f-score_tok: 0.9349550625402265
train_label=N_precision_tok: 0.7778264680105171
train_label=N_recall_tok: 0.6249119842275735
train_label=N_f-score_tok: 0.6930345150710604
train_label=P_precision_tok: 0.8692775297218786
train_label=P_recall_tok: 0.6459207738737658
train_label=P_f-score_tok: 0.7411365408430032
train_precision_macro_tok: 0.8499298471057544
train_recall_macro_tok: 0.7468166795918605
train_f-score_macro_tok: 0.78970870615143
train_precision_micro_tok: 0.8901788880329653
train_recall_micro_tok: 0.8901788880329653
train_f-score_micro_tok: 0.8901788880329653
train_time: 146.4646384716034
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4644    0.0683    0.1192      1624
           N     0.6451    0.7897    0.7101      3310
           P     0.6929    0.8163    0.7496      3610

   micro avg     0.6639    0.6639    0.6639      8544
   macro avg     0.6008    0.5581    0.5263      8544
weighted avg     0.6310    0.6639    0.6145      8544

F1-macro sent:  0.5262941428855472
F1-micro sent:  0.6638576779026217
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9027    0.9696    0.9350    124347
           N     0.7778    0.6249    0.6930     14202
           P     0.8693    0.6459    0.7411     25017

   micro avg     0.8902    0.8902    0.8902    163566
   macro avg     0.8499    0.7468    0.7897    163566
weighted avg     0.8867    0.8902    0.8843    163566

F1-macro tok:  0.78970870615143
F1-micro tok:  0.8901788880329653
**************************************************
dev_cost_sum: 43072.85607910156
dev_cost_avg: 39.12157682025573
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19065.0
dev_accuracy_tok: 0.8961643320485099
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0737704918032787
dev_label=N_precision_sent: 0.6700404858299596
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7180043383947939
dev_label=P_precision_sent: 0.6418918918918919
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7335907335907337
dev_precision_macro_sent: 0.6373107925739505
dev_recall_macro_sent: 0.5561738839602774
dev_f-score_macro_sent: 0.5084551879296021
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.9008527572484366
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9377718597425655
dev_label=N_precision_tok: 0.8095588235294118
dev_label=N_recall_tok: 0.592891760904685
dev_label=N_f-score_tok: 0.6844886540254896
dev_label=P_precision_tok: 0.9113597246127366
dev_label=P_recall_tok: 0.6594022415940224
dev_label=P_f-score_tok: 0.7651734104046243
dev_precision_macro_tok: 0.8739237684635284
dev_recall_macro_tok: 0.7433801154065938
dev_f-score_macro_tok: 0.7958113080575598
dev_precision_micro_tok: 0.8961643320485099
dev_recall_micro_tok: 0.8961643320485099
dev_f-score_micro_tok: 0.89616433204851
dev_time: 8.568293333053589
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0393    0.0738       229
           N     0.6700    0.7734    0.7180       428
           P     0.6419    0.8559    0.7336       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6373    0.5562    0.5085      1101
weighted avg     0.6441    0.6540    0.5903      1101

F1-macro sent:  0.5084551879296021
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9778    0.9378     16205
           N     0.8096    0.5929    0.6845      1857
           P     0.9114    0.6594    0.7652      3212

   micro avg     0.8962    0.8962    0.8962     21274
   macro avg     0.8739    0.7434    0.7958     21274
weighted avg     0.8945    0.8962    0.8896     21274

F1-macro tok:  0.7958113080575598
F1-micro tok:  0.89616433204851
**************************************************
Best epoch: 12
**************************************************

EPOCH: 18
Learning rate: 0.810000
train_cost_sum: 316252.5517578125
train_cost_avg: 37.01457768700989
train_count_sent: 8544.0
train_total_correct_sent: 5717.0
train_accuracy_sent: 0.669124531835206
train_count_tok: 163566.0
train_total_correct_tok: 145922.0
train_accuracy_tok: 0.8921291710991281
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15169660678642716
train_label=N_precision_sent: 0.6482155863073562
train_label=N_recall_sent: 0.8066465256797583
train_label=N_f-score_sent: 0.718804684345134
train_label=P_precision_sent: 0.715698393077874
train_label=P_recall_sent: 0.8019390581717452
train_label=P_f-score_sent: 0.7563683866753756
train_precision_macro_sent: 0.5879713264617434
train_recall_macro_sent: 0.567393880988268
train_f-score_macro_sent: 0.5422898926023123
train_precision_micro_sent: 0.669124531835206
train_recall_micro_sent: 0.669124531835206
train_f-score_micro_sent: 0.669124531835206
train_label=O_precision_tok: 0.9040457403202722
train_label=O_recall_tok: 0.9702204315343353
train_label=O_f-score_tok: 0.9359648714487425
train_label=N_precision_tok: 0.7835024492652204
train_label=N_recall_tok: 0.6306858188987466
train_label=N_f-score_tok: 0.6988374814699227
train_label=P_precision_tok: 0.8734814021942735
train_label=P_recall_tok: 0.6523963704680817
train_label=P_f-score_tok: 0.7469223376504508
train_precision_macro_tok: 0.8536765305932553
train_recall_macro_tok: 0.7511008736337214
train_f-score_macro_tok: 0.7939082301897052
train_precision_micro_tok: 0.8921291710991281
train_recall_micro_tok: 0.8921291710991281
train_f-score_micro_tok: 0.8921291710991281
train_time: 145.8396863937378
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0936    0.1517      1624
           N     0.6482    0.8066    0.7188      3310
           P     0.7157    0.8019    0.7564      3610

   micro avg     0.6691    0.6691    0.6691      8544
   macro avg     0.5880    0.5674    0.5423      8544
weighted avg     0.6295    0.6691    0.6269      8544

F1-macro sent:  0.5422898926023123
F1-micro sent:  0.669124531835206
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9040    0.9702    0.9360    124347
           N     0.7835    0.6307    0.6988     14202
           P     0.8735    0.6524    0.7469     25017

   micro avg     0.8921    0.8921    0.8921    163566
   macro avg     0.8537    0.7511    0.7939    163566
weighted avg     0.8889    0.8921    0.8865    163566

F1-macro tok:  0.7939082301897052
F1-micro tok:  0.8921291710991281
**************************************************
dev_cost_sum: 42901.589782714844
dev_cost_avg: 38.96602160101257
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 0.5384615384615384
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10980392156862745
dev_label=N_precision_sent: 0.6140065146579805
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7236084452975048
dev_label=P_precision_sent: 0.7223427331887202
dev_label=P_recall_sent: 0.75
dev_label=P_f-score_sent: 0.7359116022099448
dev_precision_macro_sent: 0.624936928769413
dev_recall_macro_sent: 0.5639921642247888
dev_f-score_macro_sent: 0.5231079896920257
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9009198273904157
dev_label=O_recall_tok: 0.9791422400493675
dev_label=O_f-score_tok: 0.9384037614217701
dev_label=N_precision_tok: 0.8119030124908155
dev_label=N_recall_tok: 0.5950457727517501
dev_label=N_f-score_tok: 0.6867619639527657
dev_label=P_precision_tok: 0.9182963928726641
dev_label=P_recall_tok: 0.6578455790784558
dev_label=P_f-score_tok: 0.7665517866860148
dev_precision_macro_tok: 0.8770397442512984
dev_recall_macro_tok: 0.7440111972931911
dev_f-score_macro_tok: 0.7972391706868501
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 8.422418594360352
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0611    0.1098       229
           N     0.6140    0.8808    0.7236       428
           P     0.7223    0.7500    0.7359       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6249    0.5640    0.5231      1101
weighted avg     0.6420    0.6576    0.6009      1101

F1-macro sent:  0.5231079896920257
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9791    0.9384     16205
           N     0.8119    0.5950    0.6868      1857
           P     0.9183    0.6578    0.7666      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8770    0.7440    0.7972     21274
weighted avg     0.8958    0.8971    0.8905     21274

F1-macro tok:  0.7972391706868501
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 12
**************************************************

EPOCH: 19
Learning rate: 0.729000
train_cost_sum: 314708.5665283203
train_cost_avg: 36.83386780528094
train_count_sent: 8544.0
train_total_correct_sent: 5743.0
train_accuracy_sent: 0.6721676029962547
train_count_tok: 163566.0
train_total_correct_tok: 146173.0
train_accuracy_tok: 0.8936637198439773
train_label=O_precision_sent: 0.4280821917808219
train_label=O_recall_sent: 0.0769704433497537
train_label=O_f-score_sent: 0.13048016701461376
train_label=N_precision_sent: 0.648766328011611
train_label=N_recall_sent: 0.8102719033232628
train_label=N_f-score_sent: 0.7205803331542182
train_label=P_precision_sent: 0.7129674599320058
train_label=P_recall_sent: 0.8132963988919668
train_label=P_f-score_sent: 0.7598343685300208
train_precision_macro_sent: 0.5966053265748129
train_recall_macro_sent: 0.5668462485216611
train_f-score_macro_sent: 0.5369649562329509
train_precision_micro_sent: 0.6721676029962547
train_recall_micro_sent: 0.6721676029962547
train_f-score_micro_sent: 0.6721676029962547
train_label=O_precision_tok: 0.9056247045848432
train_label=O_recall_tok: 0.9707351202682815
train_label=O_f-score_tok: 0.9370502340529587
train_label=N_precision_tok: 0.7814979509983434
train_label=N_recall_tok: 0.6311082946063935
train_label=N_f-score_tok: 0.6982976900003897
train_label=P_precision_tok: 0.8772993088782562
train_label=P_recall_tok: 0.6596314506135827
train_label=P_f-score_tok: 0.7530517717388824
train_precision_macro_tok: 0.8548073214871477
train_recall_macro_tok: 0.7538249551627526
train_f-score_macro_tok: 0.7961332319307436
train_precision_micro_tok: 0.8936637198439773
train_recall_micro_tok: 0.8936637198439773
train_f-score_micro_tok: 0.8936637198439773
train_time: 145.8707206249237
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4281    0.0770    0.1305      1624
           N     0.6488    0.8103    0.7206      3310
           P     0.7130    0.8133    0.7598      3610

   micro avg     0.6722    0.6722    0.6722      8544
   macro avg     0.5966    0.5668    0.5370      8544
weighted avg     0.6339    0.6722    0.6250      8544

F1-macro sent:  0.5369649562329509
F1-micro sent:  0.6721676029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9707    0.9371    124347
           N     0.7815    0.6311    0.6983     14202
           P     0.8773    0.6596    0.7531     25017

   micro avg     0.8937    0.8937    0.8937    163566
   macro avg     0.8548    0.7538    0.7961    163566
weighted avg     0.8905    0.8937    0.8882    163566

F1-macro tok:  0.7961332319307436
F1-micro tok:  0.8936637198439773
**************************************************
dev_cost_sum: 42838.56231689453
dev_cost_avg: 38.90877594631656
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19077.0
dev_accuracy_tok: 0.8967284008649056
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.6335078534031413
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7252747252747251
dev_label=P_precision_sent: 0.6866537717601547
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7388137356919876
dev_precision_macro_sent: 0.7127811477817048
dev_recall_macro_sent: 0.562327233571571
dev_f-score_macro_sent: 0.5130294869889043
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9090172473665934
dev_label=O_recall_tok: 0.9692070348657822
dev_label=O_f-score_tok: 0.9381477167517844
dev_label=N_precision_tok: 0.7750163505559189
dev_label=N_recall_tok: 0.6381260096930533
dev_label=N_f-score_tok: 0.6999409332545777
dev_label=P_precision_tok: 0.8860964734495338
dev_label=P_recall_tok: 0.6805728518057285
dev_label=P_f-score_tok: 0.769853847508364
dev_precision_macro_tok: 0.856710023790682
dev_recall_macro_tok: 0.7626352987881879
dev_f-score_macro_tok: 0.8026474991715755
dev_precision_micro_tok: 0.8967284008649056
dev_recall_micro_tok: 0.8967284008649056
dev_f-score_micro_tok: 0.8967284008649056
dev_time: 8.47771167755127
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.6335    0.8481    0.7253       428
           P     0.6867    0.7995    0.7388       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7128    0.5623    0.5130      1101
weighted avg     0.6934    0.6603    0.5955      1101

F1-macro sent:  0.5130294869889043
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9090    0.9692    0.9381     16205
           N     0.7750    0.6381    0.6999      1857
           P     0.8861    0.6806    0.7699      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8567    0.7626    0.8026     21274
weighted avg     0.8939    0.8967    0.8919     21274

F1-macro tok:  0.8026474991715755
F1-micro tok:  0.8967284008649056
**************************************************
Best epoch: 12
**************************************************

test0_cost_sum: 43945.17687988281
test0_cost_avg: 39.913875458567496
test0_count_sent: 1101.0
test0_total_correct_sent: 716.0
test0_accuracy_sent: 0.6503178928247049
test0_count_tok: 21274.0
test0_total_correct_tok: 18966.0
test0_accuracy_tok: 0.8915107643132462
test0_label=O_precision_sent: 0.4473684210526316
test0_label=O_recall_sent: 0.07423580786026202
test0_label=O_f-score_sent: 0.1273408239700375
test0_label=N_precision_sent: 0.6475095785440613
test0_label=N_recall_sent: 0.7897196261682243
test0_label=N_f-score_sent: 0.7115789473684212
test0_label=P_precision_sent: 0.66728280961183
test0_label=P_recall_sent: 0.8130630630630631
test0_label=P_f-score_sent: 0.732994923857868
test0_precision_macro_sent: 0.5873869364028409
test0_recall_macro_sent: 0.5590061656971831
test0_f-score_macro_sent: 0.5239715650654423
test0_precision_micro_sent: 0.6503178928247049
test0_recall_micro_sent: 0.6503178928247049
test0_f-score_micro_sent: 0.6503178928247049
test0_label=O_precision_tok: 0.897197322137751
test0_label=O_recall_tok: 0.97587164455415
test0_label=O_f-score_tok: 0.9348822086252253
test0_label=N_precision_tok: 0.8196850393700787
test0_label=N_recall_tok: 0.5605815831987075
test0_label=N_f-score_tok: 0.6658138791173648
test0_label=P_precision_tok: 0.8877207737594617
test0_label=P_recall_tok: 0.6572229140722291
test0_label=P_f-score_tok: 0.7552772808586762
test0_precision_macro_tok: 0.8682010450890972
test0_recall_macro_tok: 0.7312253806083623
test0_f-score_macro_tok: 0.7853244562004221
test0_precision_micro_tok: 0.8915107643132462
test0_recall_micro_tok: 0.8915107643132462
test0_f-score_micro_tok: 0.8915107643132462
test0_time: 8.518308639526367
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4474    0.0742    0.1273       229
           N     0.6475    0.7897    0.7116       428
           P     0.6673    0.8131    0.7330       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.5874    0.5590    0.5240      1101
weighted avg     0.6139    0.6503    0.5987      1101

F1-macro sent:  0.5239715650654423
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9759    0.9349     16205
           N     0.8197    0.5606    0.6658      1857
           P     0.8877    0.6572    0.7553      3212

   micro avg     0.8915    0.8915    0.8915     21274
   macro avg     0.8682    0.7312    0.7853     21274
weighted avg     0.8890    0.8915    0.8843     21274

F1-macro tok:  0.7853244562004221
F1-micro tok:  0.8915107643132462
**************************************************
test1_cost_sum: 85370.85981369019
test1_cost_avg: 38.629348331986506
test1_count_sent: 2210.0
test1_total_correct_sent: 1512.0
test1_accuracy_sent: 0.6841628959276018
test1_count_tok: 42405.0
test1_total_correct_tok: 37462.0
test1_accuracy_tok: 0.8834335573635185
test1_label=O_precision_sent: 0.3783783783783784
test1_label=O_recall_sent: 0.07197943444730077
test1_label=O_f-score_sent: 0.12095032397408208
test1_label=N_precision_sent: 0.6912045889101338
test1_label=N_recall_sent: 0.7927631578947368
test1_label=N_f-score_sent: 0.7385086823289071
test1_label=P_precision_sent: 0.6981651376146789
test1_label=P_recall_sent: 0.8371837183718371
test1_label=P_f-score_sent: 0.7613806903451725
test1_precision_macro_sent: 0.5892493683010637
test1_recall_macro_sent: 0.5673087702379583
test1_f-score_macro_sent: 0.5402798988827205
test1_precision_micro_sent: 0.6841628959276018
test1_recall_micro_sent: 0.6841628959276018
test1_f-score_micro_sent: 0.6841628959276018
test1_label=O_precision_tok: 0.8882759405124122
test1_label=O_recall_tok: 0.9762485155322208
test1_label=O_f-score_tok: 0.9301868532717934
test1_label=N_precision_tok: 0.8148148148148148
test1_label=N_recall_tok: 0.55
test1_label=N_f-score_tok: 0.6567164179104479
test1_label=P_precision_tok: 0.8842553191489362
test1_label=P_recall_tok: 0.6252444711900105
test1_label=P_f-score_tok: 0.7325284216092359
test1_precision_macro_tok: 0.8624486914920544
test1_recall_macro_tok: 0.7171643289074104
test1_f-score_macro_tok: 0.7731438975971591
test1_precision_micro_tok: 0.8834335573635185
test1_recall_micro_tok: 0.8834335573635185
test1_f-score_micro_tok: 0.8834335573635185
test1_time: 16.923099994659424
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3784    0.0720    0.1210       389
           N     0.6912    0.7928    0.7385       912
           P     0.6982    0.8372    0.7614       909

   micro avg     0.6842    0.6842    0.6842      2210
   macro avg     0.5892    0.5673    0.5403      2210
weighted avg     0.6390    0.6842    0.6392      2210

F1-macro sent:  0.5402798988827205
F1-micro sent:  0.6841628959276018
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8883    0.9762    0.9302     31998
           N     0.8148    0.5500    0.6567      3760
           P     0.8843    0.6252    0.7325      6647

   micro avg     0.8834    0.8834    0.8834     42405
   macro avg     0.8624    0.7172    0.7731     42405
weighted avg     0.8811    0.8834    0.8750     42405

F1-macro tok:  0.7731438975971591
F1-micro tok:  0.8834335573635185
**************************************************
