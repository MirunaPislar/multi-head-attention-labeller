to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.3_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.3
sentence_composition: attention
random_seed: 100
{'O': 0, 'N': 1, 'P': 2}
{'O': 0, 'N': 1, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 21:27:52.354682: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 21:27:52.455093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 8.85GiB
2019-03-28 21:27:52.455138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 21:27:52.969135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 21:27:52.969186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 21:27:52.969198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 21:27:52.969412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428530.68603515625
train_cost_avg: 50.15574508838439
train_count_sent: 8544.0
train_total_correct_sent: 4264.0
train_accuracy_sent: 0.499063670411985
train_count_tok: 163566.0
train_total_correct_tok: 126102.0
train_accuracy_tok: 0.7709548439162173
train_label=O_precision_sent: 0.20466321243523317
train_label=O_recall_sent: 0.04864532019704434
train_label=O_f-score_sent: 0.07860696517412936
train_label=N_precision_sent: 0.48504486540378866
train_label=N_recall_sent: 0.5879154078549849
train_label=N_f-score_sent: 0.5315487571701721
train_label=P_precision_sent: 0.5400385914134105
train_label=P_recall_sent: 0.6202216066481995
train_label=P_f-score_sent: 0.5773594636410521
train_precision_macro_sent: 0.40991555641747746
train_recall_macro_sent: 0.4189274449000762
train_f-score_macro_sent: 0.3958383953284512
train_precision_micro_sent: 0.499063670411985
train_recall_micro_sent: 0.499063670411985
train_f-score_micro_sent: 0.499063670411985
train_label=O_precision_tok: 0.7958588627324519
train_label=O_recall_tok: 0.9526727625113594
train_label=O_f-score_tok: 0.8672340269770676
train_label=N_precision_tok: 0.5005643340857788
train_label=N_recall_tok: 0.18736797634136038
train_label=N_f-score_tok: 0.2726713802643714
train_label=P_precision_tok: 0.5295681769836205
train_label=P_recall_tok: 0.19902466322900428
train_label=P_f-score_tok: 0.28931694703506783
train_precision_macro_tok: 0.6086637912672838
train_recall_macro_tok: 0.44635513402724136
train_f-score_macro_tok: 0.4764074514255023
train_precision_micro_tok: 0.7709548439162173
train_recall_micro_tok: 0.7709548439162173
train_f-score_micro_tok: 0.7709548439162174
train_time: 175.9349992275238
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2047    0.0486    0.0786      1624
           N     0.4850    0.5879    0.5315      3310
           P     0.5400    0.6202    0.5774      3610

   micro avg     0.4991    0.4991    0.4991      8544
   macro avg     0.4099    0.4189    0.3958      8544
weighted avg     0.4550    0.4991    0.4648      8544

F1-macro sent:  0.3958383953284512
F1-micro sent:  0.499063670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7959    0.9527    0.8672    124347
           N     0.5006    0.1874    0.2727     14202
           P     0.5296    0.1990    0.2893     25017

   micro avg     0.7710    0.7710    0.7710    163566
   macro avg     0.6087    0.4464    0.4764    163566
weighted avg     0.7295    0.7710    0.7272    163566

F1-macro tok:  0.4764074514255023
F1-micro tok:  0.7709548439162174
**************************************************
dev_cost_sum: 50824.193908691406
dev_cost_avg: 46.16184732851172
dev_count_sent: 1101.0
dev_total_correct_sent: 644.0
dev_accuracy_sent: 0.5849227974568574
dev_count_tok: 21274.0
dev_total_correct_tok: 17533.0
dev_accuracy_tok: 0.8241515464886716
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5218617771509168
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.6508355321020228
dev_label=P_precision_sent: 0.6989795918367347
dev_label=P_recall_sent: 0.6171171171171171
dev_label=P_f-score_sent: 0.6555023923444976
dev_precision_macro_sent: 0.40694712299588387
dev_recall_macro_sent: 0.4938676994751761
dev_f-score_macro_sent: 0.4354459748155068
dev_precision_micro_sent: 0.5849227974568574
dev_recall_micro_sent: 0.5849227974568574
dev_f-score_micro_sent: 0.5849227974568574
dev_label=O_precision_tok: 0.8530136679363657
dev_label=O_recall_tok: 0.939709966059858
dev_label=O_f-score_tok: 0.8942654960801011
dev_label=N_precision_tok: 0.6181075561606535
dev_label=N_recall_tok: 0.48896068928379105
dev_label=N_f-score_tok: 0.5460012026458209
dev_label=P_precision_tok: 0.7153097798259088
dev_label=P_recall_tok: 0.4349315068493151
dev_label=P_f-score_tok: 0.5409486931268151
dev_precision_macro_tok: 0.728810334640976
dev_recall_macro_tok: 0.6212007207309881
dev_f-score_macro_tok: 0.660405130617579
dev_precision_micro_tok: 0.8241515464886716
dev_recall_micro_tok: 0.8241515464886716
dev_f-score_micro_tok: 0.8241515464886716
dev_time: 12.227030038833618
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5219    0.8645    0.6508       428
           P     0.6990    0.6171    0.6555       444

   micro avg     0.5849    0.5849    0.5849      1101
   macro avg     0.4069    0.4939    0.4354      1101
weighted avg     0.4847    0.5849    0.5173      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.4354459748155068
F1-micro sent:  0.5849227974568574
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8530    0.9397    0.8943     16205
           N     0.6181    0.4890    0.5460      1857
           P     0.7153    0.4349    0.5409      3212

   micro avg     0.8242    0.8242    0.8242     21274
   macro avg     0.7288    0.6212    0.6604     21274
weighted avg     0.8117    0.8242    0.8105     21274

F1-macro tok:  0.660405130617579
F1-micro tok:  0.8241515464886716
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379061.58850097656
train_cost_avg: 44.365822624177966
train_count_sent: 8544.0
train_total_correct_sent: 4846.0
train_accuracy_sent: 0.5671816479400749
train_count_tok: 163566.0
train_total_correct_tok: 132150.0
train_accuracy_tok: 0.8079307435530612
train_label=O_precision_sent: 0.2972972972972973
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013245033112582783
train_label=N_precision_sent: 0.5348942941577631
train_label=N_recall_sent: 0.7108761329305135
train_label=N_f-score_sent: 0.6104553119730185
train_label=P_precision_sent: 0.6041869522882181
train_label=P_recall_sent: 0.6875346260387811
train_label=P_f-score_sent: 0.6431718061674009
train_precision_macro_sent: 0.4787928479144261
train_recall_macro_sent: 0.4683947193280244
train_f-score_macro_sent: 0.422290717084334
train_precision_micro_sent: 0.5671816479400749
train_recall_micro_sent: 0.5671816479400749
train_f-score_micro_sent: 0.5671816479400749
train_label=O_precision_tok: 0.8293048293048293
train_label=O_recall_tok: 0.9527531826260385
train_label=O_f-score_tok: 0.8867531923174803
train_label=N_precision_tok: 0.639757695636049
train_label=N_recall_tok: 0.3643852978453739
train_label=N_f-score_tok: 0.4643129514153695
train_label=P_precision_tok: 0.6737717908082409
train_label=P_recall_tok: 0.33988887556461606
train_label=P_f-score_tok: 0.45184260169514046
train_precision_macro_tok: 0.7142781052497065
train_recall_macro_tok: 0.5523424520120095
train_f-score_macro_tok: 0.60096958180933
train_precision_micro_tok: 0.8079307435530612
train_recall_micro_tok: 0.8079307435530612
train_f-score_micro_tok: 0.8079307435530612
train_time: 196.5836889743805
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2973    0.0068    0.0132      1624
           N     0.5349    0.7109    0.6105      3310
           P     0.6042    0.6875    0.6432      3610

   micro avg     0.5672    0.5672    0.5672      8544
   macro avg     0.4788    0.4684    0.4223      8544
weighted avg     0.5190    0.5672    0.5108      8544

F1-macro sent:  0.422290717084334
F1-micro sent:  0.5671816479400749
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8293    0.9528    0.8868    124347
           N     0.6398    0.3644    0.4643     14202
           P     0.6738    0.3399    0.4518     25017

   micro avg     0.8079    0.8079    0.8079    163566
   macro avg     0.7143    0.5523    0.6010    163566
weighted avg     0.7891    0.8079    0.7836    163566

F1-macro tok:  0.60096958180933
F1-micro tok:  0.8079307435530612
**************************************************
dev_cost_sum: 49132.01989746094
dev_cost_avg: 44.62490453901992
dev_count_sent: 1101.0
dev_total_correct_sent: 637.0
dev_accuracy_sent: 0.5785649409627611
dev_count_tok: 21274.0
dev_total_correct_tok: 17795.0
dev_accuracy_tok: 0.8364670489799756
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4969843184559711
dev_label=N_recall_sent: 0.9626168224299065
dev_label=N_f-score_sent: 0.6555290373906126
dev_label=P_precision_sent: 0.8272058823529411
dev_label=P_recall_sent: 0.5067567567567568
dev_label=P_f-score_sent: 0.6284916201117319
dev_precision_macro_sent: 0.4413967336029707
dev_recall_macro_sent: 0.48979119306222113
dev_f-score_macro_sent: 0.42800688583411484
dev_precision_micro_sent: 0.5785649409627611
dev_recall_micro_sent: 0.5785649409627611
dev_f-score_micro_sent: 0.5785649409627611
dev_label=O_precision_tok: 0.84548592384856
dev_label=O_recall_tok: 0.9674174637457574
dev_label=O_f-score_tok: 0.9023512821250755
dev_label=N_precision_tok: 0.719253604749788
dev_label=N_recall_tok: 0.45665051157781367
dev_label=N_f-score_tok: 0.5586297760210804
dev_label=P_precision_tok: 0.8177720540888602
dev_label=P_recall_tok: 0.3953922789539228
dev_label=P_f-score_tok: 0.5330535152151102
dev_precision_macro_tok: 0.7941705275624028
dev_recall_macro_tok: 0.6064867514258313
dev_f-score_macro_tok: 0.664678191120422
dev_precision_micro_tok: 0.8364670489799756
dev_recall_micro_tok: 0.8364670489799756
dev_f-score_micro_tok: 0.8364670489799756
dev_time: 11.892789840698242
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4970    0.9626    0.6555       428
           P     0.8272    0.5068    0.6285       444

   micro avg     0.5786    0.5786    0.5786      1101
   macro avg     0.4414    0.4898    0.4280      1101
weighted avg     0.5268    0.5786    0.5083      1101

F1-macro sent:  0.42800688583411484
F1-micro sent:  0.5785649409627611
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8455    0.9674    0.9024     16205
           N     0.7193    0.4567    0.5586      1857
           P     0.8178    0.3954    0.5331      3212

   micro avg     0.8365    0.8365    0.8365     21274
   macro avg     0.7942    0.6065    0.6647     21274
weighted avg     0.8303    0.8365    0.8166     21274

F1-macro tok:  0.664678191120422
F1-micro tok:  0.8364670489799756
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369130.04260253906
train_cost_avg: 43.20342258924848
train_count_sent: 8544.0
train_total_correct_sent: 5035.0
train_accuracy_sent: 0.5893024344569289
train_count_tok: 163566.0
train_total_correct_tok: 135440.0
train_accuracy_tok: 0.828044948216622
train_label=O_precision_sent: 0.34375
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013285024154589374
train_label=N_precision_sent: 0.5488155855656409
train_label=N_recall_sent: 0.7489425981873111
train_label=N_f-score_sent: 0.6334483199182318
train_label=P_precision_sent: 0.6370463078848561
train_label=P_recall_sent: 0.7049861495844876
train_label=P_f-score_sent: 0.6692965154503616
train_precision_macro_sent: 0.5098706311501656
train_recall_macro_sent: 0.48690071559552567
train_f-score_macro_sent: 0.43867661984106093
train_precision_micro_sent: 0.5893024344569289
train_recall_micro_sent: 0.5893024344569289
train_f-score_micro_sent: 0.5893024344569289
train_label=O_precision_tok: 0.8473837416703529
train_label=O_recall_tok: 0.955157744054943
train_label=O_f-score_tok: 0.8980488376576979
train_label=N_precision_tok: 0.6751972942502819
train_label=N_recall_tok: 0.4217011688494578
train_label=N_f-score_tok: 0.5191574202496533
train_label=P_precision_tok: 0.734828677583597
train_label=P_recall_tok: 0.4269097014030459
train_label=P_f-score_tok: 0.5400621981745088
train_precision_macro_tok: 0.7524699045014106
train_recall_macro_tok: 0.6012562047691489
train_f-score_macro_tok: 0.6524228186939534
train_precision_micro_tok: 0.828044948216622
train_recall_micro_tok: 0.828044948216622
train_f-score_micro_tok: 0.828044948216622
train_time: 196.59607863426208
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3438    0.0068    0.0133      1624
           N     0.5488    0.7489    0.6334      3310
           P     0.6370    0.7050    0.6693      3610

   micro avg     0.5893    0.5893    0.5893      8544
   macro avg     0.5099    0.4869    0.4387      8544
weighted avg     0.5471    0.5893    0.5307      8544

F1-macro sent:  0.43867661984106093
F1-micro sent:  0.5893024344569289
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8474    0.9552    0.8980    124347
           N     0.6752    0.4217    0.5192     14202
           P     0.7348    0.4269    0.5401     25017

   micro avg     0.8280    0.8280    0.8280    163566
   macro avg     0.7525    0.6013    0.6524    163566
weighted avg     0.8152    0.8280    0.8104    163566

F1-macro tok:  0.6524228186939534
F1-micro tok:  0.828044948216622
**************************************************
dev_cost_sum: 48159.646057128906
dev_cost_avg: 43.74173120538502
dev_count_sent: 1101.0
dev_total_correct_sent: 683.0
dev_accuracy_sent: 0.620345140781108
dev_count_tok: 21274.0
dev_total_correct_tok: 18216.0
dev_accuracy_tok: 0.8562564632885212
dev_label=O_precision_sent: 0.4074074074074074
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.0859375
dev_label=N_precision_sent: 0.578688524590164
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.6801541425818883
dev_label=P_precision_sent: 0.6875
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7026431718061673
dev_precision_macro_sent: 0.5578653106658571
dev_recall_macro_sent: 0.5304232527021573
dev_f-score_macro_sent: 0.48957827146268523
dev_precision_micro_sent: 0.620345140781108
dev_recall_micro_sent: 0.620345140781108
dev_f-score_micro_sent: 0.620345140781108
dev_label=O_precision_tok: 0.8692865105908584
dev_label=O_recall_tok: 0.9623572971305153
dev_label=O_f-score_tok: 0.9134573143944941
dev_label=N_precision_tok: 0.7104838709677419
dev_label=N_recall_tok: 0.47442110931610126
dev_label=N_f-score_tok: 0.5689376816273813
dev_label=P_precision_tok: 0.830945558739255
dev_label=P_recall_tok: 0.5417185554171855
dev_label=P_f-score_tok: 0.6558612891066716
dev_precision_macro_tok: 0.8035719800992851
dev_recall_macro_tok: 0.6594989872879341
dev_f-score_macro_tok: 0.7127520950428491
dev_precision_micro_tok: 0.8562564632885212
dev_recall_micro_tok: 0.8562564632885212
dev_f-score_micro_tok: 0.8562564632885212
dev_time: 11.590626239776611
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4074    0.0480    0.0859       229
           N     0.5787    0.8248    0.6802       428
           P     0.6875    0.7185    0.7026       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.5579    0.5304    0.4896      1101
weighted avg     0.5869    0.6203    0.5656      1101

F1-macro sent:  0.48957827146268523
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8693    0.9624    0.9135     16205
           N     0.7105    0.4744    0.5689      1857
           P     0.8309    0.5417    0.6559      3212

   micro avg     0.8563    0.8563    0.8563     21274
   macro avg     0.8036    0.6595    0.7128     21274
weighted avg     0.8496    0.8563    0.8445     21274

F1-macro tok:  0.7127520950428491
F1-micro tok:  0.8562564632885212
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361965.95153808594
train_cost_avg: 42.364928784888335
train_count_sent: 8544.0
train_total_correct_sent: 5149.0
train_accuracy_sent: 0.6026451310861424
train_count_tok: 163566.0
train_total_correct_tok: 137625.0
train_accuracy_tok: 0.841403470158835
train_label=O_precision_sent: 0.3258426966292135
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.033858727378867484
train_label=N_precision_sent: 0.5716582452916859
train_label=N_recall_sent: 0.751963746223565
train_label=N_f-score_sent: 0.6495302713987474
train_label=P_precision_sent: 0.6415508412582297
train_label=P_recall_sent: 0.728808864265928
train_label=P_f-score_sent: 0.6824017637141745
train_precision_macro_sent: 0.5130172610597097
train_recall_macro_sent: 0.4995432511155453
train_f-score_macro_sent: 0.4552635874972631
train_precision_micro_sent: 0.6026451310861424
train_recall_micro_sent: 0.6026451310861424
train_f-score_micro_sent: 0.6026451310861424
train_label=O_precision_tok: 0.8587190740780778
train_label=O_recall_tok: 0.9582458764586198
train_label=O_f-score_tok: 0.9057566152045183
train_label=N_precision_tok: 0.6955082220505463
train_label=N_recall_tok: 0.4437403182650331
train_label=N_f-score_tok: 0.5418045823840433
train_label=P_precision_tok: 0.7727676870316271
train_label=P_recall_tok: 0.48638925530639165
train_label=P_f-score_tok: 0.597011996173
train_precision_macro_tok: 0.7756649943867503
train_recall_macro_tok: 0.6294584833433482
train_f-score_macro_tok: 0.6815243979205206
train_precision_micro_tok: 0.841403470158835
train_recall_micro_tok: 0.841403470158835
train_f-score_micro_tok: 0.841403470158835
train_time: 198.97800850868225
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3258    0.0179    0.0339      1624
           N     0.5717    0.7520    0.6495      3310
           P     0.6416    0.7288    0.6824      3610

   micro avg     0.6026    0.6026    0.6026      8544
   macro avg     0.5130    0.4995    0.4553      8544
weighted avg     0.5545    0.6026    0.5464      8544

F1-macro sent:  0.4552635874972631
F1-micro sent:  0.6026451310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8587    0.9582    0.9058    124347
           N     0.6955    0.4437    0.5418     14202
           P     0.7728    0.4864    0.5970     25017

   micro avg     0.8414    0.8414    0.8414    163566
   macro avg     0.7757    0.6295    0.6815    163566
weighted avg     0.8314    0.8414    0.8269    163566

F1-macro tok:  0.6815243979205206
F1-micro tok:  0.841403470158835
**************************************************
dev_cost_sum: 47448.65808105469
dev_cost_avg: 43.09596555954104
dev_count_sent: 1101.0
dev_total_correct_sent: 695.0
dev_accuracy_sent: 0.631244323342416
dev_count_tok: 21274.0
dev_total_correct_tok: 18400.0
dev_accuracy_tok: 0.8649055184732537
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6219739292364991
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.6922279792746113
dev_label=P_precision_sent: 0.6412078152753108
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7169811320754716
dev_precision_macro_sent: 0.4210605815039366
dev_recall_macro_sent: 0.5311456316129214
dev_f-score_macro_sent: 0.4697363704500277
dev_precision_micro_sent: 0.631244323342416
dev_recall_micro_sent: 0.631244323342416
dev_f-score_micro_sent: 0.631244323342416
dev_label=O_precision_tok: 0.8772244989614326
dev_label=O_recall_tok: 0.9642702869484727
dev_label=O_f-score_tok: 0.9186901052384031
dev_label=N_precision_tok: 0.7606986899563318
dev_label=N_recall_tok: 0.46903607969843836
dev_label=N_f-score_tok: 0.5802798134576949
dev_label=P_precision_tok: 0.8216753022452504
dev_label=P_recall_tok: 0.5924657534246576
dev_label=P_f-score_tok: 0.6884949348769898
dev_precision_macro_tok: 0.819866163721005
dev_recall_macro_tok: 0.6752573733571895
dev_f-score_macro_tok: 0.7291549511910294
dev_precision_micro_tok: 0.8649055184732537
dev_recall_micro_tok: 0.8649055184732537
dev_f-score_micro_tok: 0.8649055184732537
dev_time: 11.660937309265137
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6220    0.7804    0.6922       428
           P     0.6412    0.8131    0.7170       444

   micro avg     0.6312    0.6312    0.6312      1101
   macro avg     0.4211    0.5311    0.4697      1101
weighted avg     0.5004    0.6312    0.5582      1101

F1-macro sent:  0.4697363704500277
F1-micro sent:  0.631244323342416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8772    0.9643    0.9187     16205
           N     0.7607    0.4690    0.5803      1857
           P     0.8217    0.5925    0.6885      3212

   micro avg     0.8649    0.8649    0.8649     21274
   macro avg     0.8199    0.6753    0.7292     21274
weighted avg     0.8587    0.8649    0.8544     21274

F1-macro tok:  0.7291549511910294
F1-micro tok:  0.8649055184732537
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 356208.3934326172
train_cost_avg: 41.691057283780104
train_count_sent: 8544.0
train_total_correct_sent: 5211.0
train_accuracy_sent: 0.6099016853932584
train_count_tok: 163566.0
train_total_correct_tok: 139059.0
train_accuracy_tok: 0.850170573346539
train_label=O_precision_sent: 0.28225806451612906
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.04004576659038902
train_label=N_precision_sent: 0.5769320027848689
train_label=N_recall_sent: 0.7510574018126889
train_label=N_f-score_sent: 0.6525790786192414
train_label=P_precision_sent: 0.6543420092434931
train_label=P_recall_sent: 0.7451523545706371
train_label=P_f-score_sent: 0.6968009325216941
train_precision_macro_sent: 0.504510692181497
train_recall_macro_sent: 0.5059204935070857
train_f-score_macro_sent: 0.46314192591044145
train_precision_micro_sent: 0.6099016853932584
train_recall_micro_sent: 0.6099016853932584
train_f-score_micro_sent: 0.6099016853932584
train_label=O_precision_tok: 0.8655052517203912
train_label=O_recall_tok: 0.9608836562200938
train_label=O_f-score_tok: 0.9107040095732801
train_label=N_precision_tok: 0.7061356297093649
train_label=N_recall_tok: 0.4619067736938459
train_label=N_f-score_tok: 0.5584879959135024
train_label=P_precision_tok: 0.8021693578207815
train_label=P_recall_tok: 0.5202862053803413
train_label=P_f-score_tok: 0.6311858982130301
train_precision_macro_tok: 0.7912700797501793
train_recall_macro_tok: 0.6476922117647602
train_f-score_macro_tok: 0.7001259678999375
train_precision_micro_tok: 0.850170573346539
train_recall_micro_tok: 0.850170573346539
train_f-score_micro_tok: 0.850170573346539
train_time: 196.7998812198639
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2823    0.0216    0.0400      1624
           N     0.5769    0.7511    0.6526      3310
           P     0.6543    0.7452    0.6968      3610

   micro avg     0.6099    0.6099    0.6099      8544
   macro avg     0.5045    0.5059    0.4631      8544
weighted avg     0.5536    0.6099    0.5548      8544

F1-macro sent:  0.46314192591044145
F1-micro sent:  0.6099016853932584
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8655    0.9609    0.9107    124347
           N     0.7061    0.4619    0.5585     14202
           P     0.8022    0.5203    0.6312     25017

   micro avg     0.8502    0.8502    0.8502    163566
   macro avg     0.7913    0.6477    0.7001    163566
weighted avg     0.8420    0.8502    0.8374    163566

F1-macro tok:  0.7001259678999375
F1-micro tok:  0.850170573346539
**************************************************
dev_cost_sum: 46826.37072753906
dev_cost_avg: 42.53076360357771
dev_count_sent: 1101.0
dev_total_correct_sent: 668.0
dev_accuracy_sent: 0.6067211625794732
dev_count_tok: 21274.0
dev_total_correct_tok: 18503.0
dev_accuracy_tok: 0.869747109147316
dev_label=O_precision_sent: 0.2857142857142857
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.03292181069958847
dev_label=N_precision_sent: 0.6724565756823822
dev_label=N_recall_sent: 0.633177570093458
dev_label=N_f-score_sent: 0.6522262334536703
dev_label=P_precision_sent: 0.5745614035087719
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.6968085106382979
dev_precision_macro_sent: 0.5109107549684799
dev_recall_macro_sent: 0.5119266513789634
dev_f-score_macro_sent: 0.4606521849305188
dev_precision_micro_sent: 0.6067211625794732
dev_recall_micro_sent: 0.6067211625794732
dev_f-score_micro_sent: 0.6067211625794732
dev_label=O_precision_tok: 0.8827983725135624
dev_label=O_recall_tok: 0.9640234495526072
dev_label=O_f-score_tok: 0.9216247308338987
dev_label=N_precision_tok: 0.7276720351390923
dev_label=N_recall_tok: 0.535271943995692
dev_label=N_f-score_tok: 0.6168166304685077
dev_label=P_precision_tok: 0.8530741410488246
dev_label=P_recall_tok: 0.5874844333748444
dev_label=P_f-score_tok: 0.6957964601769911
dev_precision_macro_tok: 0.8211815162338264
dev_recall_macro_tok: 0.6955932756410479
dev_f-score_macro_tok: 0.7447459404931326
dev_precision_micro_tok: 0.869747109147316
dev_recall_micro_tok: 0.869747109147316
dev_f-score_micro_tok: 0.8697471091473159
dev_time: 11.679489374160767
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0175    0.0329       229
           N     0.6725    0.6332    0.6522       428
           P     0.5746    0.8851    0.6968       444

   micro avg     0.6067    0.6067    0.6067      1101
   macro avg     0.5109    0.5119    0.4607      1101
weighted avg     0.5525    0.6067    0.5414      1101

F1-macro sent:  0.4606521849305188
F1-micro sent:  0.6067211625794732
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8828    0.9640    0.9216     16205
           N     0.7277    0.5353    0.6168      1857
           P     0.8531    0.5875    0.6958      3212

   micro avg     0.8697    0.8697    0.8697     21274
   macro avg     0.8212    0.6956    0.7447     21274
weighted avg     0.8648    0.8697    0.8609     21274

F1-macro tok:  0.7447459404931326
F1-micro tok:  0.8697471091473159
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351367.3436279297
train_cost_avg: 41.12445501263222
train_count_sent: 8544.0
train_total_correct_sent: 5276.0
train_accuracy_sent: 0.6175093632958801
train_count_tok: 163566.0
train_total_correct_tok: 140184.0
train_accuracy_tok: 0.8570485308682734
train_label=O_precision_sent: 0.3248407643312102
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05727119595732735
train_label=N_precision_sent: 0.6012376237623762
train_label=N_recall_sent: 0.7338368580060423
train_label=N_f-score_sent: 0.660952380952381
train_label=P_precision_sent: 0.6432022084195997
train_label=P_recall_sent: 0.7745152354570637
train_label=P_f-score_sent: 0.7027774286791504
train_precision_macro_sent: 0.523093532171062
train_recall_macro_sent: 0.5132520114499352
train_f-score_macro_sent: 0.4736670018629529
train_precision_micro_sent: 0.6175093632958801
train_recall_micro_sent: 0.6175093632958801
train_f-score_micro_sent: 0.6175093632958801
train_label=O_precision_tok: 0.8712793505775553
train_label=O_recall_tok: 0.9632721336260626
train_label=O_f-score_tok: 0.9149692731349042
train_label=N_precision_tok: 0.7231439236831191
train_label=N_recall_tok: 0.4910575975214759
train_label=N_f-score_tok: 0.5849199027090498
train_label=P_precision_tok: 0.8166119421135839
train_label=P_recall_tok: 0.5368349522324819
train_label=P_f-score_tok: 0.6478064780647806
train_precision_macro_tok: 0.8036784054580862
train_recall_macro_tok: 0.6637215611266735
train_f-score_macro_tok: 0.7158985513029116
train_precision_micro_tok: 0.8570485308682734
train_recall_micro_tok: 0.8570485308682734
train_f-score_micro_tok: 0.8570485308682734
train_time: 197.41993689537048
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3248    0.0314    0.0573      1624
           N     0.6012    0.7338    0.6610      3310
           P     0.6432    0.7745    0.7028      3610

   micro avg     0.6175    0.6175    0.6175      8544
   macro avg     0.5231    0.5133    0.4737      8544
weighted avg     0.5664    0.6175    0.5639      8544

F1-macro sent:  0.4736670018629529
F1-micro sent:  0.6175093632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8713    0.9633    0.9150    124347
           N     0.7231    0.4911    0.5849     14202
           P     0.8166    0.5368    0.6478     25017

   micro avg     0.8570    0.8570    0.8570    163566
   macro avg     0.8037    0.6637    0.7159    163566
weighted avg     0.8501    0.8570    0.8455    163566

F1-macro tok:  0.7158985513029116
F1-micro tok:  0.8570485308682734
**************************************************
dev_cost_sum: 46341.78991699219
dev_cost_avg: 42.0906357102563
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18594.0
dev_accuracy_tok: 0.8740246310049826
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5839753466872111
dev_label=N_recall_sent: 0.8855140186915887
dev_label=N_f-score_sent: 0.70380687093779
dev_label=P_precision_sent: 0.7057522123893806
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7120535714285714
dev_precision_macro_sent: 0.42990918635886394
dev_recall_macro_sent: 0.5346608290533524
dev_f-score_macro_sent: 0.4719534807887871
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8762436435993809
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9244540338805143
dev_label=N_precision_tok: 0.7912541254125413
dev_label=N_recall_tok: 0.5164243403338719
dev_label=N_f-score_tok: 0.6249592701205605
dev_label=P_precision_tok: 0.9045685279187817
dev_label=P_recall_tok: 0.5547945205479452
dev_label=P_f-score_tok: 0.6877653415669626
dev_precision_macro_tok: 0.8573554323102347
dev_recall_macro_tok: 0.6831657233485519
dev_f-score_macro_tok: 0.7457262151893458
dev_precision_micro_tok: 0.8740246310049826
dev_recall_micro_tok: 0.8740246310049826
dev_f-score_micro_tok: 0.8740246310049826
dev_time: 11.956536769866943
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5840    0.8855    0.7038       428
           P     0.7058    0.7185    0.7121       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.4299    0.5347    0.4720      1101
weighted avg     0.5116    0.6340    0.5607      1101

F1-macro sent:  0.4719534807887871
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8762    0.9783    0.9245     16205
           N     0.7913    0.5164    0.6250      1857
           P     0.9046    0.5548    0.6878      3212

   micro avg     0.8740    0.8740    0.8740     21274
   macro avg     0.8574    0.6832    0.7457     21274
weighted avg     0.8731    0.8740    0.8626     21274

F1-macro tok:  0.7457262151893458
F1-micro tok:  0.8740246310049826
**************************************************
Best epoch: 2
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347320.2941894531
train_cost_avg: 40.650783495956595
train_count_sent: 8544.0
train_total_correct_sent: 5322.0
train_accuracy_sent: 0.6228932584269663
train_count_tok: 163566.0
train_total_correct_tok: 140987.0
train_accuracy_tok: 0.8619578641037868
train_label=O_precision_sent: 0.21428571428571427
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.01770956316410862
train_label=N_precision_sent: 0.6034229828850856
train_label=N_recall_sent: 0.7456193353474321
train_label=N_f-score_sent: 0.6670270270270271
train_label=P_precision_sent: 0.6475821167883211
train_label=P_recall_sent: 0.7864265927977839
train_label=P_f-score_sent: 0.7102827120340256
train_precision_macro_sent: 0.488430271319707
train_recall_macro_sent: 0.5137607937823955
train_f-score_macro_sent: 0.46500643407505377
train_precision_micro_sent: 0.6228932584269663
train_recall_micro_sent: 0.6228932584269663
train_f-score_micro_sent: 0.6228932584269663
train_label=O_precision_tok: 0.8747467828672195
train_label=O_recall_tok: 0.9654032666650583
train_label=O_f-score_tok: 0.917841892186359
train_label=N_precision_tok: 0.7345087647778231
train_label=N_recall_tok: 0.5074637375017603
train_label=N_f-score_tok: 0.6002331973015742
train_label=P_precision_tok: 0.8314164648910412
train_label=P_recall_tok: 0.5490266618699284
train_label=P_f-score_tok: 0.6613380841177745
train_precision_macro_tok: 0.813557337512028
train_recall_macro_tok: 0.6739645553455823
train_f-score_macro_tok: 0.7264710578685692
train_precision_micro_tok: 0.8619578641037868
train_recall_micro_tok: 0.8619578641037868
train_f-score_micro_tok: 0.8619578641037867
train_time: 196.52116799354553
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2143    0.0092    0.0177      1624
           N     0.6034    0.7456    0.6670      3310
           P     0.6476    0.7864    0.7103      3610

   micro avg     0.6229    0.6229    0.6229      8544
   macro avg     0.4884    0.5138    0.4650      8544
weighted avg     0.5481    0.6229    0.5619      8544

F1-macro sent:  0.46500643407505377
F1-micro sent:  0.6228932584269663
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8747    0.9654    0.9178    124347
           N     0.7345    0.5075    0.6002     14202
           P     0.8314    0.5490    0.6613     25017

   micro avg     0.8620    0.8620    0.8620    163566
   macro avg     0.8136    0.6740    0.7265    163566
weighted avg     0.8559    0.8620    0.8510    163566

F1-macro tok:  0.7264710578685692
F1-micro tok:  0.8619578641037867
**************************************************
dev_cost_sum: 46025.76647949219
dev_cost_avg: 41.803602615342584
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 18630.0
dev_accuracy_tok: 0.8757168374541694
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6727688787185355
dev_label=N_recall_sent: 0.6869158878504673
dev_label=N_f-score_sent: 0.6797687861271676
dev_label=P_precision_sent: 0.5984848484848485
dev_label=P_recall_sent: 0.8896396396396397
dev_label=P_f-score_sent: 0.7155797101449275
dev_precision_macro_sent: 0.6737512424011279
dev_recall_macro_sent: 0.5298853213904432
dev_f-score_macro_sent: 0.47369985641115614
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.8757852970351593
dev_label=O_recall_tok: 0.9806849737735267
dev_label=O_f-score_tok: 0.9252714622572851
dev_label=N_precision_tok: 0.8365758754863813
dev_label=N_recall_tok: 0.4631125471190092
dev_label=N_f-score_tok: 0.5961871750433276
dev_label=P_precision_tok: 0.8942857142857142
dev_label=P_recall_tok: 0.5846824408468244
dev_label=P_f-score_tok: 0.7070783132530121
dev_precision_macro_tok: 0.8688822956024183
dev_recall_macro_tok: 0.6761599872464533
dev_f-score_macro_tok: 0.7428456501845416
dev_precision_micro_tok: 0.8757168374541694
dev_recall_micro_tok: 0.8757168374541694
dev_f-score_micro_tok: 0.8757168374541694
dev_time: 12.030603647232056
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6728    0.6869    0.6798       428
           P     0.5985    0.8896    0.7156       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.6738    0.5299    0.4737      1101
weighted avg     0.6589    0.6285    0.5582      1101

F1-macro sent:  0.47369985641115614
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8758    0.9807    0.9253     16205
           N     0.8366    0.4631    0.5962      1857
           P     0.8943    0.5847    0.7071      3212

   micro avg     0.8757    0.8757    0.8757     21274
   macro avg     0.8689    0.6762    0.7428     21274
weighted avg     0.8752    0.8757    0.8636     21274

F1-macro tok:  0.7428456501845416
F1-micro tok:  0.8757168374541694
**************************************************
Best epoch: 2
**************************************************

EPOCH: 7
Learning rate: 0.900000
train_cost_sum: 343136.3596191406
train_cost_avg: 40.1610907793938
train_count_sent: 8544.0
train_total_correct_sent: 5395.0
train_accuracy_sent: 0.631437265917603
train_count_tok: 163566.0
train_total_correct_tok: 141626.0
train_accuracy_tok: 0.865864543976132
train_label=O_precision_sent: 0.47368421052631576
train_label=O_recall_sent: 0.011083743842364532
train_label=O_f-score_sent: 0.021660649819494584
train_label=N_precision_sent: 0.6136587771203156
train_label=N_recall_sent: 0.751963746223565
train_label=N_f-score_sent: 0.6758077654086343
train_label=P_precision_sent: 0.6489887640449438
train_label=P_recall_sent: 0.8
train_label=P_f-score_sent: 0.7166253101736972
train_precision_macro_sent: 0.5787772505638583
train_recall_macro_sent: 0.5210158300219766
train_f-score_macro_sent: 0.471364575133942
train_precision_micro_sent: 0.631437265917603
train_recall_micro_sent: 0.631437265917603
train_f-score_micro_sent: 0.631437265917603
train_label=O_precision_tok: 0.878031493186219
train_label=O_recall_tok: 0.9663522240182715
train_label=O_f-score_tok: 0.9200771816448572
train_label=N_precision_tok: 0.7432743274327432
train_label=N_recall_tok: 0.5233065765385158
train_label=N_f-score_tok: 0.6141894963018057
train_label=P_precision_tok: 0.839576352321685
train_label=P_recall_tok: 0.5608586161410241
train_label=P_f-score_tok: 0.6724819669774018
train_precision_macro_tok: 0.8202940576468825
train_recall_macro_tok: 0.6835058055659372
train_f-score_macro_tok: 0.7355828816413549
train_precision_micro_tok: 0.865864543976132
train_recall_micro_tok: 0.865864543976132
train_f-score_micro_tok: 0.865864543976132
train_time: 197.5037076473236
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4737    0.0111    0.0217      1624
           N     0.6137    0.7520    0.6758      3310
           P     0.6490    0.8000    0.7166      3610

   micro avg     0.6314    0.6314    0.6314      8544
   macro avg     0.5788    0.5210    0.4714      8544
weighted avg     0.6020    0.6314    0.5687      8544

F1-macro sent:  0.471364575133942
F1-micro sent:  0.631437265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8780    0.9664    0.9201    124347
           N     0.7433    0.5233    0.6142     14202
           P     0.8396    0.5609    0.6725     25017

   micro avg     0.8659    0.8659    0.8659    163566
   macro avg     0.8203    0.6835    0.7356    163566
weighted avg     0.8604    0.8659    0.8556    163566

F1-macro tok:  0.7355828816413549
F1-micro tok:  0.865864543976132
**************************************************
dev_cost_sum: 45476.94873046875
dev_cost_avg: 41.30513054538488
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18752.0
dev_accuracy_tok: 0.8814515370875247
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5854037267080745
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7033582089552238
dev_label=P_precision_sent: 0.7026431718061674
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7104677060133631
dev_precision_macro_sent: 0.6515711883936361
dev_recall_macro_sent: 0.5360144048059814
dev_f-score_macro_sent: 0.47702243142631057
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8828989051297726
dev_label=O_recall_tok: 0.9803147176797284
dev_label=O_f-score_tok: 0.9290601789578338
dev_label=N_precision_tok: 0.7991701244813278
dev_label=N_recall_tok: 0.518578352180937
dev_label=N_f-score_tok: 0.6290006531678642
dev_label=P_precision_tok: 0.9166666666666666
dev_label=P_recall_tok: 0.5924657534246576
dev_label=P_f-score_tok: 0.7197428139183056
dev_precision_macro_tok: 0.866245232092589
dev_recall_macro_tok: 0.6971196077617744
dev_f-score_macro_tok: 0.7592678820146679
dev_precision_micro_tok: 0.8814515370875247
dev_recall_micro_tok: 0.8814515370875247
dev_f-score_micro_tok: 0.8814515370875247
dev_time: 11.676684617996216
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5854    0.8808    0.7034       428
           P     0.7026    0.7185    0.7105       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.6516    0.5360    0.4770      1101
weighted avg     0.6496    0.6340    0.5635      1101

F1-macro sent:  0.47702243142631057
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8829    0.9803    0.9291     16205
           N     0.7992    0.5186    0.6290      1857
           P     0.9167    0.5925    0.7197      3212

   micro avg     0.8815    0.8815    0.8815     21274
   macro avg     0.8662    0.6971    0.7593     21274
weighted avg     0.8807    0.8815    0.8713     21274

F1-macro tok:  0.7592678820146679
F1-micro tok:  0.8814515370875247
**************************************************
Best epoch: 2
**************************************************

EPOCH: 8
Learning rate: 0.810000
train_cost_sum: 339912.94512939453
train_cost_avg: 39.783818484245614
train_count_sent: 8544.0
train_total_correct_sent: 5471.0
train_accuracy_sent: 0.6403323970037453
train_count_tok: 163566.0
train_total_correct_tok: 142242.0
train_accuracy_tok: 0.8696306078280327
train_label=O_precision_sent: 0.38461538461538464
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.018039687312086595
train_label=N_precision_sent: 0.6151990349819059
train_label=N_recall_sent: 0.770392749244713
train_label=N_f-score_sent: 0.6841046277665995
train_label=P_precision_sent: 0.6665137614678899
train_label=P_recall_sent: 0.8049861495844876
train_label=P_f-score_sent: 0.7292346298619824
train_precision_macro_sent: 0.5554427270217267
train_recall_macro_sent: 0.5282051173437237
train_f-score_macro_sent: 0.4771263149802228
train_precision_micro_sent: 0.6403323970037453
train_recall_micro_sent: 0.6403323970037453
train_f-score_micro_sent: 0.6403323970037453
train_label=O_precision_tok: 0.8810342808630229
train_label=O_recall_tok: 0.9681053825182755
train_label=O_f-score_tok: 0.922519857615247
train_label=N_precision_tok: 0.7504956383822363
train_label=N_recall_tok: 0.5330939304323334
train_label=N_f-score_tok: 0.6233841086867024
train_label=P_precision_tok: 0.8484740529628311
train_label=P_recall_tok: 0.5712115761282328
train_label=P_f-score_tok: 0.6827683413363912
train_precision_macro_tok: 0.8266679907360301
train_recall_macro_tok: 0.6908036296929473
train_f-score_macro_tok: 0.7428907692127802
train_precision_micro_tok: 0.8696306078280327
train_recall_micro_tok: 0.8696306078280327
train_f-score_micro_tok: 0.8696306078280327
train_time: 201.0109031200409
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.0092    0.0180      1624
           N     0.6152    0.7704    0.6841      3310
           P     0.6665    0.8050    0.7292      3610

   micro avg     0.6403    0.6403    0.6403      8544
   macro avg     0.5554    0.5282    0.4771      8544
weighted avg     0.5931    0.6403    0.5766      8544

F1-macro sent:  0.4771263149802228
F1-micro sent:  0.6403323970037453
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8810    0.9681    0.9225    124347
           N     0.7505    0.5331    0.6234     14202
           P     0.8485    0.5712    0.6828     25017

   micro avg     0.8696    0.8696    0.8696    163566
   macro avg     0.8267    0.6908    0.7429    163566
weighted avg     0.8647    0.8696    0.8599    163566

F1-macro tok:  0.7428907692127802
F1-micro tok:  0.8696306078280327
**************************************************
dev_cost_sum: 45216.755432128906
dev_cost_avg: 41.06880602373197
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18791.0
dev_accuracy_tok: 0.8832847607408104
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.610648918469218
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7133138969873662
dev_label=P_precision_sent: 0.678714859437751
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.7176220806794056
dev_precision_macro_sent: 0.5964545926356563
dev_recall_macro_sent: 0.5410349030007847
dev_f-score_macro_sent: 0.4798646621082601
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8852138992693401
dev_label=O_recall_tok: 0.979389077445233
dev_label=O_f-score_tok: 0.9299232436866467
dev_label=N_precision_tok: 0.7851112816577129
dev_label=N_recall_tok: 0.5508885298869144
dev_label=N_f-score_tok: 0.6474683544303798
dev_label=P_precision_tok: 0.9289911851126347
dev_label=P_recall_tok: 0.5905977584059776
dev_label=P_f-score_tok: 0.7221164826798631
dev_precision_macro_tok: 0.8664387886798958
dev_recall_macro_tok: 0.7069584552460416
dev_f-score_macro_tok: 0.7665026935989632
dev_precision_micro_tok: 0.8832847607408104
dev_recall_micro_tok: 0.8832847607408104
dev_f-score_micro_tok: 0.8832847607408104
dev_time: 15.383882284164429
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6106    0.8575    0.7133       428
           P     0.6787    0.7613    0.7176       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.5965    0.5410    0.4799      1101
weighted avg     0.6151    0.6412    0.5685      1101

F1-macro sent:  0.4798646621082601
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8852    0.9794    0.9299     16205
           N     0.7851    0.5509    0.6475      1857
           P     0.9290    0.5906    0.7221      3212

   micro avg     0.8833    0.8833    0.8833     21274
   macro avg     0.8664    0.7070    0.7665     21274
weighted avg     0.8831    0.8833    0.8739     21274

F1-macro tok:  0.7665026935989632
F1-micro tok:  0.8832847607408104
**************************************************
Best epoch: 2
**************************************************

EPOCH: 9
Learning rate: 0.729000
train_cost_sum: 337415.4910888672
train_cost_avg: 39.49151347013895
train_count_sent: 8544.0
train_total_correct_sent: 5477.0
train_accuracy_sent: 0.6410346441947565
train_count_tok: 163566.0
train_total_correct_tok: 142615.0
train_accuracy_tok: 0.8719110328552389
train_label=O_precision_sent: 0.5272727272727272
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.03454437164979154
train_label=N_precision_sent: 0.6013057181449797
train_label=N_recall_sent: 0.8069486404833837
train_label=N_f-score_sent: 0.6891124871001032
train_label=P_precision_sent: 0.6861872992340005
train_label=P_recall_sent: 0.7692520775623268
train_label=P_f-score_sent: 0.7253493535327151
train_precision_macro_sent: 0.6049219148839025
train_recall_macro_sent: 0.5313526203009511
train_f-score_macro_sent: 0.48300207076087
train_precision_micro_sent: 0.6410346441947565
train_recall_micro_sent: 0.6410346441947565
train_f-score_micro_sent: 0.6410346441947565
train_label=O_precision_tok: 0.8832178344883218
train_label=O_recall_tok: 0.968579861194882
train_label=O_f-score_tok: 0.9239313878916198
train_label=N_precision_tok: 0.7516192345436703
train_label=N_recall_tok: 0.5392902408111534
train_label=N_f-score_tok: 0.6279927845195147
train_label=P_precision_tok: 0.8533301981071072
train_label=P_recall_tok: 0.5802454331054883
train_label=P_f-score_tok: 0.6907775768535263
train_precision_macro_tok: 0.8293890890463665
train_recall_macro_tok: 0.6960385117038412
train_f-score_macro_tok: 0.7475672497548868
train_precision_micro_tok: 0.8719110328552389
train_recall_micro_tok: 0.8719110328552389
train_f-score_micro_tok: 0.8719110328552389
train_time: 248.34448385238647
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5273    0.0179    0.0345      1624
           N     0.6013    0.8069    0.6891      3310
           P     0.6862    0.7693    0.7253      3610

   micro avg     0.6410    0.6410    0.6410      8544
   macro avg     0.6049    0.5314    0.4830      8544
weighted avg     0.6231    0.6410    0.5800      8544

F1-macro sent:  0.48300207076087
F1-micro sent:  0.6410346441947565
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8832    0.9686    0.9239    124347
           N     0.7516    0.5393    0.6280     14202
           P     0.8533    0.5802    0.6908     25017

   micro avg     0.8719    0.8719    0.8719    163566
   macro avg     0.8294    0.6960    0.7476    163566
weighted avg     0.8672    0.8719    0.8626    163566

F1-macro tok:  0.7475672497548868
F1-micro tok:  0.8719110328552389
**************************************************
dev_cost_sum: 45012.05895996094
dev_cost_avg: 40.882887338747445
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18782.0
dev_accuracy_tok: 0.8828617091285137
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5779816513761468
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.6987060998151571
dev_label=P_precision_sent: 0.7056179775280899
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7064116985376828
dev_precision_macro_sent: 0.7611998763014122
dev_recall_macro_sent: 0.5330394672516046
dev_f-score_macro_sent: 0.4741446052229524
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8798699509560809
dev_label=O_recall_tok: 0.9853131749460043
dev_label=O_f-score_tok: 0.929611085235212
dev_label=N_precision_tok: 0.8324225865209471
dev_label=N_recall_tok: 0.4921917070543888
dev_label=N_f-score_tok: 0.6186125211505922
dev_label=P_precision_tok: 0.936914736323312
dev_label=P_recall_tok: 0.5918430884184309
dev_label=P_f-score_tok: 0.7254340774661324
dev_precision_macro_tok: 0.8830690912667799
dev_recall_macro_tok: 0.6897826568062747
dev_f-score_macro_tok: 0.7578858946173122
dev_precision_micro_tok: 0.8828617091285137
dev_recall_micro_tok: 0.8828617091285137
dev_f-score_micro_tok: 0.8828617091285137
dev_time: 14.12285566329956
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5780    0.8832    0.6987       428
           P     0.7056    0.7072    0.7064       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.7612    0.5330    0.4741      1101
weighted avg     0.7172    0.6303    0.5601      1101

F1-macro sent:  0.4741446052229524
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8799    0.9853    0.9296     16205
           N     0.8324    0.4922    0.6186      1857
           P     0.9369    0.5918    0.7254      3212

   micro avg     0.8829    0.8829    0.8829     21274
   macro avg     0.8831    0.6898    0.7579     21274
weighted avg     0.8843    0.8829    0.8716     21274

F1-macro tok:  0.7578858946173122
F1-micro tok:  0.8828617091285137
**************************************************
Best epoch: 2
**************************************************

test0_cost_sum: 48159.64630126953
test0_cost_avg: 43.74173142712946
test0_count_sent: 1101.0
test0_total_correct_sent: 683.0
test0_accuracy_sent: 0.620345140781108
test0_count_tok: 21274.0
test0_total_correct_tok: 18216.0
test0_accuracy_tok: 0.8562564632885212
test0_label=O_precision_sent: 0.4074074074074074
test0_label=O_recall_sent: 0.048034934497816595
test0_label=O_f-score_sent: 0.0859375
test0_label=N_precision_sent: 0.578688524590164
test0_label=N_recall_sent: 0.8247663551401869
test0_label=N_f-score_sent: 0.6801541425818883
test0_label=P_precision_sent: 0.6875
test0_label=P_recall_sent: 0.7184684684684685
test0_label=P_f-score_sent: 0.7026431718061673
test0_precision_macro_sent: 0.5578653106658571
test0_recall_macro_sent: 0.5304232527021573
test0_f-score_macro_sent: 0.48957827146268523
test0_precision_micro_sent: 0.620345140781108
test0_recall_micro_sent: 0.620345140781108
test0_f-score_micro_sent: 0.620345140781108
test0_label=O_precision_tok: 0.8692865105908584
test0_label=O_recall_tok: 0.9623572971305153
test0_label=O_f-score_tok: 0.9134573143944941
test0_label=N_precision_tok: 0.7104838709677419
test0_label=N_recall_tok: 0.47442110931610126
test0_label=N_f-score_tok: 0.5689376816273813
test0_label=P_precision_tok: 0.830945558739255
test0_label=P_recall_tok: 0.5417185554171855
test0_label=P_f-score_tok: 0.6558612891066716
test0_precision_macro_tok: 0.8035719800992851
test0_recall_macro_tok: 0.6594989872879341
test0_f-score_macro_tok: 0.7127520950428491
test0_precision_micro_tok: 0.8562564632885212
test0_recall_micro_tok: 0.8562564632885212
test0_f-score_micro_tok: 0.8562564632885212
test0_time: 13.206799745559692
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4074    0.0480    0.0859       229
           N     0.5787    0.8248    0.6802       428
           P     0.6875    0.7185    0.7026       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.5579    0.5304    0.4896      1101
weighted avg     0.5869    0.6203    0.5656      1101

F1-macro sent:  0.48957827146268523
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8693    0.9624    0.9135     16205
           N     0.7105    0.4744    0.5689      1857
           P     0.8309    0.5417    0.6559      3212

   micro avg     0.8563    0.8563    0.8563     21274
   macro avg     0.8036    0.6595    0.7128     21274
weighted avg     0.8496    0.8563    0.8445     21274

F1-macro tok:  0.7127520950428491
F1-micro tok:  0.8562564632885212
**************************************************
test1_cost_sum: 93507.56141281128
test1_cost_avg: 42.311113761453065
test1_count_sent: 2210.0
test1_total_correct_sent: 1430.0
test1_accuracy_sent: 0.6470588235294118
test1_count_tok: 42405.0
test1_total_correct_tok: 36162.0
test1_accuracy_tok: 0.8527767951892465
test1_label=O_precision_sent: 0.3793103448275862
test1_label=O_recall_sent: 0.08483290488431877
test1_label=O_f-score_sent: 0.13865546218487396
test1_label=N_precision_sent: 0.6140637775960752
test1_label=N_recall_sent: 0.8234649122807017
test1_label=N_f-score_sent: 0.703512880562061
test1_label=P_precision_sent: 0.7177777777777777
test1_label=P_recall_sent: 0.7106710671067107
test1_label=P_f-score_sent: 0.7142067440574902
test1_precision_macro_sent: 0.5703839667338131
test1_recall_macro_sent: 0.5396562947572437
test1_f-score_macro_sent: 0.518791695601475
test1_precision_micro_sent: 0.6470588235294118
test1_recall_micro_sent: 0.6470588235294118
test1_f-score_micro_sent: 0.6470588235294118
test1_label=O_precision_tok: 0.8622948078370168
test1_label=O_recall_tok: 0.9669354334645915
test1_label=O_f-score_tok: 0.9116221511807776
test1_label=N_precision_tok: 0.7358567358567358
test1_label=N_recall_tok: 0.4808510638297872
test1_label=N_f-score_tok: 0.5816310117419977
test1_label=P_precision_tok: 0.8394393902139169
test1_label=P_recall_tok: 0.5136151647359711
test1_label=P_f-score_tok: 0.6372969945865223
test1_precision_macro_tok: 0.8125303113025565
test1_recall_macro_tok: 0.6538005540101167
test1_f-score_macro_tok: 0.7101833858364325
test1_precision_micro_tok: 0.8527767951892465
test1_recall_micro_tok: 0.8527767951892465
test1_f-score_micro_tok: 0.8527767951892465
test1_time: 23.551958084106445
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3793    0.0848    0.1387       389
           N     0.6141    0.8235    0.7035       912
           P     0.7178    0.7107    0.7142       909

   micro avg     0.6471    0.6471    0.6471      2210
   macro avg     0.5704    0.5397    0.5188      2210
weighted avg     0.6154    0.6471    0.6085      2210

F1-macro sent:  0.518791695601475
F1-micro sent:  0.6470588235294118
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8623    0.9669    0.9116     31998
           N     0.7359    0.4809    0.5816      3760
           P     0.8394    0.5136    0.6373      6647

   micro avg     0.8528    0.8528    0.8528     42405
   macro avg     0.8125    0.6538    0.7102     42405
weighted avg     0.8475    0.8528    0.8394     42405

F1-macro tok:  0.7101833858364325
F1-micro tok:  0.8527767951892465
**************************************************
