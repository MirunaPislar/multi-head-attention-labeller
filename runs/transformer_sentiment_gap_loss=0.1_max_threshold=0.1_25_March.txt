to_write_filename: runs/transformer_sentiment_gap_loss=0.1_max_threshold=0.1_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.1
maximum_gap_threshold: 0.1
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428143.8406982422
train_cost_avg: 50.11046824651711
train_count_sent: 8544.0
train_total_correct_sent: 4321.0
train_accuracy_sent: 0.5057350187265918
train_count_tok: 163566.0
train_total_correct_tok: 125993.0
train_accuracy_tok: 0.7702884462541115
train_label=O_precision_sent: 0.2062937062937063
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06178010471204188
train_label=N_precision_sent: 0.5023205023205023
train_label=N_recall_sent: 0.5558912386706949
train_label=N_f-score_sent: 0.5277498924422773
train_label=P_precision_sent: 0.527094668117519
train_label=P_recall_sent: 0.6709141274238227
train_label=P_f-score_sent: 0.5903717245581962
train_precision_macro_sent: 0.4119029589105759
train_recall_macro_sent: 0.42104513845186714
train_f-score_macro_sent: 0.3933005739041718
train_precision_micro_sent: 0.5057350187265918
train_recall_micro_sent: 0.5057350187265918
train_f-score_micro_sent: 0.5057350187265918
train_label=O_precision_tok: 0.798217794944772
train_label=O_recall_tok: 0.9472926568393286
train_label=O_f-score_tok: 0.8663893761699341
train_label=N_precision_tok: 0.5
train_label=N_recall_tok: 0.20123926207576398
train_label=N_f-score_tok: 0.28697660407671455
train_label=P_precision_tok: 0.5196498054474709
train_label=P_recall_tok: 0.21353479633848982
train_label=P_f-score_tok: 0.3026886137632093
train_precision_macro_tok: 0.6059558667974142
train_recall_macro_tok: 0.4540222384178609
train_f-score_macro_tok: 0.4853515313366194
train_precision_micro_tok: 0.7702884462541115
train_recall_micro_tok: 0.7702884462541115
train_f-score_micro_tok: 0.7702884462541116
train_time: 200.32567358016968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2063    0.0363    0.0618      1624
           N     0.5023    0.5559    0.5277      3310
           P     0.5271    0.6709    0.5904      3610

   micro avg     0.5057    0.5057    0.5057      8544
   macro avg     0.4119    0.4210    0.3933      8544
weighted avg     0.4565    0.5057    0.4656      8544

F1-macro sent:  0.3933005739041718
F1-micro sent:  0.5057350187265918
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7982    0.9473    0.8664    124347
           N     0.5000    0.2012    0.2870     14202
           P     0.5196    0.2135    0.3027     25017

   micro avg     0.7703    0.7703    0.7703    163566
   macro avg     0.6060    0.4540    0.4854    163566
weighted avg     0.7297    0.7703    0.7299    163566

F1-macro tok:  0.4853515313366194
F1-micro tok:  0.7702884462541116
**************************************************
dev_cost_sum: 50548.896484375
dev_cost_avg: 45.91180425465486
dev_count_sent: 1101.0
dev_total_correct_sent: 657.0
dev_accuracy_sent: 0.5967302452316077
dev_count_tok: 21274.0
dev_total_correct_tok: 17502.0
dev_accuracy_tok: 0.822694368712983
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6196581196581197
dev_label=N_recall_sent: 0.677570093457944
dev_label=N_f-score_sent: 0.6473214285714286
dev_label=P_precision_sent: 0.5797788309636651
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.6815227483751162
dev_precision_macro_sent: 0.39981231687392826
dev_recall_macro_sent: 0.5013822233448402
dev_f-score_macro_sent: 0.44294805898218154
dev_precision_micro_sent: 0.5967302452316077
dev_recall_micro_sent: 0.5967302452316077
dev_f-score_micro_sent: 0.5967302452316077
dev_label=O_precision_tok: 0.8508894217364635
dev_label=O_recall_tok: 0.9416229558778155
dev_label=O_f-score_tok: 0.8939598101822017
dev_label=N_precision_tok: 0.6297071129707112
dev_label=N_recall_tok: 0.4862681744749596
dev_label=N_f-score_tok: 0.5487693710118504
dev_label=P_precision_tok: 0.702674357629785
dev_label=P_recall_tok: 0.41718555417185554
dev_label=P_f-score_tok: 0.5235397538581754
dev_precision_macro_tok: 0.7277569641123199
dev_recall_macro_tok: 0.6150255615082102
dev_f-score_macro_tok: 0.6554229783507425
dev_precision_micro_tok: 0.822694368712983
dev_recall_micro_tok: 0.822694368712983
dev_f-score_micro_tok: 0.822694368712983
dev_time: 12.453028678894043
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6197    0.6776    0.6473       428
           P     0.5798    0.8266    0.6815       444

   micro avg     0.5967    0.5967    0.5967      1101
   macro avg     0.3998    0.5014    0.4429      1101
weighted avg     0.4747    0.5967    0.5265      1101

F1-macro sent:  0.44294805898218154
F1-micro sent:  0.5967302452316077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8509    0.9416    0.8940     16205
           N     0.6297    0.4863    0.5488      1857
           P     0.7027    0.4172    0.5235      3212

   micro avg     0.8227    0.8227    0.8227     21274
   macro avg     0.7278    0.6150    0.6554     21274
weighted avg     0.8092    0.8227    0.8079     21274

F1-macro tok:  0.6554229783507425
F1-micro tok:  0.822694368712983
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378093.111328125
train_cost_avg: 44.25247089514571
train_count_sent: 8544.0
train_total_correct_sent: 4837.0
train_accuracy_sent: 0.5661282771535581
train_count_tok: 163566.0
train_total_correct_tok: 132495.0
train_accuracy_tok: 0.8100399838597263
train_label=O_precision_sent: 0.4090909090909091
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010935601458080195
train_label=N_precision_sent: 0.5379553466509989
train_label=N_recall_sent: 0.6915407854984894
train_label=N_f-score_sent: 0.6051553205551884
train_label=P_precision_sent: 0.5950316381532693
train_label=P_recall_sent: 0.7033240997229917
train_label=P_f-score_sent: 0.6446616732258474
train_precision_macro_sent: 0.5140259646317258
train_recall_macro_sent: 0.46680225238088785
train_f-score_macro_sent: 0.42025086507970527
train_precision_micro_sent: 0.5661282771535581
train_recall_micro_sent: 0.5661282771535581
train_f-score_micro_sent: 0.5661282771535581
train_label=O_precision_tok: 0.833028933283501
train_label=O_recall_tok: 0.9500108567154817
train_label=O_f-score_tok: 0.8876824118186327
train_label=N_precision_tok: 0.6435762224352828
train_label=N_recall_tok: 0.3781157583438952
train_label=N_f-score_tok: 0.47635944291670357
train_label=P_precision_tok: 0.6705435025721315
train_label=P_recall_tok: 0.35951552943998083
train_label=P_f-score_tok: 0.468071818891491
train_precision_macro_tok: 0.7157162194303051
train_recall_macro_tok: 0.5625473814997859
train_f-score_macro_tok: 0.6107045578756091
train_precision_micro_tok: 0.8100399838597263
train_recall_micro_tok: 0.8100399838597263
train_f-score_micro_tok: 0.8100399838597263
train_time: 198.14325404167175
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4091    0.0055    0.0109      1624
           N     0.5380    0.6915    0.6052      3310
           P     0.5950    0.7033    0.6447      3610

   micro avg     0.5661    0.5661    0.5661      8544
   macro avg     0.5140    0.4668    0.4203      8544
weighted avg     0.5376    0.5661    0.5089      8544

F1-macro sent:  0.42025086507970527
F1-micro sent:  0.5661282771535581
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8330    0.9500    0.8877    124347
           N     0.6436    0.3781    0.4764     14202
           P     0.6705    0.3595    0.4681     25017

   micro avg     0.8100    0.8100    0.8100    163566
   macro avg     0.7157    0.5625    0.6107    163566
weighted avg     0.7917    0.8100    0.7878    163566

F1-macro tok:  0.6107045578756091
F1-micro tok:  0.8100399838597263
**************************************************
dev_cost_sum: 48970.16003417969
dev_cost_avg: 44.47789285574903
dev_count_sent: 1101.0
dev_total_correct_sent: 674.0
dev_accuracy_sent: 0.6121707538601272
dev_count_tok: 21274.0
dev_total_correct_tok: 17781.0
dev_accuracy_tok: 0.8358089686941806
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6050583657587548
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.6602972399150744
dev_label=P_precision_sent: 0.6183986371379898
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7041707080504364
dev_precision_macro_sent: 0.40781900096558155
dev_recall_macro_sent: 0.514734360528753
dev_f-score_macro_sent: 0.45482264932183697
dev_precision_micro_sent: 0.6121707538601272
dev_recall_micro_sent: 0.6121707538601272
dev_f-score_micro_sent: 0.6121707538601272
dev_label=O_precision_tok: 0.8461746417950797
dev_label=O_recall_tok: 0.9657513113236655
dev_label=O_f-score_tok: 0.9020172910662824
dev_label=N_precision_tok: 0.7023809523809523
dev_label=N_recall_tok: 0.4765751211631664
dev_label=N_f-score_tok: 0.5678537054860443
dev_label=P_precision_tok: 0.8202764976958525
dev_label=P_recall_tok: 0.387920298879203
dev_label=P_f-score_tok: 0.5267385330796871
dev_precision_macro_tok: 0.7896106972906282
dev_recall_macro_tok: 0.6100822437886783
dev_f-score_macro_tok: 0.6655365098773379
dev_precision_micro_tok: 0.8358089686941806
dev_recall_micro_tok: 0.8358089686941806
dev_f-score_micro_tok: 0.8358089686941806
dev_time: 11.821975231170654
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6051    0.7266    0.6603       428
           P     0.6184    0.8176    0.7042       444

   micro avg     0.6122    0.6122    0.6122      1101
   macro avg     0.4078    0.5147    0.4548      1101
weighted avg     0.4846    0.6122    0.5407      1101

F1-macro sent:  0.45482264932183697
F1-micro sent:  0.6121707538601272
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8462    0.9658    0.9020     16205
           N     0.7024    0.4766    0.5679      1857
           P     0.8203    0.3879    0.5267      3212

   micro avg     0.8358    0.8358    0.8358     21274
   macro avg     0.7896    0.6101    0.6655     21274
weighted avg     0.8297    0.8358    0.8162     21274

F1-macro tok:  0.6655365098773379
F1-micro tok:  0.8358089686941806
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368352.68615722656
train_cost_avg: 43.11243985922596
train_count_sent: 8544.0
train_total_correct_sent: 5030.0
train_accuracy_sent: 0.5887172284644194
train_count_tok: 163566.0
train_total_correct_tok: 135566.0
train_accuracy_tok: 0.8288152794590563
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006119951040391678
train_label=N_precision_sent: 0.5647743813682679
train_label=N_recall_sent: 0.7033232628398791
train_label=N_f-score_sent: 0.6264800861141012
train_label=P_precision_sent: 0.6112873980054397
train_label=P_recall_sent: 0.7470914127423822
train_label=P_f-score_sent: 0.6724008975317877
train_precision_macro_sent: 0.5586872597912359
train_recall_macro_sent: 0.4844978311054171
train_f-score_macro_sent: 0.4350003115620935
train_precision_micro_sent: 0.5887172284644194
train_recall_micro_sent: 0.5887172284644194
train_f-score_micro_sent: 0.5887172284644194
train_label=O_precision_tok: 0.849434546418794
train_label=O_recall_tok: 0.9531794092338376
train_label=O_f-score_tok: 0.8983215919296955
train_label=N_precision_tok: 0.6751325088339223
train_label=N_recall_tok: 0.4305027460920997
train_label=N_f-score_tok: 0.5257545790695675
train_label=P_precision_tok: 0.7296340811965812
train_label=P_recall_tok: 0.43678298756845346
train_label=P_f-score_tok: 0.5464456279848975
train_precision_macro_tok: 0.7514003788164326
train_recall_macro_tok: 0.6068217142981303
train_f-score_macro_tok: 0.6568405996613869
train_precision_micro_tok: 0.8288152794590563
train_recall_micro_tok: 0.8288152794590563
train_f-score_micro_tok: 0.8288152794590563
train_time: 171.72130393981934
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0031    0.0061      1624
           N     0.5648    0.7033    0.6265      3310
           P     0.6113    0.7471    0.6724      3610

   micro avg     0.5887    0.5887    0.5887      8544
   macro avg     0.5587    0.4845    0.4350      8544
weighted avg     0.5721    0.5887    0.5280      8544

F1-macro sent:  0.4350003115620935
F1-micro sent:  0.5887172284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8494    0.9532    0.8983    124347
           N     0.6751    0.4305    0.5258     14202
           P     0.7296    0.4368    0.5464     25017

   micro avg     0.8288    0.8288    0.8288    163566
   macro avg     0.7514    0.6068    0.6568    163566
weighted avg     0.8160    0.8288    0.8122    163566

F1-macro tok:  0.6568405996613869
F1-micro tok:  0.8288152794590563
**************************************************
dev_cost_sum: 48103.966369628906
dev_cost_avg: 43.69115928213343
dev_count_sent: 1101.0
dev_total_correct_sent: 685.0
dev_accuracy_sent: 0.6221616712079927
dev_count_tok: 21274.0
dev_total_correct_tok: 18211.0
dev_accuracy_tok: 0.856021434615023
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6119402985074627
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.6804979253112032
dev_label=P_precision_sent: 0.631858407079646
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.707631318136769
dev_precision_macro_sent: 0.41459956852903623
dev_recall_macro_sent: 0.5234697314136566
dev_f-score_macro_sent: 0.4627097478159907
dev_precision_micro_sent: 0.6221616712079927
dev_recall_micro_sent: 0.6221616712079927
dev_f-score_micro_sent: 0.6221616712079927
dev_label=O_precision_tok: 0.8708774287474103
dev_label=O_recall_tok: 0.9597655044739278
dev_label=O_f-score_tok: 0.913163457022076
dev_label=N_precision_tok: 0.7282700421940929
dev_label=N_recall_tok: 0.464728056004308
dev_label=N_f-score_tok: 0.5673898750821829
dev_label=P_precision_tok: 0.804932735426009
dev_label=P_recall_tok: 0.5588418430884184
dev_label=P_f-score_tok: 0.6596839397280413
dev_precision_macro_tok: 0.8013600687891707
dev_recall_macro_tok: 0.6611118011888847
dev_f-score_macro_tok: 0.7134124239441001
dev_precision_micro_tok: 0.856021434615023
dev_recall_micro_tok: 0.856021434615023
dev_f-score_micro_tok: 0.856021434615023
dev_time: 8.406853914260864
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6119    0.7664    0.6805       428
           P     0.6319    0.8041    0.7076       444

   micro avg     0.6222    0.6222    0.6222      1101
   macro avg     0.4146    0.5235    0.4627      1101
weighted avg     0.4927    0.6222    0.5499      1101

F1-macro sent:  0.4627097478159907
F1-micro sent:  0.6221616712079927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8709    0.9598    0.9132     16205
           N     0.7283    0.4647    0.5674      1857
           P     0.8049    0.5588    0.6597      3212

   micro avg     0.8560    0.8560    0.8560     21274
   macro avg     0.8014    0.6611    0.7134     21274
weighted avg     0.8485    0.8560    0.8447     21274

F1-macro tok:  0.7134124239441001
F1-micro tok:  0.856021434615023
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361607.42919921875
train_cost_avg: 42.322966900657626
train_count_sent: 8544.0
train_total_correct_sent: 5096.0
train_accuracy_sent: 0.596441947565543
train_count_tok: 163566.0
train_total_correct_tok: 137697.0
train_accuracy_tok: 0.841843659440226
train_label=O_precision_sent: 0.40476190476190477
train_label=O_recall_sent: 0.010467980295566502
train_label=O_f-score_sent: 0.02040816326530612
train_label=N_precision_sent: 0.5607968857339134
train_label=N_recall_sent: 0.7398791540785499
train_label=N_f-score_sent: 0.6380096391819721
train_label=P_precision_sent: 0.6360338573155986
train_label=P_recall_sent: 0.7285318559556787
train_label=P_f-score_sent: 0.6791478373143964
train_precision_macro_sent: 0.5338642159371388
train_recall_macro_sent: 0.492959663443265
train_f-score_macro_sent: 0.44585521325389155
train_precision_micro_sent: 0.596441947565543
train_recall_micro_sent: 0.596441947565543
train_f-score_micro_sent: 0.596441947565543
train_label=O_precision_tok: 0.860458216342953
train_label=O_recall_tok: 0.9562353735916428
train_label=O_f-score_tok: 0.9058220808654085
train_label=N_precision_tok: 0.6932488998604701
train_label=N_recall_tok: 0.4547950992817913
train_label=N_f-score_tok: 0.5492580466856585
train_label=P_precision_tok: 0.7678849386713156
train_label=P_recall_tok: 0.4929847703561578
train_label=P_f-score_tok: 0.6004674034763132
train_precision_macro_tok: 0.7738640182915795
train_recall_macro_tok: 0.6346717477431972
train_f-score_macro_tok: 0.68518251034246
train_precision_micro_tok: 0.841843659440226
train_recall_micro_tok: 0.841843659440226
train_f-score_micro_tok: 0.841843659440226
train_time: 148.6821961402893
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4048    0.0105    0.0204      1624
           N     0.5608    0.7399    0.6380      3310
           P     0.6360    0.7285    0.6791      3610

   micro avg     0.5964    0.5964    0.5964      8544
   macro avg     0.5339    0.4930    0.4459      8544
weighted avg     0.5629    0.5964    0.5380      8544

F1-macro sent:  0.44585521325389155
F1-micro sent:  0.596441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8605    0.9562    0.9058    124347
           N     0.6932    0.4548    0.5493     14202
           P     0.7679    0.4930    0.6005     25017

   micro avg     0.8418    0.8418    0.8418    163566
   macro avg     0.7739    0.6347    0.6852    163566
weighted avg     0.8318    0.8418    0.8282    163566

F1-macro tok:  0.68518251034246
F1-micro tok:  0.841843659440226
**************************************************
dev_cost_sum: 47383.697021484375
dev_cost_avg: 43.036963688904976
dev_count_sent: 1101.0
dev_total_correct_sent: 685.0
dev_accuracy_sent: 0.6221616712079927
dev_count_tok: 21274.0
dev_total_correct_tok: 18381.0
dev_accuracy_tok: 0.8640124095139607
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6326530612244898
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.6753812636165578
dev_label=P_precision_sent: 0.6134868421052632
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.709125475285171
dev_precision_macro_sent: 0.6376021899988066
dev_recall_macro_sent: 0.5243742599882665
dev_f-score_macro_sent: 0.4672493727373579
dev_precision_micro_sent: 0.6221616712079927
dev_recall_micro_sent: 0.6221616712079927
dev_f-score_micro_sent: 0.6221616712079927
dev_label=O_precision_tok: 0.8717138103161398
dev_label=O_recall_tok: 0.9698858377044122
dev_label=O_f-score_tok: 0.9181831459033153
dev_label=N_precision_tok: 0.7762430939226519
dev_label=N_recall_tok: 0.45395799676898224
dev_label=N_f-score_tok: 0.5728848114169216
dev_label=P_precision_tok: 0.8438368860055607
dev_label=P_recall_tok: 0.5669364881693649
dev_label=P_f-score_tok: 0.6782122905027934
dev_precision_macro_tok: 0.8305979300814507
dev_recall_macro_tok: 0.6635934408809198
dev_f-score_macro_tok: 0.7230934159410101
dev_precision_micro_tok: 0.8640124095139607
dev_recall_micro_tok: 0.8640124095139607
dev_f-score_micro_tok: 0.8640124095139607
dev_time: 11.839499950408936
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6327    0.7243    0.6754       428
           P     0.6135    0.8401    0.7091       444

   micro avg     0.6222    0.6222    0.6222      1101
   macro avg     0.6376    0.5244    0.4672      1101
weighted avg     0.6320    0.6222    0.5521      1101

F1-macro sent:  0.4672493727373579
F1-micro sent:  0.6221616712079927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8717    0.9699    0.9182     16205
           N     0.7762    0.4540    0.5729      1857
           P     0.8438    0.5669    0.6782      3212

   micro avg     0.8640    0.8640    0.8640     21274
   macro avg     0.8306    0.6636    0.7231     21274
weighted avg     0.8592    0.8640    0.8518     21274

F1-macro tok:  0.7230934159410101
F1-micro tok:  0.8640124095139607
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355769.84716796875
train_cost_avg: 41.639729303367126
train_count_sent: 8544.0
train_total_correct_sent: 5230.0
train_accuracy_sent: 0.612125468164794
train_count_tok: 163566.0
train_total_correct_tok: 139113.0
train_accuracy_tok: 0.8505007153075823
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036742192284139616
train_label=N_precision_sent: 0.568691487045504
train_label=N_recall_sent: 0.7891238670694865
train_label=N_f-score_sent: 0.6610148045046185
train_label=P_precision_sent: 0.6633688483003551
train_label=P_recall_sent: 0.724376731301939
train_label=P_f-score_sent: 0.6925317796610169
train_precision_macro_sent: 0.5217978895597307
train_recall_macro_sent: 0.5051159630039398
train_f-score_macro_sent: 0.4524069344646831
train_precision_micro_sent: 0.612125468164794
train_recall_micro_sent: 0.612125468164794
train_f-score_micro_sent: 0.612125468164794
train_label=O_precision_tok: 0.8676077860651265
train_label=O_recall_tok: 0.9588570693301809
train_label=O_f-score_tok: 0.9109530431062146
train_label=N_precision_tok: 0.7059380922299432
train_label=N_recall_tok: 0.4721166032953105
train_label=N_f-score_tok: 0.5658227848101266
train_label=P_precision_tok: 0.7917442768731598
train_label=P_recall_tok: 0.5267218291561738
train_label=P_f-score_tok: 0.6325972155544888
train_precision_macro_tok: 0.7884300517227433
train_recall_macro_tok: 0.6525651672605551
train_f-score_macro_tok: 0.7031243478236101
train_precision_micro_tok: 0.8505007153075823
train_recall_micro_tok: 0.8505007153075823
train_f-score_micro_tok: 0.8505007153075823
train_time: 198.29014945030212
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0018    0.0037      1624
           N     0.5687    0.7891    0.6610      3310
           P     0.6634    0.7244    0.6925      3610

   micro avg     0.6121    0.6121    0.6121      8544
   macro avg     0.5218    0.5051    0.4524      8544
weighted avg     0.5640    0.6121    0.5494      8544

F1-macro sent:  0.4524069344646831
F1-micro sent:  0.612125468164794
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8676    0.9589    0.9110    124347
           N     0.7059    0.4721    0.5658     14202
           P     0.7917    0.5267    0.6326     25017

   micro avg     0.8505    0.8505    0.8505    163566
   macro avg     0.7884    0.6526    0.7031    163566
weighted avg     0.8420    0.8505    0.8384    163566

F1-macro tok:  0.7031243478236101
F1-micro tok:  0.8505007153075823
**************************************************
dev_cost_sum: 46765.45690917969
dev_cost_avg: 42.47543770134395
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18525.0
dev_accuracy_tok: 0.870781235310708
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6326923076923077
dev_label=N_recall_sent: 0.7686915887850467
dev_label=N_f-score_sent: 0.6940928270042194
dev_label=P_precision_sent: 0.6224137931034482
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7050781249999999
dev_precision_macro_sent: 0.7517020335985852
dev_recall_macro_sent: 0.528707154691728
dev_f-score_macro_sent: 0.4692888680593774
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.88057691228464
dev_label=O_recall_tok: 0.9682813946312866
dev_label=O_f-score_tok: 0.9223489301669409
dev_label=N_precision_tok: 0.7539308176100629
dev_label=N_recall_tok: 0.5164243403338719
dev_label=N_f-score_tok: 0.6129753914988814
dev_label=P_precision_tok: 0.858909757214842
dev_label=P_recall_tok: 0.5837484433374844
dev_label=P_f-score_tok: 0.6950880444856348
dev_precision_macro_tok: 0.8311391623698482
dev_recall_macro_tok: 0.689484726100881
dev_f-score_macro_tok: 0.7434707887171523
dev_precision_micro_tok: 0.870781235310708
dev_recall_micro_tok: 0.870781235310708
dev_f-score_micro_tok: 0.870781235310708
dev_time: 11.901612997055054
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6327    0.7687    0.6941       428
           P     0.6224    0.8131    0.7051       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.7517    0.5287    0.4693      1101
weighted avg     0.7049    0.6276    0.5560      1101

F1-macro sent:  0.4692888680593774
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9683    0.9223     16205
           N     0.7539    0.5164    0.6130      1857
           P     0.8589    0.5837    0.6951      3212

   micro avg     0.8708    0.8708    0.8708     21274
   macro avg     0.8311    0.6895    0.7435     21274
weighted avg     0.8663    0.8708    0.8610     21274

F1-macro tok:  0.7434707887171523
F1-micro tok:  0.870781235310708
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351160.78649902344
train_cost_avg: 41.10027931870593
train_count_sent: 8544.0
train_total_correct_sent: 5276.0
train_accuracy_sent: 0.6175093632958801
train_count_tok: 163566.0
train_total_correct_tok: 140274.0
train_accuracy_tok: 0.8575987674700121
train_label=O_precision_sent: 0.4230769230769231
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026252983293556086
train_label=N_precision_sent: 0.5862470862470862
train_label=N_recall_sent: 0.7598187311178247
train_label=N_f-score_sent: 0.6618421052631579
train_label=P_precision_sent: 0.6518324607329843
train_label=P_recall_sent: 0.7587257617728532
train_label=P_f-score_sent: 0.7012288786482335
train_precision_macro_sent: 0.5537188233523311
train_recall_macro_sent: 0.5106970969734115
train_f-score_macro_sent: 0.4631079890683158
train_precision_micro_sent: 0.6175093632958801
train_recall_micro_sent: 0.6175093632958801
train_f-score_micro_sent: 0.6175093632958801
train_label=O_precision_tok: 0.8734321550741163
train_label=O_recall_tok: 0.9609882023691766
train_label=O_f-score_tok: 0.9151206736126267
train_label=N_precision_tok: 0.7233673469387755
train_label=N_recall_tok: 0.4991550485847064
train_label=N_f-score_tok: 0.5907007749354221
train_label=P_precision_tok: 0.8074200778577327
train_label=P_recall_tok: 0.5471879122196907
train_label=P_f-score_tok: 0.6523075456863073
train_precision_macro_tok: 0.8014065266235416
train_recall_macro_tok: 0.6691103877245245
train_f-score_macro_tok: 0.7193763314114521
train_precision_micro_tok: 0.8575987674700121
train_recall_micro_tok: 0.8575987674700121
train_f-score_micro_tok: 0.8575987674700121
train_time: 198.11450958251953
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4231    0.0135    0.0263      1624
           N     0.5862    0.7598    0.6618      3310
           P     0.6518    0.7587    0.7012      3610

   micro avg     0.6175    0.6175    0.6175      8544
   macro avg     0.5537    0.5107    0.4631      8544
weighted avg     0.5829    0.6175    0.5577      8544

F1-macro sent:  0.4631079890683158
F1-micro sent:  0.6175093632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8734    0.9610    0.9151    124347
           N     0.7234    0.4992    0.5907     14202
           P     0.8074    0.5472    0.6523     25017

   micro avg     0.8576    0.8576    0.8576    163566
   macro avg     0.8014    0.6691    0.7194    163566
weighted avg     0.8503    0.8576    0.8468    163566

F1-macro tok:  0.7193763314114521
F1-micro tok:  0.8575987674700121
**************************************************
dev_cost_sum: 46252.05041503906
dev_cost_avg: 42.00912844236064
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18634.0
dev_accuracy_tok: 0.8759048603929679
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6381322957198443
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.6963906581740976
dev_label=P_precision_sent: 0.6354344122657581
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.72356935014549
dev_precision_macro_sent: 0.4245222359952008
dev_recall_macro_sent: 0.5354817434256686
dev_f-score_macro_sent: 0.47332000277319586
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8805928567448599
dev_label=O_recall_tok: 0.9752545510644862
dev_label=O_f-score_tok: 0.9255094869992972
dev_label=N_precision_tok: 0.810928013876843
dev_label=N_recall_tok: 0.5035002692514808
dev_label=N_f-score_tok: 0.6212624584717608
dev_label=P_precision_tok: 0.8716651333946642
dev_label=P_recall_tok: 0.589975093399751
dev_label=P_f-score_tok: 0.7036761975492016
dev_precision_macro_tok: 0.8543953346721224
dev_recall_macro_tok: 0.6895766379052394
dev_f-score_macro_tok: 0.7501493810067532
dev_precision_micro_tok: 0.8759048603929679
dev_recall_micro_tok: 0.8759048603929679
dev_f-score_micro_tok: 0.8759048603929679
dev_time: 11.550443172454834
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6381    0.7664    0.6964       428
           P     0.6354    0.8401    0.7236       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4245    0.5355    0.4733      1101
weighted avg     0.5043    0.6367    0.5625      1101

F1-macro sent:  0.47332000277319586
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9753    0.9255     16205
           N     0.8109    0.5035    0.6213      1857
           P     0.8717    0.5900    0.7037      3212

   micro avg     0.8759    0.8759    0.8759     21274
   macro avg     0.8544    0.6896    0.7501     21274
weighted avg     0.8732    0.8759    0.8655     21274

F1-macro tok:  0.7501493810067532
F1-micro tok:  0.8759048603929679
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347346.42333984375
train_cost_avg: 40.653841683034145
train_count_sent: 8544.0
train_total_correct_sent: 5305.0
train_accuracy_sent: 0.6209035580524345
train_count_tok: 163566.0
train_total_correct_tok: 140929.0
train_accuracy_tok: 0.8616032671826663
train_label=O_precision_sent: 0.4444444444444444
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009744214372716201
train_label=N_precision_sent: 0.5886458818054909
train_label=N_recall_sent: 0.7643504531722054
train_label=N_f-score_sent: 0.6650893796004206
train_label=P_precision_sent: 0.6544465468306528
train_label=P_recall_sent: 0.7664819944598338
train_label=P_f-score_sent: 0.706047461087012
train_precision_macro_sent: 0.5625122910268627
train_recall_macro_sent: 0.5119195186688078
train_f-score_macro_sent: 0.46029368502004964
train_precision_micro_sent: 0.6209035580524345
train_recall_micro_sent: 0.6209035580524345
train_f-score_micro_sent: 0.6209035580524345
train_label=O_precision_tok: 0.8766794133591197
train_label=O_recall_tok: 0.9624035963875285
train_label=O_f-score_tok: 0.9175435973517652
train_label=N_precision_tok: 0.7323334004429233
train_label=N_recall_tok: 0.5122517955217575
train_label=N_f-score_tok: 0.6028339410009943
train_label=P_precision_tok: 0.816419479154502
train_label=P_recall_tok: 0.5588999480353359
train_label=P_f-score_tok: 0.663550293049854
train_precision_macro_tok: 0.808477430985515
train_recall_macro_tok: 0.6778517799815407
train_f-score_macro_tok: 0.7279759438008712
train_precision_micro_tok: 0.8616032671826663
train_recall_micro_tok: 0.8616032671826663
train_f-score_micro_tok: 0.8616032671826663
train_time: 198.20181131362915
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.0049    0.0097      1624
           N     0.5886    0.7644    0.6651      3310
           P     0.6544    0.7665    0.7060      3610

   micro avg     0.6209    0.6209    0.6209      8544
   macro avg     0.5625    0.5119    0.4603      8544
weighted avg     0.5890    0.6209    0.5578      8544

F1-macro sent:  0.46029368502004964
F1-micro sent:  0.6209035580524345
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8767    0.9624    0.9175    124347
           N     0.7323    0.5123    0.6028     14202
           P     0.8164    0.5589    0.6636     25017

   micro avg     0.8616    0.8616    0.8616    163566
   macro avg     0.8085    0.6779    0.7280    163566
weighted avg     0.8549    0.8616    0.8514    163566

F1-macro tok:  0.7279759438008712
F1-micro tok:  0.8616032671826663
**************************************************
dev_cost_sum: 45868.45373535156
dev_cost_avg: 41.660720922208505
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18673.0
dev_accuracy_tok: 0.8777380840462536
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017167381974248927
dev_label=N_precision_sent: 0.6243093922651933
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.698249227600412
dev_label=P_precision_sent: 0.6462093862815884
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7174348697394789
dev_precision_macro_sent: 0.5901729261822606
dev_recall_macro_sent: 0.5356986685089367
dev_f-score_macro_sent: 0.4776171597713799
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8812785388127854
dev_label=O_recall_tok: 0.9766121567417464
dev_label=O_f-score_tok: 0.9264994292070369
dev_label=N_precision_tok: 0.828440366972477
dev_label=N_recall_tok: 0.4862681744749596
dev_label=N_f-score_tok: 0.6128266033254157
dev_label=P_precision_tok: 0.8733153638814016
dev_label=P_recall_tok: 0.6052303860523038
dev_label=P_f-score_tok: 0.714968738506804
dev_precision_macro_tok: 0.8610114232222214
dev_recall_macro_tok: 0.68937023908967
dev_f-score_macro_tok: 0.7514315903464189
dev_precision_micro_tok: 0.8777380840462536
dev_recall_micro_tok: 0.8777380840462536
dev_f-score_micro_tok: 0.8777380840462536
dev_time: 11.820663213729858
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0087    0.0172       229
           N     0.6243    0.7921    0.6982       428
           P     0.6462    0.8063    0.7174       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.5902    0.5357    0.4776      1101
weighted avg     0.6073    0.6349    0.5643      1101

F1-macro sent:  0.4776171597713799
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8813    0.9766    0.9265     16205
           N     0.8284    0.4863    0.6128      1857
           P     0.8733    0.6052    0.7150      3212

   micro avg     0.8777    0.8777    0.8777     21274
   macro avg     0.8610    0.6894    0.7514     21274
weighted avg     0.8755    0.8777    0.8672     21274

F1-macro tok:  0.7514315903464189
F1-micro tok:  0.8777380840462536
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 343234.3161621094
train_cost_avg: 40.172555730583966
train_count_sent: 8544.0
train_total_correct_sent: 5353.0
train_accuracy_sent: 0.6265215355805244
train_count_tok: 163566.0
train_total_correct_tok: 141842.0
train_accuracy_tok: 0.867185111820305
train_label=O_precision_sent: 0.47368421052631576
train_label=O_recall_sent: 0.0332512315270936
train_label=O_f-score_sent: 0.0621403912543153
train_label=N_precision_sent: 0.5919075144508671
train_label=N_recall_sent: 0.7734138972809668
train_label=N_f-score_sent: 0.6705959397511461
train_label=P_precision_sent: 0.6672350791717417
train_label=P_recall_sent: 0.7587257617728532
train_label=P_f-score_sent: 0.7100453661697991
train_precision_macro_sent: 0.5776089347163081
train_recall_macro_sent: 0.5217969635269712
train_f-score_macro_sent: 0.48092723239175345
train_precision_micro_sent: 0.6265215355805244
train_recall_micro_sent: 0.6265215355805244
train_f-score_micro_sent: 0.6265215355805244
train_label=O_precision_tok: 0.8812450858641898
train_label=O_recall_tok: 0.9644462673003772
train_label=O_f-score_tok: 0.9209703802114932
train_label=N_precision_tok: 0.7419928825622776
train_label=N_recall_tok: 0.5285171102661597
train_label=N_f-score_tok: 0.617320503330866
train_label=P_precision_tok: 0.8299257040833957
train_label=P_recall_tok: 0.5760083143462446
train_label=P_f-score_tok: 0.6800377536573855
train_precision_macro_tok: 0.8177212241699544
train_recall_macro_tok: 0.6896572306375938
train_f-score_macro_tok: 0.7394428790665816
train_precision_micro_tok: 0.867185111820305
train_recall_micro_tok: 0.867185111820305
train_f-score_micro_tok: 0.867185111820305
train_time: 154.16249537467957
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4737    0.0333    0.0621      1624
           N     0.5919    0.7734    0.6706      3310
           P     0.6672    0.7587    0.7100      3610

   micro avg     0.6265    0.6265    0.6265      8544
   macro avg     0.5776    0.5218    0.4809      8544
weighted avg     0.6013    0.6265    0.5716      8544

F1-macro sent:  0.48092723239175345
F1-micro sent:  0.6265215355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8812    0.9644    0.9210    124347
           N     0.7420    0.5285    0.6173     14202
           P     0.8299    0.5760    0.6800     25017

   micro avg     0.8672    0.8672    0.8672    163566
   macro avg     0.8177    0.6897    0.7394    163566
weighted avg     0.8613    0.8672    0.8578    163566

F1-macro tok:  0.7394428790665816
F1-micro tok:  0.867185111820305
**************************************************
dev_cost_sum: 45377.11315917969
dev_cost_avg: 41.21445336891888
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 18806.0
dev_accuracy_tok: 0.8839898467613049
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6069078947368421
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7123552123552125
dev_label=P_precision_sent: 0.6890243902439024
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.7243589743589743
dev_precision_macro_sent: 0.7653107616602481
dev_recall_macro_sent: 0.5433432861502894
dev_f-score_macro_sent: 0.4818032796293666
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8922545578077228
dev_label=O_recall_tok: 0.9724776303609997
dev_label=O_f-score_tok: 0.9306404464522987
dev_label=N_precision_tok: 0.774888558692422
dev_label=N_recall_tok: 0.5616585891222402
dev_label=N_f-score_tok: 0.6512644395878864
dev_label=P_precision_tok: 0.884377758164166
dev_label=P_recall_tok: 0.6239103362391034
dev_label=P_f-score_tok: 0.7316538882803943
dev_precision_macro_tok: 0.850506958221437
dev_recall_macro_tok: 0.7193488519074478
dev_f-score_macro_tok: 0.7711862581068597
dev_precision_micro_tok: 0.8839898467613049
dev_recall_micro_tok: 0.8839898467613049
dev_f-score_micro_tok: 0.8839898467613049
dev_time: 8.354488611221313
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6069    0.8621    0.7124       428
           P     0.6890    0.7635    0.7244       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.7653    0.5433    0.4818      1101
weighted avg     0.7218    0.6440    0.5708      1101

F1-macro sent:  0.4818032796293666
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8923    0.9725    0.9306     16205
           N     0.7749    0.5617    0.6513      1857
           P     0.8844    0.6239    0.7317      3212

   micro avg     0.8840    0.8840    0.8840     21274
   macro avg     0.8505    0.7193    0.7712     21274
weighted avg     0.8808    0.8840    0.8762     21274

F1-macro tok:  0.7711862581068597
F1-micro tok:  0.8839898467613049
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339784.5673828125
train_cost_avg: 39.76879299892468
train_count_sent: 8544.0
train_total_correct_sent: 5424.0
train_accuracy_sent: 0.6348314606741573
train_count_tok: 163566.0
train_total_correct_tok: 142315.0
train_accuracy_tok: 0.870076910849443
train_label=O_precision_sent: 0.5121951219512195
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.02522522522522522
train_label=N_precision_sent: 0.5902113459399333
train_label=N_recall_sent: 0.8015105740181269
train_label=N_f-score_sent: 0.6798206278026906
train_label=P_precision_sent: 0.686127744510978
train_label=P_recall_sent: 0.7617728531855956
train_label=P_f-score_sent: 0.721974271462326
train_precision_macro_sent: 0.5961780708007103
train_recall_macro_sent: 0.5254048205621604
train_f-score_macro_sent: 0.4756733748300806
train_precision_micro_sent: 0.6348314606741573
train_recall_micro_sent: 0.6348314606741573
train_f-score_micro_sent: 0.6348314606741573
train_label=O_precision_tok: 0.8838688775660472
train_label=O_recall_tok: 0.9653630566077187
train_label=O_f-score_tok: 0.922820275293186
train_label=N_precision_tok: 0.7454244548286605
train_label=N_recall_tok: 0.5391494155752711
train_label=N_f-score_tok: 0.6257252594590177
train_label=P_precision_tok: 0.8361743507607825
train_label=P_recall_tok: 0.5843226605907983
train_label=P_f-score_tok: 0.687922068754559
train_precision_macro_tok: 0.82182256105183
train_recall_macro_tok: 0.6962783775912627
train_f-score_macro_tok: 0.7454892011689208
train_precision_micro_tok: 0.870076910849443
train_recall_micro_tok: 0.870076910849443
train_f-score_micro_tok: 0.870076910849443
train_time: 145.87261199951172
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5122    0.0129    0.0252      1624
           N     0.5902    0.8015    0.6798      3310
           P     0.6861    0.7618    0.7220      3610

   micro avg     0.6348    0.6348    0.6348      8544
   macro avg     0.5962    0.5254    0.4757      8544
weighted avg     0.6159    0.6348    0.5732      8544

F1-macro sent:  0.4756733748300806
F1-micro sent:  0.6348314606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8839    0.9654    0.9228    124347
           N     0.7454    0.5391    0.6257     14202
           P     0.8362    0.5843    0.6879     25017

   micro avg     0.8701    0.8701    0.8701    163566
   macro avg     0.8218    0.6963    0.7455    163566
weighted avg     0.8646    0.8701    0.8611    163566

F1-macro tok:  0.7454892011689208
F1-micro tok:  0.870076910849443
**************************************************
dev_cost_sum: 45068.50817871094
dev_cost_avg: 40.93415820046407
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18807.0
dev_accuracy_tok: 0.8840368524960045
dev_label=O_precision_sent: 0.7692307692307693
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08264462809917354
dev_label=N_precision_sent: 0.5886075949367089
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7018867924528303
dev_label=P_precision_sent: 0.706140350877193
dev_label=P_recall_sent: 0.7252252252252253
dev_label=P_f-score_sent: 0.7155555555555555
dev_precision_macro_sent: 0.6879929050148904
dev_recall_macro_sent: 0.5460174086668802
dev_f-score_macro_sent: 0.500028992035853
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8875699888017917
dev_label=O_recall_tok: 0.978216599814872
dev_label=O_f-score_tok: 0.9306913254073095
dev_label=N_precision_tok: 0.7863636363636364
dev_label=N_recall_tok: 0.5589660743134087
dev_label=N_f-score_tok: 0.6534466477809253
dev_label=P_precision_tok: 0.9154727793696275
dev_label=P_recall_tok: 0.5968244084682441
dev_label=P_f-score_tok: 0.7225782133433849
dev_precision_macro_tok: 0.8631354681783519
dev_recall_macro_tok: 0.7113356941988416
dev_f-score_macro_tok: 0.7689053955105399
dev_precision_micro_tok: 0.8840368524960045
dev_recall_micro_tok: 0.8840368524960045
dev_f-score_micro_tok: 0.8840368524960045
dev_time: 8.628427267074585
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7692    0.0437    0.0826       229
           N     0.5886    0.8692    0.7019       428
           P     0.7061    0.7252    0.7156       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6880    0.5460    0.5000      1101
weighted avg     0.6736    0.6394    0.5786      1101

F1-macro sent:  0.500028992035853
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8876    0.9782    0.9307     16205
           N     0.7864    0.5590    0.6534      1857
           P     0.9155    0.5968    0.7226      3212

   micro avg     0.8840    0.8840    0.8840     21274
   macro avg     0.8631    0.7113    0.7689     21274
weighted avg     0.8829    0.8840    0.8751     21274

F1-macro tok:  0.7689053955105399
F1-micro tok:  0.8840368524960045
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336774.5934448242
train_cost_avg: 39.41650204176313
train_count_sent: 8544.0
train_total_correct_sent: 5415.0
train_accuracy_sent: 0.6337780898876404
train_count_tok: 163566.0
train_total_correct_tok: 142735.0
train_accuracy_tok: 0.8726446816575572
train_label=O_precision_sent: 0.4520547945205479
train_label=O_recall_sent: 0.020320197044334975
train_label=O_f-score_sent: 0.038892162639952856
train_label=N_precision_sent: 0.595418098510882
train_label=N_recall_sent: 0.7851963746223565
train_label=N_f-score_sent: 0.6772638436482086
train_label=P_precision_sent: 0.6777886020457866
train_label=P_recall_sent: 0.7709141274238227
train_label=P_f-score_sent: 0.7213582166925868
train_precision_macro_sent: 0.5750871650257389
train_recall_macro_sent: 0.5254768996968381
train_f-score_macro_sent: 0.4791714076602494
train_precision_micro_sent: 0.6337780898876404
train_recall_micro_sent: 0.6337780898876404
train_f-score_micro_sent: 0.6337780898876404
train_label=O_precision_tok: 0.8863745396305235
train_label=O_recall_tok: 0.9657973252269858
train_label=O_f-score_tok: 0.9243830723995135
train_label=N_precision_tok: 0.7497123130034522
train_label=N_recall_tok: 0.5504858470637939
train_label=N_f-score_tok: 0.6348355663824604
train_label=P_precision_tok: 0.8398776134625191
train_label=P_recall_tok: 0.5925170883799017
train_label=P_f-score_tok: 0.6948389818590915
train_precision_macro_tok: 0.8253214886988315
train_recall_macro_tok: 0.7029334202235605
train_f-score_macro_tok: 0.7513525402136886
train_precision_micro_tok: 0.8726446816575572
train_recall_micro_tok: 0.8726446816575572
train_f-score_micro_tok: 0.872644681657557
train_time: 144.74831914901733
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4521    0.0203    0.0389      1624
           N     0.5954    0.7852    0.6773      3310
           P     0.6778    0.7709    0.7214      3610

   micro avg     0.6338    0.6338    0.6338      8544
   macro avg     0.5751    0.5255    0.4792      8544
weighted avg     0.6030    0.6338    0.5746      8544

F1-macro sent:  0.4791714076602494
F1-micro sent:  0.6337780898876404
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8864    0.9658    0.9244    124347
           N     0.7497    0.5505    0.6348     14202
           P     0.8399    0.5925    0.6948     25017

   micro avg     0.8726    0.8726    0.8726    163566
   macro avg     0.8253    0.7029    0.7514    163566
weighted avg     0.8674    0.8726    0.8641    163566

F1-macro tok:  0.7513525402136886
F1-micro tok:  0.872644681657557
**************************************************
dev_cost_sum: 44846.09912109375
dev_cost_avg: 40.732151790275886
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 18827.0
dev_accuracy_tok: 0.8849769671899972
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6168384879725086
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.710891089108911
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7185877466251297
dev_precision_macro_sent: 0.42783505154639173
dev_recall_macro_sent: 0.5393547753360838
dev_f-score_macro_sent: 0.4764929452446802
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.8824017249958533
dev_label=O_recall_tok: 0.9848812095032398
dev_label=O_f-score_tok: 0.9308293479528753
dev_label=N_precision_tok: 0.8627450980392157
dev_label=N_recall_tok: 0.47388260635433493
dev_label=N_f-score_tok: 0.6117483489746264
dev_label=P_precision_tok: 0.9169358560221504
dev_label=P_recall_tok: 0.6186176836861769
dev_label=P_f-score_tok: 0.7387990332775608
dev_precision_macro_tok: 0.8873608930190732
dev_recall_macro_tok: 0.6924604998479172
dev_f-score_macro_tok: 0.7604589100683542
dev_precision_micro_tok: 0.8849769671899972
dev_recall_micro_tok: 0.8849769671899972
dev_f-score_micro_tok: 0.8849769671899972
dev_time: 8.31920313835144
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6168    0.8388    0.7109       428
           P     0.6667    0.7793    0.7186       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.4278    0.5394    0.4765      1101
weighted avg     0.5086    0.6403    0.5661      1101

F1-macro sent:  0.4764929452446802
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8824    0.9849    0.9308     16205
           N     0.8627    0.4739    0.6117      1857
           P     0.9169    0.6186    0.7388      3212

   micro avg     0.8850    0.8850    0.8850     21274
   macro avg     0.8874    0.6925    0.7605     21274
weighted avg     0.8859    0.8850    0.8740     21274

F1-macro tok:  0.7604589100683542
F1-micro tok:  0.8849769671899972
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333607.5903930664
train_cost_avg: 39.04583220892631
train_count_sent: 8544.0
train_total_correct_sent: 5444.0
train_accuracy_sent: 0.6371722846441947
train_count_tok: 163566.0
train_total_correct_tok: 143179.0
train_accuracy_tok: 0.8753591822261351
train_label=O_precision_sent: 0.3089430894308943
train_label=O_recall_sent: 0.023399014778325122
train_label=O_f-score_sent: 0.04350314825414997
train_label=N_precision_sent: 0.6096932802622337
train_label=N_recall_sent: 0.7867069486404834
train_label=N_f-score_sent: 0.6869806094182825
train_label=P_precision_sent: 0.6751807228915663
train_label=P_recall_sent: 0.7761772853185596
train_label=P_f-score_sent: 0.7221649484536082
train_precision_macro_sent: 0.5312723641948981
train_recall_macro_sent: 0.528761082912456
train_f-score_macro_sent: 0.4842162353753469
train_precision_micro_sent: 0.6371722846441947
train_recall_micro_sent: 0.6371722846441947
train_f-score_micro_sent: 0.6371722846441947
train_label=O_precision_tok: 0.8882871434165516
train_label=O_recall_tok: 0.9668669127522176
train_label=O_f-score_tok: 0.9259128050705832
train_label=N_precision_tok: 0.7535898908673176
train_label=N_recall_tok: 0.5542881284326151
train_label=N_f-score_tok: 0.6387536514118792
train_label=P_precision_tok: 0.8484780284701513
train_label=P_recall_tok: 0.6027901027301436
train_label=P_f-score_tok: 0.7048375788735687
train_precision_macro_tok: 0.8301183542513401
train_recall_macro_tok: 0.7079817146383255
train_f-score_macro_tok: 0.756501345118677
train_precision_micro_tok: 0.8753591822261351
train_recall_micro_tok: 0.8753591822261351
train_f-score_micro_tok: 0.875359182226135
train_time: 145.71516871452332
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3089    0.0234    0.0435      1624
           N     0.6097    0.7867    0.6870      3310
           P     0.6752    0.7762    0.7222      3610

   micro avg     0.6372    0.6372    0.6372      8544
   macro avg     0.5313    0.5288    0.4842      8544
weighted avg     0.5802    0.6372    0.5795      8544

F1-macro sent:  0.4842162353753469
F1-micro sent:  0.6371722846441947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8883    0.9669    0.9259    124347
           N     0.7536    0.5543    0.6388     14202
           P     0.8485    0.6028    0.7048     25017

   micro avg     0.8754    0.8754    0.8754    163566
   macro avg     0.8301    0.7080    0.7565    163566
weighted avg     0.8705    0.8754    0.8672    163566

F1-macro tok:  0.756501345118677
F1-micro tok:  0.875359182226135
**************************************************
dev_cost_sum: 44428.099609375
dev_cost_avg: 40.35249737454587
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18909.0
dev_accuracy_tok: 0.8888314374353671
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6689342403628118
dev_label=N_recall_sent: 0.6892523364485982
dev_label=N_f-score_sent: 0.6789413118527042
dev_label=P_precision_sent: 0.5981735159817352
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.7138964577656676
dev_precision_macro_sent: 0.7557025854481824
dev_recall_macro_sent: 0.5291626360883187
dev_f-score_macro_sent: 0.4728999461946297
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8950379517389827
dev_label=O_recall_tok: 0.9750694230175871
dev_label=O_f-score_tok: 0.9333412091319887
dev_label=N_precision_tok: 0.8013646702047005
dev_label=N_recall_tok: 0.5691976305869683
dev_label=N_f-score_tok: 0.6656171284634761
dev_label=P_precision_tok: 0.8913515862668405
dev_label=P_recall_tok: 0.6385429638854296
dev_label=P_f-score_tok: 0.7440594957373482
dev_precision_macro_tok: 0.8625847360701746
dev_recall_macro_tok: 0.7276033391633284
dev_f-score_macro_tok: 0.7810059444442711
dev_precision_micro_tok: 0.8888314374353671
dev_recall_micro_tok: 0.8888314374353671
dev_f-score_micro_tok: 0.8888314374353671
dev_time: 8.370444297790527
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6689    0.6893    0.6789       428
           P     0.5982    0.8851    0.7139       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.7557    0.5292    0.4729      1101
weighted avg     0.7093    0.6276    0.5572      1101

F1-macro sent:  0.4728999461946297
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9751    0.9333     16205
           N     0.8014    0.5692    0.6656      1857
           P     0.8914    0.6385    0.7441      3212

   micro avg     0.8888    0.8888    0.8888     21274
   macro avg     0.8626    0.7276    0.7810     21274
weighted avg     0.8863    0.8888    0.8814     21274

F1-macro tok:  0.7810059444442711
F1-micro tok:  0.8888314374353671
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 331117.03509521484
train_cost_avg: 38.754334631930575
train_count_sent: 8544.0
train_total_correct_sent: 5514.0
train_accuracy_sent: 0.6453651685393258
train_count_tok: 163566.0
train_total_correct_tok: 143509.0
train_accuracy_tok: 0.8773767164325105
train_label=O_precision_sent: 0.4574468085106383
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.05005820721769499
train_label=N_precision_sent: 0.6092639302912176
train_label=N_recall_sent: 0.8027190332326284
train_label=N_f-score_sent: 0.6927388867162039
train_label=P_precision_sent: 0.6881878209831255
train_label=P_recall_sent: 0.7795013850415512
train_label=P_f-score_sent: 0.7310040264969476
train_precision_macro_sent: 0.5849661865949938
train_recall_macro_sent: 0.536232750262165
train_f-score_macro_sent: 0.4912670401436155
train_precision_micro_sent: 0.6453651685393258
train_recall_micro_sent: 0.6453651685393258
train_f-score_micro_sent: 0.6453651685393258
train_label=O_precision_tok: 0.8902576251110453
train_label=O_recall_tok: 0.9671001310847869
train_label=O_f-score_tok: 0.9270893160696458
train_label=N_precision_tok: 0.7612676724546921
train_label=N_recall_tok: 0.5649204337417265
train_label=N_f-score_tok: 0.6485590719857726
train_label=P_precision_tok: 0.8486097955089987
train_label=P_recall_tok: 0.6087860255026581
train_label=P_f-score_tok: 0.708965645656829
train_precision_macro_tok: 0.8333783643582454
train_recall_macro_tok: 0.7136021967763905
train_f-score_macro_tok: 0.7615380112374158
train_precision_micro_tok: 0.8773767164325105
train_recall_micro_tok: 0.8773767164325105
train_f-score_micro_tok: 0.8773767164325105
train_time: 146.10424709320068
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4574    0.0265    0.0501      1624
           N     0.6093    0.8027    0.6927      3310
           P     0.6882    0.7795    0.7310      3610

   micro avg     0.6454    0.6454    0.6454      8544
   macro avg     0.5850    0.5362    0.4913      8544
weighted avg     0.6138    0.6454    0.5867      8544

F1-macro sent:  0.4912670401436155
F1-micro sent:  0.6453651685393258
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8903    0.9671    0.9271    124347
           N     0.7613    0.5649    0.6486     14202
           P     0.8486    0.6088    0.7090     25017

   micro avg     0.8774    0.8774    0.8774    163566
   macro avg     0.8334    0.7136    0.7615    163566
weighted avg     0.8727    0.8774    0.8695    163566

F1-macro tok:  0.7615380112374158
F1-micro tok:  0.8773767164325105
**************************************************
dev_cost_sum: 44112.876037597656
dev_cost_avg: 40.066190769843466
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18967.0
dev_accuracy_tok: 0.8915577700479459
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6239015817223199
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7121364092276831
dev_label=P_precision_sent: 0.6773584905660377
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7371663244353184
dev_precision_macro_sent: 0.7670866907627859
dev_recall_macro_sent: 0.5489104784497185
dev_f-score_macro_sent: 0.4888729169930062
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8956438216848409
dev_label=O_recall_tok: 0.978216599814872
dev_label=O_f-score_tok: 0.93511090136857
dev_label=N_precision_tok: 0.7949852507374632
dev_label=N_recall_tok: 0.5805061927840603
dev_label=N_f-score_tok: 0.6710239651416122
dev_label=P_precision_tok: 0.917981072555205
dev_label=P_recall_tok: 0.6341843088418431
dev_label=P_f-score_tok: 0.7501380961148959
dev_precision_macro_tok: 0.8695367149925031
dev_recall_macro_tok: 0.7309690338135918
dev_f-score_macro_tok: 0.785424320875026
dev_precision_micro_tok: 0.8915577700479459
dev_recall_micro_tok: 0.8915577700479459
dev_f-score_micro_tok: 0.8915577700479459
dev_time: 7.947998285293579
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6239    0.8294    0.7121       428
           P     0.6774    0.8086    0.7372       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.7671    0.5489    0.4889      1101
weighted avg     0.7237    0.6503    0.5777      1101

F1-macro sent:  0.4888729169930062
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8956    0.9782    0.9351     16205
           N     0.7950    0.5805    0.6710      1857
           P     0.9180    0.6342    0.7501      3212

   micro avg     0.8916    0.8916    0.8916     21274
   macro avg     0.8695    0.7310    0.7854     21274
weighted avg     0.8902    0.8916    0.8841     21274

F1-macro tok:  0.785424320875026
F1-micro tok:  0.8915577700479459
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328726.0694580078
train_cost_avg: 38.47449314817507
train_count_sent: 8544.0
train_total_correct_sent: 5499.0
train_accuracy_sent: 0.6436095505617978
train_count_tok: 163566.0
train_total_correct_tok: 143935.0
train_accuracy_tok: 0.8799811696807405
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.04918032786885246
train_label=N_precision_sent: 0.6118143459915611
train_label=N_recall_sent: 0.7885196374622356
train_label=N_f-score_sent: 0.6890179514255543
train_label=P_precision_sent: 0.678826895565093
train_label=P_recall_sent: 0.7886426592797784
train_label=P_f-score_sent: 0.729625832906202
train_precision_macro_sent: 0.596880413852218
train_recall_macro_sent: 0.5343414552358438
train_f-score_macro_sent: 0.4892747040668696
train_precision_micro_sent: 0.6436095505617978
train_recall_micro_sent: 0.6436095505617978
train_f-score_micro_sent: 0.6436095505617978
train_label=O_precision_tok: 0.8922969779141013
train_label=O_recall_tok: 0.9685476931490105
train_label=O_f-score_tok: 0.9288600956347369
train_label=N_precision_tok: 0.7619627305927521
train_label=N_recall_tok: 0.5729474721870159
train_label=N_f-score_tok: 0.6540733893332262
train_label=P_precision_tok: 0.857541587585129
train_label=P_recall_tok: 0.6140624375424711
train_label=P_f-score_tok: 0.7156600125783233
train_precision_macro_tok: 0.8372670986973274
train_recall_macro_tok: 0.7185192009594993
train_f-score_macro_tok: 0.766197832515429
train_precision_micro_tok: 0.8799811696807405
train_recall_micro_tok: 0.8799811696807405
train_f-score_micro_tok: 0.8799811696807406
train_time: 145.9856014251709
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0259    0.0492      1624
           N     0.6118    0.7885    0.6890      3310
           P     0.6788    0.7886    0.7296      3610

   micro avg     0.6436    0.6436    0.6436      8544
   macro avg     0.5969    0.5343    0.4893      8544
weighted avg     0.6189    0.6436    0.5846      8544

F1-macro sent:  0.4892747040668696
F1-micro sent:  0.6436095505617978
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8923    0.9685    0.9289    124347
           N     0.7620    0.5729    0.6541     14202
           P     0.8575    0.6141    0.7157     25017

   micro avg     0.8800    0.8800    0.8800    163566
   macro avg     0.8373    0.7185    0.7662    163566
weighted avg     0.8757    0.8800    0.8724    163566

F1-macro tok:  0.766197832515429
F1-micro tok:  0.8799811696807406
**************************************************
dev_cost_sum: 43873.29235839844
dev_cost_avg: 39.84858524831829
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 18958.0
dev_accuracy_tok: 0.8911347184356492
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.6313932980599647
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7195979899497487
dev_label=P_precision_sent: 0.6821705426356589
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7333333333333333
dev_precision_macro_sent: 0.6415583172689115
dev_recall_macro_sent: 0.5590921084738169
dev_f-score_macro_sent: 0.5140000497313376
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.8937978388113462
dev_label=O_recall_tok: 0.9800061709348966
dev_label=O_f-score_tok: 0.9349189061902099
dev_label=N_precision_tok: 0.8441558441558441
dev_label=N_recall_tok: 0.5250403877221325
dev_label=N_f-score_tok: 0.647410358565737
dev_label=P_precision_tok: 0.8940876222883879
dev_label=P_recall_tok: 0.6544209215442092
dev_label=P_f-score_tok: 0.7557073521481215
dev_precision_macro_tok: 0.8773471017518594
dev_recall_macro_tok: 0.7198224934004127
dev_f-score_macro_tok: 0.7793455389680228
dev_precision_micro_tok: 0.8911347184356492
dev_recall_micro_tok: 0.8911347184356492
dev_f-score_micro_tok: 0.8911347184356491
dev_time: 7.4743123054504395
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.6314    0.8364    0.7196       428
           P     0.6822    0.7928    0.7333       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6416    0.5591    0.5140      1101
weighted avg     0.6477    0.6549    0.5940      1101

F1-macro sent:  0.5140000497313376
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8938    0.9800    0.9349     16205
           N     0.8442    0.5250    0.6474      1857
           P     0.8941    0.6544    0.7557      3212

   micro avg     0.8911    0.8911    0.8911     21274
   macro avg     0.8773    0.7198    0.7793     21274
weighted avg     0.8895    0.8911    0.8828     21274

F1-macro tok:  0.7793455389680228
F1-micro tok:  0.8911347184356491
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325944.20703125
train_cost_avg: 38.14890063568001
train_count_sent: 8544.0
train_total_correct_sent: 5586.0
train_accuracy_sent: 0.6537921348314607
train_count_tok: 163566.0
train_total_correct_tok: 144410.0
train_accuracy_tok: 0.8828851961899172
train_label=O_precision_sent: 0.45962732919254656
train_label=O_recall_sent: 0.04556650246305419
train_label=O_f-score_sent: 0.08291316526610645
train_label=N_precision_sent: 0.6229777256740915
train_label=N_recall_sent: 0.8027190332326284
train_label=N_f-score_sent: 0.7015181518151815
train_label=P_precision_sent: 0.6932977173385139
train_label=P_recall_sent: 0.7908587257617729
train_label=P_f-score_sent: 0.7388716356107661
train_precision_macro_sent: 0.5919675907350506
train_recall_macro_sent: 0.5463814204858185
train_f-score_macro_sent: 0.5077676508973513
train_precision_micro_sent: 0.6537921348314607
train_recall_micro_sent: 0.6537921348314607
train_f-score_micro_sent: 0.6537921348314607
train_label=O_precision_tok: 0.8948983306464194
train_label=O_recall_tok: 0.9687085333783686
train_label=O_f-score_tok: 0.9303417648194632
train_label=N_precision_tok: 0.7686140803538518
train_label=N_recall_tok: 0.5873116462470075
train_label=N_f-score_tok: 0.665841781751417
train_label=P_precision_tok: 0.8620727734525979
train_label=P_recall_tok: 0.6240956149818123
train_label=P_f-score_tok: 0.7240307920608422
train_precision_macro_tok: 0.8418617281509565
train_recall_macro_tok: 0.7267052648690627
train_f-score_macro_tok: 0.7734047795439074
train_precision_micro_tok: 0.8828851961899172
train_recall_micro_tok: 0.8828851961899172
train_f-score_micro_tok: 0.8828851961899172
train_time: 146.7964026927948
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4596    0.0456    0.0829      1624
           N     0.6230    0.8027    0.7015      3310
           P     0.6933    0.7909    0.7389      3610

   micro avg     0.6538    0.6538    0.6538      8544
   macro avg     0.5920    0.5464    0.5078      8544
weighted avg     0.6216    0.6538    0.5997      8544

F1-macro sent:  0.5077676508973513
F1-micro sent:  0.6537921348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9687    0.9303    124347
           N     0.7686    0.5873    0.6658     14202
           P     0.8621    0.6241    0.7240     25017

   micro avg     0.8829    0.8829    0.8829    163566
   macro avg     0.8419    0.7267    0.7734    163566
weighted avg     0.8789    0.8829    0.8758    163566

F1-macro tok:  0.7734047795439074
F1-micro tok:  0.8828851961899172
**************************************************
dev_cost_sum: 43687.164611816406
dev_cost_avg: 39.679531890841425
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19025.0
dev_accuracy_tok: 0.8942841026605246
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.059322033898305086
dev_label=N_precision_sent: 0.6301369863013698
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7272727272727273
dev_label=P_precision_sent: 0.692156862745098
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.740041928721174
dev_precision_macro_sent: 0.774097949682156
dev_recall_macro_sent: 0.5618086049155714
dev_f-score_macro_sent: 0.5088788966307355
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.8998465298698346
dev_label=O_recall_tok: 0.9769207034865782
dev_label=O_f-score_tok: 0.9368009941416652
dev_label=N_precision_tok: 0.8082901554404145
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6807980049875313
dev_label=P_precision_tok: 0.9021459227467811
dev_label=P_recall_tok: 0.6544209215442092
dev_label=P_f-score_tok: 0.7585709130277878
dev_precision_macro_tok: 0.8700942026856767
dev_recall_macro_tok: 0.7397956197598585
dev_f-score_macro_tok: 0.7920566373856613
dev_precision_micro_tok: 0.8942841026605246
dev_recall_micro_tok: 0.8942841026605246
dev_f-score_micro_tok: 0.8942841026605246
dev_time: 7.542145490646362
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0306    0.0593       229
           N     0.6301    0.8598    0.7273       428
           P     0.6922    0.7950    0.7400       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.7741    0.5618    0.5089      1101
weighted avg     0.7321    0.6612    0.5935      1101

F1-macro sent:  0.5088788966307355
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8998    0.9769    0.9368     16205
           N     0.8083    0.5880    0.6808      1857
           P     0.9021    0.6544    0.7586      3212

   micro avg     0.8943    0.8943    0.8943     21274
   macro avg     0.8701    0.7398    0.7921     21274
weighted avg     0.8922    0.8943    0.8875     21274

F1-macro tok:  0.7920566373856613
F1-micro tok:  0.8942841026605246
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323969.9913330078
train_cost_avg: 37.917836064256534
train_count_sent: 8544.0
train_total_correct_sent: 5585.0
train_accuracy_sent: 0.6536750936329588
train_count_tok: 163566.0
train_total_correct_tok: 144672.0
train_accuracy_tok: 0.8844869960749789
train_label=O_precision_sent: 0.5694444444444444
train_label=O_recall_sent: 0.050492610837438424
train_label=O_f-score_sent: 0.09276018099547513
train_label=N_precision_sent: 0.626231083353351
train_label=N_recall_sent: 0.7876132930513595
train_label=N_f-score_sent: 0.69771176234444
train_label=P_precision_sent: 0.6835024781685155
train_label=P_recall_sent: 0.8022160664819945
train_label=P_f-score_sent: 0.738116477634765
train_precision_macro_sent: 0.626392668655437
train_recall_macro_sent: 0.5467739901235974
train_f-score_macro_sent: 0.5095294736582267
train_precision_micro_sent: 0.6536750936329588
train_recall_micro_sent: 0.6536750936329588
train_f-score_micro_sent: 0.6536750936329588
train_label=O_precision_tok: 0.8958550069851083
train_label=O_recall_tok: 0.9695207765366274
train_label=O_f-score_tok: 0.931233320073073
train_label=N_precision_tok: 0.7785957485966688
train_label=N_recall_tok: 0.5957611603999436
train_label=N_f-score_tok: 0.6750169532091428
train_label=P_precision_tok: 0.8635736746290065
train_label=P_recall_tok: 0.6257345005396331
train_label=P_f-score_tok: 0.7256628963471168
train_precision_macro_tok: 0.8460081434035945
train_recall_macro_tok: 0.730338812492068
train_f-score_macro_tok: 0.7773043898764441
train_precision_micro_tok: 0.8844869960749789
train_recall_micro_tok: 0.8844869960749789
train_f-score_micro_tok: 0.8844869960749789
train_time: 146.04265022277832
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5694    0.0505    0.0928      1624
           N     0.6262    0.7876    0.6977      3310
           P     0.6835    0.8022    0.7381      3610

   micro avg     0.6537    0.6537    0.6537      8544
   macro avg     0.6264    0.5468    0.5095      8544
weighted avg     0.6396    0.6537    0.5998      8544

F1-macro sent:  0.5095294736582267
F1-micro sent:  0.6536750936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9695    0.9312    124347
           N     0.7786    0.5958    0.6750     14202
           P     0.8636    0.6257    0.7257     25017

   micro avg     0.8845    0.8845    0.8845    163566
   macro avg     0.8460    0.7303    0.7773    163566
weighted avg     0.8807    0.8845    0.8775    163566

F1-macro tok:  0.7773043898764441
F1-micro tok:  0.8844869960749789
**************************************************
dev_cost_sum: 43443.02429199219
dev_cost_avg: 39.457787731146404
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 0.8461538461538461
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09090909090909091
dev_label=N_precision_sent: 0.5966514459665144
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.7225806451612904
dev_label=P_precision_sent: 0.740139211136891
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7291428571428571
dev_precision_macro_sent: 0.7276481677524173
dev_recall_macro_sent: 0.5607970844778583
dev_f-score_macro_sent: 0.5142108644044128
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.8968944099378882
dev_label=O_recall_tok: 0.9801912989817957
dev_label=O_f-score_tok: 0.9366946778711485
dev_label=N_precision_tok: 0.8001469507714916
dev_label=N_recall_tok: 0.5864297253634895
dev_label=N_f-score_tok: 0.6768178993163455
dev_label=P_precision_tok: 0.9273717657739446
dev_label=P_recall_tok: 0.636052303860523
dev_label=P_f-score_tok: 0.7545706371191137
dev_precision_macro_tok: 0.8748043754944415
dev_recall_macro_tok: 0.7342244427352694
dev_f-score_macro_tok: 0.7893610714355358
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 7.24861216545105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8462    0.0480    0.0909       229
           N     0.5967    0.9159    0.7226       428
           P     0.7401    0.7185    0.7291       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7276    0.5608    0.5142      1101
weighted avg     0.7064    0.6558    0.5938      1101

F1-macro sent:  0.5142108644044128
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8969    0.9802    0.9367     16205
           N     0.8001    0.5864    0.6768      1857
           P     0.9274    0.6361    0.7546      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8748    0.7342    0.7894     21274
weighted avg     0.8931    0.8939    0.8865     21274

F1-macro tok:  0.7893610714355358
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 322002.42401123047
train_cost_avg: 37.68754962678259
train_count_sent: 8544.0
train_total_correct_sent: 5542.0
train_accuracy_sent: 0.6486423220973783
train_count_tok: 163566.0
train_total_correct_tok: 144928.0
train_accuracy_tok: 0.8860521135199246
train_label=O_precision_sent: 0.4230769230769231
train_label=O_recall_sent: 0.04064039408866995
train_label=O_f-score_sent: 0.07415730337078652
train_label=N_precision_sent: 0.6196550909520435
train_label=N_recall_sent: 0.7924471299093656
train_label=N_f-score_sent: 0.6954792522868886
train_label=P_precision_sent: 0.6866425992779783
train_label=P_recall_sent: 0.7903047091412743
train_label=P_f-score_sent: 0.7348358016741791
train_precision_macro_sent: 0.5764582044356483
train_recall_macro_sent: 0.5411307443797699
train_f-score_macro_sent: 0.5014907857772847
train_precision_micro_sent: 0.6486423220973783
train_recall_micro_sent: 0.6486423220973783
train_f-score_micro_sent: 0.6486423220973783
train_label=O_precision_tok: 0.8975566566968737
train_label=O_recall_tok: 0.97016413745406
train_label=O_f-score_tok: 0.9324490923776729
train_label=N_precision_tok: 0.7745224099926524
train_label=N_recall_tok: 0.5937896070975919
train_label=N_f-score_tok: 0.6722200079713033
train_label=P_precision_tok: 0.867885288966725
train_label=P_recall_tok: 0.633888955510253
train_label=P_f-score_tok: 0.7326572570398948
train_precision_macro_tok: 0.8466547852187504
train_recall_macro_tok: 0.7326142333539684
train_f-score_macro_tok: 0.7791087857962903
train_precision_micro_tok: 0.8860521135199246
train_recall_micro_tok: 0.8860521135199246
train_f-score_micro_tok: 0.8860521135199246
train_time: 146.43418741226196
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4231    0.0406    0.0742      1624
           N     0.6197    0.7924    0.6955      3310
           P     0.6866    0.7903    0.7348      3610

   micro avg     0.6486    0.6486    0.6486      8544
   macro avg     0.5765    0.5411    0.5015      8544
weighted avg     0.6106    0.6486    0.5940      8544

F1-macro sent:  0.5014907857772847
F1-micro sent:  0.6486423220973783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8976    0.9702    0.9324    124347
           N     0.7745    0.5938    0.6722     14202
           P     0.8679    0.6339    0.7327     25017

   micro avg     0.8861    0.8861    0.8861    163566
   macro avg     0.8467    0.7326    0.7791    163566
weighted avg     0.8823    0.8861    0.8793    163566

F1-macro tok:  0.7791087857962903
F1-micro tok:  0.8860521135199246
**************************************************
dev_cost_sum: 43255.008361816406
dev_cost_avg: 39.28701940219474
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19045.0
dev_accuracy_tok: 0.8952242173545173
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.059322033898305086
dev_label=N_precision_sent: 0.6838709677419355
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7122060470324748
dev_label=P_precision_sent: 0.6184419713831478
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.7250698974836906
dev_precision_macro_sent: 0.7674376463750278
dev_recall_macro_sent: 0.5498948219737511
dev_f-score_macro_sent: 0.4988659928048234
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.9006027521892415
dev_label=O_recall_tok: 0.9773526689293428
dev_label=O_f-score_tok: 0.937409369358705
dev_label=N_precision_tok: 0.7932251235003529
dev_label=N_recall_tok: 0.6052773290253096
dev_label=N_f-score_tok: 0.6866218692730606
dev_label=P_precision_tok: 0.9172170849845883
dev_label=P_recall_tok: 0.6485056039850561
dev_label=P_f-score_tok: 0.7598030275396681
dev_precision_macro_tok: 0.8703483202247275
dev_recall_macro_tok: 0.7437118673132362
dev_f-score_macro_tok: 0.7946114220571445
dev_precision_micro_tok: 0.8952242173545173
dev_recall_micro_tok: 0.8952242173545173
dev_f-score_micro_tok: 0.8952242173545172
dev_time: 7.428150415420532
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0306    0.0593       229
           N     0.6839    0.7430    0.7122       428
           P     0.6184    0.8761    0.7251       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.7674    0.5499    0.4989      1101
weighted avg     0.7232    0.6485    0.5816      1101

F1-macro sent:  0.4988659928048234
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9006    0.9774    0.9374     16205
           N     0.7932    0.6053    0.6866      1857
           P     0.9172    0.6485    0.7598      3212

   micro avg     0.8952    0.8952    0.8952     21274
   macro avg     0.8703    0.7437    0.7946     21274
weighted avg     0.8937    0.8952    0.8887     21274

F1-macro tok:  0.7946114220571445
F1-micro tok:  0.8952242173545172
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319867.45935058594
train_cost_avg: 37.43767080414161
train_count_sent: 8544.0
train_total_correct_sent: 5612.0
train_accuracy_sent: 0.6568352059925093
train_count_tok: 163566.0
train_total_correct_tok: 145118.0
train_accuracy_tok: 0.8872137241235953
train_label=O_precision_sent: 0.4411764705882353
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08361204013377926
train_label=N_precision_sent: 0.6128887894383531
train_label=N_recall_sent: 0.8274924471299093
train_label=N_f-score_sent: 0.7042036251446201
train_label=P_precision_sent: 0.7165172855313701
train_label=P_recall_sent: 0.7750692520775623
train_label=P_f-score_sent: 0.7446440452428477
train_precision_macro_sent: 0.5901941818526528
train_recall_macro_sent: 0.549581321739108
train_f-score_macro_sent: 0.5108199035070823
train_precision_micro_sent: 0.6568352059925093
train_recall_micro_sent: 0.6568352059925093
train_f-score_micro_sent: 0.6568352059925093
train_label=O_precision_tok: 0.8990567796294225
train_label=O_recall_tok: 0.9696816167659855
train_label=O_f-score_tok: 0.9330346433905178
train_label=N_precision_tok: 0.7771024222081103
train_label=N_recall_tok: 0.6031544852837628
train_label=N_f-score_tok: 0.6791674925668979
train_label=P_precision_tok: 0.8668873453440417
train_label=P_recall_tok: 0.6385657752728144
train_label=P_f-score_tok: 0.7354125906318332
train_precision_macro_tok: 0.8476821823938582
train_recall_macro_tok: 0.7371339591075209
train_f-score_macro_tok: 0.7825382421964163
train_precision_micro_tok: 0.8872137241235953
train_recall_micro_tok: 0.8872137241235953
train_f-score_micro_tok: 0.8872137241235953
train_time: 147.2344856262207
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4412    0.0462    0.0836      1624
           N     0.6129    0.8275    0.7042      3310
           P     0.7165    0.7751    0.7446      3610

   micro avg     0.6568    0.6568    0.6568      8544
   macro avg     0.5902    0.5496    0.5108      8544
weighted avg     0.6240    0.6568    0.6033      8544

F1-macro sent:  0.5108199035070823
F1-micro sent:  0.6568352059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9697    0.9330    124347
           N     0.7771    0.6032    0.6792     14202
           P     0.8669    0.6386    0.7354     25017

   micro avg     0.8872    0.8872    0.8872    163566
   macro avg     0.8477    0.7371    0.7825    163566
weighted avg     0.8835    0.8872    0.8808    163566

F1-macro tok:  0.7825382421964163
F1-micro tok:  0.8872137241235953
**************************************************
dev_cost_sum: 43034.62780761719
dev_cost_avg: 39.086855411096444
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19052.0
dev_accuracy_tok: 0.8955532574974147
dev_label=O_precision_sent: 0.8235294117647058
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.1138211382113821
dev_label=N_precision_sent: 0.6131621187800963
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.7269267364414843
dev_label=P_precision_sent: 0.720173535791757
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7337016574585635
dev_precision_macro_sent: 0.7189550221121864
dev_recall_macro_sent: 0.5671354944709228
dev_f-score_macro_sent: 0.52481651070381
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.8985285795132993
dev_label=O_recall_tok: 0.9797593335390312
dev_label=O_f-score_tok: 0.9373874538745388
dev_label=N_precision_tok: 0.8157894736842105
dev_label=N_recall_tok: 0.5842757135164244
dev_label=N_f-score_tok: 0.6808911201757138
dev_label=P_precision_tok: 0.9190853122251539
dev_label=P_recall_tok: 0.6506849315068494
dev_label=P_f-score_tok: 0.7619394823186293
dev_precision_macro_tok: 0.8778011218075547
dev_recall_macro_tok: 0.7382399928541017
dev_f-score_macro_tok: 0.7934060187896274
dev_precision_micro_tok: 0.8955532574974147
dev_recall_micro_tok: 0.8955532574974147
dev_f-score_micro_tok: 0.8955532574974148
dev_time: 7.240471124649048
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8235    0.0611    0.1138       229
           N     0.6132    0.8925    0.7269       428
           P     0.7202    0.7477    0.7337       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.7190    0.5671    0.5248      1101
weighted avg     0.7001    0.6612    0.6021      1101

F1-macro sent:  0.52481651070381
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9798    0.9374     16205
           N     0.8158    0.5843    0.6809      1857
           P     0.9191    0.6507    0.7619      3212

   micro avg     0.8956    0.8956    0.8956     21274
   macro avg     0.8778    0.7382    0.7934     21274
weighted avg     0.8944    0.8956    0.8885     21274

F1-macro tok:  0.7934060187896274
F1-micro tok:  0.8955532574974148
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317422.7903442383
train_cost_avg: 37.151543813698304
train_count_sent: 8544.0
train_total_correct_sent: 5675.0
train_accuracy_sent: 0.6642088014981273
train_count_tok: 163566.0
train_total_correct_tok: 145625.0
train_accuracy_tok: 0.8903133903133903
train_label=O_precision_sent: 0.41711229946524064
train_label=O_recall_sent: 0.0480295566502463
train_label=O_f-score_sent: 0.08614025400331307
train_label=N_precision_sent: 0.629672358098754
train_label=N_recall_sent: 0.8244712990936556
train_label=N_f-score_sent: 0.7140240711669283
train_label=P_precision_sent: 0.7129008202833707
train_label=P_recall_sent: 0.7944598337950138
train_label=P_f-score_sent: 0.7514738634874885
train_precision_macro_sent: 0.5865618259491218
train_recall_macro_sent: 0.5556535631796385
train_f-score_macro_sent: 0.5172127295525767
train_precision_micro_sent: 0.6642088014981273
train_recall_micro_sent: 0.6642088014981273
train_f-score_micro_sent: 0.6642088014981273
train_label=O_precision_tok: 0.901804595553895
train_label=O_recall_tok: 0.9705421119930517
train_label=O_f-score_tok: 0.9349116093147205
train_label=N_precision_tok: 0.7850400071923043
train_label=N_recall_tok: 0.6148429798619913
train_label=N_f-score_tok: 0.6895952615992104
train_label=P_precision_tok: 0.8706090879793748
train_label=P_recall_tok: 0.6479194147979374
train_label=P_f-score_tok: 0.7429357167411481
train_precision_macro_tok: 0.8524845635751914
train_recall_macro_tok: 0.7444348355509934
train_f-score_macro_tok: 0.7891475292183596
train_precision_micro_tok: 0.8903133903133903
train_recall_micro_tok: 0.8903133903133903
train_f-score_micro_tok: 0.8903133903133903
train_time: 148.02120995521545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4171    0.0480    0.0861      1624
           N     0.6297    0.8245    0.7140      3310
           P     0.7129    0.7945    0.7515      3610

   micro avg     0.6642    0.6642    0.6642      8544
   macro avg     0.5866    0.5557    0.5172      8544
weighted avg     0.6244    0.6642    0.6105      8544

F1-macro sent:  0.5172127295525767
F1-micro sent:  0.6642088014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9705    0.9349    124347
           N     0.7850    0.6148    0.6896     14202
           P     0.8706    0.6479    0.7429     25017

   micro avg     0.8903    0.8903    0.8903    163566
   macro avg     0.8525    0.7444    0.7891    163566
weighted avg     0.8869    0.8903    0.8842    163566

F1-macro tok:  0.7891475292183596
F1-micro tok:  0.8903133903133903
**************************************************
dev_cost_sum: 43057.56982421875
dev_cost_avg: 39.10769284670186
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19047.0
dev_accuracy_tok: 0.8953182288239165
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11244979919678715
dev_label=N_precision_sent: 0.6693069306930693
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7245444801714898
dev_label=P_precision_sent: 0.6527777777777778
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7372549019607842
dev_precision_macro_sent: 0.674028236156949
dev_recall_macro_sent: 0.5659006147313702
dev_f-score_macro_sent: 0.524749727109687
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.8966411181244365
dev_label=O_recall_tok: 0.9817957420549214
dev_label=O_f-score_tok: 0.9372882853692304
dev_label=N_precision_tok: 0.8241673121611154
dev_label=N_recall_tok: 0.5729671513193323
dev_label=N_f-score_tok: 0.6759847522236341
dev_label=P_precision_tok: 0.9258597588209022
dev_label=P_recall_tok: 0.6453922789539228
dev_label=P_f-score_tok: 0.7605943863511283
dev_precision_macro_tok: 0.8822227297021513
dev_recall_macro_tok: 0.7333850574427254
dev_f-score_macro_tok: 0.7912891413146642
dev_precision_micro_tok: 0.8953182288239165
dev_recall_micro_tok: 0.8953182288239165
dev_f-score_micro_tok: 0.8953182288239167
dev_time: 7.563859462738037
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0611    0.1124       229
           N     0.6693    0.7897    0.7245       428
           P     0.6528    0.8468    0.7373       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6740    0.5659    0.5247      1101
weighted avg     0.6690    0.6612    0.6024      1101

F1-macro sent:  0.524749727109687
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9818    0.9373     16205
           N     0.8242    0.5730    0.6760      1857
           P     0.9259    0.6454    0.7606      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8822    0.7334    0.7913     21274
weighted avg     0.8947    0.8953    0.8878     21274

F1-macro tok:  0.7912891413146642
F1-micro tok:  0.8953182288239167
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315782.19873046875
train_cost_avg: 36.959527004970596
train_count_sent: 8544.0
train_total_correct_sent: 5707.0
train_accuracy_sent: 0.6679541198501873
train_count_tok: 163566.0
train_total_correct_tok: 145677.0
train_accuracy_tok: 0.8906313047943949
train_label=O_precision_sent: 0.5028248587570622
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.09883398112159913
train_label=N_precision_sent: 0.6374643874643875
train_label=N_recall_sent: 0.8111782477341389
train_label=N_f-score_sent: 0.7139058760967828
train_label=P_precision_sent: 0.7058965102286402
train_label=P_recall_sent: 0.8124653739612189
train_label=P_f-score_sent: 0.7554410817772055
train_precision_macro_sent: 0.61539525215003
train_recall_macro_sent: 0.5594821924534609
train_f-score_macro_sent: 0.5227269796651958
train_precision_micro_sent: 0.6679541198501873
train_recall_micro_sent: 0.6679541198501873
train_f-score_micro_sent: 0.6679541198501873
train_label=O_precision_tok: 0.9023545602776406
train_label=O_recall_tok: 0.9702123895228675
train_label=O_f-score_tok: 0.9350539634559863
train_label=N_precision_tok: 0.7836800285688778
train_label=N_recall_tok: 0.6180819602872835
train_label=N_f-score_tok: 0.6910994764397906
train_label=P_precision_tok: 0.8708415921144266
train_label=P_recall_tok: 0.6497981372666587
train_label=P_f-score_tok: 0.7442541891768153
train_precision_macro_tok: 0.8522920603203149
train_recall_macro_tok: 0.7460308290256031
train_f-score_macro_tok: 0.7901358763575308
train_precision_micro_tok: 0.8906313047943949
train_recall_micro_tok: 0.8906313047943949
train_f-score_micro_tok: 0.8906313047943949
train_time: 147.5104057788849
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5028    0.0548    0.0988      1624
           N     0.6375    0.8112    0.7139      3310
           P     0.7059    0.8125    0.7554      3610

   micro avg     0.6680    0.6680    0.6680      8544
   macro avg     0.6154    0.5595    0.5227      8544
weighted avg     0.6408    0.6680    0.6145      8544

F1-macro sent:  0.5227269796651958
F1-micro sent:  0.6679541198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9702    0.9351    124347
           N     0.7837    0.6181    0.6911     14202
           P     0.8708    0.6498    0.7443     25017

   micro avg     0.8906    0.8906    0.8906    163566
   macro avg     0.8523    0.7460    0.7901    163566
weighted avg     0.8872    0.8906    0.8847    163566

F1-macro tok:  0.7901358763575308
F1-micro tok:  0.8906313047943949
**************************************************
dev_cost_sum: 42719.7822265625
dev_cost_avg: 38.800892122218436
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19079.0
dev_accuracy_tok: 0.8968224123343048
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6254237288135593
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.724950884086444
dev_label=P_precision_sent: 0.6956521739130435
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7410526315789474
dev_precision_macro_sent: 0.7070253009088677
dev_recall_macro_sent: 0.5574698581371234
dev_f-score_macro_sent: 0.5000638499511418
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9026407346147265
dev_label=O_recall_tok: 0.9766121567417464
dev_label=O_f-score_tok: 0.9381706088090581
dev_label=N_precision_tok: 0.8092443140132062
dev_label=N_recall_tok: 0.5939687668282175
dev_label=N_f-score_tok: 0.6850931677018633
dev_label=P_precision_tok: 0.904121110176619
dev_label=P_recall_tok: 0.6693648816936488
dev_label=P_f-score_tok: 0.7692307692307692
dev_precision_macro_tok: 0.8720020529348506
dev_recall_macro_tok: 0.7466486017545376
dev_f-score_macro_tok: 0.7974981819138969
dev_precision_micro_tok: 0.8968224123343048
dev_recall_micro_tok: 0.8968224123343048
dev_f-score_micro_tok: 0.8968224123343048
dev_time: 7.6441614627838135
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6254    0.8621    0.7250       428
           P     0.6957    0.7928    0.7411       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.7070    0.5575    0.5001      1101
weighted avg     0.6901    0.6585    0.5878      1101

F1-macro sent:  0.5000638499511418
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9026    0.9766    0.9382     16205
           N     0.8092    0.5940    0.6851      1857
           P     0.9041    0.6694    0.7692      3212

   micro avg     0.8968    0.8968    0.8968     21274
   macro avg     0.8720    0.7466    0.7975     21274
weighted avg     0.8947    0.8968    0.8906     21274

F1-macro tok:  0.7974981819138969
F1-micro tok:  0.8968224123343048
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313923.2035522461
train_cost_avg: 36.74194798130221
train_count_sent: 8544.0
train_total_correct_sent: 5712.0
train_accuracy_sent: 0.6685393258426966
train_count_tok: 163566.0
train_total_correct_tok: 146026.0
train_accuracy_tok: 0.8927650000611373
train_label=O_precision_sent: 0.44776119402985076
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.09863013698630137
train_label=N_precision_sent: 0.6462503014227152
train_label=N_recall_sent: 0.8096676737160121
train_label=N_f-score_sent: 0.7187877162397747
train_label=P_precision_sent: 0.7011439466158246
train_label=P_recall_sent: 0.8149584487534626
train_label=P_f-score_sent: 0.7537791442480143
train_precision_macro_sent: 0.5983851473561302
train_recall_macro_sent: 0.5600149472270991
train_f-score_macro_sent: 0.5237323324913635
train_precision_micro_sent: 0.6685393258426966
train_recall_micro_sent: 0.6685393258426966
train_f-score_micro_sent: 0.6685393258426966
train_label=O_precision_tok: 0.9045127828452793
train_label=O_recall_tok: 0.970517985958648
train_label=O_f-score_tok: 0.9363536203097359
train_label=N_precision_tok: 0.7868910540301152
train_label=N_recall_tok: 0.6255456977890438
train_label=N_f-score_tok: 0.6970029813274753
train_label=P_precision_tok: 0.8730310262529833
train_label=P_recall_tok: 0.6579925650557621
train_label=P_f-score_tok: 0.750410284463895
train_precision_macro_tok: 0.8548116210427926
train_recall_macro_tok: 0.7513520829344845
train_f-score_macro_tok: 0.7945889620337021
train_precision_micro_tok: 0.8927650000611373
train_recall_micro_tok: 0.8927650000611373
train_f-score_micro_tok: 0.8927650000611373
train_time: 146.2916784286499
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4478    0.0554    0.0986      1624
           N     0.6463    0.8097    0.7188      3310
           P     0.7011    0.8150    0.7538      3610

   micro avg     0.6685    0.6685    0.6685      8544
   macro avg     0.5984    0.5600    0.5237      8544
weighted avg     0.6317    0.6685    0.6157      8544

F1-macro sent:  0.5237323324913635
F1-micro sent:  0.6685393258426966
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9045    0.9705    0.9364    124347
           N     0.7869    0.6255    0.6970     14202
           P     0.8730    0.6580    0.7504     25017

   micro avg     0.8928    0.8928    0.8928    163566
   macro avg     0.8548    0.7514    0.7946    163566
weighted avg     0.8895    0.8928    0.8871    163566

F1-macro tok:  0.7945889620337021
F1-micro tok:  0.8927650000611373
**************************************************
dev_cost_sum: 42672.078125
dev_cost_avg: 38.7575641462307
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.6399317406143344
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7396449704142012
dev_label=P_precision_sent: 0.6986301369863014
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7476439790575916
dev_precision_macro_sent: 0.7795206258668786
dev_recall_macro_sent: 0.5658965090871387
dev_f-score_macro_sent: 0.5072079044734302
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.906508739650414
dev_label=O_recall_tok: 0.9729095958037642
dev_label=O_f-score_tok: 0.9385361788254903
dev_label=N_precision_tok: 0.8113069016152716
dev_label=N_recall_tok: 0.5950457727517501
dev_label=N_f-score_tok: 0.6865486175831003
dev_label=P_precision_tok: 0.8785714285714286
dev_label=P_recall_tok: 0.6892901618929016
dev_label=P_f-score_tok: 0.7725052337752966
dev_precision_macro_tok: 0.8654623566123715
dev_recall_macro_tok: 0.7524151768161387
dev_f-score_macro_tok: 0.7991966767279624
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 7.578109502792358
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.6399    0.8762    0.7396       428
           P     0.6986    0.8041    0.7476       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.7795    0.5659    0.5072      1101
weighted avg     0.7385    0.6685    0.5962      1101

F1-macro sent:  0.5072079044734302
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9729    0.9385     16205
           N     0.8113    0.5950    0.6865      1857
           P     0.8786    0.6893    0.7725      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8655    0.7524    0.7992     21274
weighted avg     0.8940    0.8971    0.8915     21274

F1-macro tok:  0.7991966767279624
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 311993.68377685547
train_cost_avg: 36.51611467425743
train_count_sent: 8544.0
train_total_correct_sent: 5754.0
train_accuracy_sent: 0.6734550561797753
train_count_tok: 163566.0
train_total_correct_tok: 146431.0
train_accuracy_tok: 0.8952410647689618
train_label=O_precision_sent: 0.47368421052631576
train_label=O_recall_sent: 0.08312807881773399
train_label=O_f-score_sent: 0.141435306443164
train_label=N_precision_sent: 0.6481526201400628
train_label=N_recall_sent: 0.8108761329305136
train_label=N_f-score_sent: 0.72044020936787
train_label=P_precision_sent: 0.7127246236036912
train_label=P_recall_sent: 0.8130193905817175
train_label=P_f-score_sent: 0.759575569358178
train_precision_macro_sent: 0.61152048475669
train_recall_macro_sent: 0.5690078674433217
train_f-score_macro_sent: 0.540483695056404
train_precision_micro_sent: 0.6734550561797753
train_recall_micro_sent: 0.6734550561797753
train_f-score_micro_sent: 0.6734550561797753
train_label=O_precision_tok: 0.9066810846531047
train_label=O_recall_tok: 0.9709924646352546
train_label=O_f-score_tok: 0.9377354240934472
train_label=N_precision_tok: 0.7936633315780235
train_label=N_recall_tok: 0.6367413040416843
train_label=N_f-score_tok: 0.7065947804344429
train_label=P_precision_tok: 0.8759800052617732
train_label=P_recall_tok: 0.6654674821121638
train_label=P_f-score_tok: 0.7563490981781837
train_precision_macro_tok: 0.8587748071643005
train_recall_macro_tok: 0.7577337502630342
train_f-score_macro_tok: 0.8002264342353579
train_precision_micro_tok: 0.8952410647689618
train_recall_micro_tok: 0.8952410647689618
train_f-score_micro_tok: 0.8952410647689618
train_time: 147.2771499156952
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4737    0.0831    0.1414      1624
           N     0.6482    0.8109    0.7204      3310
           P     0.7127    0.8130    0.7596      3610

   micro avg     0.6735    0.6735    0.6735      8544
   macro avg     0.6115    0.5690    0.5405      8544
weighted avg     0.6423    0.6735    0.6269      8544

F1-macro sent:  0.540483695056404
F1-micro sent:  0.6734550561797753
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9067    0.9710    0.9377    124347
           N     0.7937    0.6367    0.7066     14202
           P     0.8760    0.6655    0.7563     25017

   micro avg     0.8952    0.8952    0.8952    163566
   macro avg     0.8588    0.7577    0.8002    163566
weighted avg     0.8922    0.8952    0.8899    163566

F1-macro tok:  0.8002264342353579
F1-micro tok:  0.8952410647689618
**************************************************
dev_cost_sum: 42523.39196777344
dev_cost_avg: 38.6225176819014
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 19115.0
dev_accuracy_tok: 0.8985146187834916
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.691609977324263
dev_label=N_recall_sent: 0.7126168224299065
dev_label=N_f-score_sent: 0.7019562715765246
dev_label=P_precision_sent: 0.6061068702290077
dev_label=P_recall_sent: 0.8941441441441441
dev_label=P_f-score_sent: 0.7224749772520473
dev_precision_macro_sent: 0.6992389491844236
dev_recall_macro_sent: 0.5414094051607825
dev_f-score_macro_sent: 0.48620642767220207
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.9038329911019849
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9393840590449655
dev_label=N_precision_tok: 0.8111837327523602
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.6907854050711193
dev_label=P_precision_tok: 0.9099365750528541
dev_label=P_recall_tok: 0.6699875466998755
dev_label=P_f-score_tok: 0.7717410794333871
dev_precision_macro_tok: 0.8749844329690664
dev_recall_macro_tok: 0.749780566237965
dev_f-score_macro_tok: 0.8006368478498239
dev_precision_micro_tok: 0.8985146187834916
dev_recall_micro_tok: 0.8985146187834916
dev_f-score_micro_tok: 0.8985146187834916
dev_time: 7.572754859924316
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6916    0.7126    0.7020       428
           P     0.6061    0.8941    0.7225       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.6992    0.5414    0.4862      1101
weighted avg     0.6797    0.6412    0.5713      1101

F1-macro sent:  0.48620642767220207
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9038    0.9778    0.9394     16205
           N     0.8112    0.6015    0.6908      1857
           P     0.9099    0.6700    0.7717      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8750    0.7498    0.8006     21274
weighted avg     0.8967    0.8985    0.8924     21274

F1-macro tok:  0.8006368478498239
F1-micro tok:  0.8985146187834916
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 310342.7723388672
train_cost_avg: 36.32289002093483
train_count_sent: 8544.0
train_total_correct_sent: 5734.0
train_accuracy_sent: 0.6711142322097379
train_count_tok: 163566.0
train_total_correct_tok: 146649.0
train_accuracy_tok: 0.8965738600931734
train_label=O_precision_sent: 0.41262135922330095
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.09289617486338797
train_label=N_precision_sent: 0.6455544933078394
train_label=N_recall_sent: 0.816012084592145
train_label=N_f-score_sent: 0.7208433413397385
train_label=P_precision_sent: 0.7096774193548387
train_label=P_recall_sent: 0.8166204986149584
train_label=P_f-score_sent: 0.7594023699124163
train_precision_macro_sent: 0.5892844239619931
train_recall_macro_sent: 0.5616574948949786
train_f-score_macro_sent: 0.524380628705181
train_precision_micro_sent: 0.6711142322097379
train_recall_micro_sent: 0.6711142322097379
train_f-score_micro_sent: 0.6711142322097379
train_label=O_precision_tok: 0.9081456196806111
train_label=O_recall_tok: 0.9713704391742463
train_label=O_f-score_tok: 0.9386946232965871
train_label=N_precision_tok: 0.7949030181786553
train_label=N_recall_tok: 0.6435009153640332
train_label=N_f-score_tok: 0.7112339001517568
train_label=P_precision_tok: 0.8771570941515867
train_label=P_recall_tok: 0.6684654434984211
train_label=P_f-score_tok: 0.7587223810171952
train_precision_macro_tok: 0.8600685773369511
train_recall_macro_tok: 0.7611122660122335
train_f-score_macro_tok: 0.8028836348218463
train_precision_micro_tok: 0.8965738600931734
train_recall_micro_tok: 0.8965738600931734
train_f-score_micro_tok: 0.8965738600931734
train_time: 146.50721168518066
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4126    0.0523    0.0929      1624
           N     0.6456    0.8160    0.7208      3310
           P     0.7097    0.8166    0.7594      3610

   micro avg     0.6711    0.6711    0.6711      8544
   macro avg     0.5893    0.5617    0.5244      8544
weighted avg     0.6284    0.6711    0.6178      8544

F1-macro sent:  0.524380628705181
F1-micro sent:  0.6711142322097379
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9714    0.9387    124347
           N     0.7949    0.6435    0.7112     14202
           P     0.8772    0.6685    0.7587     25017

   micro avg     0.8966    0.8966    0.8966    163566
   macro avg     0.8601    0.7611    0.8029    163566
weighted avg     0.8936    0.8966    0.8914    163566

F1-macro tok:  0.8028836348218463
F1-micro tok:  0.8965738600931734
**************************************************
dev_cost_sum: 42445.61669921875
dev_cost_avg: 38.55187711100704
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19118.0
dev_accuracy_tok: 0.8986556359875905
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.6292517006802721
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7283464566929134
dev_label=P_precision_sent: 0.703187250996016
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7463002114164905
dev_precision_macro_sent: 0.716873589952702
dev_recall_macro_sent: 0.5662774454657081
dev_f-score_macro_sent: 0.5165488893698013
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9044
dev_label=O_recall_tok: 0.9766738660907127
dev_label=O_f-score_tok: 0.9391484942886812
dev_label=N_precision_tok: 0.8129548762736536
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.6914268028474156
dev_label=P_precision_tok: 0.9058333333333334
dev_label=P_recall_tok: 0.6768368617683687
dev_label=P_f-score_tok: 0.774768353528154
dev_precision_macro_tok: 0.8743960698689955
dev_recall_macro_tok: 0.751672845384009
dev_f-score_macro_tok: 0.8017812168880836
dev_precision_micro_tok: 0.8986556359875905
dev_recall_micro_tok: 0.8986556359875905
dev_f-score_micro_tok: 0.8986556359875905
dev_time: 7.159405946731567
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.6293    0.8645    0.7283       428
           P     0.7032    0.7950    0.7463       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7169    0.5663    0.5165      1101
weighted avg     0.6984    0.6649    0.5997      1101

F1-macro sent:  0.5165488893698013
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9044    0.9767    0.9391     16205
           N     0.8130    0.6015    0.6914      1857
           P     0.9058    0.6768    0.7748      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8744    0.7517    0.8018     21274
weighted avg     0.8966    0.8987    0.8927     21274

F1-macro tok:  0.8017812168880836
F1-micro tok:  0.8986556359875905
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.810000
train_cost_sum: 308617.05645751953
train_cost_avg: 36.120910165908185
train_count_sent: 8544.0
train_total_correct_sent: 5779.0
train_accuracy_sent: 0.6763810861423221
train_count_tok: 163566.0
train_total_correct_tok: 146831.0
train_accuracy_tok: 0.8976865607766895
train_label=O_precision_sent: 0.5202312138728323
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.1001669449081803
train_label=N_precision_sent: 0.6398225957049486
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7218856992362391
train_label=P_precision_sent: 0.7213114754098361
train_label=P_recall_sent: 0.8166204986149584
train_label=P_f-score_sent: 0.7660127322333377
train_precision_macro_sent: 0.627121761662539
train_recall_macro_sent: 0.566711964854647
train_f-score_macro_sent: 0.5293551254592525
train_precision_micro_sent: 0.6763810861423221
train_recall_micro_sent: 0.6763810861423221
train_f-score_micro_sent: 0.6763810861423221
train_label=O_precision_tok: 0.9091538693164709
train_label=O_recall_tok: 0.9712498090022277
train_label=O_f-score_tok: 0.9391765524696039
train_label=N_precision_tok: 0.7981754995655951
train_label=N_recall_tok: 0.6468807210252078
train_label=N_f-score_tok: 0.7146079651524581
train_label=P_precision_tok: 0.8780183180682765
train_label=P_recall_tok: 0.6744213934524523
train_label=P_f-score_tok: 0.7628693509370833
train_precision_macro_tok: 0.8617825623167809
train_recall_macro_tok: 0.7641839744932959
train_f-score_macro_tok: 0.8055512895197151
train_precision_micro_tok: 0.8976865607766895
train_recall_micro_tok: 0.8976865607766895
train_f-score_micro_tok: 0.8976865607766896
train_time: 147.18984937667847
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5202    0.0554    0.1002      1624
           N     0.6398    0.8281    0.7219      3310
           P     0.7213    0.8166    0.7660      3610

   micro avg     0.6764    0.6764    0.6764      8544
   macro avg     0.6271    0.5667    0.5294      8544
weighted avg     0.6515    0.6764    0.6224      8544

F1-macro sent:  0.5293551254592525
F1-micro sent:  0.6763810861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9712    0.9392    124347
           N     0.7982    0.6469    0.7146     14202
           P     0.8780    0.6744    0.7629     25017

   micro avg     0.8977    0.8977    0.8977    163566
   macro avg     0.8618    0.7642    0.8056    163566
weighted avg     0.8948    0.8977    0.8927    163566

F1-macro tok:  0.8055512895197151
F1-micro tok:  0.8976865607766896
**************************************************
dev_cost_sum: 42259.33850097656
dev_cost_avg: 38.382687103520944
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19143.0
dev_accuracy_tok: 0.8998307793550813
dev_label=O_precision_sent: 0.7647058823529411
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10569105691056911
dev_label=N_precision_sent: 0.6460176991150443
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7351460221550856
dev_label=P_precision_sent: 0.6936416184971098
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7476635514018691
dev_precision_macro_sent: 0.7014550666550318
dev_recall_macro_sent: 0.5734610360268443
dev_f-score_macro_sent: 0.5295002101558413
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9036961102568484
dev_label=O_recall_tok: 0.9792039493983339
dev_label=O_f-score_tok: 0.9399360265371401
dev_label=N_precision_tok: 0.8222554144884242
dev_label=N_recall_tok: 0.592891760904685
dev_label=N_f-score_tok: 0.6889862327909888
dev_label=P_precision_tok: 0.914983164983165
dev_label=P_recall_tok: 0.6768368617683687
dev_label=P_f-score_tok: 0.7780959198282033
dev_precision_macro_tok: 0.8803115632428126
dev_recall_macro_tok: 0.7496441906904625
dev_f-score_macro_tok: 0.8023393930521108
dev_precision_micro_tok: 0.8998307793550813
dev_recall_micro_tok: 0.8998307793550813
dev_f-score_micro_tok: 0.8998307793550813
dev_time: 7.183612585067749
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7647    0.0568    0.1057       229
           N     0.6460    0.8528    0.7351       428
           P     0.6936    0.8108    0.7477       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.7015    0.5735    0.5295      1101
weighted avg     0.6899    0.6703    0.6093      1101

F1-macro sent:  0.5295002101558413
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9037    0.9792    0.9399     16205
           N     0.8223    0.5929    0.6890      1857
           P     0.9150    0.6768    0.7781      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8803    0.7496    0.8023     21274
weighted avg     0.8983    0.8998    0.8936     21274

F1-macro tok:  0.8023393930521108
F1-micro tok:  0.8998307793550813
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.810000
train_cost_sum: 307141.9494628906
train_cost_avg: 35.948261875338325
train_count_sent: 8544.0
train_total_correct_sent: 5821.0
train_accuracy_sent: 0.6812968164794008
train_count_tok: 163566.0
train_total_correct_tok: 147192.0
train_accuracy_tok: 0.8998936209236639
train_label=O_precision_sent: 0.514018691588785
train_label=O_recall_sent: 0.06773399014778325
train_label=O_f-score_sent: 0.11969532100108814
train_label=N_precision_sent: 0.6491849751948973
train_label=N_recall_sent: 0.8302114803625378
train_label=N_f-score_sent: 0.7286225639665916
train_label=P_precision_sent: 0.7232121064193312
train_label=P_recall_sent: 0.820775623268698
train_label=P_f-score_sent: 0.7689113792656028
train_precision_macro_sent: 0.6288052577343378
train_recall_macro_sent: 0.572907031259673
train_f-score_macro_sent: 0.5390764214110942
train_precision_micro_sent: 0.6812968164794008
train_recall_micro_sent: 0.6812968164794008
train_f-score_micro_sent: 0.6812968164794008
train_label=O_precision_tok: 0.9112976201248756
train_label=O_recall_tok: 0.9718690438852566
train_label=O_f-score_tok: 0.9406092022462728
train_label=N_precision_tok: 0.8041201419544707
train_label=N_recall_tok: 0.6541332206731446
train_label=N_f-score_tok: 0.7214133178023684
train_label=P_precision_tok: 0.8789753105510025
train_label=P_recall_tok: 0.6816564735979533
train_label=P_f-score_tok: 0.7678418659102166
train_precision_macro_tok: 0.864797690876783
train_recall_macro_tok: 0.7692195793854516
train_f-score_macro_tok: 0.8099547953196193
train_precision_micro_tok: 0.8998936209236639
train_recall_micro_tok: 0.8998936209236639
train_f-score_micro_tok: 0.8998936209236639
train_time: 147.50293588638306
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5140    0.0677    0.1197      1624
           N     0.6492    0.8302    0.7286      3310
           P     0.7232    0.8208    0.7689      3610

   micro avg     0.6813    0.6813    0.6813      8544
   macro avg     0.6288    0.5729    0.5391      8544
weighted avg     0.6548    0.6813    0.6299      8544

F1-macro sent:  0.5390764214110942
F1-micro sent:  0.6812968164794008
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9113    0.9719    0.9406    124347
           N     0.8041    0.6541    0.7214     14202
           P     0.8790    0.6817    0.7678     25017

   micro avg     0.8999    0.8999    0.8999    163566
   macro avg     0.8648    0.7692    0.8100    163566
weighted avg     0.8970    0.8999    0.8952    163566

F1-macro tok:  0.8099547953196193
F1-micro tok:  0.8998936209236639
**************************************************
dev_cost_sum: 42252.952880859375
dev_cost_avg: 38.37688726690225
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19132.0
dev_accuracy_tok: 0.8993137162733853
dev_label=O_precision_sent: 0.8888888888888888
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06722689075630252
dev_label=N_precision_sent: 0.6692307692307692
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7341772151898734
dev_label=P_precision_sent: 0.666083916083916
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7499999999999999
dev_precision_macro_sent: 0.7414011914011912
dev_recall_macro_sent: 0.5687089060247449
dev_f-score_macro_sent: 0.5171347019820586
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9108497943578753
dev_label=O_recall_tok: 0.9703178031471767
dev_label=O_f-score_tok: 0.9396438388908808
dev_label=N_precision_tok: 0.7845340383344349
dev_label=N_recall_tok: 0.6392030156165859
dev_label=N_f-score_tok: 0.7044510385756677
dev_label=P_precision_tok: 0.8891112890312249
dev_label=P_recall_tok: 0.6914694894146949
dev_label=P_f-score_tok: 0.7779334500875656
dev_precision_macro_tok: 0.8614983739078451
dev_recall_macro_tok: 0.7669967693928191
dev_f-score_macro_tok: 0.8073427758513714
dev_precision_micro_tok: 0.8993137162733853
dev_recall_micro_tok: 0.8993137162733853
dev_f-score_micro_tok: 0.8993137162733853
dev_time: 7.536051511764526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8889    0.0349    0.0672       229
           N     0.6692    0.8131    0.7342       428
           P     0.6661    0.8581    0.7500       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.7414    0.5687    0.5171      1101
weighted avg     0.7136    0.6694    0.6018      1101

F1-macro sent:  0.5171347019820586
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9108    0.9703    0.9396     16205
           N     0.7845    0.6392    0.7045      1857
           P     0.8891    0.6915    0.7779      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8615    0.7670    0.8073     21274
weighted avg     0.8965    0.8993    0.8947     21274

F1-macro tok:  0.8073427758513714
F1-micro tok:  0.8993137162733853
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.810000
train_cost_sum: 305669.2170410156
train_cost_avg: 35.77589150760951
train_count_sent: 8544.0
train_total_correct_sent: 5793.0
train_accuracy_sent: 0.6780196629213483
train_count_tok: 163566.0
train_total_correct_tok: 147522.0
train_accuracy_tok: 0.9019111551300393
train_label=O_precision_sent: 0.47470817120622566
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.12971823498139287
train_label=N_precision_sent: 0.6435921421889617
train_label=N_recall_sent: 0.8314199395770393
train_label=N_f-score_sent: 0.7255470603743738
train_label=P_precision_sent: 0.7277486910994765
train_label=P_recall_sent: 0.8085872576177285
train_label=P_f-score_sent: 0.7660412019420024
train_precision_macro_sent: 0.6153496681648879
train_recall_macro_sent: 0.5717101166347092
train_f-score_macro_sent: 0.5404354990992564
train_precision_micro_sent: 0.6780196629213483
train_recall_micro_sent: 0.6780196629213483
train_f-score_micro_sent: 0.6780196629213483
train_label=O_precision_tok: 0.9135324706736002
train_label=O_recall_tok: 0.9719896740572752
train_label=O_f-score_tok: 0.9418548924414867
train_label=N_precision_tok: 0.8056077962044794
train_label=N_recall_tok: 0.6635685114772567
train_label=N_f-score_tok: 0.7277220077220078
train_label=P_precision_tok: 0.8809037006747087
train_label=P_recall_tok: 0.6888915537434545
train_label=P_f-score_tok: 0.773154482851439
train_precision_macro_tok: 0.8666813225175961
train_recall_macro_tok: 0.7748165797593288
train_f-score_macro_tok: 0.8142437943383113
train_precision_micro_tok: 0.9019111551300393
train_recall_micro_tok: 0.9019111551300393
train_f-score_micro_tok: 0.9019111551300393
train_time: 146.705402135849
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4747    0.0751    0.1297      1624
           N     0.6436    0.8314    0.7255      3310
           P     0.7277    0.8086    0.7660      3610

   micro avg     0.6780    0.6780    0.6780      8544
   macro avg     0.6153    0.5717    0.5404      8544
weighted avg     0.6470    0.6780    0.6294      8544

F1-macro sent:  0.5404354990992564
F1-micro sent:  0.6780196629213483
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9135    0.9720    0.9419    124347
           N     0.8056    0.6636    0.7277     14202
           P     0.8809    0.6889    0.7732     25017

   micro avg     0.9019    0.9019    0.9019    163566
   macro avg     0.8667    0.7748    0.8142    163566
weighted avg     0.8992    0.9019    0.8975    163566

F1-macro tok:  0.8142437943383113
F1-micro tok:  0.9019111551300393
**************************************************
dev_cost_sum: 42274.70819091797
dev_cost_avg: 38.39664685823612
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19137.0
dev_accuracy_tok: 0.8995487449468835
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6047619047619047
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.720226843100189
dev_label=P_precision_sent: 0.7225806451612903
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7392739273927393
dev_precision_macro_sent: 0.7202252944188428
dev_recall_macro_sent: 0.5562592445933262
dev_f-score_macro_sent: 0.5006846539940967
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9117971334068358
dev_label=O_recall_tok: 0.9696390003085468
dev_label=O_f-score_tok: 0.9398289371373886
dev_label=N_precision_tok: 0.7721932114882507
dev_label=N_recall_tok: 0.6370490037695208
dev_label=N_f-score_tok: 0.6981410445559163
dev_label=P_precision_tok: 0.8931845356715823
dev_label=P_recall_tok: 0.6976961394769614
dev_label=P_f-score_tok: 0.7834294703723126
dev_precision_macro_tok: 0.859058293522223
dev_recall_macro_tok: 0.7681280478516763
dev_f-score_macro_tok: 0.8071331506885392
dev_precision_micro_tok: 0.8995487449468835
dev_recall_micro_tok: 0.8995487449468835
dev_f-score_micro_tok: 0.8995487449468835
dev_time: 6.988853693008423
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6048    0.8902    0.7202       428
           P     0.7226    0.7568    0.7393       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7202    0.5563    0.5007      1101
weighted avg     0.6998    0.6558    0.5870      1101

F1-macro sent:  0.5006846539940967
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9118    0.9696    0.9398     16205
           N     0.7722    0.6370    0.6981      1857
           P     0.8932    0.6977    0.7834      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8591    0.7681    0.8071     21274
weighted avg     0.8968    0.8995    0.8951     21274

F1-macro tok:  0.8071331506885392
F1-micro tok:  0.8995487449468835
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.810000
train_cost_sum: 304459.13885498047
train_cost_avg: 35.63426250643498
train_count_sent: 8544.0
train_total_correct_sent: 5880.0
train_accuracy_sent: 0.6882022471910112
train_count_tok: 163566.0
train_total_correct_tok: 147593.0
train_accuracy_tok: 0.9023452306714109
train_label=O_precision_sent: 0.546875
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.1156387665198238
train_label=N_precision_sent: 0.6549295774647887
train_label=N_recall_sent: 0.8429003021148036
train_label=N_f-score_sent: 0.737120211360634
train_label=P_precision_sent: 0.7294721407624634
train_label=P_recall_sent: 0.8268698060941828
train_label=P_f-score_sent: 0.7751233445858219
train_precision_macro_sent: 0.6437589060757507
train_recall_macro_sent: 0.5781417602075932
train_f-score_macro_sent: 0.5426274408220932
train_precision_micro_sent: 0.6882022471910112
train_recall_micro_sent: 0.6882022471910112
train_f-score_micro_sent: 0.6882022471910112
train_label=O_precision_tok: 0.9142774968968544
train_label=O_recall_tok: 0.9714589013003933
train_label=O_f-score_tok: 0.9420012399062662
train_label=N_precision_tok: 0.8057054741711642
train_label=N_recall_tok: 0.6622306717363752
train_label=N_f-score_tok: 0.7269565217391305
train_label=P_precision_tok: 0.8796600738530022
train_label=P_recall_tok: 0.6951273134268697
train_label=P_f-score_tok: 0.7765819675791542
train_precision_macro_tok: 0.8665476816403404
train_recall_macro_tok: 0.7762722954878795
train_f-score_macro_tok: 0.815179909741517
train_precision_micro_tok: 0.9023452306714109
train_recall_micro_tok: 0.9023452306714109
train_f-score_micro_tok: 0.9023452306714109
train_time: 148.07051825523376
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5469    0.0647    0.1156      1624
           N     0.6549    0.8429    0.7371      3310
           P     0.7295    0.8269    0.7751      3610

   micro avg     0.6882    0.6882    0.6882      8544
   macro avg     0.6438    0.5781    0.5426      8544
weighted avg     0.6659    0.6882    0.6350      8544

F1-macro sent:  0.5426274408220932
F1-micro sent:  0.6882022471910112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9143    0.9715    0.9420    124347
           N     0.8057    0.6622    0.7270     14202
           P     0.8797    0.6951    0.7766     25017

   micro avg     0.9023    0.9023    0.9023    163566
   macro avg     0.8665    0.7763    0.8152    163566
weighted avg     0.8996    0.9023    0.8980    163566

F1-macro tok:  0.815179909741517
F1-micro tok:  0.9023452306714109
**************************************************
dev_cost_sum: 42074.53515625
dev_cost_avg: 38.21483665417802
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19165.0
dev_accuracy_tok: 0.9008649055184732
dev_label=O_precision_sent: 0.475
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.1412639405204461
dev_label=N_precision_sent: 0.6610169491525424
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7320125130344108
dev_label=P_precision_sent: 0.6924528301886792
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7535934291581108
dev_precision_macro_sent: 0.6094899264470739
dev_recall_macro_sent: 0.5765464889449707
dev_f-score_macro_sent: 0.5422899609043226
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9102038459317434
dev_label=O_recall_tok: 0.9726627584078988
dev_label=O_f-score_tok: 0.9403973509933775
dev_label=N_precision_tok: 0.7993127147766323
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.7022946859903383
dev_label=P_precision_tok: 0.8952837729816147
dev_label=P_recall_tok: 0.6973848069738481
dev_label=P_f-score_tok: 0.784039201960098
dev_precision_macro_tok: 0.8682667778966634
dev_recall_macro_tok: 0.7654421699719807
dev_f-score_macro_tok: 0.8089104129812713
dev_precision_micro_tok: 0.9008649055184732
dev_recall_micro_tok: 0.9008649055184732
dev_f-score_micro_tok: 0.9008649055184732
dev_time: 7.360756158828735
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4750    0.0830    0.1413       229
           N     0.6610    0.8201    0.7320       428
           P     0.6925    0.8266    0.7536       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6095    0.5765    0.5423      1101
weighted avg     0.6350    0.6694    0.6178      1101

F1-macro sent:  0.5422899609043226
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9727    0.9404     16205
           N     0.7993    0.6263    0.7023      1857
           P     0.8953    0.6974    0.7840      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8683    0.7654    0.8089     21274
weighted avg     0.8983    0.9009    0.8960     21274

F1-macro tok:  0.8089104129812713
F1-micro tok:  0.9008649055184732
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 0.810000
train_cost_sum: 302962.72247314453
train_cost_avg: 35.45912013964707
train_count_sent: 8544.0
train_total_correct_sent: 5902.0
train_accuracy_sent: 0.6907771535580525
train_count_tok: 163566.0
train_total_correct_tok: 147919.0
train_accuracy_tok: 0.904338309917709
train_label=O_precision_sent: 0.5043103448275862
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.12607758620689655
train_label=N_precision_sent: 0.658600237247924
train_label=N_recall_sent: 0.8386706948640483
train_label=N_f-score_sent: 0.7378073089700996
train_label=P_precision_sent: 0.7344398340248963
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7808485792137019
train_precision_macro_sent: 0.6324501387001354
train_recall_macro_sent: 0.5814110117931947
train_f-score_macro_sent: 0.548244491463566
train_precision_micro_sent: 0.6907771535580525
train_recall_micro_sent: 0.6907771535580525
train_f-score_micro_sent: 0.6907771535580525
train_label=O_precision_tok: 0.9165036767492988
train_label=O_recall_tok: 0.9722470184242483
train_label=O_f-score_tok: 0.94355276148554
train_label=N_precision_tok: 0.8084349593495935
train_label=N_recall_tok: 0.6721588508660752
train_label=N_f-score_tok: 0.7340253748558246
train_label=P_precision_tok: 0.8805421201128577
train_label=P_recall_tok: 0.6986049486349283
train_label=P_f-score_tok: 0.7790928340577287
train_precision_macro_tok: 0.8684935854039167
train_recall_macro_tok: 0.781003605975084
train_f-score_macro_tok: 0.8188903234663645
train_precision_micro_tok: 0.904338309917709
train_recall_micro_tok: 0.904338309917709
train_f-score_micro_tok: 0.904338309917709
train_time: 147.44991326332092
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5043    0.0720    0.1261      1624
           N     0.6586    0.8387    0.7378      3310
           P     0.7344    0.8335    0.7808      3610

   micro avg     0.6908    0.6908    0.6908      8544
   macro avg     0.6325    0.5814    0.5482      8544
weighted avg     0.6613    0.6908    0.6397      8544

F1-macro sent:  0.548244491463566
F1-micro sent:  0.6907771535580525
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9165    0.9722    0.9436    124347
           N     0.8084    0.6722    0.7340     14202
           P     0.8805    0.6986    0.7791     25017

   micro avg     0.9043    0.9043    0.9043    163566
   macro avg     0.8685    0.7810    0.8189    163566
weighted avg     0.9016    0.9043    0.9002    163566

F1-macro tok:  0.8188903234663645
F1-micro tok:  0.904338309917709
**************************************************
dev_cost_sum: 42037.163818359375
dev_cost_avg: 38.180893567992165
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19157.0
dev_accuracy_tok: 0.9004888596408762
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.635593220338983
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.736738703339882
dev_label=P_precision_sent: 0.7145708582834331
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7576719576719576
dev_precision_macro_sent: 0.683388026207472
dev_recall_macro_sent: 0.5710140720649638
dev_f-score_macro_sent: 0.5176626889565267
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9104831252889505
dev_label=O_recall_tok: 0.9722307929651343
dev_label=O_f-score_tok: 0.9403443850905727
dev_label=N_precision_tok: 0.7938144329896907
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.697463768115942
dev_label=P_precision_tok: 0.8934393638170974
dev_label=P_recall_tok: 0.6995641344956414
dev_label=P_f-score_tok: 0.784704033525406
dev_precision_macro_tok: 0.8659123073652463
dev_recall_macro_tok: 0.7645886161002801
dev_f-score_macro_tok: 0.8075040622439736
dev_precision_micro_tok: 0.9004888596408762
dev_recall_micro_tok: 0.9004888596408762
dev_f-score_micro_tok: 0.9004888596408761
dev_time: 7.9969727993011475
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6356    0.8762    0.7367       428
           P     0.7146    0.8063    0.7577       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6834    0.5710    0.5177      1101
weighted avg     0.6808    0.6721    0.6041      1101

F1-macro sent:  0.5176626889565267
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9722    0.9403     16205
           N     0.7938    0.6220    0.6975      1857
           P     0.8934    0.6996    0.7847      3212

   micro avg     0.9005    0.9005    0.9005     21274
   macro avg     0.8659    0.7646    0.8075     21274
weighted avg     0.8977    0.9005    0.8956     21274

F1-macro tok:  0.8075040622439736
F1-micro tok:  0.9004888596408761
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 0.810000
train_cost_sum: 302013.92010498047
train_cost_avg: 35.34807117333573
train_count_sent: 8544.0
train_total_correct_sent: 5887.0
train_accuracy_sent: 0.6890215355805244
train_count_tok: 163566.0
train_total_correct_tok: 148089.0
train_accuracy_tok: 0.9053776457209933
train_label=O_precision_sent: 0.4846153846153846
train_label=O_recall_sent: 0.07758620689655173
train_label=O_f-score_sent: 0.1337579617834395
train_label=N_precision_sent: 0.6560958421423537
train_label=N_recall_sent: 0.8438066465256797
train_label=N_f-score_sent: 0.7382053654024051
train_label=P_precision_sent: 0.7370250807052396
train_label=P_recall_sent: 0.8221606648199447
train_label=P_f-score_sent: 0.7772685609532539
train_precision_macro_sent: 0.6259121024876594
train_recall_macro_sent: 0.5811845060807254
train_f-score_macro_sent: 0.5497439627130328
train_precision_micro_sent: 0.6890215355805244
train_recall_micro_sent: 0.6890215355805244
train_f-score_micro_sent: 0.6890215355805244
train_label=O_precision_tok: 0.9171801019788758
train_label=O_recall_tok: 0.972094220206358
train_label=O_f-score_tok: 0.9438390873705291
train_label=N_precision_tok: 0.8140205136899211
train_label=N_recall_tok: 0.6761723700887199
train_label=N_f-score_tok: 0.7387207200276933
train_label=P_precision_tok: 0.8814636832357211
train_label=P_recall_tok: 0.7038813606747412
train_label=P_f-score_tok: 0.7827265857669912
train_precision_macro_tok: 0.8708880996348394
train_recall_macro_tok: 0.7840493169899396
train_f-score_macro_tok: 0.8217621310550712
train_precision_micro_tok: 0.9053776457209933
train_recall_micro_tok: 0.9053776457209933
train_f-score_micro_tok: 0.9053776457209933
train_time: 195.406512260437
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4846    0.0776    0.1338      1624
           N     0.6561    0.8438    0.7382      3310
           P     0.7370    0.8222    0.7773      3610

   micro avg     0.6890    0.6890    0.6890      8544
   macro avg     0.6259    0.5812    0.5497      8544
weighted avg     0.6577    0.6890    0.6398      8544

F1-macro sent:  0.5497439627130328
F1-micro sent:  0.6890215355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9172    0.9721    0.9438    124347
           N     0.8140    0.6762    0.7387     14202
           P     0.8815    0.7039    0.7827     25017

   micro avg     0.9054    0.9054    0.9054    163566
   macro avg     0.8709    0.7840    0.8218    163566
weighted avg     0.9028    0.9054    0.9014    163566

F1-macro tok:  0.8217621310550712
F1-micro tok:  0.9053776457209933
**************************************************
dev_cost_sum: 42037.961181640625
dev_cost_avg: 38.181617785323
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19157.0
dev_accuracy_tok: 0.9004888596408762
dev_label=O_precision_sent: 0.8235294117647058
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.1138211382113821
dev_label=N_precision_sent: 0.6345177664974619
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7360157016683023
dev_label=P_precision_sent: 0.7119675456389453
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7491995731056562
dev_precision_macro_sent: 0.7233382413003709
dev_recall_macro_sent: 0.5759480453395485
dev_f-score_macro_sent: 0.5330121376617801
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9079885057471264
dev_label=O_recall_tok: 0.9749460043196544
dev_label=O_f-score_tok: 0.9402767445320636
dev_label=N_precision_tok: 0.7864406779661017
dev_label=N_recall_tok: 0.624663435648896
dev_label=N_f-score_tok: 0.6962785114045618
dev_label=P_precision_tok: 0.9162150896206753
dev_label=P_recall_tok: 0.6843088418430884
dev_label=P_f-score_tok: 0.7834610586348244
dev_precision_macro_tok: 0.8702147577779679
dev_recall_macro_tok: 0.7613060939372129
dev_f-score_macro_tok: 0.8066721048571499
dev_precision_micro_tok: 0.9004888596408762
dev_recall_micro_tok: 0.9004888596408762
dev_f-score_micro_tok: 0.9004888596408761
dev_time: 11.044618606567383
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8235    0.0611    0.1138       229
           N     0.6345    0.8762    0.7360       428
           P     0.7120    0.7905    0.7492       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.7233    0.5759    0.5330      1101
weighted avg     0.7051    0.6721    0.6119      1101

F1-macro sent:  0.5330121376617801
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9749    0.9403     16205
           N     0.7864    0.6247    0.6963      1857
           P     0.9162    0.6843    0.7835      3212

   micro avg     0.9005    0.9005    0.9005     21274
   macro avg     0.8702    0.7613    0.8067     21274
weighted avg     0.8986    0.9005    0.8953     21274

F1-macro tok:  0.8066721048571499
F1-micro tok:  0.9004888596408761
**************************************************
Best epoch: 25
**************************************************

EPOCH: 28
Learning rate: 0.810000
train_cost_sum: 300669.35272216797
train_cost_avg: 35.19070139538483
train_count_sent: 8544.0
train_total_correct_sent: 5952.0
train_accuracy_sent: 0.6966292134831461
train_count_tok: 163566.0
train_total_correct_tok: 148069.0
train_accuracy_tok: 0.9052553709206069
train_label=O_precision_sent: 0.4850498338870432
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.1516883116883117
train_label=N_precision_sent: 0.6704191616766467
train_label=N_recall_sent: 0.845619335347432
train_label=N_f-score_sent: 0.7478957915831663
train_label=P_precision_sent: 0.7391838741396264
train_label=P_recall_sent: 0.8329639889196676
train_label=P_f-score_sent: 0.7832768950247461
train_precision_macro_sent: 0.631550956567772
train_recall_macro_sent: 0.589494934033204
train_f-score_macro_sent: 0.5609536660987414
train_precision_micro_sent: 0.6966292134831461
train_recall_micro_sent: 0.6966292134831461
train_f-score_micro_sent: 0.6966292134831461
train_label=O_precision_tok: 0.9180544782588858
train_label=O_recall_tok: 0.9708798764747039
train_label=O_f-score_tok: 0.9437285273735679
train_label=N_precision_tok: 0.8093883357041252
train_label=N_recall_tok: 0.6811012533445994
train_label=N_f-score_tok: 0.7397239322448667
train_label=P_precision_tok: 0.8785362700740814
train_label=P_recall_tok: 0.7063197026022305
train_label=P_f-score_tok: 0.7830711278528694
train_precision_macro_tok: 0.8686596946790308
train_recall_macro_tok: 0.7861002774738446
train_f-score_macro_tok: 0.8221745291571013
train_precision_micro_tok: 0.9052553709206069
train_recall_micro_tok: 0.9052553709206069
train_f-score_micro_tok: 0.9052553709206069
train_time: 198.89669680595398
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4850    0.0899    0.1517      1624
           N     0.6704    0.8456    0.7479      3310
           P     0.7392    0.8330    0.7833      3610

   micro avg     0.6966    0.6966    0.6966      8544
   macro avg     0.6316    0.5895    0.5610      8544
weighted avg     0.6642    0.6966    0.6495      8544

F1-macro sent:  0.5609536660987414
F1-micro sent:  0.6966292134831461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9181    0.9709    0.9437    124347
           N     0.8094    0.6811    0.7397     14202
           P     0.8785    0.7063    0.7831     25017

   micro avg     0.9053    0.9053    0.9053    163566
   macro avg     0.8687    0.7861    0.8222    163566
weighted avg     0.9026    0.9053    0.9014    163566

F1-macro tok:  0.8221745291571013
F1-micro tok:  0.9052553709206069
**************************************************
dev_cost_sum: 42050.98175048828
dev_cost_avg: 38.19344391506656
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19192.0
dev_accuracy_tok: 0.9021340603553634
dev_label=O_precision_sent: 0.43243243243243246
dev_label=O_recall_sent: 0.13973799126637554
dev_label=O_f-score_sent: 0.21122112211221122
dev_label=N_precision_sent: 0.6826347305389222
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7362755651237891
dev_label=P_precision_sent: 0.6996197718631179
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7587628865979381
dev_precision_macro_sent: 0.6048956449448242
dev_recall_macro_sent: 0.5892107468853173
dev_f-score_macro_sent: 0.5687531912779794
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9058185966913862
dev_label=O_recall_tok: 0.9798827522369639
dev_label=O_f-score_tok: 0.941396176078257
dev_label=N_precision_tok: 0.8177874186550976
dev_label=N_recall_tok: 0.6090468497576736
dev_label=N_f-score_tok: 0.6981481481481481
dev_label=P_precision_tok: 0.9241846675137654
dev_label=P_recall_tok: 0.6793275217932753
dev_label=P_f-score_tok: 0.7830611878700879
dev_precision_macro_tok: 0.8825968942867498
dev_recall_macro_tok: 0.7560857079293042
dev_f-score_macro_tok: 0.8075351706988311
dev_precision_micro_tok: 0.9021340603553634
dev_recall_micro_tok: 0.9021340603553634
dev_f-score_micro_tok: 0.9021340603553635
dev_time: 10.877182483673096
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4324    0.1397    0.2112       229
           N     0.6826    0.7991    0.7363       428
           P     0.6996    0.8288    0.7588       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6049    0.5892    0.5688      1101
weighted avg     0.6374    0.6739    0.6361      1101

F1-macro sent:  0.5687531912779794
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9799    0.9414     16205
           N     0.8178    0.6090    0.6981      1857
           P     0.9242    0.6793    0.7831      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8826    0.7561    0.8075     21274
weighted avg     0.9009    0.9021    0.8963     21274

F1-macro tok:  0.8075351706988311
F1-micro tok:  0.9021340603553635
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.810000
train_cost_sum: 298984.35485839844
train_cost_avg: 34.99348722593615
train_count_sent: 8544.0
train_total_correct_sent: 5882.0
train_accuracy_sent: 0.6884363295880149
train_count_tok: 163566.0
train_total_correct_tok: 148685.0
train_accuracy_tok: 0.9090214347725077
train_label=O_precision_sent: 0.5130111524163569
train_label=O_recall_sent: 0.08497536945812807
train_label=O_f-score_sent: 0.14580031695721074
train_label=N_precision_sent: 0.669223156853043
train_label=N_recall_sent: 0.8172205438066465
train_label=N_f-score_sent: 0.7358541893362349
train_label=P_precision_sent: 0.7179305457122608
train_label=P_recall_sent: 0.8418282548476455
train_label=P_f-score_sent: 0.774958561774831
train_precision_macro_sent: 0.6333882849938869
train_recall_macro_sent: 0.5813413893708067
train_f-score_macro_sent: 0.5522043560227589
train_precision_micro_sent: 0.6884363295880149
train_recall_micro_sent: 0.6884363295880149
train_f-score_micro_sent: 0.6884363295880149
train_label=O_precision_tok: 0.9217726249952328
train_label=O_recall_tok: 0.9718690438852566
train_label=O_f-score_tok: 0.9461581823591125
train_label=N_precision_tok: 0.814540059347181
train_label=N_recall_tok: 0.6958174904942965
train_label=N_f-score_tok: 0.7505126452494872
train_label=P_precision_tok: 0.8831718235033695
train_label=P_recall_tok: 0.7176719830515249
train_label=P_f-score_tok: 0.7918669783442862
train_precision_macro_tok: 0.873161502615261
train_recall_macro_tok: 0.7951195058103594
train_f-score_macro_tok: 0.8295126019842952
train_precision_micro_tok: 0.9090214347725077
train_recall_micro_tok: 0.9090214347725077
train_f-score_micro_tok: 0.9090214347725077
train_time: 199.17641425132751
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5130    0.0850    0.1458      1624
           N     0.6692    0.8172    0.7359      3310
           P     0.7179    0.8418    0.7750      3610

   micro avg     0.6884    0.6884    0.6884      8544
   macro avg     0.6334    0.5813    0.5522      8544
weighted avg     0.6601    0.6884    0.6402      8544

F1-macro sent:  0.5522043560227589
F1-micro sent:  0.6884363295880149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9218    0.9719    0.9462    124347
           N     0.8145    0.6958    0.7505     14202
           P     0.8832    0.7177    0.7919     25017

   micro avg     0.9090    0.9090    0.9090    163566
   macro avg     0.8732    0.7951    0.8295    163566
weighted avg     0.9066    0.9090    0.9056    163566

F1-macro tok:  0.8295126019842952
F1-micro tok:  0.9090214347725077
**************************************************
dev_cost_sum: 41885.63525390625
dev_cost_avg: 38.04326544405654
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19128.0
dev_accuracy_tok: 0.8991256933345868
dev_label=O_precision_sent: 0.6842105263157895
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10483870967741936
dev_label=N_precision_sent: 0.7079646017699115
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.7272727272727274
dev_label=P_precision_sent: 0.6317460317460317
dev_label=P_recall_sent: 0.8963963963963963
dev_label=P_f-score_sent: 0.7411545623836127
dev_precision_macro_sent: 0.6746403866105776
dev_recall_macro_sent: 0.5669428355834102
dev_f-score_macro_sent: 0.5244219997779198
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9157839293029789
dev_label=O_recall_tok: 0.9656278926257328
dev_label=O_f-score_tok: 0.9400456566142016
dev_label=N_precision_tok: 0.7532956685499058
dev_label=N_recall_tok: 0.6462035541195477
dev_label=N_f-score_tok: 0.6956521739130433
dev_label=P_precision_tok: 0.8789514263685428
dev_label=P_recall_tok: 0.709838107098381
dev_label=P_f-score_tok: 0.7853944195659662
dev_precision_macro_tok: 0.8493436747404758
dev_recall_macro_tok: 0.7738898512812206
dev_f-score_macro_tok: 0.8070307500310704
dev_precision_micro_tok: 0.8991256933345868
dev_recall_micro_tok: 0.8991256933345868
dev_f-score_micro_tok: 0.8991256933345868
dev_time: 10.79129147529602
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6842    0.0568    0.1048       229
           N     0.7080    0.7477    0.7273       428
           P     0.6317    0.8964    0.7412       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6746    0.5669    0.5244      1101
weighted avg     0.6723    0.6639    0.6034      1101

F1-macro sent:  0.5244219997779198
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9158    0.9656    0.9400     16205
           N     0.7533    0.6462    0.6957      1857
           P     0.8790    0.7098    0.7854      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8493    0.7739    0.8070     21274
weighted avg     0.8960    0.8991    0.8954     21274

F1-macro tok:  0.8070307500310704
F1-micro tok:  0.8991256933345868
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.810000
train_cost_sum: 298035.5680541992
train_cost_avg: 34.88244008124991
train_count_sent: 8544.0
train_total_correct_sent: 5939.0
train_accuracy_sent: 0.6951076779026217
train_count_tok: 163566.0
train_total_correct_tok: 148817.0
train_accuracy_tok: 0.909828448455058
train_label=O_precision_sent: 0.5020576131687243
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.13069094804499198
train_label=N_precision_sent: 0.6644581164221486
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7452229299363057
train_label=P_precision_sent: 0.7384049079754601
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7830839297332466
train_precision_macro_sent: 0.6349735458554444
train_recall_macro_sent: 0.5856598422765288
train_f-score_macro_sent: 0.5529992692381814
train_precision_micro_sent: 0.6951076779026217
train_recall_micro_sent: 0.6951076779026217
train_f-score_micro_sent: 0.6951076779026217
train_label=O_precision_tok: 0.922556017864641
train_label=O_recall_tok: 0.9718047077935134
train_label=O_f-score_tok: 0.946540190810396
train_label=N_precision_tok: 0.8200480092707557
train_label=N_recall_tok: 0.6975778059428249
train_label=N_f-score_tok: 0.753871323669292
train_label=P_precision_tok: 0.8814146341463415
train_label=P_recall_tok: 0.7222688571771195
train_label=P_f-score_tok: 0.7939451194059363
train_precision_macro_tok: 0.8746728870939128
train_recall_macro_tok: 0.7972171236378193
train_f-score_macro_tok: 0.8314522112952081
train_precision_micro_tok: 0.909828448455058
train_recall_micro_tok: 0.909828448455058
train_f-score_micro_tok: 0.909828448455058
train_time: 199.55535292625427
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5021    0.0751    0.1307      1624
           N     0.6645    0.8483    0.7452      3310
           P     0.7384    0.8335    0.7831      3610

   micro avg     0.6951    0.6951    0.6951      8544
   macro avg     0.6350    0.5857    0.5530      8544
weighted avg     0.6648    0.6951    0.6444      8544

F1-macro sent:  0.5529992692381814
F1-micro sent:  0.6951076779026217
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9226    0.9718    0.9465    124347
           N     0.8200    0.6976    0.7539     14202
           P     0.8814    0.7223    0.7939     25017

   micro avg     0.9098    0.9098    0.9098    163566
   macro avg     0.8747    0.7972    0.8315    163566
weighted avg     0.9074    0.9098    0.9065    163566

F1-macro tok:  0.8314522112952081
F1-micro tok:  0.909828448455058
**************************************************
dev_cost_sum: 42056.7451171875
dev_cost_avg: 38.19867858055177
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19182.0
dev_accuracy_tok: 0.901664003008367
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.6146496815286624
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.7310606060606061
dev_label=P_precision_sent: 0.7450549450549451
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.754171301446051
dev_precision_macro_sent: 0.6569385792315728
dev_recall_macro_sent: 0.5711392022966116
dev_f-score_macro_sent: 0.524766911139196
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9116881614712856
dev_label=O_recall_tok: 0.9727861771058315
dev_label=O_f-score_tok: 0.9412467160257941
dev_label=N_precision_tok: 0.8204199855177408
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6998147004323655
dev_label=P_precision_tok: 0.8781706379707916
dev_label=P_recall_tok: 0.7113947696139477
dev_label=P_f-score_tok: 0.7860337117303062
dev_precision_macro_tok: 0.8700929283199393
dev_recall_macro_tok: 0.764768267466995
dev_f-score_macro_tok: 0.8090317093961552
dev_precision_micro_tok: 0.901664003008367
dev_recall_micro_tok: 0.901664003008367
dev_f-score_micro_tok: 0.901664003008367
dev_time: 10.669440031051636
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.6146    0.9019    0.7311       428
           P     0.7451    0.7635    0.7542       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6569    0.5711    0.5248      1101
weighted avg     0.6665    0.6685    0.6069      1101

F1-macro sent:  0.524766911139196
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9117    0.9728    0.9412     16205
           N     0.8204    0.6101    0.6998      1857
           P     0.8782    0.7114    0.7860      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8701    0.7648    0.8090     21274
weighted avg     0.8987    0.9017    0.8967     21274

F1-macro tok:  0.8090317093961552
F1-micro tok:  0.901664003008367
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.810000
train_cost_sum: 296697.4074707031
train_cost_avg: 34.72582016276956
train_count_sent: 8544.0
train_total_correct_sent: 5949.0
train_accuracy_sent: 0.6962780898876404
train_count_tok: 163566.0
train_total_correct_tok: 149066.0
train_accuracy_tok: 0.9113507697198684
train_label=O_precision_sent: 0.5126050420168067
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.1310418904403867
train_label=N_precision_sent: 0.6655518394648829
train_label=N_recall_sent: 0.8416918429003021
train_label=N_f-score_sent: 0.7433297758804696
train_label=P_precision_sent: 0.7381067961165049
train_label=P_recall_sent: 0.842382271468144
train_label=P_f-score_sent: 0.7868046571798188
train_precision_macro_sent: 0.6387545591993982
train_recall_macro_sent: 0.5863990890259353
train_f-score_macro_sent: 0.5537254411668917
train_precision_micro_sent: 0.6962780898876404
train_recall_micro_sent: 0.6962780898876404
train_f-score_micro_sent: 0.6962780898876404
train_label=O_precision_tok: 0.924039307154055
train_label=O_recall_tok: 0.9717323296903021
train_label=O_f-score_tok: 0.9472858979585437
train_label=N_precision_tok: 0.8233839050131926
train_label=N_recall_tok: 0.7031404027601746
train_label=N_f-score_tok: 0.758526395746297
train_label=P_precision_tok: 0.882697237943211
train_label=P_recall_tok: 0.7294239916856537
train_label=P_f-score_tok: 0.7987743488728387
train_precision_macro_tok: 0.8767068167034863
train_recall_macro_tok: 0.8014322413787102
train_f-score_macro_tok: 0.8348622141925599
train_precision_micro_tok: 0.9113507697198684
train_recall_micro_tok: 0.9113507697198684
train_f-score_micro_tok: 0.9113507697198684
train_time: 199.8099546432495
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5126    0.0751    0.1310      1624
           N     0.6656    0.8417    0.7433      3310
           P     0.7381    0.8424    0.7868      3610

   micro avg     0.6963    0.6963    0.6963      8544
   macro avg     0.6388    0.5864    0.5537      8544
weighted avg     0.6671    0.6963    0.6453      8544

F1-macro sent:  0.5537254411668917
F1-micro sent:  0.6962780898876404
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9240    0.9717    0.9473    124347
           N     0.8234    0.7031    0.7585     14202
           P     0.8827    0.7294    0.7988     25017

   micro avg     0.9114    0.9114    0.9114    163566
   macro avg     0.8767    0.8014    0.8349    163566
weighted avg     0.9090    0.9114    0.9082    163566

F1-macro tok:  0.8348622141925599
F1-micro tok:  0.9113507697198684
**************************************************
dev_cost_sum: 41905.84881591797
dev_cost_avg: 38.06162471927154
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19187.0
dev_accuracy_tok: 0.9018990316818651
dev_label=O_precision_sent: 0.8125
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10612244897959185
dev_label=N_precision_sent: 0.6557377049180327
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7369498464687819
dev_label=P_precision_sent: 0.6884328358208955
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.753061224489796
dev_precision_macro_sent: 0.7188901802463095
dev_recall_macro_sent: 0.5763237117867163
dev_f-score_macro_sent: 0.5320445066460566
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9099804305283757
dev_label=O_recall_tok: 0.9756248071582845
dev_label=O_f-score_tok: 0.9416599660502101
dev_label=N_precision_tok: 0.8015214384508991
dev_label=N_recall_tok: 0.6241249326871298
dev_label=N_f-score_tok: 0.70178625491977
dev_label=P_precision_tok: 0.9038304808475958
dev_label=P_recall_tok: 0.6905354919053549
dev_label=P_f-score_tok: 0.7829156371337804
dev_precision_macro_tok: 0.8717774499422902
dev_recall_macro_tok: 0.7634284105835897
dev_f-score_macro_tok: 0.8087872860345868
dev_precision_micro_tok: 0.9018990316818651
dev_recall_micro_tok: 0.9018990316818651
dev_f-score_micro_tok: 0.9018990316818651
dev_time: 10.763072729110718
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8125    0.0568    0.1061       229
           N     0.6557    0.8411    0.7369       428
           P     0.6884    0.8311    0.7531       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.7189    0.5763    0.5320      1101
weighted avg     0.7015    0.6739    0.6122      1101

F1-macro sent:  0.5320445066460566
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9100    0.9756    0.9417     16205
           N     0.8015    0.6241    0.7018      1857
           P     0.9038    0.6905    0.7829      3212

   micro avg     0.9019    0.9019    0.9019     21274
   macro avg     0.8718    0.7634    0.8088     21274
weighted avg     0.8996    0.9019    0.8968     21274

F1-macro tok:  0.8087872860345868
F1-micro tok:  0.9018990316818651
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.810000
train_cost_sum: 295678.2457885742
train_cost_avg: 34.60653625802601
train_count_sent: 8544.0
train_total_correct_sent: 6010.0
train_accuracy_sent: 0.7034176029962547
train_count_tok: 163566.0
train_total_correct_tok: 149237.0
train_accuracy_tok: 0.912396219263172
train_label=O_precision_sent: 0.5532786885245902
train_label=O_recall_sent: 0.08312807881773399
train_label=O_f-score_sent: 0.14453961456102782
train_label=N_precision_sent: 0.6649544711650712
train_label=N_recall_sent: 0.8604229607250755
train_label=N_f-score_sent: 0.7501646253127882
train_label=P_precision_sent: 0.7535474234503361
train_label=P_recall_sent: 0.8385041551246537
train_label=P_f-score_sent: 0.7937590140291071
train_precision_macro_sent: 0.6572601943799992
train_recall_macro_sent: 0.5940183982224877
train_f-score_macro_sent: 0.5628210846343077
train_precision_micro_sent: 0.7034176029962547
train_recall_micro_sent: 0.7034176029962547
train_f-score_micro_sent: 0.7034176029962547
train_label=O_precision_tok: 0.9255331367969677
train_label=O_recall_tok: 0.9720379261260826
train_label=O_f-score_tok: 0.9482156725843525
train_label=N_precision_tok: 0.8218202651825176
train_label=N_recall_tok: 0.707013096746937
train_label=N_f-score_tok: 0.7601059803179411
train_label=P_precision_tok: 0.8830530525707126
train_label=P_recall_tok: 0.7325418715273614
train_label=P_f-score_tok: 0.8007865414026655
train_precision_macro_tok: 0.8768021515167326
train_recall_macro_tok: 0.8038642981334604
train_f-score_macro_tok: 0.836369398101653
train_precision_micro_tok: 0.912396219263172
train_recall_micro_tok: 0.912396219263172
train_f-score_micro_tok: 0.912396219263172
train_time: 199.5493323802948
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5533    0.0831    0.1445      1624
           N     0.6650    0.8604    0.7502      3310
           P     0.7535    0.8385    0.7938      3610

   micro avg     0.7034    0.7034    0.7034      8544
   macro avg     0.6573    0.5940    0.5628      8544
weighted avg     0.6812    0.7034    0.6535      8544

F1-macro sent:  0.5628210846343077
F1-micro sent:  0.7034176029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9255    0.9720    0.9482    124347
           N     0.8218    0.7070    0.7601     14202
           P     0.8831    0.7325    0.8008     25017

   micro avg     0.9124    0.9124    0.9124    163566
   macro avg     0.8768    0.8039    0.8364    163566
weighted avg     0.9100    0.9124    0.9093    163566

F1-macro tok:  0.836369398101653
F1-micro tok:  0.912396219263172
**************************************************
dev_cost_sum: 41883.73272705078
dev_cost_avg: 38.041537445096075
dev_count_sent: 1101.0
dev_total_correct_sent: 755.0
dev_accuracy_sent: 0.6857402361489555
dev_count_tok: 21274.0
dev_total_correct_tok: 19168.0
dev_accuracy_tok: 0.9010059227225722
dev_label=O_precision_sent: 0.5238095238095238
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08800000000000001
dev_label=N_precision_sent: 0.6660746003552398
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.756811301715439
dev_label=P_precision_sent: 0.7137330754352031
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7679500520291364
dev_precision_macro_sent: 0.6345390665333223
dev_recall_macro_sent: 0.5850947466259876
dev_f-score_macro_sent: 0.5375871179148585
dev_precision_micro_sent: 0.6857402361489555
dev_recall_micro_sent: 0.6857402361489555
dev_f-score_micro_sent: 0.6857402361489555
dev_label=O_precision_tok: 0.9123101889416947
dev_label=O_recall_tok: 0.9713668620796051
dev_label=O_f-score_tok: 0.940912758898951
dev_label=N_precision_tok: 0.796875
dev_label=N_recall_tok: 0.6316639741518578
dev_label=N_f-score_tok: 0.7047161309702612
dev_label=P_precision_tok: 0.8846153846153846
dev_label=P_recall_tok: 0.7017434620174346
dev_label=P_f-score_tok: 0.7826388888888889
dev_precision_macro_tok: 0.864600191185693
dev_recall_macro_tok: 0.7682580994162992
dev_f-score_macro_tok: 0.809422592919367
dev_precision_micro_tok: 0.9010059227225722
dev_recall_micro_tok: 0.9010059227225722
dev_f-score_micro_tok: 0.9010059227225722
dev_time: 10.384450674057007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5238    0.0480    0.0880       229
           N     0.6661    0.8762    0.7568       428
           P     0.7137    0.8311    0.7680       444

   micro avg     0.6857    0.6857    0.6857      1101
   macro avg     0.6345    0.5851    0.5376      1101
weighted avg     0.6557    0.6857    0.6222      1101

F1-macro sent:  0.5375871179148585
F1-micro sent:  0.6857402361489555
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9714    0.9409     16205
           N     0.7969    0.6317    0.7047      1857
           P     0.8846    0.7017    0.7826      3212

   micro avg     0.9010    0.9010    0.9010     21274
   macro avg     0.8646    0.7683    0.8094     21274
weighted avg     0.8981    0.9010    0.8964     21274

F1-macro tok:  0.809422592919367
F1-micro tok:  0.9010059227225722
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.729000
train_cost_sum: 294254.35333251953
train_cost_avg: 34.439882178431596
train_count_sent: 8544.0
train_total_correct_sent: 5990.0
train_accuracy_sent: 0.7010767790262172
train_count_tok: 163566.0
train_total_correct_tok: 149612.0
train_accuracy_tok: 0.9146888717704168
train_label=O_precision_sent: 0.47686832740213525
train_label=O_recall_sent: 0.08251231527093596
train_label=O_f-score_sent: 0.14068241469816273
train_label=N_precision_sent: 0.6741060715142788
train_label=N_recall_sent: 0.8486404833836858
train_label=N_f-score_sent: 0.7513708706700548
train_label=P_precision_sent: 0.743896484375
train_label=P_recall_sent: 0.8440443213296399
train_label=P_f-score_sent: 0.7908123540098624
train_precision_macro_sent: 0.6316236277638047
train_recall_macro_sent: 0.5917323733280871
train_f-score_macro_sent: 0.5609552131260266
train_precision_micro_sent: 0.7010767790262172
train_recall_micro_sent: 0.7010767790262172
train_f-score_micro_sent: 0.7010767790262172
train_label=O_precision_tok: 0.9270797409663946
train_label=O_recall_tok: 0.9728421272728734
train_label=O_f-score_tok: 0.9494098072455579
train_label=N_precision_tok: 0.8325958702064897
train_label=N_recall_tok: 0.7154626108998733
train_label=N_f-score_tok: 0.7695978186775735
train_label=P_precision_tok: 0.8852325525698137
train_label=P_recall_tok: 0.7387376583922932
train_label=P_f-score_tok: 0.8053776092735434
train_precision_macro_tok: 0.8816360545808993
train_recall_macro_tok: 0.8090141321883467
train_f-score_macro_tok: 0.8414617450655584
train_precision_micro_tok: 0.9146888717704168
train_recall_micro_tok: 0.9146888717704168
train_f-score_micro_tok: 0.9146888717704169
train_time: 200.25804448127747
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4769    0.0825    0.1407      1624
           N     0.6741    0.8486    0.7514      3310
           P     0.7439    0.8440    0.7908      3610

   micro avg     0.7011    0.7011    0.7011      8544
   macro avg     0.6316    0.5917    0.5610      8544
weighted avg     0.6661    0.7011    0.6520      8544

F1-macro sent:  0.5609552131260266
F1-micro sent:  0.7010767790262172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9271    0.9728    0.9494    124347
           N     0.8326    0.7155    0.7696     14202
           P     0.8852    0.7387    0.8054     25017

   micro avg     0.9147    0.9147    0.9147    163566
   macro avg     0.8816    0.8090    0.8415    163566
weighted avg     0.9125    0.9147    0.9118    163566

F1-macro tok:  0.8414617450655584
F1-micro tok:  0.9146888717704169
**************************************************
dev_cost_sum: 41917.67150878906
dev_cost_avg: 38.07236285993557
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19190.0
dev_accuracy_tok: 0.9020400488859641
dev_label=O_precision_sent: 0.5517241379310345
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12403100775193798
dev_label=N_precision_sent: 0.6604127579737336
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7325702393340271
dev_label=P_precision_sent: 0.6827458256029685
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7487283825025433
dev_precision_macro_sent: 0.6316275738359122
dev_recall_macro_sent: 0.5737092436680242
dev_f-score_macro_sent: 0.5351098765295027
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9146880819366853
dev_label=O_recall_tok: 0.9699475470533786
dev_label=O_f-score_tok: 0.9415076821707747
dev_label=N_precision_tok: 0.7801418439716312
dev_label=N_recall_tok: 0.6515885837372105
dev_label=N_f-score_tok: 0.710093896713615
dev_label=P_precision_tok: 0.8909019298936589
dev_label=P_recall_tok: 0.7042341220423413
dev_label=P_f-score_tok: 0.7866458007303079
dev_precision_macro_tok: 0.8619106186006585
dev_recall_macro_tok: 0.7752567509443101
dev_f-score_macro_tok: 0.8127491265382325
dev_precision_micro_tok: 0.9020400488859641
dev_recall_micro_tok: 0.9020400488859641
dev_f-score_micro_tok: 0.9020400488859641
dev_time: 10.550159931182861
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5517    0.0699    0.1240       229
           N     0.6604    0.8224    0.7326       428
           P     0.6827    0.8288    0.7487       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6316    0.5737    0.5351      1101
weighted avg     0.6468    0.6685    0.6125      1101

F1-macro sent:  0.5351098765295027
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9699    0.9415     16205
           N     0.7801    0.6516    0.7101      1857
           P     0.8909    0.7042    0.7866      3212

   micro avg     0.9020    0.9020    0.9020     21274
   macro avg     0.8619    0.7753    0.8127     21274
weighted avg     0.8994    0.9020    0.8979     21274

F1-macro tok:  0.8127491265382325
F1-micro tok:  0.9020400488859641
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.656100
train_cost_sum: 292891.1484375
train_cost_avg: 34.28033104371489
train_count_sent: 8544.0
train_total_correct_sent: 6021.0
train_accuracy_sent: 0.7047050561797753
train_count_tok: 163566.0
train_total_correct_tok: 149951.0
train_accuracy_tok: 0.9167614296369662
train_label=O_precision_sent: 0.5257352941176471
train_label=O_recall_sent: 0.08805418719211823
train_label=O_f-score_sent: 0.1508438818565401
train_label=N_precision_sent: 0.674088109900521
train_label=N_recall_sent: 0.8598187311178248
train_label=N_f-score_sent: 0.75570897503983
train_label=P_precision_sent: 0.748641975308642
train_label=P_recall_sent: 0.8398891966759002
train_label=P_f-score_sent: 0.791644908616188
train_precision_macro_sent: 0.6494884597756033
train_recall_macro_sent: 0.5959207049952812
train_f-score_macro_sent: 0.5660659218375194
train_precision_micro_sent: 0.7047050561797753
train_recall_micro_sent: 0.7047050561797753
train_f-score_micro_sent: 0.7047050561797753
train_label=O_precision_tok: 0.9298132349550381
train_label=O_recall_tok: 0.9729064633646167
train_label=O_f-score_tok: 0.9508718565415768
train_label=N_precision_tok: 0.828162869607368
train_label=N_recall_tok: 0.7217997465145755
train_label=N_f-score_tok: 0.7713318284424379
train_label=P_precision_tok: 0.8882246892494544
train_label=P_recall_tok: 0.7483711076468001
train_label=P_f-score_tok: 0.8123223776982319
train_precision_macro_tok: 0.8820669312706202
train_recall_macro_tok: 0.8143591058419974
train_f-score_macro_tok: 0.8448420208940822
train_precision_micro_tok: 0.9167614296369662
train_recall_micro_tok: 0.9167614296369662
train_f-score_micro_tok: 0.9167614296369662
train_time: 183.25054287910461
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5257    0.0881    0.1508      1624
           N     0.6741    0.8598    0.7557      3310
           P     0.7486    0.8399    0.7916      3610

   micro avg     0.7047    0.7047    0.7047      8544
   macro avg     0.6495    0.5959    0.5661      8544
weighted avg     0.6774    0.7047    0.6559      8544

F1-macro sent:  0.5660659218375194
F1-micro sent:  0.7047050561797753
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9298    0.9729    0.9509    124347
           N     0.8282    0.7218    0.7713     14202
           P     0.8882    0.7484    0.8123     25017

   micro avg     0.9168    0.9168    0.9168    163566
   macro avg     0.8821    0.8144    0.8448    163566
weighted avg     0.9146    0.9168    0.9141    163566

F1-macro tok:  0.8448420208940822
F1-micro tok:  0.9167614296369662
**************************************************
dev_cost_sum: 41940.851318359375
dev_cost_avg: 38.093416274622506
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19164.0
dev_accuracy_tok: 0.9008178997837736
dev_label=O_precision_sent: 0.5909090909090909
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10358565737051793
dev_label=N_precision_sent: 0.628140703517588
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7317073170731708
dev_label=P_precision_sent: 0.7240663900414938
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.75377969762419
dev_precision_macro_sent: 0.6477053948227242
dev_recall_macro_sent: 0.5729909397623555
dev_f-score_macro_sent: 0.5296908906892929
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9147670961347869
dev_label=O_recall_tok: 0.9682813946312866
dev_label=O_f-score_tok: 0.9407638347622758
dev_label=N_precision_tok: 0.7818181818181819
dev_label=N_recall_tok: 0.6483575659666129
dev_label=N_f-score_tok: 0.708860759493671
dev_label=P_precision_tok: 0.8791166214645486
dev_label=P_recall_tok: 0.7064134495641345
dev_label=P_f-score_tok: 0.783359226652857
dev_precision_macro_tok: 0.8585672998058391
dev_recall_macro_tok: 0.7743508033873446
dev_f-score_macro_tok: 0.8109946069696012
dev_precision_micro_tok: 0.9008178997837736
dev_recall_micro_tok: 0.9008178997837736
dev_f-score_micro_tok: 0.9008178997837736
dev_time: 7.083008289337158
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5909    0.0568    0.1036       229
           N     0.6281    0.8762    0.7317       428
           P     0.7241    0.7860    0.7538       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6477    0.5730    0.5297      1101
weighted avg     0.6591    0.6694    0.6100      1101

F1-macro sent:  0.5296908906892929
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9148    0.9683    0.9408     16205
           N     0.7818    0.6484    0.7089      1857
           P     0.8791    0.7064    0.7834      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8586    0.7744    0.8110     21274
weighted avg     0.8978    0.9008    0.8968     21274

F1-macro tok:  0.8109946069696012
F1-micro tok:  0.9008178997837736
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.590490
train_cost_sum: 291526.5867919922
train_cost_avg: 34.120621113294966
train_count_sent: 8544.0
train_total_correct_sent: 6051.0
train_accuracy_sent: 0.7082162921348315
train_count_tok: 163566.0
train_total_correct_tok: 150288.0
train_accuracy_tok: 0.9188217600234767
train_label=O_precision_sent: 0.5115511551155115
train_label=O_recall_sent: 0.09544334975369458
train_label=O_f-score_sent: 0.16087182148417226
train_label=N_precision_sent: 0.6867381764992686
train_label=N_recall_sent: 0.8510574018126889
train_label=N_f-score_sent: 0.7601187263896384
train_label=P_precision_sent: 0.7438994926310704
train_label=P_recall_sent: 0.8529085872576178
train_label=P_f-score_sent: 0.7946831849270874
train_precision_macro_sent: 0.6473962747486168
train_recall_macro_sent: 0.5998031129413337
train_f-score_macro_sent: 0.571891244266966
train_precision_micro_sent: 0.7082162921348315
train_recall_micro_sent: 0.7082162921348315
train_f-score_micro_sent: 0.7082162921348315
train_label=O_precision_tok: 0.9316039914995842
train_label=O_recall_tok: 0.9730270935366354
train_label=O_f-score_tok: 0.9518650948183288
train_label=N_precision_tok: 0.8356109324758842
train_label=N_recall_tok: 0.7319391634980988
train_label=N_f-score_tok: 0.7803468208092486
train_label=P_precision_tok: 0.8894117647058823
train_label=P_recall_tok: 0.7554862693368509
train_label=P_f-score_tok: 0.8169969956988783
train_precision_macro_tok: 0.8855422295604503
train_recall_macro_tok: 0.8201508421238617
train_f-score_macro_tok: 0.8497363037754851
train_precision_micro_tok: 0.9188217600234767
train_recall_micro_tok: 0.9188217600234767
train_f-score_micro_tok: 0.9188217600234767
train_time: 146.61594414710999
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5116    0.0954    0.1609      1624
           N     0.6867    0.8511    0.7601      3310
           P     0.7439    0.8529    0.7947      3610

   micro avg     0.7082    0.7082    0.7082      8544
   macro avg     0.6474    0.5998    0.5719      8544
weighted avg     0.6776    0.7082    0.6608      8544

F1-macro sent:  0.571891244266966
F1-micro sent:  0.7082162921348315
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9316    0.9730    0.9519    124347
           N     0.8356    0.7319    0.7803     14202
           P     0.8894    0.7555    0.8170     25017

   micro avg     0.9188    0.9188    0.9188    163566
   macro avg     0.8855    0.8202    0.8497    163566
weighted avg     0.9168    0.9188    0.9163    163566

F1-macro tok:  0.8497363037754851
F1-micro tok:  0.9188217600234767
**************************************************
dev_cost_sum: 41891.413513183594
dev_cost_avg: 38.0485136359524
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19162.0
dev_accuracy_tok: 0.9007238883143743
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.6306913996627319
dev_label=N_recall_sent: 0.8738317757009346
dev_label=N_f-score_sent: 0.7326150832517141
dev_label=P_precision_sent: 0.7099391480730223
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7470651013874067
dev_precision_macro_sent: 0.6913212936896959
dev_recall_macro_sent: 0.5700516661623465
dev_f-score_macro_sent: 0.5232813730217835
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9152562157114509
dev_label=O_recall_tok: 0.9677260104905894
dev_label=O_f-score_tok: 0.940760070787966
dev_label=N_precision_tok: 0.7874172185430464
dev_label=N_recall_tok: 0.6402800215401184
dev_label=N_f-score_tok: 0.7062667062667063
dev_label=P_precision_tok: 0.8711026615969581
dev_label=P_recall_tok: 0.7132627646326276
dev_label=P_f-score_tok: 0.7843204382060938
dev_precision_macro_tok: 0.8579253652838185
dev_recall_macro_tok: 0.7737562655544452
dev_f-score_macro_tok: 0.8104490717535887
dev_precision_micro_tok: 0.9007238883143743
dev_recall_micro_tok: 0.9007238883143743
dev_f-score_micro_tok: 0.9007238883143743
dev_time: 7.330644607543945
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.6307    0.8738    0.7326       428
           P     0.7099    0.7883    0.7471       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6913    0.5701    0.5233      1101
weighted avg     0.6840    0.6676    0.6048      1101

F1-macro sent:  0.5232813730217835
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9153    0.9677    0.9408     16205
           N     0.7874    0.6403    0.7063      1857
           P     0.8711    0.7133    0.7843      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8579    0.7738    0.8104     21274
weighted avg     0.8974    0.9007    0.8967     21274

F1-macro tok:  0.8104490717535887
F1-micro tok:  0.9007238883143743
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42050.98175048828
test0_cost_avg: 38.19344391506656
test0_count_sent: 1101.0
test0_total_correct_sent: 742.0
test0_accuracy_sent: 0.6739327883742052
test0_count_tok: 21274.0
test0_total_correct_tok: 19192.0
test0_accuracy_tok: 0.9021340603553634
test0_label=O_precision_sent: 0.43243243243243246
test0_label=O_recall_sent: 0.13973799126637554
test0_label=O_f-score_sent: 0.21122112211221122
test0_label=N_precision_sent: 0.6826347305389222
test0_label=N_recall_sent: 0.7990654205607477
test0_label=N_f-score_sent: 0.7362755651237891
test0_label=P_precision_sent: 0.6996197718631179
test0_label=P_recall_sent: 0.8288288288288288
test0_label=P_f-score_sent: 0.7587628865979381
test0_precision_macro_sent: 0.6048956449448242
test0_recall_macro_sent: 0.5892107468853173
test0_f-score_macro_sent: 0.5687531912779794
test0_precision_micro_sent: 0.6739327883742052
test0_recall_micro_sent: 0.6739327883742052
test0_f-score_micro_sent: 0.6739327883742052
test0_label=O_precision_tok: 0.9058185966913862
test0_label=O_recall_tok: 0.9798827522369639
test0_label=O_f-score_tok: 0.941396176078257
test0_label=N_precision_tok: 0.8177874186550976
test0_label=N_recall_tok: 0.6090468497576736
test0_label=N_f-score_tok: 0.6981481481481481
test0_label=P_precision_tok: 0.9241846675137654
test0_label=P_recall_tok: 0.6793275217932753
test0_label=P_f-score_tok: 0.7830611878700879
test0_precision_macro_tok: 0.8825968942867498
test0_recall_macro_tok: 0.7560857079293042
test0_f-score_macro_tok: 0.8075351706988311
test0_precision_micro_tok: 0.9021340603553634
test0_recall_micro_tok: 0.9021340603553634
test0_f-score_micro_tok: 0.9021340603553635
test0_time: 8.055444478988647
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4324    0.1397    0.2112       229
           N     0.6826    0.7991    0.7363       428
           P     0.6996    0.8288    0.7588       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6049    0.5892    0.5688      1101
weighted avg     0.6374    0.6739    0.6361      1101

F1-macro sent:  0.5687531912779794
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9799    0.9414     16205
           N     0.8178    0.6090    0.6981      1857
           P     0.9242    0.6793    0.7831      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8826    0.7561    0.8075     21274
weighted avg     0.9009    0.9021    0.8963     21274

F1-macro tok:  0.8075351706988311
F1-micro tok:  0.9021340603553635
**************************************************
test1_cost_sum: 81457.83470535278
test1_cost_avg: 36.85874873545375
test1_count_sent: 2210.0
test1_total_correct_sent: 1554.0
test1_accuracy_sent: 0.7031674208144797
test1_count_tok: 42405.0
test1_total_correct_tok: 37916.0
test1_accuracy_tok: 0.8941398419997642
test1_label=O_precision_sent: 0.37735849056603776
test1_label=O_recall_sent: 0.15424164524421594
test1_label=O_f-score_sent: 0.21897810218978103
test1_label=N_precision_sent: 0.7156862745098039
test1_label=N_recall_sent: 0.8004385964912281
test1_label=N_f-score_sent: 0.7556935817805384
test1_label=P_precision_sent: 0.7410281280310378
test1_label=P_recall_sent: 0.8404840484048405
test1_label=P_f-score_sent: 0.7876288659793813
test1_precision_macro_sent: 0.6113576310356265
test1_recall_macro_sent: 0.5983880967134282
test1_f-score_macro_sent: 0.5874335166499002
test1_precision_micro_sent: 0.7031674208144797
test1_recall_micro_sent: 0.7031674208144797
test1_f-score_micro_sent: 0.7031674208144797
test1_label=O_precision_tok: 0.896114647863199
test1_label=O_recall_tok: 0.9809988124257766
test1_label=O_f-score_tok: 0.9366374744505945
test1_label=N_precision_tok: 0.8254716981132075
test1_label=N_recall_tok: 0.6050531914893617
test1_label=N_f-score_tok: 0.6982811540822591
test1_label=P_precision_tok: 0.9201298701298701
test1_label=P_recall_tok: 0.6395366330675493
test1_label=P_f-score_tok: 0.7545930593769415
test1_precision_macro_tok: 0.8805720720354255
test1_recall_macro_tok: 0.7418628789942292
test1_f-score_macro_tok: 0.7965038959699317
test1_precision_micro_tok: 0.8941398419997642
test1_recall_micro_tok: 0.8941398419997642
test1_f-score_micro_tok: 0.8941398419997642
test1_time: 14.885510683059692
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3774    0.1542    0.2190       389
           N     0.7157    0.8004    0.7557       912
           P     0.7410    0.8405    0.7876       909

   micro avg     0.7032    0.7032    0.7032      2210
   macro avg     0.6114    0.5984    0.5874      2210
weighted avg     0.6666    0.7032    0.6744      2210

F1-macro sent:  0.5874335166499002
F1-micro sent:  0.7031674208144797
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9810    0.9366     31998
           N     0.8255    0.6051    0.6983      3760
           P     0.9201    0.6395    0.7546      6647

   micro avg     0.8941    0.8941    0.8941     42405
   macro avg     0.8806    0.7419    0.7965     42405
weighted avg     0.8936    0.8941    0.8870     42405

F1-macro tok:  0.7965038959699317
F1-micro tok:  0.8941398419997642
**************************************************
