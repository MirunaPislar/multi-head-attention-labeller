to_write_filename: runs/transformer_sentiment_sent+word+LM_loss_model_selector=dev_f-score_macro_tok.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_tok:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'O': 0, 'P': 2}
{'N': 1, 'O': 0, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428548.14025878906
train_cost_avg: 50.157787951637296
train_count_sent: 8544.0
train_total_correct_sent: 4266.0
train_accuracy_sent: 0.49929775280898875
train_count_tok: 163566.0
train_total_correct_tok: 125798.0
train_accuracy_tok: 0.7690962669503442
train_label=O_precision_sent: 0.20905923344947736
train_label=O_recall_sent: 0.03694581280788178
train_label=O_f-score_sent: 0.06279434850863423
train_label=N_precision_sent: 0.48922585794094176
train_label=N_recall_sent: 0.5555891238670695
train_label=N_f-score_sent: 0.5202999009760928
train_label=P_precision_sent: 0.5262338817252112
train_label=P_recall_sent: 0.6556786703601108
train_label=P_f-score_sent: 0.5838677849037989
train_precision_macro_sent: 0.40817299103854343
train_recall_macro_sent: 0.41607120234502065
train_f-score_macro_sent: 0.3889873447961753
train_precision_micro_sent: 0.49929775280898875
train_recall_micro_sent: 0.49929775280898875
train_f-score_micro_sent: 0.49929775280898875
train_label=O_precision_tok: 0.7969114887757994
train_label=O_recall_tok: 0.949536378038875
train_label=O_f-score_tok: 0.8665548660778175
train_label=N_precision_tok: 0.4828510182207931
train_label=N_recall_tok: 0.19032530629488803
train_label=N_f-score_tok: 0.273030303030303
train_label=P_precision_tok: 0.512237405669998
train_label=P_recall_tok: 0.20078346724227525
train_label=P_f-score_tok: 0.2884874938977113
train_precision_macro_tok: 0.5973333042221968
train_recall_macro_tok: 0.44688171719201275
train_f-score_macro_tok: 0.4760242210019439
train_precision_micro_tok: 0.7690962669503442
train_recall_micro_tok: 0.7690962669503442
train_f-score_micro_tok: 0.769096266950344
train_time: 144.4704008102417
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2091    0.0369    0.0628      1624
           N     0.4892    0.5556    0.5203      3310
           P     0.5262    0.6557    0.5839      3610

   micro avg     0.4993    0.4993    0.4993      8544
   macro avg     0.4082    0.4161    0.3890      8544
weighted avg     0.4516    0.4993    0.4602      8544

F1-macro sent:  0.3889873447961753
F1-micro sent:  0.49929775280898875
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7969    0.9495    0.8666    124347
           N     0.4829    0.1903    0.2730     14202
           P     0.5122    0.2008    0.2885     25017

   micro avg     0.7691    0.7691    0.7691    163566
   macro avg     0.5973    0.4469    0.4760    163566
weighted avg     0.7261    0.7691    0.7266    163566

F1-macro tok:  0.4760242210019439
F1-micro tok:  0.769096266950344
**************************************************
dev_cost_sum: 50555.43859863281
dev_cost_avg: 45.9177462294576
dev_count_sent: 1101.0
dev_total_correct_sent: 648.0
dev_accuracy_sent: 0.5885558583106267
dev_count_tok: 21274.0
dev_total_correct_tok: 17529.0
dev_accuracy_tok: 0.8239635235498731
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6363636363636364
dev_label=N_recall_sent: 0.6051401869158879
dev_label=N_f-score_sent: 0.6203592814371257
dev_label=P_precision_sent: 0.5605187319884726
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.6836555360281195
dev_precision_macro_sent: 0.39896078945070296
dev_recall_macro_sent: 0.49375543768067137
dev_f-score_macro_sent: 0.4346716058217484
dev_precision_micro_sent: 0.5885558583106267
dev_recall_micro_sent: 0.5885558583106267
dev_f-score_micro_sent: 0.5885558583106267
dev_label=O_precision_tok: 0.8479991156312182
dev_label=O_recall_tok: 0.9467448318420241
dev_label=O_f-score_tok: 0.8946555092282124
dev_label=N_precision_tok: 0.6712095400340715
dev_label=N_recall_tok: 0.4243403338718363
dev_label=N_f-score_tok: 0.5199604091059056
dev_label=P_precision_tok: 0.6967131474103586
dev_label=P_recall_tok: 0.43555417185554174
dev_label=P_f-score_tok: 0.5360153256704981
dev_precision_macro_tok: 0.7386406010252161
dev_recall_macro_tok: 0.602213112523134
dev_f-score_macro_tok: 0.6502104146682054
dev_precision_micro_tok: 0.8239635235498731
dev_recall_micro_tok: 0.8239635235498731
dev_f-score_micro_tok: 0.8239635235498731
dev_time: 8.587713718414307
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6364    0.6051    0.6204       428
           P     0.5605    0.8761    0.6837       444

   micro avg     0.5886    0.5886    0.5886      1101
   macro avg     0.3990    0.4938    0.4347      1101
weighted avg     0.4734    0.5886    0.5169      1101

F1-macro sent:  0.4346716058217484
F1-micro sent:  0.5885558583106267
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8480    0.9467    0.8947     16205
           N     0.6712    0.4243    0.5200      1857
           P     0.6967    0.4356    0.5360      3212

   micro avg     0.8240    0.8240    0.8240     21274
   macro avg     0.7386    0.6022    0.6502     21274
weighted avg     0.8097    0.8240    0.8078     21274

F1-macro tok:  0.6502104146682054
F1-micro tok:  0.8239635235498731
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378359.7727050781
train_cost_avg: 44.28368126229847
train_count_sent: 8544.0
train_total_correct_sent: 4820.0
train_accuracy_sent: 0.5641385767790262
train_count_tok: 163566.0
train_total_correct_tok: 132313.0
train_accuracy_tok: 0.8089272831762102
train_label=O_precision_sent: 0.17647058823529413
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.00723763570566948
train_label=N_precision_sent: 0.5340510180201263
train_label=N_recall_sent: 0.6894259818731118
train_label=N_f-score_sent: 0.6018726097850454
train_label=P_precision_sent: 0.5975926362992684
train_label=P_recall_sent: 0.7013850415512466
train_label=P_f-score_sent: 0.6453421689817765
train_precision_macro_sent: 0.436038080851563
train_recall_macro_sent: 0.46483520156838215
train_f-score_macro_sent: 0.41815080482416384
train_precision_micro_sent: 0.5641385767790262
train_recall_micro_sent: 0.5641385767790262
train_f-score_micro_sent: 0.5641385767790262
train_label=O_precision_tok: 0.8319442489089117
train_label=O_recall_tok: 0.9504531673462167
train_label=O_f-score_tok: 0.8872589684204994
train_label=N_precision_tok: 0.6434886499402629
train_label=N_recall_tok: 0.37924236023095337
train_label=N_f-score_tok: 0.4772284245968457
train_label=P_precision_tok: 0.6654232643118149
train_label=P_recall_tok: 0.3494024063636727
train_label=P_f-score_tok: 0.45820774251041857
train_precision_macro_tok: 0.7136187210536632
train_recall_macro_tok: 0.5596993113136143
train_f-score_macro_tok: 0.6075650451759212
train_precision_micro_tok: 0.8089272831762102
train_recall_micro_tok: 0.8089272831762102
train_f-score_micro_tok: 0.8089272831762102
train_time: 141.60106801986694
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1765    0.0037    0.0072      1624
           N     0.5341    0.6894    0.6019      3310
           P     0.5976    0.7014    0.6453      3610

   micro avg     0.5641    0.5641    0.5641      8544
   macro avg     0.4360    0.4648    0.4182      8544
weighted avg     0.4929    0.5641    0.5072      8544

F1-macro sent:  0.41815080482416384
F1-micro sent:  0.5641385767790262
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8319    0.9505    0.8873    124347
           N     0.6435    0.3792    0.4772     14202
           P     0.6654    0.3494    0.4582     25017

   micro avg     0.8089    0.8089    0.8089    163566
   macro avg     0.7136    0.5597    0.6076    163566
weighted avg     0.7901    0.8089    0.7860    163566

F1-macro tok:  0.6075650451759212
F1-micro tok:  0.8089272831762102
**************************************************
dev_cost_sum: 49001.33264160156
dev_cost_avg: 44.50620585068262
dev_count_sent: 1101.0
dev_total_correct_sent: 664.0
dev_accuracy_sent: 0.6030881017257039
dev_count_tok: 21274.0
dev_total_correct_tok: 17752.0
dev_accuracy_tok: 0.8344458023878913
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5271523178807948
dev_label=N_recall_sent: 0.9299065420560748
dev_label=N_f-score_sent: 0.672865595942519
dev_label=P_precision_sent: 0.7687861271676301
dev_label=P_recall_sent: 0.5990990990990991
dev_label=P_f-score_sent: 0.6734177215189873
dev_precision_macro_sent: 0.43197948168280825
dev_recall_macro_sent: 0.5096685470517247
dev_f-score_macro_sent: 0.4487611058205021
dev_precision_micro_sent: 0.6030881017257039
dev_recall_micro_sent: 0.6030881017257039
dev_f-score_micro_sent: 0.6030881017257039
dev_label=O_precision_tok: 0.8431003921147339
dev_label=O_recall_tok: 0.9685899413761185
dev_label=O_f-score_tok: 0.901499052323244
dev_label=N_precision_tok: 0.6929621036349575
dev_label=N_recall_tok: 0.4824986537425956
dev_label=N_f-score_tok: 0.5688888888888889
dev_label=P_precision_tok: 0.8504398826979472
dev_label=P_recall_tok: 0.36114570361145704
dev_label=P_f-score_tok: 0.506993006993007
dev_precision_macro_tok: 0.7955007928158796
dev_recall_macro_tok: 0.6040780995767238
dev_f-score_macro_tok: 0.6591269827350467
dev_precision_micro_tok: 0.8344458023878913
dev_recall_micro_tok: 0.8344458023878913
dev_f-score_micro_tok: 0.8344458023878913
dev_time: 8.199972867965698
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5272    0.9299    0.6729       428
           P     0.7688    0.5991    0.6734       444

   micro avg     0.6031    0.6031    0.6031      1101
   macro avg     0.4320    0.5097    0.4488      1101
weighted avg     0.5150    0.6031    0.5331      1101

F1-macro sent:  0.4487611058205021
F1-micro sent:  0.6030881017257039
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8431    0.9686    0.9015     16205
           N     0.6930    0.4825    0.5689      1857
           P     0.8504    0.3611    0.5070      3212

   micro avg     0.8344    0.8344    0.8344     21274
   macro avg     0.7955    0.6041    0.6591     21274
weighted avg     0.8311    0.8344    0.8129     21274

F1-macro tok:  0.6591269827350467
F1-micro tok:  0.8344458023878913
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 367876.021484375
train_cost_avg: 43.05665045463191
train_count_sent: 8544.0
train_total_correct_sent: 5031.0
train_accuracy_sent: 0.5888342696629213
train_count_tok: 163566.0
train_total_correct_tok: 135406.0
train_accuracy_tok: 0.8278370810559652
train_label=O_precision_sent: 0.2727272727272727
train_label=O_recall_sent: 0.011083743842364532
train_label=O_f-score_sent: 0.021301775147928994
train_label=N_precision_sent: 0.5598574821852732
train_label=N_recall_sent: 0.7120845921450151
train_label=N_f-score_sent: 0.6268617021276596
train_label=P_precision_sent: 0.6223055295220243
train_label=P_recall_sent: 0.7357340720221607
train_label=P_f-score_sent: 0.6742828128966744
train_precision_macro_sent: 0.48496342814485677
train_recall_macro_sent: 0.48630080266984677
train_f-score_macro_sent: 0.44081543005742096
train_precision_micro_sent: 0.5888342696629213
train_recall_micro_sent: 0.5888342696629213
train_f-score_micro_sent: 0.5888342696629213
train_label=O_precision_tok: 0.8489066318814819
train_label=O_recall_tok: 0.9525119222820012
train_label=O_f-score_tok: 0.8977299427748512
train_label=N_precision_tok: 0.6750989881214254
train_label=N_recall_tok: 0.43219264892268694
train_label=N_f-score_tok: 0.5270026616296042
train_label=P_precision_tok: 0.7240987224934787
train_label=P_recall_tok: 0.4327457329016269
train_label=P_f-score_tok: 0.5417333867093674
train_precision_macro_tok: 0.749368114165462
train_recall_macro_tok: 0.6058167680354384
train_f-score_macro_tok: 0.6554886637046077
train_precision_micro_tok: 0.8278370810559652
train_recall_micro_tok: 0.8278370810559652
train_f-score_micro_tok: 0.8278370810559652
train_time: 141.64333295822144
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2727    0.0111    0.0213      1624
           N     0.5599    0.7121    0.6269      3310
           P     0.6223    0.7357    0.6743      3610

   micro avg     0.5888    0.5888    0.5888      8544
   macro avg     0.4850    0.4863    0.4408      8544
weighted avg     0.5317    0.5888    0.5318      8544

F1-macro sent:  0.44081543005742096
F1-micro sent:  0.5888342696629213
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8489    0.9525    0.8977    124347
           N     0.6751    0.4322    0.5270     14202
           P     0.7241    0.4327    0.5417     25017

   micro avg     0.8278    0.8278    0.8278    163566
   macro avg     0.7494    0.6058    0.6555    163566
weighted avg     0.8147    0.8278    0.8111    163566

F1-macro tok:  0.6554886637046077
F1-micro tok:  0.8278370810559652
**************************************************
dev_cost_sum: 47992.97119140625
dev_cost_avg: 43.59034622289396
dev_count_sent: 1101.0
dev_total_correct_sent: 658.0
dev_accuracy_sent: 0.59763851044505
dev_count_tok: 21274.0
dev_total_correct_tok: 18209.0
dev_accuracy_tok: 0.8559274231456238
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.645933014354067
dev_label=N_recall_sent: 0.6308411214953271
dev_label=N_f-score_sent: 0.6382978723404256
dev_label=P_precision_sent: 0.5682819383259912
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.688
dev_precision_macro_sent: 0.5714049842266861
dev_recall_macro_sent: 0.5022765184480077
dev_f-score_macro_sent: 0.4449852936661447
dev_precision_micro_sent: 0.59763851044505
dev_recall_micro_sent: 0.59763851044505
dev_f-score_micro_sent: 0.59763851044505
dev_label=O_precision_tok: 0.8725054809151723
dev_label=O_recall_tok: 0.957790805307004
dev_label=O_f-score_tok: 0.9131611460846032
dev_label=N_precision_tok: 0.7460176991150442
dev_label=N_recall_tok: 0.45395799676898224
dev_label=N_f-score_tok: 0.5644459323736191
dev_label=P_precision_tok: 0.7834394904458599
dev_label=P_recall_tok: 0.5744084682440846
dev_label=P_f-score_tok: 0.6628345608047422
dev_precision_macro_tok: 0.8006542234920255
dev_recall_macro_tok: 0.6620524234400237
dev_f-score_macro_tok: 0.7134805464209881
dev_precision_micro_tok: 0.8559274231456238
dev_recall_micro_tok: 0.8559274231456238
dev_f-score_micro_tok: 0.8559274231456238
dev_time: 7.74290657043457
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6459    0.6308    0.6383       428
           P     0.5683    0.8716    0.6880       444

   micro avg     0.5976    0.5976    0.5976      1101
   macro avg     0.5714    0.5023    0.4450      1101
weighted avg     0.5843    0.5976    0.5274      1101

F1-macro sent:  0.4449852936661447
F1-micro sent:  0.59763851044505
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8725    0.9578    0.9132     16205
           N     0.7460    0.4540    0.5644      1857
           P     0.7834    0.5744    0.6628      3212

   micro avg     0.8559    0.8559    0.8559     21274
   macro avg     0.8007    0.6621    0.7135     21274
weighted avg     0.8480    0.8559    0.8449     21274

F1-macro tok:  0.7134805464209881
F1-micro tok:  0.8559274231456238
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 360815.36755371094
train_cost_avg: 42.230263056380025
train_count_sent: 8544.0
train_total_correct_sent: 5097.0
train_accuracy_sent: 0.5965589887640449
train_count_tok: 163566.0
train_total_correct_tok: 137768.0
train_accuracy_tok: 0.8422777349815976
train_label=O_precision_sent: 0.23076923076923078
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007272727272727273
train_label=N_precision_sent: 0.5713947430736444
train_label=N_recall_sent: 0.7290030211480363
train_label=N_f-score_sent: 0.6406478162750565
train_label=P_precision_sent: 0.6235157159487776
train_label=P_recall_sent: 0.7418282548476455
train_label=P_f-score_sent: 0.6775458570524985
train_precision_macro_sent: 0.4752265632638843
train_recall_macro_sent: 0.49150861909215665
train_f-score_macro_sent: 0.4418221335334274
train_precision_micro_sent: 0.5965589887640449
train_recall_micro_sent: 0.5965589887640449
train_f-score_micro_sent: 0.5965589887640449
train_label=O_precision_tok: 0.8612540029850314
train_label=O_recall_tok: 0.9559699872132018
train_label=O_f-score_tok: 0.9061436373961863
train_label=N_precision_tok: 0.6977092699636053
train_label=N_recall_tok: 0.45894944374031826
train_label=N_f-score_tok: 0.553686714237173
train_label=P_precision_tok: 0.7639797555857302
train_label=P_recall_tok: 0.49478354718791223
train_label=P_f-score_tok: 0.6005968121497367
train_precision_macro_tok: 0.774314342844789
train_recall_macro_tok: 0.6365676593804774
train_f-score_macro_tok: 0.6868090545943654
train_precision_micro_tok: 0.8422777349815976
train_recall_micro_tok: 0.8422777349815976
train_f-score_micro_tok: 0.8422777349815976
train_time: 141.67108011245728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2308    0.0037    0.0073      1624
           N     0.5714    0.7290    0.6406      3310
           P     0.6235    0.7418    0.6775      3610

   micro avg     0.5966    0.5966    0.5966      8544
   macro avg     0.4752    0.4915    0.4418      8544
weighted avg     0.5287    0.5966    0.5358      8544

F1-macro sent:  0.4418221335334274
F1-micro sent:  0.5965589887640449
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8613    0.9560    0.9061    124347
           N     0.6977    0.4589    0.5537     14202
           P     0.7640    0.4948    0.6006     25017

   micro avg     0.8423    0.8423    0.8423    163566
   macro avg     0.7743    0.6366    0.6868    163566
weighted avg     0.8322    0.8423    0.8288    163566

F1-macro tok:  0.6868090545943654
F1-micro tok:  0.8422777349815976
**************************************************
dev_cost_sum: 47247.72082519531
dev_cost_avg: 42.91346123995941
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18425.0
dev_accuracy_tok: 0.8660806618407446
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.6068222621184919
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.6862944162436548
dev_label=P_precision_sent: 0.6439114391143912
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7079107505070994
dev_precision_macro_sent: 0.583577900410961
dev_recall_macro_sent: 0.5267074914771115
dev_f-score_macro_sent: 0.4676210584695877
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8752648600423776
dev_label=O_recall_tok: 0.9686516507250849
dev_label=O_f-score_tok: 0.9195934268724918
dev_label=N_precision_tok: 0.7568692756036636
dev_label=N_recall_tok: 0.4894991922455573
dev_label=N_f-score_tok: 0.5945062132112492
dev_label=P_precision_tok: 0.8503973819541842
dev_label=P_recall_tok: 0.5663138231631383
dev_label=P_f-score_tok: 0.6798729209493553
dev_precision_macro_tok: 0.8275105058667419
dev_recall_macro_tok: 0.6748215553779269
dev_f-score_macro_tok: 0.731324187011032
dev_precision_micro_tok: 0.8660806618407446
dev_recall_micro_tok: 0.8660806618407446
dev_f-score_micro_tok: 0.8660806618407446
dev_time: 7.622982025146484
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6068    0.7897    0.6863       428
           P     0.6439    0.7860    0.7079       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.5836    0.5267    0.4676      1101
weighted avg     0.5996    0.6249    0.5541      1101

F1-macro sent:  0.4676210584695877
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8753    0.9687    0.9196     16205
           N     0.7569    0.4895    0.5945      1857
           P     0.8504    0.5663    0.6799      3212

   micro avg     0.8661    0.8661    0.8661     21274
   macro avg     0.8275    0.6748    0.7313     21274
weighted avg     0.8612    0.8661    0.8550     21274

F1-macro tok:  0.731324187011032
F1-micro tok:  0.8660806618407446
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 354850.82177734375
train_cost_avg: 41.53216547019473
train_count_sent: 8544.0
train_total_correct_sent: 5271.0
train_accuracy_sent: 0.6169241573033708
train_count_tok: 163566.0
train_total_correct_tok: 139226.0
train_accuracy_tok: 0.8511915679297654
train_label=O_precision_sent: 0.32857142857142857
train_label=O_recall_sent: 0.01416256157635468
train_label=O_f-score_sent: 0.02715466351829988
train_label=N_precision_sent: 0.5882766705744431
train_label=N_recall_sent: 0.7580060422960725
train_label=N_f-score_sent: 0.6624422442244224
train_label=P_precision_sent: 0.6507483962936564
train_label=P_recall_sent: 0.7587257617728532
train_label=P_f-score_sent: 0.7006010998848958
train_precision_macro_sent: 0.5225321651465094
train_recall_macro_sent: 0.51029812188176
train_f-score_macro_sent: 0.46339933587587273
train_precision_micro_sent: 0.6169241573033708
train_recall_micro_sent: 0.6169241573033708
train_f-score_micro_sent: 0.6169241573033708
train_label=O_precision_tok: 0.868321389034551
train_label=O_recall_tok: 0.9588007752499055
train_label=O_f-score_tok: 0.9113208051947059
train_label=N_precision_tok: 0.7073625349487418
train_label=N_recall_tok: 0.48098859315589354
train_label=N_f-score_tok: 0.5726141078838174
train_label=P_precision_tok: 0.7931948208370972
train_label=P_recall_tok: 0.5264819922452733
train_label=P_f-score_tok: 0.632886454278987
train_precision_macro_tok: 0.7896262482734633
train_recall_macro_tok: 0.6554237868836907
train_f-score_macro_tok: 0.7056071224525035
train_precision_micro_tok: 0.8511915679297654
train_recall_micro_tok: 0.8511915679297654
train_f-score_micro_tok: 0.8511915679297654
train_time: 143.1238236427307
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3286    0.0142    0.0272      1624
           N     0.5883    0.7580    0.6624      3310
           P     0.6507    0.7587    0.7006      3610

   micro avg     0.6169    0.6169    0.6169      8544
   macro avg     0.5225    0.5103    0.4634      8544
weighted avg     0.5653    0.6169    0.5578      8544

F1-macro sent:  0.46339933587587273
F1-micro sent:  0.6169241573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8683    0.9588    0.9113    124347
           N     0.7074    0.4810    0.5726     14202
           P     0.7932    0.5265    0.6329     25017

   micro avg     0.8512    0.8512    0.8512    163566
   macro avg     0.7896    0.6554    0.7056    163566
weighted avg     0.8429    0.8512    0.8393    163566

F1-macro tok:  0.7056071224525035
F1-micro tok:  0.8511915679297654
**************************************************
dev_cost_sum: 46612.75061035156
dev_cost_avg: 42.336739882244835
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18498.0
dev_accuracy_tok: 0.8695120804738178
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.636734693877551
dev_label=N_recall_sent: 0.7289719626168224
dev_label=N_f-score_sent: 0.6797385620915032
dev_label=P_precision_sent: 0.613747954173486
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7109004739336492
dev_precision_macro_sent: 0.4168275493503457
dev_recall_macro_sent: 0.524522185737139
dev_f-score_macro_sent: 0.46354634534171746
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8785166955646289
dev_label=O_recall_tok: 0.9692687442147485
dev_label=O_f-score_tok: 0.9216641239291163
dev_label=N_precision_tok: 0.7577235772357723
dev_label=N_recall_tok: 0.501884760366182
dev_label=N_f-score_tok: 0.6038224813735017
dev_label=P_precision_tok: 0.8586605080831409
dev_label=P_recall_tok: 0.5787671232876712
dev_label=P_f-score_tok: 0.6914636414357448
dev_precision_macro_tok: 0.8316335936278474
dev_recall_macro_tok: 0.6833068759562005
dev_f-score_macro_tok: 0.7389834155794542
dev_precision_micro_tok: 0.8695120804738178
dev_recall_micro_tok: 0.8695120804738178
dev_f-score_micro_tok: 0.8695120804738177
dev_time: 7.24020528793335
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6367    0.7290    0.6797       428
           P     0.6137    0.8446    0.7109       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4168    0.5245    0.4635      1101
weighted avg     0.4950    0.6240    0.5509      1101

F1-macro sent:  0.46354634534171746
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8785    0.9693    0.9217     16205
           N     0.7577    0.5019    0.6038      1857
           P     0.8587    0.5788    0.6915      3212

   micro avg     0.8695    0.8695    0.8695     21274
   macro avg     0.8316    0.6833    0.7390     21274
weighted avg     0.8650    0.8695    0.8592     21274

F1-macro tok:  0.7389834155794542
F1-micro tok:  0.8695120804738177
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350566.146484375
train_cost_avg: 41.0306819387143
train_count_sent: 8544.0
train_total_correct_sent: 5299.0
train_accuracy_sent: 0.6202013108614233
train_count_tok: 163566.0
train_total_correct_tok: 140166.0
train_accuracy_tok: 0.8569384835479256
train_label=O_precision_sent: 0.4603174603174603
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.03438055720213397
train_label=N_precision_sent: 0.5863970588235294
train_label=N_recall_sent: 0.7709969788519637
train_label=N_f-score_sent: 0.6661446097624641
train_label=P_precision_sent: 0.658270767740373
train_label=P_recall_sent: 0.7529085872576178
train_label=P_f-score_sent: 0.7024163328595426
train_precision_macro_sent: 0.5683284289604542
train_recall_macro_sent: 0.5139209029889081
train_f-score_macro_sent: 0.4676471666080469
train_precision_micro_sent: 0.6202013108614233
train_recall_micro_sent: 0.6202013108614233
train_f-score_micro_sent: 0.6202013108614233
train_label=O_precision_tok: 0.8728862462655496
train_label=O_recall_tok: 0.9610123284035803
train_label=O_f-score_tok: 0.9148318838804508
train_label=N_precision_tok: 0.7214048901782014
train_label=N_recall_tok: 0.49028305872412337
train_label=N_f-score_tok: 0.5838014588748219
train_label=P_precision_tok: 0.805501675189561
train_label=P_recall_tok: 0.5477875044969421
train_label=P_f-score_tok: 0.6521056388294075
train_precision_macro_tok: 0.7999309372111041
train_recall_macro_tok: 0.6663609638748819
train_f-score_macro_tok: 0.71691299386156
train_precision_micro_tok: 0.8569384835479256
train_recall_micro_tok: 0.8569384835479256
train_f-score_micro_tok: 0.8569384835479256
train_time: 140.50739908218384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4603    0.0179    0.0344      1624
           N     0.5864    0.7710    0.6661      3310
           P     0.6583    0.7529    0.7024      3610

   micro avg     0.6202    0.6202    0.6202      8544
   macro avg     0.5683    0.5139    0.4676      8544
weighted avg     0.5928    0.6202    0.5614      8544

F1-macro sent:  0.4676471666080469
F1-micro sent:  0.6202013108614233
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8729    0.9610    0.9148    124347
           N     0.7214    0.4903    0.5838     14202
           P     0.8055    0.5478    0.6521     25017

   micro avg     0.8569    0.8569    0.8569    163566
   macro avg     0.7999    0.6664    0.7169    163566
weighted avg     0.8494    0.8569    0.8459    163566

F1-macro tok:  0.71691299386156
F1-micro tok:  0.8569384835479256
**************************************************
dev_cost_sum: 46184.271484375
dev_cost_avg: 41.947567197434154
dev_count_sent: 1101.0
dev_total_correct_sent: 695.0
dev_accuracy_sent: 0.631244323342416
dev_count_tok: 21274.0
dev_total_correct_tok: 18620.0
dev_accuracy_tok: 0.875246780107173
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6182795698924731
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.6997971602434077
dev_label=P_precision_sent: 0.6445672191528545
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7092198581560285
dev_precision_macro_sent: 0.4209489296817759
dev_recall_macro_sent: 0.5314543515478095
dev_f-score_macro_sent: 0.46967233946647874
dev_precision_micro_sent: 0.631244323342416
dev_recall_micro_sent: 0.631244323342416
dev_f-score_micro_sent: 0.631244323342416
dev_label=O_precision_tok: 0.8798641652285253
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.925134628892531
dev_label=N_precision_tok: 0.7998303647158609
dev_label=N_recall_tok: 0.5078082929456113
dev_label=N_f-score_tok: 0.6212121212121212
dev_label=P_precision_tok: 0.8780487804878049
dev_label=P_recall_tok: 0.5828144458281445
dev_label=P_f-score_tok: 0.7005988023952096
dev_precision_macro_tok: 0.852581103477397
dev_recall_macro_tok: 0.6886463330624029
dev_f-score_macro_tok: 0.7489818508332872
dev_precision_micro_tok: 0.875246780107173
dev_recall_micro_tok: 0.875246780107173
dev_f-score_micro_tok: 0.875246780107173
dev_time: 7.311147928237915
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6183    0.8061    0.6998       428
           P     0.6446    0.7883    0.7092       444

   micro avg     0.6312    0.6312    0.6312      1101
   macro avg     0.4209    0.5315    0.4697      1101
weighted avg     0.5003    0.6312    0.5580      1101

F1-macro sent:  0.46967233946647874
F1-micro sent:  0.631244323342416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8799    0.9753    0.9251     16205
           N     0.7998    0.5078    0.6212      1857
           P     0.8780    0.5828    0.7006      3212

   micro avg     0.8752    0.8752    0.8752     21274
   macro avg     0.8526    0.6886    0.7490     21274
weighted avg     0.8726    0.8752    0.8647     21274

F1-macro tok:  0.7489818508332872
F1-micro tok:  0.875246780107173
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346361.58807373047
train_cost_avg: 40.53857538316134
train_count_sent: 8544.0
train_total_correct_sent: 5360.0
train_accuracy_sent: 0.6273408239700374
train_count_tok: 163566.0
train_total_correct_tok: 141049.0
train_accuracy_tok: 0.8623369159849846
train_label=O_precision_sent: 0.4603174603174603
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.03438055720213397
train_label=N_precision_sent: 0.593251253989968
train_label=N_recall_sent: 0.7861027190332326
train_label=N_f-score_sent: 0.6761954261954262
train_label=P_precision_sent: 0.6664224664224664
train_label=P_recall_sent: 0.7559556786703601
train_label=P_f-score_sent: 0.7083711875405581
train_precision_macro_sent: 0.5733303935766316
train_recall_macro_sent: 0.5199718468535784
train_f-score_macro_sent: 0.472982390312706
train_precision_micro_sent: 0.6273408239700374
train_recall_micro_sent: 0.6273408239700374
train_f-score_micro_sent: 0.6273408239700374
train_label=O_precision_tok: 0.8771938824115668
train_label=O_recall_tok: 0.9626368147200978
train_label=O_f-score_tok: 0.9179313359355229
train_label=N_precision_tok: 0.7343
train_label=N_recall_tok: 0.5170398535417546
train_label=N_f-score_tok: 0.6068093545987934
train_label=P_precision_tok: 0.8186707195884726
train_label=P_recall_tok: 0.5598193228604549
train_label=P_f-score_tok: 0.6649416009875606
train_precision_macro_tok: 0.8100548673333465
train_recall_macro_tok: 0.6798319970407691
train_f-score_macro_tok: 0.729894097173959
train_precision_micro_tok: 0.8623369159849846
train_recall_micro_tok: 0.8623369159849846
train_f-score_micro_tok: 0.8623369159849846
train_time: 141.72202682495117
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4603    0.0179    0.0344      1624
           N     0.5933    0.7861    0.6762      3310
           P     0.6664    0.7560    0.7084      3610

   micro avg     0.6273    0.6273    0.6273      8544
   macro avg     0.5733    0.5200    0.4730      8544
weighted avg     0.5989    0.6273    0.5678      8544

F1-macro sent:  0.472982390312706
F1-micro sent:  0.6273408239700374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8772    0.9626    0.9179    124347
           N     0.7343    0.5170    0.6068     14202
           P     0.8187    0.5598    0.6649     25017

   micro avg     0.8623    0.8623    0.8623    163566
   macro avg     0.8101    0.6798    0.7299    163566
weighted avg     0.8558    0.8623    0.8522    163566

F1-macro tok:  0.729894097173959
F1-micro tok:  0.8623369159849846
**************************************************
dev_cost_sum: 45942.39172363281
dev_cost_avg: 41.72787622491627
dev_count_sent: 1101.0
dev_total_correct_sent: 668.0
dev_accuracy_sent: 0.6067211625794732
dev_count_tok: 21274.0
dev_total_correct_tok: 18663.0
dev_accuracy_tok: 0.8772680266992573
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6943699731903485
dev_label=N_recall_sent: 0.6051401869158879
dev_label=N_f-score_sent: 0.6466916354556804
dev_label=P_precision_sent: 0.56
dev_label=P_recall_sent: 0.9144144144144144
dev_label=P_f-score_sent: 0.6946107784431137
dev_precision_macro_sent: 0.7514566577301162
dev_recall_macro_sent: 0.5108850126705083
dev_f-score_macro_sent: 0.4557214942881038
dev_precision_micro_sent: 0.6067211625794732
dev_recall_micro_sent: 0.6067211625794732
dev_f-score_micro_sent: 0.6067211625794732
dev_label=O_precision_tok: 0.8800533096401599
dev_label=O_recall_tok: 0.9779697624190065
dev_label=O_f-score_tok: 0.9264314734165375
dev_label=N_precision_tok: 0.8472906403940886
dev_label=N_recall_tok: 0.4631125471190092
dev_label=N_f-score_tok: 0.5988857938718662
dev_label=P_precision_tok: 0.8685028876055086
dev_label=P_recall_tok: 0.6086550435865504
dev_label=P_f-score_tok: 0.7157239611934835
dev_precision_macro_tok: 0.8652822792132523
dev_recall_macro_tok: 0.6832457843748553
dev_f-score_macro_tok: 0.7470137428272957
dev_precision_micro_tok: 0.8772680266992573
dev_recall_micro_tok: 0.8772680266992573
dev_f-score_micro_tok: 0.8772680266992573
dev_time: 7.316157341003418
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6944    0.6051    0.6467       428
           P     0.5600    0.9144    0.6946       444

   micro avg     0.6067    0.6067    0.6067      1101
   macro avg     0.7515    0.5109    0.4557      1101
weighted avg     0.7038    0.6067    0.5369      1101

F1-macro sent:  0.4557214942881038
F1-micro sent:  0.6067211625794732
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8801    0.9780    0.9264     16205
           N     0.8473    0.4631    0.5989      1857
           P     0.8685    0.6087    0.7157      3212

   micro avg     0.8773    0.8773    0.8773     21274
   macro avg     0.8653    0.6832    0.7470     21274
weighted avg     0.8754    0.8773    0.8660     21274

F1-macro tok:  0.7470137428272957
F1-micro tok:  0.8772680266992573
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342542.6770629883
train_cost_avg: 40.09160546149207
train_count_sent: 8544.0
train_total_correct_sent: 5359.0
train_accuracy_sent: 0.6272237827715356
train_count_tok: 163566.0
train_total_correct_tok: 141663.0
train_accuracy_tok: 0.8660907523568467
train_label=O_precision_sent: 0.44776119402985076
train_label=O_recall_sent: 0.01847290640394089
train_label=O_f-score_sent: 0.03548196333530455
train_label=N_precision_sent: 0.5899954317039744
train_label=N_recall_sent: 0.7803625377643505
train_label=N_f-score_sent: 0.6719562955254943
train_label=P_precision_sent: 0.6699194925591607
train_label=P_recall_sent: 0.7606648199445983
train_label=P_f-score_sent: 0.7124140614865742
train_precision_macro_sent: 0.5692253727643286
train_recall_macro_sent: 0.5198334213709632
train_f-score_macro_sent: 0.47328410678245764
train_precision_micro_sent: 0.6272237827715356
train_recall_micro_sent: 0.6272237827715356
train_f-score_micro_sent: 0.6272237827715356
train_label=O_precision_tok: 0.8805937247409802
train_label=O_recall_tok: 0.9637546543141371
train_label=O_f-score_tok: 0.9202993430272964
train_label=N_precision_tok: 0.7378213464039212
train_label=N_recall_tok: 0.5193634699338121
train_label=N_f-score_tok: 0.6096119674366709
train_label=P_precision_tok: 0.8265346987813948
train_label=P_recall_tok: 0.5774873086301315
train_label=P_f-score_tok: 0.6799228162650602
train_precision_macro_tok: 0.8149832566420988
train_recall_macro_tok: 0.6868684776260269
train_f-score_macro_tok: 0.7366113755763425
train_precision_micro_tok: 0.8660907523568467
train_recall_micro_tok: 0.8660907523568467
train_f-score_micro_tok: 0.8660907523568468
train_time: 142.71693086624146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4478    0.0185    0.0355      1624
           N     0.5900    0.7804    0.6720      3310
           P     0.6699    0.7607    0.7124      3610

   micro avg     0.6272    0.6272    0.6272      8544
   macro avg     0.5692    0.5198    0.4733      8544
weighted avg     0.5967    0.6272    0.5681      8544

F1-macro sent:  0.47328410678245764
F1-micro sent:  0.6272237827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9638    0.9203    124347
           N     0.7378    0.5194    0.6096     14202
           P     0.8265    0.5775    0.6799     25017

   micro avg     0.8661    0.8661    0.8661    163566
   macro avg     0.8150    0.6869    0.7366    163566
weighted avg     0.8599    0.8661    0.8566    163566

F1-macro tok:  0.7366113755763425
F1-micro tok:  0.8660907523568468
**************************************************
dev_cost_sum: 45350.46057128906
dev_cost_avg: 41.19024575048961
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18799.0
dev_accuracy_tok: 0.8836608066184074
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.5748148148148148
dev_label=N_recall_sent: 0.9065420560747663
dev_label=N_f-score_sent: 0.7035358114233907
dev_label=P_precision_sent: 0.7387173396674585
dev_label=P_recall_sent: 0.7004504504504504
dev_label=P_f-score_sent: 0.7190751445086706
dev_precision_macro_sent: 0.7045107181607578
dev_recall_macro_sent: 0.5414865851445047
dev_f-score_macro_sent: 0.4855996633733652
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8946050534941953
dev_label=O_recall_tok: 0.9700709657513114
dev_label=O_f-score_tok: 0.9308109068300915
dev_label=N_precision_tok: 0.7287689269256089
dev_label=N_recall_tok: 0.5961227786752827
dev_label=N_f-score_tok: 0.6558056872037915
dev_label=P_precision_tok: 0.9033440219880898
dev_label=P_recall_tok: 0.613947696139477
dev_label=P_f-score_tok: 0.7310472659870251
dev_precision_macro_tok: 0.8422393341359647
dev_recall_macro_tok: 0.7267138135220237
dev_f-score_macro_tok: 0.7725546200069694
dev_precision_micro_tok: 0.8836608066184074
dev_recall_micro_tok: 0.8836608066184074
dev_f-score_micro_tok: 0.8836608066184074
dev_time: 7.068072557449341
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.5748    0.9065    0.7035       428
           P     0.7387    0.7005    0.7191       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.7045    0.5415    0.4856      1101
weighted avg     0.6877    0.6385    0.5706      1101

F1-macro sent:  0.4855996633733652
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8946    0.9701    0.9308     16205
           N     0.7288    0.5961    0.6558      1857
           P     0.9033    0.6139    0.7310      3212

   micro avg     0.8837    0.8837    0.8837     21274
   macro avg     0.8422    0.7267    0.7726     21274
weighted avg     0.8814    0.8837    0.8766     21274

F1-macro tok:  0.7725546200069694
F1-micro tok:  0.8836608066184074
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339140.6779785156
train_cost_avg: 39.69343141134312
train_count_sent: 8544.0
train_total_correct_sent: 5366.0
train_accuracy_sent: 0.6280430711610487
train_count_tok: 163566.0
train_total_correct_tok: 142257.0
train_accuracy_tok: 0.8697223139283226
train_label=O_precision_sent: 0.423728813559322
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.0574052812858783
train_label=N_precision_sent: 0.5933503836317136
train_label=N_recall_sent: 0.7709969788519637
train_label=N_f-score_sent: 0.6706083300486139
train_label=P_precision_sent: 0.670060606060606
train_label=P_recall_sent: 0.7656509695290858
train_label=P_f-score_sent: 0.7146735617323853
train_precision_macro_sent: 0.5623799344172139
train_recall_macro_sent: 0.5224787085736503
train_f-score_macro_sent: 0.48089572435562583
train_precision_micro_sent: 0.6280430711610487
train_recall_micro_sent: 0.6280430711610487
train_f-score_micro_sent: 0.6280430711610487
train_label=O_precision_tok: 0.8835286669218764
train_label=O_recall_tok: 0.965162006321021
train_label=O_f-score_tok: 0.9225429793645242
train_label=N_precision_tok: 0.7429406037000974
train_label=N_recall_tok: 0.5372482748908605
train_label=N_f-score_tok: 0.6235697940503433
train_label=P_precision_tok: 0.8368843069873998
train_label=P_recall_tok: 0.5840828236798977
train_label=P_f-score_tok: 0.6879958565812087
train_precision_macro_tok: 0.8211178592031246
train_recall_macro_tok: 0.6954977016305931
train_f-score_macro_tok: 0.7447028766653587
train_precision_micro_tok: 0.8697223139283226
train_recall_micro_tok: 0.8697223139283226
train_f-score_micro_tok: 0.8697223139283226
train_time: 142.0446581840515
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4237    0.0308    0.0574      1624
           N     0.5934    0.7710    0.6706      3310
           P     0.6701    0.7657    0.7147      3610

   micro avg     0.6280    0.6280    0.6280      8544
   macro avg     0.5624    0.5225    0.4809      8544
weighted avg     0.5935    0.6280    0.5727      8544

F1-macro sent:  0.48089572435562583
F1-micro sent:  0.6280430711610487
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8835    0.9652    0.9225    124347
           N     0.7429    0.5372    0.6236     14202
           P     0.8369    0.5841    0.6880     25017

   micro avg     0.8697    0.8697    0.8697    163566
   macro avg     0.8211    0.6955    0.7447    163566
weighted avg     0.8642    0.8697    0.8607    163566

F1-macro tok:  0.7447028766653587
F1-micro tok:  0.8697223139283226
**************************************************
dev_cost_sum: 44962.117248535156
dev_cost_avg: 40.83752701955963
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18825.0
dev_accuracy_tok: 0.8848829557205979
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5811437403400309
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.6995348837209302
dev_label=P_precision_sent: 0.7133333333333334
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.7181208053691276
dev_precision_macro_sent: 0.6814923578911215
dev_recall_macro_sent: 0.5381926941837973
dev_f-score_macro_sent: 0.48113558735047707
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.8911203881304299
dev_label=O_recall_tok: 0.9747608762727553
dev_label=O_f-score_tok: 0.9310659868556778
dev_label=N_precision_tok: 0.7794226498889711
dev_label=N_recall_tok: 0.567043618739903
dev_label=N_f-score_tok: 0.6564837905236908
dev_label=P_precision_tok: 0.8994082840236687
dev_label=P_recall_tok: 0.6151930261519303
dev_label=P_f-score_tok: 0.7306341283046774
dev_precision_macro_tok: 0.8566504406810233
dev_recall_macro_tok: 0.7189991737215294
dev_f-score_macro_tok: 0.7727279685613486
dev_precision_micro_tok: 0.8848829557205979
dev_recall_micro_tok: 0.8848829557205979
dev_f-score_micro_tok: 0.8848829557205979
dev_time: 6.991266965866089
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5811    0.8785    0.6995       428
           P     0.7133    0.7230    0.7181       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.6815    0.5382    0.4811      1101
weighted avg     0.6696    0.6358    0.5669      1101

F1-macro sent:  0.48113558735047707
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8911    0.9748    0.9311     16205
           N     0.7794    0.5670    0.6565      1857
           P     0.8994    0.6152    0.7306      3212

   micro avg     0.8849    0.8849    0.8849     21274
   macro avg     0.8567    0.7190    0.7727     21274
weighted avg     0.8826    0.8849    0.8768     21274

F1-macro tok:  0.7727279685613486
F1-micro tok:  0.8848829557205979
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 335828.07971191406
train_cost_avg: 39.305720940064845
train_count_sent: 8544.0
train_total_correct_sent: 5411.0
train_accuracy_sent: 0.6333099250936329
train_count_tok: 163566.0
train_total_correct_tok: 142798.0
train_accuracy_tok: 0.8730298472787743
train_label=O_precision_sent: 0.43089430894308944
train_label=O_recall_sent: 0.03263546798029557
train_label=O_f-score_sent: 0.06067544361763023
train_label=N_precision_sent: 0.5911639381027136
train_label=N_recall_sent: 0.7963746223564955
train_label=N_f-score_sent: 0.6785944136954564
train_label=P_precision_sent: 0.6870267541645634
train_label=P_recall_sent: 0.754016620498615
train_label=P_f-score_sent: 0.7189646064447968
train_precision_macro_sent: 0.5696950004034554
train_recall_macro_sent: 0.5276755702784687
train_f-score_macro_sent: 0.4860781545859611
train_precision_micro_sent: 0.6333099250936329
train_recall_micro_sent: 0.6333099250936329
train_f-score_micro_sent: 0.6333099250936329
train_label=O_precision_tok: 0.8860612047801951
train_label=O_recall_tok: 0.9665532743049692
train_label=O_f-score_tok: 0.9245586368706489
train_label=N_precision_tok: 0.7501203195687747
train_label=N_recall_tok: 0.5487255316152655
train_label=N_f-score_tok: 0.6338091171566834
train_label=P_precision_tok: 0.8450439146800501
train_label=P_recall_tok: 0.5922772514690011
train_label=P_f-score_tok: 0.6964348663956195
train_precision_macro_tok: 0.8270751463430065
train_recall_macro_tok: 0.702518685796412
train_f-score_macro_tok: 0.7516008734743173
train_precision_micro_tok: 0.8730298472787743
train_recall_micro_tok: 0.8730298472787743
train_f-score_micro_tok: 0.8730298472787743
train_time: 143.20863556861877
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4309    0.0326    0.0607      1624
           N     0.5912    0.7964    0.6786      3310
           P     0.6870    0.7540    0.7190      3610

   micro avg     0.6333    0.6333    0.6333      8544
   macro avg     0.5697    0.5277    0.4861      8544
weighted avg     0.6012    0.6333    0.5782      8544

F1-macro sent:  0.4860781545859611
F1-micro sent:  0.6333099250936329
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8861    0.9666    0.9246    124347
           N     0.7501    0.5487    0.6338     14202
           P     0.8450    0.5923    0.6964     25017

   micro avg     0.8730    0.8730    0.8730    163566
   macro avg     0.8271    0.7025    0.7516    163566
weighted avg     0.8680    0.8730    0.8644    163566

F1-macro tok:  0.7516008734743173
F1-micro tok:  0.8730298472787743
**************************************************
dev_cost_sum: 44674.71875
dev_cost_avg: 40.5764929609446
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 18835.0
dev_accuracy_tok: 0.8853530130675943
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5775075987841946
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.699815837937385
dev_label=P_precision_sent: 0.7120181405895691
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7096045197740114
dev_precision_macro_sent: 0.7631752464579211
dev_recall_macro_sent: 0.5345970996503584
dev_f-score_macro_sent: 0.4755787916758045
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.8857508912655971
dev_label=O_recall_tok: 0.981240357914224
dev_label=O_f-score_tok: 0.9310536639634628
dev_label=N_precision_tok: 0.8260869565217391
dev_label=N_recall_tok: 0.5013462574044157
dev_label=N_f-score_tok: 0.6239946380697051
dev_label=P_precision_tok: 0.9125284738041002
dev_label=P_recall_tok: 0.6235990037359901
dev_label=P_f-score_tok: 0.7408914370260773
dev_precision_macro_tok: 0.8747887738638122
dev_recall_macro_tok: 0.7020618730182099
dev_f-score_macro_tok: 0.7653132463530818
dev_precision_micro_tok: 0.8853530130675943
dev_recall_micro_tok: 0.8853530130675943
dev_f-score_micro_tok: 0.8853530130675943
dev_time: 6.8846659660339355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5775    0.8879    0.6998       428
           P     0.7120    0.7072    0.7096       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.7632    0.5346    0.4756      1101
weighted avg     0.7196    0.6322    0.5618      1101

F1-macro sent:  0.4755787916758045
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8858    0.9812    0.9311     16205
           N     0.8261    0.5013    0.6240      1857
           P     0.9125    0.6236    0.7409      3212

   micro avg     0.8854    0.8854    0.8854     21274
   macro avg     0.8748    0.7021    0.7653     21274
weighted avg     0.8846    0.8854    0.8755     21274

F1-macro tok:  0.7653132463530818
F1-micro tok:  0.8853530130675943
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 332851.21545410156
train_cost_avg: 38.95730517955309
train_count_sent: 8544.0
train_total_correct_sent: 5487.0
train_accuracy_sent: 0.6422050561797753
train_count_tok: 163566.0
train_total_correct_tok: 143231.0
train_accuracy_tok: 0.8756770967071397
train_label=O_precision_sent: 0.42391304347826086
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.045454545454545456
train_label=N_precision_sent: 0.6113065916021581
train_label=N_recall_sent: 0.7873111782477341
train_label=N_f-score_sent: 0.6882345173643206
train_label=P_precision_sent: 0.6784435426116018
train_label=P_recall_sent: 0.7872576177285319
train_label=P_f-score_sent: 0.7288113860751377
train_precision_macro_sent: 0.5712210592306736
train_recall_macro_sent: 0.5328611914337964
train_f-score_macro_sent: 0.48750014963133453
train_precision_micro_sent: 0.6422050561797753
train_recall_micro_sent: 0.6422050561797753
train_f-score_micro_sent: 0.6422050561797753
train_label=O_precision_tok: 0.8881626563861686
train_label=O_recall_tok: 0.9671242571191907
train_label=O_f-score_tok: 0.9259631413402939
train_label=N_precision_tok: 0.7541952707856598
train_label=N_recall_tok: 0.5569638079143783
train_label=N_f-score_tok: 0.6407452409882545
train_label=P_precision_tok: 0.8521158633174927
train_label=P_recall_tok: 0.6020705919974417
train_label=P_f-score_tok: 0.7055957651137189
train_precision_macro_tok: 0.8314912634964404
train_recall_macro_tok: 0.7087195523436702
train_f-score_macro_tok: 0.7574347158140892
train_precision_micro_tok: 0.8756770967071397
train_recall_micro_tok: 0.8756770967071397
train_f-score_micro_tok: 0.8756770967071397
train_time: 142.7979612350464
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4239    0.0240    0.0455      1624
           N     0.6113    0.7873    0.6882      3310
           P     0.6784    0.7873    0.7288      3610

   micro avg     0.6422    0.6422    0.6422      8544
   macro avg     0.5712    0.5329    0.4875      8544
weighted avg     0.6041    0.6422    0.5832      8544

F1-macro sent:  0.48750014963133453
F1-micro sent:  0.6422050561797753
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8882    0.9671    0.9260    124347
           N     0.7542    0.5570    0.6407     14202
           P     0.8521    0.6021    0.7056     25017

   micro avg     0.8757    0.8757    0.8757    163566
   macro avg     0.8315    0.7087    0.7574    163566
weighted avg     0.8710    0.8757    0.8675    163566

F1-macro tok:  0.7574347158140892
F1-micro tok:  0.8756770967071397
**************************************************
dev_cost_sum: 44304.64440917969
dev_cost_avg: 40.24036731078991
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18897.0
dev_accuracy_tok: 0.8882673686189715
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6190476190476191
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7055276381909548
dev_label=P_precision_sent: 0.6629001883239172
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.722051282051282
dev_precision_macro_sent: 0.7606492691238455
dev_recall_macro_sent: 0.5419955624726469
dev_f-score_macro_sent: 0.484480329735918
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8978043912175648
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.933195020746888
dev_label=N_precision_tok: 0.7746979388770433
dev_label=N_recall_tok: 0.5869682283252557
dev_label=N_f-score_tok: 0.667892156862745
dev_label=P_precision_tok: 0.8850771869639794
dev_label=P_recall_tok: 0.6425902864259029
dev_label=P_f-score_tok: 0.7445887445887446
dev_precision_macro_tok: 0.8525265056861958
dev_recall_macro_tok: 0.7336829318428988
dev_f-score_macro_tok: 0.7818919740661259
dev_precision_micro_tok: 0.8882673686189715
dev_recall_micro_tok: 0.8882673686189715
dev_f-score_micro_tok: 0.8882673686189715
dev_time: 7.358498573303223
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6190    0.8201    0.7055       428
           P     0.6629    0.7928    0.7221       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.7606    0.5420    0.4845      1101
weighted avg     0.7160    0.6412    0.5708      1101

F1-macro sent:  0.484480329735918
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8978    0.9715    0.9332     16205
           N     0.7747    0.5870    0.6679      1857
           P     0.8851    0.6426    0.7446      3212

   micro avg     0.8883    0.8883    0.8883     21274
   macro avg     0.8525    0.7337    0.7819     21274
weighted avg     0.8851    0.8883    0.8816     21274

F1-macro tok:  0.7818919740661259
F1-micro tok:  0.8882673686189715
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330298.43157958984
train_cost_avg: 38.65852429536398
train_count_sent: 8544.0
train_total_correct_sent: 5511.0
train_accuracy_sent: 0.6450140449438202
train_count_tok: 163566.0
train_total_correct_tok: 143694.0
train_accuracy_tok: 0.8785077583360845
train_label=O_precision_sent: 0.46875
train_label=O_recall_sent: 0.03694581280788178
train_label=O_f-score_sent: 0.06849315068493152
train_label=N_precision_sent: 0.6118604651162791
train_label=N_recall_sent: 0.7948640483383685
train_label=N_f-score_sent: 0.6914586070959263
train_label=P_precision_sent: 0.685131195335277
train_label=P_recall_sent: 0.7811634349030471
train_label=P_f-score_sent: 0.7300025886616619
train_precision_macro_sent: 0.5885805534838521
train_recall_macro_sent: 0.5376577653497657
train_f-score_macro_sent: 0.4966514488141733
train_precision_micro_sent: 0.6450140449438202
train_recall_micro_sent: 0.6450140449438202
train_f-score_micro_sent: 0.6450140449438202
train_label=O_precision_tok: 0.8900242338268759
train_label=O_recall_tok: 0.968764827458644
train_label=O_f-score_tok: 0.9277267563873005
train_label=N_precision_tok: 0.7627473363774734
train_label=N_recall_tok: 0.5645683706520208
train_label=N_f-score_tok: 0.648862992635753
train_label=P_precision_tok: 0.8592002710945442
train_label=P_recall_tok: 0.6081064875884399
train_label=P_f-score_tok: 0.7121690892493504
train_precision_macro_tok: 0.8373239470996312
train_recall_macro_tok: 0.7138132285663682
train_f-score_macro_tok: 0.762919612757468
train_precision_micro_tok: 0.8785077583360845
train_recall_micro_tok: 0.8785077583360845
train_f-score_micro_tok: 0.8785077583360845
train_time: 141.85352730751038
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4688    0.0369    0.0685      1624
           N     0.6119    0.7949    0.6915      3310
           P     0.6851    0.7812    0.7300      3610

   micro avg     0.6450    0.6450    0.6450      8544
   macro avg     0.5886    0.5377    0.4967      8544
weighted avg     0.6156    0.6450    0.5893      8544

F1-macro sent:  0.4966514488141733
F1-micro sent:  0.6450140449438202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8900    0.9688    0.9277    124347
           N     0.7627    0.5646    0.6489     14202
           P     0.8592    0.6081    0.7122     25017

   micro avg     0.8785    0.8785    0.8785    163566
   macro avg     0.8373    0.7138    0.7629    163566
weighted avg     0.8743    0.8785    0.8705    163566

F1-macro tok:  0.762919612757468
F1-micro tok:  0.8785077583360845
**************************************************
dev_cost_sum: 44072.470703125
dev_cost_avg: 40.02949201010445
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18919.0
dev_accuracy_tok: 0.8893014947823634
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6666666666666666
dev_label=N_recall_sent: 0.7289719626168224
dev_label=N_f-score_sent: 0.6964285714285714
dev_label=P_precision_sent: 0.6158730158730159
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7225325884543761
dev_precision_macro_sent: 0.7608465608465608
dev_recall_macro_sent: 0.538648757723973
dev_f-score_macro_sent: 0.4816077429494882
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8923570102918846
dev_label=O_recall_tok: 0.9791422400493675
dev_label=O_f-score_tok: 0.9337374212911198
dev_label=N_precision_tok: 0.8029253271747498
dev_label=N_recall_tok: 0.5616585891222402
dev_label=N_f-score_tok: 0.6609632446134348
dev_label=P_precision_tok: 0.9156791248860529
dev_label=P_recall_tok: 0.6254669987546699
dev_label=P_f-score_tok: 0.7432482426933036
dev_precision_macro_tok: 0.8703204874508957
dev_recall_macro_tok: 0.7220892759754259
dev_f-score_macro_tok: 0.7793163028659528
dev_precision_micro_tok: 0.8893014947823634
dev_recall_micro_tok: 0.8893014947823634
dev_f-score_micro_tok: 0.8893014947823634
dev_time: 7.478957891464233
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6667    0.7290    0.6964       428
           P     0.6159    0.8739    0.7225       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.7608    0.5386    0.4816      1101
weighted avg     0.7155    0.6385    0.5675      1101

F1-macro sent:  0.4816077429494882
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8924    0.9791    0.9337     16205
           N     0.8029    0.5617    0.6610      1857
           P     0.9157    0.6255    0.7432      3212

   micro avg     0.8893    0.8893    0.8893     21274
   macro avg     0.8703    0.7221    0.7793     21274
weighted avg     0.8881    0.8893    0.8812     21274

F1-macro tok:  0.7793163028659528
F1-micro tok:  0.8893014947823634
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328000.9473876953
train_cost_avg: 38.38962399200554
train_count_sent: 8544.0
train_total_correct_sent: 5523.0
train_accuracy_sent: 0.6464185393258427
train_count_tok: 163566.0
train_total_correct_tok: 143945.0
train_accuracy_tok: 0.8800423070809337
train_label=O_precision_sent: 0.47474747474747475
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.054556006964596636
train_label=N_precision_sent: 0.6312807881773399
train_label=N_recall_sent: 0.7743202416918429
train_label=N_f-score_sent: 0.6955223880597016
train_label=P_precision_sent: 0.6643101482326111
train_label=P_recall_sent: 0.8069252077562327
train_label=P_f-score_sent: 0.7287054409005629
train_precision_macro_sent: 0.5901128037191419
train_recall_macro_sent: 0.5367287787158609
train_f-score_macro_sent: 0.49292794530828704
train_precision_micro_sent: 0.6464185393258427
train_recall_micro_sent: 0.6464185393258427
train_f-score_micro_sent: 0.6464185393258427
train_label=O_precision_tok: 0.8916240480190655
train_label=O_recall_tok: 0.9688211215389193
train_label=O_f-score_tok: 0.9286209820396206
train_label=N_precision_tok: 0.7630838491840181
train_label=N_recall_tok: 0.5728770595690748
train_label=N_f-score_tok: 0.6544401544401545
train_label=P_precision_tok: 0.862177505480299
train_label=P_recall_tok: 0.6131430627173522
train_label=P_f-score_tok: 0.716641749205756
train_precision_macro_tok: 0.8389618008944608
train_recall_macro_tok: 0.7182804146084488
train_f-score_macro_tok: 0.7665676285618437
train_precision_micro_tok: 0.8800423070809337
train_recall_micro_tok: 0.8800423070809337
train_f-score_micro_tok: 0.8800423070809337
train_time: 142.88081192970276
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4747    0.0289    0.0546      1624
           N     0.6313    0.7743    0.6955      3310
           P     0.6643    0.8069    0.7287      3610

   micro avg     0.6464    0.6464    0.6464      8544
   macro avg     0.5901    0.5367    0.4929      8544
weighted avg     0.6155    0.6464    0.5877      8544

F1-macro sent:  0.49292794530828704
F1-micro sent:  0.6464185393258427
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8916    0.9688    0.9286    124347
           N     0.7631    0.5729    0.6544     14202
           P     0.8622    0.6131    0.7166     25017

   micro avg     0.8800    0.8800    0.8800    163566
   macro avg     0.8390    0.7183    0.7666    163566
weighted avg     0.8760    0.8800    0.8724    163566

F1-macro tok:  0.7665676285618437
F1-micro tok:  0.8800423070809337
**************************************************
dev_cost_sum: 43796.714782714844
dev_cost_avg: 39.779032500195136
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 18961.0
dev_accuracy_tok: 0.891275735639748
dev_label=O_precision_sent: 0.6551724137931034
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14728682170542637
dev_label=N_precision_sent: 0.6237113402061856
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7188118811881187
dev_label=P_precision_sent: 0.6938775510204082
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7280513918629549
dev_precision_macro_sent: 0.6575871016732324
dev_recall_macro_sent: 0.5656220130672238
dev_f-score_macro_sent: 0.5313833649188333
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.8945321307779031
dev_label=O_recall_tok: 0.9792656587473002
dev_label=O_f-score_tok: 0.9349830608337016
dev_label=N_precision_tok: 0.8255144032921811
dev_label=N_recall_tok: 0.5401184706515886
dev_label=N_f-score_tok: 0.6529947916666667
dev_label=P_precision_tok: 0.9008193186718413
dev_label=P_recall_tok: 0.650373599003736
dev_label=P_f-score_tok: 0.7553787741818839
dev_precision_macro_tok: 0.8736219509139751
dev_recall_macro_tok: 0.7232525761342083
dev_f-score_macro_tok: 0.7811188755607508
dev_precision_micro_tok: 0.891275735639748
dev_recall_micro_tok: 0.891275735639748
dev_f-score_micro_tok: 0.891275735639748
dev_time: 6.702981472015381
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6552    0.0830    0.1473       229
           N     0.6237    0.8481    0.7188       428
           P     0.6939    0.7658    0.7281       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6576    0.5656    0.5314      1101
weighted avg     0.6586    0.6558    0.6037      1101

F1-macro sent:  0.5313833649188333
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8945    0.9793    0.9350     16205
           N     0.8255    0.5401    0.6530      1857
           P     0.9008    0.6504    0.7554      3212

   micro avg     0.8913    0.8913    0.8913     21274
   macro avg     0.8736    0.7233    0.7811     21274
weighted avg     0.8895    0.8913    0.8833     21274

F1-macro tok:  0.7811188755607508
F1-micro tok:  0.891275735639748
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325678.58416748047
train_cost_avg: 38.11781181735493
train_count_sent: 8544.0
train_total_correct_sent: 5599.0
train_accuracy_sent: 0.6553136704119851
train_count_tok: 163566.0
train_total_correct_tok: 144378.0
train_accuracy_tok: 0.882689556509299
train_label=O_precision_sent: 0.5344827586206896
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.07126436781609195
train_label=N_precision_sent: 0.6144469525959368
train_label=N_recall_sent: 0.8223564954682779
train_label=N_f-score_sent: 0.703359173126615
train_label=P_precision_sent: 0.7041020510255127
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7400105152471083
train_precision_macro_sent: 0.6176772540807131
train_recall_macro_sent: 0.5467707429071854
train_f-score_macro_sent: 0.5048780187299383
train_precision_micro_sent: 0.6553136704119851
train_recall_micro_sent: 0.6553136704119851
train_f-score_micro_sent: 0.6553136704119851
train_label=O_precision_tok: 0.8941634529813112
train_label=O_recall_tok: 0.9696172806742422
train_label=O_f-score_tok: 0.930363019750219
train_label=N_precision_tok: 0.7690383546414675
train_label=N_recall_tok: 0.5844951415293621
train_label=N_f-score_tok: 0.6641862698031686
train_label=P_precision_tok: 0.864822663395048
train_label=P_recall_tok: 0.6198984690410521
train_label=P_f-score_tok: 0.7221588395538895
train_precision_macro_tok: 0.8426748236726089
train_recall_macro_tok: 0.7246702970815523
train_f-score_macro_tok: 0.772236043035759
train_precision_micro_tok: 0.882689556509299
train_recall_micro_tok: 0.882689556509299
train_f-score_micro_tok: 0.882689556509299
train_time: 97.12583589553833
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5345    0.0382    0.0713      1624
           N     0.6144    0.8224    0.7034      3310
           P     0.7041    0.7798    0.7400      3610

   micro avg     0.6553    0.6553    0.6553      8544
   macro avg     0.6177    0.5468    0.5049      8544
weighted avg     0.6371    0.6553    0.5987      8544

F1-macro sent:  0.5048780187299383
F1-micro sent:  0.6553136704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8942    0.9696    0.9304    124347
           N     0.7690    0.5845    0.6642     14202
           P     0.8648    0.6199    0.7222     25017

   micro avg     0.8827    0.8827    0.8827    163566
   macro avg     0.8427    0.7247    0.7722    163566
weighted avg     0.8788    0.8827    0.8754    163566

F1-macro tok:  0.772236043035759
F1-micro tok:  0.882689556509299
**************************************************
dev_cost_sum: 43657.17578125
dev_cost_avg: 39.65229407924614
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 18980.0
dev_accuracy_tok: 0.8921688445990411
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042735042735042736
dev_label=N_precision_sent: 0.6500956022944551
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.7150368033648791
dev_label=P_precision_sent: 0.6492146596858639
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7315634218289087
dev_precision_macro_sent: 0.7664367539934397
dev_recall_macro_sent: 0.5513548074458984
dev_f-score_macro_sent: 0.4964450893096101
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8967665213205731
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9352704937396646
dev_label=N_precision_tok: 0.8176964149504196
dev_label=N_recall_tok: 0.5772751750134626
dev_label=N_f-score_tok: 0.6767676767676768
dev_label=P_precision_tok: 0.8993055555555556
dev_label=P_recall_tok: 0.6450809464508095
dev_label=P_f-score_tok: 0.751269035532995
dev_precision_macro_tok: 0.8712561639421827
dev_recall_macro_tok: 0.7331951238985607
dev_f-score_macro_tok: 0.7877690686801122
dev_precision_micro_tok: 0.8921688445990411
dev_recall_micro_tok: 0.8921688445990411
dev_f-score_micro_tok: 0.8921688445990411
dev_time: 4.941220760345459
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0218    0.0427       229
           N     0.6501    0.7944    0.7150       428
           P     0.6492    0.8378    0.7316       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.7664    0.5514    0.4964      1101
weighted avg     0.7225    0.6512    0.5819      1101

F1-macro sent:  0.4964450893096101
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8968    0.9772    0.9353     16205
           N     0.8177    0.5773    0.6768      1857
           P     0.8993    0.6451    0.7513      3212

   micro avg     0.8922    0.8922    0.8922     21274
   macro avg     0.8713    0.7332    0.7878     21274
weighted avg     0.8902    0.8922    0.8849     21274

F1-macro tok:  0.7877690686801122
F1-micro tok:  0.8921688445990411
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323326.4754638672
train_cost_avg: 37.84251819567734
train_count_sent: 8544.0
train_total_correct_sent: 5577.0
train_accuracy_sent: 0.6527387640449438
train_count_tok: 163566.0
train_total_correct_tok: 144689.0
train_accuracy_tok: 0.8845909296553074
train_label=O_precision_sent: 0.5257731958762887
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05926786751888438
train_label=N_precision_sent: 0.6205031742299554
train_label=N_recall_sent: 0.7972809667673716
train_label=N_f-score_sent: 0.6978712151262727
train_label=P_precision_sent: 0.6883643299952312
train_label=P_recall_sent: 0.7997229916897507
train_label=P_f-score_sent: 0.7398769861609431
train_precision_macro_sent: 0.6115469000338251
train_recall_macro_sent: 0.5428026331146073
train_f-score_macro_sent: 0.4990053562687001
train_precision_micro_sent: 0.6527387640449438
train_recall_micro_sent: 0.6527387640449438
train_f-score_micro_sent: 0.6527387640449438
train_label=O_precision_tok: 0.8956894887671314
train_label=O_recall_tok: 0.9702204315343353
train_label=O_f-score_tok: 0.9314664473963581
train_label=N_precision_tok: 0.775326721660951
train_label=N_recall_tok: 0.5890015490775947
train_label=N_f-score_tok: 0.6694409987595533
train_label=P_precision_tok: 0.8671127578388542
train_label=P_recall_tok: 0.6267737938202023
train_label=P_f-score_tok: 0.7276102088167052
train_precision_macro_tok: 0.8460429894223122
train_recall_macro_tok: 0.7286652581440441
train_f-score_macro_tok: 0.776172551657539
train_precision_micro_tok: 0.8845909296553074
train_recall_micro_tok: 0.8845909296553074
train_f-score_micro_tok: 0.8845909296553075
train_time: 92.8391695022583
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5258    0.0314    0.0593      1624
           N     0.6205    0.7973    0.6979      3310
           P     0.6884    0.7997    0.7399      3610

   micro avg     0.6527    0.6527    0.6527      8544
   macro avg     0.6115    0.5428    0.4990      8544
weighted avg     0.6312    0.6527    0.5942      8544

F1-macro sent:  0.4990053562687001
F1-micro sent:  0.6527387640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8957    0.9702    0.9315    124347
           N     0.7753    0.5890    0.6694     14202
           P     0.8671    0.6268    0.7276     25017

   micro avg     0.8846    0.8846    0.8846    163566
   macro avg     0.8460    0.7287    0.7762    163566
weighted avg     0.8809    0.8846    0.8775    163566

F1-macro tok:  0.776172551657539
F1-micro tok:  0.8845909296553075
**************************************************
dev_cost_sum: 43383.522521972656
dev_cost_avg: 39.403744343299415
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19004.0
dev_accuracy_tok: 0.8932969822318323
dev_label=O_precision_sent: 0.7647058823529411
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10569105691056911
dev_label=N_precision_sent: 0.5987460815047022
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.7166979362101313
dev_label=P_precision_sent: 0.7197309417040358
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.7213483146067415
dev_precision_macro_sent: 0.6943943018538931
dev_recall_macro_sent: 0.5574216321369732
dev_f-score_macro_sent: 0.514579102575814
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8994314951677089
dev_label=O_recall_tok: 0.9763036099969146
dev_label=O_f-score_tok: 0.9362923509394881
dev_label=N_precision_tok: 0.7701307639366827
dev_label=N_recall_tok: 0.6025848142164781
dev_label=N_f-score_tok: 0.6761329305135951
dev_label=P_precision_tok: 0.9251456745853878
dev_label=P_recall_tok: 0.6425902864259029
dev_label=P_f-score_tok: 0.7584052911997061
dev_precision_macro_tok: 0.8649026445632598
dev_recall_macro_tok: 0.7404929035464319
dev_f-score_macro_tok: 0.7902768575509298
dev_precision_micro_tok: 0.8932969822318323
dev_recall_micro_tok: 0.8932969822318323
dev_f-score_micro_tok: 0.8932969822318322
dev_time: 4.936264276504517
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7647    0.0568    0.1057       229
           N     0.5987    0.8925    0.7167       428
           P     0.7197    0.7230    0.7213       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6944    0.5574    0.5146      1101
weighted avg     0.6821    0.6503    0.5915      1101

F1-macro sent:  0.514579102575814
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8994    0.9763    0.9363     16205
           N     0.7701    0.6026    0.6761      1857
           P     0.9251    0.6426    0.7584      3212

   micro avg     0.8933    0.8933    0.8933     21274
   macro avg     0.8649    0.7405    0.7903     21274
weighted avg     0.8920    0.8933    0.8867     21274

F1-macro tok:  0.7902768575509298
F1-micro tok:  0.8932969822318322
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321329.45587158203
train_cost_avg: 37.60878462916456
train_count_sent: 8544.0
train_total_correct_sent: 5612.0
train_accuracy_sent: 0.6568352059925093
train_count_tok: 163566.0
train_total_correct_tok: 144991.0
train_accuracy_tok: 0.8864372791411418
train_label=O_precision_sent: 0.49557522123893805
train_label=O_recall_sent: 0.034482758620689655
train_label=O_f-score_sent: 0.06447898675877951
train_label=N_precision_sent: 0.6210648148148148
train_label=N_recall_sent: 0.8105740181268882
train_label=N_f-score_sent: 0.7032765399737876
train_label=P_precision_sent: 0.6988567258574556
train_label=P_recall_sent: 0.7958448753462604
train_label=P_f-score_sent: 0.7442041186374823
train_precision_macro_sent: 0.6051655873037362
train_recall_macro_sent: 0.5469672173646127
train_f-score_macro_sent: 0.5039865484566831
train_precision_micro_sent: 0.6568352059925093
train_recall_micro_sent: 0.6568352059925093
train_f-score_micro_sent: 0.6568352059925093
train_label=O_precision_tok: 0.8970041905667667
train_label=O_recall_tok: 0.9708798764747039
train_label=O_f-score_tok: 0.9324811246065615
train_label=N_precision_tok: 0.7801177119735148
train_label=N_recall_tok: 0.5973102379946487
train_label=N_f-score_tok: 0.676583187111182
train_label=P_precision_tok: 0.8717410517012815
train_label=P_recall_tok: 0.6308510213055123
train_label=P_f-score_tok: 0.7319867350015075
train_precision_macro_tok: 0.8496209847471876
train_recall_macro_tok: 0.733013711924955
train_f-score_macro_tok: 0.780350348906417
train_precision_micro_tok: 0.8864372791411418
train_recall_micro_tok: 0.8864372791411418
train_f-score_micro_tok: 0.8864372791411418
train_time: 92.66603899002075
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4956    0.0345    0.0645      1624
           N     0.6211    0.8106    0.7033      3310
           P     0.6989    0.7958    0.7442      3610

   micro avg     0.6568    0.6568    0.6568      8544
   macro avg     0.6052    0.5470    0.5040      8544
weighted avg     0.6301    0.6568    0.5991      8544

F1-macro sent:  0.5039865484566831
F1-micro sent:  0.6568352059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9709    0.9325    124347
           N     0.7801    0.5973    0.6766     14202
           P     0.8717    0.6309    0.7320     25017

   micro avg     0.8864    0.8864    0.8864    163566
   macro avg     0.8496    0.7330    0.7804    163566
weighted avg     0.8830    0.8864    0.8796    163566

F1-macro tok:  0.780350348906417
F1-micro tok:  0.8864372791411418
**************************************************
dev_cost_sum: 43285.89343261719
dev_cost_avg: 39.31507123761779
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19007.0
dev_accuracy_tok: 0.8934379994359312
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6452205882352942
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7222222222222222
dev_label=P_precision_sent: 0.662431941923775
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7336683417085428
dev_precision_macro_sent: 0.7136619544974675
dev_recall_macro_sent: 0.5546665303837895
dev_f-score_macro_sent: 0.4994812518067089
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.8996301564722617
dev_label=O_recall_tok: 0.9756865165072508
dev_label=O_f-score_tok: 0.9361160449970397
dev_label=N_precision_tok: 0.792831541218638
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6801968019680197
dev_label=P_precision_tok: 0.9071180555555556
dev_label=P_recall_tok: 0.6506849315068494
dev_label=P_f-score_tok: 0.7577955039883976
dev_precision_macro_tok: 0.8665265844154851
dev_recall_macro_tok: 0.7406519079092057
dev_f-score_macro_tok: 0.791369450317819
dev_precision_micro_tok: 0.8934379994359312
dev_recall_micro_tok: 0.8934379994359312
dev_f-score_micro_tok: 0.8934379994359312
dev_time: 5.004037380218506
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6452    0.8201    0.7222       428
           P     0.6624    0.8221    0.7337       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.7137    0.5547    0.4995      1101
weighted avg     0.6913    0.6549    0.5855      1101

F1-macro sent:  0.4994812518067089
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8996    0.9757    0.9361     16205
           N     0.7928    0.5956    0.6802      1857
           P     0.9071    0.6507    0.7578      3212

   micro avg     0.8934    0.8934    0.8934     21274
   macro avg     0.8665    0.7407    0.7914     21274
weighted avg     0.8914    0.8934    0.8869     21274

F1-macro tok:  0.791369450317819
F1-micro tok:  0.8934379994359312
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319180.0794067383
train_cost_avg: 37.357219031687535
train_count_sent: 8544.0
train_total_correct_sent: 5698.0
train_accuracy_sent: 0.6669007490636704
train_count_tok: 163566.0
train_total_correct_tok: 145239.0
train_accuracy_tok: 0.887953486665933
train_label=O_precision_sent: 0.4537037037037037
train_label=O_recall_sent: 0.03017241379310345
train_label=O_f-score_sent: 0.05658198614318707
train_label=N_precision_sent: 0.6273179556761647
train_label=N_recall_sent: 0.8380664652567976
train_label=N_f-score_sent: 0.7175375064666323
train_label=P_precision_sent: 0.716243148978575
train_label=P_recall_sent: 0.796398891966759
train_label=P_f-score_sent: 0.7541972717733473
train_precision_macro_sent: 0.5990882694528145
train_recall_macro_sent: 0.5548792570055533
train_f-score_macro_sent: 0.5094389214610556
train_precision_micro_sent: 0.6669007490636704
train_recall_micro_sent: 0.6669007490636704
train_f-score_micro_sent: 0.6669007490636704
train_label=O_precision_tok: 0.899213020926489
train_label=O_recall_tok: 0.9703491037178219
train_label=O_f-score_tok: 0.9334277127307751
train_label=N_precision_tok: 0.7747381726254966
train_label=N_recall_tok: 0.6042106745528799
train_label=N_f-score_tok: 0.6789302951182846
train_label=P_precision_tok: 0.8739211187588769
train_label=P_recall_tok: 0.6394851500979334
train_label=P_f-score_tok: 0.7385453454285251
train_precision_macro_tok: 0.8492907707702875
train_recall_macro_tok: 0.7380149761228784
train_f-score_macro_tok: 0.7836344510925283
train_precision_micro_tok: 0.887953486665933
train_recall_micro_tok: 0.887953486665933
train_f-score_micro_tok: 0.887953486665933
train_time: 92.50201606750488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4537    0.0302    0.0566      1624
           N     0.6273    0.8381    0.7175      3310
           P     0.7162    0.7964    0.7542      3610

   micro avg     0.6669    0.6669    0.6669      8544
   macro avg     0.5991    0.5549    0.5094      8544
weighted avg     0.6319    0.6669    0.6074      8544

F1-macro sent:  0.5094389214610556
F1-micro sent:  0.6669007490636704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9703    0.9334    124347
           N     0.7747    0.6042    0.6789     14202
           P     0.8739    0.6395    0.7385     25017

   micro avg     0.8880    0.8880    0.8880    163566
   macro avg     0.8493    0.7380    0.7836    163566
weighted avg     0.8845    0.8880    0.8815    163566

F1-macro tok:  0.7836344510925283
F1-micro tok:  0.887953486665933
**************************************************
dev_cost_sum: 43101.606689453125
dev_cost_avg: 39.14768999950329
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 19017.0
dev_accuracy_tok: 0.8939080567829275
dev_label=O_precision_sent: 0.46153846153846156
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09411764705882353
dev_label=N_precision_sent: 0.5615491009681881
dev_label=N_recall_sent: 0.9485981308411215
dev_label=N_f-score_sent: 0.7054735013032146
dev_label=P_precision_sent: 0.7926136363636364
dev_label=P_recall_sent: 0.6283783783783784
dev_label=P_f-score_sent: 0.7010050251256281
dev_precision_macro_sent: 0.605233732956762
dev_recall_macro_sent: 0.5431260853147969
dev_f-score_macro_sent: 0.5001987244958888
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8952761668824953
dev_label=O_recall_tok: 0.981240357914224
dev_label=O_f-score_tok: 0.9362892304068774
dev_label=N_precision_tok: 0.8294635708566853
dev_label=N_recall_tok: 0.5578890683898762
dev_label=N_f-score_tok: 0.6670959433354798
dev_label=P_precision_tok: 0.9187279151943463
dev_label=P_recall_tok: 0.6475716064757161
dev_label=P_f-score_tok: 0.7596785975164354
dev_precision_macro_tok: 0.8811558843111756
dev_recall_macro_tok: 0.7289003442599388
dev_f-score_macro_tok: 0.787687923752931
dev_precision_micro_tok: 0.8939080567829275
dev_recall_micro_tok: 0.8939080567829275
dev_f-score_micro_tok: 0.8939080567829275
dev_time: 4.953823804855347
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0524    0.0941       229
           N     0.5615    0.9486    0.7055       428
           P     0.7926    0.6284    0.7010       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.6052    0.5431    0.5002      1101
weighted avg     0.6339    0.6331    0.5765      1101

F1-macro sent:  0.5001987244958888
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8953    0.9812    0.9363     16205
           N     0.8295    0.5579    0.6671      1857
           P     0.9187    0.6476    0.7597      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8812    0.7289    0.7877     21274
weighted avg     0.8931    0.8939    0.8861     21274

F1-macro tok:  0.787687923752931
F1-micro tok:  0.8939080567829275
**************************************************
Best epoch: 15
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317196.4514160156
train_cost_avg: 37.12505283427149
train_count_sent: 8544.0
train_total_correct_sent: 5679.0
train_accuracy_sent: 0.6646769662921348
train_count_tok: 163566.0
train_total_correct_tok: 145614.0
train_accuracy_tok: 0.8902461391731779
train_label=O_precision_sent: 0.5441176470588235
train_label=O_recall_sent: 0.04556650246305419
train_label=O_f-score_sent: 0.08409090909090909
train_label=N_precision_sent: 0.6230628988149499
train_label=N_recall_sent: 0.8259818731117825
train_label=N_f-score_sent: 0.7103143673681476
train_label=P_precision_sent: 0.7141791044776119
train_label=P_recall_sent: 0.7952908587257618
train_label=P_f-score_sent: 0.7525557011795544
train_precision_macro_sent: 0.6271198834504618
train_recall_macro_sent: 0.5556130781001994
train_f-score_macro_sent: 0.5156536592128703
train_precision_micro_sent: 0.6646769662921348
train_recall_micro_sent: 0.6646769662921348
train_f-score_micro_sent: 0.6646769662921348
train_label=O_precision_tok: 0.9009039244641339
train_label=O_recall_tok: 0.9714347752659895
train_label=O_f-score_tok: 0.9348409040781027
train_label=N_precision_tok: 0.7862643834375284
train_label=N_recall_tok: 0.61104069849317
train_label=N_f-score_tok: 0.6876659138634652
train_label=P_precision_tok: 0.8749932238304331
train_label=P_recall_tok: 0.6452012631410641
train_label=P_f-score_tok: 0.742729615313823
train_precision_macro_tok: 0.8540538439106985
train_recall_macro_tok: 0.7425589123000745
train_f-score_macro_tok: 0.7884121444184636
train_precision_micro_tok: 0.8902461391731779
train_recall_micro_tok: 0.8902461391731779
train_f-score_micro_tok: 0.8902461391731779
train_time: 94.01148343086243
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5441    0.0456    0.0841      1624
           N     0.6231    0.8260    0.7103      3310
           P     0.7142    0.7953    0.7526      3610

   micro avg     0.6647    0.6647    0.6647      8544
   macro avg     0.6271    0.5556    0.5157      8544
weighted avg     0.6466    0.6647    0.6091      8544

F1-macro sent:  0.5156536592128703
F1-micro sent:  0.6646769662921348
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9714    0.9348    124347
           N     0.7863    0.6110    0.6877     14202
           P     0.8750    0.6452    0.7427     25017

   micro avg     0.8902    0.8902    0.8902    163566
   macro avg     0.8541    0.7426    0.7884    163566
weighted avg     0.8870    0.8902    0.8840    163566

F1-macro tok:  0.7884121444184636
F1-micro tok:  0.8902461391731779
**************************************************
dev_cost_sum: 43053.984924316406
dev_cost_avg: 39.10443680682689
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19001.0
dev_accuracy_tok: 0.8931559650277334
dev_label=O_precision_sent: 0.6538461538461539
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.13333333333333336
dev_label=N_precision_sent: 0.6583969465648855
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7247899159663865
dev_label=P_precision_sent: 0.6642468239564429
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7356783919597991
dev_precision_macro_sent: 0.6588299747891607
dev_recall_macro_sent: 0.5682116328465755
dev_f-score_macro_sent: 0.531267213753173
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.8905544719977709
dev_label=O_recall_tok: 0.9861771058315335
dev_label=O_f-score_tok: 0.9359297218155198
dev_label=N_precision_tok: 0.8539130434782609
dev_label=N_recall_tok: 0.5288099084544965
dev_label=N_f-score_tok: 0.6531426671100765
dev_label=P_precision_tok: 0.9352914180816888
dev_label=P_recall_tok: 0.6344956413449564
dev_label=P_f-score_tok: 0.7560749397143386
dev_precision_macro_tok: 0.8932529778525735
dev_recall_macro_tok: 0.7164942185436621
dev_f-score_macro_tok: 0.7817157762133117
dev_precision_micro_tok: 0.8931559650277334
dev_recall_micro_tok: 0.8931559650277334
dev_f-score_micro_tok: 0.8931559650277334
dev_time: 4.90105128288269
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6538    0.0742    0.1333       229
           N     0.6584    0.8061    0.7248       428
           P     0.6642    0.8243    0.7357       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6588    0.5682    0.5313      1101
weighted avg     0.6598    0.6612    0.6062      1101

F1-macro sent:  0.531267213753173
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8906    0.9862    0.9359     16205
           N     0.8539    0.5288    0.6531      1857
           P     0.9353    0.6345    0.7561      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8933    0.7165    0.7817     21274
weighted avg     0.8941    0.8932    0.8841     21274

F1-macro tok:  0.7817157762133117
F1-micro tok:  0.8931559650277334
**************************************************
Best epoch: 15
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315334.1481323242
train_cost_avg: 36.90708662597428
train_count_sent: 8544.0
train_total_correct_sent: 5761.0
train_accuracy_sent: 0.6742743445692884
train_count_tok: 163566.0
train_total_correct_tok: 145852.0
train_accuracy_tok: 0.8917012092977759
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07936507936507936
train_label=N_precision_sent: 0.6452301850972947
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7227538543328017
train_label=P_precision_sent: 0.7093078758949881
train_label=P_recall_sent: 0.8232686980609418
train_label=P_f-score_sent: 0.7620512820512821
train_precision_macro_sent: 0.6181793536640942
train_recall_macro_sent: 0.5626074324647353
train_f-score_macro_sent: 0.5213900719163878
train_precision_micro_sent: 0.6742743445692884
train_recall_micro_sent: 0.6742743445692884
train_f-score_micro_sent: 0.6742743445692884
train_label=O_precision_tok: 0.9023845452779728
train_label=O_recall_tok: 0.9714347752659895
train_label=O_f-score_tok: 0.9356374100050734
train_label=N_precision_tok: 0.7920086587895734
train_label=N_recall_tok: 0.6182931981411068
train_label=N_f-score_tok: 0.6944521333386057
train_label=P_precision_tok: 0.8742547134339582
train_label=P_recall_tok: 0.6505975936363273
train_label=P_f-score_tok: 0.7460237429527432
train_precision_macro_tok: 0.8562159725005015
train_recall_macro_tok: 0.7467751890144746
train_f-score_macro_tok: 0.7920377620988074
train_precision_micro_tok: 0.8917012092977759
train_recall_micro_tok: 0.8917012092977759
train_f-score_micro_tok: 0.8917012092977759
train_time: 93.32122850418091
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0431    0.0794      1624
           N     0.6452    0.8215    0.7228      3310
           P     0.7093    0.8233    0.7621      3610

   micro avg     0.6743    0.6743    0.6743      8544
   macro avg     0.6182    0.5626    0.5214      8544
weighted avg     0.6447    0.6743    0.6171      8544

F1-macro sent:  0.5213900719163878
F1-micro sent:  0.6742743445692884
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9714    0.9356    124347
           N     0.7920    0.6183    0.6945     14202
           P     0.8743    0.6506    0.7460     25017

   micro avg     0.8917    0.8917    0.8917    163566
   macro avg     0.8562    0.7468    0.7920    163566
weighted avg     0.8885    0.8917    0.8857    163566

F1-macro tok:  0.7920377620988074
F1-micro tok:  0.8917012092977759
**************************************************
dev_cost_sum: 42714.11950683594
dev_cost_avg: 38.795748870877325
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19076.0
dev_accuracy_tok: 0.8966813951302058
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017167381974248927
dev_label=N_precision_sent: 0.5944272445820433
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7150837988826816
dev_label=P_precision_sent: 0.7339246119733924
dev_label=P_recall_sent: 0.7454954954954955
dev_label=P_f-score_sent: 0.7396648044692739
dev_precision_macro_sent: 0.609450618851812
dev_recall_macro_sent: 0.5504751272106291
dev_f-score_macro_sent: 0.49063866177540144
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9014332840404959
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9381714860745257
dev_label=N_precision_tok: 0.7947997189037245
dev_label=N_recall_tok: 0.6090468497576736
dev_label=N_f-score_tok: 0.6896341463414634
dev_label=P_precision_tok: 0.9237549581313353
dev_label=P_recall_tok: 0.6525529265255293
dev_label=P_f-score_tok: 0.7648239372377303
dev_precision_macro_tok: 0.8733293203585185
dev_recall_macro_tok: 0.7465437493503919
dev_f-score_macro_tok: 0.7975431898845731
dev_precision_micro_tok: 0.8966813951302058
dev_recall_micro_tok: 0.8966813951302058
dev_f-score_micro_tok: 0.8966813951302058
dev_time: 4.890979766845703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0087    0.0172       229
           N     0.5944    0.8972    0.7151       428
           P     0.7339    0.7455    0.7397       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6095    0.5505    0.4906      1101
weighted avg     0.6310    0.6512    0.5798      1101

F1-macro sent:  0.49063866177540144
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9014    0.9780    0.9382     16205
           N     0.7948    0.6090    0.6896      1857
           P     0.9238    0.6526    0.7648      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8733    0.7465    0.7975     21274
weighted avg     0.8955    0.8967    0.8903     21274

F1-macro tok:  0.7975431898845731
F1-micro tok:  0.8966813951302058
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313622.5140991211
train_cost_avg: 36.70675492733159
train_count_sent: 8544.0
train_total_correct_sent: 5731.0
train_accuracy_sent: 0.6707631086142322
train_count_tok: 163566.0
train_total_correct_tok: 146180.0
train_accuracy_tok: 0.8937065160241126
train_label=O_precision_sent: 0.4866666666666667
train_label=O_recall_sent: 0.04495073891625616
train_label=O_f-score_sent: 0.08229988726042842
train_label=N_precision_sent: 0.637066541705717
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7176035893375561
train_label=P_precision_sent: 0.7123121667474551
train_label=P_recall_sent: 0.8141274238227146
train_label=P_f-score_sent: 0.7598241985522234
train_precision_macro_sent: 0.6120151250399463
train_recall_macro_sent: 0.5601761045987909
train_f-score_macro_sent: 0.5199092250500693
train_precision_micro_sent: 0.6707631086142322
train_recall_micro_sent: 0.6707631086142322
train_f-score_micro_sent: 0.6707631086142322
train_label=O_precision_tok: 0.9045851512044721
train_label=O_recall_tok: 0.972094220206358
train_label=O_f-score_tok: 0.9371254467504477
train_label=N_precision_tok: 0.7912647374062165
train_label=N_recall_tok: 0.6237853823405154
train_label=N_f-score_tok: 0.6976139853531773
train_label=P_precision_tok: 0.8773408739262658
train_label=P_recall_tok: 0.6573130271415437
train_label=P_f-score_tok: 0.7515539305301646
train_precision_macro_tok: 0.8577302541789847
train_recall_macro_tok: 0.7510642098961391
train_f-score_macro_tok: 0.79543112087793
train_precision_micro_tok: 0.8937065160241126
train_recall_micro_tok: 0.8937065160241126
train_f-score_micro_tok: 0.8937065160241126
train_time: 92.17659258842468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4867    0.0450    0.0823      1624
           N     0.6371    0.8215    0.7176      3310
           P     0.7123    0.8141    0.7598      3610

   micro avg     0.6708    0.6708    0.6708      8544
   macro avg     0.6120    0.5602    0.5199      8544
weighted avg     0.6403    0.6708    0.6147      8544

F1-macro sent:  0.5199092250500693
F1-micro sent:  0.6707631086142322
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9721    0.9371    124347
           N     0.7913    0.6238    0.6976     14202
           P     0.8773    0.6573    0.7516     25017

   micro avg     0.8937    0.8937    0.8937    163566
   macro avg     0.8577    0.7511    0.7954    163566
weighted avg     0.8906    0.8937    0.8879    163566

F1-macro tok:  0.79543112087793
F1-micro tok:  0.8937065160241126
**************************************************
dev_cost_sum: 42590.27490234375
dev_cost_avg: 38.68326512474455
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04219409282700421
dev_label=N_precision_sent: 0.6130081300813008
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.722914669223394
dev_label=P_precision_sent: 0.7175732217573222
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7440347071583514
dev_precision_macro_sent: 0.6518604506128743
dev_recall_macro_sent: 0.5583992350510737
dev_f-score_macro_sent: 0.5030478230695832
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9058174926778844
dev_label=O_recall_tok: 0.9733415612465288
dev_label=O_f-score_tok: 0.9383663513593908
dev_label=N_precision_tok: 0.7947629157820241
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.6868501529051988
dev_label=P_precision_tok: 0.8941993464052288
dev_label=P_recall_tok: 0.6815068493150684
dev_label=P_f-score_tok: 0.7734982332155478
dev_precision_macro_tok: 0.8649265849550458
dev_recall_macro_tok: 0.7531957455417135
dev_f-score_macro_tok: 0.7995715791600458
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 4.9952311515808105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0218    0.0422       229
           N     0.6130    0.8808    0.7229       428
           P     0.7176    0.7725    0.7440       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6519    0.5584    0.5030      1101
weighted avg     0.6577    0.6585    0.5898      1101

F1-macro sent:  0.5030478230695832
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9733    0.9384     16205
           N     0.7948    0.6047    0.6869      1857
           P     0.8942    0.6815    0.7735      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8649    0.7532    0.7996     21274
weighted avg     0.8944    0.8971    0.8915     21274

F1-macro tok:  0.7995715791600458
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 19
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 311740.8201904297
train_cost_avg: 36.48651921704467
train_count_sent: 8544.0
train_total_correct_sent: 5772.0
train_accuracy_sent: 0.675561797752809
train_count_tok: 163566.0
train_total_correct_tok: 146346.0
train_accuracy_tok: 0.8947213968673197
train_label=O_precision_sent: 0.47058823529411764
train_label=O_recall_sent: 0.059113300492610835
train_label=O_f-score_sent: 0.10503282275711158
train_label=N_precision_sent: 0.6474682025437964
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.721679818108867
train_label=P_precision_sent: 0.713635274382938
train_label=P_recall_sent: 0.8249307479224377
train_label=P_f-score_sent: 0.7652576127457278
train_precision_macro_sent: 0.6105639040736174
train_recall_macro_sent: 0.5663832628654392
train_f-score_macro_sent: 0.5306567512039021
train_precision_micro_sent: 0.675561797752809
train_recall_micro_sent: 0.675561797752809
train_f-score_micro_sent: 0.675561797752809
train_label=O_precision_tok: 0.9056118624246604
train_label=O_recall_tok: 0.9715151953806687
train_label=O_f-score_tok: 0.9374066414994782
train_label=N_precision_tok: 0.7942452412571934
train_label=N_recall_tok: 0.6316715955499226
train_label=N_f-score_tok: 0.7036906302702279
train_label=P_precision_tok: 0.8778807947019868
train_label=P_recall_tok: 0.6623496022704561
train_label=P_f-score_tok: 0.7550350861204775
train_precision_macro_tok: 0.8592459661279469
train_recall_macro_tok: 0.7551787977336825
train_f-score_macro_tok: 0.7987107859633946
train_precision_micro_tok: 0.8947213968673197
train_recall_micro_tok: 0.8947213968673197
train_f-score_micro_tok: 0.8947213968673197
train_time: 93.74237704277039
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4706    0.0591    0.1050      1624
           N     0.6475    0.8151    0.7217      3310
           P     0.7136    0.8249    0.7653      3610

   micro avg     0.6756    0.6756    0.6756      8544
   macro avg     0.6106    0.5664    0.5307      8544
weighted avg     0.6418    0.6756    0.6229      8544

F1-macro sent:  0.5306567512039021
F1-micro sent:  0.675561797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9715    0.9374    124347
           N     0.7942    0.6317    0.7037     14202
           P     0.8779    0.6623    0.7550     25017

   micro avg     0.8947    0.8947    0.8947    163566
   macro avg     0.8592    0.7552    0.7987    163566
weighted avg     0.8917    0.8947    0.8892    163566

F1-macro tok:  0.7987107859633946
F1-micro tok:  0.8947213968673197
**************************************************
dev_cost_sum: 42555.19122314453
dev_cost_avg: 38.65139983936833
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19084.0
dev_accuracy_tok: 0.8970574410078029
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.6666666666666666
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.7150595882990248
dev_label=P_precision_sent: 0.6491525423728813
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7408123791102514
dev_precision_macro_sent: 0.6469397363465159
dev_recall_macro_sent: 0.5591029240888442
dev_f-score_macro_sent: 0.5125015401568336
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9025822265290999
dev_label=O_recall_tok: 0.9771058315334773
dev_label=O_f-score_tok: 0.9383667180277349
dev_label=N_precision_tok: 0.8113905325443787
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6837020878778435
dev_label=P_precision_tok: 0.9050021017234132
dev_label=P_recall_tok: 0.6702988792029888
dev_label=P_f-score_tok: 0.7701663387587193
dev_precision_macro_tok: 0.8729916202656306
dev_recall_macro_tok: 0.7460474865980286
dev_f-score_macro_tok: 0.7974117148880993
dev_precision_micro_tok: 0.8970574410078029
dev_recall_micro_tok: 0.8970574410078029
dev_f-score_micro_tok: 0.8970574410078029
dev_time: 4.943041086196899
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6667    0.7710    0.7151       428
           P     0.6492    0.8626    0.7408       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6469    0.5591    0.5125      1101
weighted avg     0.6509    0.6567    0.5937      1101

F1-macro sent:  0.5125015401568336
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9026    0.9771    0.9384     16205
           N     0.8114    0.5907    0.6837      1857
           P     0.9050    0.6703    0.7702      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8730    0.7460    0.7974     21274
weighted avg     0.8950    0.8971    0.8907     21274

F1-macro tok:  0.7974117148880993
F1-micro tok:  0.8970574410078029
**************************************************
Best epoch: 19
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 310290.138671875
train_cost_avg: 36.31672971346852
train_count_sent: 8544.0
train_total_correct_sent: 5765.0
train_accuracy_sent: 0.6747425093632958
train_count_tok: 163566.0
train_total_correct_tok: 146685.0
train_accuracy_tok: 0.8967939547338689
train_label=O_precision_sent: 0.5329949238578681
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11532125205930807
train_label=N_precision_sent: 0.6398148148148148
train_label=N_recall_sent: 0.8350453172205438
train_label=N_f-score_sent: 0.7245085190039318
train_label=P_precision_sent: 0.719145766078967
train_label=P_recall_sent: 0.8022160664819945
train_label=P_f-score_sent: 0.758412989393741
train_precision_macro_sent: 0.6306518349172167
train_recall_macro_sent: 0.5673055187054438
train_f-score_macro_sent: 0.5327475868189936
train_precision_micro_sent: 0.6747425093632958
train_recall_micro_sent: 0.6747425093632958
train_f-score_micro_sent: 0.6747425093632958
train_label=O_precision_tok: 0.9079895145601898
train_label=O_recall_tok: 0.9721746403210371
train_label=O_f-score_tok: 0.938986500132047
train_label=N_precision_tok: 0.7971714687280393
train_label=N_recall_tok: 0.6389945078158006
train_label=N_f-score_tok: 0.709372312983663
train_label=P_precision_tok: 0.8780782357574166
train_label=P_recall_tok: 0.6684654434984211
train_label=P_f-score_tok: 0.759066769551995
train_precision_macro_tok: 0.861079739681882
train_recall_macro_tok: 0.7598781972117529
train_f-score_macro_tok: 0.8024751942225684
train_precision_micro_tok: 0.8967939547338689
train_recall_micro_tok: 0.8967939547338689
train_f-score_micro_tok: 0.8967939547338689
train_time: 93.4602267742157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5330    0.0647    0.1153      1624
           N     0.6398    0.8350    0.7245      3310
           P     0.7191    0.8022    0.7584      3610

   micro avg     0.6747    0.6747    0.6747      8544
   macro avg     0.6307    0.5673    0.5327      8544
weighted avg     0.6530    0.6747    0.6230      8544

F1-macro sent:  0.5327475868189936
F1-micro sent:  0.6747425093632958
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9722    0.9390    124347
           N     0.7972    0.6390    0.7094     14202
           P     0.8781    0.6685    0.7591     25017

   micro avg     0.8968    0.8968    0.8968    163566
   macro avg     0.8611    0.7599    0.8025    163566
weighted avg     0.8938    0.8968    0.8915    163566

F1-macro tok:  0.8024751942225684
F1-micro tok:  0.8967939547338689
**************************************************
dev_cost_sum: 42416.308166503906
dev_cost_avg: 38.52525719028511
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19095.0
dev_accuracy_tok: 0.8975745040894989
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06611570247933884
dev_label=N_precision_sent: 0.6397188049209139
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.7301905717151455
dev_label=P_precision_sent: 0.6936416184971098
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7476635514018691
dev_precision_macro_sent: 0.6495816796008796
dev_recall_macro_sent: 0.5654041994490103
dev_f-score_macro_sent: 0.5146566085321178
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.8990281387727427
dev_label=O_recall_tok: 0.9818574514038877
dev_label=O_f-score_tok: 0.9386190012683244
dev_label=N_precision_tok: 0.8185269552012149
dev_label=N_recall_tok: 0.5805061927840603
dev_label=N_f-score_tok: 0.6792690611216131
dev_label=P_precision_tok: 0.9322709163346613
dev_label=P_recall_tok: 0.6556662515566625
dev_label=P_f-score_tok: 0.7698775360994333
dev_precision_macro_tok: 0.8832753367695396
dev_recall_macro_tok: 0.7393432985815368
dev_f-score_macro_tok: 0.7959218661631237
dev_precision_micro_tok: 0.8975745040894989
dev_recall_micro_tok: 0.8975745040894989
dev_f-score_micro_tok: 0.8975745040894989
dev_time: 4.951474905014038
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0349    0.0661       229
           N     0.6397    0.8505    0.7302       428
           P     0.6936    0.8108    0.7477       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6496    0.5654    0.5147      1101
weighted avg     0.6564    0.6649    0.5991      1101

F1-macro sent:  0.5146566085321178
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9819    0.9386     16205
           N     0.8185    0.5805    0.6793      1857
           P     0.9323    0.6557    0.7699      3212

   micro avg     0.8976    0.8976    0.8976     21274
   macro avg     0.8833    0.7393    0.7959     21274
weighted avg     0.8970    0.8976    0.8905     21274

F1-macro tok:  0.7959218661631237
F1-micro tok:  0.8975745040894989
**************************************************
Best epoch: 19
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 308305.1354370117
train_cost_avg: 36.084402555830025
train_count_sent: 8544.0
train_total_correct_sent: 5815.0
train_accuracy_sent: 0.6805945692883895
train_count_tok: 163566.0
train_total_correct_tok: 146880.0
train_accuracy_tok: 0.8979861340376362
train_label=O_precision_sent: 0.4896907216494845
train_label=O_recall_sent: 0.058497536945812806
train_label=O_f-score_sent: 0.10451045104510451
train_label=N_precision_sent: 0.6488081189520888
train_label=N_recall_sent: 0.8305135951661632
train_label=N_f-score_sent: 0.728501391281304
train_label=P_precision_sent: 0.7223437879893022
train_label=P_recall_sent: 0.8229916897506925
train_label=P_f-score_sent: 0.7693901333678621
train_precision_macro_sent: 0.6202808761969585
train_recall_macro_sent: 0.5706676072875562
train_f-score_macro_sent: 0.5341339918980902
train_precision_micro_sent: 0.6805945692883895
train_recall_micro_sent: 0.6805945692883895
train_f-score_micro_sent: 0.6805945692883895
train_label=O_precision_tok: 0.908962363488673
train_label=O_recall_tok: 0.9718931699196603
train_label=O_f-score_tok: 0.9393749781386147
train_label=N_precision_tok: 0.7971875272949602
train_label=N_recall_tok: 0.6426559639487396
train_label=N_f-score_tok: 0.7116291762504385
train_label=P_precision_tok: 0.8820520849642502
train_label=P_recall_tok: 0.6755806051884718
train_label=P_f-score_tok: 0.7651319661369913
train_precision_macro_tok: 0.8627339919159612
train_recall_macro_tok: 0.763376579685624
train_f-score_macro_tok: 0.8053787068420148
train_precision_micro_tok: 0.8979861340376362
train_recall_micro_tok: 0.8979861340376362
train_f-score_micro_tok: 0.8979861340376362
train_time: 92.7175681591034
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4897    0.0585    0.1045      1624
           N     0.6488    0.8305    0.7285      3310
           P     0.7223    0.8230    0.7694      3610

   micro avg     0.6806    0.6806    0.6806      8544
   macro avg     0.6203    0.5707    0.5341      8544
weighted avg     0.6496    0.6806    0.6272      8544

F1-macro sent:  0.5341339918980902
F1-micro sent:  0.6805945692883895
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9090    0.9719    0.9394    124347
           N     0.7972    0.6427    0.7116     14202
           P     0.8821    0.6756    0.7651     25017

   micro avg     0.8980    0.8980    0.8980    163566
   macro avg     0.8627    0.7634    0.8054    163566
weighted avg     0.8951    0.8980    0.8930    163566

F1-macro tok:  0.8053787068420148
F1-micro tok:  0.8979861340376362
**************************************************
dev_cost_sum: 42311.665771484375
dev_cost_avg: 38.43021414303758
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.4523809523809524
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14022140221402213
dev_label=N_precision_sent: 0.6713709677419355
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7207792207792209
dev_label=P_precision_sent: 0.6678507992895204
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.746772591857001
dev_precision_macro_sent: 0.5972009064708027
dev_recall_macro_sent: 0.5692845541129424
dev_f-score_macro_sent: 0.5359244049500813
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9034541821296032
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.938552787663108
dev_label=N_precision_tok: 0.8263836239575436
dev_label=N_recall_tok: 0.5869682283252557
dev_label=N_f-score_tok: 0.6863979848866498
dev_label=P_precision_tok: 0.8934426229508197
dev_label=P_recall_tok: 0.6787048567870486
dev_label=P_f-score_tok: 0.7714083510261854
dev_precision_macro_tok: 0.8744268096793221
dev_recall_macro_tok: 0.7473872743853726
dev_f-score_macro_tok: 0.7987863745253144
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 5.0638344287872314
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4524    0.0830    0.1402       229
           N     0.6714    0.7780    0.7208       428
           P     0.6679    0.8468    0.7468       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.5972    0.5693    0.5359      1101
weighted avg     0.6244    0.6612    0.6105      1101

F1-macro sent:  0.5359244049500813
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9035    0.9765    0.9386     16205
           N     0.8264    0.5870    0.6864      1857
           P     0.8934    0.6787    0.7714      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8744    0.7474    0.7988     21274
weighted avg     0.8952    0.8975    0.8913     21274

F1-macro tok:  0.7987863745253144
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 19
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 306791.5590209961
train_cost_avg: 35.90725175807538
train_count_sent: 8544.0
train_total_correct_sent: 5822.0
train_accuracy_sent: 0.6814138576779026
train_count_tok: 163566.0
train_total_correct_tok: 147183.0
train_accuracy_tok: 0.8998385972634899
train_label=O_precision_sent: 0.44680851063829785
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11296395911780527
train_label=N_precision_sent: 0.6477780390312721
train_label=N_recall_sent: 0.8323262839879154
train_label=N_f-score_sent: 0.728546872934021
train_label=P_precision_sent: 0.730276134122288
train_label=P_recall_sent: 0.8204986149584488
train_label=P_f-score_sent: 0.7727628489433864
train_precision_macro_sent: 0.6082875612639526
train_recall_macro_sent: 0.5724933571200524
train_f-score_macro_sent: 0.5380912269984043
train_precision_micro_sent: 0.6814138576779026
train_recall_micro_sent: 0.6814138576779026
train_f-score_micro_sent: 0.6814138576779026
train_label=O_precision_tok: 0.91105233013806
train_label=O_recall_tok: 0.9722228923898445
train_label=O_f-score_tok: 0.9406441723758283
train_label=N_precision_tok: 0.8023184868822453
train_label=N_recall_tok: 0.6481481481481481
train_label=N_f-score_tok: 0.7170399221032132
train_label=P_precision_tok: 0.880806310254163
train_label=P_recall_tok: 0.6829356037894232
train_label=P_f-score_tok: 0.7693520061241951
train_precision_macro_tok: 0.8647257090914895
train_recall_macro_tok: 0.7677688814424718
train_f-score_macro_tok: 0.8090120335344122
train_precision_micro_tok: 0.8998385972634899
train_recall_micro_tok: 0.8998385972634899
train_f-score_micro_tok: 0.8998385972634899
train_time: 93.13988709449768
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4468    0.0647    0.1130      1624
           N     0.6478    0.8323    0.7285      3310
           P     0.7303    0.8205    0.7728      3610

   micro avg     0.6814    0.6814    0.6814      8544
   macro avg     0.6083    0.5725    0.5381      8544
weighted avg     0.6444    0.6814    0.6302      8544

F1-macro sent:  0.5380912269984043
F1-micro sent:  0.6814138576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9111    0.9722    0.9406    124347
           N     0.8023    0.6481    0.7170     14202
           P     0.8808    0.6829    0.7694     25017

   micro avg     0.8998    0.8998    0.8998    163566
   macro avg     0.8647    0.7678    0.8090    163566
weighted avg     0.8970    0.8998    0.8950    163566

F1-macro tok:  0.8090120335344122
F1-micro tok:  0.8998385972634899
**************************************************
dev_cost_sum: 42273.782653808594
dev_cost_avg: 38.39580622507592
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19130.0
dev_accuracy_tok: 0.899219704803986
dev_label=O_precision_sent: 0.7647058823529411
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10569105691056911
dev_label=N_precision_sent: 0.6860706860706861
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.7260726072607261
dev_label=P_precision_sent: 0.6467661691542289
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7449856733524355
dev_precision_macro_sent: 0.6991809125259519
dev_recall_macro_sent: 0.5687249915711737
dev_f-score_macro_sent: 0.5255831125079102
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9046150331277131
dev_label=O_recall_tok: 0.9773526689293428
dev_label=O_f-score_tok: 0.939578204253552
dev_label=N_precision_tok: 0.8111432706222865
dev_label=N_recall_tok: 0.6036618201400108
dev_label=N_f-score_tok: 0.6921889472059277
dev_label=P_precision_tok: 0.9106543624161074
dev_label=P_recall_tok: 0.6759028642590287
dev_label=P_f-score_tok: 0.7759113652609008
dev_precision_macro_tok: 0.8754708887220356
dev_recall_macro_tok: 0.7523057844427941
dev_f-score_macro_tok: 0.8025595055734601
dev_precision_micro_tok: 0.899219704803986
dev_recall_micro_tok: 0.899219704803986
dev_f-score_micro_tok: 0.899219704803986
dev_time: 4.943840265274048
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7647    0.0568    0.1057       229
           N     0.6861    0.7710    0.7261       428
           P     0.6468    0.8784    0.7450       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6992    0.5687    0.5256      1101
weighted avg     0.6866    0.6658    0.6047      1101

F1-macro sent:  0.5255831125079102
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9774    0.9396     16205
           N     0.8111    0.6037    0.6922      1857
           P     0.9107    0.6759    0.7759      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8755    0.7523    0.8026     21274
weighted avg     0.8974    0.8992    0.8933     21274

F1-macro tok:  0.8025595055734601
F1-micro tok:  0.899219704803986
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 304998.07177734375
train_cost_avg: 35.697339861580495
train_count_sent: 8544.0
train_total_correct_sent: 5866.0
train_accuracy_sent: 0.6865636704119851
train_count_tok: 163566.0
train_total_correct_tok: 147436.0
train_accuracy_tok: 0.9013853734883778
train_label=O_precision_sent: 0.5238095238095238
train_label=O_recall_sent: 0.06096059113300493
train_label=O_f-score_sent: 0.10921125206839494
train_label=N_precision_sent: 0.6490904904443933
train_label=N_recall_sent: 0.8516616314199396
train_label=N_f-score_sent: 0.7367045603031491
train_label=P_precision_sent: 0.7347956131605184
train_label=P_recall_sent: 0.8166204986149584
train_label=P_f-score_sent: 0.7735502492784045
train_precision_macro_sent: 0.6358985424714785
train_recall_macro_sent: 0.576414240389301
train_f-score_macro_sent: 0.5398220205499829
train_precision_micro_sent: 0.6865636704119851
train_recall_micro_sent: 0.6865636704119851
train_f-score_micro_sent: 0.6865636704119851
train_label=O_precision_tok: 0.9125476433072947
train_label=O_recall_tok: 0.9723435225618632
train_label=O_f-score_tok: 0.9414971071709456
train_label=N_precision_tok: 0.8062510792609221
train_label=N_recall_tok: 0.6575130263343191
train_label=N_f-score_tok: 0.7243251628917157
train_label=P_precision_tok: 0.8820360203191544
train_label=P_recall_tok: 0.6871327497301835
train_label=P_f-score_tok: 0.7724801150406686
train_precision_macro_tok: 0.8669449142957903
train_recall_macro_tok: 0.7723297662087886
train_f-score_macro_tok: 0.8127674617011099
train_precision_micro_tok: 0.9013853734883778
train_recall_micro_tok: 0.9013853734883778
train_f-score_micro_tok: 0.9013853734883778
train_time: 93.10790848731995
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5238    0.0610    0.1092      1624
           N     0.6491    0.8517    0.7367      3310
           P     0.7348    0.8166    0.7736      3610

   micro avg     0.6866    0.6866    0.6866      8544
   macro avg     0.6359    0.5764    0.5398      8544
weighted avg     0.6615    0.6866    0.6330      8544

F1-macro sent:  0.5398220205499829
F1-micro sent:  0.6865636704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9723    0.9415    124347
           N     0.8063    0.6575    0.7243     14202
           P     0.8820    0.6871    0.7725     25017

   micro avg     0.9014    0.9014    0.9014    163566
   macro avg     0.8669    0.7723    0.8128    163566
weighted avg     0.8987    0.9014    0.8968    163566

F1-macro tok:  0.8127674617011099
F1-micro tok:  0.9013853734883778
**************************************************
dev_cost_sum: 42179.76873779297
dev_cost_avg: 38.310416655579445
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 19166.0
dev_accuracy_tok: 0.9009119112531729
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.5728571428571428
dev_label=N_recall_sent: 0.9369158878504673
dev_label=N_f-score_sent: 0.7109929078014184
dev_label=P_precision_sent: 0.7721518987341772
dev_label=P_recall_sent: 0.6869369369369369
dev_label=P_f-score_sent: 0.7270560190703218
dev_precision_macro_sent: 0.6705585694193289
dev_recall_macro_sent: 0.5471066912319004
dev_f-score_macro_sent: 0.4906971600210765
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.9095570021314592
dev_label=O_recall_tok: 0.9743289108299907
dev_label=O_f-score_tok: 0.9408294601358599
dev_label=N_precision_tok: 0.7869071476285905
dev_label=N_recall_tok: 0.6343564889606893
dev_label=N_f-score_tok: 0.7024448419797257
dev_label=P_precision_tok: 0.9094292803970223
dev_label=P_recall_tok: 0.6846201743462017
dev_label=P_f-score_tok: 0.7811722912966251
dev_precision_macro_tok: 0.8686311433856906
dev_recall_macro_tok: 0.7644351913789605
dev_f-score_macro_tok: 0.8081488644707369
dev_precision_micro_tok: 0.9009119112531729
dev_recall_micro_tok: 0.9009119112531729
dev_f-score_micro_tok: 0.9009119112531729
dev_time: 4.8825273513793945
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.5729    0.9369    0.7110       428
           P     0.7722    0.6869    0.7271       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.6706    0.5471    0.4907      1101
weighted avg     0.6727    0.6449    0.5767      1101

F1-macro sent:  0.4906971600210765
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9096    0.9743    0.9408     16205
           N     0.7869    0.6344    0.7024      1857
           P     0.9094    0.6846    0.7812      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8686    0.7644    0.8081     21274
weighted avg     0.8988    0.9009    0.8959     21274

F1-macro tok:  0.8081488644707369
F1-micro tok:  0.9009119112531729
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 303758.3596801758
train_cost_avg: 35.55224247193068
train_count_sent: 8544.0
train_total_correct_sent: 5866.0
train_accuracy_sent: 0.6865636704119851
train_count_tok: 163566.0
train_total_correct_tok: 147740.0
train_accuracy_tok: 0.9032439504542509
train_label=O_precision_sent: 0.49387755102040815
train_label=O_recall_sent: 0.07450738916256158
train_label=O_f-score_sent: 0.1294810058855003
train_label=N_precision_sent: 0.6507022795302786
train_label=N_recall_sent: 0.8537764350453172
train_label=N_f-score_sent: 0.7385339082712662
train_label=P_precision_sent: 0.7378665318503539
train_label=P_recall_sent: 0.8085872576177285
train_label=P_f-score_sent: 0.7716098334655035
train_precision_macro_sent: 0.6274821208003468
train_recall_macro_sent: 0.5789570272752025
train_f-score_macro_sent: 0.5465415825407566
train_precision_micro_sent: 0.6865636704119851
train_recall_micro_sent: 0.6865636704119851
train_f-score_micro_sent: 0.6865636704119851
train_label=O_precision_tok: 0.9151399067288475
train_label=O_recall_tok: 0.9721103042292938
train_label=O_f-score_tok: 0.9427652231559654
train_label=N_precision_tok: 0.8029421826890182
train_label=N_recall_tok: 0.6610336572313759
train_label=N_f-score_tok: 0.7251100641075152
train_label=P_precision_tok: 0.8830991610229455
train_label=P_recall_tok: 0.6984450573609945
train_label=P_f-score_tok: 0.7799924112224629
train_precision_macro_tok: 0.8670604168136037
train_recall_macro_tok: 0.7771963396072215
train_f-score_macro_tok: 0.8159558994953144
train_precision_micro_tok: 0.9032439504542509
train_recall_micro_tok: 0.9032439504542509
train_f-score_micro_tok: 0.9032439504542509
train_time: 93.97142577171326
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4939    0.0745    0.1295      1624
           N     0.6507    0.8538    0.7385      3310
           P     0.7379    0.8086    0.7716      3610

   micro avg     0.6866    0.6866    0.6866      8544
   macro avg     0.6275    0.5790    0.5465      8544
weighted avg     0.6577    0.6866    0.6367      8544

F1-macro sent:  0.5465415825407566
F1-micro sent:  0.6865636704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9151    0.9721    0.9428    124347
           N     0.8029    0.6610    0.7251     14202
           P     0.8831    0.6984    0.7800     25017

   micro avg     0.9032    0.9032    0.9032    163566
   macro avg     0.8671    0.7772    0.8160    163566
weighted avg     0.9005    0.9032    0.8990    163566

F1-macro tok:  0.8159558994953144
F1-micro tok:  0.9032439504542509
**************************************************
dev_cost_sum: 42063.07958984375
dev_cost_avg: 38.204431961710945
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19164.0
dev_accuracy_tok: 0.9008178997837736
dev_label=O_precision_sent: 0.4909090909090909
dev_label=O_recall_sent: 0.11790393013100436
dev_label=O_f-score_sent: 0.19014084507042253
dev_label=N_precision_sent: 0.6476014760147601
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7237113402061857
dev_label=P_precision_sent: 0.7103174603174603
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7552742616033754
dev_precision_macro_sent: 0.6162760090804372
dev_recall_macro_sent: 0.5814345647937452
dev_f-score_macro_sent: 0.5563754822933279
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.904892234006158
dev_label=O_recall_tok: 0.9793273680962666
dev_label=O_f-score_tok: 0.9406395400527517
dev_label=N_precision_tok: 0.8123652048885693
dev_label=N_recall_tok: 0.6085083467959074
dev_label=N_f-score_tok: 0.6958128078817735
dev_label=P_precision_tok: 0.9228144989339019
dev_label=P_recall_tok: 0.6737235367372354
dev_label=P_f-score_tok: 0.7788375022494151
dev_precision_macro_tok: 0.8800239792762098
dev_recall_macro_tok: 0.7538530838764698
dev_f-score_macro_tok: 0.80509661672798
dev_precision_micro_tok: 0.9008178997837736
dev_recall_micro_tok: 0.9008178997837736
dev_f-score_micro_tok: 0.9008178997837736
dev_time: 4.460381984710693
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4909    0.1179    0.1901       229
           N     0.6476    0.8201    0.7237       428
           P     0.7103    0.8063    0.7553       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6163    0.5814    0.5564      1101
weighted avg     0.6403    0.6685    0.6255      1101

F1-macro sent:  0.5563754822933279
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9049    0.9793    0.9406     16205
           N     0.8124    0.6085    0.6958      1857
           P     0.9228    0.6737    0.7788      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8800    0.7539    0.8051     21274
weighted avg     0.8995    0.9008    0.8948     21274

F1-macro tok:  0.80509661672798
F1-micro tok:  0.9008178997837736
**************************************************
Best epoch: 24
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 302193.0563964844
train_cost_avg: 35.36903749958853
train_count_sent: 8544.0
train_total_correct_sent: 5884.0
train_accuracy_sent: 0.6886704119850188
train_count_tok: 163566.0
train_total_correct_tok: 148075.0
train_accuracy_tok: 0.9052920533607229
train_label=O_precision_sent: 0.4819277108433735
train_label=O_recall_sent: 0.07389162561576355
train_label=O_f-score_sent: 0.12813667912439936
train_label=N_precision_sent: 0.6582961746068998
train_label=N_recall_sent: 0.8474320241691843
train_label=N_f-score_sent: 0.740985338792762
train_label=P_precision_sent: 0.7335151214675261
train_label=P_recall_sent: 0.8196675900277008
train_label=P_f-score_sent: 0.7742019884877028
train_precision_macro_sent: 0.6245796689725998
train_recall_macro_sent: 0.5803304132708829
train_f-score_macro_sent: 0.5477746688016213
train_precision_micro_sent: 0.6886704119850188
train_recall_micro_sent: 0.6886704119850188
train_f-score_micro_sent: 0.6886704119850188
train_label=O_precision_tok: 0.9170712096847599
train_label=O_recall_tok: 0.9723033125045236
train_label=O_f-score_tok: 0.9438799608092653
train_label=N_precision_tok: 0.8083817217874274
train_label=N_recall_tok: 0.6763836079425433
train_label=N_f-score_tok: 0.7365152386428981
train_label=P_precision_tok: 0.8850707915553988
train_label=P_recall_tok: 0.7021625294799536
train_label=P_f-score_tok: 0.7830777460770328
train_precision_macro_tok: 0.8701745743425287
train_recall_macro_tok: 0.7836164833090068
train_f-score_macro_tok: 0.8211576485097322
train_precision_micro_tok: 0.9052920533607229
train_recall_micro_tok: 0.9052920533607229
train_f-score_micro_tok: 0.9052920533607228
train_time: 56.822824478149414
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4819    0.0739    0.1281      1624
           N     0.6583    0.8474    0.7410      3310
           P     0.7335    0.8197    0.7742      3610

   micro avg     0.6887    0.6887    0.6887      8544
   macro avg     0.6246    0.5803    0.5478      8544
weighted avg     0.6566    0.6887    0.6385      8544

F1-macro sent:  0.5477746688016213
F1-micro sent:  0.6886704119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9171    0.9723    0.9439    124347
           N     0.8084    0.6764    0.7365     14202
           P     0.8851    0.7022    0.7831     25017

   micro avg     0.9053    0.9053    0.9053    163566
   macro avg     0.8702    0.7836    0.8212    163566
weighted avg     0.9027    0.9053    0.9013    163566

F1-macro tok:  0.8211576485097322
F1-micro tok:  0.9052920533607228
**************************************************
dev_cost_sum: 41972.058166503906
dev_cost_avg: 38.121760369213355
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19141.0
dev_accuracy_tok: 0.899736767885682
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.033898305084745756
dev_label=N_precision_sent: 0.6003110419906688
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.7208216619981327
dev_label=P_precision_sent: 0.729490022172949
dev_label=P_recall_sent: 0.740990990990991
dev_label=P_f-score_sent: 0.735195530726257
dev_precision_macro_sent: 0.633743211864063
dev_recall_macro_sent: 0.5534424662592642
dev_f-score_macro_sent: 0.4966384992697119
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.9081333103091004
dev_label=O_recall_tok: 0.9735883986423943
dev_label=O_f-score_tok: 0.9397224373101436
dev_label=N_precision_tok: 0.8075552387740556
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6950920245398773
dev_label=P_precision_tok: 0.8931144915932746
dev_label=P_recall_tok: 0.6945828144458281
dev_label=P_f-score_tok: 0.7814360770577933
dev_precision_macro_tok: 0.8696010135588103
dev_recall_macro_tok: 0.7594316895898096
dev_f-score_macro_tok: 0.8054168463026047
dev_precision_micro_tok: 0.899736767885682
dev_recall_micro_tok: 0.899736767885682
dev_f-score_micro_tok: 0.899736767885682
dev_time: 2.3779914379119873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0175    0.0339       229
           N     0.6003    0.9019    0.7208       428
           P     0.7295    0.7410    0.7352       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.6337    0.5534    0.4966      1101
weighted avg     0.6464    0.6530    0.5837      1101

F1-macro sent:  0.4966384992697119
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9736    0.9397     16205
           N     0.8076    0.6101    0.6951      1857
           P     0.8931    0.6946    0.7814      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8696    0.7594    0.8054     21274
weighted avg     0.8971    0.8997    0.8945     21274

F1-macro tok:  0.8054168463026047
F1-micro tok:  0.899736767885682
**************************************************
Best epoch: 24
**************************************************

EPOCH: 27
Learning rate: 1.000000
train_cost_sum: 300843.8483886719
train_cost_avg: 35.211124577325826
train_count_sent: 8544.0
train_total_correct_sent: 5898.0
train_accuracy_sent: 0.6903089887640449
train_count_tok: 163566.0
train_total_correct_tok: 148202.0
train_accuracy_tok: 0.9060684983431765
train_label=O_precision_sent: 0.42402826855123676
train_label=O_recall_sent: 0.07389162561576355
train_label=O_f-score_sent: 0.12585212375458837
train_label=N_precision_sent: 0.6575857209957726
train_label=N_recall_sent: 0.8459214501510574
train_label=N_f-score_sent: 0.7399577167019027
train_label=P_precision_sent: 0.7439420434673994
train_label=P_recall_sent: 0.8249307479224377
train_label=P_f-score_sent: 0.7823459871272823
train_precision_macro_sent: 0.6085186776714696
train_recall_macro_sent: 0.5815812745630863
train_f-score_macro_sent: 0.5493852758612578
train_precision_micro_sent: 0.6903089887640449
train_recall_micro_sent: 0.6903089887640449
train_f-score_micro_sent: 0.6903089887640449
train_label=O_precision_tok: 0.9181244350593615
train_label=O_recall_tok: 0.9720540101490185
train_label=O_f-score_tok: 0.9443198774990429
train_label=N_precision_tok: 0.8142857142857143
train_label=N_recall_tok: 0.678284748626954
train_label=N_f-score_tok: 0.7400891210817454
train_label=P_precision_tok: 0.8811053024645258
train_label=P_recall_tok: 0.7073989687012832
train_label=P_f-score_tok: 0.7847545563389651
train_precision_macro_tok: 0.8711718172698671
train_recall_macro_tok: 0.7859125758257518
train_f-score_macro_tok: 0.8230545183065844
train_precision_micro_tok: 0.9060684983431765
train_recall_micro_tok: 0.9060684983431765
train_f-score_micro_tok: 0.9060684983431765
train_time: 49.6775689125061
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4240    0.0739    0.1259      1624
           N     0.6576    0.8459    0.7400      3310
           P     0.7439    0.8249    0.7823      3610

   micro avg     0.6903    0.6903    0.6903      8544
   macro avg     0.6085    0.5816    0.5494      8544
weighted avg     0.6497    0.6903    0.6411      8544

F1-macro sent:  0.5493852758612578
F1-micro sent:  0.6903089887640449
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9181    0.9721    0.9443    124347
           N     0.8143    0.6783    0.7401     14202
           P     0.8811    0.7074    0.7848     25017

   micro avg     0.9061    0.9061    0.9061    163566
   macro avg     0.8712    0.7859    0.8231    163566
weighted avg     0.9034    0.9061    0.9022    163566

F1-macro tok:  0.8230545183065844
F1-micro tok:  0.9060684983431765
**************************************************
dev_cost_sum: 42031.39929199219
dev_cost_avg: 38.175657849220876
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19139.0
dev_accuracy_tok: 0.8996427564162828
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11067193675889327
dev_label=N_precision_sent: 0.6360544217687075
dev_label=N_recall_sent: 0.8738317757009346
dev_label=N_f-score_sent: 0.7362204724409449
dev_label=P_precision_sent: 0.7177914110429447
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7524115755627009
dev_precision_macro_sent: 0.6457263887149952
dev_recall_macro_sent: 0.5751692291401715
dev_f-score_macro_sent: 0.5331013282541797
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.908797603272455
dev_label=O_recall_tok: 0.9734032705954953
dev_label=O_f-score_tok: 0.9399916572313927
dev_label=N_precision_tok: 0.7796052631578947
dev_label=N_recall_tok: 0.6381260096930533
dev_label=N_f-score_tok: 0.7018063369854901
dev_label=P_precision_tok: 0.9094701710471422
dev_label=P_recall_tok: 0.6787048567870486
dev_label=P_f-score_tok: 0.7773221608129791
dev_precision_macro_tok: 0.865957679159164
dev_recall_macro_tok: 0.763411379025199
dev_f-score_macro_tok: 0.8063733850099539
dev_precision_micro_tok: 0.8996427564162828
dev_recall_micro_tok: 0.8996427564162828
dev_f-score_micro_tok: 0.8996427564162828
dev_time: 2.3495442867279053
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0611    0.1107       229
           N     0.6361    0.8738    0.7362       428
           P     0.7178    0.7905    0.7524       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6457    0.5752    0.5331      1101
weighted avg     0.6581    0.6712    0.6126      1101

F1-macro sent:  0.5331013282541797
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9734    0.9400     16205
           N     0.7796    0.6381    0.7018      1857
           P     0.9095    0.6787    0.7773      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8660    0.7634    0.8064     21274
weighted avg     0.8976    0.8996    0.8946     21274

F1-macro tok:  0.8063733850099539
F1-micro tok:  0.8996427564162828
**************************************************
Best epoch: 24
**************************************************

EPOCH: 28
Learning rate: 1.000000
train_cost_sum: 299367.1371459961
train_cost_avg: 35.03828852364187
train_count_sent: 8544.0
train_total_correct_sent: 5883.0
train_accuracy_sent: 0.6885533707865169
train_count_tok: 163566.0
train_total_correct_tok: 148539.0
train_accuracy_tok: 0.9081288287296871
train_label=O_precision_sent: 0.4745762711864407
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.09328151027207106
train_label=N_precision_sent: 0.6554621848739496
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7395312088490913
train_label=P_precision_sent: 0.7325495958853784
train_label=P_recall_sent: 0.8285318559556787
train_label=P_f-score_sent: 0.7775900168984791
train_precision_macro_sent: 0.6208626839819229
train_recall_macro_sent: 0.5761981208222579
train_f-score_macro_sent: 0.5368009120065471
train_precision_micro_sent: 0.6885533707865169
train_recall_micro_sent: 0.6885533707865169
train_f-score_micro_sent: 0.6885533707865169
train_label=O_precision_tok: 0.9202927771986822
train_label=O_recall_tok: 0.9727214971008549
train_label=O_f-score_tok: 0.9457811070537733
train_label=N_precision_tok: 0.8120989917506874
train_label=N_recall_tok: 0.6862413744543022
train_label=N_f-score_tok: 0.7438842880586192
train_label=P_precision_tok: 0.8859640409257972
train_label=P_recall_tok: 0.713035136107447
train_label=P_f-score_tok: 0.7901486124338332
train_precision_macro_tok: 0.872785269958389
train_recall_macro_tok: 0.7906660025542015
train_f-score_macro_tok: 0.8266046691820752
train_precision_micro_tok: 0.9081288287296871
train_recall_micro_tok: 0.9081288287296871
train_f-score_micro_tok: 0.9081288287296871
train_time: 49.49246168136597
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4746    0.0517    0.0933      1624
           N     0.6555    0.8483    0.7395      3310
           P     0.7325    0.8285    0.7776      3610

   micro avg     0.6886    0.6886    0.6886      8544
   macro avg     0.6209    0.5762    0.5368      8544
weighted avg     0.6537    0.6886    0.6328      8544

F1-macro sent:  0.5368009120065471
F1-micro sent:  0.6885533707865169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9203    0.9727    0.9458    124347
           N     0.8121    0.6862    0.7439     14202
           P     0.8860    0.7130    0.7901     25017

   micro avg     0.9081    0.9081    0.9081    163566
   macro avg     0.8728    0.7907    0.8266    163566
weighted avg     0.9056    0.9081    0.9044    163566

F1-macro tok:  0.8266046691820752
F1-micro tok:  0.9081288287296871
**************************************************
dev_cost_sum: 41971.75408935547
dev_cost_avg: 38.12148418651723
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19179.0
dev_accuracy_tok: 0.9015229858042682
dev_label=O_precision_sent: 0.3793103448275862
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08527131782945736
dev_label=N_precision_sent: 0.6336805555555556
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7270916334661354
dev_label=P_precision_sent: 0.7157258064516129
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7553191489361701
dev_precision_macro_sent: 0.5762389022782516
dev_recall_macro_sent: 0.5667960741217077
dev_f-score_macro_sent: 0.5225607000772543
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9055850305208512
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9411276456987016
dev_label=N_precision_tok: 0.8183807439824945
dev_label=N_recall_tok: 0.6042003231017771
dev_label=N_f-score_tok: 0.6951672862453531
dev_label=P_precision_tok: 0.9195450716090986
dev_label=P_recall_tok: 0.6796388542963886
dev_label=P_f-score_tok: 0.7815968492660222
dev_precision_macro_tok: 0.8811702820374814
dev_recall_macro_tok: 0.7544711276300992
dev_f-score_macro_tok: 0.8059639270700257
dev_precision_micro_tok: 0.9015229858042682
dev_recall_micro_tok: 0.9015229858042682
dev_f-score_micro_tok: 0.9015229858042682
dev_time: 2.347384452819824
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3793    0.0480    0.0853       229
           N     0.6337    0.8528    0.7271       428
           P     0.7157    0.7995    0.7553       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.5762    0.5668    0.5226      1101
weighted avg     0.6139    0.6639    0.6050      1101

F1-macro sent:  0.5225607000772543
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9796    0.9411     16205
           N     0.8184    0.6042    0.6952      1857
           P     0.9195    0.6796    0.7816      3212

   micro avg     0.9015    0.9015    0.9015     21274
   macro avg     0.8812    0.7545    0.8060     21274
weighted avg     0.9001    0.9015    0.8956     21274

F1-macro tok:  0.8059639270700257
F1-micro tok:  0.9015229858042682
**************************************************
Best epoch: 24
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 297774.3167114258
train_cost_avg: 34.85186291098148
train_count_sent: 8544.0
train_total_correct_sent: 5867.0
train_accuracy_sent: 0.6866807116104869
train_count_tok: 163566.0
train_total_correct_tok: 148818.0
train_accuracy_tok: 0.9098345621950772
train_label=O_precision_sent: 0.4620253164556962
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.15051546391752577
train_label=N_precision_sent: 0.6657622101628021
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.7330255296034764
train_label=P_precision_sent: 0.7240057498802108
train_label=P_recall_sent: 0.8371191135734072
train_label=P_f-score_sent: 0.776464542651593
train_precision_macro_sent: 0.6172644254995697
train_recall_macro_sent: 0.5808094821302713
train_f-score_macro_sent: 0.5533351787241984
train_precision_micro_sent: 0.6866807116104869
train_recall_micro_sent: 0.6866807116104869
train_f-score_micro_sent: 0.6866807116104869
train_label=O_precision_tok: 0.9218338082684424
train_label=O_recall_tok: 0.972978841467828
train_label=O_f-score_tok: 0.9467160681239313
train_label=N_precision_tok: 0.8185524126455906
train_label=N_recall_tok: 0.6927897479228278
train_label=N_f-score_tok: 0.7504385630386697
train_label=P_precision_tok: 0.8863054187192119
train_label=P_recall_tok: 0.7191909501538953
train_label=P_f-score_tok: 0.7940507977138822
train_precision_macro_tok: 0.8755638798777484
train_recall_macro_tok: 0.794986513181517
train_f-score_macro_tok: 0.8304018096254945
train_precision_micro_tok: 0.9098345621950772
train_recall_micro_tok: 0.9098345621950772
train_f-score_micro_tok: 0.9098345621950772
train_time: 49.58666229248047
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4620    0.0899    0.1505      1624
           N     0.6658    0.8154    0.7330      3310
           P     0.7240    0.8371    0.7765      3610

   micro avg     0.6867    0.6867    0.6867      8544
   macro avg     0.6173    0.5808    0.5533      8544
weighted avg     0.6516    0.6867    0.6407      8544

F1-macro sent:  0.5533351787241984
F1-micro sent:  0.6866807116104869
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9218    0.9730    0.9467    124347
           N     0.8186    0.6928    0.7504     14202
           P     0.8863    0.7192    0.7941     25017

   micro avg     0.9098    0.9098    0.9098    163566
   macro avg     0.8756    0.7950    0.8304    163566
weighted avg     0.9074    0.9098    0.9063    163566

F1-macro tok:  0.8304018096254945
F1-micro tok:  0.9098345621950772
**************************************************
dev_cost_sum: 41870.79962158203
dev_cost_avg: 38.02979075529703
dev_count_sent: 1101.0
dev_total_correct_sent: 747.0
dev_accuracy_sent: 0.6784741144414169
dev_count_tok: 21274.0
dev_total_correct_tok: 19132.0
dev_accuracy_tok: 0.8993137162733853
dev_label=O_precision_sent: 0.5588235294117647
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14448669201520914
dev_label=N_precision_sent: 0.6642201834862386
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7440904419321687
dev_label=P_precision_sent: 0.7011494252873564
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7577639751552796
dev_precision_macro_sent: 0.6413977127284533
dev_recall_macro_sent: 0.5843627163873665
dev_f-score_macro_sent: 0.5487803697008858
dev_precision_micro_sent: 0.6784741144414169
dev_recall_micro_sent: 0.6784741144414169
dev_f-score_micro_sent: 0.6784741144414169
dev_label=O_precision_tok: 0.9149967868201203
dev_label=O_recall_tok: 0.966491823511262
dev_label=O_f-score_tok: 0.9400396134685792
dev_label=N_precision_tok: 0.7699742268041238
dev_label=N_recall_tok: 0.6435110393107162
dev_label=N_f-score_tok: 0.7010853622763272
dev_label=P_precision_tok: 0.8733205374280231
dev_label=P_recall_tok: 0.7082814445828145
dev_label=P_f-score_tok: 0.7821901323706378
dev_precision_macro_tok: 0.8527638503507556
dev_recall_macro_tok: 0.7727614358015975
dev_f-score_macro_tok: 0.8077717027051814
dev_precision_micro_tok: 0.8993137162733853
dev_recall_micro_tok: 0.8993137162733853
dev_f-score_micro_tok: 0.8993137162733853
dev_time: 2.3573427200317383
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5588    0.0830    0.1445       229
           N     0.6642    0.8458    0.7441       428
           P     0.7011    0.8243    0.7578       444

   micro avg     0.6785    0.6785    0.6785      1101
   macro avg     0.6414    0.5844    0.5488      1101
weighted avg     0.6572    0.6785    0.6249      1101

F1-macro sent:  0.5487803697008858
F1-micro sent:  0.6784741144414169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9150    0.9665    0.9400     16205
           N     0.7700    0.6435    0.7011      1857
           P     0.8733    0.7083    0.7822      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8528    0.7728    0.8078     21274
weighted avg     0.8960    0.8993    0.8953     21274

F1-macro tok:  0.8077717027051814
F1-micro tok:  0.8993137162733853
**************************************************
Best epoch: 24
**************************************************

EPOCH: 30
Learning rate: 0.810000
train_cost_sum: 295563.5064086914
train_cost_avg: 34.59310702348916
train_count_sent: 8544.0
train_total_correct_sent: 5964.0
train_accuracy_sent: 0.6980337078651685
train_count_tok: 163566.0
train_total_correct_tok: 149293.0
train_accuracy_tok: 0.912738588704254
train_label=O_precision_sent: 0.48872180451127817
train_label=O_recall_sent: 0.08004926108374384
train_label=O_f-score_sent: 0.13756613756613756
train_label=N_precision_sent: 0.659741458910434
train_label=N_recall_sent: 0.8634441087613293
train_label=N_f-score_sent: 0.7479717351478671
train_label=P_precision_sent: 0.754181449569184
train_label=P_recall_sent: 0.824376731301939
train_label=P_f-score_sent: 0.7877183695076759
train_precision_macro_sent: 0.6342149043302987
train_recall_macro_sent: 0.5892900337156707
train_f-score_macro_sent: 0.5577520807405602
train_precision_micro_sent: 0.6980337078651685
train_recall_micro_sent: 0.6980337078651685
train_f-score_micro_sent: 0.6980337078651685
train_label=O_precision_tok: 0.9253248243882283
train_label=O_recall_tok: 0.9724963207797535
train_label=O_f-score_tok: 0.9483243344978886
train_label=N_precision_tok: 0.8184332546977955
train_label=N_recall_tok: 0.7084213491057597
train_label=N_f-score_tok: 0.7594640498207208
train_label=P_precision_tok: 0.889153349200952
train_label=P_recall_tok: 0.7317024423392093
train_label=P_f-score_tok: 0.8027804578545742
train_precision_macro_tok: 0.8776371427623252
train_recall_macro_tok: 0.8042067040749075
train_f-score_macro_tok: 0.8368562807243944
train_precision_micro_tok: 0.912738588704254
train_recall_micro_tok: 0.912738588704254
train_f-score_micro_tok: 0.912738588704254
train_time: 49.57247543334961
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4887    0.0800    0.1376      1624
           N     0.6597    0.8634    0.7480      3310
           P     0.7542    0.8244    0.7877      3610

   micro avg     0.6980    0.6980    0.6980      8544
   macro avg     0.6342    0.5893    0.5578      8544
weighted avg     0.6671    0.6980    0.6487      8544

F1-macro sent:  0.5577520807405602
F1-micro sent:  0.6980337078651685
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9253    0.9725    0.9483    124347
           N     0.8184    0.7084    0.7595     14202
           P     0.8892    0.7317    0.8028     25017

   micro avg     0.9127    0.9127    0.9127    163566
   macro avg     0.8776    0.8042    0.8369    163566
weighted avg     0.9105    0.9127    0.9097    163566

F1-macro tok:  0.8368562807243944
F1-micro tok:  0.912738588704254
**************************************************
dev_cost_sum: 42072.35998535156
dev_cost_avg: 38.21286102211768
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19165.0
dev_accuracy_tok: 0.9008649055184732
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.6419965576592083
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7393458870168483
dev_label=P_precision_sent: 0.7049504950495049
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.750263435194942
dev_precision_macro_sent: 0.6934267953473489
dev_recall_macro_sent: 0.5737773544674741
dev_f-score_macro_sent: 0.5265910855460066
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9119879483168202
dev_label=O_recall_tok: 0.9713051527306387
dev_label=O_f-score_tok: 0.9407124073631363
dev_label=N_precision_tok: 0.8177905308464849
dev_label=N_recall_tok: 0.6138933764135702
dev_label=N_f-score_tok: 0.7013226699477084
dev_label=P_precision_tok: 0.871804654711942
dev_label=P_recall_tok: 0.7113947696139477
dev_label=P_f-score_tok: 0.7834733413337905
dev_precision_macro_tok: 0.8671943779584157
dev_recall_macro_tok: 0.7655310995860521
dev_f-score_macro_tok: 0.8085028062148784
dev_precision_micro_tok: 0.9008649055184732
dev_recall_micro_tok: 0.9008649055184732
dev_f-score_micro_tok: 0.9008649055184732
dev_time: 2.344407796859741
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.6420    0.8715    0.7393       428
           P     0.7050    0.8018    0.7503       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6934    0.5738    0.5266      1101
weighted avg     0.6864    0.6721    0.6087      1101

F1-macro sent:  0.5265910855460066
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9120    0.9713    0.9407     16205
           N     0.8178    0.6139    0.7013      1857
           P     0.8718    0.7114    0.7835      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8672    0.7655    0.8085     21274
weighted avg     0.8977    0.9009    0.8961     21274

F1-macro tok:  0.8085028062148784
F1-micro tok:  0.9008649055184732
**************************************************
Best epoch: 30
**************************************************

EPOCH: 31
Learning rate: 0.810000
train_cost_sum: 294485.1053466797
train_cost_avg: 34.46688967072562
train_count_sent: 8544.0
train_total_correct_sent: 5974.0
train_accuracy_sent: 0.6992041198501873
train_count_tok: 163566.0
train_total_correct_tok: 149701.0
train_accuracy_tok: 0.9152329946321363
train_label=O_precision_sent: 0.508130081300813
train_label=O_recall_sent: 0.0769704433497537
train_label=O_f-score_sent: 0.13368983957219255
train_label=N_precision_sent: 0.6643258426966292
train_label=N_recall_sent: 0.8574018126888218
train_label=N_f-score_sent: 0.748615141123714
train_label=P_precision_sent: 0.7478887232985594
train_label=P_recall_sent: 0.8340720221606648
train_label=P_f-score_sent: 0.7886327920377161
train_precision_macro_sent: 0.6401148824320005
train_recall_macro_sent: 0.5894814260664134
train_f-score_macro_sent: 0.5569792575778741
train_precision_micro_sent: 0.6992041198501873
train_recall_micro_sent: 0.6992041198501873
train_f-score_micro_sent: 0.6992041198501873
train_label=O_precision_tok: 0.9273826490736058
train_label=O_recall_tok: 0.9733166059494801
train_label=O_f-score_tok: 0.9497945874680699
train_label=N_precision_tok: 0.8294055288265514
train_label=N_recall_tok: 0.7161667370792846
train_label=N_f-score_tok: 0.7686378235405252
train_label=P_precision_tok: 0.8895994614607876
train_label=P_recall_tok: 0.7395371147619618
train_label=P_f-score_tok: 0.8076570480639106
train_precision_macro_tok: 0.8821292131203148
train_recall_macro_tok: 0.8096734859302422
train_f-score_macro_tok: 0.8420298196908352
train_precision_micro_tok: 0.9152329946321363
train_recall_micro_tok: 0.9152329946321363
train_f-score_micro_tok: 0.9152329946321363
train_time: 49.71538996696472
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5081    0.0770    0.1337      1624
           N     0.6643    0.8574    0.7486      3310
           P     0.7479    0.8341    0.7886      3610

   micro avg     0.6992    0.6992    0.6992      8544
   macro avg     0.6401    0.5895    0.5570      8544
weighted avg     0.6699    0.6992    0.6486      8544

F1-macro sent:  0.5569792575778741
F1-micro sent:  0.6992041198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9274    0.9733    0.9498    124347
           N     0.8294    0.7162    0.7686     14202
           P     0.8896    0.7395    0.8077     25017

   micro avg     0.9152    0.9152    0.9152    163566
   macro avg     0.8821    0.8097    0.8420    163566
weighted avg     0.9131    0.9152    0.9123    163566

F1-macro tok:  0.8420298196908352
F1-micro tok:  0.9152329946321363
**************************************************
dev_cost_sum: 41960.03747558594
dev_cost_avg: 38.110842393811026
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19175.0
dev_accuracy_tok: 0.9013349628654695
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6746987951807228
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7257019438444924
dev_label=P_precision_sent: 0.657672849915683
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7521697203471552
dev_precision_macro_sent: 0.6774572150321353
dev_recall_macro_sent: 0.5646642643132869
dev_f-score_macro_sent: 0.5121496900164627
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9083027101515847
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.9410190059784064
dev_label=N_precision_tok: 0.8224023581429624
dev_label=N_recall_tok: 0.6009693053311793
dev_label=N_f-score_tok: 0.6944617299315493
dev_label=P_precision_tok: 0.895641743302679
dev_label=P_recall_tok: 0.6973848069738481
dev_label=P_f-score_tok: 0.7841764396989324
dev_precision_macro_tok: 0.8754489371990753
dev_recall_macro_tok: 0.7581781012013363
dev_f-score_macro_tok: 0.8065523918696295
dev_precision_micro_tok: 0.9013349628654695
dev_recall_micro_tok: 0.9013349628654695
dev_f-score_micro_tok: 0.9013349628654695
dev_time: 2.3438663482666016
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6747    0.7850    0.7257       428
           P     0.6577    0.8784    0.7522       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6775    0.5647    0.5121      1101
weighted avg     0.6731    0.6658    0.5976      1101

F1-macro sent:  0.5121496900164627
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9762    0.9410     16205
           N     0.8224    0.6010    0.6945      1857
           P     0.8956    0.6974    0.7842      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8754    0.7582    0.8066     21274
weighted avg     0.8989    0.9013    0.8958     21274

F1-macro tok:  0.8065523918696295
F1-micro tok:  0.9013349628654695
**************************************************
Best epoch: 30
**************************************************

EPOCH: 32
Learning rate: 0.810000
train_cost_sum: 293393.8731689453
train_cost_avg: 34.33917054879978
train_count_sent: 8544.0
train_total_correct_sent: 6039.0
train_accuracy_sent: 0.706811797752809
train_count_tok: 163566.0
train_total_correct_tok: 149688.0
train_accuracy_tok: 0.9151535160118851
train_label=O_precision_sent: 0.58
train_label=O_recall_sent: 0.07142857142857142
train_label=O_f-score_sent: 0.12719298245614036
train_label=N_precision_sent: 0.680622009569378
train_label=N_recall_sent: 0.8595166163141994
train_label=N_f-score_sent: 0.7596795727636849
train_label=P_precision_sent: 0.739193083573487
train_label=P_recall_sent: 0.8526315789473684
train_label=P_f-score_sent: 0.7918703370208386
train_precision_macro_sent: 0.6666050310476216
train_recall_macro_sent: 0.594525588896713
train_f-score_macro_sent: 0.5595809640802213
train_precision_micro_sent: 0.706811797752809
train_recall_micro_sent: 0.706811797752809
train_f-score_micro_sent: 0.706811797752809
train_label=O_precision_tok: 0.9277560414269275
train_label=O_recall_tok: 0.9725445728485609
train_label=O_f-score_tok: 0.9496224926088647
train_label=N_precision_tok: 0.8292226292226292
train_label=N_recall_tok: 0.7172933389663427
train_label=N_f-score_tok: 0.7692075357722656
train_label=P_precision_tok: 0.8871052505852564
train_label=P_recall_tok: 0.7422152936003518
train_label=P_f-score_tok: 0.8082179855488815
train_precision_macro_tok: 0.881361307078271
train_recall_macro_tok: 0.810684401805085
train_f-score_macro_tok: 0.8423493379766707
train_precision_micro_tok: 0.9151535160118851
train_recall_micro_tok: 0.9151535160118851
train_f-score_micro_tok: 0.9151535160118851
train_time: 49.63270354270935
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5800    0.0714    0.1272      1624
           N     0.6806    0.8595    0.7597      3310
           P     0.7392    0.8526    0.7919      3610

   micro avg     0.7068    0.7068    0.7068      8544
   macro avg     0.6666    0.5945    0.5596      8544
weighted avg     0.6862    0.7068    0.6531      8544

F1-macro sent:  0.5595809640802213
F1-micro sent:  0.706811797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9278    0.9725    0.9496    124347
           N     0.8292    0.7173    0.7692     14202
           P     0.8871    0.7422    0.8082     25017

   micro avg     0.9152    0.9152    0.9152    163566
   macro avg     0.8814    0.8107    0.8423    163566
weighted avg     0.9130    0.9152    0.9123    163566

F1-macro tok:  0.8423493379766707
F1-micro tok:  0.9151535160118851
**************************************************
dev_cost_sum: 42009.8837890625
dev_cost_avg: 38.15611606636013
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19168.0
dev_accuracy_tok: 0.9010059227225722
dev_label=O_precision_sent: 0.8235294117647058
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.1138211382113821
dev_label=N_precision_sent: 0.6880165289256198
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7302631578947367
dev_label=P_precision_sent: 0.6516666666666666
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.7490421455938697
dev_precision_macro_sent: 0.7210708691189973
dev_recall_macro_sent: 0.5732677949957466
dev_f-score_macro_sent: 0.5310421472333294
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9122318840579711
dev_label=O_recall_tok: 0.9710583153347733
dev_label=O_f-score_tok: 0.9407263488267823
dev_label=N_precision_tok: 0.8020833333333334
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.7006369426751593
dev_label=P_precision_tok: 0.8811919504643962
dev_label=P_recall_tok: 0.708904109589041
dev_label=P_f-score_tok: 0.7857142857142856
dev_precision_macro_tok: 0.8651690559519003
dev_recall_macro_tok: 0.7673111152546263
dev_f-score_macro_tok: 0.8090258590720758
dev_precision_micro_tok: 0.9010059227225722
dev_recall_micro_tok: 0.9010059227225722
dev_f-score_micro_tok: 0.9010059227225722
dev_time: 2.349524736404419
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8235    0.0611    0.1138       229
           N     0.6880    0.7780    0.7303       428
           P     0.6517    0.8806    0.7490       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.7211    0.5733    0.5310      1101
weighted avg     0.7015    0.6703    0.6096      1101

F1-macro sent:  0.5310421472333294
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9122    0.9711    0.9407     16205
           N     0.8021    0.6220    0.7006      1857
           P     0.8812    0.7089    0.7857      3212

   micro avg     0.9010    0.9010    0.9010     21274
   macro avg     0.8652    0.7673    0.8090     21274
weighted avg     0.8979    0.9010    0.8964     21274

F1-macro tok:  0.8090258590720758
F1-micro tok:  0.9010059227225722
**************************************************
Best epoch: 32
**************************************************

EPOCH: 33
Learning rate: 0.810000
train_cost_sum: 292512.220703125
train_cost_avg: 34.23598088753804
train_count_sent: 8544.0
train_total_correct_sent: 6052.0
train_accuracy_sent: 0.7083333333333334
train_count_tok: 163566.0
train_total_correct_tok: 150056.0
train_accuracy_tok: 0.9174033723389946
train_label=O_precision_sent: 0.5229681978798587
train_label=O_recall_sent: 0.09113300492610837
train_label=O_f-score_sent: 0.15521761929732564
train_label=N_precision_sent: 0.6866859623733719
train_label=N_recall_sent: 0.8601208459214501
train_label=N_f-score_sent: 0.7636802575107295
train_label=P_precision_sent: 0.7428918590522479
train_label=P_recall_sent: 0.846814404432133
train_label=P_f-score_sent: 0.7914563106796116
train_precision_macro_sent: 0.6508486731018261
train_recall_macro_sent: 0.5993560850932305
train_f-score_macro_sent: 0.5701180624958889
train_precision_micro_sent: 0.7083333333333334
train_recall_micro_sent: 0.7083333333333334
train_f-score_micro_sent: 0.7083333333333334
train_label=O_precision_tok: 0.9298570550261297
train_label=O_recall_tok: 0.9730270935366354
train_label=O_f-score_tok: 0.9509523828237061
train_label=N_precision_tok: 0.8293058709049627
train_label=N_recall_tok: 0.7201098436839881
train_label=N_f-score_tok: 0.7708600286424964
train_label=P_precision_tok: 0.8921095008051529
train_label=P_recall_tok: 0.7529280089539113
train_label=P_f-score_tok: 0.8166308989616528
train_precision_macro_tok: 0.8837574755787484
train_recall_macro_tok: 0.8153549820581784
train_f-score_macro_tok: 0.8461477701426183
train_precision_micro_tok: 0.9174033723389946
train_recall_micro_tok: 0.9174033723389946
train_f-score_micro_tok: 0.9174033723389946
train_time: 49.72721457481384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5230    0.0911    0.1552      1624
           N     0.6867    0.8601    0.7637      3310
           P     0.7429    0.8468    0.7915      3610

   micro avg     0.7083    0.7083    0.7083      8544
   macro avg     0.6508    0.5994    0.5701      8544
weighted avg     0.6793    0.7083    0.6598      8544

F1-macro sent:  0.5701180624958889
F1-micro sent:  0.7083333333333334
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9299    0.9730    0.9510    124347
           N     0.8293    0.7201    0.7709     14202
           P     0.8921    0.7529    0.8166     25017

   micro avg     0.9174    0.9174    0.9174    163566
   macro avg     0.8838    0.8154    0.8461    163566
weighted avg     0.9154    0.9174    0.9148    163566

F1-macro tok:  0.8461477701426183
F1-micro tok:  0.9174033723389946
**************************************************
dev_cost_sum: 41972.200256347656
dev_cost_avg: 38.12188942447562
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19197.0
dev_accuracy_tok: 0.9023690890288615
dev_label=O_precision_sent: 0.7058823529411765
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0975609756097561
dev_label=N_precision_sent: 0.6772277227722773
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7331189710610932
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7546432062561094
dev_precision_macro_sent: 0.6832589141267068
dev_recall_macro_sent: 0.5736121788850026
dev_f-score_macro_sent: 0.5284410509756529
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9123466790094885
dev_label=O_recall_tok: 0.9730947238506634
dev_label=O_f-score_tok: 0.9417420645585117
dev_label=N_precision_tok: 0.8117564730580826
dev_label=N_recall_tok: 0.624663435648896
dev_label=N_f-score_tok: 0.7060255629945222
dev_label=P_precision_tok: 0.8855915657946115
dev_label=P_recall_tok: 0.7061021170610212
dev_label=P_f-score_tok: 0.7857266585830591
dev_precision_macro_tok: 0.8698982392873943
dev_recall_macro_tok: 0.7679534255201936
dev_f-score_macro_tok: 0.8111647620453644
dev_precision_micro_tok: 0.9023690890288615
dev_recall_micro_tok: 0.9023690890288615
dev_f-score_micro_tok: 0.9023690890288615
dev_time: 2.3547234535217285
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7059    0.0524    0.0976       229
           N     0.6772    0.7991    0.7331       428
           P     0.6667    0.8694    0.7546       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6833    0.5736    0.5284      1101
weighted avg     0.6789    0.6721    0.6096      1101

F1-macro sent:  0.5284410509756529
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9731    0.9417     16205
           N     0.8118    0.6247    0.7060      1857
           P     0.8856    0.7061    0.7857      3212

   micro avg     0.9024    0.9024    0.9024     21274
   macro avg     0.8699    0.7680    0.8112     21274
weighted avg     0.8995    0.9024    0.8976     21274

F1-macro tok:  0.8111647620453644
F1-micro tok:  0.9023690890288615
**************************************************
Best epoch: 33
**************************************************

EPOCH: 34
Learning rate: 0.810000
train_cost_sum: 291403.28411865234
train_cost_avg: 34.10618962062878
train_count_sent: 8544.0
train_total_correct_sent: 5991.0
train_accuracy_sent: 0.7011938202247191
train_count_tok: 163566.0
train_total_correct_tok: 150206.0
train_accuracy_tok: 0.9183204333418926
train_label=O_precision_sent: 0.46524064171123
train_label=O_recall_sent: 0.10714285714285714
train_label=O_f-score_sent: 0.17417417417417416
train_label=N_precision_sent: 0.6832880770180202
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.7520717293845945
train_label=P_precision_sent: 0.7402282107307598
train_label=P_recall_sent: 0.8445983379501385
train_label=P_f-score_sent: 0.7889765817052659
train_precision_macro_sent: 0.6295856431533366
train_recall_macro_sent: 0.5959983238426804
train_f-score_macro_sent: 0.5717408284213449
train_precision_micro_sent: 0.7011938202247191
train_recall_micro_sent: 0.7011938202247191
train_f-score_micro_sent: 0.7011938202247191
train_label=O_precision_tok: 0.931202304037456
train_label=O_recall_tok: 0.9724802367568176
train_label=O_f-score_tok: 0.9513937515243542
train_label=N_precision_tok: 0.8340371285156561
train_label=N_recall_tok: 0.7370792846078017
train_label=N_f-score_tok: 0.7825664411467873
train_label=P_precision_tok: 0.8892512762336926
train_label=P_recall_tok: 0.7520086341287924
train_label=P_f-score_tok: 0.8148918198947437
train_precision_macro_tok: 0.8848302362622683
train_recall_macro_tok: 0.8205227184978039
train_f-score_macro_tok: 0.8496173375219618
train_precision_micro_tok: 0.9183204333418926
train_recall_micro_tok: 0.9183204333418926
train_f-score_micro_tok: 0.9183204333418926
train_time: 49.55842351913452
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4652    0.1071    0.1742      1624
           N     0.6833    0.8363    0.7521      3310
           P     0.7402    0.8446    0.7890      3610

   micro avg     0.7012    0.7012    0.7012      8544
   macro avg     0.6296    0.5960    0.5717      8544
weighted avg     0.6659    0.7012    0.6578      8544

F1-macro sent:  0.5717408284213449
F1-micro sent:  0.7011938202247191
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9312    0.9725    0.9514    124347
           N     0.8340    0.7371    0.7826     14202
           P     0.8893    0.7520    0.8149     25017

   micro avg     0.9183    0.9183    0.9183    163566
   macro avg     0.8848    0.8205    0.8496    163566
weighted avg     0.9163    0.9183    0.9159    163566

F1-macro tok:  0.8496173375219618
F1-micro tok:  0.9183204333418926
**************************************************
dev_cost_sum: 41899.62487792969
dev_cost_avg: 38.055971732906166
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19185.0
dev_accuracy_tok: 0.9018050202124659
dev_label=O_precision_sent: 0.4642857142857143
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10116731517509726
dev_label=N_precision_sent: 0.6544117647058824
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7325102880658436
dev_label=P_precision_sent: 0.6975425330812854
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7584789311408018
dev_precision_macro_sent: 0.6054133373576274
dev_recall_macro_sent: 0.5732084469892085
dev_f-score_macro_sent: 0.5307188447939142
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9135967460778617
dev_label=O_recall_tok: 0.9702560937982104
dev_label=O_f-score_tok: 0.9410743677988926
dev_label=N_precision_tok: 0.8060315284441398
dev_label=N_recall_tok: 0.6332794830371568
dev_label=N_f-score_tok: 0.7092882991556092
dev_label=P_precision_tok: 0.8775431861804223
dev_label=P_recall_tok: 0.711706102117061
dev_label=P_f-score_tok: 0.7859721505930892
dev_precision_macro_tok: 0.8657238202341412
dev_recall_macro_tok: 0.7717472263174759
dev_f-score_macro_tok: 0.812111605849197
dev_precision_micro_tok: 0.9018050202124659
dev_recall_micro_tok: 0.9018050202124659
dev_f-score_micro_tok: 0.9018050202124659
dev_time: 2.3667778968811035
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4643    0.0568    0.1012       229
           N     0.6544    0.8318    0.7325       428
           P     0.6975    0.8311    0.7585       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6054    0.5732    0.5307      1101
weighted avg     0.6323    0.6703    0.6117      1101

F1-macro sent:  0.5307188447939142
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9703    0.9411     16205
           N     0.8060    0.6333    0.7093      1857
           P     0.8775    0.7117    0.7860      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8657    0.7717    0.8121     21274
weighted avg     0.8988    0.9018    0.8974     21274

F1-macro tok:  0.812111605849197
F1-micro tok:  0.9018050202124659
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 0.810000
train_cost_sum: 290331.71856689453
train_cost_avg: 33.980772304177734
train_count_sent: 8544.0
train_total_correct_sent: 6049.0
train_accuracy_sent: 0.7079822097378277
train_count_tok: 163566.0
train_total_correct_tok: 150353.0
train_accuracy_tok: 0.9192191531247326
train_label=O_precision_sent: 0.4463768115942029
train_label=O_recall_sent: 0.09482758620689655
train_label=O_f-score_sent: 0.1564245810055866
train_label=N_precision_sent: 0.6813842482100239
train_label=N_recall_sent: 0.8625377643504532
train_label=N_f-score_sent: 0.7613333333333333
train_label=P_precision_sent: 0.7582938388625592
train_label=P_recall_sent: 0.8421052631578947
train_label=P_f-score_sent: 0.7980049875311721
train_precision_macro_sent: 0.628684966222262
train_recall_macro_sent: 0.5998235379050815
train_f-score_macro_sent: 0.5719209672900306
train_precision_micro_sent: 0.7079822097378277
train_recall_micro_sent: 0.7079822097378277
train_f-score_micro_sent: 0.7079822097378278
train_label=O_precision_tok: 0.9325766454876319
train_label=O_recall_tok: 0.9726330349747079
train_label=O_f-score_tok: 0.9521837542070974
train_label=N_precision_tok: 0.8332534738859607
train_label=N_recall_tok: 0.7346852555978032
train_label=N_f-score_tok: 0.780871127076785
train_label=P_precision_tok: 0.8885090840981458
train_label=P_recall_tok: 0.7584842307231083
train_label=P_f-score_tok: 0.8183641343022879
train_precision_macro_tok: 0.8847797344905795
train_recall_macro_tok: 0.8219341737652064
train_f-score_macro_tok: 0.85047300519539
train_precision_micro_tok: 0.9192191531247326
train_recall_micro_tok: 0.9192191531247326
train_f-score_micro_tok: 0.9192191531247326
train_time: 49.38933968544006
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4464    0.0948    0.1564      1624
           N     0.6814    0.8625    0.7613      3310
           P     0.7583    0.8421    0.7980      3610

   micro avg     0.7080    0.7080    0.7080      8544
   macro avg     0.6287    0.5998    0.5719      8544
weighted avg     0.6692    0.7080    0.6618      8544

F1-macro sent:  0.5719209672900306
F1-micro sent:  0.7079822097378278
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9326    0.9726    0.9522    124347
           N     0.8333    0.7347    0.7809     14202
           P     0.8885    0.7585    0.8184     25017

   micro avg     0.9192    0.9192    0.9192    163566
   macro avg     0.8848    0.8219    0.8505    163566
weighted avg     0.9172    0.9192    0.9168    163566

F1-macro tok:  0.85047300519539
F1-micro tok:  0.9192191531247326
**************************************************
dev_cost_sum: 41940.72644042969
dev_cost_avg: 38.093302852343044
dev_count_sent: 1101.0
dev_total_correct_sent: 745.0
dev_accuracy_sent: 0.6766575840145322
dev_count_tok: 21274.0
dev_total_correct_tok: 19184.0
dev_accuracy_tok: 0.9017580144777663
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.6440972222222222
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7390438247011952
dev_label=P_precision_sent: 0.7140077821011673
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7661795407098121
dev_precision_macro_sent: 0.6648228802290087
dev_recall_macro_sent: 0.5746555640242127
dev_f-score_macro_sent: 0.5211855662481136
dev_precision_micro_sent: 0.6766575840145322
dev_recall_micro_sent: 0.6766575840145322
dev_f-score_micro_sent: 0.6766575840145322
dev_label=O_precision_tok: 0.9162820587719811
dev_label=O_recall_tok: 0.967849429188522
dev_label=O_f-score_tok: 0.9413600624212232
dev_label=N_precision_tok: 0.7970627503337784
dev_label=N_recall_tok: 0.6429725363489499
dev_label=N_f-score_tok: 0.7117734724292101
dev_label=P_precision_tok: 0.8672433245581046
dev_label=P_recall_tok: 0.7179327521793275
dev_label=P_f-score_tok: 0.7855561233180038
dev_precision_macro_tok: 0.8601960445546214
dev_recall_macro_tok: 0.7762515725722664
dev_f-score_macro_tok: 0.8128965527228124
dev_precision_micro_tok: 0.9017580144777663
dev_recall_micro_tok: 0.9017580144777663
dev_f-score_micro_tok: 0.9017580144777663
dev_time: 2.3722550868988037
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.6441    0.8668    0.7390       428
           P     0.7140    0.8266    0.7662       444

   micro avg     0.6767    0.6767    0.6767      1101
   macro avg     0.6648    0.5747    0.5212      1101
weighted avg     0.6707    0.6767    0.6084      1101

F1-macro sent:  0.5211855662481136
F1-micro sent:  0.6766575840145322
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9163    0.9678    0.9414     16205
           N     0.7971    0.6430    0.7118      1857
           P     0.8672    0.7179    0.7856      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8602    0.7763    0.8129     21274
weighted avg     0.8985    0.9018    0.8978     21274

F1-macro tok:  0.8128965527228124
F1-micro tok:  0.9017580144777663
**************************************************
Best epoch: 35
**************************************************

EPOCH: 36
Learning rate: 0.810000
train_cost_sum: 289294.61822509766
train_cost_avg: 33.85938883720712
train_count_sent: 8544.0
train_total_correct_sent: 6080.0
train_accuracy_sent: 0.7116104868913857
train_count_tok: 163566.0
train_total_correct_tok: 150597.0
train_accuracy_tok: 0.9207109056894465
train_label=O_precision_sent: 0.4860050890585242
train_label=O_recall_sent: 0.11761083743842364
train_label=O_f-score_sent: 0.1893901834407536
train_label=N_precision_sent: 0.6852119460500964
train_label=N_recall_sent: 0.8595166163141994
train_label=N_f-score_sent: 0.7625301527740552
train_label=P_precision_sent: 0.7611902975743936
train_label=P_recall_sent: 0.843213296398892
train_label=P_f-score_sent: 0.8001051386515967
train_precision_macro_sent: 0.6441357775610047
train_recall_macro_sent: 0.606780250050505
train_f-score_macro_sent: 0.5840084916221352
train_precision_micro_sent: 0.7116104868913857
train_recall_micro_sent: 0.7116104868913857
train_f-score_micro_sent: 0.7116104868913858
train_label=O_precision_tok: 0.9340914705700698
train_label=O_recall_tok: 0.9730110095136996
train_label=O_f-score_tok: 0.953154111275234
train_label=N_precision_tok: 0.8372241765270227
train_label=N_recall_tok: 0.7373609350795662
train_label=N_f-score_tok: 0.784125795582179
train_label=P_precision_tok: 0.8887134231305156
train_label=P_recall_tok: 0.7648399088619738
train_label=P_f-score_tok: 0.8221367649902249
train_precision_macro_tok: 0.8866763567425361
train_recall_macro_tok: 0.8250706178184132
train_f-score_macro_tok: 0.8531388906158792
train_precision_micro_tok: 0.9207109056894465
train_recall_micro_tok: 0.9207109056894465
train_f-score_micro_tok: 0.9207109056894465
train_time: 49.74520182609558
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4860    0.1176    0.1894      1624
           N     0.6852    0.8595    0.7625      3310
           P     0.7612    0.8432    0.8001      3610

   micro avg     0.7116    0.7116    0.7116      8544
   macro avg     0.6441    0.6068    0.5840      8544
weighted avg     0.6794    0.7116    0.6695      8544

F1-macro sent:  0.5840084916221352
F1-micro sent:  0.7116104868913858
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9341    0.9730    0.9532    124347
           N     0.8372    0.7374    0.7841     14202
           P     0.8887    0.7648    0.8221     25017

   micro avg     0.9207    0.9207    0.9207    163566
   macro avg     0.8867    0.8251    0.8531    163566
weighted avg     0.9187    0.9207    0.9184    163566

F1-macro tok:  0.8531388906158792
F1-micro tok:  0.9207109056894465
**************************************************
dev_cost_sum: 42031.51867675781
dev_cost_avg: 38.175766282250514
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19177.0
dev_accuracy_tok: 0.9014289743348689
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10894941634241244
dev_label=N_precision_sent: 0.659217877094972
dev_label=N_recall_sent: 0.8271028037383178
dev_label=N_f-score_sent: 0.7336787564766839
dev_label=P_precision_sent: 0.6940298507462687
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7591836734693876
dev_precision_macro_sent: 0.6177492426137469
dev_recall_macro_sent: 0.5753586709183983
dev_f-score_macro_sent: 0.5339372820961613
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9131948473946849
dev_label=O_recall_tok: 0.9711817340327059
dev_label=O_f-score_tok: 0.9412960913902928
dev_label=N_precision_tok: 0.8127629733520336
dev_label=N_recall_tok: 0.6241249326871298
dev_label=N_f-score_tok: 0.7060615290892476
dev_label=P_precision_tok: 0.8722264728385616
dev_label=P_recall_tok: 0.709838107098381
dev_label=P_f-score_tok: 0.7826982492276003
dev_precision_macro_tok: 0.8660614311950935
dev_recall_macro_tok: 0.768381591272739
dev_f-score_macro_tok: 0.8100186232357136
dev_precision_micro_tok: 0.9014289743348689
dev_recall_micro_tok: 0.9014289743348689
dev_f-score_micro_tok: 0.9014289743348689
dev_time: 2.363412618637085
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0611    0.1089       229
           N     0.6592    0.8271    0.7337       428
           P     0.6940    0.8378    0.7592       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6177    0.5754    0.5339      1101
weighted avg     0.6401    0.6721    0.6140      1101

F1-macro sent:  0.5339372820961613
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9132    0.9712    0.9413     16205
           N     0.8128    0.6241    0.7061      1857
           P     0.8722    0.7098    0.7827      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8661    0.7684    0.8100     21274
weighted avg     0.8982    0.9014    0.8968     21274

F1-macro tok:  0.8100186232357136
F1-micro tok:  0.9014289743348689
**************************************************
Best epoch: 35
**************************************************

EPOCH: 37
Learning rate: 0.810000
train_cost_sum: 288346.52502441406
train_cost_avg: 33.748422872707636
train_count_sent: 8544.0
train_total_correct_sent: 6045.0
train_accuracy_sent: 0.7075140449438202
train_count_tok: 163566.0
train_total_correct_tok: 150789.0
train_accuracy_tok: 0.9218847437731558
train_label=O_precision_sent: 0.4409448818897638
train_label=O_recall_sent: 0.10344827586206896
train_label=O_f-score_sent: 0.16758104738154614
train_label=N_precision_sent: 0.683825323249573
train_label=N_recall_sent: 0.8468277945619336
train_label=N_f-score_sent: 0.7566473208260224
train_label=P_precision_sent: 0.7563976377952756
train_label=P_recall_sent: 0.8515235457063712
train_label=P_f-score_sent: 0.8011467292155329
train_precision_macro_sent: 0.6270559476448708
train_recall_macro_sent: 0.6005998720434579
train_f-score_macro_sent: 0.5751250324743671
train_precision_micro_sent: 0.7075140449438202
train_recall_micro_sent: 0.7075140449438202
train_f-score_micro_sent: 0.7075140449438202
train_label=O_precision_tok: 0.9356003774110223
train_label=O_recall_tok: 0.972882337330213
train_label=O_f-score_tok: 0.9538772082681186
train_label=N_precision_tok: 0.8360357510084632
train_label=N_recall_tok: 0.7442613716377975
train_label=N_f-score_tok: 0.7874837027379401
train_label=P_precision_tok: 0.8900605892419408
train_label=P_recall_tok: 0.7692369188951513
train_label=P_f-score_tok: 0.8252497963034438
train_precision_macro_tok: 0.8872322392204754
train_recall_macro_tok: 0.828793542621054
train_f-score_macro_tok: 0.8555369024365008
train_precision_micro_tok: 0.9218847437731558
train_recall_micro_tok: 0.9218847437731558
train_f-score_micro_tok: 0.9218847437731558
train_time: 49.53830361366272
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4409    0.1034    0.1676      1624
           N     0.6838    0.8468    0.7566      3310
           P     0.7564    0.8515    0.8011      3610

   micro avg     0.7075    0.7075    0.7075      8544
   macro avg     0.6271    0.6006    0.5751      8544
weighted avg     0.6683    0.7075    0.6635      8544

F1-macro sent:  0.5751250324743671
F1-micro sent:  0.7075140449438202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9356    0.9729    0.9539    124347
           N     0.8360    0.7443    0.7875     14202
           P     0.8901    0.7692    0.8252     25017

   micro avg     0.9219    0.9219    0.9219    163566
   macro avg     0.8872    0.8288    0.8555    163566
weighted avg     0.9200    0.9219    0.9198    163566

F1-macro tok:  0.8555369024365008
F1-micro tok:  0.9218847437731558
**************************************************
dev_cost_sum: 42019.77673339844
dev_cost_avg: 38.16510148355898
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19125.0
dev_accuracy_tok: 0.8989846761304879
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.6941431670281996
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.719910011248594
dev_label=P_precision_sent: 0.6327503974562798
dev_label=P_recall_sent: 0.8963963963963963
dev_label=P_f-score_sent: 0.7418452935694314
dev_precision_macro_sent: 0.7150251275554326
dev_recall_macro_sent: 0.5611204192806446
dev_f-score_macro_sent: 0.5122517682726752
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9166715602795231
dev_label=O_recall_tok: 0.9632829373650108
dev_label=O_f-score_tok: 0.9393994102425226
dev_label=N_precision_tok: 0.7901315789473684
dev_label=N_recall_tok: 0.6467420570813139
dev_label=N_f-score_tok: 0.7112822031388806
dev_label=P_precision_tok: 0.8491743119266055
dev_label=P_recall_tok: 0.7204234122042341
dev_label=P_f-score_tok: 0.7795182752231766
dev_precision_macro_tok: 0.8519924837178324
dev_recall_macro_tok: 0.7768161355501864
dev_f-score_macro_tok: 0.8100666295348599
dev_precision_micro_tok: 0.8989846761304879
dev_recall_micro_tok: 0.8989846761304879
dev_f-score_micro_tok: 0.8989846761304879
dev_time: 2.3616864681243896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.6941    0.7477    0.7199       428
           P     0.6328    0.8964    0.7418       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7150    0.5611    0.5123      1101
weighted avg     0.6952    0.6603    0.5946      1101

F1-macro sent:  0.5122517682726752
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9167    0.9633    0.9394     16205
           N     0.7901    0.6467    0.7113      1857
           P     0.8492    0.7204    0.7795      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8520    0.7768    0.8101     21274
weighted avg     0.8954    0.8990    0.8953     21274

F1-macro tok:  0.8100666295348599
F1-micro tok:  0.8989846761304879
**************************************************
Best epoch: 35
**************************************************

EPOCH: 38
Learning rate: 0.810000
train_cost_sum: 287286.71197509766
train_cost_avg: 33.624381083227725
train_count_sent: 8544.0
train_total_correct_sent: 6070.0
train_accuracy_sent: 0.7104400749063671
train_count_tok: 163566.0
train_total_correct_tok: 150911.0
train_accuracy_tok: 0.9226306200555128
train_label=O_precision_sent: 0.47468354430379744
train_label=O_recall_sent: 0.09236453201970443
train_label=O_f-score_sent: 0.15463917525773196
train_label=N_precision_sent: 0.6919350932429159
train_label=N_recall_sent: 0.863141993957704
train_label=N_f-score_sent: 0.7681139938163731
train_label=P_precision_sent: 0.7472554281532081
train_label=P_recall_sent: 0.8484764542936288
train_label=P_f-score_sent: 0.7946555973537424
train_precision_macro_sent: 0.6379580218999737
train_recall_macro_sent: 0.6013276600903458
train_f-score_macro_sent: 0.5724695888092824
train_precision_micro_sent: 0.7104400749063671
train_recall_micro_sent: 0.7104400749063671
train_f-score_micro_sent: 0.7104400749063671
train_label=O_precision_tok: 0.9369055094304519
train_label=O_recall_tok: 0.9719414219884678
train_label=O_f-score_tok: 0.9541019325502084
train_label=N_precision_tok: 0.8377932982814094
train_label=N_recall_tok: 0.7517251091395578
train_label=N_f-score_tok: 0.7924290220820189
train_label=P_precision_tok: 0.8877943736827637
train_label=P_recall_tok: 0.7745533037534477
train_label=P_f-score_tok: 0.8273167815895651
train_precision_macro_tok: 0.8874977271315417
train_recall_macro_tok: 0.8327399449604912
train_f-score_macro_tok: 0.8579492454072642
train_precision_micro_tok: 0.9226306200555128
train_recall_micro_tok: 0.9226306200555128
train_f-score_micro_tok: 0.9226306200555128
train_time: 49.61018228530884
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4747    0.0924    0.1546      1624
           N     0.6919    0.8631    0.7681      3310
           P     0.7473    0.8485    0.7947      3610

   micro avg     0.7104    0.7104    0.7104      8544
   macro avg     0.6380    0.6013    0.5725      8544
weighted avg     0.6740    0.7104    0.6627      8544

F1-macro sent:  0.5724695888092824
F1-micro sent:  0.7104400749063671
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9369    0.9719    0.9541    124347
           N     0.8378    0.7517    0.7924     14202
           P     0.8878    0.7746    0.8273     25017

   micro avg     0.9226    0.9226    0.9226    163566
   macro avg     0.8875    0.8327    0.8579    163566
weighted avg     0.9208    0.9226    0.9207    163566

F1-macro tok:  0.8579492454072642
F1-micro tok:  0.9226306200555128
**************************************************
dev_cost_sum: 41899.68035888672
dev_cost_avg: 38.056022124329445
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19206.0
dev_accuracy_tok: 0.9027921406411582
dev_label=O_precision_sent: 0.5277777777777778
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14339622641509434
dev_label=N_precision_sent: 0.659217877094972
dev_label=N_recall_sent: 0.8271028037383178
dev_label=N_f-score_sent: 0.7336787564766839
dev_label=P_precision_sent: 0.6950757575757576
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7551440329218106
dev_precision_macro_sent: 0.6273571374828358
dev_recall_macro_sent: 0.5788829375431016
dev_f-score_macro_sent: 0.5440730052711963
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9151970199639137
dev_label=O_recall_tok: 0.9703178031471767
dev_label=O_f-score_tok: 0.9419517162882645
dev_label=N_precision_tok: 0.8065173116089613
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7135135135135136
dev_label=P_precision_tok: 0.8755725190839695
dev_label=P_recall_tok: 0.7141967621419676
dev_label=P_f-score_tok: 0.7866941015089163
dev_precision_macro_tok: 0.8657622835522815
dev_recall_macro_tok: 0.7747520279558322
dev_f-score_macro_tok: 0.8140531104368981
dev_precision_micro_tok: 0.9027921406411582
dev_recall_micro_tok: 0.9027921406411582
dev_f-score_micro_tok: 0.9027921406411582
dev_time: 2.3444318771362305
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5278    0.0830    0.1434       229
           N     0.6592    0.8271    0.7337       428
           P     0.6951    0.8266    0.7551       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6274    0.5789    0.5441      1101
weighted avg     0.6463    0.6721    0.6196      1101

F1-macro sent:  0.5440730052711963
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9152    0.9703    0.9420     16205
           N     0.8065    0.6397    0.7135      1857
           P     0.8756    0.7142    0.7867      3212

   micro avg     0.9028    0.9028    0.9028     21274
   macro avg     0.8658    0.7748    0.8141     21274
weighted avg     0.8997    0.9028    0.8986     21274

F1-macro tok:  0.8140531104368981
F1-micro tok:  0.9027921406411582
**************************************************
Best epoch: 38
**************************************************

EPOCH: 39
Learning rate: 0.810000
train_cost_sum: 285758.7830810547
train_cost_avg: 33.44555045424329
train_count_sent: 8544.0
train_total_correct_sent: 6097.0
train_accuracy_sent: 0.7136001872659176
train_count_tok: 163566.0
train_total_correct_tok: 151442.0
train_accuracy_tok: 0.9258770160057713
train_label=O_precision_sent: 0.5090252707581228
train_label=O_recall_sent: 0.08682266009852217
train_label=O_f-score_sent: 0.14834297738032615
train_label=N_precision_sent: 0.686401925391095
train_label=N_recall_sent: 0.861631419939577
train_label=N_f-score_sent: 0.7640991292699263
train_label=P_precision_sent: 0.754863813229572
train_label=P_recall_sent: 0.8598337950138504
train_label=P_f-score_sent: 0.8039368039368039
train_precision_macro_sent: 0.6500970031262633
train_recall_macro_sent: 0.6027626250173165
train_f-score_macro_sent: 0.5721263035290187
train_precision_micro_sent: 0.7136001872659176
train_recall_micro_sent: 0.7136001872659176
train_f-score_micro_sent: 0.7136001872659176
train_label=O_precision_tok: 0.9398988604320571
train_label=O_recall_tok: 0.9730512195710391
train_label=O_f-score_tok: 0.9561877667140826
train_label=N_precision_tok: 0.8431234885716514
train_label=N_recall_tok: 0.7610195747077876
train_label=N_f-score_tok: 0.7999703933977276
train_label=P_precision_tok: 0.8920686835650041
train_label=P_recall_tok: 0.7849862093776232
train_label=P_f-score_tok: 0.835108758053199
train_precision_macro_tok: 0.8916970108562375
train_recall_macro_tok: 0.8396856678854833
train_f-score_macro_tok: 0.8637556393883363
train_precision_micro_tok: 0.9258770160057713
train_recall_micro_tok: 0.9258770160057713
train_f-score_micro_tok: 0.9258770160057713
train_time: 51.99994230270386
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5090    0.0868    0.1483      1624
           N     0.6864    0.8616    0.7641      3310
           P     0.7549    0.8598    0.8039      3610

   micro avg     0.7136    0.7136    0.7136      8544
   macro avg     0.6501    0.6028    0.5721      8544
weighted avg     0.6816    0.7136    0.6639      8544

F1-macro sent:  0.5721263035290187
F1-micro sent:  0.7136001872659176
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9399    0.9731    0.9562    124347
           N     0.8431    0.7610    0.8000     14202
           P     0.8921    0.7850    0.8351     25017

   micro avg     0.9259    0.9259    0.9259    163566
   macro avg     0.8917    0.8397    0.8638    163566
weighted avg     0.9242    0.9259    0.9241    163566

F1-macro tok:  0.8637556393883363
F1-micro tok:  0.9258770160057713
**************************************************
dev_cost_sum: 42146.77166748047
dev_cost_avg: 38.28044656446909
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19141.0
dev_accuracy_tok: 0.899736767885682
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.11790393013100436
dev_label=O_f-score_sent: 0.19081272084805656
dev_label=N_precision_sent: 0.6834677419354839
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7337662337662337
dev_label=P_precision_sent: 0.6751361161524501
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7477386934673367
dev_precision_macro_sent: 0.6195346193626446
dev_recall_macro_sent: 0.5825992809117325
dev_f-score_macro_sent: 0.557439216027209
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.918866368135753
dev_label=O_recall_tok: 0.9623572971305153
dev_label=O_f-score_tok: 0.9401091117340327
dev_label=N_precision_tok: 0.7528981086028066
dev_label=N_recall_tok: 0.6645126548196015
dev_label=N_f-score_tok: 0.705949656750572
dev_label=P_precision_tok: 0.8681937664288396
dev_label=P_recall_tok: 0.7198007471980075
dev_label=P_f-score_tok: 0.7870638297872341
dev_precision_macro_tok: 0.8466527477224663
dev_recall_macro_tok: 0.7822235663827081
dev_f-score_macro_tok: 0.8110408660906129
dev_precision_micro_tok: 0.899736767885682
dev_recall_micro_tok: 0.899736767885682
dev_f-score_micro_tok: 0.899736767885682
dev_time: 4.860266923904419
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.1179    0.1908       229
           N     0.6835    0.7921    0.7338       428
           P     0.6751    0.8378    0.7477       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6195    0.5826    0.5574      1101
weighted avg     0.6419    0.6703    0.6265      1101

F1-macro sent:  0.557439216027209
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9189    0.9624    0.9401     16205
           N     0.7529    0.6645    0.7059      1857
           P     0.8682    0.7198    0.7871      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8467    0.7822    0.8110     21274
weighted avg     0.8967    0.8997    0.8966     21274

F1-macro tok:  0.8110408660906129
F1-micro tok:  0.899736767885682
**************************************************
Best epoch: 38
**************************************************

EPOCH: 40
Learning rate: 0.810000
train_cost_sum: 284847.8170776367
train_cost_avg: 33.33892990140879
train_count_sent: 8544.0
train_total_correct_sent: 6111.0
train_accuracy_sent: 0.7152387640449438
train_count_tok: 163566.0
train_total_correct_tok: 151639.0
train_accuracy_tok: 0.9270814227895773
train_label=O_precision_sent: 0.5072463768115942
train_label=O_recall_sent: 0.10775862068965517
train_label=O_f-score_sent: 0.17775520568816658
train_label=N_precision_sent: 0.6941495926931622
train_label=N_recall_sent: 0.8495468277945619
train_label=N_f-score_sent: 0.7640266268170086
train_label=P_precision_sent: 0.7531340405014465
train_label=P_recall_sent: 0.8653739612188366
train_label=P_f-score_sent: 0.8053622067543182
train_precision_macro_sent: 0.651510003335401
train_recall_macro_sent: 0.6075598032343512
train_f-score_macro_sent: 0.5823813464198312
train_precision_micro_sent: 0.7152387640449438
train_recall_micro_sent: 0.7152387640449438
train_f-score_micro_sent: 0.7152387640449438
train_label=O_precision_tok: 0.940972951119197
train_label=O_recall_tok: 0.9733005219265443
train_label=O_f-score_tok: 0.9568637682534411
train_label=N_precision_tok: 0.8433922591698466
train_label=N_recall_tok: 0.7625686523024926
train_label=N_f-score_tok: 0.8009466405354436
train_label=P_precision_tok: 0.8948701709943002
train_label=P_recall_tok: 0.7907422952392373
train_label=P_f-score_tok: 0.8395900091250558
train_precision_macro_tok: 0.8930784604277813
train_recall_macro_tok: 0.8422038231560913
train_f-score_macro_tok: 0.8658001393046467
train_precision_micro_tok: 0.9270814227895773
train_recall_micro_tok: 0.9270814227895773
train_f-score_micro_tok: 0.9270814227895773
train_time: 91.93814444541931
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5072    0.1078    0.1778      1624
           N     0.6941    0.8495    0.7640      3310
           P     0.7531    0.8654    0.8054      3610

   micro avg     0.7152    0.7152    0.7152      8544
   macro avg     0.6515    0.6076    0.5824      8544
weighted avg     0.6835    0.7152    0.6701      8544

F1-macro sent:  0.5823813464198312
F1-micro sent:  0.7152387640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9410    0.9733    0.9569    124347
           N     0.8434    0.7626    0.8009     14202
           P     0.8949    0.7907    0.8396     25017

   micro avg     0.9271    0.9271    0.9271    163566
   macro avg     0.8931    0.8422    0.8658    163566
weighted avg     0.9254    0.9271    0.9254    163566

F1-macro tok:  0.8658001393046467
F1-micro tok:  0.9270814227895773
**************************************************
dev_cost_sum: 41934.444274902344
dev_cost_avg: 38.087596979929465
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19108.0
dev_accuracy_tok: 0.8981855786405941
dev_label=O_precision_sent: 0.5476190476190477
dev_label=O_recall_sent: 0.10043668122270742
dev_label=O_f-score_sent: 0.16974169741697417
dev_label=N_precision_sent: 0.6522522522522523
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7365208545269583
dev_label=P_precision_sent: 0.6984126984126984
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7426160337552742
dev_precision_macro_sent: 0.6327613327613327
dev_recall_macro_sent: 0.5796746221796215
dev_f-score_macro_sent: 0.5496261952330689
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9186891054030115
dev_label=O_recall_tok: 0.9600740512187597
dev_label=O_f-score_tok: 0.9389257694628848
dev_label=N_precision_tok: 0.7730720606826802
dev_label=N_recall_tok: 0.6585891222401723
dev_label=N_f-score_tok: 0.7112532712997964
dev_label=P_precision_tok: 0.8440333696046427
dev_label=P_recall_tok: 0.7244707347447074
dev_label=P_f-score_tok: 0.7796950913050763
dev_precision_macro_tok: 0.8452648452301115
dev_recall_macro_tok: 0.7810446360678798
dev_f-score_macro_tok: 0.8099580440225859
dev_precision_micro_tok: 0.8981855786405941
dev_recall_micro_tok: 0.8981855786405941
dev_f-score_micro_tok: 0.8981855786405941
dev_time: 5.027320623397827
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5476    0.1004    0.1697       229
           N     0.6523    0.8458    0.7365       428
           P     0.6984    0.7928    0.7426       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6328    0.5797    0.5496      1101
weighted avg     0.6491    0.6694    0.6211      1101

F1-macro sent:  0.5496261952330689
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9187    0.9601    0.9389     16205
           N     0.7731    0.6586    0.7113      1857
           P     0.8440    0.7245    0.7797      3212

   micro avg     0.8982    0.8982    0.8982     21274
   macro avg     0.8453    0.7810    0.8100     21274
weighted avg     0.8947    0.8982    0.8950     21274

F1-macro tok:  0.8099580440225859
F1-micro tok:  0.8981855786405941
**************************************************
Best epoch: 38
**************************************************

EPOCH: 41
Learning rate: 0.810000
train_cost_sum: 284313.7417602539
train_cost_avg: 33.27642108617204
train_count_sent: 8544.0
train_total_correct_sent: 6047.0
train_accuracy_sent: 0.7077481273408239
train_count_tok: 163566.0
train_total_correct_tok: 151751.0
train_accuracy_tok: 0.9277661616717411
train_label=O_precision_sent: 0.4702549575070821
train_label=O_recall_sent: 0.1022167487684729
train_label=O_f-score_sent: 0.16793120890237734
train_label=N_precision_sent: 0.6803357314148681
train_label=N_recall_sent: 0.8570996978851964
train_label=N_f-score_sent: 0.7585561497326203
train_label=P_precision_sent: 0.7570256155185278
train_label=P_recall_sent: 0.843213296398892
train_label=P_f-score_sent: 0.797798453675796
train_precision_macro_sent: 0.6358721014801594
train_recall_macro_sent: 0.6008432476841871
train_f-score_macro_sent: 0.5747619374369313
train_precision_micro_sent: 0.7077481273408239
train_recall_micro_sent: 0.7077481273408239
train_f-score_micro_sent: 0.7077481273408239
train_label=O_precision_tok: 0.9418315098127714
train_label=O_recall_tok: 0.973332689972416
train_label=O_f-score_tok: 0.9573230295863605
train_label=N_precision_tok: 0.8436820863085999
train_label=N_recall_tok: 0.765385157020138
train_label=N_f-score_tok: 0.8026286642545964
train_label=P_precision_tok: 0.8951118326118326
train_label=P_recall_tok: 0.7934604468961106
train_label=P_f-score_tok: 0.841226453075668
train_precision_macro_tok: 0.8935418095777345
train_recall_macro_tok: 0.8440594312962215
train_f-score_macro_tok: 0.8670593823055417
train_precision_micro_tok: 0.9277661616717411
train_recall_micro_tok: 0.9277661616717411
train_f-score_micro_tok: 0.9277661616717411
train_time: 92.15627336502075
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4703    0.1022    0.1679      1624
           N     0.6803    0.8571    0.7586      3310
           P     0.7570    0.8432    0.7978      3610

   micro avg     0.7077    0.7077    0.7077      8544
   macro avg     0.6359    0.6008    0.5748      8544
weighted avg     0.6728    0.7077    0.6629      8544

F1-macro sent:  0.5747619374369313
F1-micro sent:  0.7077481273408239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9418    0.9733    0.9573    124347
           N     0.8437    0.7654    0.8026     14202
           P     0.8951    0.7935    0.8412     25017

   micro avg     0.9278    0.9278    0.9278    163566
   macro avg     0.8935    0.8441    0.8671    163566
weighted avg     0.9262    0.9278    0.9261    163566

F1-macro tok:  0.8670593823055417
F1-micro tok:  0.9277661616717411
**************************************************
dev_cost_sum: 41976.87823486328
dev_cost_avg: 38.126138269630594
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19133.0
dev_accuracy_tok: 0.899360722008085
dev_label=O_precision_sent: 0.43636363636363634
dev_label=O_recall_sent: 0.10480349344978165
dev_label=O_f-score_sent: 0.16901408450704225
dev_label=N_precision_sent: 0.677734375
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7382978723404254
dev_label=P_precision_sent: 0.6985018726591761
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7627811860940696
dev_precision_macro_sent: 0.6041999613409375
dev_recall_macro_sent: 0.5852137490304244
dev_f-score_macro_sent: 0.5566977143138457
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9196808510638298
dev_label=O_recall_tok: 0.9602591792656587
dev_label=O_f-score_tok: 0.939532075471698
dev_label=N_precision_tok: 0.7696170747018205
dev_label=N_recall_tok: 0.6602046311254712
dev_label=N_f-score_tok: 0.7107246376811596
dev_label=P_precision_tok: 0.8496921405287939
dev_label=P_recall_tok: 0.7303860523038606
dev_label=P_f-score_tok: 0.7855349070818683
dev_precision_macro_tok: 0.8463300220981481
dev_recall_macro_tok: 0.7836166208983301
dev_f-score_macro_tok: 0.811930540078242
dev_precision_micro_tok: 0.899360722008085
dev_recall_micro_tok: 0.899360722008085
dev_f-score_micro_tok: 0.899360722008085
dev_time: 4.879319667816162
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4364    0.1048    0.1690       229
           N     0.6777    0.8107    0.7383       428
           P     0.6985    0.8401    0.7628       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6042    0.5852    0.5567      1101
weighted avg     0.6359    0.6757    0.6298      1101

F1-macro sent:  0.5566977143138457
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9603    0.9395     16205
           N     0.7696    0.6602    0.7107      1857
           P     0.8497    0.7304    0.7855      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8463    0.7836    0.8119     21274
weighted avg     0.8960    0.8994    0.8963     21274

F1-macro tok:  0.811930540078242
F1-micro tok:  0.899360722008085
**************************************************
Best epoch: 38
**************************************************

EPOCH: 42
Learning rate: 0.810000
train_cost_sum: 283391.28674316406
train_cost_avg: 33.16845584540778
train_count_sent: 8544.0
train_total_correct_sent: 6128.0
train_accuracy_sent: 0.7172284644194756
train_count_tok: 163566.0
train_total_correct_tok: 152056.0
train_accuracy_tok: 0.9296308523776335
train_label=O_precision_sent: 0.4906976744186046
train_label=O_recall_sent: 0.12992610837438423
train_label=O_f-score_sent: 0.20545277507302825
train_label=N_precision_sent: 0.6901306240928883
train_label=N_recall_sent: 0.8619335347432024
train_label=N_f-score_sent: 0.7665233745298228
train_label=P_precision_sent: 0.7698492462311558
train_label=P_recall_sent: 0.8487534626038781
train_label=P_f-score_sent: 0.8073781291172595
train_precision_macro_sent: 0.6502258482475495
train_recall_macro_sent: 0.613537701907155
train_f-score_macro_sent: 0.5931180929067036
train_precision_micro_sent: 0.7172284644194756
train_recall_micro_sent: 0.7172284644194756
train_f-score_micro_sent: 0.7172284644194756
train_label=O_precision_tok: 0.9434087208532319
train_label=O_recall_tok: 0.9738473787063621
train_label=O_f-score_tok: 0.9583864253322043
train_label=N_precision_tok: 0.8471814671814671
train_label=N_recall_tok: 0.7724968314321926
train_label=N_f-score_tok: 0.8081172657631114
train_label=P_precision_tok: 0.8981444040077279
train_label=P_recall_tok: 0.7990566414837911
train_label=P_f-score_tok: 0.8457080001692262
train_precision_macro_tok: 0.8962448640141423
train_recall_macro_tok: 0.8484669505407819
train_f-score_macro_tok: 0.870737230421514
train_precision_micro_tok: 0.9296308523776335
train_recall_micro_tok: 0.9296308523776335
train_f-score_micro_tok: 0.9296308523776335
train_time: 123.04600524902344
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4907    0.1299    0.2055      1624
           N     0.6901    0.8619    0.7665      3310
           P     0.7698    0.8488    0.8074      3610

   micro avg     0.7172    0.7172    0.7172      8544
   macro avg     0.6502    0.6135    0.5931      8544
weighted avg     0.6859    0.7172    0.6771      8544

F1-macro sent:  0.5931180929067036
F1-micro sent:  0.7172284644194756
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9434    0.9738    0.9584    124347
           N     0.8472    0.7725    0.8081     14202
           P     0.8981    0.7991    0.8457     25017

   micro avg     0.9296    0.9296    0.9296    163566
   macro avg     0.8962    0.8485    0.8707    163566
weighted avg     0.9281    0.9296    0.9281    163566

F1-macro tok:  0.870737230421514
F1-micro tok:  0.9296308523776335
**************************************************
dev_cost_sum: 42207.51330566406
dev_cost_avg: 38.33561608143875
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19128.0
dev_accuracy_tok: 0.8991256933345868
dev_label=O_precision_sent: 0.3793103448275862
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.15331010452961671
dev_label=N_precision_sent: 0.6548507462686567
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7282157676348548
dev_label=P_precision_sent: 0.7159763313609467
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7634069400630916
dev_precision_macro_sent: 0.5833791408190633
dev_recall_macro_sent: 0.5779102981690419
dev_f-score_macro_sent: 0.5483109374091878
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9194282001299545
dev_label=O_recall_tok: 0.9605060166615242
dev_label=O_f-score_tok: 0.9395183195509145
dev_label=N_precision_tok: 0.8
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.712279653420974
dev_label=P_precision_tok: 0.8304728546409808
dev_label=P_recall_tok: 0.7381693648816936
dev_label=P_f-score_tok: 0.7816054062963573
dev_precision_macro_tok: 0.8499670182569785
dev_recall_macro_tok: 0.7801903039895451
dev_f-score_macro_tok: 0.811134459756082
dev_precision_micro_tok: 0.8991256933345868
dev_recall_micro_tok: 0.8991256933345868
dev_f-score_micro_tok: 0.8991256933345868
dev_time: 8.144405126571655
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3793    0.0961    0.1533       229
           N     0.6549    0.8201    0.7282       428
           P     0.7160    0.8176    0.7634       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.5834    0.5779    0.5483      1101
weighted avg     0.6222    0.6685    0.6228      1101

F1-macro sent:  0.5483109374091878
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9194    0.9605    0.9395     16205
           N     0.8000    0.6419    0.7123      1857
           P     0.8305    0.7382    0.7816      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8500    0.7802    0.8111     21274
weighted avg     0.8956    0.8991    0.8958     21274

F1-macro tok:  0.811134459756082
F1-micro tok:  0.8991256933345868
**************************************************
Best epoch: 38
**************************************************

EPOCH: 43
Learning rate: 0.729000
train_cost_sum: 281464.3512573242
train_cost_avg: 32.942925006709295
train_count_sent: 8544.0
train_total_correct_sent: 6168.0
train_accuracy_sent: 0.7219101123595506
train_count_tok: 163566.0
train_total_correct_tok: 152537.0
train_accuracy_tok: 0.9325715613269261
train_label=O_precision_sent: 0.4605543710021322
train_label=O_recall_sent: 0.1330049261083744
train_label=O_f-score_sent: 0.2064022933588151
train_label=N_precision_sent: 0.700955180014695
train_label=N_recall_sent: 0.8646525679758308
train_label=N_f-score_sent: 0.7742459082916271
train_label=P_precision_sent: 0.7740480961923848
train_label=P_recall_sent: 0.8559556786703602
train_label=P_f-score_sent: 0.8129439621152329
train_precision_macro_sent: 0.6451858824030706
train_recall_macro_sent: 0.617871057584855
train_f-score_macro_sent: 0.5978640545885584
train_precision_micro_sent: 0.7219101123595506
train_recall_micro_sent: 0.7219101123595506
train_f-score_micro_sent: 0.7219101123595506
train_label=O_precision_tok: 0.9463105597825238
train_label=O_recall_tok: 0.9742173112338858
train_label=O_f-score_tok: 0.9600611821953471
train_label=N_precision_tok: 0.8538732394366197
train_label=N_recall_tok: 0.7854527531333615
train_label=N_f-score_tok: 0.818235164673953
train_label=P_precision_tok: 0.9000800426894343
train_label=P_recall_tok: 0.8090898189231323
train_label=P_f-score_tok: 0.8521629302178717
train_precision_macro_tok: 0.9000879473028592
train_recall_macro_tok: 0.8562532944301265
train_f-score_macro_tok: 0.8768197590290573
train_precision_micro_tok: 0.9325715613269261
train_recall_micro_tok: 0.9325715613269261
train_f-score_micro_tok: 0.9325715613269261
train_time: 141.27727794647217
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4606    0.1330    0.2064      1624
           N     0.7010    0.8647    0.7742      3310
           P     0.7740    0.8560    0.8129      3610

   micro avg     0.7219    0.7219    0.7219      8544
   macro avg     0.6452    0.6179    0.5979      8544
weighted avg     0.6861    0.7219    0.6827      8544

F1-macro sent:  0.5978640545885584
F1-micro sent:  0.7219101123595506
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9463    0.9742    0.9601    124347
           N     0.8539    0.7855    0.8182     14202
           P     0.9001    0.8091    0.8522     25017

   micro avg     0.9326    0.9326    0.9326    163566
   macro avg     0.9001    0.8563    0.8768    163566
weighted avg     0.9312    0.9326    0.9312    163566

F1-macro tok:  0.8768197590290573
F1-micro tok:  0.9325715613269261
**************************************************
dev_cost_sum: 42172.78338623047
dev_cost_avg: 38.30407210375156
dev_count_sent: 1101.0
dev_total_correct_sent: 755.0
dev_accuracy_sent: 0.6857402361489555
dev_count_tok: 21274.0
dev_total_correct_tok: 19177.0
dev_accuracy_tok: 0.9014289743348689
dev_label=O_precision_sent: 0.5806451612903226
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13846153846153847
dev_label=N_precision_sent: 0.6636690647482014
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.75
dev_label=P_precision_sent: 0.7159533073929961
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7682672233820459
dev_precision_macro_sent: 0.6534225111438401
dev_recall_macro_sent: 0.5898603272088151
dev_f-score_macro_sent: 0.5522429206145282
dev_precision_micro_sent: 0.6857402361489555
dev_recall_micro_sent: 0.6857402361489555
dev_f-score_micro_sent: 0.6857402361489555
dev_label=O_precision_tok: 0.915688678694459
dev_label=O_recall_tok: 0.9677877198395557
dev_label=O_f-score_tok: 0.9410176407056283
dev_label=N_precision_tok: 0.7967806841046278
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7096774193548387
dev_label=P_precision_tok: 0.8682228915662651
dev_label=P_recall_tok: 0.7179327521793275
dev_label=P_f-score_tok: 0.7859577368779822
dev_precision_macro_tok: 0.8602307514551173
dev_recall_macro_tok: 0.775153996865745
dev_f-score_macro_tok: 0.812217598979483
dev_precision_micro_tok: 0.9014289743348689
dev_recall_micro_tok: 0.9014289743348689
dev_f-score_micro_tok: 0.9014289743348689
dev_time: 7.5789477825164795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5806    0.0786    0.1385       229
           N     0.6637    0.8621    0.7500       428
           P     0.7160    0.8288    0.7683       444

   micro avg     0.6857    0.6857    0.6857      1101
   macro avg     0.6534    0.5899    0.5522      1101
weighted avg     0.6675    0.6857    0.6302      1101

F1-macro sent:  0.5522429206145282
F1-micro sent:  0.6857402361489555
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9678    0.9410     16205
           N     0.7968    0.6397    0.7097      1857
           P     0.8682    0.7179    0.7860      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8602    0.7752    0.8122     21274
weighted avg     0.8981    0.9014    0.8974     21274

F1-macro tok:  0.812217598979483
F1-micro tok:  0.9014289743348689
**************************************************
Best epoch: 38
**************************************************

EPOCH: 44
Learning rate: 0.656100
train_cost_sum: 280562.8352050781
train_cost_avg: 32.837410487485734
train_count_sent: 8544.0
train_total_correct_sent: 6157.0
train_accuracy_sent: 0.72062265917603
train_count_tok: 163566.0
train_total_correct_tok: 152687.0
train_accuracy_tok: 0.933488622329824
train_label=O_precision_sent: 0.5053304904051172
train_label=O_recall_sent: 0.145935960591133
train_label=O_f-score_sent: 0.22646918299092214
train_label=N_precision_sent: 0.6998760842627013
train_label=N_recall_sent: 0.8531722054380665
train_label=N_f-score_sent: 0.7689584751531653
train_label=P_precision_sent: 0.7663366336633664
train_label=P_recall_sent: 0.8576177285318559
train_label=P_f-score_sent: 0.8094117647058825
train_precision_macro_sent: 0.6571810694437283
train_recall_macro_sent: 0.6189086315203518
train_f-score_macro_sent: 0.60161314094999
train_precision_micro_sent: 0.72062265917603
train_recall_micro_sent: 0.72062265917603
train_f-score_micro_sent: 0.72062265917603
train_label=O_precision_tok: 0.9473659513232809
train_label=O_recall_tok: 0.9741610171536105
train_label=O_f-score_tok: 0.9605766600187937
train_label=N_precision_tok: 0.8564227890636933
train_label=N_recall_tok: 0.7896070975918885
train_label=N_f-score_tok: 0.8216588511137163
train_label=P_precision_tok: 0.899637296532201
train_label=P_recall_tok: 0.8130071551345085
train_label=P_f-score_tok: 0.8541312335958006
train_precision_macro_tok: 0.9011420123063919
train_recall_macro_tok: 0.8589250899600026
train_f-score_macro_tok: 0.8787889149094369
train_precision_micro_tok: 0.933488622329824
train_recall_micro_tok: 0.933488622329824
train_f-score_micro_tok: 0.933488622329824
train_time: 140.7869894504547
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5053    0.1459    0.2265      1624
           N     0.6999    0.8532    0.7690      3310
           P     0.7663    0.8576    0.8094      3610

   micro avg     0.7206    0.7206    0.7206      8544
   macro avg     0.6572    0.6189    0.6016      8544
weighted avg     0.6910    0.7206    0.6829      8544

F1-macro sent:  0.60161314094999
F1-micro sent:  0.72062265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9474    0.9742    0.9606    124347
           N     0.8564    0.7896    0.8217     14202
           P     0.8996    0.8130    0.8541     25017

   micro avg     0.9335    0.9335    0.9335    163566
   macro avg     0.9011    0.8589    0.8788    163566
weighted avg     0.9322    0.9335    0.9322    163566

F1-macro tok:  0.8787889149094369
F1-micro tok:  0.933488622329824
**************************************************
dev_cost_sum: 42214.35754394531
dev_cost_avg: 38.34183246498212
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19192.0
dev_accuracy_tok: 0.9021340603553634
dev_label=O_precision_sent: 0.33076923076923076
dev_label=O_recall_sent: 0.18777292576419213
dev_label=O_f-score_sent: 0.23955431754874648
dev_label=N_precision_sent: 0.6778656126482213
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.734475374732334
dev_label=P_precision_sent: 0.7462365591397849
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7634763476347635
dev_precision_macro_sent: 0.5849571341857457
dev_recall_macro_sent: 0.590235442151534
dev_f-score_macro_sent: 0.579168679971948
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9184415889221381
dev_label=O_recall_tok: 0.9659364393705646
dev_label=O_f-score_tok: 0.9415904716073148
dev_label=N_precision_tok: 0.7735849056603774
dev_label=N_recall_tok: 0.6623586429725363
dev_label=N_f-score_tok: 0.7136640557006092
dev_label=P_precision_tok: 0.8742900416508899
dev_label=P_recall_tok: 0.7188667496886675
dev_label=P_f-score_tok: 0.7889970955065778
dev_precision_macro_tok: 0.8554388454111352
dev_recall_macro_tok: 0.7823872773439228
dev_f-score_macro_tok: 0.8147505409381672
dev_precision_micro_tok: 0.9021340603553634
dev_recall_micro_tok: 0.9021340603553634
dev_f-score_micro_tok: 0.9021340603553635
dev_time: 7.45024561882019
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3308    0.1878    0.2396       229
           N     0.6779    0.8014    0.7345       428
           P     0.7462    0.7815    0.7635       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.5850    0.5902    0.5792      1101
weighted avg     0.6332    0.6658    0.6432      1101

F1-macro sent:  0.579168679971948
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9659    0.9416     16205
           N     0.7736    0.6624    0.7137      1857
           P     0.8743    0.7189    0.7890      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8554    0.7824    0.8148     21274
weighted avg     0.8991    0.9021    0.8987     21274

F1-macro tok:  0.8147505409381672
F1-micro tok:  0.9021340603553635
**************************************************
Best epoch: 44
**************************************************

EPOCH: 45
Learning rate: 0.656100
train_cost_sum: 279546.2572631836
train_cost_avg: 32.718428986795836
train_count_sent: 8544.0
train_total_correct_sent: 6175.0
train_accuracy_sent: 0.7227294007490637
train_count_tok: 163566.0
train_total_correct_tok: 152949.0
train_accuracy_tok: 0.9350904222148857
train_label=O_precision_sent: 0.4688581314878893
train_label=O_recall_sent: 0.16687192118226601
train_label=O_f-score_sent: 0.24613987284287014
train_label=N_precision_sent: 0.70752847944527
train_label=N_recall_sent: 0.863141993957704
train_label=N_f-score_sent: 0.7776265650517148
train_label=P_precision_sent: 0.7757128309572301
train_label=P_recall_sent: 0.8440443213296399
train_label=P_f-score_sent: 0.8084372512602812
train_precision_macro_sent: 0.6506998139634631
train_recall_macro_sent: 0.6246860788232033
train_f-score_macro_sent: 0.6107345630516221
train_precision_micro_sent: 0.7227294007490637
train_recall_micro_sent: 0.7227294007490637
train_f-score_micro_sent: 0.7227294007490636
train_label=O_precision_tok: 0.9490052380616822
train_label=O_recall_tok: 0.9747400419792999
train_label=O_f-score_tok: 0.9617005070100687
train_label=N_precision_tok: 0.8606277072725891
train_label=N_recall_tok: 0.7974228981833544
train_label=N_f-score_tok: 0.8278206205913526
train_label=P_precision_tok: 0.8999471086036671
train_label=P_recall_tok: 0.8161650077946996
train_label=P_f-score_tok: 0.8560109003249134
train_precision_macro_tok: 0.9031933513126461
train_recall_macro_tok: 0.8627759826524514
train_f-score_macro_tok: 0.8818440093087783
train_precision_micro_tok: 0.9350904222148857
train_recall_micro_tok: 0.9350904222148857
train_f-score_micro_tok: 0.9350904222148857
train_time: 141.47717428207397
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4689    0.1669    0.2461      1624
           N     0.7075    0.8631    0.7776      3310
           P     0.7757    0.8440    0.8084      3610

   micro avg     0.7227    0.7227    0.7227      8544
   macro avg     0.6507    0.6247    0.6107      8544
weighted avg     0.6910    0.7227    0.6896      8544

F1-macro sent:  0.6107345630516221
F1-micro sent:  0.7227294007490636
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9490    0.9747    0.9617    124347
           N     0.8606    0.7974    0.8278     14202
           P     0.8999    0.8162    0.8560     25017

   micro avg     0.9351    0.9351    0.9351    163566
   macro avg     0.9032    0.8628    0.8818    163566
weighted avg     0.9338    0.9351    0.9339    163566

F1-macro tok:  0.8818440093087783
F1-micro tok:  0.9350904222148857
**************************************************
dev_cost_sum: 42238.71838378906
dev_cost_avg: 38.36395856838244
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19154.0
dev_accuracy_tok: 0.9003478424367772
dev_label=O_precision_sent: 0.4411764705882353
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11406844106463877
dev_label=N_precision_sent: 0.6354344122657581
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7349753694581281
dev_label=P_precision_sent: 0.7270833333333333
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7554112554112553
dev_precision_macro_sent: 0.6012314053957756
dev_recall_macro_sent: 0.5743445155149844
dev_f-score_macro_sent: 0.5348183553113407
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.919723958947741
dev_label=O_recall_tok: 0.9622338784325826
dev_label=O_f-score_tok: 0.9404988087698664
dev_label=N_precision_tok: 0.776500638569604
dev_label=N_recall_tok: 0.6548196015078083
dev_label=N_f-score_tok: 0.7104878761320479
dev_label=P_precision_tok: 0.8514887436456063
dev_label=P_recall_tok: 0.7300747198007472
dev_label=P_f-score_tok: 0.7861213543412672
dev_precision_macro_tok: 0.8492377803876504
dev_recall_macro_tok: 0.7823760665803793
dev_f-score_macro_tok: 0.8123693464143938
dev_precision_micro_tok: 0.9003478424367772
dev_recall_micro_tok: 0.9003478424367772
dev_f-score_micro_tok: 0.9003478424367772
dev_time: 7.26142692565918
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4412    0.0655    0.1141       229
           N     0.6354    0.8715    0.7350       428
           P     0.7271    0.7860    0.7554       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6012    0.5743    0.5348      1101
weighted avg     0.6320    0.6694    0.6141      1101

F1-macro sent:  0.5348183553113407
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9622    0.9405     16205
           N     0.7765    0.6548    0.7105      1857
           P     0.8515    0.7301    0.7861      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8492    0.7824    0.8124     21274
weighted avg     0.8969    0.9003    0.8971     21274

F1-macro tok:  0.8123693464143938
F1-micro tok:  0.9003478424367772
**************************************************
Best epoch: 44
**************************************************

EPOCH: 46
Learning rate: 0.656100
train_cost_sum: 278876.1104736328
train_cost_avg: 32.63999420337463
train_count_sent: 8544.0
train_total_correct_sent: 6201.0
train_accuracy_sent: 0.7257724719101124
train_count_tok: 163566.0
train_total_correct_tok: 153158.0
train_accuracy_tok: 0.9363681938789234
train_label=O_precision_sent: 0.4874551971326165
train_label=O_recall_sent: 0.16748768472906403
train_label=O_f-score_sent: 0.24931255728689275
train_label=N_precision_sent: 0.707896051974013
train_label=N_recall_sent: 0.8558912386706948
train_label=N_f-score_sent: 0.774890590809628
train_label=P_precision_sent: 0.7771084337349398
train_label=P_recall_sent: 0.8576177285318559
train_label=P_f-score_sent: 0.8153805636028444
train_precision_macro_sent: 0.6574865609471897
train_recall_macro_sent: 0.6269988839772048
train_f-score_macro_sent: 0.6131945705664551
train_precision_micro_sent: 0.7257724719101124
train_recall_micro_sent: 0.7257724719101124
train_f-score_micro_sent: 0.7257724719101125
train_label=O_precision_tok: 0.9503155748951351
train_label=O_recall_tok: 0.9747561260022357
train_label=O_f-score_tok: 0.9623807028409
train_label=N_precision_tok: 0.8618176296408777
train_label=N_recall_tok: 0.799253626249824
train_label=N_f-score_tok: 0.829357395974135
train_label=P_precision_tok: 0.901487964989059
train_label=P_recall_tok: 0.8234000879402007
train_label=P_f-score_tok: 0.8606764576848351
train_precision_macro_tok: 0.9045403898416907
train_recall_macro_tok: 0.8658032800640868
train_f-score_macro_tok: 0.8841381854999568
train_precision_micro_tok: 0.9363681938789234
train_recall_micro_tok: 0.9363681938789234
train_f-score_micro_tok: 0.9363681938789234
train_time: 142.27013421058655
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4875    0.1675    0.2493      1624
           N     0.7079    0.8559    0.7749      3310
           P     0.7771    0.8576    0.8154      3610

   micro avg     0.7258    0.7258    0.7258      8544
   macro avg     0.6575    0.6270    0.6132      8544
weighted avg     0.6952    0.7258    0.6921      8544

F1-macro sent:  0.6131945705664551
F1-micro sent:  0.7257724719101125
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9503    0.9748    0.9624    124347
           N     0.8618    0.7993    0.8294     14202
           P     0.9015    0.8234    0.8607     25017

   micro avg     0.9364    0.9364    0.9364    163566
   macro avg     0.9045    0.8658    0.8841    163566
weighted avg     0.9352    0.9364    0.9353    163566

F1-macro tok:  0.8841381854999568
F1-micro tok:  0.9363681938789234
**************************************************
dev_cost_sum: 42360.58679199219
dev_cost_avg: 38.47464740417092
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19183.0
dev_accuracy_tok: 0.9017110087430666
dev_label=O_precision_sent: 0.4482758620689655
dev_label=O_recall_sent: 0.11353711790393013
dev_label=O_f-score_sent: 0.18118466898954705
dev_label=N_precision_sent: 0.6800804828973843
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7308108108108108
dev_label=P_precision_sent: 0.6904761904761905
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7616161616161615
dev_precision_macro_sent: 0.6062775118141801
dev_recall_macro_sent: 0.5841186143904179
dev_f-score_macro_sent: 0.5578705471388398
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9188664824504674
dev_label=O_recall_tok: 0.9644554149953718
dev_label=O_f-score_tok: 0.9411091708315771
dev_label=N_precision_tok: 0.7795527156549521
dev_label=N_recall_tok: 0.6569736133548735
dev_label=N_f-score_tok: 0.7130333138515489
dev_label=P_precision_tok: 0.8644444444444445
dev_label=P_recall_tok: 0.7266500622665006
dev_label=P_f-score_tok: 0.7895805142083896
dev_precision_macro_tok: 0.8542878808499547
dev_recall_macro_tok: 0.782693030205582
dev_f-score_macro_tok: 0.8145743329638385
dev_precision_micro_tok: 0.9017110087430666
dev_recall_micro_tok: 0.9017110087430666
dev_f-score_micro_tok: 0.9017110087430666
dev_time: 7.114017486572266
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4483    0.1135    0.1812       229
           N     0.6801    0.7897    0.7308       428
           P     0.6905    0.8491    0.7616       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6063    0.5841    0.5579      1101
weighted avg     0.6361    0.6730    0.6289      1101

F1-macro sent:  0.5578705471388398
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9189    0.9645    0.9411     16205
           N     0.7796    0.6570    0.7130      1857
           P     0.8644    0.7267    0.7896      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8543    0.7827    0.8146     21274
weighted avg     0.8985    0.9017    0.8983     21274

F1-macro tok:  0.8145743329638385
F1-micro tok:  0.9017110087430666
**************************************************
Best epoch: 44
**************************************************

EPOCH: 47
Learning rate: 0.656100
train_cost_sum: 278081.39025878906
train_cost_avg: 32.54697919695565
train_count_sent: 8544.0
train_total_correct_sent: 6198.0
train_accuracy_sent: 0.7254213483146067
train_count_tok: 163566.0
train_total_correct_tok: 153290.0
train_accuracy_tok: 0.9371752075614737
train_label=O_precision_sent: 0.48660714285714285
train_label=O_recall_sent: 0.13423645320197045
train_label=O_f-score_sent: 0.2104247104247104
train_label=N_precision_sent: 0.7044164816185542
train_label=N_recall_sent: 0.8625377643504532
train_label=N_f-score_sent: 0.7754991172076598
train_label=P_precision_sent: 0.7729408854810784
train_label=P_recall_sent: 0.8656509695290858
train_label=P_f-score_sent: 0.8166732000522671
train_precision_macro_sent: 0.6546548366522585
train_recall_macro_sent: 0.6208083956938365
train_f-score_macro_sent: 0.600865675894879
train_precision_micro_sent: 0.7254213483146067
train_recall_micro_sent: 0.7254213483146067
train_f-score_micro_sent: 0.7254213483146066
train_label=O_precision_tok: 0.9514728511760826
train_label=O_recall_tok: 0.9746194118072813
train_label=O_f-score_tok: 0.9629070511165229
train_label=N_precision_tok: 0.8588455772113943
train_label=N_recall_tok: 0.8067173637515843
train_label=N_f-score_tok: 0.8319657250744318
train_label=P_precision_tok: 0.9032116916075961
train_label=P_recall_tok: 0.8251189191349882
train_label=P_f-score_tok: 0.8624010361179003
train_precision_macro_tok: 0.9045100399983577
train_recall_macro_tok: 0.8688185648979513
train_f-score_macro_tok: 0.885757937436285
train_precision_micro_tok: 0.9371752075614737
train_recall_micro_tok: 0.9371752075614737
train_f-score_micro_tok: 0.9371752075614737
train_time: 141.97315430641174
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4866    0.1342    0.2104      1624
           N     0.7044    0.8625    0.7755      3310
           P     0.7729    0.8657    0.8167      3610

   micro avg     0.7254    0.7254    0.7254      8544
   macro avg     0.6547    0.6208    0.6009      8544
weighted avg     0.6920    0.7254    0.6855      8544

F1-macro sent:  0.600865675894879
F1-micro sent:  0.7254213483146066
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9515    0.9746    0.9629    124347
           N     0.8588    0.8067    0.8320     14202
           P     0.9032    0.8251    0.8624     25017

   micro avg     0.9372    0.9372    0.9372    163566
   macro avg     0.9045    0.8688    0.8858    163566
weighted avg     0.9360    0.9372    0.9362    163566

F1-macro tok:  0.885757937436285
F1-micro tok:  0.9371752075614737
**************************************************
dev_cost_sum: 42623.64324951172
dev_cost_avg: 38.713572433707284
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19194.0
dev_accuracy_tok: 0.9022280718247626
dev_label=O_precision_sent: 0.4230769230769231
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.15658362989323843
dev_label=N_precision_sent: 0.6877551020408164
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.7342047930283224
dev_label=P_precision_sent: 0.6851520572450805
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7637088733798604
dev_precision_macro_sent: 0.5986613607876067
dev_recall_macro_sent: 0.5820218863927797
dev_f-score_macro_sent: 0.5514990987671404
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9156366604477612
dev_label=O_recall_tok: 0.9691453255168158
dev_label=O_f-score_tok: 0.9416314416764098
dev_label=N_precision_tok: 0.7921385742838108
dev_label=N_recall_tok: 0.6402800215401184
dev_label=N_f-score_tok: 0.7081596188207266
dev_label=P_precision_tok: 0.8775276611980161
dev_label=P_recall_tok: 0.7160647571606475
dev_label=P_f-score_tok: 0.7886164923709926
dev_precision_macro_tok: 0.8617676319765293
dev_recall_macro_tok: 0.7751633680725272
dev_f-score_macro_tok: 0.8128025176227096
dev_precision_micro_tok: 0.9022280718247626
dev_recall_micro_tok: 0.9022280718247626
dev_f-score_micro_tok: 0.9022280718247626
dev_time: 6.613261461257935
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4231    0.0961    0.1566       229
           N     0.6878    0.7874    0.7342       428
           P     0.6852    0.8626    0.7637       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.5987    0.5820    0.5515      1101
weighted avg     0.6317    0.6739    0.6260      1101

F1-macro sent:  0.5514990987671404
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9156    0.9691    0.9416     16205
           N     0.7921    0.6403    0.7082      1857
           P     0.8775    0.7161    0.7886      3212

   micro avg     0.9022    0.9022    0.9022     21274
   macro avg     0.8618    0.7752    0.8128     21274
weighted avg     0.8991    0.9022    0.8981     21274

F1-macro tok:  0.8128025176227096
F1-micro tok:  0.9022280718247626
**************************************************
Best epoch: 44
**************************************************

EPOCH: 48
Learning rate: 0.656100
train_cost_sum: 277259.6448364258
train_cost_avg: 32.450801127858824
train_count_sent: 8544.0
train_total_correct_sent: 6217.0
train_accuracy_sent: 0.7276451310861424
train_count_tok: 163566.0
train_total_correct_tok: 153562.0
train_accuracy_tok: 0.9388381448467286
train_label=O_precision_sent: 0.49176954732510286
train_label=O_recall_sent: 0.14716748768472906
train_label=O_f-score_sent: 0.2265402843601896
train_label=N_precision_sent: 0.7036946415463665
train_label=N_recall_sent: 0.8688821752265861
train_label=N_f-score_sent: 0.7776125456266053
train_label=P_precision_sent: 0.7811634349030471
train_label=P_recall_sent: 0.8592797783933518
train_label=P_f-score_sent: 0.8183616937079541
train_precision_macro_sent: 0.6588758745915055
train_recall_macro_sent: 0.6251098137682223
train_f-score_macro_sent: 0.607504841231583
train_precision_micro_sent: 0.7276451310861424
train_recall_micro_sent: 0.7276451310861424
train_f-score_micro_sent: 0.7276451310861423
train_label=O_precision_tok: 0.9530187626256671
train_label=O_recall_tok: 0.9750456384150804
train_label=O_f-score_tok: 0.9639063791897221
train_label=N_precision_tok: 0.8632985511598228
train_label=N_recall_tok: 0.8097451063230531
train_label=N_f-score_tok: 0.8356647167823275
train_label=P_precision_tok: 0.904186935371786
train_label=P_recall_tok: 0.8321541351880721
train_label=P_f-score_tok: 0.8666763805915779
train_precision_macro_tok: 0.906834749719092
train_recall_macro_tok: 0.872314959975402
train_f-score_macro_tok: 0.8887491588545425
train_precision_micro_tok: 0.9388381448467286
train_recall_micro_tok: 0.9388381448467286
train_f-score_micro_tok: 0.9388381448467286
train_time: 142.3280725479126
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4918    0.1472    0.2265      1624
           N     0.7037    0.8689    0.7776      3310
           P     0.7812    0.8593    0.8184      3610

   micro avg     0.7276    0.7276    0.7276      8544
   macro avg     0.6589    0.6251    0.6075      8544
weighted avg     0.6961    0.7276    0.6901      8544

F1-macro sent:  0.607504841231583
F1-micro sent:  0.7276451310861423
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9530    0.9750    0.9639    124347
           N     0.8633    0.8097    0.8357     14202
           P     0.9042    0.8322    0.8667     25017

   micro avg     0.9388    0.9388    0.9388    163566
   macro avg     0.9068    0.8723    0.8887    163566
weighted avg     0.9378    0.9388    0.9379    163566

F1-macro tok:  0.8887491588545425
F1-micro tok:  0.9388381448467286
**************************************************
dev_cost_sum: 42463.46911621094
dev_cost_avg: 38.56809184033691
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19142.0
dev_accuracy_tok: 0.8997837736203816
dev_label=O_precision_sent: 0.4666666666666667
dev_label=O_recall_sent: 0.09170305676855896
dev_label=O_f-score_sent: 0.15328467153284672
dev_label=N_precision_sent: 0.654275092936803
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7287784679089028
dev_label=P_precision_sent: 0.696911196911197
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7505197505197505
dev_precision_macro_sent: 0.6059509855048889
dev_recall_macro_sent: 0.575732008791226
dev_f-score_macro_sent: 0.5441942966538333
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9164761737295587
dev_label=O_recall_tok: 0.9648873804381364
dev_label=O_f-score_tok: 0.9400589190164131
dev_label=N_precision_tok: 0.798492117888965
dev_label=N_recall_tok: 0.6273559504577275
dev_label=N_f-score_tok: 0.7026537997587455
dev_label=P_precision_tok: 0.8500363108206246
dev_label=P_recall_tok: 0.7288293897882939
dev_label=P_f-score_tok: 0.7847804223935636
dev_precision_macro_tok: 0.8550015341463828
dev_recall_macro_tok: 0.7736909068947192
dev_f-score_macro_tok: 0.8091643803895741
dev_precision_micro_tok: 0.8997837736203816
dev_recall_micro_tok: 0.8997837736203816
dev_f-score_micro_tok: 0.8997837736203816
dev_time: 6.788236618041992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0917    0.1533       229
           N     0.6543    0.8224    0.7288       428
           P     0.6969    0.8131    0.7505       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6060    0.5757    0.5442      1101
weighted avg     0.6324    0.6667    0.6178      1101

F1-macro sent:  0.5441942966538333
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9165    0.9649    0.9401     16205
           N     0.7985    0.6274    0.7027      1857
           P     0.8500    0.7288    0.7848      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8550    0.7737    0.8092     21274
weighted avg     0.8961    0.8998    0.8959     21274

F1-macro tok:  0.8091643803895741
F1-micro tok:  0.8997837736203816
**************************************************
Best epoch: 44
**************************************************

EPOCH: 49
Learning rate: 0.590490
train_cost_sum: 276528.46044921875
train_cost_avg: 32.36522243085425
train_count_sent: 8544.0
train_total_correct_sent: 6256.0
train_accuracy_sent: 0.7322097378277154
train_count_tok: 163566.0
train_total_correct_tok: 153727.0
train_accuracy_tok: 0.9398469119499162
train_label=O_precision_sent: 0.5216572504708098
train_label=O_recall_sent: 0.1705665024630542
train_label=O_f-score_sent: 0.25707656612529006
train_label=N_precision_sent: 0.7147869674185464
train_label=N_recall_sent: 0.861631419939577
train_label=N_f-score_sent: 0.7813698630136987
train_label=P_precision_sent: 0.777280636341039
train_label=P_recall_sent: 0.8662049861495845
train_label=P_f-score_sent: 0.8193370889558497
train_precision_macro_sent: 0.6712416180767984
train_recall_macro_sent: 0.6328009695174052
train_f-score_macro_sent: 0.6192611726982795
train_precision_micro_sent: 0.7322097378277154
train_recall_micro_sent: 0.7322097378277154
train_f-score_micro_sent: 0.7322097378277154
train_label=O_precision_tok: 0.9538647874917419
train_label=O_recall_tok: 0.975351234850861
train_label=O_f-score_tok: 0.964488359609535
train_label=N_precision_tok: 0.8625421822272216
train_label=N_recall_tok: 0.8098859315589354
train_label=N_f-score_tok: 0.8353851182045974
train_label=P_precision_tok: 0.9072910800155959
train_label=P_recall_tok: 0.837150737498501
train_label=P_f-score_tok: 0.8708108108108107
train_precision_macro_tok: 0.9078993499115198
train_recall_macro_tok: 0.8741293013027658
train_f-score_macro_tok: 0.8902280962083143
train_precision_micro_tok: 0.9398469119499162
train_recall_micro_tok: 0.9398469119499162
train_f-score_micro_tok: 0.9398469119499162
train_time: 142.756356716156
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5217    0.1706    0.2571      1624
           N     0.7148    0.8616    0.7814      3310
           P     0.7773    0.8662    0.8193      3610

   micro avg     0.7322    0.7322    0.7322      8544
   macro avg     0.6712    0.6328    0.6193      8544
weighted avg     0.7045    0.7322    0.6978      8544

F1-macro sent:  0.6192611726982795
F1-micro sent:  0.7322097378277154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9539    0.9754    0.9645    124347
           N     0.8625    0.8099    0.8354     14202
           P     0.9073    0.8372    0.8708     25017

   micro avg     0.9398    0.9398    0.9398    163566
   macro avg     0.9079    0.8741    0.8902    163566
weighted avg     0.9388    0.9398    0.9390    163566

F1-macro tok:  0.8902280962083143
F1-micro tok:  0.9398469119499162
**************************************************
dev_cost_sum: 42373.186279296875
dev_cost_avg: 38.48609108019698
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19168.0
dev_accuracy_tok: 0.9010059227225722
dev_label=O_precision_sent: 0.4222222222222222
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.1386861313868613
dev_label=N_precision_sent: 0.6767068273092369
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.7278617710583153
dev_label=P_precision_sent: 0.6845878136200717
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7624750499001997
dev_precision_macro_sent: 0.5945056210505103
dev_recall_macro_sent: 0.5769043234149548
dev_f-score_macro_sent: 0.5430076507817921
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9183949239175137
dev_label=O_recall_tok: 0.9646405430422709
dev_label=O_f-score_tok: 0.9409498585445133
dev_label=N_precision_tok: 0.7927392739273927
dev_label=N_recall_tok: 0.6467420570813139
dev_label=N_f-score_tok: 0.7123368920521945
dev_label=P_precision_tok: 0.8528122717311907
dev_label=P_recall_tok: 0.726961394769614
dev_label=P_f-score_tok: 0.7848739495798319
dev_precision_macro_tok: 0.8546488231920324
dev_recall_macro_tok: 0.779447998297733
dev_f-score_macro_tok: 0.8127202333921799
dev_precision_micro_tok: 0.9010059227225722
dev_recall_micro_tok: 0.9010059227225722
dev_f-score_micro_tok: 0.9010059227225722
dev_time: 6.907538414001465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4222    0.0830    0.1387       229
           N     0.6767    0.7874    0.7279       428
           P     0.6846    0.8604    0.7625       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.5945    0.5769    0.5430      1101
weighted avg     0.6270    0.6703    0.6193      1101

F1-macro sent:  0.5430076507817921
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9646    0.9409     16205
           N     0.7927    0.6467    0.7123      1857
           P     0.8528    0.7270    0.7849      3212

   micro avg     0.9010    0.9010    0.9010     21274
   macro avg     0.8546    0.7794    0.8127     21274
weighted avg     0.8975    0.9010    0.8974     21274

F1-macro tok:  0.8127202333921799
F1-micro tok:  0.9010059227225722
**************************************************
Best epoch: 44
**************************************************

EPOCH: 50
Learning rate: 0.531441
train_cost_sum: 275484.16174316406
train_cost_avg: 32.24299645870366
train_count_sent: 8544.0
train_total_correct_sent: 6247.0
train_accuracy_sent: 0.7311563670411985
train_count_tok: 163566.0
train_total_correct_tok: 153988.0
train_accuracy_tok: 0.9414425980949586
train_label=O_precision_sent: 0.5170940170940171
train_label=O_recall_sent: 0.14901477832512317
train_label=O_f-score_sent: 0.23135755258126198
train_label=N_precision_sent: 0.7085476365417586
train_label=N_recall_sent: 0.8740181268882176
train_label=N_f-score_sent: 0.7826322196672528
train_label=P_precision_sent: 0.7793638868019034
train_label=P_recall_sent: 0.8620498614958448
train_label=P_f-score_sent: 0.8186242272787059
train_precision_macro_sent: 0.6683351801458931
train_recall_macro_sent: 0.6283609222363952
train_f-score_macro_sent: 0.6108713331757402
train_precision_micro_sent: 0.7311563670411985
train_recall_micro_sent: 0.7311563670411985
train_f-score_micro_sent: 0.7311563670411985
train_label=O_precision_tok: 0.9551665512247339
train_label=O_recall_tok: 0.9759141756536145
train_label=O_f-score_tok: 0.9654289067006107
train_label=N_precision_tok: 0.8689959598982493
train_label=N_recall_tok: 0.8178425573862836
train_label=N_f-score_tok: 0.8426436448055719
train_label=P_precision_tok: 0.9079561161022806
train_label=P_recall_tok: 0.8402686173402086
train_label=P_f-score_tok: 0.8728020095912309
train_precision_macro_tok: 0.910706209075088
train_recall_macro_tok: 0.8780084501267024
train_f-score_macro_tok: 0.8936248536991379
train_precision_micro_tok: 0.9414425980949586
train_recall_micro_tok: 0.9414425980949586
train_f-score_micro_tok: 0.9414425980949586
train_time: 141.8717589378357
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5171    0.1490    0.2314      1624
           N     0.7085    0.8740    0.7826      3310
           P     0.7794    0.8620    0.8186      3610

   micro avg     0.7312    0.7312    0.7312      8544
   macro avg     0.6683    0.6284    0.6109      8544
weighted avg     0.7021    0.7312    0.6931      8544

F1-macro sent:  0.6108713331757402
F1-micro sent:  0.7311563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9552    0.9759    0.9654    124347
           N     0.8690    0.8178    0.8426     14202
           P     0.9080    0.8403    0.8728     25017

   micro avg     0.9414    0.9414    0.9414    163566
   macro avg     0.9107    0.8780    0.8936    163566
weighted avg     0.9405    0.9414    0.9406    163566

F1-macro tok:  0.8936248536991379
F1-micro tok:  0.9414425980949586
**************************************************
dev_cost_sum: 42650.22607421875
dev_cost_avg: 38.73771668866372
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19183.0
dev_accuracy_tok: 0.9017110087430666
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.1358490566037736
dev_label=N_precision_sent: 0.6818181818181818
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7387580299785865
dev_label=P_precision_sent: 0.6815742397137746
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7597208374875373
dev_precision_macro_sent: 0.6211308071773187
dev_recall_macro_sent: 0.5809284981835282
dev_f-score_macro_sent: 0.5447759746899657
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9163258151221222
dev_label=O_recall_tok: 0.9677260104905894
dev_label=O_f-score_tok: 0.94132476965095
dev_label=N_precision_tok: 0.8074792243767313
dev_label=N_recall_tok: 0.6278944534194938
dev_label=N_f-score_tok: 0.7064525901242047
dev_label=P_precision_tok: 0.8597201767304861
dev_label=P_recall_tok: 0.726961394769614
dev_label=P_f-score_tok: 0.7877867746288798
dev_precision_macro_tok: 0.8611750720764465
dev_recall_macro_tok: 0.7741939528932323
dev_f-score_macro_tok: 0.8118547114680115
dev_precision_micro_tok: 0.9017110087430666
dev_recall_micro_tok: 0.9017110087430666
dev_f-score_micro_tok: 0.9017110087430666
dev_time: 7.083451509475708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0786    0.1358       229
           N     0.6818    0.8061    0.7388       428
           P     0.6816    0.8581    0.7597       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6211    0.5809    0.5448      1101
weighted avg     0.6439    0.6757    0.6218      1101

F1-macro sent:  0.5447759746899657
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9163    0.9677    0.9413     16205
           N     0.8075    0.6279    0.7065      1857
           P     0.8597    0.7270    0.7878      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8612    0.7742    0.8119     21274
weighted avg     0.8983    0.9017    0.8976     21274

F1-macro tok:  0.8118547114680115
F1-micro tok:  0.9017110087430666
**************************************************
Best epoch: 44
**************************************************

EPOCH: 51
Learning rate: 0.478297
train_cost_sum: 274455.0842895508
train_cost_avg: 32.12255200018151
train_count_sent: 8544.0
train_total_correct_sent: 6265.0
train_accuracy_sent: 0.7332631086142322
train_count_tok: 163566.0
train_total_correct_tok: 154372.0
train_accuracy_tok: 0.9437902742623773
train_label=O_precision_sent: 0.5142231947483589
train_label=O_recall_sent: 0.14470443349753695
train_label=O_f-score_sent: 0.22585295530994715
train_label=N_precision_sent: 0.7090686274509804
train_label=N_recall_sent: 0.8740181268882176
train_label=N_f-score_sent: 0.7829499323410013
train_label=P_precision_sent: 0.7828799600698777
train_label=P_recall_sent: 0.8689750692520776
train_label=P_f-score_sent: 0.8236838650387291
train_precision_macro_sent: 0.6687239274230724
train_recall_macro_sent: 0.6292325432126108
train_f-score_macro_sent: 0.6108289175632259
train_precision_micro_sent: 0.7332631086142322
train_recall_micro_sent: 0.7332631086142322
train_f-score_micro_sent: 0.7332631086142322
train_label=O_precision_tok: 0.9570887143161063
train_label=O_recall_tok: 0.976839006972424
train_label=O_f-score_tok: 0.9668630104274456
train_label=N_precision_tok: 0.8726633767010618
train_label=N_recall_tok: 0.8217856639909872
train_label=N_f-score_tok: 0.8464606904554685
train_label=P_precision_tok: 0.9121525838738778
train_label=P_recall_tok: 0.8487828276771795
train_label=P_f-score_tok: 0.8793274805366905
train_precision_macro_tok: 0.913968224963682
train_recall_macro_tok: 0.8824691662135303
train_f-score_macro_tok: 0.8975503938065348
train_precision_micro_tok: 0.9437902742623773
train_recall_micro_tok: 0.9437902742623773
train_f-score_micro_tok: 0.9437902742623773
train_time: 142.1751410961151
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5142    0.1447    0.2259      1624
           N     0.7091    0.8740    0.7829      3310
           P     0.7829    0.8690    0.8237      3610

   micro avg     0.7333    0.7333    0.7333      8544
   macro avg     0.6687    0.6292    0.6108      8544
weighted avg     0.7032    0.7333    0.6943      8544

F1-macro sent:  0.6108289175632259
F1-micro sent:  0.7332631086142322
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9571    0.9768    0.9669    124347
           N     0.8727    0.8218    0.8465     14202
           P     0.9122    0.8488    0.8793     25017

   micro avg     0.9438    0.9438    0.9438    163566
   macro avg     0.9140    0.8825    0.8976    163566
weighted avg     0.9429    0.9438    0.9430    163566

F1-macro tok:  0.8975503938065348
F1-micro tok:  0.9437902742623773
**************************************************
dev_cost_sum: 42412.40203857422
dev_cost_avg: 38.52170939016732
dev_count_sent: 1101.0
dev_total_correct_sent: 751.0
dev_accuracy_sent: 0.6821071752951862
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.47619047619047616
dev_label=O_recall_sent: 0.13100436681222707
dev_label=O_f-score_sent: 0.2054794520547945
dev_label=N_precision_sent: 0.689108910891089
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7459807073954984
dev_label=P_precision_sent: 0.699812382739212
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7635619242579325
dev_precision_macro_sent: 0.6217039232735924
dev_recall_macro_sent: 0.59472618968395
dev_f-score_macro_sent: 0.5716740279027418
dev_precision_micro_sent: 0.6821071752951862
dev_recall_micro_sent: 0.6821071752951862
dev_f-score_micro_sent: 0.6821071752951862
dev_label=O_precision_tok: 0.9224723115398357
dev_label=O_recall_tok: 0.9560012341869794
dev_label=O_f-score_tok: 0.9389375435619262
dev_label=N_precision_tok: 0.7576126674786845
dev_label=N_recall_tok: 0.6698976844372644
dev_label=N_f-score_tok: 0.7110603029436983
dev_label=P_precision_tok: 0.8305144467935166
dev_label=P_recall_tok: 0.7338107098381071
dev_label=P_f-score_tok: 0.7791735537190083
dev_precision_macro_tok: 0.8368664752706789
dev_recall_macro_tok: 0.7865698761541169
dev_f-score_macro_tok: 0.8097238000748775
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 7.181843042373657
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4762    0.1310    0.2055       229
           N     0.6891    0.8131    0.7460       428
           P     0.6998    0.8401    0.7636       444

   micro avg     0.6821    0.6821    0.6821      1101
   macro avg     0.6217    0.5947    0.5717      1101
weighted avg     0.6491    0.6821    0.6407      1101

F1-macro sent:  0.5716740279027418
F1-micro sent:  0.6821071752951862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9225    0.9560    0.9389     16205
           N     0.7576    0.6699    0.7111      1857
           P     0.8305    0.7338    0.7792      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8369    0.7866    0.8097     21274
weighted avg     0.8942    0.8975    0.8949     21274

F1-macro tok:  0.8097238000748775
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 44
**************************************************

test0_cost_sum: 42214.35778808594
test0_cost_avg: 38.341832686726555
test0_count_sent: 1101.0
test0_total_correct_sent: 733.0
test0_accuracy_sent: 0.6657584014532243
test0_count_tok: 21274.0
test0_total_correct_tok: 19192.0
test0_accuracy_tok: 0.9021340603553634
test0_label=O_precision_sent: 0.33076923076923076
test0_label=O_recall_sent: 0.18777292576419213
test0_label=O_f-score_sent: 0.23955431754874648
test0_label=N_precision_sent: 0.6778656126482213
test0_label=N_recall_sent: 0.8014018691588785
test0_label=N_f-score_sent: 0.734475374732334
test0_label=P_precision_sent: 0.7462365591397849
test0_label=P_recall_sent: 0.7815315315315315
test0_label=P_f-score_sent: 0.7634763476347635
test0_precision_macro_sent: 0.5849571341857457
test0_recall_macro_sent: 0.590235442151534
test0_f-score_macro_sent: 0.579168679971948
test0_precision_micro_sent: 0.6657584014532243
test0_recall_micro_sent: 0.6657584014532243
test0_f-score_micro_sent: 0.6657584014532243
test0_label=O_precision_tok: 0.9184415889221381
test0_label=O_recall_tok: 0.9659364393705646
test0_label=O_f-score_tok: 0.9415904716073148
test0_label=N_precision_tok: 0.7735849056603774
test0_label=N_recall_tok: 0.6623586429725363
test0_label=N_f-score_tok: 0.7136640557006092
test0_label=P_precision_tok: 0.8742900416508899
test0_label=P_recall_tok: 0.7188667496886675
test0_label=P_f-score_tok: 0.7889970955065778
test0_precision_macro_tok: 0.8554388454111352
test0_recall_macro_tok: 0.7823872773439228
test0_f-score_macro_tok: 0.8147505409381672
test0_precision_micro_tok: 0.9021340603553634
test0_recall_micro_tok: 0.9021340603553634
test0_f-score_micro_tok: 0.9021340603553635
test0_time: 7.302399396896362
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3308    0.1878    0.2396       229
           N     0.6779    0.8014    0.7345       428
           P     0.7462    0.7815    0.7635       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.5850    0.5902    0.5792      1101
weighted avg     0.6332    0.6658    0.6432      1101

F1-macro sent:  0.579168679971948
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9659    0.9416     16205
           N     0.7736    0.6624    0.7137      1857
           P     0.8743    0.7189    0.7890      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8554    0.7824    0.8148     21274
weighted avg     0.8991    0.9021    0.8987     21274

F1-macro tok:  0.8147505409381672
F1-micro tok:  0.9021340603553635
**************************************************
test1_cost_sum: 81754.9852027893
test1_cost_avg: 36.99320597411281
test1_count_sent: 2210.0
test1_total_correct_sent: 1516.0
test1_accuracy_sent: 0.685972850678733
test1_count_tok: 42405.0
test1_total_correct_tok: 37971.0
test1_accuracy_tok: 0.8954368588609833
test1_label=O_precision_sent: 0.3127147766323024
test1_label=O_recall_sent: 0.23393316195372751
test1_label=O_f-score_sent: 0.2676470588235294
test1_label=N_precision_sent: 0.7144268774703557
test1_label=N_recall_sent: 0.7927631578947368
test1_label=N_f-score_sent: 0.7515592515592515
test1_label=P_precision_sent: 0.7739801543550165
test1_label=P_recall_sent: 0.7722772277227723
test1_label=P_f-score_sent: 0.7731277533039649
test1_precision_macro_sent: 0.6003739361525583
test1_recall_macro_sent: 0.5996578491904122
test1_f-score_macro_sent: 0.5974446878955819
test1_precision_micro_sent: 0.685972850678733
test1_recall_micro_sent: 0.685972850678733
test1_f-score_micro_sent: 0.685972850678733
test1_label=O_precision_tok: 0.9098497986537727
test1_label=O_recall_tok: 0.9673729608100506
test1_label=O_f-score_tok: 0.9377300474105938
test1_label=N_precision_tok: 0.76504914004914
test1_label=N_recall_tok: 0.6625
test1_label=N_f-score_tok: 0.7100912200684151
test1_label=P_precision_tok: 0.8826053042121685
test1_label=P_recall_tok: 0.680908680607793
test1_label=P_f-score_tok: 0.7687473460721869
test1_precision_macro_tok: 0.852501414305027
test1_recall_macro_tok: 0.7702605471392813
test1_f-score_macro_tok: 0.805522871183732
test1_precision_micro_tok: 0.8954368588609833
test1_recall_micro_tok: 0.8954368588609833
test1_f-score_micro_tok: 0.8954368588609833
test1_time: 16.670136213302612
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3127    0.2339    0.2676       389
           N     0.7144    0.7928    0.7516       912
           P     0.7740    0.7723    0.7731       909

   micro avg     0.6860    0.6860    0.6860      2210
   macro avg     0.6004    0.5997    0.5974      2210
weighted avg     0.6682    0.6860    0.6753      2210

F1-macro sent:  0.5974446878955819
F1-micro sent:  0.685972850678733
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9098    0.9674    0.9377     31998
           N     0.7650    0.6625    0.7101      3760
           P     0.8826    0.6809    0.7687      6647

   micro avg     0.8954    0.8954    0.8954     42405
   macro avg     0.8525    0.7703    0.8055     42405
weighted avg     0.8927    0.8954    0.8911     42405

F1-macro tok:  0.805522871183732
F1-micro tok:  0.8954368588609833
**************************************************
