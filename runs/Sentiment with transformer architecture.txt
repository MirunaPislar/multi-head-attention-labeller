debug_mode: False
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.3
masking_attention: False
residual_connection: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'O': 0, 'P': 2}
{'N': 1, 'O': 0, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-05 18:42:46.929143: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-05 18:42:52.709573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: e7b6:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-05 18:42:52.709638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-05 18:43:16.032731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-05 18:43:16.032809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-05 18:43:16.032825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-05 18:43:16.033170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: e7b6:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7751365.
Parameter count without word embeddings: 1950865.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 113277.1819152832
train_cost_avg: 13.258097134279401
train_count_sent: 8544.0
train_total_correct_sent: 3663.0
train_accuracy_sent: 0.42872191011235955
train_count_tok: 163566.0
train_total_correct_tok: 126196.0
train_accuracy_tok: 0.7715295354780334
train_label=O_precision_sent: 0.18681318681318682
train_label=O_recall_sent: 0.020935960591133004
train_label=O_f-score_sent: 0.03765227021040974
train_label=N_precision_sent: 0.4122995932041158
train_label=N_recall_sent: 0.5205438066465257
train_label=N_f-score_sent: 0.46014154092669246
train_label=P_precision_sent: 0.45565383695912026
train_label=P_recall_sent: 0.52797783933518
train_label=P_f-score_sent: 0.489156935711536
train_precision_macro_sent: 0.3515888723254743
train_recall_macro_sent: 0.3564858688576129
train_f-score_macro_sent: 0.32898358228287944
train_precision_micro_sent: 0.42872191011235955
train_recall_micro_sent: 0.42872191011235955
train_f-score_micro_sent: 0.4287219101123596
train_label=O_precision_tok: 0.7877393381991948
train_label=O_recall_tok: 0.9677676180366234
train_label=O_f-score_tok: 0.8685224746672826
train_label=N_precision_tok: 0.5091981132075472
train_label=N_recall_tok: 0.15202084213491057
train_label=N_f-score_tok: 0.23413946426634857
train_label=P_precision_tok: 0.5636335924401769
train_label=P_recall_tok: 0.14781948275172882
train_label=P_f-score_tok: 0.23421369307745898
train_precision_macro_tok: 0.6201903479489729
train_recall_macro_tok: 0.4225359809744209
train_f-score_macro_tok: 0.44562521067036337
train_precision_micro_tok: 0.7715295354780334
train_recall_micro_tok: 0.7715295354780334
train_f-score_micro_tok: 0.7715295354780334
train_time: 54.19727683067322
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1868    0.0209    0.0377      1624
           N     0.4123    0.5205    0.4601      3310
           P     0.4557    0.5280    0.4892      3610

   micro avg     0.4287    0.4287    0.4287      8544
   macro avg     0.3516    0.3565    0.3290      8544
weighted avg     0.3878    0.4287    0.3921      8544

F1-macro sent:  0.32898358228287944
F1-micro sent:  0.4287219101123596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7877    0.9678    0.8685    124347
           N     0.5092    0.1520    0.2341     14202
           P     0.5636    0.1478    0.2342     25017

   micro avg     0.7715    0.7715    0.7715    163566
   macro avg     0.6202    0.4225    0.4456    163566
weighted avg     0.7293    0.7715    0.7164    163566

F1-macro tok:  0.44562521067036337
F1-micro tok:  0.7715295354780334
**************************************************
dev_cost_sum: 11934.168731689453
dev_cost_avg: 10.839390310344644
dev_count_sent: 1101.0
dev_total_correct_sent: 456.0
dev_accuracy_sent: 0.4141689373297003
dev_count_tok: 21274.0
dev_total_correct_tok: 17371.0
dev_accuracy_tok: 0.816536617467331
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6206896551724138
dev_label=N_recall_sent: 0.04205607476635514
dev_label=N_f-score_sent: 0.0787746170678337
dev_label=P_precision_sent: 0.4085820895522388
dev_label=P_recall_sent: 0.9864864864864865
dev_label=P_f-score_sent: 0.5778364116094986
dev_precision_macro_sent: 0.3430905815748842
dev_recall_macro_sent: 0.34284752041761385
dev_f-score_macro_sent: 0.21887034289244411
dev_precision_micro_sent: 0.4141689373297003
dev_recall_micro_sent: 0.4141689373297003
dev_f-score_micro_sent: 0.41416893732970034
dev_label=O_precision_tok: 0.8454878454878455
dev_label=O_recall_tok: 0.9400802221536563
dev_label=O_f-score_tok: 0.8902784676971627
dev_label=N_precision_tok: 0.7442424242424243
dev_label=N_recall_tok: 0.3306408185245019
dev_label=N_f-score_tok: 0.45786726323639076
dev_label=P_precision_tok: 0.6264911559029206
dev_label=P_recall_tok: 0.47415940224159403
dev_label=P_f-score_tok: 0.5397838029416977
dev_precision_macro_tok: 0.7387404752110635
dev_recall_macro_tok: 0.581626814306584
dev_f-score_macro_tok: 0.6293098446250837
dev_precision_micro_tok: 0.816536617467331
dev_recall_micro_tok: 0.816536617467331
dev_f-score_micro_tok: 0.816536617467331
dev_time: 2.39442777633667
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6207    0.0421    0.0788       428
           P     0.4086    0.9865    0.5778       444

   micro avg     0.4142    0.4142    0.4142      1101
   macro avg     0.3431    0.3428    0.2189      1101
weighted avg     0.4061    0.4142    0.2636      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.21887034289244411
F1-micro sent:  0.41416893732970034
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8455    0.9401    0.8903     16205
           N     0.7442    0.3306    0.4579      1857
           P     0.6265    0.4742    0.5398      3212

   micro avg     0.8165    0.8165    0.8165     21274
   macro avg     0.7387    0.5816    0.6293     21274
weighted avg     0.8036    0.8165    0.7996     21274

F1-macro tok:  0.6293098446250837
F1-micro tok:  0.816536617467331
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 90697.23838806152
train_cost_avg: 10.615313481748775
train_count_sent: 8544.0
train_total_correct_sent: 4290.0
train_accuracy_sent: 0.5021067415730337
train_count_tok: 163566.0
train_total_correct_tok: 132832.0
train_accuracy_tok: 0.812100314246237
train_label=O_precision_sent: 0.30120481927710846
train_label=O_recall_sent: 0.01539408866995074
train_label=O_f-score_sent: 0.02929115407147042
train_label=N_precision_sent: 0.4911717495987159
train_label=N_recall_sent: 0.5546827794561934
train_label=N_f-score_sent: 0.5209988649262203
train_label=P_precision_sent: 0.5142917637095067
train_label=P_recall_sent: 0.6728531855955678
train_label=P_f-score_sent: 0.5829833193327734
train_precision_macro_sent: 0.435556110861777
train_recall_macro_sent: 0.41431001790723726
train_f-score_macro_sent: 0.37775777944348804
train_precision_micro_sent: 0.5021067415730337
train_recall_micro_sent: 0.5021067415730337
train_f-score_micro_sent: 0.5021067415730337
train_label=O_precision_tok: 0.833604278827545
train_label=O_recall_tok: 0.9525843003852124
train_label=O_f-score_tok: 0.8891315933674121
train_label=N_precision_tok: 0.6512267828479706
train_label=N_recall_tok: 0.3999436699056471
train_label=N_f-score_tok: 0.4955505147443727
train_label=P_precision_tok: 0.6824849007765315
train_label=P_recall_tok: 0.34780349362433544
train_label=P_f-score_tok: 0.4607848329184981
train_precision_macro_tok: 0.7224386541506824
train_recall_macro_tok: 0.5667771546383983
train_f-score_macro_tok: 0.6151556470100943
train_precision_micro_tok: 0.812100314246237
train_recall_micro_tok: 0.812100314246237
train_f-score_micro_tok: 0.812100314246237
train_time: 45.98506951332092
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3012    0.0154    0.0293      1624
           N     0.4912    0.5547    0.5210      3310
           P     0.5143    0.6729    0.5830      3610

   micro avg     0.5021    0.5021    0.5021      8544
   macro avg     0.4356    0.4143    0.3778      8544
weighted avg     0.4648    0.5021    0.4537      8544

F1-macro sent:  0.37775777944348804
F1-micro sent:  0.5021067415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8336    0.9526    0.8891    124347
           N     0.6512    0.3999    0.4956     14202
           P     0.6825    0.3478    0.4608     25017

   micro avg     0.8121    0.8121    0.8121    163566
   macro avg     0.7224    0.5668    0.6152    163566
weighted avg     0.7947    0.8121    0.7894    163566

F1-macro tok:  0.6151556470100943
F1-micro tok:  0.812100314246237
**************************************************
dev_cost_sum: 10567.772659301758
dev_cost_avg: 9.598340290010679
dev_count_sent: 1101.0
dev_total_correct_sent: 560.0
dev_accuracy_sent: 0.508628519527702
dev_count_tok: 21274.0
dev_total_correct_tok: 17774.0
dev_accuracy_tok: 0.8354799285512833
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.44656084656084655
dev_label=N_recall_sent: 0.985981308411215
dev_label=N_f-score_sent: 0.6147123088128186
dev_label=P_precision_sent: 0.8846153846153846
dev_label=P_recall_sent: 0.3108108108108108
dev_label=P_f-score_sent: 0.46
dev_precision_macro_sent: 0.4437254103920771
dev_recall_macro_sent: 0.43226403974067523
dev_f-score_macro_sent: 0.3582374362709395
dev_precision_micro_sent: 0.508628519527702
dev_recall_micro_sent: 0.508628519527702
dev_f-score_micro_sent: 0.508628519527702
dev_label=O_precision_tok: 0.846058181031686
dev_label=O_recall_tok: 0.9655661832767665
dev_label=O_f-score_tok: 0.9018703709040606
dev_label=N_precision_tok: 0.6906528189910979
dev_label=N_recall_tok: 0.5013462574044157
dev_label=N_f-score_tok: 0.5809672386895476
dev_label=P_precision_tok: 0.835195530726257
dev_label=P_recall_tok: 0.3723536737235367
dev_label=P_f-score_tok: 0.5150732127476313
dev_precision_macro_tok: 0.7906355102496803
dev_recall_macro_tok: 0.613088704801573
dev_f-score_macro_tok: 0.6659702741137465
dev_precision_micro_tok: 0.8354799285512833
dev_recall_micro_tok: 0.8354799285512833
dev_f-score_micro_tok: 0.8354799285512833
dev_time: 2.125192165374756
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4466    0.9860    0.6147       428
           P     0.8846    0.3108    0.4600       444

   micro avg     0.5086    0.5086    0.5086      1101
   macro avg     0.4437    0.4323    0.3582      1101
weighted avg     0.5303    0.5086    0.4245      1101

F1-macro sent:  0.3582374362709395
F1-micro sent:  0.508628519527702
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8461    0.9656    0.9019     16205
           N     0.6907    0.5013    0.5810      1857
           P     0.8352    0.3724    0.5151      3212

   micro avg     0.8355    0.8355    0.8355     21274
   macro avg     0.7906    0.6131    0.6660     21274
weighted avg     0.8309    0.8355    0.8155     21274

F1-macro tok:  0.6659702741137465
F1-micro tok:  0.8354799285512833
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 84137.66459655762
train_cost_avg: 9.847573103529683
train_count_sent: 8544.0
train_total_correct_sent: 4802.0
train_accuracy_sent: 0.5620318352059925
train_count_tok: 163566.0
train_total_correct_tok: 135826.0
train_accuracy_tok: 0.8304048518640793
train_label=O_precision_sent: 0.21875
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008454106280193236
train_label=N_precision_sent: 0.5302854490601068
train_label=N_recall_sent: 0.6903323262839879
train_label=N_f-score_sent: 0.5998162488515554
train_label=P_precision_sent: 0.59719248156079
train_label=P_recall_sent: 0.6952908587257618
train_label=P_f-score_sent: 0.6425188787917574
train_precision_macro_sent: 0.44874264354029886
train_recall_macro_sent: 0.4633111766124453
train_f-score_macro_sent: 0.41692974464116866
train_precision_micro_sent: 0.5620318352059925
train_recall_micro_sent: 0.5620318352059925
train_f-score_micro_sent: 0.5620318352059925
train_label=O_precision_tok: 0.8507389904408127
train_label=O_recall_tok: 0.9540479464723717
train_label=O_f-score_tok: 0.8994366816531081
train_label=N_precision_tok: 0.6775268033725409
train_label=N_recall_tok: 0.458315730178848
train_label=N_f-score_tok: 0.5467680288966358
train_label=P_precision_tok: 0.7362183020948181
train_label=P_recall_tok: 0.42706959267697964
train_label=P_f-score_tok: 0.540565154696552
train_precision_macro_tok: 0.7548280319693905
train_recall_macro_tok: 0.6131444231093998
train_f-score_macro_tok: 0.6622566217487652
train_precision_micro_tok: 0.8304048518640793
train_recall_micro_tok: 0.8304048518640793
train_f-score_micro_tok: 0.8304048518640793
train_time: 46.01413297653198
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2188    0.0043    0.0085      1624
           N     0.5303    0.6903    0.5998      3310
           P     0.5972    0.6953    0.6425      3610

   micro avg     0.5620    0.5620    0.5620      8544
   macro avg     0.4487    0.4633    0.4169      8544
weighted avg     0.4993    0.5620    0.5055      8544

F1-macro sent:  0.41692974464116866
F1-micro sent:  0.5620318352059925
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8507    0.9540    0.8994    124347
           N     0.6775    0.4583    0.5468     14202
           P     0.7362    0.4271    0.5406     25017

   micro avg     0.8304    0.8304    0.8304    163566
   macro avg     0.7548    0.6131    0.6623    163566
weighted avg     0.8182    0.8304    0.8139    163566

F1-macro tok:  0.6622566217487652
F1-micro tok:  0.8304048518640793
**************************************************
dev_cost_sum: 9802.993469238281
dev_cost_avg: 8.903717955711427
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 18292.0
dev_accuracy_tok: 0.8598288991256934
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.15492957746478872
dev_label=N_precision_sent: 0.5626959247648903
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.6735459662288931
dev_label=P_precision_sent: 0.7156862745098039
dev_label=P_recall_sent: 0.6576576576576577
dev_label=P_f-score_sent: 0.6854460093896714
dev_precision_macro_sent: 0.5594607330915647
dev_recall_macro_sent: 0.5308375244607543
dev_f-score_macro_sent: 0.5046405176944511
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.8736263736263736
dev_label=O_recall_tok: 0.9615550755939525
dev_label=O_f-score_tok: 0.9154842689697716
dev_label=N_precision_tok: 0.7521891418563923
dev_label=N_recall_tok: 0.46257404415724285
dev_label=N_f-score_tok: 0.5728576192064021
dev_label=P_precision_tok: 0.806184668989547
dev_label=P_recall_tok: 0.5762764632627646
dev_label=P_f-score_tok: 0.6721132897603486
dev_precision_macro_tok: 0.8106667281574377
dev_recall_macro_tok: 0.6668018610046533
dev_f-score_macro_tok: 0.7201517259788407
dev_precision_micro_tok: 0.8598288991256934
dev_recall_micro_tok: 0.8598288991256934
dev_f-score_micro_tok: 0.8598288991256934
dev_time: 2.0816378593444824
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0961    0.1549       229
           N     0.5627    0.8388    0.6735       428
           P     0.7157    0.6577    0.6854       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.5595    0.5308    0.5046      1101
weighted avg     0.5906    0.6113    0.5705      1101

F1-macro sent:  0.5046405176944511
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8736    0.9616    0.9155     16205
           N     0.7522    0.4626    0.5729      1857
           P     0.8062    0.5763    0.6721      3212

   micro avg     0.8598    0.8598    0.8598     21274
   macro avg     0.8107    0.6668    0.7202     21274
weighted avg     0.8528    0.8598    0.8488     21274

F1-macro tok:  0.7201517259788407
F1-micro tok:  0.8598288991256934
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 79227.58721923828
train_cost_avg: 9.272891762551296
train_count_sent: 8544.0
train_total_correct_sent: 4936.0
train_accuracy_sent: 0.5777153558052435
train_count_tok: 163566.0
train_total_correct_tok: 138205.0
train_accuracy_tok: 0.8449494393700402
train_label=O_precision_sent: 0.30612244897959184
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.01793185893604304
train_label=N_precision_sent: 0.547040792265975
train_label=N_recall_sent: 0.7009063444108762
train_label=N_f-score_sent: 0.614488147265263
train_label=P_precision_sent: 0.6114245416078985
train_label=P_recall_sent: 0.7204986149584488
train_label=P_f-score_sent: 0.6614954221770093
train_precision_macro_sent: 0.4881959276178218
train_recall_macro_sent: 0.47688047085709845
train_f-score_macro_sent: 0.4313051427927717
train_precision_micro_sent: 0.5777153558052435
train_recall_micro_sent: 0.5777153558052435
train_f-score_micro_sent: 0.5777153558052435
train_label=O_precision_tok: 0.863484275542717
train_label=O_recall_tok: 0.9567581043370568
train_label=O_f-score_tok: 0.907731396351373
train_label=N_precision_tok: 0.6961845967007388
train_label=N_recall_tok: 0.484368398817068
train_label=N_f-score_tok: 0.5712743428974795
train_label=P_precision_tok: 0.7768137809631586
train_label=P_recall_tok: 0.49390414518127673
train_label=P_f-score_tok: 0.6038657967402195
train_precision_macro_tok: 0.7788275510688715
train_recall_macro_tok: 0.6450102161118004
train_f-score_macro_tok: 0.6942905119963573
train_precision_micro_tok: 0.8449494393700402
train_recall_micro_tok: 0.8449494393700402
train_f-score_micro_tok: 0.8449494393700402
train_time: 46.15663242340088
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3061    0.0092    0.0179      1624
           N     0.5470    0.7009    0.6145      3310
           P     0.6114    0.7205    0.6615      3610

   micro avg     0.5777    0.5777    0.5777      8544
   macro avg     0.4882    0.4769    0.4313      8544
weighted avg     0.5285    0.5777    0.5210      8544

F1-macro sent:  0.4313051427927717
F1-micro sent:  0.5777153558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8635    0.9568    0.9077    124347
           N     0.6962    0.4844    0.5713     14202
           P     0.7768    0.4939    0.6039     25017

   micro avg     0.8449    0.8449    0.8449    163566
   macro avg     0.7788    0.6450    0.6943    163566
weighted avg     0.8357    0.8449    0.8320    163566

F1-macro tok:  0.6942905119963573
F1-micro tok:  0.8449494393700402
**************************************************
dev_cost_sum: 9266.294021606445
dev_cost_avg: 8.416252517353719
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18492.0
dev_accuracy_tok: 0.86923004606562
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5736677115987461
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.6866791744840526
dev_label=P_precision_sent: 0.6911447084233261
dev_label=P_recall_sent: 0.7207207207207207
dev_label=P_f-score_sent: 0.7056229327453142
dev_precision_macro_sent: 0.4216041400073574
dev_recall_macro_sent: 0.5252869692122029
dev_f-score_macro_sent: 0.4641007024097889
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8745633006155382
dev_label=O_recall_tok: 0.9732181425485961
dev_label=O_f-score_tok: 0.9212570827735266
dev_label=N_precision_tok: 0.7949438202247191
dev_label=N_recall_tok: 0.45718901453957994
dev_label=N_f-score_tok: 0.5805128205128205
dev_label=P_precision_tok: 0.8614818223653935
dev_label=P_recall_tok: 0.5828144458281445
dev_label=P_f-score_tok: 0.6952646239554316
dev_precision_macro_tok: 0.8436629810685502
dev_recall_macro_tok: 0.6710738676387735
dev_f-score_macro_tok: 0.7323448424139262
dev_precision_micro_tok: 0.86923004606562
dev_recall_micro_tok: 0.86923004606562
dev_f-score_micro_tok: 0.86923004606562
dev_time: 2.0675902366638184
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5737    0.8551    0.6867       428
           P     0.6911    0.7207    0.7056       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4216    0.5253    0.4641      1101
weighted avg     0.5017    0.6231    0.5515      1101

F1-macro sent:  0.4641007024097889
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8746    0.9732    0.9213     16205
           N     0.7949    0.4572    0.5805      1857
           P     0.8615    0.5828    0.6953      3212

   micro avg     0.8692    0.8692    0.8692     21274
   macro avg     0.8437    0.6711    0.7323     21274
weighted avg     0.8656    0.8692    0.8574     21274

F1-macro tok:  0.7323448424139262
F1-micro tok:  0.86923004606562
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 75254.59370422363
train_cost_avg: 8.807887839913814
train_count_sent: 8544.0
train_total_correct_sent: 5156.0
train_accuracy_sent: 0.6034644194756554
train_count_tok: 163566.0
train_total_correct_tok: 139840.0
train_accuracy_tok: 0.8549454043016275
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5664463186687941
train_label=N_recall_sent: 0.7507552870090635
train_label=N_f-score_sent: 0.645706119267247
train_label=P_precision_sent: 0.6431495304599085
train_label=P_recall_sent: 0.7398891966759003
train_label=P_f-score_sent: 0.6881360298853535
train_precision_macro_sent: 0.4031986163762342
train_recall_macro_sent: 0.4968814945616546
train_f-score_macro_sent: 0.4446140497175335
train_precision_micro_sent: 0.6034644194756554
train_recall_micro_sent: 0.6034644194756554
train_f-score_micro_sent: 0.6034644194756554
train_label=O_precision_tok: 0.8707590537872552
train_label=O_recall_tok: 0.9612053366788101
train_label=O_f-score_tok: 0.9137494744084707
train_label=N_precision_tok: 0.7128101265822785
train_label=N_recall_tok: 0.49563441768764965
train_label=N_f-score_tok: 0.5847073971009678
train_label=P_precision_tok: 0.8082542001460921
train_label=P_recall_tok: 0.5307590838230004
train_label=P_f-score_tok: 0.6407528049221861
train_precision_macro_tok: 0.7972744601718752
train_recall_macro_tok: 0.6625329460631534
train_f-score_macro_tok: 0.7130698921438748
train_precision_micro_tok: 0.8549454043016275
train_recall_micro_tok: 0.8549454043016275
train_f-score_micro_tok: 0.8549454043016275
train_time: 45.822654247283936
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5664    0.7508    0.6457      3310
           P     0.6431    0.7399    0.6881      3610

   micro avg     0.6035    0.6035    0.6035      8544
   macro avg     0.4032    0.4969    0.4446      8544
weighted avg     0.4912    0.6035    0.5409      8544

F1-macro sent:  0.4446140497175335
F1-micro sent:  0.6034644194756554
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8708    0.9612    0.9137    124347
           N     0.7128    0.4956    0.5847     14202
           P     0.8083    0.5308    0.6408     25017

   micro avg     0.8549    0.8549    0.8549    163566
   macro avg     0.7973    0.6625    0.7131    163566
weighted avg     0.8475    0.8549    0.8434    163566

F1-macro tok:  0.7130698921438748
F1-micro tok:  0.8549454043016275
**************************************************
dev_cost_sum: 8836.574584960938
dev_cost_avg: 8.025953301508572
dev_count_sent: 1101.0
dev_total_correct_sent: 678.0
dev_accuracy_sent: 0.6158038147138964
dev_count_tok: 21274.0
dev_total_correct_tok: 18570.0
dev_accuracy_tok: 0.8728964933721914
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6479481641468683
dev_label=N_recall_sent: 0.7009345794392523
dev_label=N_f-score_sent: 0.6734006734006733
dev_label=P_precision_sent: 0.5924764890282131
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.6987060998151572
dev_precision_macro_sent: 0.41347488439169383
dev_recall_macro_sent: 0.5174286435968679
dev_f-score_macro_sent: 0.4573689244052768
dev_precision_micro_sent: 0.6158038147138964
dev_recall_micro_sent: 0.6158038147138964
dev_f-score_micro_sent: 0.6158038147138964
dev_label=O_precision_tok: 0.8860723602132244
dev_label=O_recall_tok: 0.9642085775995063
dev_label=O_f-score_tok: 0.9234906468867282
dev_label=N_precision_tok: 0.7060833902939166
dev_label=N_recall_tok: 0.5562735595045772
dev_label=N_f-score_tok: 0.6222891566265061
dev_label=P_precision_tok: 0.8782728525493799
dev_label=P_recall_tok: 0.5952677459526775
dev_label=P_f-score_tok: 0.7095936166264614
dev_precision_macro_tok: 0.8234762010188404
dev_recall_macro_tok: 0.7052499610189203
dev_f-score_macro_tok: 0.7517911400465652
dev_precision_micro_tok: 0.8728964933721914
dev_recall_micro_tok: 0.8728964933721914
dev_f-score_micro_tok: 0.8728964933721913
dev_time: 2.1468658447265625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6479    0.7009    0.6734       428
           P     0.5925    0.8514    0.6987       444

   micro avg     0.6158    0.6158    0.6158      1101
   macro avg     0.4135    0.5174    0.4574      1101
weighted avg     0.4908    0.6158    0.5435      1101

F1-macro sent:  0.4573689244052768
F1-micro sent:  0.6158038147138964
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8861    0.9642    0.9235     16205
           N     0.7061    0.5563    0.6223      1857
           P     0.8783    0.5953    0.7096      3212

   micro avg     0.8729    0.8729    0.8729     21274
   macro avg     0.8235    0.7052    0.7518     21274
weighted avg     0.8692    0.8729    0.8649     21274

F1-macro tok:  0.7517911400465652
F1-micro tok:  0.8728964933721913
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 72709.48756408691
train_cost_avg: 8.510005566957737
train_count_sent: 8544.0
train_total_correct_sent: 5172.0
train_accuracy_sent: 0.6053370786516854
train_count_tok: 163566.0
train_total_correct_tok: 141004.0
train_accuracy_tok: 0.8620617976841153
train_label=O_precision_sent: 0.19298245614035087
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013087447947650209
train_label=N_precision_sent: 0.5666892349356805
train_label=N_recall_sent: 0.7586102719033233
train_label=N_f-score_sent: 0.64875339103475
train_label=P_precision_sent: 0.653353057199211
train_label=P_recall_sent: 0.7340720221606648
train_label=P_f-score_sent: 0.6913644664753456
train_precision_macro_sent: 0.47100824942508074
train_recall_macro_sent: 0.4998185643595889
train_f-score_macro_sent: 0.45106843515258194
train_precision_micro_sent: 0.6053370786516854
train_recall_micro_sent: 0.6053370786516854
train_f-score_micro_sent: 0.6053370786516854
train_label=O_precision_tok: 0.875206141182995
train_label=O_recall_tok: 0.9645588554609279
train_label=O_f-score_tok: 0.9177126810998167
train_label=N_precision_tok: 0.7272455388296282
train_label=N_recall_tok: 0.5136600478805802
train_label=N_f-score_tok: 0.6020715553171295
train_label=P_precision_tok: 0.8348390226156551
train_label=P_recall_tok: 0.5503857376983651
train_label=P_f-score_tok: 0.6634064080944351
train_precision_macro_tok: 0.8124302342094261
train_recall_macro_tok: 0.676201547013291
train_f-score_macro_tok: 0.7277302148371271
train_precision_micro_tok: 0.8620617976841153
train_recall_micro_tok: 0.8620617976841153
train_f-score_micro_tok: 0.8620617976841153
train_time: 46.04583668708801
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1930    0.0068    0.0131      1624
           N     0.5667    0.7586    0.6488      3310
           P     0.6534    0.7341    0.6914      3610

   micro avg     0.6053    0.6053    0.6053      8544
   macro avg     0.4710    0.4998    0.4511      8544
weighted avg     0.5323    0.6053    0.5459      8544

F1-macro sent:  0.45106843515258194
F1-micro sent:  0.6053370786516854
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8752    0.9646    0.9177    124347
           N     0.7272    0.5137    0.6021     14202
           P     0.8348    0.5504    0.6634     25017

   micro avg     0.8621    0.8621    0.8621    163566
   macro avg     0.8124    0.6762    0.7277    163566
weighted avg     0.8562    0.8621    0.8514    163566

F1-macro tok:  0.7277302148371271
F1-micro tok:  0.8620617976841153
**************************************************
dev_cost_sum: 8608.504776000977
dev_cost_avg: 7.818805427793802
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 18695.0
dev_accuracy_tok: 0.8787722102096456
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5986622073578596
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.6978557504873295
dev_label=P_precision_sent: 0.6739562624254473
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.7159450897571277
dev_precision_macro_sent: 0.42420615659443567
dev_recall_macro_sent: 0.5333207038814516
dev_f-score_macro_sent: 0.47126694674815245
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8772219470584998
dev_label=O_recall_tok: 0.9836470225239123
dev_label=O_f-score_tok: 0.9273912031649988
dev_label=N_precision_tok: 0.8236889692585895
dev_label=N_recall_tok: 0.4905761981690899
dev_label=N_f-score_tok: 0.6149173135335808
dev_label=P_precision_tok: 0.9233850776164246
dev_label=P_recall_tok: 0.5740971357409713
dev_label=P_f-score_tok: 0.7080053753119601
dev_precision_macro_tok: 0.8747653313111713
dev_recall_macro_tok: 0.6827734521446579
dev_f-score_macro_tok: 0.75010463067018
dev_precision_micro_tok: 0.8787722102096456
dev_recall_micro_tok: 0.8787722102096456
dev_f-score_micro_tok: 0.8787722102096456
dev_time: 2.072570323944092
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5987    0.8364    0.6979       428
           P     0.6740    0.7635    0.7159       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.4242    0.5333    0.4713      1101
weighted avg     0.5045    0.6331    0.5600      1101

F1-macro sent:  0.47126694674815245
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8772    0.9836    0.9274     16205
           N     0.8237    0.4906    0.6149      1857
           P     0.9234    0.5741    0.7080      3212

   micro avg     0.8788    0.8788    0.8788     21274
   macro avg     0.8748    0.6828    0.7501     21274
weighted avg     0.8795    0.8788    0.8670     21274

F1-macro tok:  0.75010463067018
F1-micro tok:  0.8787722102096456
**************************************************
Best epoch: 2
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 70527.39552307129
train_cost_avg: 8.254610899235871
train_count_sent: 8544.0
train_total_correct_sent: 5248.0
train_accuracy_sent: 0.6142322097378277
train_count_tok: 163566.0
train_total_correct_tok: 141727.0
train_accuracy_tok: 0.8664820317180832
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5728282168517309
train_label=N_recall_sent: 0.7948640483383685
train_label=N_f-score_sent: 0.665823105149943
train_label=P_precision_sent: 0.6625316455696203
train_label=P_recall_sent: 0.7249307479224377
train_label=P_f-score_sent: 0.6923280423280423
train_precision_macro_sent: 0.41178662080711703
train_recall_macro_sent: 0.5065982654202688
train_f-score_macro_sent: 0.4527170491593284
train_precision_micro_sent: 0.6142322097378277
train_recall_micro_sent: 0.6142322097378277
train_f-score_micro_sent: 0.6142322097378277
train_label=O_precision_tok: 0.8782616316008559
train_label=O_recall_tok: 0.9671564251650623
train_label=O_f-score_tok: 0.9205679730557256
train_label=N_precision_tok: 0.7411672079519732
train_label=N_recall_tok: 0.530277425714688
train_label=N_f-score_tok: 0.6182325657759719
train_label=P_precision_tok: 0.8458596406022341
train_label=P_recall_tok: 0.5569412799296478
train_label=P_f-score_tok: 0.6716479066740582
train_precision_macro_tok: 0.8217628267183544
train_recall_macro_tok: 0.6847917102697995
train_f-score_macro_tok: 0.7368161485019185
train_precision_micro_tok: 0.8664820317180832
train_recall_micro_tok: 0.8664820317180832
train_f-score_micro_tok: 0.8664820317180832
train_time: 45.73516488075256
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5728    0.7949    0.6658      3310
           P     0.6625    0.7249    0.6923      3610

   micro avg     0.6142    0.6142    0.6142      8544
   macro avg     0.4118    0.5066    0.4527      8544
weighted avg     0.5018    0.6142    0.5505      8544

F1-macro sent:  0.4527170491593284
F1-micro sent:  0.6142322097378277
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8783    0.9672    0.9206    124347
           N     0.7412    0.5303    0.6182     14202
           P     0.8459    0.5569    0.6716     25017

   micro avg     0.8665    0.8665    0.8665    163566
   macro avg     0.8218    0.6848    0.7368    163566
weighted avg     0.8614    0.8665    0.8562    163566

F1-macro tok:  0.7368161485019185
F1-micro tok:  0.8664820317180832
**************************************************
dev_cost_sum: 8399.392860412598
dev_cost_avg: 7.62887634914859
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18767.0
dev_accuracy_tok: 0.8821566231080192
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5852895148669797
dev_label=N_recall_sent: 0.8738317757009346
dev_label=N_f-score_sent: 0.7010309278350516
dev_label=P_precision_sent: 0.7077922077922078
dev_label=P_recall_sent: 0.7364864864864865
dev_label=P_f-score_sent: 0.7218543046357615
dev_precision_macro_sent: 0.4310272408863958
dev_recall_macro_sent: 0.5367727540624737
dev_f-score_macro_sent: 0.47429507749027106
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.88424688057041
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9294727288696314
dev_label=N_precision_tok: 0.8140531276778064
dev_label=N_recall_tok: 0.5115778136779753
dev_label=N_f-score_tok: 0.6283068783068784
dev_label=P_precision_tok: 0.9016241299303944
dev_label=P_recall_tok: 0.6049190535491905
dev_label=P_f-score_tok: 0.7240544065585988
dev_precision_macro_tok: 0.8666413793928703
dev_recall_macro_tok: 0.6986903575730993
dev_f-score_macro_tok: 0.7606113379117029
dev_precision_micro_tok: 0.8821566231080192
dev_recall_micro_tok: 0.8821566231080192
dev_f-score_micro_tok: 0.8821566231080192
dev_time: 2.0350518226623535
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5853    0.8738    0.7010       428
           P     0.7078    0.7365    0.7219       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4310    0.5368    0.4743      1101
weighted avg     0.5130    0.6367    0.5636      1101

F1-macro sent:  0.47429507749027106
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8842    0.9796    0.9295     16205
           N     0.8141    0.5116    0.6283      1857
           P     0.9016    0.6049    0.7241      3212

   micro avg     0.8822    0.8822    0.8822     21274
   macro avg     0.8666    0.6987    0.7606     21274
weighted avg     0.8807    0.8822    0.8722     21274

F1-macro tok:  0.7606113379117029
F1-micro tok:  0.8821566231080192
**************************************************
Best epoch: 2
**************************************************

EPOCH: 7
Learning rate: 0.900000
train_cost_sum: 68455.10420227051
train_cost_avg: 8.01206743940432
train_count_sent: 8544.0
train_total_correct_sent: 5307.0
train_accuracy_sent: 0.6211376404494382
train_count_tok: 163566.0
train_total_correct_tok: 142480.0
train_accuracy_tok: 0.8710856779526307
train_label=O_precision_sent: 0.34285714285714286
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014466546112115732
train_label=N_precision_sent: 0.5929307116104869
train_label=N_recall_sent: 0.7652567975830815
train_label=N_f-score_sent: 0.6681614349775784
train_label=P_precision_sent: 0.6518763275902761
train_label=P_recall_sent: 0.7650969529085873
train_label=P_f-score_sent: 0.7039632980756978
train_precision_macro_sent: 0.5292213940193019
train_recall_macro_sent: 0.5125809710177484
train_f-score_macro_sent: 0.4621970930551306
train_precision_micro_sent: 0.6211376404494382
train_recall_micro_sent: 0.6211376404494382
train_f-score_micro_sent: 0.6211376404494382
train_label=O_precision_tok: 0.8821926637759288
train_label=O_recall_tok: 0.9686120292407537
train_label=O_f-score_tok: 0.9233847628174414
train_label=N_precision_tok: 0.7498790985588548
train_label=N_recall_tok: 0.5459090268976201
train_label=N_f-score_tok: 0.6318405932928569
train_label=P_precision_tok: 0.8553206778849033
train_label=P_recall_tok: 0.5709317663988488
train_label=P_f-score_tok: 0.684773228497459
train_precision_macro_tok: 0.8291308134065623
train_recall_macro_tok: 0.6951509408457408
train_f-score_macro_tok: 0.7466661948692525
train_precision_micro_tok: 0.8710856779526307
train_recall_micro_tok: 0.8710856779526307
train_f-score_micro_tok: 0.8710856779526307
train_time: 45.71212339401245
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3429    0.0074    0.0145      1624
           N     0.5929    0.7653    0.6682      3310
           P     0.6519    0.7651    0.7040      3610

   micro avg     0.6211    0.6211    0.6211      8544
   macro avg     0.5292    0.5126    0.4622      8544
weighted avg     0.5703    0.6211    0.5590      8544

F1-macro sent:  0.4621970930551306
F1-micro sent:  0.6211376404494382
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8822    0.9686    0.9234    124347
           N     0.7499    0.5459    0.6318     14202
           P     0.8553    0.5709    0.6848     25017

   micro avg     0.8711    0.8711    0.8711    163566
   macro avg     0.8291    0.6952    0.7467    163566
weighted avg     0.8666    0.8711    0.8616    163566

F1-macro tok:  0.7466661948692525
F1-micro tok:  0.8710856779526307
**************************************************
dev_cost_sum: 8225.365600585938
dev_cost_avg: 7.470813442857345
dev_count_sent: 1101.0
dev_total_correct_sent: 683.0
dev_accuracy_sent: 0.620345140781108
dev_count_tok: 21274.0
dev_total_correct_tok: 18798.0
dev_accuracy_tok: 0.8836138008837078
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5584415584415584
dev_label=N_recall_sent: 0.9042056074766355
dev_label=N_f-score_sent: 0.6904549509366636
dev_label=P_precision_sent: 0.7254901960784313
dev_label=P_recall_sent: 0.6666666666666666
dev_label=P_f-score_sent: 0.6948356807511736
dev_precision_macro_sent: 0.42797725150666327
dev_recall_macro_sent: 0.5236240913811007
dev_f-score_macro_sent: 0.46176354389594576
dev_precision_micro_sent: 0.620345140781108
dev_recall_micro_sent: 0.620345140781108
dev_f-score_micro_sent: 0.620345140781108
dev_label=O_precision_tok: 0.8869307373839096
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9303676751078376
dev_label=N_precision_tok: 0.7802281368821293
dev_label=N_recall_tok: 0.5525040387722132
dev_label=N_f-score_tok: 0.6469104665825977
dev_label=P_precision_tok: 0.9203836930455636
dev_label=P_recall_tok: 0.5974470734744707
dev_label=P_f-score_tok: 0.7245610723050783
dev_precision_macro_tok: 0.8625141891038673
dev_recall_macro_tok: 0.7094098071368408
dev_f-score_macro_tok: 0.7672797379985045
dev_precision_micro_tok: 0.8836138008837078
dev_recall_micro_tok: 0.8836138008837078
dev_f-score_micro_tok: 0.8836138008837078
dev_time: 2.0323712825775146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5584    0.9042    0.6905       428
           P     0.7255    0.6667    0.6948       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.4280    0.5236    0.4618      1101
weighted avg     0.5097    0.6203    0.5486      1101

F1-macro sent:  0.46176354389594576
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8869    0.9783    0.9304     16205
           N     0.7802    0.5525    0.6469      1857
           P     0.9204    0.5974    0.7246      3212

   micro avg     0.8836    0.8836    0.8836     21274
   macro avg     0.8625    0.7094    0.7673     21274
weighted avg     0.8827    0.8836    0.8746     21274

F1-macro tok:  0.7672797379985045
F1-micro tok:  0.8836138008837078
**************************************************
Best epoch: 2
**************************************************

EPOCH: 8
Learning rate: 0.810000
train_cost_sum: 66933.27668762207
train_cost_avg: 7.83395092317674
train_count_sent: 8544.0
train_total_correct_sent: 5319.0
train_accuracy_sent: 0.6225421348314607
train_count_tok: 163566.0
train_total_correct_tok: 143150.0
train_accuracy_tok: 0.8751818837655747
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5811565081491404
train_label=N_recall_sent: 0.786404833836858
train_label=N_f-score_sent: 0.6683784824752856
train_label=P_precision_sent: 0.6684715727295102
train_label=P_recall_sent: 0.7523545706371191
train_label=P_f-score_sent: 0.7079369216734003
train_precision_macro_sent: 0.4165426936262169
train_recall_macro_sent: 0.5129198014913258
train_f-score_macro_sent: 0.45877180138289536
train_precision_micro_sent: 0.6225421348314607
train_recall_micro_sent: 0.6225421348314607
train_f-score_micro_sent: 0.6225421348314607
train_label=O_precision_tok: 0.8855462814103552
train_label=O_recall_tok: 0.9701078433737846
train_label=O_f-score_tok: 0.9259003407939578
train_label=N_precision_tok: 0.7591395775055464
train_label=N_recall_tok: 0.5541473031967329
train_label=N_f-score_tok: 0.6406447148846107
train_label=P_precision_tok: 0.8628813758982212
train_label=P_recall_tok: 0.585601790782268
train_label=P_f-score_tok: 0.6977021073937373
train_precision_macro_tok: 0.8358557449380409
train_recall_macro_tok: 0.7032856457842619
train_f-score_macro_tok: 0.7547490543574353
train_precision_micro_tok: 0.8751818837655747
train_recall_micro_tok: 0.8751818837655747
train_f-score_micro_tok: 0.8751818837655747
train_time: 45.898844718933105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5812    0.7864    0.6684      3310
           P     0.6685    0.7524    0.7079      3610

   micro avg     0.6225    0.6225    0.6225      8544
   macro avg     0.4165    0.5129    0.4588      8544
weighted avg     0.5076    0.6225    0.5581      8544

F1-macro sent:  0.45877180138289536
F1-micro sent:  0.6225421348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8855    0.9701    0.9259    124347
           N     0.7591    0.5541    0.6406     14202
           P     0.8629    0.5856    0.6977     25017

   micro avg     0.8752    0.8752    0.8752    163566
   macro avg     0.8359    0.7033    0.7547    163566
weighted avg     0.8711    0.8752    0.8662    163566

F1-macro tok:  0.7547490543574353
F1-micro tok:  0.8751818837655747
**************************************************
dev_cost_sum: 8104.511672973633
dev_cost_avg: 7.361046024499212
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18874.0
dev_accuracy_tok: 0.8871862367208799
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6171003717472119
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.6873706004140787
dev_label=P_precision_sent: 0.6376554174067496
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7130089374379345
dev_precision_macro_sent: 0.4182519297179872
dev_recall_macro_sent: 0.5280864977126659
dev_f-score_macro_sent: 0.4667931792840044
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8925671103090458
dev_label=O_recall_tok: 0.9766738660907127
dev_label=O_f-score_tok: 0.932728290656216
dev_label=N_precision_tok: 0.7707142857142857
dev_label=N_recall_tok: 0.5810446957458266
dev_label=N_f-score_tok: 0.6625729198649064
dev_label=P_precision_tok: 0.9187675070028011
dev_label=P_recall_tok: 0.6127023661270237
dev_label=P_f-score_tok: 0.73515128875607
dev_precision_macro_tok: 0.8606829676753774
dev_recall_macro_tok: 0.723473642654521
dev_f-score_macro_tok: 0.7768174997590641
dev_precision_micro_tok: 0.8871862367208799
dev_recall_micro_tok: 0.8871862367208799
dev_f-score_micro_tok: 0.8871862367208799
dev_time: 2.0502960681915283
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6171    0.7757    0.6874       428
           P     0.6377    0.8086    0.7130       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.4183    0.5281    0.4668      1101
weighted avg     0.4970    0.6276    0.5547      1101

F1-macro sent:  0.4667931792840044
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8926    0.9767    0.9327     16205
           N     0.7707    0.5810    0.6626      1857
           P     0.9188    0.6127    0.7352      3212

   micro avg     0.8872    0.8872    0.8872     21274
   macro avg     0.8607    0.7235    0.7768     21274
weighted avg     0.8859    0.8872    0.8793     21274

F1-macro tok:  0.7768174997590641
F1-micro tok:  0.8871862367208799
**************************************************
Best epoch: 2
**************************************************

EPOCH: 9
Learning rate: 0.729000
train_cost_sum: 65456.78202819824
train_cost_avg: 7.661140218656161
train_count_sent: 8544.0
train_total_correct_sent: 5343.0
train_accuracy_sent: 0.6253511235955056
train_count_tok: 163566.0
train_total_correct_tok: 143460.0
train_accuracy_tok: 0.8770771431715638
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003680981595092024
train_label=N_precision_sent: 0.5855410866636731
train_label=N_recall_sent: 0.7879154078549849
train_label=N_f-score_sent: 0.6718186501803195
train_label=P_precision_sent: 0.6689520078354554
train_label=P_recall_sent: 0.756786703601108
train_label=P_f-score_sent: 0.710163763971926
train_precision_macro_sent: 0.5848310314997095
train_recall_macro_sent: 0.5155164673654956
train_f-score_macro_sent: 0.4618877985824459
train_precision_micro_sent: 0.6253511235955056
train_recall_micro_sent: 0.6253511235955056
train_f-score_micro_sent: 0.6253511235955056
train_label=O_precision_tok: 0.8874080611944689
train_label=O_recall_tok: 0.9702847676260786
train_label=O_f-score_tok: 0.9269977372871264
train_label=N_precision_tok: 0.7636105860113421
train_label=N_recall_tok: 0.56886354034643
train_label=N_f-score_tok: 0.6520054878540876
train_label=P_precision_tok: 0.8650886878891108
train_label=P_recall_tok: 0.5887596434424591
train_label=P_f-score_tok: 0.7006636063078276
train_precision_macro_tok: 0.8387024450316406
train_recall_macro_tok: 0.7093026504716559
train_f-score_macro_tok: 0.7598889438163473
train_precision_micro_tok: 0.8770771431715638
train_recall_micro_tok: 0.8770771431715638
train_f-score_micro_tok: 0.8770771431715638
train_time: 45.99636912345886
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0018    0.0037      1624
           N     0.5855    0.7879    0.6718      3310
           P     0.6690    0.7568    0.7102      3610

   micro avg     0.6254    0.6254    0.6254      8544
   macro avg     0.5848    0.5155    0.4619      8544
weighted avg     0.6045    0.6254    0.5610      8544

F1-macro sent:  0.4618877985824459
F1-micro sent:  0.6253511235955056
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8874    0.9703    0.9270    124347
           N     0.7636    0.5689    0.6520     14202
           P     0.8651    0.5888    0.7007     25017

   micro avg     0.8771    0.8771    0.8771    163566
   macro avg     0.8387    0.7093    0.7599    163566
weighted avg     0.8732    0.8771    0.8685    163566

F1-macro tok:  0.7598889438163473
F1-micro tok:  0.8770771431715638
**************************************************
dev_cost_sum: 8030.216606140137
dev_cost_avg: 7.293566399763975
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 18896.0
dev_accuracy_tok: 0.8882203628842719
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6512096774193549
dev_label=N_recall_sent: 0.7546728971962616
dev_label=N_f-score_sent: 0.6991341991341992
dev_label=P_precision_sent: 0.6099173553719008
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.703527168732126
dev_precision_macro_sent: 0.4203756775970852
dev_recall_macro_sent: 0.5285846594257809
dev_f-score_macro_sent: 0.46755378928877506
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.8889323425889715
dev_label=O_recall_tok: 0.9818574514038877
dev_label=O_f-score_tok: 0.9330870279146141
dev_label=N_precision_tok: 0.8108326596604689
dev_label=N_recall_tok: 0.5401184706515886
dev_label=N_f-score_tok: 0.6483516483516484
dev_label=P_precision_tok: 0.9270346117867165
dev_label=P_recall_tok: 0.6170610211706102
dev_label=P_f-score_tok: 0.7409345794392523
dev_precision_macro_tok: 0.8755998713453857
dev_recall_macro_tok: 0.7130123144086955
dev_f-score_macro_tok: 0.7741244185685049
dev_precision_micro_tok: 0.8882203628842719
dev_recall_micro_tok: 0.8882203628842719
dev_f-score_micro_tok: 0.8882203628842719
dev_time: 2.05495023727417
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6512    0.7547    0.6991       428
           P     0.6099    0.8311    0.7035       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.4204    0.5286    0.4676      1101
weighted avg     0.4991    0.6285    0.5555      1101

F1-macro sent:  0.46755378928877506
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8889    0.9819    0.9331     16205
           N     0.8108    0.5401    0.6484      1857
           P     0.9270    0.6171    0.7409      3212

   micro avg     0.8882    0.8882    0.8882     21274
   macro avg     0.8756    0.7130    0.7741     21274
weighted avg     0.8879    0.8882    0.8792     21274

F1-macro tok:  0.7741244185685049
F1-micro tok:  0.8882203628842719
**************************************************
Best epoch: 2
**************************************************

test0_cost_sum: 9802.993469238281
test0_cost_avg: 8.903717955711427
test0_count_sent: 1101.0
test0_total_correct_sent: 673.0
test0_accuracy_sent: 0.6112624886466849
test0_count_tok: 21274.0
test0_total_correct_tok: 18292.0
test0_accuracy_tok: 0.8598288991256934
test0_label=O_precision_sent: 0.4
test0_label=O_recall_sent: 0.09606986899563319
test0_label=O_f-score_sent: 0.15492957746478872
test0_label=N_precision_sent: 0.5626959247648903
test0_label=N_recall_sent: 0.8387850467289719
test0_label=N_f-score_sent: 0.6735459662288931
test0_label=P_precision_sent: 0.7156862745098039
test0_label=P_recall_sent: 0.6576576576576577
test0_label=P_f-score_sent: 0.6854460093896714
test0_precision_macro_sent: 0.5594607330915647
test0_recall_macro_sent: 0.5308375244607543
test0_f-score_macro_sent: 0.5046405176944511
test0_precision_micro_sent: 0.6112624886466849
test0_recall_micro_sent: 0.6112624886466849
test0_f-score_micro_sent: 0.6112624886466849
test0_label=O_precision_tok: 0.8736263736263736
test0_label=O_recall_tok: 0.9615550755939525
test0_label=O_f-score_tok: 0.9154842689697716
test0_label=N_precision_tok: 0.7521891418563923
test0_label=N_recall_tok: 0.46257404415724285
test0_label=N_f-score_tok: 0.5728576192064021
test0_label=P_precision_tok: 0.806184668989547
test0_label=P_recall_tok: 0.5762764632627646
test0_label=P_f-score_tok: 0.6721132897603486
test0_precision_macro_tok: 0.8106667281574377
test0_recall_macro_tok: 0.6668018610046533
test0_f-score_macro_tok: 0.7201517259788407
test0_precision_micro_tok: 0.8598288991256934
test0_recall_micro_tok: 0.8598288991256934
test0_f-score_micro_tok: 0.8598288991256934
test0_time: 2.015197992324829
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0961    0.1549       229
           N     0.5627    0.8388    0.6735       428
           P     0.7157    0.6577    0.6854       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.5595    0.5308    0.5046      1101
weighted avg     0.5906    0.6113    0.5705      1101

F1-macro sent:  0.5046405176944511
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8736    0.9616    0.9155     16205
           N     0.7522    0.4626    0.5729      1857
           P     0.8062    0.5763    0.6721      3212

   micro avg     0.8598    0.8598    0.8598     21274
   macro avg     0.8107    0.6668    0.7202     21274
weighted avg     0.8528    0.8598    0.8488     21274

F1-macro tok:  0.7201517259788407
F1-micro tok:  0.8598288991256934
**************************************************
test1_cost_sum: 19988.310081481934
test1_cost_avg: 9.04448419976558
test1_count_sent: 2210.0
test1_total_correct_sent: 1361.0
test1_accuracy_sent: 0.6158371040723982
test1_count_tok: 42405.0
test1_total_correct_tok: 36312.0
test1_accuracy_tok: 0.8563141139016626
test1_label=O_precision_sent: 0.32679738562091504
test1_label=O_recall_sent: 0.12853470437017994
test1_label=O_f-score_sent: 0.18450184501845018
test1_label=N_precision_sent: 0.5797101449275363
test1_label=N_recall_sent: 0.8333333333333334
test1_label=N_f-score_sent: 0.6837606837606838
test1_label=P_precision_sent: 0.7386058981233244
test1_label=P_recall_sent: 0.6061606160616062
test1_label=P_f-score_sent: 0.6658610271903325
test1_precision_macro_sent: 0.5483711428905919
test1_recall_macro_sent: 0.5226762179217065
test1_f-score_macro_sent: 0.5113745186564888
test1_precision_micro_sent: 0.6158371040723982
test1_recall_micro_sent: 0.6158371040723982
test1_f-score_micro_sent: 0.6158371040723982
test1_label=O_precision_tok: 0.8664592791883863
test1_label=O_recall_tok: 0.9662166385399087
test1_label=O_f-score_tok: 0.9136229314420804
test1_label=N_precision_tok: 0.7696335078534031
test1_label=N_recall_tok: 0.46914893617021275
test1_label=N_f-score_tok: 0.5829477858559153
test1_label=P_precision_tok: 0.8194538478898669
test1_label=P_recall_tok: 0.5462614713404543
test1_label=P_f-score_tok: 0.6555334897996029
test1_precision_macro_tok: 0.8185155449772187
test1_recall_macro_tok: 0.6605423486835252
test1_f-score_macro_tok: 0.7173680690325329
test1_precision_micro_tok: 0.8563141139016626
test1_recall_micro_tok: 0.8563141139016626
test1_f-score_micro_tok: 0.8563141139016626
test1_time: 4.210991382598877
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3268    0.1285    0.1845       389
           N     0.5797    0.8333    0.6838       912
           P     0.7386    0.6062    0.6659       909

   micro avg     0.6158    0.6158    0.6158      2210
   macro avg     0.5484    0.5227    0.5114      2210
weighted avg     0.6005    0.6158    0.5885      2210

F1-macro sent:  0.5113745186564888
F1-micro sent:  0.6158371040723982
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8665    0.9662    0.9136     31998
           N     0.7696    0.4691    0.5829      3760
           P     0.8195    0.5463    0.6555      6647

   micro avg     0.8563    0.8563    0.8563     42405
   macro avg     0.8185    0.6605    0.7174     42405
weighted avg     0.8505    0.8563    0.8438     42405

F1-macro tok:  0.7173680690325329
F1-micro tok:  0.8563141139016626
**************************************************
