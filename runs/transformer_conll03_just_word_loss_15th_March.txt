to_write_filename: runs/transformer_conll03_word_loss.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 0.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'O': 0, 'PER': 4, 'LOC': 1, 'MISC': 2, 'ORG': 3}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-16 10:58:40.211620: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-16 10:58:40.311349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 8191:00:00.0
totalMemory: 11.17GiB freeMemory: 9.98GiB
2019-03-16 10:58:40.311406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-16 10:58:40.675834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-16 10:58:40.675886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-16 10:58:40.675897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-16 10:58:40.676134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 8191:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 8600002.
Parameter count without word embeddings: 2033002.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 57132.79126167297
train_cost_avg: 4.068997312276403
train_count_sent: 14041.0
train_total_correct_sent: 5158.0
train_accuracy_sent: 0.3673527526529449
train_count_tok: 203621.0
train_total_correct_tok: 187325.0
train_accuracy_tok: 0.9199689619440038
train_label=0_precision_sent: 0.21350469978898906
train_label=0_recall_sent: 0.7652114128566517
train_label=0_f-score_sent: 0.3338582677165355
train_label=1_precision_sent: 0.8110650069156293
train_label=1_recall_sent: 0.26338483650736616
train_label=1_f-score_sent: 0.39764019800637423
train_precision_macro_sent: 0.5122848533523092
train_recall_macro_sent: 0.514298124682009
train_f-score_macro_sent: 0.3657492328614549
train_precision_micro_sent: 0.3673527526529449
train_recall_micro_sent: 0.3673527526529449
train_f-score_micro_sent: 0.3673527526529449
train_label=O_precision_tok: 0.9496541034612448
train_label=O_recall_tok: 0.9827395063038837
train_label=O_f-score_tok: 0.9659135696566434
train_label=LOC_precision_tok: 0.7284156316267798
train_label=LOC_recall_tok: 0.5796070868988791
train_label=LOC_f-score_tok: 0.6455466809853011
train_label=MISC_precision_tok: 0.6012591815320042
train_label=MISC_recall_tok: 0.37426518615284127
train_label=MISC_f-score_tok: 0.46135265700483086
train_label=ORG_precision_tok: 0.6891620672353236
train_label=ORG_recall_tok: 0.5480299251870324
train_label=ORG_f-score_tok: 0.6105462021448018
train_label=PER_precision_tok: 0.8084470192487385
train_label=PER_recall_tok: 0.7774982027318476
train_label=PER_f-score_tok: 0.7926706367384333
train_precision_macro_tok: 0.7553876006208181
train_recall_macro_tok: 0.6524279814548969
train_f-score_macro_tok: 0.6952059493060021
train_precision_micro_tok: 0.9199689619440038
train_recall_micro_tok: 0.9199689619440038
train_f-score_micro_tok: 0.9199689619440038
train_time: 140.81895875930786
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2135    0.7652    0.3339      2909
           1     0.8111    0.2634    0.3976     11132

   micro avg     0.3674    0.3674    0.3674     14041
   macro avg     0.5123    0.5143    0.3657     14041
weighted avg     0.6873    0.3674    0.3844     14041

F1-macro sent:  0.3657492328614549
F1-micro sent:  0.3673527526529449
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9497    0.9827    0.9659    169578
         LOC     0.7284    0.5796    0.6455      8297
        MISC     0.6013    0.3743    0.4614      4593
         ORG     0.6892    0.5480    0.6105     10025
         PER     0.8084    0.7775    0.7927     11128

   micro avg     0.9200    0.9200    0.9200    203621
   macro avg     0.7554    0.6524    0.6952    203621
weighted avg     0.9122    0.9200    0.9145    203621

F1-macro tok:  0.6952059493060021
F1-micro tok:  0.9199689619440038
**************************************************
dev_cost_sum: 5742.7542090415955
dev_cost_avg: 1.7670012950897216
dev_count_sent: 3250.0
dev_total_correct_sent: 1051.0
dev_accuracy_sent: 0.3233846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 49936.0
dev_accuracy_tok: 0.9722362836338149
dev_label=0_precision_sent: 0.1645077720207254
dev_label=0_recall_sent: 0.5906976744186047
dev_label=0_f-score_sent: 0.2573454913880446
dev_label=1_precision_sent: 0.7173447537473233
dev_label=1_recall_sent: 0.2571976967370441
dev_label=1_f-score_sent: 0.3786380333427522
dev_precision_macro_sent: 0.44092626288402437
dev_recall_macro_sent: 0.42394768557782436
dev_f-score_macro_sent: 0.3179917623653984
dev_precision_micro_sent: 0.3233846153846154
dev_recall_micro_sent: 0.3233846153846154
dev_f-score_micro_sent: 0.3233846153846154
dev_label=O_precision_tok: 0.9862664721276546
dev_label=O_recall_tok: 0.9959540681493955
dev_label=O_f-score_tok: 0.9910865973143429
dev_label=LOC_precision_tok: 0.8874172185430463
dev_label=LOC_recall_tok: 0.8958930276981852
dev_label=LOC_f-score_tok: 0.8916349809885932
dev_label=MISC_precision_tok: 0.8906581740976646
dev_label=MISC_recall_tok: 0.6616719242902208
dev_label=MISC_f-score_tok: 0.7592760180995475
dev_label=ORG_precision_tok: 0.8677277716794731
dev_label=ORG_recall_tok: 0.755736137667304
dev_label=ORG_f-score_tok: 0.8078691875319367
dev_label=PER_precision_tok: 0.9240544629349471
dev_label=PER_recall_tok: 0.9698316926008257
dev_label=PER_f-score_tok: 0.9463898357607685
dev_precision_macro_tok: 0.911224819876557
dev_recall_macro_tok: 0.8558173700811864
dev_f-score_macro_tok: 0.8792513239390377
dev_precision_micro_tok: 0.9722362836338149
dev_recall_micro_tok: 0.9722362836338149
dev_f-score_micro_tok: 0.9722362836338149
dev_time: 13.217949628829956
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1645    0.5907    0.2573       645
           1     0.7173    0.2572    0.3786      2605

   micro avg     0.3234    0.3234    0.3234      3250
   macro avg     0.4409    0.4239    0.3180      3250
weighted avg     0.6076    0.3234    0.3546      3250

F1-macro sent:  0.3179917623653984
F1-micro sent:  0.3233846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9863    0.9960    0.9911     42759
         LOC     0.8874    0.8959    0.8916      2094
        MISC     0.8907    0.6617    0.7593      1268
         ORG     0.8677    0.7557    0.8079      2092
         PER     0.9241    0.9698    0.9464      3149

   micro avg     0.9722    0.9722    0.9722     51362
   macro avg     0.9112    0.8558    0.8793     51362
weighted avg     0.9712    0.9722    0.9711     51362

F1-macro tok:  0.8792513239390377
F1-micro tok:  0.9722362836338149
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 23607.49614715576
train_cost_avg: 1.6813258419739165
train_count_sent: 14041.0
train_total_correct_sent: 6339.0
train_accuracy_sent: 0.4514635709707286
train_count_tok: 203621.0
train_total_correct_tok: 196338.0
train_accuracy_tok: 0.9642325693322398
train_label=0_precision_sent: 0.20453704845271853
train_label=0_recall_sent: 0.5702990718459952
train_label=0_f-score_sent: 0.30108892921960073
train_label=1_precision_sent: 0.7892074198988196
train_label=1_recall_sent: 0.4204096298957959
train_label=1_f-score_sent: 0.5485875043957332
train_precision_macro_sent: 0.4968722341757691
train_recall_macro_sent: 0.4953543508708955
train_f-score_macro_sent: 0.424838216807667
train_precision_micro_sent: 0.4514635709707286
train_recall_micro_sent: 0.4514635709707286
train_f-score_micro_sent: 0.4514635709707286
train_label=O_precision_tok: 0.9881807661354277
train_label=O_recall_tok: 0.9919859887485405
train_label=O_f-score_tok: 0.9900797212551756
train_label=LOC_precision_tok: 0.8425074626865672
train_label=LOC_recall_tok: 0.8504278654935519
train_label=LOC_f-score_tok: 0.8464491362763916
train_label=MISC_precision_tok: 0.7603955375253549
train_label=MISC_recall_tok: 0.6529501415197039
train_label=MISC_f-score_tok: 0.7025887314044745
train_label=ORG_precision_tok: 0.7943152454780362
train_label=ORG_recall_tok: 0.7665835411471321
train_label=ORG_f-score_tok: 0.7802030456852791
train_label=PER_precision_tok: 0.9107581607581607
train_label=PER_recall_tok: 0.9326923076923077
train_label=PER_f-score_tok: 0.9215947433848339
train_precision_macro_tok: 0.8592314345167094
train_recall_macro_tok: 0.8389279689202471
train_f-score_macro_tok: 0.8481830756012311
train_precision_micro_tok: 0.9642325693322398
train_recall_micro_tok: 0.9642325693322398
train_f-score_micro_tok: 0.9642325693322398
train_time: 140.57085919380188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2045    0.5703    0.3011      2909
           1     0.7892    0.4204    0.5486     11132

   micro avg     0.4515    0.4515    0.4515     14041
   macro avg     0.4969    0.4954    0.4248     14041
weighted avg     0.6681    0.4515    0.4973     14041

F1-macro sent:  0.424838216807667
F1-micro sent:  0.4514635709707286
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9882    0.9920    0.9901    169578
         LOC     0.8425    0.8504    0.8464      8297
        MISC     0.7604    0.6530    0.7026      4593
         ORG     0.7943    0.7666    0.7802     10025
         PER     0.9108    0.9327    0.9216     11128

   micro avg     0.9642    0.9642    0.9642    203621
   macro avg     0.8592    0.8389    0.8482    203621
weighted avg     0.9633    0.9642    0.9637    203621

F1-macro tok:  0.8481830756012311
F1-micro tok:  0.9642325693322398
**************************************************
dev_cost_sum: 5119.269211769104
dev_cost_avg: 1.5751597574674165
dev_count_sent: 3250.0
dev_total_correct_sent: 1816.0
dev_accuracy_sent: 0.5587692307692308
dev_count_tok: 51362.0
dev_total_correct_tok: 50094.0
dev_accuracy_tok: 0.9753124878314707
dev_label=0_precision_sent: 0.19155590304925724
dev_label=0_recall_sent: 0.3798449612403101
dev_label=0_f-score_sent: 0.25467775467775466
dev_label=1_precision_sent: 0.7970573313039067
dev_label=1_recall_sent: 0.6030710172744722
dev_label=1_f-score_sent: 0.6866258741258742
dev_precision_macro_sent: 0.494306617176582
dev_recall_macro_sent: 0.49145798925739115
dev_f-score_macro_sent: 0.4706518144018144
dev_precision_micro_sent: 0.5587692307692308
dev_recall_micro_sent: 0.5587692307692308
dev_f-score_micro_sent: 0.5587692307692308
dev_label=O_precision_tok: 0.9913574207375312
dev_label=O_recall_tok: 0.9952524614700998
dev_label=O_f-score_tok: 0.9933011227038256
dev_label=LOC_precision_tok: 0.9582869855394883
dev_label=LOC_recall_tok: 0.8228271251193887
dev_label=LOC_f-score_tok: 0.8854059609455293
dev_label=MISC_precision_tok: 0.9194214876033058
dev_label=MISC_recall_tok: 0.7018927444794952
dev_label=MISC_f-score_tok: 0.7960644007155635
dev_label=ORG_precision_tok: 0.7612484799351439
dev_label=ORG_recall_tok: 0.8977055449330784
dev_label=ORG_f-score_tok: 0.8238648826497039
dev_label=PER_precision_tok: 0.9515927545284197
dev_label=PER_recall_tok: 0.9676087646872022
dev_label=PER_f-score_tok: 0.9595339316643048
dev_precision_macro_tok: 0.9163814256687777
dev_recall_macro_tok: 0.8770573281378529
dev_f-score_macro_tok: 0.8916340597357856
dev_precision_micro_tok: 0.9753124878314707
dev_recall_micro_tok: 0.9753124878314707
dev_f-score_micro_tok: 0.9753124878314707
dev_time: 13.350348949432373
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1916    0.3798    0.2547       645
           1     0.7971    0.6031    0.6866      2605

   micro avg     0.5588    0.5588    0.5588      3250
   macro avg     0.4943    0.4915    0.4707      3250
weighted avg     0.6769    0.5588    0.6009      3250

F1-macro sent:  0.4706518144018144
F1-micro sent:  0.5587692307692308
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9914    0.9953    0.9933     42759
         LOC     0.9583    0.8228    0.8854      2094
        MISC     0.9194    0.7019    0.7961      1268
         ORG     0.7612    0.8977    0.8239      2092
         PER     0.9516    0.9676    0.9595      3149

   micro avg     0.9753    0.9753    0.9753     51362
   macro avg     0.9164    0.8771    0.8916     51362
weighted avg     0.9764    0.9753    0.9751     51362

F1-macro tok:  0.8916340597357856
F1-micro tok:  0.9753124878314707
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 19623.03688621521
train_cost_avg: 1.397552659085194
train_count_sent: 14041.0
train_total_correct_sent: 6443.0
train_accuracy_sent: 0.458870450822591
train_count_tok: 203621.0
train_total_correct_tok: 197576.0
train_accuracy_tok: 0.97031249232643
train_label=0_precision_sent: 0.1946868081781482
train_label=0_recall_sent: 0.5139223100721898
train_label=0_f-score_sent: 0.28239516433698525
train_label=1_precision_sent: 0.7777428481609556
train_label=1_recall_sent: 0.44448436938555513
train_label=1_f-score_sent: 0.5656796615982622
train_precision_macro_sent: 0.4862148281695519
train_recall_macro_sent: 0.47920333972887247
train_f-score_macro_sent: 0.42403741296762376
train_precision_micro_sent: 0.458870450822591
train_recall_micro_sent: 0.458870450822591
train_f-score_micro_sent: 0.458870450822591
train_label=O_precision_tok: 0.9901330481182858
train_label=O_recall_tok: 0.9935545884489734
train_label=O_f-score_tok: 0.991840867481795
train_label=LOC_precision_tok: 0.8700862895493768
train_label=LOC_recall_tok: 0.8750150656863926
train_label=LOC_f-score_tok: 0.8725437173246801
train_label=MISC_precision_tok: 0.7965357404244938
train_label=MISC_recall_tok: 0.71086435880688
train_label=MISC_f-score_tok: 0.7512655315232397
train_label=ORG_precision_tok: 0.8310032894736842
train_label=ORG_recall_tok: 0.8063840399002494
train_label=ORG_f-score_tok: 0.8185085809750419
train_label=PER_precision_tok: 0.9287612971823498
train_label=PER_recall_tok: 0.9419482386772107
train_label=PER_f-score_tok: 0.9353082894619434
train_precision_macro_tok: 0.8833039329496379
train_recall_macro_tok: 0.8655532583039411
train_f-score_macro_tok: 0.87389339735334
train_precision_micro_tok: 0.97031249232643
train_recall_micro_tok: 0.97031249232643
train_f-score_micro_tok: 0.97031249232643
train_time: 139.52649211883545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1947    0.5139    0.2824      2909
           1     0.7777    0.4445    0.5657     11132

   micro avg     0.4589    0.4589    0.4589     14041
   macro avg     0.4862    0.4792    0.4240     14041
weighted avg     0.6569    0.4589    0.5070     14041

F1-macro sent:  0.42403741296762376
F1-micro sent:  0.458870450822591
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9901    0.9936    0.9918    169578
         LOC     0.8701    0.8750    0.8725      8297
        MISC     0.7965    0.7109    0.7513      4593
         ORG     0.8310    0.8064    0.8185     10025
         PER     0.9288    0.9419    0.9353     11128

   micro avg     0.9703    0.9703    0.9703    203621
   macro avg     0.8833    0.8656    0.8739    203621
weighted avg     0.9697    0.9703    0.9699    203621

F1-macro tok:  0.87389339735334
F1-micro tok:  0.97031249232643
**************************************************
dev_cost_sum: 4384.140076637268
dev_cost_avg: 1.3489661774268518
dev_count_sent: 3250.0
dev_total_correct_sent: 1814.0
dev_accuracy_sent: 0.5581538461538461
dev_count_tok: 51362.0
dev_total_correct_tok: 50300.0
dev_accuracy_tok: 0.9793232350765158
dev_label=0_precision_sent: 0.1926961926961927
dev_label=0_recall_sent: 0.38449612403100775
dev_label=0_f-score_sent: 0.2567287784679089
dev_label=1_precision_sent: 0.7977585328578706
dev_label=1_recall_sent: 0.601151631477927
dev_label=1_f-score_sent: 0.6856392294220665
dev_precision_macro_sent: 0.4952273627770316
dev_recall_macro_sent: 0.4928238777544674
dev_f-score_macro_sent: 0.4711840039449877
dev_precision_micro_sent: 0.5581538461538461
dev_recall_micro_sent: 0.5581538461538461
dev_f-score_micro_sent: 0.5581538461538461
dev_label=O_precision_tok: 0.9896940717701128
dev_label=O_recall_tok: 0.9971701863935079
dev_label=O_f-score_tok: 0.9934180636292681
dev_label=LOC_precision_tok: 0.9207403891789274
dev_label=LOC_recall_tok: 0.9264565425023877
dev_label=LOC_f-score_tok: 0.9235896215186861
dev_label=MISC_precision_tok: 0.9180651530108588
dev_label=MISC_recall_tok: 0.7334384858044164
dev_label=MISC_f-score_tok: 0.8154318281455502
dev_label=ORG_precision_tok: 0.8915724563206577
dev_label=ORG_recall_tok: 0.8293499043977055
dev_label=ORG_f-score_tok: 0.8593363051015354
dev_label=PER_precision_tok: 0.9511512134411948
dev_label=PER_recall_tok: 0.9707843759923785
dev_label=PER_f-score_tok: 0.9608675153229608
dev_precision_macro_tok: 0.9342446567443503
dev_recall_macro_tok: 0.8914398990180793
dev_f-score_macro_tok: 0.9105286667436001
dev_precision_micro_tok: 0.9793232350765158
dev_recall_micro_tok: 0.9793232350765158
dev_f-score_micro_tok: 0.9793232350765158
dev_time: 12.901800155639648
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1927    0.3845    0.2567       645
           1     0.7978    0.6012    0.6856      2605

   micro avg     0.5582    0.5582    0.5582      3250
   macro avg     0.4952    0.4928    0.4712      3250
weighted avg     0.6777    0.5582    0.6005      3250

F1-macro sent:  0.4711840039449877
F1-micro sent:  0.5581538461538461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9897    0.9972    0.9934     42759
         LOC     0.9207    0.9265    0.9236      2094
        MISC     0.9181    0.7334    0.8154      1268
         ORG     0.8916    0.8293    0.8593      2092
         PER     0.9512    0.9708    0.9609      3149

   micro avg     0.9793    0.9793    0.9793     51362
   macro avg     0.9342    0.8914    0.9105     51362
weighted avg     0.9788    0.9793    0.9787     51362

F1-macro tok:  0.9105286667436001
F1-micro tok:  0.9793232350765158
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 16888.11651611328
train_cost_avg: 1.2027716342221553
train_count_sent: 14041.0
train_total_correct_sent: 7029.0
train_accuracy_sent: 0.5006053699878926
train_count_tok: 203621.0
train_total_correct_tok: 198453.0
train_accuracy_tok: 0.9746195137043822
train_label=0_precision_sent: 0.19024611203382152
train_label=0_recall_sent: 0.43313853557923687
train_label=0_f-score_sent: 0.26437263953000417
train_label=1_precision_sent: 0.7777028848746292
train_label=1_recall_sent: 0.5182357168523176
train_label=1_f-score_sent: 0.6219946091644204
train_precision_macro_sent: 0.48397449845422535
train_recall_macro_sent: 0.47568712621577725
train_f-score_macro_sent: 0.44318362434721226
train_precision_micro_sent: 0.5006053699878926
train_recall_micro_sent: 0.5006053699878926
train_f-score_micro_sent: 0.5006053699878926
train_label=O_precision_tok: 0.9910530585372163
train_label=O_recall_tok: 0.9941855665239595
train_label=O_f-score_tok: 0.9926168411384431
train_label=LOC_precision_tok: 0.8942156744354547
train_label=LOC_recall_tok: 0.8924912619018922
train_label=LOC_f-score_tok: 0.8933526360236458
train_label=MISC_precision_tok: 0.8256508239789826
train_label=MISC_recall_tok: 0.7526671021119095
train_label=MISC_f-score_tok: 0.7874715261958998
train_label=ORG_precision_tok: 0.8577572964669739
train_label=ORG_recall_tok: 0.8355112219451372
train_label=ORG_f-score_tok: 0.846488125315816
train_label=PER_precision_tok: 0.9422565194252261
train_label=PER_recall_tok: 0.9546189791516895
train_label=PER_f-score_tok: 0.948397464512097
train_precision_macro_tok: 0.9021866745687707
train_recall_macro_tok: 0.8858948263269177
train_f-score_macro_tok: 0.8936653186371804
train_precision_micro_tok: 0.9746195137043822
train_recall_micro_tok: 0.9746195137043822
train_f-score_micro_tok: 0.9746195137043822
train_time: 139.52173948287964
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1902    0.4331    0.2644      2909
           1     0.7777    0.5182    0.6220     11132

   micro avg     0.5006    0.5006    0.5006     14041
   macro avg     0.4840    0.4757    0.4432     14041
weighted avg     0.6560    0.5006    0.5479     14041

F1-macro sent:  0.44318362434721226
F1-micro sent:  0.5006053699878926
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9911    0.9942    0.9926    169578
         LOC     0.8942    0.8925    0.8934      8297
        MISC     0.8257    0.7527    0.7875      4593
         ORG     0.8578    0.8355    0.8465     10025
         PER     0.9423    0.9546    0.9484     11128

   micro avg     0.9746    0.9746    0.9746    203621
   macro avg     0.9022    0.8859    0.8937    203621
weighted avg     0.9741    0.9746    0.9743    203621

F1-macro tok:  0.8936653186371804
F1-micro tok:  0.9746195137043822
**************************************************
dev_cost_sum: 3764.3857979774475
dev_cost_avg: 1.15827255322383
dev_count_sent: 3250.0
dev_total_correct_sent: 1441.0
dev_accuracy_sent: 0.4433846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50444.0
dev_accuracy_tok: 0.9821268642186831
dev_label=0_precision_sent: 0.19592476489028213
dev_label=0_recall_sent: 0.5813953488372093
dev_label=0_f-score_sent: 0.29308323563892147
dev_label=1_precision_sent: 0.7979041916167665
dev_label=1_recall_sent: 0.4092130518234165
dev_label=1_f-score_sent: 0.5409794468409034
dev_precision_macro_sent: 0.4969144782535243
dev_recall_macro_sent: 0.4953042003303129
dev_f-score_macro_sent: 0.4170313412399124
dev_precision_micro_sent: 0.4433846153846154
dev_recall_micro_sent: 0.4433846153846154
dev_f-score_micro_sent: 0.4433846153846154
dev_label=O_precision_tok: 0.9919975806639216
dev_label=O_recall_tok: 0.9972871208400571
dev_label=O_f-score_tok: 0.994635318265575
dev_label=LOC_precision_tok: 0.9235127478753541
dev_label=LOC_recall_tok: 0.9340974212034384
dev_label=LOC_f-score_tok: 0.9287749287749288
dev_label=MISC_precision_tok: 0.9096774193548387
dev_label=MISC_recall_tok: 0.7783911671924291
dev_label=MISC_f-score_tok: 0.8389290267743307
dev_label=ORG_precision_tok: 0.8980099502487562
dev_label=ORG_recall_tok: 0.862810707456979
dev_label=ORG_f-score_tok: 0.8800585080448562
dev_label=PER_precision_tok: 0.965528146742568
dev_label=PER_recall_tok: 0.9695141314703081
dev_label=PER_f-score_tok: 0.9675170337505943
dev_precision_macro_tok: 0.9377451689770877
dev_recall_macro_tok: 0.9084201096326423
dev_f-score_macro_tok: 0.921982963122057
dev_precision_micro_tok: 0.9821268642186831
dev_recall_micro_tok: 0.9821268642186831
dev_f-score_micro_tok: 0.9821268642186831
dev_time: 13.117914915084839
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1959    0.5814    0.2931       645
           1     0.7979    0.4092    0.5410      2605

   micro avg     0.4434    0.4434    0.4434      3250
   macro avg     0.4969    0.4953    0.4170      3250
weighted avg     0.6784    0.4434    0.4918      3250

F1-macro sent:  0.4170313412399124
F1-micro sent:  0.4433846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9920    0.9973    0.9946     42759
         LOC     0.9235    0.9341    0.9288      2094
        MISC     0.9097    0.7784    0.8389      1268
         ORG     0.8980    0.8628    0.8801      2092
         PER     0.9655    0.9695    0.9675      3149

   micro avg     0.9821    0.9821    0.9821     51362
   macro avg     0.9377    0.9084    0.9220     51362
weighted avg     0.9817    0.9821    0.9818     51362

F1-macro tok:  0.921982963122057
F1-micro tok:  0.9821268642186831
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 14925.83241224289
train_cost_avg: 1.0630177631395834
train_count_sent: 14041.0
train_total_correct_sent: 7060.0
train_accuracy_sent: 0.5028131899437362
train_count_tok: 203621.0
train_total_correct_tok: 198968.0
train_accuracy_tok: 0.9771487223812868
train_label=0_precision_sent: 0.1778481012658228
train_label=0_recall_sent: 0.3863870745960811
train_label=0_f-score_sent: 0.2435800195037382
train_label=1_precision_sent: 0.7688123300090662
train_label=1_recall_sent: 0.5332375134746676
train_label=1_f-score_sent: 0.6297141038561503
train_precision_macro_sent: 0.4733302156374445
train_recall_macro_sent: 0.4598122940353744
train_f-score_macro_sent: 0.43664706167994427
train_precision_micro_sent: 0.5028131899437362
train_recall_micro_sent: 0.5028131899437362
train_f-score_micro_sent: 0.5028131899437362
train_label=O_precision_tok: 0.9921360342555995
train_label=O_recall_tok: 0.9946986047718454
train_label=O_f-score_tok: 0.9934156669434678
train_label=LOC_precision_tok: 0.9060766819387509
train_label=LOC_recall_tok: 0.9057490659274436
train_label=LOC_f-score_tok: 0.9059128443131818
train_label=MISC_precision_tok: 0.8487850908233073
train_label=MISC_recall_tok: 0.7833659917265404
train_label=MISC_f-score_tok: 0.8147644927536232
train_label=ORG_precision_tok: 0.8701232555770602
train_label=ORG_recall_tok: 0.852069825436409
train_label=ORG_f-score_tok: 0.8610019151295232
train_label=PER_precision_tok: 0.9448245224344736
train_label=PER_recall_tok: 0.955607476635514
train_label=PER_f-score_tok: 0.9501854085690032
train_precision_macro_tok: 0.9123891170058382
train_recall_macro_tok: 0.8982981928995505
train_f-score_macro_tok: 0.9050560655417599
train_precision_micro_tok: 0.9771487223812868
train_recall_micro_tok: 0.9771487223812868
train_f-score_micro_tok: 0.9771487223812868
train_time: 139.72249627113342
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1778    0.3864    0.2436      2909
           1     0.7688    0.5332    0.6297     11132

   micro avg     0.5028    0.5028    0.5028     14041
   macro avg     0.4733    0.4598    0.4366     14041
weighted avg     0.6464    0.5028    0.5497     14041

F1-macro sent:  0.43664706167994427
F1-micro sent:  0.5028131899437362
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9921    0.9947    0.9934    169578
         LOC     0.9061    0.9057    0.9059      8297
        MISC     0.8488    0.7834    0.8148      4593
         ORG     0.8701    0.8521    0.8610     10025
         PER     0.9448    0.9556    0.9502     11128

   micro avg     0.9771    0.9771    0.9771    203621
   macro avg     0.9124    0.8983    0.9051    203621
weighted avg     0.9768    0.9771    0.9769    203621

F1-macro tok:  0.9050560655417599
F1-micro tok:  0.9771487223812868
**************************************************
dev_cost_sum: 3587.159928560257
dev_cost_avg: 1.103741516480079
dev_count_sent: 3250.0
dev_total_correct_sent: 1772.0
dev_accuracy_sent: 0.5452307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50483.0
dev_accuracy_tok: 0.9828861804446868
dev_label=0_precision_sent: 0.23454429572976418
dev_label=0_recall_sent: 0.5705426356589147
dev_label=0_f-score_sent: 0.3324299909665763
dev_label=1_precision_sent: 0.8352171326591314
dev_label=1_recall_sent: 0.5389635316698657
dev_label=1_f-score_sent: 0.6551563229118059
dev_precision_macro_sent: 0.5348807141944478
dev_recall_macro_sent: 0.5547530836643901
dev_f-score_macro_sent: 0.4937931569391911
dev_precision_micro_sent: 0.5452307692307692
dev_recall_micro_sent: 0.5452307692307692
dev_f-score_micro_sent: 0.5452307692307692
dev_label=O_precision_tok: 0.9946993578517221
dev_label=O_recall_tok: 0.9962347108211137
dev_label=O_f-score_tok: 0.9954664423256684
dev_label=LOC_precision_tok: 0.9292740046838408
dev_label=LOC_recall_tok: 0.9474689589302769
dev_label=LOC_f-score_tok: 0.9382832820997872
dev_label=MISC_precision_tok: 0.832824427480916
dev_label=MISC_recall_tok: 0.860410094637224
dev_label=MISC_f-score_tok: 0.8463925523661753
dev_label=ORG_precision_tok: 0.9280692266089778
dev_label=ORG_recall_tok: 0.8202676864244742
dev_label=ORG_f-score_tok: 0.8708449632073079
dev_label=PER_precision_tok: 0.9540548874498921
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9680851063829786
dev_precision_macro_tok: 0.9277843808150699
dev_recall_macro_tok: 0.9213831177269238
dev_f-score_macro_tok: 0.9238144692763834
dev_precision_micro_tok: 0.9828861804446868
dev_recall_micro_tok: 0.9828861804446868
dev_f-score_micro_tok: 0.9828861804446868
dev_time: 12.869673252105713
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2345    0.5705    0.3324       645
           1     0.8352    0.5390    0.6552      2605

   micro avg     0.5452    0.5452    0.5452      3250
   macro avg     0.5349    0.5548    0.4938      3250
weighted avg     0.7160    0.5452    0.5911      3250

F1-macro sent:  0.4937931569391911
F1-micro sent:  0.5452307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9962    0.9955     42759
         LOC     0.9293    0.9475    0.9383      2094
        MISC     0.8328    0.8604    0.8464      1268
         ORG     0.9281    0.8203    0.8708      2092
         PER     0.9541    0.9825    0.9681      3149

   micro avg     0.9829    0.9829    0.9829     51362
   macro avg     0.9278    0.9214    0.9238     51362
weighted avg     0.9828    0.9829    0.9827     51362

F1-macro tok:  0.9238144692763834
F1-micro tok:  0.9828861804446868
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 13538.568093299866
train_cost_avg: 0.9642168003204804
train_count_sent: 14041.0
train_total_correct_sent: 7079.0
train_accuracy_sent: 0.5041663699166726
train_count_tok: 203621.0
train_total_correct_tok: 199435.0
train_accuracy_tok: 0.9794421989873343
train_label=0_precision_sent: 0.18429661941112324
train_label=0_recall_sent: 0.40666895840495015
train_label=0_f-score_sent: 0.2536449399656947
train_label=1_precision_sent: 0.7735502492784047
train_label=1_recall_sent: 0.5296442687747036
train_label=1_f-score_sent: 0.6287725285272475
train_precision_macro_sent: 0.4789234343447639
train_recall_macro_sent: 0.46815661358982685
train_f-score_macro_sent: 0.4412087342464711
train_precision_micro_sent: 0.5041663699166726
train_recall_micro_sent: 0.5041663699166726
train_f-score_micro_sent: 0.5041663699166726
train_label=O_precision_tok: 0.9928879842817981
train_label=O_recall_tok: 0.9953236858554765
train_label=O_f-score_tok: 0.9941043431142732
train_label=LOC_precision_tok: 0.9130800673238759
train_label=LOC_recall_tok: 0.9153911052187538
train_label=LOC_f-score_tok: 0.9142341257899488
train_label=MISC_precision_tok: 0.8548009367681498
train_label=MISC_recall_tok: 0.7946875680383192
train_label=MISC_f-score_tok: 0.8236488773552973
train_label=ORG_precision_tok: 0.8841184250686743
train_label=ORG_recall_tok: 0.8668329177057357
train_label=ORG_f-score_tok: 0.8753903495517277
train_label=PER_precision_tok: 0.955842997323818
train_label=PER_recall_tok: 0.9628864126527678
train_label=PER_f-score_tok: 0.9593517772405765
train_precision_macro_tok: 0.9201460821532633
train_recall_macro_tok: 0.9070243378942106
train_f-score_macro_tok: 0.9133458946103648
train_precision_micro_tok: 0.9794421989873343
train_recall_micro_tok: 0.9794421989873343
train_f-score_micro_tok: 0.9794421989873343
train_time: 138.79690718650818
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1843    0.4067    0.2536      2909
           1     0.7736    0.5296    0.6288     11132

   micro avg     0.5042    0.5042    0.5042     14041
   macro avg     0.4789    0.4682    0.4412     14041
weighted avg     0.6515    0.5042    0.5511     14041

F1-macro sent:  0.4412087342464711
F1-micro sent:  0.5041663699166726
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9929    0.9953    0.9941    169578
         LOC     0.9131    0.9154    0.9142      8297
        MISC     0.8548    0.7947    0.8236      4593
         ORG     0.8841    0.8668    0.8754     10025
         PER     0.9558    0.9629    0.9594     11128

   micro avg     0.9794    0.9794    0.9794    203621
   macro avg     0.9201    0.9070    0.9133    203621
weighted avg     0.9791    0.9794    0.9793    203621

F1-macro tok:  0.9133458946103648
F1-micro tok:  0.9794421989873343
**************************************************
dev_cost_sum: 3264.7409286499023
dev_cost_avg: 1.0045356703538162
dev_count_sent: 3250.0
dev_total_correct_sent: 2208.0
dev_accuracy_sent: 0.6793846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50573.0
dev_accuracy_tok: 0.9846384486585413
dev_label=0_precision_sent: 0.1384335154826958
dev_label=0_recall_sent: 0.11782945736434108
dev_label=0_f-score_sent: 0.12730318257956447
dev_label=1_precision_sent: 0.7893372824879674
dev_label=1_recall_sent: 0.818426103646833
dev_label=1_f-score_sent: 0.8036185450433472
dev_precision_macro_sent: 0.4638853989853316
dev_recall_macro_sent: 0.468127780505587
dev_f-score_macro_sent: 0.4654608638114558
dev_precision_micro_sent: 0.6793846153846154
dev_recall_micro_sent: 0.6793846153846154
dev_f-score_micro_sent: 0.6793846153846154
dev_label=O_precision_tok: 0.9930167597765364
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9953452560109194
dev_label=LOC_precision_tok: 0.9547004383828543
dev_label=LOC_recall_tok: 0.936007640878701
dev_label=LOC_f-score_tok: 0.9452616349168073
dev_label=MISC_precision_tok: 0.8675179569034318
dev_label=MISC_recall_tok: 0.8572555205047319
dev_label=MISC_f-score_tok: 0.8623562078540263
dev_label=ORG_precision_tok: 0.9316416364577939
dev_label=ORG_recall_tok: 0.859942638623327
dev_label=ORG_f-score_tok: 0.8943574446930151
dev_label=PER_precision_tok: 0.9690363349131121
dev_label=PER_recall_tok: 0.9739599872975547
dev_label=PER_f-score_tok: 0.9714919227114348
dev_precision_macro_tok: 0.9431826252867458
dev_recall_macro_tok: 0.9249700970525279
dev_f-score_macro_tok: 0.9337624932372405
dev_precision_micro_tok: 0.9846384486585413
dev_recall_micro_tok: 0.9846384486585413
dev_f-score_micro_tok: 0.9846384486585412
dev_time: 12.9666166305542
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1384    0.1178    0.1273       645
           1     0.7893    0.8184    0.8036      2605

   micro avg     0.6794    0.6794    0.6794      3250
   macro avg     0.4639    0.4681    0.4655      3250
weighted avg     0.6602    0.6794    0.6694      3250

F1-macro sent:  0.4654608638114558
F1-micro sent:  0.6793846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9930    0.9977    0.9953     42759
         LOC     0.9547    0.9360    0.9453      2094
        MISC     0.8675    0.8573    0.8624      1268
         ORG     0.9316    0.8599    0.8944      2092
         PER     0.9690    0.9740    0.9715      3149

   micro avg     0.9846    0.9846    0.9846     51362
   macro avg     0.9432    0.9250    0.9338     51362
weighted avg     0.9844    0.9846    0.9844     51362

F1-macro tok:  0.9337624932372405
F1-micro tok:  0.9846384486585412
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 12228.55865430832
train_cost_avg: 0.8709179299414799
train_count_sent: 14041.0
train_total_correct_sent: 7680.0
train_accuracy_sent: 0.5469695890606082
train_count_tok: 203621.0
train_total_correct_tok: 199836.0
train_accuracy_tok: 0.9814115439959533
train_label=0_precision_sent: 0.17073636016787486
train_label=0_recall_sent: 0.30766586455826744
train_label=0_f-score_sent: 0.2196049564470617
train_label=1_precision_sent: 0.7711103534492556
train_label=1_recall_sent: 0.609504132231405
train_label=1_f-score_sent: 0.6808489288043752
train_precision_macro_sent: 0.47092335680856523
train_recall_macro_sent: 0.45858499839483624
train_f-score_macro_sent: 0.45022694262571844
train_precision_micro_sent: 0.5469695890606082
train_recall_micro_sent: 0.5469695890606082
train_f-score_micro_sent: 0.5469695890606082
train_label=O_precision_tok: 0.9934918206425797
train_label=O_recall_tok: 0.9956126384318721
train_label=O_f-score_tok: 0.9945510989108088
train_label=LOC_precision_tok: 0.9216534486902187
train_label=LOC_recall_tok: 0.924430517054357
train_label=LOC_f-score_tok: 0.9230398940971177
train_label=MISC_precision_tok: 0.8679288847841146
train_label=MISC_recall_tok: 0.8184193337687786
train_label=MISC_f-score_tok: 0.8424473330345136
train_label=ORG_precision_tok: 0.8999082662317807
train_label=ORG_recall_tok: 0.8806982543640898
train_label=ORG_f-score_tok: 0.8901996370235934
train_label=PER_precision_tok: 0.9578318623517874
train_label=PER_recall_tok: 0.9654924514737598
train_label=PER_f-score_tok: 0.9616469008726783
train_precision_macro_tok: 0.9281628565400961
train_recall_macro_tok: 0.9169306390185714
train_f-score_macro_tok: 0.9223769727877424
train_precision_micro_tok: 0.9814115439959533
train_recall_micro_tok: 0.9814115439959533
train_f-score_micro_tok: 0.9814115439959533
train_time: 140.25042819976807
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1707    0.3077    0.2196      2909
           1     0.7711    0.6095    0.6808     11132

   micro avg     0.5470    0.5470    0.5470     14041
   macro avg     0.4709    0.4586    0.4502     14041
weighted avg     0.6467    0.5470    0.5853     14041

F1-macro sent:  0.45022694262571844
F1-micro sent:  0.5469695890606082
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9935    0.9956    0.9946    169578
         LOC     0.9217    0.9244    0.9230      8297
        MISC     0.8679    0.8184    0.8424      4593
         ORG     0.8999    0.8807    0.8902     10025
         PER     0.9578    0.9655    0.9616     11128

   micro avg     0.9814    0.9814    0.9814    203621
   macro avg     0.9282    0.9169    0.9224    203621
weighted avg     0.9812    0.9814    0.9813    203621

F1-macro tok:  0.9223769727877424
F1-micro tok:  0.9814115439959533
**************************************************
dev_cost_sum: 3213.6059092879295
dev_cost_avg: 0.9888018182424398
dev_count_sent: 3250.0
dev_total_correct_sent: 1732.0
dev_accuracy_sent: 0.5329230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50615.0
dev_accuracy_tok: 0.9854561738250068
dev_label=0_precision_sent: 0.17352281226626776
dev_label=0_recall_sent: 0.35968992248062015
dev_label=0_f-score_sent: 0.23410696266397577
dev_label=1_precision_sent: 0.7841087297438578
dev_label=1_recall_sent: 0.5758157389635317
dev_label=1_f-score_sent: 0.6640106241699867
dev_precision_macro_sent: 0.4788157710050628
dev_recall_macro_sent: 0.4677528307220759
dev_f-score_macro_sent: 0.44905879341698124
dev_precision_micro_sent: 0.5329230769230769
dev_recall_micro_sent: 0.5329230769230769
dev_f-score_micro_sent: 0.5329230769230769
dev_label=O_precision_tok: 0.9939405239116249
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9956692775514492
dev_label=LOC_precision_tok: 0.9626679940268791
dev_label=LOC_recall_tok: 0.9235912129894938
dev_label=LOC_f-score_tok: 0.9427248354862295
dev_label=MISC_precision_tok: 0.8994932432432432
dev_label=MISC_recall_tok: 0.8399053627760252
dev_label=MISC_f-score_tok: 0.8686786296900488
dev_label=ORG_precision_tok: 0.8894030541416011
dev_label=ORG_recall_tok: 0.9187380497131931
dev_label=ORG_f-score_tok: 0.9038325887608747
dev_label=PER_precision_tok: 0.9825806451612903
dev_label=PER_recall_tok: 0.9672912035566846
dev_label=PER_f-score_tok: 0.9748759801568251
dev_precision_macro_tok: 0.9456170920969278
dev_recall_macro_tok: 0.9293859768644005
dev_f-score_macro_tok: 0.9371562623290854
dev_precision_micro_tok: 0.9854561738250068
dev_recall_micro_tok: 0.9854561738250068
dev_f-score_micro_tok: 0.9854561738250068
dev_time: 12.880748510360718
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1735    0.3597    0.2341       645
           1     0.7841    0.5758    0.6640      2605

   micro avg     0.5329    0.5329    0.5329      3250
   macro avg     0.4788    0.4678    0.4491      3250
weighted avg     0.6629    0.5329    0.5787      3250

F1-macro sent:  0.44905879341698124
F1-micro sent:  0.5329230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9939    0.9974    0.9957     42759
         LOC     0.9627    0.9236    0.9427      2094
        MISC     0.8995    0.8399    0.8687      1268
         ORG     0.8894    0.9187    0.9038      2092
         PER     0.9826    0.9673    0.9749      3149

   micro avg     0.9855    0.9855    0.9855     51362
   macro avg     0.9456    0.9294    0.9372     51362
weighted avg     0.9854    0.9855    0.9854     51362

F1-macro tok:  0.9371562623290854
F1-micro tok:  0.9854561738250068
**************************************************
Best epoch: 4
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 11127.70530462265
train_cost_avg: 0.7925151559449221
train_count_sent: 14041.0
train_total_correct_sent: 7433.0
train_accuracy_sent: 0.529378249412435
train_count_tok: 203621.0
train_total_correct_tok: 200191.0
train_accuracy_tok: 0.9831549791033342
train_label=0_precision_sent: 0.1699089773335713
train_label=0_recall_sent: 0.32726022688209006
train_label=0_f-score_sent: 0.2236842105263158
train_label=1_precision_sent: 0.7680730030812989
train_label=1_recall_sent: 0.582195472511678
train_label=1_f-score_sent: 0.6623403168114461
train_precision_macro_sent: 0.46899099020743507
train_recall_macro_sent: 0.45472784969688407
train_f-score_macro_sent: 0.44301226366888097
train_precision_micro_sent: 0.529378249412435
train_recall_micro_sent: 0.529378249412435
train_f-score_micro_sent: 0.529378249412435
train_label=O_precision_tok: 0.9940607929930307
train_label=O_recall_tok: 0.9958780030428476
train_label=O_f-score_tok: 0.9949685682807704
train_label=LOC_precision_tok: 0.9328159107446035
train_label=LOC_recall_tok: 0.9270820778594673
train_label=LOC_f-score_tok: 0.9299401559572025
train_label=MISC_precision_tok: 0.8847915712322492
train_label=MISC_recall_tok: 0.8410624863923362
train_label=MISC_f-score_tok: 0.8623730327045429
train_label=ORG_precision_tok: 0.9041247484909457
train_label=ORG_recall_tok: 0.8964588528678304
train_label=ORG_f-score_tok: 0.9002754820936639
train_label=PER_precision_tok: 0.9632412127716662
train_label=PER_recall_tok: 0.9678289000718907
train_label=PER_f-score_tok: 0.9655296068851137
train_precision_macro_tok: 0.9358068472464991
train_recall_macro_tok: 0.9256620640468745
train_f-score_macro_tok: 0.9306173691842586
train_precision_micro_tok: 0.9831549791033342
train_recall_micro_tok: 0.9831549791033342
train_f-score_micro_tok: 0.9831549791033342
train_time: 140.01702547073364
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1699    0.3273    0.2237      2909
           1     0.7681    0.5822    0.6623     11132

   micro avg     0.5294    0.5294    0.5294     14041
   macro avg     0.4690    0.4547    0.4430     14041
weighted avg     0.6441    0.5294    0.5715     14041

F1-macro sent:  0.44301226366888097
F1-micro sent:  0.529378249412435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9941    0.9959    0.9950    169578
         LOC     0.9328    0.9271    0.9299      8297
        MISC     0.8848    0.8411    0.8624      4593
         ORG     0.9041    0.8965    0.9003     10025
         PER     0.9632    0.9678    0.9655     11128

   micro avg     0.9832    0.9832    0.9832    203621
   macro avg     0.9358    0.9257    0.9306    203621
weighted avg     0.9830    0.9832    0.9831    203621

F1-macro tok:  0.9306173691842586
F1-micro tok:  0.9831549791033342
**************************************************
dev_cost_sum: 2981.7203990519047
dev_cost_avg: 0.9174524304775091
dev_count_sent: 3250.0
dev_total_correct_sent: 1792.0
dev_accuracy_sent: 0.5513846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50677.0
dev_accuracy_tok: 0.9866632919278844
dev_label=0_precision_sent: 0.18850574712643678
dev_label=0_recall_sent: 0.3813953488372093
dev_label=0_f-score_sent: 0.2523076923076923
dev_label=1_precision_sent: 0.7948586118251928
dev_label=1_recall_sent: 0.5934740882917466
dev_label=1_f-score_sent: 0.6795604395604395
dev_precision_macro_sent: 0.4916821794758148
dev_recall_macro_sent: 0.48743471856447795
dev_f-score_macro_sent: 0.46593406593406594
dev_precision_micro_sent: 0.5513846153846154
dev_recall_micro_sent: 0.5513846153846154
dev_f-score_micro_sent: 0.5513846153846154
dev_label=O_precision_tok: 0.9957239993457485
dev_label=O_recall_tok: 0.9966089010500714
dev_label=O_f-score_tok: 0.9961662536817991
dev_label=LOC_precision_tok: 0.9575903614457831
dev_label=LOC_recall_tok: 0.9489016236867239
dev_label=LOC_f-score_tok: 0.9532261933317342
dev_label=MISC_precision_tok: 0.8955954323001631
dev_label=MISC_recall_tok: 0.8659305993690851
dev_label=MISC_f-score_tok: 0.8805132317562149
dev_label=ORG_precision_tok: 0.9211943220753793
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9102781136638453
dev_label=PER_precision_tok: 0.9611921763427507
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9720565149136577
dev_precision_macro_tok: 0.9462592583019649
dev_recall_macro_tok: 0.9388455950021253
dev_f-score_macro_tok: 0.9424480614694503
dev_precision_micro_tok: 0.9866632919278844
dev_recall_micro_tok: 0.9866632919278844
dev_f-score_micro_tok: 0.9866632919278844
dev_time: 13.023048877716064
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1885    0.3814    0.2523       645
           1     0.7949    0.5935    0.6796      2605

   micro avg     0.5514    0.5514    0.5514      3250
   macro avg     0.4917    0.4874    0.4659      3250
weighted avg     0.6745    0.5514    0.5948      3250

F1-macro sent:  0.46593406593406594
F1-micro sent:  0.5513846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9966    0.9962     42759
         LOC     0.9576    0.9489    0.9532      2094
        MISC     0.8956    0.8659    0.8805      1268
         ORG     0.9212    0.8996    0.9103      2092
         PER     0.9612    0.9832    0.9721      3149

   micro avg     0.9867    0.9867    0.9867     51362
   macro avg     0.9463    0.9388    0.9424     51362
weighted avg     0.9865    0.9867    0.9866     51362

F1-macro tok:  0.9424480614694503
F1-micro tok:  0.9866632919278844
**************************************************
Best epoch: 4
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 10393.864226579666
train_cost_avg: 0.7402509954119839
train_count_sent: 14041.0
train_total_correct_sent: 7353.0
train_accuracy_sent: 0.523680649526387
train_count_tok: 203621.0
train_total_correct_tok: 200421.0
train_accuracy_tok: 0.9842845286095245
train_label=0_precision_sent: 0.1657526976826464
train_label=0_recall_sent: 0.322103815744242
train_label=0_f-score_sent: 0.21887409483765477
train_label=1_precision_sent: 0.7649022412970911
train_label=1_recall_sent: 0.5763564498742364
train_label=1_f-score_sent: 0.6573770491803278
train_precision_macro_sent: 0.4653274694898687
train_recall_macro_sent: 0.4492301328092392
train_f-score_macro_sent: 0.43812557200899127
train_precision_micro_sent: 0.523680649526387
train_recall_micro_sent: 0.523680649526387
train_f-score_micro_sent: 0.523680649526387
train_label=O_precision_tok: 0.9945250640214288
train_label=O_recall_tok: 0.9962082345587281
train_label=O_f-score_tok: 0.9953659377273946
train_label=LOC_precision_tok: 0.9330604382374187
train_label=LOC_recall_tok: 0.9340725563456671
train_label=LOC_f-score_tok: 0.9335662229717521
train_label=MISC_precision_tok: 0.890485968514716
train_label=MISC_recall_tok: 0.8497713912475506
train_label=MISC_f-score_tok: 0.8696524064171124
train_label=ORG_precision_tok: 0.911922337951259
train_label=ORG_recall_tok: 0.8995511221945137
train_label=ORG_f-score_tok: 0.9056944862910515
train_label=PER_precision_tok: 0.9675254965110037
train_label=PER_recall_tok: 0.9718727534148095
train_label=PER_f-score_tok: 0.9696942526674437
train_precision_macro_tok: 0.9395038610471653
train_recall_macro_tok: 0.9302952115522537
train_f-score_macro_tok: 0.9347946612149508
train_precision_micro_tok: 0.9842845286095245
train_recall_micro_tok: 0.9842845286095245
train_f-score_micro_tok: 0.9842845286095245
train_time: 138.86079955101013
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1658    0.3221    0.2189      2909
           1     0.7649    0.5764    0.6574     11132

   micro avg     0.5237    0.5237    0.5237     14041
   macro avg     0.4653    0.4492    0.4381     14041
weighted avg     0.6408    0.5237    0.5665     14041

F1-macro sent:  0.43812557200899127
F1-micro sent:  0.523680649526387
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9962    0.9954    169578
         LOC     0.9331    0.9341    0.9336      8297
        MISC     0.8905    0.8498    0.8697      4593
         ORG     0.9119    0.8996    0.9057     10025
         PER     0.9675    0.9719    0.9697     11128

   micro avg     0.9843    0.9843    0.9843    203621
   macro avg     0.9395    0.9303    0.9348    203621
weighted avg     0.9841    0.9843    0.9842    203621

F1-macro tok:  0.9347946612149508
F1-micro tok:  0.9842845286095245
**************************************************
dev_cost_sum: 2975.865742981434
dev_cost_avg: 0.9156509978404412
dev_count_sent: 3250.0
dev_total_correct_sent: 1560.0
dev_accuracy_sent: 0.48
dev_count_tok: 51362.0
dev_total_correct_tok: 50630.0
dev_accuracy_tok: 0.9857482185273159
dev_label=0_precision_sent: 0.1715901948460088
dev_label=0_recall_sent: 0.4232558139534884
dev_label=0_f-score_sent: 0.24418604651162792
dev_label=1_precision_sent: 0.7757685352622061
dev_label=1_recall_sent: 0.4940499040307102
dev_label=1_f-score_sent: 0.6036585365853658
dev_precision_macro_sent: 0.47367936505410746
dev_recall_macro_sent: 0.4586528589920993
dev_f-score_macro_sent: 0.42392229154849687
dev_precision_micro_sent: 0.48
dev_recall_micro_sent: 0.48
dev_f-score_micro_sent: 0.48
dev_label=O_precision_tok: 0.9930652517918644
dev_label=O_recall_tok: 0.9980121144086626
dev_label=O_f-score_tok: 0.9955325378217914
dev_label=LOC_precision_tok: 0.9534995206136145
dev_label=LOC_recall_tok: 0.9498567335243553
dev_label=LOC_f-score_tok: 0.9516746411483252
dev_label=MISC_precision_tok: 0.857915057915058
dev_label=MISC_recall_tok: 0.8761829652996845
dev_label=MISC_f-score_tok: 0.8669527896995709
dev_label=ORG_precision_tok: 0.9545940170940171
dev_label=ORG_recall_tok: 0.8542065009560229
dev_label=ORG_f-score_tok: 0.9016145307769929
dev_label=PER_precision_tok: 0.9783232387631495
dev_label=PER_recall_tok: 0.9745951095585901
dev_label=PER_f-score_tok: 0.9764556156538339
dev_precision_macro_tok: 0.9474794172355407
dev_recall_macro_tok: 0.930570684749463
dev_f-score_macro_tok: 0.9384460230201028
dev_precision_micro_tok: 0.9857482185273159
dev_recall_micro_tok: 0.9857482185273159
dev_f-score_micro_tok: 0.9857482185273159
dev_time: 12.790127038955688
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1716    0.4233    0.2442       645
           1     0.7758    0.4940    0.6037      2605

   micro avg     0.4800    0.4800    0.4800      3250
   macro avg     0.4737    0.4587    0.4239      3250
weighted avg     0.6559    0.4800    0.5323      3250

F1-macro sent:  0.42392229154849687
F1-micro sent:  0.48
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9931    0.9980    0.9955     42759
         LOC     0.9535    0.9499    0.9517      2094
        MISC     0.8579    0.8762    0.8670      1268
         ORG     0.9546    0.8542    0.9016      2092
         PER     0.9783    0.9746    0.9765      3149

   micro avg     0.9857    0.9857    0.9857     51362
   macro avg     0.9475    0.9306    0.9384     51362
weighted avg     0.9856    0.9857    0.9856     51362

F1-macro tok:  0.9384460230201028
F1-micro tok:  0.9857482185273159
**************************************************
Best epoch: 4
**************************************************

EPOCH: 9
Learning rate: 0.900000
train_cost_sum: 9529.876718044281
train_cost_avg: 0.6787178062847575
train_count_sent: 14041.0
train_total_correct_sent: 7493.0
train_accuracy_sent: 0.5336514493269711
train_count_tok: 203621.0
train_total_correct_tok: 200633.0
train_accuracy_tok: 0.9853256785891435
train_label=0_precision_sent: 0.15002885170225044
train_label=0_recall_sent: 0.268133379168099
train_label=0_f-score_sent: 0.19240256536753822
train_label=1_precision_sent: 0.7592173716353766
train_label=1_recall_sent: 0.6030362917714697
train_label=1_f-score_sent: 0.6721738259737658
train_precision_macro_sent: 0.45462311166881353
train_recall_macro_sent: 0.4355848354697843
train_f-score_macro_sent: 0.432288195670652
train_precision_micro_sent: 0.5336514493269711
train_recall_micro_sent: 0.5336514493269711
train_f-score_micro_sent: 0.5336514493269711
train_label=O_precision_tok: 0.9947951932078449
train_label=O_recall_tok: 0.9963497623512484
train_label=O_f-score_tok: 0.9955718709213631
train_label=LOC_precision_tok: 0.9432846627247496
train_label=LOC_recall_tok: 0.9421477642521393
train_label=LOC_f-score_tok: 0.9427158707187651
train_label=MISC_precision_tok: 0.896543883583447
train_label=MISC_recall_tok: 0.8584802961027651
train_label=MISC_f-score_tok: 0.877099321543766
train_label=ORG_precision_tok: 0.9176731078904992
train_label=ORG_recall_tok: 0.9095261845386534
train_label=ORG_f-score_tok: 0.9135814838935925
train_label=PER_precision_tok: 0.9676436318006633
train_label=PER_recall_tok: 0.9701653486700216
train_label=PER_f-score_tok: 0.9689028494503029
train_precision_macro_tok: 0.9439880958414408
train_recall_macro_tok: 0.9353338711829655
train_f-score_macro_tok: 0.9395742793055579
train_precision_micro_tok: 0.9853256785891435
train_recall_micro_tok: 0.9853256785891435
train_f-score_micro_tok: 0.9853256785891435
train_time: 139.14776587486267
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1500    0.2681    0.1924      2909
           1     0.7592    0.6030    0.6722     11132

   micro avg     0.5337    0.5337    0.5337     14041
   macro avg     0.4546    0.4356    0.4323     14041
weighted avg     0.6330    0.5337    0.5728     14041

F1-macro sent:  0.432288195670652
F1-micro sent:  0.5336514493269711
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9948    0.9963    0.9956    169578
         LOC     0.9433    0.9421    0.9427      8297
        MISC     0.8965    0.8585    0.8771      4593
         ORG     0.9177    0.9095    0.9136     10025
         PER     0.9676    0.9702    0.9689     11128

   micro avg     0.9853    0.9853    0.9853    203621
   macro avg     0.9440    0.9353    0.9396    203621
weighted avg     0.9852    0.9853    0.9853    203621

F1-macro tok:  0.9395742793055579
F1-micro tok:  0.9853256785891435
**************************************************
dev_cost_sum: 2968.0034054219723
dev_cost_avg: 0.9132318170529146
dev_count_sent: 3250.0
dev_total_correct_sent: 1793.0
dev_accuracy_sent: 0.5516923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50682.0
dev_accuracy_tok: 0.9867606401619875
dev_label=0_precision_sent: 0.09481037924151696
dev_label=0_recall_sent: 0.14728682170542637
dev_label=0_f-score_sent: 0.11536126290224652
dev_label=1_precision_sent: 0.755338078291815
dev_label=1_recall_sent: 0.6518234165067178
dev_label=1_f-score_sent: 0.6997733360807749
dev_precision_macro_sent: 0.42507422876666595
dev_recall_macro_sent: 0.3995551191060721
dev_f-score_macro_sent: 0.4075672994915107
dev_precision_micro_sent: 0.5516923076923077
dev_recall_micro_sent: 0.5516923076923077
dev_f-score_micro_sent: 0.5516923076923077
dev_label=O_precision_tok: 0.9957932130503879
dev_label=O_recall_tok: 0.9964685797142122
dev_label=O_f-score_tok: 0.9961307819093597
dev_label=LOC_precision_tok: 0.9621542940320232
dev_label=LOC_recall_tok: 0.9469914040114613
dev_label=LOC_f-score_tok: 0.9545126353790614
dev_label=MISC_precision_tok: 0.9073614557485525
dev_label=MISC_recall_tok: 0.8651419558359621
dev_label=MISC_f-score_tok: 0.8857488897860315
dev_label=ORG_precision_tok: 0.9180009704027171
dev_label=ORG_recall_tok: 0.904397705544933
dev_label=ORG_f-score_tok: 0.9111485673007464
dev_label=PER_precision_tok: 0.9565217391304348
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.9705882352941176
dev_precision_macro_tok: 0.9479663344728231
dev_recall_macro_tok: 0.939614854394448
dev_f-score_macro_tok: 0.9436258219338634
dev_precision_micro_tok: 0.9867606401619875
dev_recall_micro_tok: 0.9867606401619875
dev_f-score_micro_tok: 0.9867606401619875
dev_time: 13.076786994934082
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0948    0.1473    0.1154       645
           1     0.7553    0.6518    0.6998      2605

   micro avg     0.5517    0.5517    0.5517      3250
   macro avg     0.4251    0.3996    0.4076      3250
weighted avg     0.6242    0.5517    0.5838      3250

F1-macro sent:  0.4075672994915107
F1-micro sent:  0.5516923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9965    0.9961     42759
         LOC     0.9622    0.9470    0.9545      2094
        MISC     0.9074    0.8651    0.8857      1268
         ORG     0.9180    0.9044    0.9111      2092
         PER     0.9565    0.9851    0.9706      3149

   micro avg     0.9868    0.9868    0.9868     51362
   macro avg     0.9480    0.9396    0.9436     51362
weighted avg     0.9867    0.9868    0.9867     51362

F1-macro tok:  0.9436258219338634
F1-micro tok:  0.9867606401619875
**************************************************
Best epoch: 4
**************************************************

EPOCH: 10
Learning rate: 0.810000
train_cost_sum: 8859.157160043716
train_cost_avg: 0.6309491603193302
train_count_sent: 14041.0
train_total_correct_sent: 7309.0
train_accuracy_sent: 0.5205469695890607
train_count_tok: 203621.0
train_total_correct_tok: 200884.0
train_accuracy_tok: 0.986558360876334
train_label=0_precision_sent: 0.15884347670890595
train_label=0_recall_sent: 0.30594706084565143
train_label=0_f-score_sent: 0.20911654135338348
train_label=1_precision_sent: 0.7607252903531643
train_label=1_recall_sent: 0.5766259432267338
train_label=1_f-score_sent: 0.6560040878896269
train_precision_macro_sent: 0.4597843835310351
train_recall_macro_sent: 0.4412865020361926
train_f-score_macro_sent: 0.43256031462150524
train_precision_micro_sent: 0.5205469695890607
train_recall_micro_sent: 0.5205469695890607
train_f-score_micro_sent: 0.5205469695890607
train_label=O_precision_tok: 0.9953421818138992
train_label=O_recall_tok: 0.9967743457288092
train_label=O_f-score_tok: 0.9960577489687684
train_label=LOC_precision_tok: 0.946480231436837
train_label=LOC_recall_tok: 0.9463661564420875
train_label=LOC_f-score_tok: 0.9464231905020188
train_label=MISC_precision_tok: 0.9034810126582279
train_label=MISC_recall_tok: 0.8702373176573046
train_label=MISC_f-score_tok: 0.8865476322501942
train_label=ORG_precision_tok: 0.9238757814075419
train_label=ORG_recall_tok: 0.9140149625935162
train_label=ORG_f-score_tok: 0.9189189189189189
train_label=PER_precision_tok: 0.97132873398441
train_label=PER_recall_tok: 0.9742092020129404
train_label=PER_f-score_tok: 0.9727668356588451
train_precision_macro_tok: 0.9481015882601833
train_recall_macro_tok: 0.9403203968869317
train_f-score_macro_tok: 0.9441428652597491
train_precision_micro_tok: 0.986558360876334
train_recall_micro_tok: 0.986558360876334
train_f-score_micro_tok: 0.986558360876334
train_time: 139.09238958358765
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1588    0.3059    0.2091      2909
           1     0.7607    0.5766    0.6560     11132

   micro avg     0.5205    0.5205    0.5205     14041
   macro avg     0.4598    0.4413    0.4326     14041
weighted avg     0.6360    0.5205    0.5634     14041

F1-macro sent:  0.43256031462150524
F1-micro sent:  0.5205469695890607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9953    0.9968    0.9961    169578
         LOC     0.9465    0.9464    0.9464      8297
        MISC     0.9035    0.8702    0.8865      4593
         ORG     0.9239    0.9140    0.9189     10025
         PER     0.9713    0.9742    0.9728     11128

   micro avg     0.9866    0.9866    0.9866    203621
   macro avg     0.9481    0.9403    0.9441    203621
weighted avg     0.9864    0.9866    0.9865    203621

F1-macro tok:  0.9441428652597491
F1-micro tok:  0.986558360876334
**************************************************
dev_cost_sum: 2810.4741283655167
dev_cost_avg: 0.8647612702663128
dev_count_sent: 3250.0
dev_total_correct_sent: 1619.0
dev_accuracy_sent: 0.49815384615384617
dev_count_tok: 51362.0
dev_total_correct_tok: 50696.0
dev_accuracy_tok: 0.987033215217476
dev_label=0_precision_sent: 0.12193251533742332
dev_label=0_recall_sent: 0.24651162790697675
dev_label=0_f-score_sent: 0.16316059517701387
dev_label=1_precision_sent: 0.750256937307297
dev_label=1_recall_sent: 0.5604606525911708
dev_label=1_f-score_sent: 0.6416172269830808
dev_precision_macro_sent: 0.4360947263223602
dev_recall_macro_sent: 0.4034861402490738
dev_f-score_macro_sent: 0.4023889110800473
dev_precision_micro_sent: 0.49815384615384617
dev_recall_micro_sent: 0.49815384615384617
dev_f-score_micro_sent: 0.49815384615384617
dev_label=O_precision_tok: 0.9945215060030307
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9961005907488266
dev_label=LOC_precision_tok: 0.958011583011583
dev_label=LOC_recall_tok: 0.9479465138490927
dev_label=LOC_f-score_tok: 0.9529524723955833
dev_label=MISC_precision_tok: 0.8849840255591054
dev_label=MISC_recall_tok: 0.8738170347003155
dev_label=MISC_f-score_tok: 0.8793650793650793
dev_label=ORG_precision_tok: 0.9364364364364365
dev_label=ORG_recall_tok: 0.8943594646271511
dev_label=ORG_f-score_tok: 0.914914425427873
dev_label=PER_precision_tok: 0.9767885532591415
dev_label=PER_recall_tok: 0.9755477929501429
dev_label=PER_f-score_tok: 0.9761677788369876
dev_precision_macro_tok: 0.9501484208538594
dev_recall_macro_tok: 0.9378711008170054
dev_f-score_macro_tok: 0.9439000693548699
dev_precision_micro_tok: 0.987033215217476
dev_recall_micro_tok: 0.987033215217476
dev_f-score_micro_tok: 0.987033215217476
dev_time: 12.96548080444336
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1219    0.2465    0.1632       645
           1     0.7503    0.5605    0.6416      2605

   micro avg     0.4982    0.4982    0.4982      3250
   macro avg     0.4361    0.4035    0.4024      3250
weighted avg     0.6256    0.4982    0.5467      3250

F1-macro sent:  0.4023889110800473
F1-micro sent:  0.49815384615384617
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9977    0.9961     42759
         LOC     0.9580    0.9479    0.9530      2094
        MISC     0.8850    0.8738    0.8794      1268
         ORG     0.9364    0.8944    0.9149      2092
         PER     0.9768    0.9755    0.9762      3149

   micro avg     0.9870    0.9870    0.9870     51362
   macro avg     0.9501    0.9379    0.9439     51362
weighted avg     0.9869    0.9870    0.9869     51362

F1-macro tok:  0.9439000693548699
F1-micro tok:  0.987033215217476
**************************************************
Best epoch: 4
**************************************************

EPOCH: 11
Learning rate: 0.729000
train_cost_sum: 8171.180243015289
train_cost_avg: 0.58195144526852
train_count_sent: 14041.0
train_total_correct_sent: 7402.0
train_accuracy_sent: 0.5271704294565914
train_count_tok: 203621.0
train_total_correct_tok: 201094.0
train_accuracy_tok: 0.9875896886863339
train_label=0_precision_sent: 0.16127860515800943
train_label=0_recall_sent: 0.305259539360605
train_label=0_f-score_sent: 0.2110516934046346
train_label=1_precision_sent: 0.7632103104862331
train_label=1_recall_sent: 0.5851598993891484
train_label=1_f-score_sent: 0.662429450348299
train_precision_macro_sent: 0.46224445782212126
train_recall_macro_sent: 0.4452097193748767
train_f-score_macro_sent: 0.4367405718764668
train_precision_micro_sent: 0.5271704294565914
train_recall_micro_sent: 0.5271704294565914
train_f-score_micro_sent: 0.5271704294565914
train_label=O_precision_tok: 0.9956530958439356
train_label=O_recall_tok: 0.9968156246682942
train_label=O_f-score_tok: 0.9962340211106986
train_label=LOC_precision_tok: 0.9439173772066771
train_label=LOC_recall_tok: 0.9473303603712185
train_label=LOC_f-score_tok: 0.9456207892204043
train_label=MISC_precision_tok: 0.9154105736782903
train_label=MISC_recall_tok: 0.8859133463966906
train_label=MISC_f-score_tok: 0.900420447001549
train_label=ORG_precision_tok: 0.9322050972096303
train_label=ORG_recall_tok: 0.9230922693266833
train_label=ORG_f-score_tok: 0.927626303127506
train_label=PER_precision_tok: 0.9755069083079132
train_label=PER_recall_tok: 0.9770848310567937
train_label=PER_f-score_tok: 0.9762952321091857
train_precision_macro_tok: 0.9525386104492893
train_recall_macro_tok: 0.946047286363936
train_f-score_macro_tok: 0.9492393585138688
train_precision_micro_tok: 0.9875896886863339
train_recall_micro_tok: 0.9875896886863339
train_f-score_micro_tok: 0.9875896886863339
train_time: 139.88264799118042
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1613    0.3053    0.2111      2909
           1     0.7632    0.5852    0.6624     11132

   micro avg     0.5272    0.5272    0.5272     14041
   macro avg     0.4622    0.4452    0.4367     14041
weighted avg     0.6385    0.5272    0.5689     14041

F1-macro sent:  0.4367405718764668
F1-micro sent:  0.5271704294565914
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9968    0.9962    169578
         LOC     0.9439    0.9473    0.9456      8297
        MISC     0.9154    0.8859    0.9004      4593
         ORG     0.9322    0.9231    0.9276     10025
         PER     0.9755    0.9771    0.9763     11128

   micro avg     0.9876    0.9876    0.9876    203621
   macro avg     0.9525    0.9460    0.9492    203621
weighted avg     0.9875    0.9876    0.9875    203621

F1-macro tok:  0.9492393585138688
F1-micro tok:  0.9875896886863339
**************************************************
dev_cost_sum: 2842.825456827879
dev_cost_avg: 0.8747155251778089
dev_count_sent: 3250.0
dev_total_correct_sent: 1676.0
dev_accuracy_sent: 0.5156923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50725.0
dev_accuracy_tok: 0.9875978349752735
dev_label=0_precision_sent: 0.1863605671843349
dev_label=0_recall_sent: 0.42790697674418604
dev_label=0_f-score_sent: 0.2596425211665099
dev_label=1_precision_sent: 0.791407574901074
dev_label=1_recall_sent: 0.5374280230326296
dev_label=1_f-score_sent: 0.6401463191586649
dev_precision_macro_sent: 0.4888840710427045
dev_recall_macro_sent: 0.48266749988840785
dev_f-score_macro_sent: 0.4498944201625874
dev_precision_micro_sent: 0.5156923076923077
dev_recall_micro_sent: 0.5156923076923077
dev_f-score_micro_sent: 0.5156923076923077
dev_label=O_precision_tok: 0.9940144863404523
dev_label=O_recall_tok: 0.9981524357445216
dev_label=O_f-score_tok: 0.9960791635548918
dev_label=LOC_precision_tok: 0.9581931763575204
dev_label=LOC_recall_tok: 0.9522445081184336
dev_label=LOC_f-score_tok: 0.9552095808383234
dev_label=MISC_precision_tok: 0.908036454018227
dev_label=MISC_recall_tok: 0.8643533123028391
dev_label=MISC_f-score_tok: 0.8856565656565656
dev_label=ORG_precision_tok: 0.9506361323155216
dev_label=ORG_recall_tok: 0.892925430210325
dev_label=ORG_f-score_tok: 0.9208774956864678
dev_label=PER_precision_tok: 0.973203026481715
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9767441860465117
dev_precision_macro_tok: 0.9568166551026872
dev_recall_macro_tok: 0.9375973792568054
dev_f-score_macro_tok: 0.946913398356552
dev_precision_micro_tok: 0.9875978349752735
dev_recall_micro_tok: 0.9875978349752735
dev_f-score_micro_tok: 0.9875978349752735
dev_time: 12.964238166809082
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1864    0.4279    0.2596       645
           1     0.7914    0.5374    0.6401      2605

   micro avg     0.5157    0.5157    0.5157      3250
   macro avg     0.4889    0.4827    0.4499      3250
weighted avg     0.6713    0.5157    0.5646      3250

F1-macro sent:  0.4498944201625874
F1-micro sent:  0.5156923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9940    0.9982    0.9961     42759
         LOC     0.9582    0.9522    0.9552      2094
        MISC     0.9080    0.8644    0.8857      1268
         ORG     0.9506    0.8929    0.9209      2092
         PER     0.9732    0.9803    0.9767      3149

   micro avg     0.9876    0.9876    0.9876     51362
   macro avg     0.9568    0.9376    0.9469     51362
weighted avg     0.9874    0.9876    0.9874     51362

F1-macro tok:  0.946913398356552
F1-micro tok:  0.9875978349752735
**************************************************
Best epoch: 4
**************************************************

test0_cost_sum: 3587.159928560257
test0_cost_avg: 1.103741516480079
test0_count_sent: 3250.0
test0_total_correct_sent: 1772.0
test0_accuracy_sent: 0.5452307692307692
test0_count_tok: 51362.0
test0_total_correct_tok: 50483.0
test0_accuracy_tok: 0.9828861804446868
test0_label=0_precision_sent: 0.23454429572976418
test0_label=0_recall_sent: 0.5705426356589147
test0_label=0_f-score_sent: 0.3324299909665763
test0_label=1_precision_sent: 0.8352171326591314
test0_label=1_recall_sent: 0.5389635316698657
test0_label=1_f-score_sent: 0.6551563229118059
test0_precision_macro_sent: 0.5348807141944478
test0_recall_macro_sent: 0.5547530836643901
test0_f-score_macro_sent: 0.4937931569391911
test0_precision_micro_sent: 0.5452307692307692
test0_recall_micro_sent: 0.5452307692307692
test0_f-score_micro_sent: 0.5452307692307692
test0_label=O_precision_tok: 0.9946993578517221
test0_label=O_recall_tok: 0.9962347108211137
test0_label=O_f-score_tok: 0.9954664423256684
test0_label=LOC_precision_tok: 0.9292740046838408
test0_label=LOC_recall_tok: 0.9474689589302769
test0_label=LOC_f-score_tok: 0.9382832820997872
test0_label=MISC_precision_tok: 0.832824427480916
test0_label=MISC_recall_tok: 0.860410094637224
test0_label=MISC_f-score_tok: 0.8463925523661753
test0_label=ORG_precision_tok: 0.9280692266089778
test0_label=ORG_recall_tok: 0.8202676864244742
test0_label=ORG_f-score_tok: 0.8708449632073079
test0_label=PER_precision_tok: 0.9540548874498921
test0_label=PER_recall_tok: 0.9825341378215307
test0_label=PER_f-score_tok: 0.9680851063829786
test0_precision_macro_tok: 0.9277843808150699
test0_recall_macro_tok: 0.9213831177269238
test0_f-score_macro_tok: 0.9238144692763834
test0_precision_micro_tok: 0.9828861804446868
test0_recall_micro_tok: 0.9828861804446868
test0_f-score_micro_tok: 0.9828861804446868
test0_time: 13.04087519645691
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2345    0.5705    0.3324       645
           1     0.8352    0.5390    0.6552      2605

   micro avg     0.5452    0.5452    0.5452      3250
   macro avg     0.5349    0.5548    0.4938      3250
weighted avg     0.7160    0.5452    0.5911      3250

F1-macro sent:  0.4937931569391911
F1-micro sent:  0.5452307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9962    0.9955     42759
         LOC     0.9293    0.9475    0.9383      2094
        MISC     0.8328    0.8604    0.8464      1268
         ORG     0.9281    0.8203    0.8708      2092
         PER     0.9541    0.9825    0.9681      3149

   micro avg     0.9829    0.9829    0.9829     51362
   macro avg     0.9278    0.9214    0.9238     51362
weighted avg     0.9828    0.9829    0.9827     51362

F1-macro tok:  0.9238144692763834
F1-micro tok:  0.9828861804446868
**************************************************
test1_cost_sum: 4979.371787071228
test1_cost_avg: 1.4420422204086962
test1_count_sent: 3453.0
test1_total_correct_sent: 1931.0
test1_accuracy_sent: 0.559223863307269
test1_count_tok: 46435.0
test1_total_correct_tok: 45189.0
test1_accuracy_tok: 0.9731667922902982
test1_label=0_precision_sent: 0.2525494901019796
test1_label=0_recall_sent: 0.6040172166427547
test1_label=0_f-score_sent: 0.3561759729272419
test1_label=1_precision_sent: 0.845464725643897
test1_label=1_recall_sent: 0.5478955007256894
test1_label=1_f-score_sent: 0.6649053280493175
test1_precision_macro_sent: 0.5490071078729383
test1_recall_macro_sent: 0.575956358684222
test1_f-score_macro_sent: 0.5105406504882797
test1_precision_micro_sent: 0.559223863307269
test1_recall_micro_sent: 0.559223863307269
test1_f-score_micro_sent: 0.559223863307269
test1_label=O_precision_tok: 0.9945233478329228
test1_label=O_recall_tok: 0.9903452234950291
test1_label=O_f-score_tok: 0.9924298882133752
test1_label=LOC_precision_tok: 0.8551288283908605
test1_label=LOC_recall_tok: 0.9137662337662338
test1_label=LOC_f-score_tok: 0.8834756403817178
test1_label=MISC_precision_tok: 0.6946778711484594
test1_label=MISC_recall_tok: 0.8104575163398693
test1_label=MISC_f-score_tok: 0.7481146304675717
test1_label=ORG_precision_tok: 0.880900822867042
test1_label=ORG_recall_tok: 0.8149038461538461
test1_label=ORG_f-score_tok: 0.8466181061394381
test1_label=PER_precision_tok: 0.9516925246826516
test1_label=PER_recall_tok: 0.9733141002524341
test1_label=PER_f-score_tok: 0.9623818862542344
test1_precision_macro_tok: 0.8753846789843873
test1_recall_macro_tok: 0.9005573840014826
test1_f-score_macro_tok: 0.8866040302912674
test1_precision_micro_tok: 0.9731667922902982
test1_recall_micro_tok: 0.9731667922902982
test1_f-score_micro_tok: 0.9731667922902982
test1_time: 12.361395835876465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2525    0.6040    0.3562       697
           1     0.8455    0.5479    0.6649      2756

   micro avg     0.5592    0.5592    0.5592      3453
   macro avg     0.5490    0.5760    0.5105      3453
weighted avg     0.7258    0.5592    0.6026      3453

F1-macro sent:  0.5105406504882797
F1-micro sent:  0.559223863307269
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9903    0.9924     38323
         LOC     0.8551    0.9138    0.8835      1925
        MISC     0.6947    0.8105    0.7481       918
         ORG     0.8809    0.8149    0.8466      2496
         PER     0.9517    0.9733    0.9624      2773

   micro avg     0.9732    0.9732    0.9732     46435
   macro avg     0.8754    0.9006    0.8866     46435
weighted avg     0.9742    0.9732    0.9735     46435

F1-macro tok:  0.8866040302912674
F1-micro tok:  0.9731667922902982
**************************************************
