to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.1_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.1
sentence_composition: attention
random_seed: 100
{'N': 1, 'P': 2, 'O': 0}
{'N': 1, 'P': 2, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 21:29:03.852780: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 21:29:03.965326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 7.72GiB
2019-03-28 21:29:03.965368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 21:29:04.668527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 21:29:04.668590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 21:29:04.668607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 21:29:04.668809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 426695.056640625
train_cost_avg: 49.94090082404319
train_count_sent: 8544.0
train_total_correct_sent: 4259.0
train_accuracy_sent: 0.49847846441947563
train_count_tok: 163566.0
train_total_correct_tok: 126256.0
train_accuracy_tok: 0.7718963598791925
train_label=O_precision_sent: 0.21865889212827988
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.0762582613116421
train_label=N_precision_sent: 0.47875
train_label=N_recall_sent: 0.5785498489425982
train_label=N_f-score_sent: 0.5239398084815322
train_label=P_precision_sent: 0.5401094977386337
train_label=P_recall_sent: 0.6285318559556786
train_label=P_f-score_sent: 0.5809755473050825
train_precision_macro_sent: 0.41250612995563785
train_recall_macro_sent: 0.41775465696937636
train_f-score_macro_sent: 0.39372453903275223
train_precision_micro_sent: 0.49847846441947563
train_recall_micro_sent: 0.49847846441947563
train_f-score_micro_sent: 0.49847846441947563
train_label=O_precision_tok: 0.7992631022851957
train_label=O_recall_tok: 0.9490216893049289
train_label=O_f-score_tok: 0.8677282135937322
train_label=N_precision_tok: 0.505270202442697
train_label=N_recall_tok: 0.21264610618222785
train_label=N_f-score_tok: 0.2993210763665196
train_label=P_precision_tok: 0.5257970431459318
train_label=P_recall_tok: 0.20897789503137867
train_label=P_f-score_tok: 0.2990846681922197
train_precision_macro_tok: 0.6101101159579415
train_recall_macro_tok: 0.45688189683951186
train_f-score_macro_tok: 0.4887113193841572
train_precision_micro_tok: 0.7718963598791925
train_recall_micro_tok: 0.7718963598791925
train_f-score_micro_tok: 0.7718963598791926
train_time: 199.3537998199463
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2187    0.0462    0.0763      1624
           N     0.4788    0.5785    0.5239      3310
           P     0.5401    0.6285    0.5810      3610

   micro avg     0.4985    0.4985    0.4985      8544
   macro avg     0.4125    0.4178    0.3937      8544
weighted avg     0.4552    0.4985    0.4629      8544

F1-macro sent:  0.39372453903275223
F1-micro sent:  0.49847846441947563
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7993    0.9490    0.8677    124347
           N     0.5053    0.2126    0.2993     14202
           P     0.5258    0.2090    0.2991     25017

   micro avg     0.7719    0.7719    0.7719    163566
   macro avg     0.6101    0.4569    0.4887    163566
weighted avg     0.7319    0.7719    0.7314    163566

F1-macro tok:  0.4887113193841572
F1-micro tok:  0.7718963598791926
**************************************************
dev_cost_sum: 50623.144775390625
dev_cost_avg: 45.979241394541894
dev_count_sent: 1101.0
dev_total_correct_sent: 653.0
dev_accuracy_sent: 0.5930971843778383
dev_count_tok: 21274.0
dev_total_correct_tok: 17505.0
dev_accuracy_tok: 0.8228353859170818
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5975609756097561
dev_label=N_recall_sent: 0.6869158878504673
dev_label=N_f-score_sent: 0.6391304347826087
dev_label=P_precision_sent: 0.5894909688013136
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.6818613485280152
dev_precision_macro_sent: 0.39568398147035655
dev_recall_macro_sent: 0.498491482136342
dev_f-score_macro_sent: 0.44033059443687456
dev_precision_micro_sent: 0.5930971843778383
dev_recall_micro_sent: 0.5930971843778383
dev_f-score_micro_sent: 0.5930971843778383
dev_label=O_precision_tok: 0.8372118020099962
dev_label=O_recall_tok: 0.961308238198087
dev_label=O_f-score_tok: 0.8949787429621968
dev_label=N_precision_tok: 0.6800341296928327
dev_label=N_recall_tok: 0.4291868605277329
dev_label=N_f-score_tok: 0.5262462859029383
dev_label=P_precision_tok: 0.7558528428093646
dev_label=P_recall_tok: 0.3518057285180573
dev_label=P_f-score_tok: 0.4801359677076695
dev_precision_macro_tok: 0.7576995915040645
dev_recall_macro_tok: 0.5807669424146258
dev_f-score_macro_tok: 0.6337869988576016
dev_precision_micro_tok: 0.8228353859170818
dev_recall_micro_tok: 0.8228353859170818
dev_f-score_micro_tok: 0.8228353859170818
dev_time: 12.297981262207031
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5976    0.6869    0.6391       428
           P     0.5895    0.8086    0.6819       444

   micro avg     0.5931    0.5931    0.5931      1101
   macro avg     0.3957    0.4985    0.4403      1101
weighted avg     0.4700    0.5931    0.5234      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.44033059443687456
F1-micro sent:  0.5930971843778383
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8372    0.9613    0.8950     16205
           N     0.6800    0.4292    0.5262      1857
           P     0.7559    0.3518    0.4801      3212

   micro avg     0.8228    0.8228    0.8228     21274
   macro avg     0.7577    0.5808    0.6338     21274
weighted avg     0.8112    0.8228    0.8002     21274

F1-macro tok:  0.6337869988576016
F1-micro tok:  0.8228353859170818
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 377816.9072265625
train_cost_avg: 44.22014363606771
train_count_sent: 8544.0
train_total_correct_sent: 4814.0
train_accuracy_sent: 0.5634363295880149
train_count_tok: 163566.0
train_total_correct_tok: 132504.0
train_accuracy_tok: 0.8100950075199003
train_label=O_precision_sent: 0.3076923076923077
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004886988393402566
train_label=N_precision_sent: 0.530382939692731
train_label=N_recall_sent: 0.6987915407854985
train_label=N_f-score_sent: 0.6030504497457958
train_label=P_precision_sent: 0.5988009592326139
train_label=P_recall_sent: 0.6916897506925208
train_label=P_f-score_sent: 0.6419023136246786
train_precision_macro_sent: 0.47895873553921753
train_recall_macro_sent: 0.46431478188840386
train_f-score_macro_sent: 0.416613250587959
train_precision_micro_sent: 0.5634363295880149
train_recall_micro_sent: 0.5634363295880149
train_f-score_micro_sent: 0.5634363295880149
train_label=O_precision_tok: 0.8335238740455322
train_label=O_recall_tok: 0.9498580584975914
train_label=O_f-score_tok: 0.8878965904776941
train_label=N_precision_tok: 0.6411477695167286
train_label=N_recall_tok: 0.38860723841712436
train_label=N_f-score_tok: 0.48391056554142925
train_label=P_precision_tok: 0.669357272178636
train_label=P_recall_tok: 0.35467881840348564
train_label=P_f-score_tok: 0.46366890497217356
train_precision_macro_tok: 0.7146763052469657
train_recall_macro_tok: 0.5643813717727338
train_f-score_macro_tok: 0.6118253536637657
train_precision_micro_tok: 0.8100950075199003
train_recall_micro_tok: 0.8100950075199003
train_f-score_micro_tok: 0.8100950075199004
train_time: 197.84538173675537
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3077    0.0025    0.0049      1624
           N     0.5304    0.6988    0.6031      3310
           P     0.5988    0.6917    0.6419      3610

   micro avg     0.5634    0.5634    0.5634      8544
   macro avg     0.4790    0.4643    0.4166      8544
weighted avg     0.5170    0.5634    0.5058      8544

F1-macro sent:  0.416613250587959
F1-micro sent:  0.5634363295880149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8335    0.9499    0.8879    124347
           N     0.6411    0.3886    0.4839     14202
           P     0.6694    0.3547    0.4637     25017

   micro avg     0.8101    0.8101    0.8101    163566
   macro avg     0.7147    0.5644    0.6118    163566
weighted avg     0.7917    0.8101    0.7879    163566

F1-macro tok:  0.6118253536637657
F1-micro tok:  0.8100950075199004
**************************************************
dev_cost_sum: 48891.63781738281
dev_cost_avg: 44.406573857750054
dev_count_sent: 1101.0
dev_total_correct_sent: 665.0
dev_accuracy_sent: 0.6039963669391463
dev_count_tok: 21274.0
dev_total_correct_tok: 17878.0
dev_accuracy_tok: 0.8403685249600451
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5351724137931034
dev_label=N_recall_sent: 0.9065420560747663
dev_label=N_f-score_sent: 0.6730268863833478
dev_label=P_precision_sent: 0.7367021276595744
dev_label=P_recall_sent: 0.6238738738738738
dev_label=P_f-score_sent: 0.6756097560975609
dev_precision_macro_sent: 0.4239581804842259
dev_recall_macro_sent: 0.5101386433162134
dev_f-score_macro_sent: 0.4495455474936363
dev_precision_micro_sent: 0.6039963669391463
dev_recall_micro_sent: 0.6039963669391463
dev_f-score_micro_sent: 0.6039963669391463
dev_label=O_precision_tok: 0.8516663036375517
dev_label=O_recall_tok: 0.9651342178340019
dev_label=O_f-score_tok: 0.9048569527611443
dev_label=N_precision_tok: 0.7111650485436893
dev_label=N_recall_tok: 0.47334410339256866
dev_label=N_f-score_tok: 0.5683802133850631
dev_label=P_precision_tok: 0.8118279569892473
dev_label=P_recall_tok: 0.42310087173100874
dev_label=P_f-score_tok: 0.556283258288989
dev_precision_macro_tok: 0.7915531030568296
dev_recall_macro_tok: 0.6205263976525265
dev_f-score_macro_tok: 0.6765068081450654
dev_precision_micro_tok: 0.8403685249600451
dev_recall_micro_tok: 0.8403685249600451
dev_f-score_micro_tok: 0.840368524960045
dev_time: 12.012431144714355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5352    0.9065    0.6730       428
           P     0.7367    0.6239    0.6756       444

   micro avg     0.6040    0.6040    0.6040      1101
   macro avg     0.4240    0.5101    0.4495      1101
weighted avg     0.5051    0.6040    0.5341      1101

F1-macro sent:  0.4495455474936363
F1-micro sent:  0.6039963669391463
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8517    0.9651    0.9049     16205
           N     0.7112    0.4733    0.5684      1857
           P     0.8118    0.4231    0.5563      3212

   micro avg     0.8404    0.8404    0.8404     21274
   macro avg     0.7916    0.6205    0.6765     21274
weighted avg     0.8334    0.8404    0.8229     21274

F1-macro tok:  0.6765068081450654
F1-micro tok:  0.840368524960045
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368106.1495361328
train_cost_avg: 43.08358491761854
train_count_sent: 8544.0
train_total_correct_sent: 5094.0
train_accuracy_sent: 0.5962078651685393
train_count_tok: 163566.0
train_total_correct_tok: 135667.0
train_accuracy_tok: 0.8294327672010076
train_label=O_precision_sent: 0.13333333333333333
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004836759371221282
train_label=N_precision_sent: 0.5631974493281713
train_label=N_recall_sent: 0.7471299093655589
train_label=N_f-score_sent: 0.6422542526944552
train_label=P_precision_sent: 0.6347319912684938
train_label=P_recall_sent: 0.7249307479224377
train_label=P_f-score_sent: 0.6768395189447821
train_precision_macro_sent: 0.4437542579766662
train_recall_macro_sent: 0.49150790382506293
train_f-score_macro_sent: 0.4413101770034862
train_precision_micro_sent: 0.5962078651685393
train_recall_micro_sent: 0.5962078651685393
train_f-score_micro_sent: 0.5962078651685393
train_label=O_precision_tok: 0.8496962837741039
train_label=O_recall_tok: 0.9539514423347568
train_label=O_f-score_tok: 0.8988107641190979
train_label=N_precision_tok: 0.6769432600852738
train_label=N_recall_tok: 0.43599493029150826
train_label=N_f-score_tok: 0.5303867403314917
train_label=P_precision_tok: 0.7326358420519743
train_label=P_recall_tok: 0.43386497181916295
train_label=P_f-score_tok: 0.5449889536051415
train_precision_macro_tok: 0.7530917953037841
train_recall_macro_tok: 0.6079371148151427
train_f-score_macro_tok: 0.6580621526852437
train_precision_micro_tok: 0.8294327672010076
train_recall_micro_tok: 0.8294327672010076
train_f-score_micro_tok: 0.8294327672010076
train_time: 197.8161482810974
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1333    0.0025    0.0048      1624
           N     0.5632    0.7471    0.6423      3310
           P     0.6347    0.7249    0.6768      3610

   micro avg     0.5962    0.5962    0.5962      8544
   macro avg     0.4438    0.4915    0.4413      8544
weighted avg     0.5117    0.5962    0.5357      8544

F1-macro sent:  0.4413101770034862
F1-micro sent:  0.5962078651685393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8497    0.9540    0.8988    124347
           N     0.6769    0.4360    0.5304     14202
           P     0.7326    0.4339    0.5450     25017

   micro avg     0.8294    0.8294    0.8294    163566
   macro avg     0.7531    0.6079    0.6581    163566
weighted avg     0.8168    0.8294    0.8127    163566

F1-macro tok:  0.6580621526852437
F1-micro tok:  0.8294327672010076
**************************************************
dev_cost_sum: 48223.09899902344
dev_cost_avg: 43.7993633051984
dev_count_sent: 1101.0
dev_total_correct_sent: 584.0
dev_accuracy_sent: 0.5304268846503178
dev_count_tok: 21274.0
dev_total_correct_tok: 18201.0
dev_accuracy_tok: 0.8555513772680267
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7562189054726368
dev_label=N_recall_sent: 0.35514018691588783
dev_label=N_f-score_sent: 0.48330683624801274
dev_label=P_precision_sent: 0.48
dev_label=P_recall_sent: 0.972972972972973
dev_label=P_f-score_sent: 0.6428571428571428
dev_precision_macro_sent: 0.412072968490879
dev_recall_macro_sent: 0.4427043866296203
dev_f-score_macro_sent: 0.3753879930350519
dev_precision_micro_sent: 0.5304268846503178
dev_recall_micro_sent: 0.5304268846503178
dev_f-score_micro_sent: 0.5304268846503178
dev_label=O_precision_tok: 0.8709641255605381
dev_label=O_recall_tok: 0.9588398642394322
dev_label=O_f-score_tok: 0.9127918930826846
dev_label=N_precision_tok: 0.7733598409542743
dev_label=N_recall_tok: 0.4189553042541734
dev_label=N_f-score_tok: 0.5434858539993014
dev_label=P_precision_tok: 0.7763591433278418
dev_label=P_recall_tok: 0.5868617683686177
dev_label=P_f-score_tok: 0.6684397163120568
dev_precision_macro_tok: 0.8068943699475515
dev_recall_macro_tok: 0.6548856456207411
dev_f-score_macro_tok: 0.7082391544646809
dev_precision_micro_tok: 0.8555513772680267
dev_recall_micro_tok: 0.8555513772680267
dev_f-score_micro_tok: 0.8555513772680267
dev_time: 11.913811922073364
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7562    0.3551    0.4833       428
           P     0.4800    0.9730    0.6429       444

   micro avg     0.5304    0.5304    0.5304      1101
   macro avg     0.4121    0.4427    0.3754      1101
weighted avg     0.4875    0.5304    0.4471      1101

F1-macro sent:  0.3753879930350519
F1-micro sent:  0.5304268846503178
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8710    0.9588    0.9128     16205
           N     0.7734    0.4190    0.5435      1857
           P     0.7764    0.5869    0.6684      3212

   micro avg     0.8556    0.8556    0.8556     21274
   macro avg     0.8069    0.6549    0.7082     21274
weighted avg     0.8482    0.8556    0.8437     21274

F1-macro tok:  0.7082391544646809
F1-micro tok:  0.8555513772680267
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361559.18591308594
train_cost_avg: 42.31732044862897
train_count_sent: 8544.0
train_total_correct_sent: 5102.0
train_accuracy_sent: 0.5971441947565543
train_count_tok: 163566.0
train_total_correct_tok: 137745.0
train_accuracy_tok: 0.8421371189611533
train_label=O_precision_sent: 0.47619047619047616
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.0121580547112462
train_label=N_precision_sent: 0.5706443914081145
train_label=N_recall_sent: 0.722356495468278
train_label=N_f-score_sent: 0.6376000000000001
train_label=P_precision_sent: 0.6233556427417494
train_label=P_recall_sent: 0.7481994459833795
train_label=P_f-score_sent: 0.680095681732343
train_precision_macro_sent: 0.5567301701134467
train_recall_macro_sent: 0.4922378589732126
train_f-score_macro_sent: 0.4432845788145297
train_precision_micro_sent: 0.5971441947565543
train_recall_micro_sent: 0.5971441947565543
train_f-score_micro_sent: 0.5971441947565543
train_label=O_precision_tok: 0.8605786971716338
train_label=O_recall_tok: 0.9565007599700838
train_label=O_f-score_tok: 0.9060079069448571
train_label=N_precision_tok: 0.6961134567500271
train_label=N_recall_tok: 0.45275313336149836
train_label=N_f-score_tok: 0.5486582192073041
train_label=P_precision_tok: 0.767708721002357
train_label=P_recall_tok: 0.4947435743694288
train_label=P_f-score_tok: 0.6017161331097012
train_precision_macro_tok: 0.7748002916413393
train_recall_macro_tok: 0.6346658225670037
train_f-score_macro_tok: 0.6854607530872875
train_precision_micro_tok: 0.8421371189611533
train_recall_micro_tok: 0.8421371189611533
train_f-score_micro_tok: 0.8421371189611533
train_time: 199.1904261112213
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4762    0.0062    0.0122      1624
           N     0.5706    0.7224    0.6376      3310
           P     0.6234    0.7482    0.6801      3610

   micro avg     0.5971    0.5971    0.5971      8544
   macro avg     0.5567    0.4922    0.4433      8544
weighted avg     0.5750    0.5971    0.5367      8544

F1-macro sent:  0.4432845788145297
F1-micro sent:  0.5971441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8606    0.9565    0.9060    124347
           N     0.6961    0.4528    0.5487     14202
           P     0.7677    0.4947    0.6017     25017

   micro avg     0.8421    0.8421    0.8421    163566
   macro avg     0.7748    0.6347    0.6855    163566
weighted avg     0.8321    0.8421    0.8284    163566

F1-macro tok:  0.6854607530872875
F1-micro tok:  0.8421371189611533
**************************************************
dev_cost_sum: 47592.14733886719
dev_cost_avg: 43.22629186091479
dev_count_sent: 1101.0
dev_total_correct_sent: 634.0
dev_accuracy_sent: 0.5758401453224341
dev_count_tok: 21274.0
dev_total_correct_tok: 18357.0
dev_accuracy_tok: 0.8628842718811695
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6695906432748538
dev_label=N_recall_sent: 0.5350467289719626
dev_label=N_f-score_sent: 0.5948051948051948
dev_label=P_precision_sent: 0.5335968379446641
dev_label=P_recall_sent: 0.9121621621621622
dev_label=P_f-score_sent: 0.6733167082294264
dev_precision_macro_sent: 0.40106249373983927
dev_recall_macro_sent: 0.4824029637113749
dev_f-score_macro_sent: 0.42270730101154036
dev_precision_micro_sent: 0.5758401453224341
dev_recall_micro_sent: 0.5758401453224341
dev_f-score_micro_sent: 0.5758401453224341
dev_label=O_precision_tok: 0.869589222614841
dev_label=O_recall_tok: 0.9719222462203023
dev_label=O_f-score_tok: 0.9179124049305009
dev_label=N_precision_tok: 0.8299319727891157
dev_label=N_recall_tok: 0.39418416801292405
dev_label=N_f-score_tok: 0.5345016429353778
dev_label=P_precision_tok: 0.8223684210526315
dev_label=P_recall_tok: 0.5837484433374844
dev_label=P_f-score_tok: 0.6828113619810634
dev_precision_macro_tok: 0.8406298721521961
dev_recall_macro_tok: 0.6499516191902369
dev_f-score_macro_tok: 0.7117418032823141
dev_precision_micro_tok: 0.8628842718811695
dev_recall_micro_tok: 0.8628842718811695
dev_f-score_micro_tok: 0.8628842718811695
dev_time: 11.914477825164795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6696    0.5350    0.5948       428
           P     0.5336    0.9122    0.6733       444

   micro avg     0.5758    0.5758    0.5758      1101
   macro avg     0.4011    0.4824    0.4227      1101
weighted avg     0.4755    0.5758    0.5028      1101

F1-macro sent:  0.42270730101154036
F1-micro sent:  0.5758401453224341
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8696    0.9719    0.9179     16205
           N     0.8299    0.3942    0.5345      1857
           P     0.8224    0.5837    0.6828      3212

   micro avg     0.8629    0.8629    0.8629     21274
   macro avg     0.8406    0.6500    0.7117     21274
weighted avg     0.8590    0.8629    0.8489     21274

F1-macro tok:  0.7117418032823141
F1-micro tok:  0.8628842718811695
**************************************************
Best epoch: 1
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355728.630859375
train_cost_avg: 41.634905297211496
train_count_sent: 8544.0
train_total_correct_sent: 5218.0
train_accuracy_sent: 0.6107209737827716
train_count_tok: 163566.0
train_total_correct_tok: 139241.0
train_accuracy_tok: 0.8512832740300551
train_label=O_precision_sent: 0.30434782608695654
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008500303582270795
train_label=N_precision_sent: 0.5751604032997251
train_label=N_recall_sent: 0.7583081570996979
train_label=N_f-score_sent: 0.6541568934063071
train_label=P_precision_sent: 0.6497474140004811
train_label=P_recall_sent: 0.7481994459833795
train_label=P_f-score_sent: 0.6955066306167116
train_precision_macro_sent: 0.5097518811290542
train_recall_macro_sent: 0.5036059826368878
train_f-score_macro_sent: 0.4527212758684298
train_precision_micro_sent: 0.6107209737827716
train_recall_micro_sent: 0.6107209737827716
train_f-score_micro_sent: 0.6107209737827716
train_label=O_precision_tok: 0.8674178853991849
train_label=O_recall_tok: 0.9601679171994499
train_label=O_f-score_tok: 0.911439367914806
train_label=N_precision_tok: 0.7151521600340498
train_label=N_recall_tok: 0.4732432051823687
train_label=N_f-score_tok: 0.5695762711864406
train_label=P_precision_tok: 0.7943116490166414
train_label=P_recall_tok: 0.5246832154135188
train_label=P_f-score_tok: 0.6319387607722304
train_precision_macro_tok: 0.7922938981499587
train_recall_macro_tok: 0.6526981125984458
train_f-score_macro_tok: 0.7043181332911589
train_precision_micro_tok: 0.8512832740300551
train_recall_micro_tok: 0.8512832740300551
train_f-score_micro_tok: 0.8512832740300551
train_time: 199.0019567012787
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3043    0.0043    0.0085      1624
           N     0.5752    0.7583    0.6542      3310
           P     0.6497    0.7482    0.6955      3610

   micro avg     0.6107    0.6107    0.6107      8544
   macro avg     0.5098    0.5036    0.4527      8544
weighted avg     0.5552    0.6107    0.5489      8544

F1-macro sent:  0.4527212758684298
F1-micro sent:  0.6107209737827716
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8674    0.9602    0.9114    124347
           N     0.7152    0.4732    0.5696     14202
           P     0.7943    0.5247    0.6319     25017

   micro avg     0.8513    0.8513    0.8513    163566
   macro avg     0.7923    0.6527    0.7043    163566
weighted avg     0.8430    0.8513    0.8390    163566

F1-macro tok:  0.7043181332911589
F1-micro tok:  0.8512832740300551
**************************************************
dev_cost_sum: 46698.18981933594
dev_cost_avg: 42.414341343629374
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18504.0
dev_accuracy_tok: 0.8697941148820156
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02553191489361702
dev_label=N_precision_sent: 0.612280701754386
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.6993987975951904
dev_label=P_precision_sent: 0.659047619047619
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7141382868937048
dev_precision_macro_sent: 0.5904427736006683
dev_recall_macro_sent: 0.5359334255693885
dev_f-score_macro_sent: 0.47968966646083744
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8828182383185491
dev_label=O_recall_tok: 0.9642085775995063
dev_label=O_f-score_tok: 0.9217201510146296
dev_label=N_precision_tok: 0.7152682255845942
dev_label=N_recall_tok: 0.5600430802369413
dev_label=N_f-score_tok: 0.6282090003020235
dev_label=P_precision_tok: 0.867043847241867
dev_label=P_recall_tok: 0.5725404732254047
dev_label=P_f-score_tok: 0.6896681042565159
dev_precision_macro_tok: 0.8217101037150035
dev_recall_macro_tok: 0.6989307103539507
dev_f-score_macro_tok: 0.7465324185243897
dev_precision_micro_tok: 0.8697941148820156
dev_recall_micro_tok: 0.8697941148820156
dev_f-score_micro_tok: 0.8697941148820156
dev_time: 11.901323318481445
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0131    0.0255       229
           N     0.6123    0.8154    0.6994       428
           P     0.6590    0.7793    0.7141       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.5904    0.5359    0.4797      1101
weighted avg     0.6078    0.6340    0.5652      1101

F1-macro sent:  0.47968966646083744
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8828    0.9642    0.9217     16205
           N     0.7153    0.5600    0.6282      1857
           P     0.8670    0.5725    0.6897      3212

   micro avg     0.8698    0.8698    0.8698     21274
   macro avg     0.8217    0.6989    0.7465     21274
weighted avg     0.8658    0.8698    0.8611     21274

F1-macro tok:  0.7465324185243897
F1-micro tok:  0.8697941148820156
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350729.3709716797
train_cost_avg: 41.0497859283333
train_count_sent: 8544.0
train_total_correct_sent: 5260.0
train_accuracy_sent: 0.6156367041198502
train_count_tok: 163566.0
train_total_correct_tok: 140320.0
train_accuracy_tok: 0.8578799995109008
train_label=O_precision_sent: 0.37142857142857144
train_label=O_recall_sent: 0.01600985221674877
train_label=O_f-score_sent: 0.030696576151121608
train_label=N_precision_sent: 0.5804822043628014
train_label=N_recall_sent: 0.7637462235649547
train_label=N_f-score_sent: 0.6596216568819309
train_label=P_precision_sent: 0.6569555717407137
train_label=P_recall_sent: 0.749584487534626
train_label=P_f-score_sent: 0.7002199508345193
train_precision_macro_sent: 0.5362887825106956
train_recall_macro_sent: 0.5097801877721099
train_f-score_macro_sent: 0.46351272795585724
train_precision_micro_sent: 0.6156367041198502
train_recall_micro_sent: 0.6156367041198502
train_f-score_micro_sent: 0.6156367041198502
train_label=O_precision_tok: 0.8740155752988922
train_label=O_recall_tok: 0.9612294627132139
train_label=O_f-score_tok: 0.9155502447319439
train_label=N_precision_tok: 0.7209964412811388
train_label=N_recall_tok: 0.49929587382058865
train_label=N_f-score_tok: 0.5900070724300037
train_label=P_precision_tok: 0.8071983977379831
train_label=P_recall_tok: 0.5477475316784587
train_label=P_f-score_tok: 0.6526325816207463
train_precision_macro_tok: 0.8007368047726713
train_recall_macro_tok: 0.669424289404087
train_f-score_macro_tok: 0.7193966329275646
train_precision_micro_tok: 0.8578799995109008
train_recall_micro_tok: 0.8578799995109008
train_f-score_micro_tok: 0.8578799995109008
train_time: 198.63966131210327
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3714    0.0160    0.0307      1624
           N     0.5805    0.7637    0.6596      3310
           P     0.6570    0.7496    0.7002      3610

   micro avg     0.6156    0.6156    0.6156      8544
   macro avg     0.5363    0.5098    0.4635      8544
weighted avg     0.5731    0.6156    0.5572      8544

F1-macro sent:  0.46351272795585724
F1-micro sent:  0.6156367041198502
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8740    0.9612    0.9156    124347
           N     0.7210    0.4993    0.5900     14202
           P     0.8072    0.5477    0.6526     25017

   micro avg     0.8579    0.8579    0.8579    163566
   macro avg     0.8007    0.6694    0.7194    163566
weighted avg     0.8505    0.8579    0.8471    163566

F1-macro tok:  0.7193966329275646
F1-micro tok:  0.8578799995109008
**************************************************
dev_cost_sum: 46233.856994628906
dev_cost_avg: 41.992603991488565
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18606.0
dev_accuracy_tok: 0.8745886998213782
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6076388888888888
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.6972111553784861
dev_label=P_precision_sent: 0.6552380952380953
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7100103199174407
dev_precision_macro_sent: 0.4209589947089947
dev_recall_macro_sent: 0.5308439280401896
dev_f-score_macro_sent: 0.4690738250986423
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8794389402204164
dev_label=O_recall_tok: 0.9750077136686208
dev_label=O_f-score_tok: 0.9247607620496913
dev_label=N_precision_tok: 0.7807443365695793
dev_label=N_recall_tok: 0.5196553581044696
dev_label=N_f-score_tok: 0.6239896540575492
dev_label=P_precision_tok: 0.8885135135135135
dev_label=P_recall_tok: 0.5731631382316313
dev_label=P_f-score_tok: 0.6968205904617714
dev_precision_macro_tok: 0.8495655967678365
dev_recall_macro_tok: 0.6892754033349072
dev_f-score_macro_tok: 0.7485236688563374
dev_precision_micro_tok: 0.8745886998213782
dev_recall_micro_tok: 0.8745886998213782
dev_f-score_micro_tok: 0.8745886998213782
dev_time: 12.034920930862427
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6076    0.8178    0.6972       428
           P     0.6552    0.7748    0.7100       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4210    0.5308    0.4691      1101
weighted avg     0.5004    0.6303    0.5574      1101

F1-macro sent:  0.4690738250986423
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8794    0.9750    0.9248     16205
           N     0.7807    0.5197    0.6240      1857
           P     0.8885    0.5732    0.6968      3212

   micro avg     0.8746    0.8746    0.8746     21274
   macro avg     0.8496    0.6893    0.7485     21274
weighted avg     0.8722    0.8746    0.8641     21274

F1-macro tok:  0.7485236688563374
F1-micro tok:  0.8745886998213782
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346735.34729003906
train_cost_avg: 40.582320609789214
train_count_sent: 8544.0
train_total_correct_sent: 5317.0
train_accuracy_sent: 0.622308052434457
train_count_tok: 163566.0
train_total_correct_tok: 141003.0
train_accuracy_tok: 0.8620556839440959
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015634395670475046
train_label=N_precision_sent: 0.5907834101382489
train_label=N_recall_sent: 0.7746223564954683
train_label=N_f-score_sent: 0.670326797385621
train_label=P_precision_sent: 0.6578631452581032
train_label=P_recall_sent: 0.7590027700831025
train_label=P_f-score_sent: 0.704823151125402
train_precision_macro_sent: 0.5273266295765618
train_recall_macro_sent: 0.5138766842289817
train_f-score_macro_sent: 0.46359478139383264
train_precision_micro_sent: 0.622308052434457
train_recall_micro_sent: 0.622308052434457
train_f-score_micro_sent: 0.622308052434457
train_label=O_precision_tok: 0.8770263044162998
train_label=O_recall_tok: 0.9628619910411992
train_label=O_f-score_tok: 0.9179419160942099
train_label=N_precision_tok: 0.7282915993537964
train_label=N_recall_tok: 0.5078862132094071
train_label=N_f-score_tok: 0.5984402223512817
train_label=P_precision_tok: 0.8201224846894138
train_label=P_recall_tok: 0.562057800695527
train_label=P_f-score_tok: 0.6669987192258431
train_precision_macro_tok: 0.8084801294865033
train_recall_macro_tok: 0.6776020016487111
train_f-score_macro_tok: 0.7277936192237782
train_precision_micro_tok: 0.8620556839440959
train_recall_micro_tok: 0.8620556839440959
train_f-score_micro_tok: 0.8620556839440959
train_time: 198.10858726501465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0080    0.0156      1624
           N     0.5908    0.7746    0.6703      3310
           P     0.6579    0.7590    0.7048      3610

   micro avg     0.6223    0.6223    0.6223      8544
   macro avg     0.5273    0.5139    0.4636      8544
weighted avg     0.5702    0.6223    0.5605      8544

F1-macro sent:  0.46359478139383264
F1-micro sent:  0.622308052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8770    0.9629    0.9179    124347
           N     0.7283    0.5079    0.5984     14202
           P     0.8201    0.5621    0.6670     25017

   micro avg     0.8621    0.8621    0.8621    163566
   macro avg     0.8085    0.6776    0.7278    163566
weighted avg     0.8554    0.8621    0.8518    163566

F1-macro tok:  0.7277936192237782
F1-micro tok:  0.8620556839440959
**************************************************
dev_cost_sum: 45877.56872558594
dev_cost_avg: 41.668999750759255
dev_count_sent: 1101.0
dev_total_correct_sent: 684.0
dev_accuracy_sent: 0.6212534059945504
dev_count_tok: 21274.0
dev_total_correct_tok: 18683.0
dev_accuracy_tok: 0.87820814139325
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6570155902004454
dev_label=N_recall_sent: 0.6892523364485982
dev_label=N_f-score_sent: 0.6727480045610035
dev_label=P_precision_sent: 0.5965996908809892
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7076076993583867
dev_precision_macro_sent: 0.6178717603604782
dev_recall_macro_sent: 0.5239073808330634
dev_f-score_macro_sent: 0.4686655765201386
dev_precision_micro_sent: 0.6212534059945504
dev_recall_micro_sent: 0.6212534059945504
dev_f-score_micro_sent: 0.6212534059945504
dev_label=O_precision_tok: 0.8850839274687027
dev_label=O_recall_tok: 0.9729095958037642
dev_label=O_f-score_tok: 0.9269210418013993
dev_label=N_precision_tok: 0.8143872113676732
dev_label=N_recall_tok: 0.4938072159396877
dev_label=N_f-score_tok: 0.6148172980221255
dev_label=P_precision_tok: 0.8565310492505354
dev_label=P_recall_tok: 0.6226650062266501
dev_label=P_f-score_tok: 0.721110510185686
dev_precision_macro_tok: 0.8520007293623038
dev_recall_macro_tok: 0.6964606059900339
dev_f-score_macro_tok: 0.7542829500030703
dev_precision_micro_tok: 0.87820814139325
dev_recall_micro_tok: 0.87820814139325
dev_f-score_micro_tok: 0.87820814139325
dev_time: 11.64193081855774
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6570    0.6893    0.6727       428
           P     0.5966    0.8694    0.7076       444

   micro avg     0.6213    0.6213    0.6213      1101
   macro avg     0.6179    0.5239    0.4687      1101
weighted avg     0.6208    0.6213    0.5522      1101

F1-macro sent:  0.4686655765201386
F1-micro sent:  0.6212534059945504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8851    0.9729    0.9269     16205
           N     0.8144    0.4938    0.6148      1857
           P     0.8565    0.6227    0.7211      3212

   micro avg     0.8782    0.8782    0.8782     21274
   macro avg     0.8520    0.6965    0.7543     21274
weighted avg     0.8746    0.8782    0.8686     21274

F1-macro tok:  0.7542829500030703
F1-micro tok:  0.87820814139325
**************************************************
Best epoch: 4
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 343021.54095458984
train_cost_avg: 40.14765226528439
train_count_sent: 8544.0
train_total_correct_sent: 5380.0
train_accuracy_sent: 0.6296816479400749
train_count_tok: 163566.0
train_total_correct_tok: 141687.0
train_accuracy_tok: 0.8662374821173104
train_label=O_precision_sent: 0.3815789473684211
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.03411764705882352
train_label=N_precision_sent: 0.5975046210720887
train_label=N_recall_sent: 0.7812688821752266
train_label=N_f-score_sent: 0.6771406127258445
train_label=P_precision_sent: 0.6678743961352657
train_label=P_recall_sent: 0.7659279778393352
train_label=P_f-score_sent: 0.7135483870967742
train_precision_macro_sent: 0.5489859881919251
train_recall_macro_sent: 0.5216846676239015
train_f-score_macro_sent: 0.4749355489604807
train_precision_micro_sent: 0.6296816479400749
train_recall_micro_sent: 0.6296816479400749
train_f-score_micro_sent: 0.6296816479400749
train_label=O_precision_tok: 0.8804317497613628
train_label=O_recall_tok: 0.964285427071019
train_label=O_f-score_tok: 0.9204527571899577
train_label=N_precision_tok: 0.7397666600751434
train_label=N_recall_tok: 0.5268272074355724
train_label=N_f-score_tok: 0.6153972692877118
train_label=P_precision_tok: 0.8283512918549415
train_label=P_recall_tok: 0.5715713314945837
train_label=P_f-score_tok: 0.6764114572246269
train_precision_macro_tok: 0.8161832338971493
train_recall_macro_tok: 0.6875613220003918
train_f-score_macro_tok: 0.7374204945674321
train_precision_micro_tok: 0.8662374821173104
train_recall_micro_tok: 0.8662374821173104
train_f-score_micro_tok: 0.8662374821173104
train_time: 199.24053192138672
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3816    0.0179    0.0341      1624
           N     0.5975    0.7813    0.6771      3310
           P     0.6679    0.7659    0.7135      3610

   micro avg     0.6297    0.6297    0.6297      8544
   macro avg     0.5490    0.5217    0.4749      8544
weighted avg     0.5862    0.6297    0.5703      8544

F1-macro sent:  0.4749355489604807
F1-micro sent:  0.6296816479400749
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9643    0.9205    124347
           N     0.7398    0.5268    0.6154     14202
           P     0.8284    0.5716    0.6764     25017

   micro avg     0.8662    0.8662    0.8662    163566
   macro avg     0.8162    0.6876    0.7374    163566
weighted avg     0.8603    0.8662    0.8566    163566

F1-macro tok:  0.7374204945674321
F1-micro tok:  0.8662374821173104
**************************************************
dev_cost_sum: 45388.79626464844
dev_cost_avg: 41.22506472720112
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18780.0
dev_accuracy_tok: 0.8827676976591144
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5569620253164557
dev_label=N_recall_sent: 0.9252336448598131
dev_label=N_f-score_sent: 0.6953467954345918
dev_label=P_precision_sent: 0.7461538461538462
dev_label=P_recall_sent: 0.6554054054054054
dev_label=P_f-score_sent: 0.6978417266187051
dev_precision_macro_sent: 0.43437195715676724
dev_recall_macro_sent: 0.5268796834217394
dev_f-score_macro_sent: 0.4643961740177656
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8872829131652661
dev_label=O_recall_tok: 0.9773526689293428
dev_label=O_f-score_tok: 0.9301424166789017
dev_label=N_precision_tok: 0.7871674491392802
dev_label=N_recall_tok: 0.5417339795368874
dev_label=N_f-score_tok: 0.641786283891547
dev_label=P_precision_tok: 0.902143522833178
dev_label=P_recall_tok: 0.6027397260273972
dev_label=P_f-score_tok: 0.7226577081000373
dev_precision_macro_tok: 0.8588646283792413
dev_recall_macro_tok: 0.7072754581645425
dev_f-score_macro_tok: 0.7648621362234954
dev_precision_micro_tok: 0.8827676976591144
dev_recall_micro_tok: 0.8827676976591144
dev_f-score_micro_tok: 0.8827676976591146
dev_time: 11.971495389938354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5570    0.9252    0.6953       428
           P     0.7462    0.6554    0.6978       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4344    0.5269    0.4644      1101
weighted avg     0.5174    0.6240    0.5517      1101

F1-macro sent:  0.4643961740177656
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8873    0.9774    0.9301     16205
           N     0.7872    0.5417    0.6418      1857
           P     0.9021    0.6027    0.7227      3212

   micro avg     0.8828    0.8828    0.8828     21274
   macro avg     0.8589    0.7073    0.7649     21274
weighted avg     0.8808    0.8828    0.8736     21274

F1-macro tok:  0.7648621362234954
F1-micro tok:  0.8827676976591146
**************************************************
Best epoch: 4
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339438.64404296875
train_cost_avg: 39.7283057166396
train_count_sent: 8544.0
train_total_correct_sent: 5425.0
train_accuracy_sent: 0.6349485018726592
train_count_tok: 163566.0
train_total_correct_tok: 142218.0
train_accuracy_tok: 0.8694838780675691
train_label=O_precision_sent: 0.4166666666666667
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.046511627906976744
train_label=N_precision_sent: 0.606203007518797
train_label=N_recall_sent: 0.7794561933534743
train_label=N_f-score_sent: 0.6819984139571769
train_label=P_precision_sent: 0.669131679389313
train_label=P_recall_sent: 0.7770083102493075
train_label=P_f-score_sent: 0.719046398359395
train_precision_macro_sent: 0.5640004511915923
train_recall_macro_sent: 0.527031681824901
train_f-score_macro_sent: 0.4825188134078495
train_precision_micro_sent: 0.6349485018726592
train_recall_micro_sent: 0.6349485018726592
train_f-score_micro_sent: 0.6349485018726592
train_label=O_precision_tok: 0.8830415811277161
train_label=O_recall_tok: 0.9651057122407457
train_label=O_f-score_tok: 0.9222516810758886
train_label=N_precision_tok: 0.7427929248509724
train_label=N_recall_tok: 0.5352063089705675
train_label=N_f-score_tok: 0.6221403724166156
train_label=P_precision_tok: 0.838152610441767
train_label=P_recall_tok: 0.5839629052244474
train_label=P_f-score_tok: 0.6883407543524867
train_precision_macro_tok: 0.8213290388068185
train_recall_macro_tok: 0.6947583088119202
train_f-score_macro_tok: 0.7442442692816637
train_precision_micro_tok: 0.8694838780675691
train_recall_micro_tok: 0.8694838780675691
train_f-score_micro_tok: 0.8694838780675691
train_time: 229.82370281219482
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0246    0.0465      1624
           N     0.6062    0.7795    0.6820      3310
           P     0.6691    0.7770    0.7190      3610

   micro avg     0.6349    0.6349    0.6349      8544
   macro avg     0.5640    0.5270    0.4825      8544
weighted avg     0.5968    0.6349    0.5769      8544

F1-macro sent:  0.4825188134078495
F1-micro sent:  0.6349485018726592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8830    0.9651    0.9223    124347
           N     0.7428    0.5352    0.6221     14202
           P     0.8382    0.5840    0.6883     25017

   micro avg     0.8695    0.8695    0.8695    163566
   macro avg     0.8213    0.6948    0.7442    163566
weighted avg     0.8640    0.8695    0.8604    163566

F1-macro tok:  0.7442442692816637
F1-micro tok:  0.8694838780675691
**************************************************
dev_cost_sum: 45099.669921875
dev_cost_avg: 40.96246132777021
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18788.0
dev_accuracy_tok: 0.8831437435367114
dev_label=O_precision_sent: 0.6470588235294118
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08943089430894309
dev_label=N_precision_sent: 0.650390625
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7085106382978724
dev_label=P_precision_sent: 0.6398601398601399
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.720472440944882
dev_precision_macro_sent: 0.6457698627965173
dev_recall_macro_sent: 0.5501322139999036
dev_f-score_macro_sent: 0.5061379911838992
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8833786860665297
dev_label=O_recall_tok: 0.9816106140080222
dev_label=O_f-score_tok: 0.9299076347480416
dev_label=N_precision_tok: 0.8148450244698205
dev_label=N_recall_tok: 0.5379644588045234
dev_label=N_f-score_tok: 0.6480700616282841
dev_label=P_precision_tok: 0.9220970112689858
dev_label=P_recall_tok: 0.5859277708592777
dev_label=P_f-score_tok: 0.716542927850752
dev_precision_macro_tok: 0.8734402406017786
dev_recall_macro_tok: 0.701834281223941
dev_f-score_macro_tok: 0.7648402080756925
dev_precision_micro_tok: 0.8831437435367114
dev_recall_micro_tok: 0.8831437435367114
dev_f-score_micro_tok: 0.8831437435367114
dev_time: 15.237945795059204
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6471    0.0480    0.0894       229
           N     0.6504    0.7780    0.7085       428
           P     0.6399    0.8243    0.7205       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.6458    0.5501    0.5061      1101
weighted avg     0.6455    0.6449    0.5846      1101

F1-macro sent:  0.5061379911838992
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8834    0.9816    0.9299     16205
           N     0.8148    0.5380    0.6481      1857
           P     0.9221    0.5859    0.7165      3212

   micro avg     0.8831    0.8831    0.8831     21274
   macro avg     0.8734    0.7018    0.7648     21274
weighted avg     0.8832    0.8831    0.8731     21274

F1-macro tok:  0.7648402080756925
F1-micro tok:  0.8831437435367114
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336189.7971191406
train_cost_avg: 39.34805677892564
train_count_sent: 8544.0
train_total_correct_sent: 5427.0
train_accuracy_sent: 0.6351825842696629
train_count_tok: 163566.0
train_total_correct_tok: 142800.0
train_accuracy_tok: 0.8730420747588129
train_label=O_precision_sent: 0.5161290322580645
train_label=O_recall_sent: 0.019704433497536946
train_label=O_f-score_sent: 0.03795966785290629
train_label=N_precision_sent: 0.598491773308958
train_label=N_recall_sent: 0.7912386706948641
train_label=N_f-score_sent: 0.6814988290398127
train_label=P_precision_sent: 0.6760837798343887
train_label=P_recall_sent: 0.7689750692520776
train_label=P_f-score_sent: 0.7195438050803524
train_precision_macro_sent: 0.5969015284671371
train_recall_macro_sent: 0.5266393911481595
train_f-score_macro_sent: 0.4796674339910238
train_precision_micro_sent: 0.6351825842696629
train_recall_micro_sent: 0.6351825842696629
train_f-score_micro_sent: 0.6351825842696629
train_label=O_precision_tok: 0.8861598584279605
train_label=O_recall_tok: 0.9664969802246938
train_label=O_f-score_tok: 0.9245865821431182
train_label=N_precision_tok: 0.7503855050115652
train_label=N_recall_tok: 0.5482326432896775
train_label=N_f-score_tok: 0.6335747416388641
train_label=P_precision_tok: 0.8442231075697211
train_label=P_recall_tok: 0.5929168165647359
train_label=P_f-score_tok: 0.6965975532439476
train_precision_macro_tok: 0.826922823669749
train_recall_macro_tok: 0.7025488133597024
train_f-score_macro_tok: 0.7515862923419766
train_precision_micro_tok: 0.8730420747588129
train_recall_micro_tok: 0.8730420747588129
train_f-score_micro_tok: 0.873042074758813
train_time: 204.99947452545166
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5161    0.0197    0.0380      1624
           N     0.5985    0.7912    0.6815      3310
           P     0.6761    0.7690    0.7195      3610

   micro avg     0.6352    0.6352    0.6352      8544
   macro avg     0.5969    0.5266    0.4797      8544
weighted avg     0.6156    0.6352    0.5753      8544

F1-macro sent:  0.4796674339910238
F1-micro sent:  0.6351825842696629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8862    0.9665    0.9246    124347
           N     0.7504    0.5482    0.6336     14202
           P     0.8442    0.5929    0.6966     25017

   micro avg     0.8730    0.8730    0.8730    163566
   macro avg     0.8269    0.7025    0.7516    163566
weighted avg     0.8680    0.8730    0.8644    163566

F1-macro tok:  0.7515862923419766
F1-micro tok:  0.873042074758813
**************************************************
dev_cost_sum: 44736.5712890625
dev_cost_avg: 40.63267147053815
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18852.0
dev_accuracy_tok: 0.886152110557488
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6219512195121951
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7125748502994012
dev_label=P_precision_sent: 0.6615969581749049
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7175257731958762
dev_precision_macro_sent: 0.7611827258957001
dev_recall_macro_sent: 0.5407542485145228
dev_f-score_macro_sent: 0.4795987585563968
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8847499028479432
dev_label=O_recall_tok: 0.9834618944770133
dev_label=O_f-score_tok: 0.9314980419662168
dev_label=N_precision_tok: 0.8452380952380952
dev_label=N_recall_tok: 0.4970382337102854
dev_label=N_f-score_tok: 0.6259749067480502
dev_label=P_precision_tok: 0.9183955739972337
dev_label=P_recall_tok: 0.6201743462017435
dev_label=P_f-score_tok: 0.7403828284705445
dev_precision_macro_tok: 0.8827945240277574
dev_recall_macro_tok: 0.7002248247963475
dev_f-score_macro_tok: 0.7659519257282704
dev_precision_micro_tok: 0.886152110557488
dev_recall_micro_tok: 0.886152110557488
dev_f-score_micro_tok: 0.886152110557488
dev_time: 8.288602828979492
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6220    0.8341    0.7126       428
           P     0.6616    0.7838    0.7175       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.7612    0.5408    0.4796      1101
weighted avg     0.7166    0.6412    0.5682      1101

F1-macro sent:  0.4795987585563968
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9835    0.9315     16205
           N     0.8452    0.4970    0.6260      1857
           P     0.9184    0.6202    0.7404      3212

   micro avg     0.8862    0.8862    0.8862     21274
   macro avg     0.8828    0.7002    0.7660     21274
weighted avg     0.8864    0.8862    0.8760     21274

F1-macro tok:  0.7659519257282704
F1-micro tok:  0.886152110557488
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333335.8889770508
train_cost_avg: 39.014031949561186
train_count_sent: 8544.0
train_total_correct_sent: 5459.0
train_accuracy_sent: 0.6389279026217228
train_count_tok: 163566.0
train_total_correct_tok: 143345.0
train_accuracy_tok: 0.8763740630693421
train_label=O_precision_sent: 0.3816793893129771
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.05698005698005698
train_label=N_precision_sent: 0.6126360624704212
train_label=N_recall_sent: 0.7821752265861027
train_label=N_f-score_sent: 0.6871019108280256
train_label=P_precision_sent: 0.6735132553140674
train_label=P_recall_sent: 0.7811634349030471
train_label=P_f-score_sent: 0.7233551365909965
train_precision_macro_sent: 0.5559429023658219
train_recall_macro_sent: 0.531375612943017
train_f-score_macro_sent: 0.48914570146635966
train_precision_micro_sent: 0.6389279026217228
train_recall_micro_sent: 0.6389279026217228
train_f-score_micro_sent: 0.6389279026217228
train_label=O_precision_tok: 0.8883091388128326
train_label=O_recall_tok: 0.9679767103347889
train_label=O_f-score_tok: 0.9264333489836288
train_label=N_precision_tok: 0.7607970254552389
train_label=N_recall_tok: 0.5618926911702578
train_label=N_f-score_tok: 0.6463893726459033
train_label=P_precision_tok: 0.8533394015246331
train_label=P_recall_tok: 0.599592277251469
train_label=P_f-score_tok: 0.7043080173729311
train_precision_macro_tok: 0.8341485219309015
train_recall_macro_tok: 0.7098205595855053
train_f-score_macro_tok: 0.7590435796674878
train_precision_micro_tok: 0.8763740630693421
train_recall_micro_tok: 0.8763740630693421
train_f-score_micro_tok: 0.8763740630693422
train_time: 144.33448457717896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3817    0.0308    0.0570      1624
           N     0.6126    0.7822    0.6871      3310
           P     0.6735    0.7812    0.7234      3610

   micro avg     0.6389    0.6389    0.6389      8544
   macro avg     0.5559    0.5314    0.4891      8544
weighted avg     0.5945    0.6389    0.5826      8544

F1-macro sent:  0.48914570146635966
F1-micro sent:  0.6389279026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8883    0.9680    0.9264    124347
           N     0.7608    0.5619    0.6464     14202
           P     0.8533    0.5996    0.7043     25017

   micro avg     0.8764    0.8764    0.8764    163566
   macro avg     0.8341    0.7098    0.7590    163566
weighted avg     0.8719    0.8764    0.8681    163566

F1-macro tok:  0.7590435796674878
F1-micro tok:  0.8763740630693422
**************************************************
dev_cost_sum: 44364.02374267578
dev_cost_avg: 40.2942994938018
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18936.0
dev_accuracy_tok: 0.8901005922722572
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.5954692556634305
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7036328871892925
dev_label=P_precision_sent: 0.6903765690376569
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7158351409978307
dev_precision_macro_sent: 0.6286152749003625
dev_recall_macro_sent: 0.5387189213455384
dev_f-score_macro_sent: 0.48170301794271636
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8944011739473982
dev_label=O_recall_tok: 0.9779080530700401
dev_label=O_f-score_tok: 0.9342923680099049
dev_label=N_precision_tok: 0.7847272727272727
dev_label=N_recall_tok: 0.5810446957458266
dev_label=N_f-score_tok: 0.6676980198019802
dev_label=P_precision_tok: 0.921595598349381
dev_label=P_recall_tok: 0.6257783312577833
dev_label=P_f-score_tok: 0.7454107175968848
dev_precision_macro_tok: 0.8669080150080174
dev_recall_macro_tok: 0.7282436933578834
dev_f-score_macro_tok: 0.7824670351362566
dev_precision_micro_tok: 0.8901005922722572
dev_recall_micro_tok: 0.8901005922722572
dev_f-score_micro_tok: 0.8901005922722572
dev_time: 8.513299942016602
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.5955    0.8598    0.7036       428
           P     0.6904    0.7432    0.7158       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.6286    0.5387    0.4817      1101
weighted avg     0.6347    0.6367    0.5675      1101

F1-macro sent:  0.48170301794271636
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9779    0.9343     16205
           N     0.7847    0.5810    0.6677      1857
           P     0.9216    0.6258    0.7454      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8669    0.7282    0.7825     21274
weighted avg     0.8889    0.8901    0.8825     21274

F1-macro tok:  0.7824670351362566
F1-micro tok:  0.8901005922722572
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330986.09173583984
train_cost_avg: 38.73900886421347
train_count_sent: 8544.0
train_total_correct_sent: 5470.0
train_accuracy_sent: 0.6402153558052435
train_count_tok: 163566.0
train_total_correct_tok: 143631.0
train_accuracy_tok: 0.8781225927148674
train_label=O_precision_sent: 0.4375
train_label=O_recall_sent: 0.034482758620689655
train_label=O_f-score_sent: 0.0639269406392694
train_label=N_precision_sent: 0.603622191655204
train_label=N_recall_sent: 0.7954682779456194
train_label=N_f-score_sent: 0.6863920750782065
train_label=P_precision_sent: 0.6859891465219536
train_label=P_recall_sent: 0.7703601108033241
train_label=P_f-score_sent: 0.7257306889352817
train_precision_macro_sent: 0.5757037793923859
train_recall_macro_sent: 0.533437049123211
train_f-score_macro_sent: 0.4920165682175859
train_precision_micro_sent: 0.6402153558052435
train_recall_micro_sent: 0.6402153558052435
train_f-score_micro_sent: 0.6402153558052435
train_label=O_precision_tok: 0.8900006650950717
train_label=O_recall_tok: 0.9685316091260746
train_label=O_f-score_tok: 0.9276070028421125
train_label=N_precision_tok: 0.7622344461305007
train_label=N_recall_tok: 0.5659062103929025
train_label=N_f-score_tok: 0.6495595247716803
train_label=P_precision_tok: 0.8563520307292549
train_label=P_recall_tok: 0.605987928208818
train_label=P_f-score_tok: 0.7097378277153558
train_precision_macro_tok: 0.8361957139849424
train_recall_macro_tok: 0.7134752492425984
train_f-score_macro_tok: 0.7623014517763829
train_precision_micro_tok: 0.8781225927148674
train_recall_micro_tok: 0.8781225927148674
train_f-score_micro_tok: 0.8781225927148674
train_time: 145.98733949661255
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4375    0.0345    0.0639      1624
           N     0.6036    0.7955    0.6864      3310
           P     0.6860    0.7704    0.7257      3610

   micro avg     0.6402    0.6402    0.6402      8544
   macro avg     0.5757    0.5334    0.4920      8544
weighted avg     0.6068    0.6402    0.5847      8544

F1-macro sent:  0.4920165682175859
F1-micro sent:  0.6402153558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8900    0.9685    0.9276    124347
           N     0.7622    0.5659    0.6496     14202
           P     0.8564    0.6060    0.7097     25017

   micro avg     0.8781    0.8781    0.8781    163566
   macro avg     0.8362    0.7135    0.7623    163566
weighted avg     0.8738    0.8781    0.8701    163566

F1-macro tok:  0.7623014517763829
F1-micro tok:  0.8781225927148674
**************************************************
dev_cost_sum: 44096.506103515625
dev_cost_avg: 40.05132252817042
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 18968.0
dev_accuracy_tok: 0.8916047757826455
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.5806451612903226
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.70064874884152
dev_label=P_precision_sent: 0.7188208616780045
dev_label=P_recall_sent: 0.713963963963964
dev_label=P_f-score_sent: 0.7163841807909604
dev_precision_macro_sent: 0.6924146002487017
dev_recall_macro_sent: 0.5425697398823138
dev_f-score_macro_sent: 0.4919521530147484
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8950693895972018
dev_label=O_recall_tok: 0.9790805307004011
dev_label=O_f-score_tok: 0.9351920073089505
dev_label=N_precision_tok: 0.7895500725689405
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.6726429675425039
dev_label=P_precision_tok: 0.928110599078341
dev_label=P_recall_tok: 0.6270236612702366
dev_label=P_f-score_tok: 0.7484206614641398
dev_precision_macro_tok: 0.8709100204148278
dev_recall_macro_tok: 0.7306651381241203
dev_f-score_macro_tok: 0.7854185454385313
dev_precision_micro_tok: 0.8916047757826455
dev_recall_micro_tok: 0.8916047757826455
dev_f-score_micro_tok: 0.8916047757826455
dev_time: 8.491069316864014
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.5806    0.8832    0.7006       428
           P     0.7188    0.7140    0.7164       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.6924    0.5426    0.4920      1101
weighted avg     0.6774    0.6376    0.5735      1101

F1-macro sent:  0.4919521530147484
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8951    0.9791    0.9352     16205
           N     0.7896    0.5859    0.6726      1857
           P     0.9281    0.6270    0.7484      3212

   micro avg     0.8916    0.8916    0.8916     21274
   macro avg     0.8709    0.7307    0.7854     21274
weighted avg     0.8908    0.8916    0.8841     21274

F1-macro tok:  0.7854185454385313
F1-micro tok:  0.8916047757826455
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328314.6268310547
train_cost_avg: 38.42633741000172
train_count_sent: 8544.0
train_total_correct_sent: 5541.0
train_accuracy_sent: 0.6485252808988764
train_count_tok: 163566.0
train_total_correct_tok: 144034.0
train_accuracy_tok: 0.8805864299426531
train_label=O_precision_sent: 0.4966887417218543
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08450704225352113
train_label=N_precision_sent: 0.6186157517899762
train_label=N_recall_sent: 0.7830815709969788
train_label=N_f-score_sent: 0.6912000000000001
train_label=P_precision_sent: 0.6837972876516774
train_label=P_recall_sent: 0.7961218836565097
train_label=P_f-score_sent: 0.7356969153974146
train_precision_macro_sent: 0.5997005937211694
train_recall_macro_sent: 0.5417952402211136
train_f-score_macro_sent: 0.5038013192169787
train_precision_micro_sent: 0.6485252808988764
train_recall_micro_sent: 0.6485252808988764
train_f-score_micro_sent: 0.6485252808988764
train_label=O_precision_tok: 0.8920203081750766
train_label=O_recall_tok: 0.969287558204058
train_label=O_f-score_tok: 0.9290501609080222
train_label=N_precision_tok: 0.770230805463966
train_label=N_recall_tok: 0.5756935642867201
train_label=N_f-score_tok: 0.6589031712132811
train_label=P_precision_tok: 0.8596422363034824
train_label=P_recall_tok: 0.6127833073510013
train_label=P_f-score_tok: 0.7155192532088682
train_precision_macro_tok: 0.8406311166475083
train_recall_macro_tok: 0.7192548099472598
train_f-score_macro_tok: 0.7678241951100572
train_precision_micro_tok: 0.8805864299426531
train_recall_micro_tok: 0.8805864299426531
train_f-score_micro_tok: 0.8805864299426531
train_time: 145.50871658325195
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4967    0.0462    0.0845      1624
           N     0.6186    0.7831    0.6912      3310
           P     0.6838    0.7961    0.7357      3610

   micro avg     0.6485    0.6485    0.6485      8544
   macro avg     0.5997    0.5418    0.5038      8544
weighted avg     0.6230    0.6485    0.5947      8544

F1-macro sent:  0.5038013192169787
F1-micro sent:  0.6485252808988764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8920    0.9693    0.9291    124347
           N     0.7702    0.5757    0.6589     14202
           P     0.8596    0.6128    0.7155     25017

   micro avg     0.8806    0.8806    0.8806    163566
   macro avg     0.8406    0.7193    0.7678    163566
weighted avg     0.8765    0.8806    0.8729    163566

F1-macro tok:  0.7678241951100572
F1-micro tok:  0.8805864299426531
**************************************************
dev_cost_sum: 43834.84014892578
dev_cost_avg: 39.81366044407428
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18987.0
dev_accuracy_tok: 0.8924978847419385
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0737704918032787
dev_label=N_precision_sent: 0.6029654036243822
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7072463768115942
dev_label=P_precision_sent: 0.6931106471816284
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7193932827735645
dev_precision_macro_sent: 0.6320253502686702
dev_recall_macro_sent: 0.5473964149024346
dev_f-score_macro_sent: 0.5001367171294792
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8978445830969938
dev_label=O_recall_tok: 0.9767972847886455
dev_label=O_f-score_tok: 0.9356583419535983
dev_label=N_precision_tok: 0.8155416012558869
dev_label=N_recall_tok: 0.559504577275175
dev_label=N_f-score_tok: 0.6636857234110507
dev_label=P_precision_tok: 0.8940928270042194
dev_label=P_recall_tok: 0.6597135740971357
dev_label=P_f-score_tok: 0.7592260838409173
dev_precision_macro_tok: 0.8691596704523668
dev_recall_macro_tok: 0.7320051453869855
dev_f-score_macro_tok: 0.7861900497351888
dev_precision_micro_tok: 0.8924978847419385
dev_recall_micro_tok: 0.8924978847419385
dev_f-score_micro_tok: 0.8924978847419385
dev_time: 8.350188732147217
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0393    0.0738       229
           N     0.6030    0.8551    0.7072       428
           P     0.6931    0.7477    0.7194       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6320    0.5474    0.5001      1101
weighted avg     0.6387    0.6421    0.5804      1101

F1-macro sent:  0.5001367171294792
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8978    0.9768    0.9357     16205
           N     0.8155    0.5595    0.6637      1857
           P     0.8941    0.6597    0.7592      3212

   micro avg     0.8925    0.8925    0.8925     21274
   macro avg     0.8692    0.7320    0.7862     21274
weighted avg     0.8901    0.8925    0.8853     21274

F1-macro tok:  0.7861900497351888
F1-micro tok:  0.8924978847419385
**************************************************
Best epoch: 8
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 325693.20330810547
train_cost_avg: 38.119522859094744
train_count_sent: 8544.0
train_total_correct_sent: 5546.0
train_accuracy_sent: 0.6491104868913857
train_count_tok: 163566.0
train_total_correct_tok: 144437.0
train_accuracy_tok: 0.8830502671704389
train_label=O_precision_sent: 0.39106145251396646
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.0776483638380477
train_label=N_precision_sent: 0.6213453767530307
train_label=N_recall_sent: 0.7897280966767372
train_label=N_f-score_sent: 0.6954902221630971
train_label=P_precision_sent: 0.6883116883116883
train_label=P_recall_sent: 0.792797783933518
train_label=P_f-score_sent: 0.7368692070030896
train_precision_macro_sent: 0.5669061725262284
train_recall_macro_sent: 0.5418764429620391
train_f-score_macro_sent: 0.5033359310014115
train_precision_micro_sent: 0.6491104868913857
train_recall_micro_sent: 0.6491104868913857
train_f-score_micro_sent: 0.6491104868913857
train_label=O_precision_tok: 0.8944092928723492
train_label=O_recall_tok: 0.9696896587774534
train_label=O_f-score_tok: 0.9305294026855997
train_label=N_precision_tok: 0.7718338587057296
train_label=N_recall_tok: 0.5861850443599493
train_label=N_f-score_tok: 0.6663198335200896
train_label=P_precision_tok: 0.8645850726331608
train_label=P_recall_tok: 0.6209377623216213
train_label=P_f-score_tok: 0.7227805695142379
train_precision_macro_tok: 0.8436094080704132
train_recall_macro_tok: 0.725604155153008
train_f-score_macro_tok: 0.7732099352399757
train_precision_micro_tok: 0.8830502671704389
train_recall_micro_tok: 0.8830502671704389
train_f-score_micro_tok: 0.8830502671704389
train_time: 145.30543208122253
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3911    0.0431    0.0776      1624
           N     0.6213    0.7897    0.6955      3310
           P     0.6883    0.7928    0.7369      3610

   micro avg     0.6491    0.6491    0.6491      8544
   macro avg     0.5669    0.5419    0.5033      8544
weighted avg     0.6059    0.6491    0.5955      8544

F1-macro sent:  0.5033359310014115
F1-micro sent:  0.6491104868913857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9697    0.9305    124347
           N     0.7718    0.5862    0.6663     14202
           P     0.8646    0.6209    0.7228     25017

   micro avg     0.8831    0.8831    0.8831    163566
   macro avg     0.8436    0.7256    0.7732    163566
weighted avg     0.8792    0.8831    0.8758    163566

F1-macro tok:  0.7732099352399757
F1-micro tok:  0.8830502671704389
**************************************************
dev_cost_sum: 43733.84436035156
dev_cost_avg: 39.72192948260814
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19009.0
dev_accuracy_tok: 0.8935320109053304
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6620553359683794
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7173447537473233
dev_label=P_precision_sent: 0.6374367622259697
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.7290260366441659
dev_precision_macro_sent: 0.766497366064783
dev_recall_macro_sent: 0.5475984187264439
dev_f-score_macro_sent: 0.4878956025691688
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8988923601249645
dev_label=O_recall_tok: 0.97655044739278
dev_label=O_f-score_tok: 0.9361135758651287
dev_label=N_precision_tok: 0.808446455505279
dev_label=N_recall_tok: 0.5772751750134626
dev_label=N_f-score_tok: 0.6735783851712221
dev_label=P_precision_tok: 0.9014084507042254
dev_label=P_recall_tok: 0.6575342465753424
dev_label=P_f-score_tok: 0.7603960396039603
dev_precision_macro_tok: 0.8695824221114896
dev_recall_macro_tok: 0.7371199563271951
dev_f-score_macro_tok: 0.7900293335467703
dev_precision_micro_tok: 0.8935320109053304
dev_recall_micro_tok: 0.8935320109053304
dev_f-score_micro_tok: 0.8935320109053304
dev_time: 8.31679105758667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6621    0.7827    0.7173       428
           P     0.6374    0.8514    0.7290       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.7665    0.5476    0.4879      1101
weighted avg     0.7224    0.6494    0.5765      1101

F1-macro sent:  0.4878956025691688
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9766    0.9361     16205
           N     0.8084    0.5773    0.6736      1857
           P     0.9014    0.6575    0.7604      3212

   micro avg     0.8935    0.8935    0.8935     21274
   macro avg     0.8696    0.7371    0.7900     21274
weighted avg     0.8914    0.8935    0.8867     21274

F1-macro tok:  0.7900293335467703
F1-micro tok:  0.8935320109053304
**************************************************
Best epoch: 8
**************************************************

EPOCH: 14
Learning rate: 0.810000
train_cost_sum: 323571.95959472656
train_cost_avg: 37.87124995256631
train_count_sent: 8544.0
train_total_correct_sent: 5646.0
train_accuracy_sent: 0.660814606741573
train_count_tok: 163566.0
train_total_correct_tok: 144759.0
train_accuracy_tok: 0.8850188914566597
train_label=O_precision_sent: 0.42127659574468085
train_label=O_recall_sent: 0.06096059113300493
train_label=O_f-score_sent: 0.10650887573964496
train_label=N_precision_sent: 0.6318289786223278
train_label=N_recall_sent: 0.8036253776435045
train_label=N_f-score_sent: 0.7074468085106382
train_label=P_precision_sent: 0.704318126372286
train_label=P_recall_sent: 0.7997229916897507
train_label=P_f-score_sent: 0.748994681541056
train_precision_macro_sent: 0.5858079002464315
train_recall_macro_sent: 0.5547696534887533
train_f-score_macro_sent: 0.5209834552637798
train_precision_micro_sent: 0.660814606741573
train_recall_micro_sent: 0.660814606741573
train_f-score_micro_sent: 0.660814606741573
train_label=O_precision_tok: 0.8963664335456444
train_label=O_recall_tok: 0.9699228771100228
train_label=O_f-score_tok: 0.9316951077258226
train_label=N_precision_tok: 0.7737820097993898
train_label=N_recall_tok: 0.5893536121673004
train_label=N_f-score_tok: 0.6690914904672448
train_label=P_precision_tok: 0.867238158039345
train_label=P_recall_tok: 0.6308510213055123
train_label=P_f-score_tok: 0.7303945389332407
train_precision_macro_tok: 0.8457955337947931
train_recall_macro_tok: 0.7300425035276118
train_f-score_macro_tok: 0.7770603790421027
train_precision_micro_tok: 0.8850188914566597
train_recall_micro_tok: 0.8850188914566597
train_f-score_micro_tok: 0.8850188914566598
train_time: 145.14476013183594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4213    0.0610    0.1065      1624
           N     0.6318    0.8036    0.7074      3310
           P     0.7043    0.7997    0.7490      3610

   micro avg     0.6608    0.6608    0.6608      8544
   macro avg     0.5858    0.5548    0.5210      8544
weighted avg     0.6224    0.6608    0.6108      8544

F1-macro sent:  0.5209834552637798
F1-micro sent:  0.660814606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8964    0.9699    0.9317    124347
           N     0.7738    0.5894    0.6691     14202
           P     0.8672    0.6309    0.7304     25017

   micro avg     0.8850    0.8850    0.8850    163566
   macro avg     0.8458    0.7300    0.7771    163566
weighted avg     0.8813    0.8850    0.8781    163566

F1-macro tok:  0.7770603790421027
F1-micro tok:  0.8850188914566598
**************************************************
dev_cost_sum: 43471.839416503906
dev_cost_avg: 39.4839595063614
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 19044.0
dev_accuracy_tok: 0.8951772116198177
dev_label=O_precision_sent: 0.6818181818181818
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.1195219123505976
dev_label=N_precision_sent: 0.5802098950524738
dev_label=N_recall_sent: 0.9042056074766355
dev_label=N_f-score_sent: 0.7068493150684931
dev_label=P_precision_sent: 0.7427184466019418
dev_label=P_recall_sent: 0.6891891891891891
dev_label=P_f-score_sent: 0.7149532710280373
dev_precision_macro_sent: 0.6682488411575324
dev_recall_macro_sent: 0.5529656600239794
dev_f-score_macro_sent: 0.5137748328157093
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.9012184012753359
dev_label=O_recall_tok: 0.9767972847886455
dev_label=O_f-score_tok: 0.9374870443305992
dev_label=N_precision_tok: 0.7802874743326489
dev_label=N_recall_tok: 0.6138933764135702
dev_label=N_f-score_tok: 0.6871609403254972
dev_label=P_precision_tok: 0.9226322810137839
dev_label=P_recall_tok: 0.6460149439601495
dev_label=P_f-score_tok: 0.759934078007691
dev_precision_macro_tok: 0.8680460522072563
dev_recall_macro_tok: 0.7455685350541218
dev_f-score_macro_tok: 0.7948606875545958
dev_precision_micro_tok: 0.8951772116198177
dev_recall_micro_tok: 0.8951772116198177
dev_f-score_micro_tok: 0.8951772116198177
dev_time: 8.338532209396362
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6818    0.0655    0.1195       229
           N     0.5802    0.9042    0.7068       428
           P     0.7427    0.6892    0.7150       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6682    0.5530    0.5138      1101
weighted avg     0.6669    0.6431    0.5880      1101

F1-macro sent:  0.5137748328157093
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9012    0.9768    0.9375     16205
           N     0.7803    0.6139    0.6872      1857
           P     0.9226    0.6460    0.7599      3212

   micro avg     0.8952    0.8952    0.8952     21274
   macro avg     0.8680    0.7456    0.7949     21274
weighted avg     0.8939    0.8952    0.8888     21274

F1-macro tok:  0.7948606875545958
F1-micro tok:  0.8951772116198177
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 0.810000
train_cost_sum: 321945.07733154297
train_cost_avg: 37.68083770266186
train_count_sent: 8544.0
train_total_correct_sent: 5641.0
train_accuracy_sent: 0.6602294007490637
train_count_tok: 163566.0
train_total_correct_tok: 145016.0
train_accuracy_tok: 0.8865901226416247
train_label=O_precision_sent: 0.46153846153846156
train_label=O_recall_sent: 0.059113300492610835
train_label=O_f-score_sent: 0.10480349344978165
train_label=N_precision_sent: 0.6333012512030799
train_label=N_recall_sent: 0.795166163141994
train_label=N_f-score_sent: 0.7050629520492903
train_label=P_precision_sent: 0.69688995215311
train_label=P_recall_sent: 0.8069252077562327
train_label=P_f-score_sent: 0.7478818998716303
train_precision_macro_sent: 0.5972432216315505
train_recall_macro_sent: 0.5537348904636125
train_f-score_macro_sent: 0.5192494484569008
train_precision_micro_sent: 0.6602294007490637
train_recall_micro_sent: 0.6602294007490637
train_f-score_micro_sent: 0.6602294007490637
train_label=O_precision_tok: 0.8975289454702291
train_label=O_recall_tok: 0.9706466581421345
train_label=O_f-score_tok: 0.9326569406237443
train_label=N_precision_tok: 0.7766651355075792
train_label=N_recall_tok: 0.5952682720743557
train_label=N_f-score_tok: 0.6739745685016144
train_label=P_precision_tok: 0.8715117556580971
train_label=P_recall_tok: 0.6341687652396371
train_label=P_f-score_tok: 0.7341338701094375
train_precision_macro_tok: 0.8485686122119684
train_recall_macro_tok: 0.7333612318187092
train_f-score_macro_tok: 0.7802551264115988
train_precision_micro_tok: 0.8865901226416247
train_recall_micro_tok: 0.8865901226416247
train_f-score_micro_tok: 0.8865901226416248
train_time: 145.47772073745728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0591    0.1048      1624
           N     0.6333    0.7952    0.7051      3310
           P     0.6969    0.8069    0.7479      3610

   micro avg     0.6602    0.6602    0.6602      8544
   macro avg     0.5972    0.5537    0.5192      8544
weighted avg     0.6275    0.6602    0.6091      8544

F1-macro sent:  0.5192494484569008
F1-micro sent:  0.6602294007490637
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8975    0.9706    0.9327    124347
           N     0.7767    0.5953    0.6740     14202
           P     0.8715    0.6342    0.7341     25017

   micro avg     0.8866    0.8866    0.8866    163566
   macro avg     0.8486    0.7334    0.7803    163566
weighted avg     0.8831    0.8866    0.8798    163566

F1-macro tok:  0.7802551264115988
F1-micro tok:  0.8865901226416248
**************************************************
dev_cost_sum: 43326.45556640625
dev_cost_avg: 39.35191241272139
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19042.0
dev_accuracy_tok: 0.8950832001504183
dev_label=O_precision_sent: 0.47058823529411764
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06504065040650407
dev_label=N_precision_sent: 0.6789587852494577
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.7041619797525308
dev_label=P_precision_sent: 0.6292134831460674
dev_label=P_recall_sent: 0.8828828828828829
dev_label=P_f-score_sent: 0.7347703842549203
dev_precision_macro_sent: 0.5929201678965476
dev_recall_macro_sent: 0.54970859730481
dev_f-score_macro_sent: 0.501324338137985
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.9006260671599317
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9370244263508511
dev_label=N_precision_tok: 0.8
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.6764065899906745
dev_label=P_precision_tok: 0.908703071672355
dev_label=P_recall_tok: 0.6631382316313823
dev_label=P_f-score_tok: 0.7667386609071274
dev_precision_macro_tok: 0.8697763796107623
dev_recall_macro_tok: 0.741839397358973
dev_f-score_macro_tok: 0.7933898924162177
dev_precision_micro_tok: 0.8950832001504183
dev_recall_micro_tok: 0.8950832001504183
dev_f-score_micro_tok: 0.8950832001504183
dev_time: 8.258363962173462
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4706    0.0349    0.0650       229
           N     0.6790    0.7313    0.7042       428
           P     0.6292    0.8829    0.7348       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.5929    0.5497    0.5013      1101
weighted avg     0.6156    0.6476    0.5836      1101

F1-macro sent:  0.501324338137985
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9006    0.9765    0.9370     16205
           N     0.8000    0.5859    0.6764      1857
           P     0.9087    0.6631    0.7667      3212

   micro avg     0.8951    0.8951    0.8951     21274
   macro avg     0.8698    0.7418    0.7934     21274
weighted avg     0.8931    0.8951    0.8886     21274

F1-macro tok:  0.7933898924162177
F1-micro tok:  0.8950832001504183
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 0.810000
train_cost_sum: 320103.3186645508
train_cost_avg: 37.46527606092589
train_count_sent: 8544.0
train_total_correct_sent: 5689.0
train_accuracy_sent: 0.6658473782771536
train_count_tok: 163566.0
train_total_correct_tok: 145193.0
train_accuracy_tok: 0.8876722546250443
train_label=O_precision_sent: 0.4797979797979798
train_label=O_recall_sent: 0.058497536945812806
train_label=O_f-score_sent: 0.10428100987925355
train_label=N_precision_sent: 0.6373416208462825
train_label=N_recall_sent: 0.8054380664652568
train_label=N_f-score_sent: 0.7115974909915921
train_label=P_precision_sent: 0.7033389382656738
train_label=P_recall_sent: 0.8110803324099723
train_label=P_f-score_sent: 0.7533770744886146
train_precision_macro_sent: 0.6068261796366453
train_recall_macro_sent: 0.5583386452736807
train_f-score_macro_sent: 0.5230851917864867
train_precision_micro_sent: 0.6658473782771536
train_recall_micro_sent: 0.6658473782771536
train_f-score_micro_sent: 0.6658473782771536
train_label=O_precision_tok: 0.8985462994682674
train_label=O_recall_tok: 0.9703088936604823
train_label=O_f-score_tok: 0.9330497825036248
train_label=N_precision_tok: 0.781723571298156
train_label=N_recall_tok: 0.6029432474299394
train_label=N_f-score_tok: 0.6807918588010813
train_label=P_precision_tok: 0.8713319515653977
train_label=P_recall_tok: 0.6385657752728144
train_label=P_f-score_tok: 0.7370072201333302
train_precision_macro_tok: 0.8505339407772737
train_recall_macro_tok: 0.7372726387877453
train_f-score_macro_tok: 0.7836162871460122
train_precision_micro_tok: 0.8876722546250443
train_recall_micro_tok: 0.8876722546250443
train_f-score_micro_tok: 0.8876722546250443
train_time: 145.3610062599182
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4798    0.0585    0.1043      1624
           N     0.6373    0.8054    0.7116      3310
           P     0.7033    0.8111    0.7534      3610

   micro avg     0.6658    0.6658    0.6658      8544
   macro avg     0.6068    0.5583    0.5231      8544
weighted avg     0.6353    0.6658    0.6138      8544

F1-macro sent:  0.5230851917864867
F1-micro sent:  0.6658473782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9703    0.9330    124347
           N     0.7817    0.6029    0.6808     14202
           P     0.8713    0.6386    0.7370     25017

   micro avg     0.8877    0.8877    0.8877    163566
   macro avg     0.8505    0.7373    0.7836    163566
weighted avg     0.8842    0.8877    0.8812    163566

F1-macro tok:  0.7836162871460122
F1-micro tok:  0.8876722546250443
**************************************************
dev_cost_sum: 43129.1689453125
dev_cost_avg: 39.17272383770436
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19061.0
dev_accuracy_tok: 0.8959763091097114
dev_label=O_precision_sent: 0.5263157894736842
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08064516129032258
dev_label=N_precision_sent: 0.6169154228855721
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7216294859359844
dev_label=P_precision_sent: 0.7160751565762005
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.743228602383532
dev_precision_macro_sent: 0.6197687896451523
dev_recall_macro_sent: 0.5617831744326459
dev_f-score_macro_sent: 0.5151677498699464
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.8988674971687429
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9374870810571387
dev_label=N_precision_tok: 0.8244392884764115
dev_label=N_recall_tok: 0.5740441572428648
dev_label=N_f-score_tok: 0.6768253968253969
dev_label=P_precision_tok: 0.9138302455838001
dev_label=P_recall_tok: 0.6603362391033624
dev_label=P_f-score_tok: 0.7666726911259716
dev_precision_macro_tok: 0.8790456770763182
dev_recall_macro_tok: 0.7379848672794531
dev_f-score_macro_tok: 0.7936617230028359
dev_precision_micro_tok: 0.8959763091097114
dev_recall_micro_tok: 0.8959763091097114
dev_f-score_micro_tok: 0.8959763091097114
dev_time: 8.028038740158081
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5263    0.0437    0.0806       229
           N     0.6169    0.8692    0.7216       428
           P     0.7161    0.7725    0.7432       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6198    0.5618    0.5152      1101
weighted avg     0.6381    0.6585    0.5970      1101

F1-macro sent:  0.5151677498699464
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9796    0.9375     16205
           N     0.8244    0.5740    0.6768      1857
           P     0.9138    0.6603    0.7667      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8790    0.7380    0.7937     21274
weighted avg     0.8946    0.8960    0.8889     21274

F1-macro tok:  0.7936617230028359
F1-micro tok:  0.8959763091097114
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 0.810000
train_cost_sum: 318413.2650756836
train_cost_avg: 37.26747016335248
train_count_sent: 8544.0
train_total_correct_sent: 5676.0
train_accuracy_sent: 0.6643258426966292
train_count_tok: 163566.0
train_total_correct_tok: 145367.0
train_accuracy_tok: 0.8887360453884059
train_label=O_precision_sent: 0.43956043956043955
train_label=O_recall_sent: 0.04926108374384237
train_label=O_f-score_sent: 0.08859357696567
train_label=N_precision_sent: 0.6310611384399156
train_label=N_recall_sent: 0.8138972809667674
train_label=N_f-score_sent: 0.7109117297796543
train_label=P_precision_sent: 0.7090153921329099
train_label=P_recall_sent: 0.8038781163434903
train_label=P_f-score_sent: 0.7534726729845516
train_precision_macro_sent: 0.593212323377755
train_recall_macro_sent: 0.5556788270180334
train_f-score_macro_sent: 0.5176593265766253
train_precision_micro_sent: 0.6643258426966292
train_recall_micro_sent: 0.6643258426966292
train_f-score_micro_sent: 0.6643258426966292
train_label=O_precision_tok: 0.899668343581144
train_label=O_recall_tok: 0.970775330325621
train_label=O_f-score_tok: 0.933870231547025
train_label=N_precision_tok: 0.7853956113994355
train_label=N_recall_tok: 0.607379242360231
train_label=N_f-score_tok: 0.6850109191979353
train_label=P_precision_tok: 0.8707083876575402
train_label=P_recall_tok: 0.6406843346524363
train_label=P_f-score_tok: 0.7381922855497985
train_precision_macro_tok: 0.8519241142127066
train_recall_macro_tok: 0.7396129691127628
train_f-score_macro_tok: 0.7856911454315862
train_precision_micro_tok: 0.8887360453884059
train_recall_micro_tok: 0.8887360453884059
train_f-score_micro_tok: 0.8887360453884059
train_time: 146.06619811058044
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4396    0.0493    0.0886      1624
           N     0.6311    0.8139    0.7109      3310
           P     0.7090    0.8039    0.7535      3610

   micro avg     0.6643    0.6643    0.6643      8544
   macro avg     0.5932    0.5557    0.5177      8544
weighted avg     0.6276    0.6643    0.6106      8544

F1-macro sent:  0.5176593265766253
F1-micro sent:  0.6643258426966292
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8997    0.9708    0.9339    124347
           N     0.7854    0.6074    0.6850     14202
           P     0.8707    0.6407    0.7382     25017

   micro avg     0.8887    0.8887    0.8887    163566
   macro avg     0.8519    0.7396    0.7857    163566
weighted avg     0.8853    0.8887    0.8823    163566

F1-macro tok:  0.7856911454315862
F1-micro tok:  0.8887360453884059
**************************************************
dev_cost_sum: 43117.12518310547
dev_cost_avg: 39.16178490745274
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 19056.0
dev_accuracy_tok: 0.8957412804362133
dev_label=O_precision_sent: 0.5384615384615384
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.057851239669421496
dev_label=N_precision_sent: 0.6810933940774487
dev_label=N_recall_sent: 0.6985981308411215
dev_label=N_f-score_sent: 0.6897347174163784
dev_label=P_precision_sent: 0.6070878274268104
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.7209515096065873
dev_precision_macro_sent: 0.6088809199885992
dev_recall_macro_sent: 0.5388510679393429
dev_f-score_macro_sent: 0.4895124888974624
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.8964177086853666
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9373067522600783
dev_label=N_precision_tok: 0.8269680436477007
dev_label=N_recall_tok: 0.5713516424340334
dev_label=N_f-score_tok: 0.6757961783439491
dev_label=P_precision_tok: 0.9298167188198481
dev_label=P_recall_tok: 0.6475716064757161
dev_label=P_f-score_tok: 0.7634428335474399
dev_precision_macro_tok: 0.8844008237176384
dev_recall_macro_tok: 0.7336758459031675
dev_f-score_macro_tok: 0.7921819213838225
dev_precision_micro_tok: 0.8957412804362133
dev_recall_micro_tok: 0.8957412804362133
dev_f-score_micro_tok: 0.8957412804362133
dev_time: 8.355979681015015
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0306    0.0579       229
           N     0.6811    0.6986    0.6897       428
           P     0.6071    0.8874    0.7210       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.6089    0.5389    0.4895      1101
weighted avg     0.6216    0.6358    0.5709      1101

F1-macro sent:  0.4895124888974624
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8964    0.9821    0.9373     16205
           N     0.8270    0.5714    0.6758      1857
           P     0.9298    0.6476    0.7634      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8844    0.7337    0.7922     21274
weighted avg     0.8954    0.8957    0.8882     21274

F1-macro tok:  0.7921819213838225
F1-micro tok:  0.8957412804362133
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 0.810000
train_cost_sum: 316994.2717285156
train_cost_avg: 37.101389481333754
train_count_sent: 8544.0
train_total_correct_sent: 5666.0
train_accuracy_sent: 0.6631554307116105
train_count_tok: 163566.0
train_total_correct_tok: 145648.0
train_accuracy_tok: 0.8904540063338346
train_label=O_precision_sent: 0.4595744680851064
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11619150080688544
train_label=N_precision_sent: 0.630653855167565
train_label=N_recall_sent: 0.8129909365558913
train_label=N_f-score_sent: 0.7103075095684307
train_label=P_precision_sent: 0.7093023255813954
train_label=P_recall_sent: 0.7941828254847645
train_label=P_f-score_sent: 0.7493465760585468
train_precision_macro_sent: 0.5998435496113556
train_recall_macro_sent: 0.5578920750316143
train_f-score_macro_sent: 0.525281862144621
train_precision_micro_sent: 0.6631554307116105
train_recall_micro_sent: 0.6631554307116105
train_f-score_micro_sent: 0.6631554307116105
train_label=O_precision_tok: 0.9018039965922848
train_label=O_recall_tok: 0.9704616918783726
train_label=O_f-score_tok: 0.9348739739929735
train_label=N_precision_tok: 0.7843629516721958
train_label=N_recall_tok: 0.6159695817490495
train_label=N_f-score_tok: 0.6900414119503057
train_label=P_precision_tok: 0.872412495295446
train_label=P_recall_tok: 0.6485989527121557
train_label=P_f-score_tok: 0.7440388848129127
train_precision_macro_tok: 0.8528598145199755
train_recall_macro_tok: 0.745010075446526
train_f-score_macro_tok: 0.7896514235853974
train_precision_micro_tok: 0.8904540063338346
train_recall_micro_tok: 0.8904540063338346
train_f-score_micro_tok: 0.8904540063338346
train_time: 146.12788438796997
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4596    0.0665    0.1162      1624
           N     0.6307    0.8130    0.7103      3310
           P     0.7093    0.7942    0.7493      3610

   micro avg     0.6632    0.6632    0.6632      8544
   macro avg     0.5998    0.5579    0.5253      8544
weighted avg     0.6314    0.6632    0.6139      8544

F1-macro sent:  0.525281862144621
F1-micro sent:  0.6631554307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9705    0.9349    124347
           N     0.7844    0.6160    0.6900     14202
           P     0.8724    0.6486    0.7440     25017

   micro avg     0.8905    0.8905    0.8905    163566
   macro avg     0.8529    0.7450    0.7897    163566
weighted avg     0.8871    0.8905    0.8844    163566

F1-macro tok:  0.7896514235853974
F1-micro tok:  0.8904540063338346
**************************************************
dev_cost_sum: 42900.56658935547
dev_cost_avg: 38.965092270077626
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.631578947368421
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0967741935483871
dev_label=N_precision_sent: 0.5955766192733017
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7106503298774741
dev_label=P_precision_sent: 0.7282850779510023
dev_label=P_recall_sent: 0.7364864864864865
dev_label=P_f-score_sent: 0.7323628219484883
dev_precision_macro_sent: 0.651813548197575
dev_recall_macro_sent: 0.5565764515689015
dev_f-score_macro_sent: 0.5132624484581165
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9024890357122515
dev_label=O_recall_tok: 0.9777846343721074
dev_label=O_f-score_tok: 0.9386292281262958
dev_label=N_precision_tok: 0.808029197080292
dev_label=N_recall_tok: 0.5961227786752827
dev_label=N_f-score_tok: 0.6860861481251936
dev_label=P_precision_tok: 0.9126544524925436
dev_label=P_recall_tok: 0.6668742216687422
dev_label=P_f-score_tok: 0.7706422018348624
dev_precision_macro_tok: 0.8743908950950291
dev_recall_macro_tok: 0.7469272115720441
dev_f-score_macro_tok: 0.7984525260287839
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 8.379463195800781
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6316    0.0524    0.0968       229
           N     0.5956    0.8808    0.7107       428
           P     0.7283    0.7365    0.7324       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6518    0.5566    0.5133      1101
weighted avg     0.6566    0.6503    0.5917      1101

F1-macro sent:  0.5132624484581165
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9778    0.9386     16205
           N     0.8080    0.5961    0.6861      1857
           P     0.9127    0.6669    0.7706      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8744    0.7469    0.7985     21274
weighted avg     0.8958    0.8975    0.8912     21274

F1-macro tok:  0.7984525260287839
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 0.810000
train_cost_sum: 315402.5278930664
train_cost_avg: 36.91508987512481
train_count_sent: 8544.0
train_total_correct_sent: 5746.0
train_accuracy_sent: 0.6725187265917603
train_count_tok: 163566.0
train_total_correct_tok: 145929.0
train_accuracy_tok: 0.8921719672792634
train_label=O_precision_sent: 0.45416666666666666
train_label=O_recall_sent: 0.06711822660098522
train_label=O_f-score_sent: 0.1169527896995708
train_label=N_precision_sent: 0.6380797017012352
train_label=N_recall_sent: 0.827190332326284
train_label=N_f-score_sent: 0.7204315221681358
train_label=P_precision_sent: 0.7224021928731622
train_label=P_recall_sent: 0.8030470914127423
train_label=P_f-score_sent: 0.7605929424111242
train_precision_macro_sent: 0.6048828537470213
train_recall_macro_sent: 0.5657852167800038
train_f-score_macro_sent: 0.5326590847596102
train_precision_micro_sent: 0.6725187265917603
train_recall_micro_sent: 0.6725187265917603
train_f-score_micro_sent: 0.6725187265917603
train_label=O_precision_tok: 0.9033797990227989
train_label=O_recall_tok: 0.9709442125664471
train_label=O_f-score_tok: 0.9359442467654286
train_label=N_precision_tok: 0.783007934385308
train_label=N_recall_tok: 0.6184340233769892
train_label=N_f-score_tok: 0.6910578700971715
train_label=P_precision_tok: 0.8775532028660037
train_label=P_recall_tok: 0.656033896950074
train_label=P_f-score_tok: 0.7507948489215215
train_precision_macro_tok: 0.854646978758037
train_recall_macro_tok: 0.7484707109645035
train_f-score_macro_tok: 0.7925989885947072
train_precision_micro_tok: 0.8921719672792634
train_recall_micro_tok: 0.8921719672792634
train_f-score_micro_tok: 0.8921719672792634
train_time: 170.7092423439026
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4542    0.0671    0.1170      1624
           N     0.6381    0.8272    0.7204      3310
           P     0.7224    0.8030    0.7606      3610

   micro avg     0.6725    0.6725    0.6725      8544
   macro avg     0.6049    0.5658    0.5327      8544
weighted avg     0.6388    0.6725    0.6227      8544

F1-macro sent:  0.5326590847596102
F1-micro sent:  0.6725187265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9034    0.9709    0.9359    124347
           N     0.7830    0.6184    0.6911     14202
           P     0.8776    0.6560    0.7508     25017

   micro avg     0.8922    0.8922    0.8922    163566
   macro avg     0.8546    0.7485    0.7926    163566
weighted avg     0.8890    0.8922    0.8864    163566

F1-macro tok:  0.7925989885947072
F1-micro tok:  0.8921719672792634
**************************************************
dev_cost_sum: 42812.43768310547
dev_cost_avg: 38.885047850232034
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6790890269151139
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7200878155872668
dev_label=P_precision_sent: 0.6351791530944625
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7372400756143667
dev_precision_macro_sent: 0.6880893933365254
dev_recall_macro_sent: 0.5526113184155057
dev_f-score_macro_sent: 0.49435965472100224
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9065447435012652
dev_label=O_recall_tok: 0.9727244677568652
dev_label=O_f-score_tok: 0.9384693239663026
dev_label=N_precision_tok: 0.7918994413407822
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6895712982669505
dev_label=P_precision_tok: 0.8903830480847595
dev_label=P_recall_tok: 0.6802615193026152
dev_label=P_f-score_tok: 0.7712672079068126
dev_precision_macro_tok: 0.8629424109756023
dev_recall_macro_tok: 0.7545494485674844
dev_f-score_macro_tok: 0.7997692767133552
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 11.720866203308105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6791    0.7664    0.7201       428
           P     0.6352    0.8784    0.7372       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6881    0.5526    0.4944      1101
weighted avg     0.6761    0.6549    0.5826      1101

F1-macro sent:  0.49435965472100224
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9727    0.9385     16205
           N     0.7919    0.6107    0.6896      1857
           P     0.8904    0.6803    0.7713      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8629    0.7545    0.7998     21274
weighted avg     0.8941    0.8970    0.8915     21274

F1-macro tok:  0.7997692767133552
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 313836.3303222656
train_cost_avg: 36.73178023434757
train_count_sent: 8544.0
train_total_correct_sent: 5712.0
train_accuracy_sent: 0.6685393258426966
train_count_tok: 163566.0
train_total_correct_tok: 146177.0
train_accuracy_tok: 0.8936881748040546
train_label=O_precision_sent: 0.4943820224719101
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.09766925638179799
train_label=N_precision_sent: 0.6335752751112151
train_label=N_recall_sent: 0.817522658610272
train_label=N_f-score_sent: 0.7138899881282152
train_label=P_precision_sent: 0.7125763125763126
train_label=P_recall_sent: 0.8083102493074792
train_label=P_f-score_sent: 0.7574302401038286
train_precision_macro_sent: 0.6135112033864792
train_recall_macro_sent: 0.5600067000119926
train_f-score_macro_sent: 0.5229964948712806
train_precision_micro_sent: 0.6685393258426966
train_recall_micro_sent: 0.6685393258426966
train_f-score_micro_sent: 0.6685393258426966
train_label=O_precision_tok: 0.9051621998590218
train_label=O_recall_tok: 0.9707270782568136
train_label=O_f-score_tok: 0.9367988482776551
train_label=N_precision_tok: 0.7882571732199788
train_label=N_recall_tok: 0.6267427122940431
train_label=N_f-score_tok: 0.6982819486938103
train_label=P_precision_tok: 0.8757399577167019
train_label=P_recall_tok: 0.6623096294519727
train_label=P_f-score_tok: 0.7542162641964631
train_precision_macro_tok: 0.8563864435985674
train_recall_macro_tok: 0.7532598066676098
train_f-score_macro_tok: 0.7964323537226429
train_precision_micro_tok: 0.8936881748040546
train_recall_micro_tok: 0.8936881748040546
train_f-score_micro_tok: 0.8936881748040547
train_time: 238.5357596874237
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4944    0.0542    0.0977      1624
           N     0.6336    0.8175    0.7139      3310
           P     0.7126    0.8083    0.7574      3610

   micro avg     0.6685    0.6685    0.6685      8544
   macro avg     0.6135    0.5600    0.5230      8544
weighted avg     0.6405    0.6685    0.6152      8544

F1-macro sent:  0.5229964948712806
F1-micro sent:  0.6685393258426966
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9052    0.9707    0.9368    124347
           N     0.7883    0.6267    0.6983     14202
           P     0.8757    0.6623    0.7542     25017

   micro avg     0.8937    0.8937    0.8937    163566
   macro avg     0.8564    0.7533    0.7964    163566
weighted avg     0.8905    0.8937    0.8882    163566

F1-macro tok:  0.7964323537226429
F1-micro tok:  0.8936881748040547
**************************************************
dev_cost_sum: 42752.39929199219
dev_cost_avg: 38.8305170681128
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19110.0
dev_accuracy_tok: 0.8982795901099934
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.7018779342723005
dev_label=N_recall_sent: 0.6985981308411215
dev_label=N_f-score_sent: 0.7002341920374707
dev_label=P_precision_sent: 0.6059701492537314
dev_label=P_recall_sent: 0.9144144144144144
dev_label=P_f-score_sent: 0.7289048473967684
dev_precision_macro_sent: 0.7026160278420107
dev_recall_macro_sent: 0.5434932647212777
dev_f-score_macro_sent: 0.4877756912074244
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.9040251213245789
dev_label=O_recall_tok: 0.9771058315334773
dev_label=O_f-score_tok: 0.9391459074733096
dev_label=N_precision_tok: 0.8192592592592592
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6897411911443717
dev_label=P_precision_tok: 0.9007887090078871
dev_label=P_recall_tok: 0.6755915317559154
dev_label=P_f-score_tok: 0.7721046077210462
dev_precision_macro_tok: 0.8746910298639085
dev_recall_macro_tok: 0.7494272130009696
dev_f-score_macro_tok: 0.8003305687795758
dev_precision_micro_tok: 0.8982795901099934
dev_recall_micro_tok: 0.8982795901099934
dev_f-score_micro_tok: 0.8982795901099935
dev_time: 15.23413634300232
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.7019    0.6986    0.7002       428
           P     0.6060    0.9144    0.7289       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.7026    0.5435    0.4878      1101
weighted avg     0.6836    0.6440    0.5733      1101

F1-macro sent:  0.4877756912074244
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9040    0.9771    0.9391     16205
           N     0.8193    0.5956    0.6897      1857
           P     0.9008    0.6756    0.7721      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8747    0.7494    0.8003     21274
weighted avg     0.8961    0.8983    0.8922     21274

F1-macro tok:  0.8003305687795758
F1-micro tok:  0.8982795901099935
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 312277.9710083008
train_cost_avg: 36.54938799254457
train_count_sent: 8544.0
train_total_correct_sent: 5778.0
train_accuracy_sent: 0.6762640449438202
train_count_tok: 163566.0
train_total_correct_tok: 146468.0
train_accuracy_tok: 0.8954672731496766
train_label=O_precision_sent: 0.5111111111111111
train_label=O_recall_sent: 0.05665024630541872
train_label=O_f-score_sent: 0.10199556541019955
train_label=N_precision_sent: 0.6482725527831094
train_label=N_recall_sent: 0.8163141993957704
train_label=N_f-score_sent: 0.7226531158063654
train_label=P_precision_sent: 0.7111534795042898
train_label=P_recall_sent: 0.8265927977839335
train_label=P_f-score_sent: 0.7645400973610043
train_precision_macro_sent: 0.6235123811328368
train_recall_macro_sent: 0.5665190811617076
train_f-score_macro_sent: 0.5297295928591897
train_precision_micro_sent: 0.6762640449438202
train_recall_micro_sent: 0.6762640449438202
train_f-score_micro_sent: 0.6762640449438202
train_label=O_precision_tok: 0.9066529564525572
train_label=O_recall_tok: 0.9714508592889254
train_label=O_f-score_tok: 0.9379340867532932
train_label=N_precision_tok: 0.7922318125770653
train_label=N_recall_tok: 0.6333614983805098
train_label=N_f-score_tok: 0.7039442792299265
train_label=P_precision_tok: 0.8787016545473706
train_label=P_recall_tok: 0.6665867210296998
train_label=P_f-score_tok: 0.7580861461529719
train_precision_macro_tok: 0.8591954745256644
train_recall_macro_tok: 0.757133026233045
train_f-score_macro_tok: 0.7999881707120639
train_precision_micro_tok: 0.8954672731496766
train_recall_micro_tok: 0.8954672731496766
train_f-score_micro_tok: 0.8954672731496766
train_time: 247.0960886478424
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5111    0.0567    0.1020      1624
           N     0.6483    0.8163    0.7227      3310
           P     0.7112    0.8266    0.7645      3610

   micro avg     0.6763    0.6763    0.6763      8544
   macro avg     0.6235    0.5665    0.5297      8544
weighted avg     0.6488    0.6763    0.6224      8544

F1-macro sent:  0.5297295928591897
F1-micro sent:  0.6762640449438202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9067    0.9715    0.9379    124347
           N     0.7922    0.6334    0.7039     14202
           P     0.8787    0.6666    0.7581     25017

   micro avg     0.8955    0.8955    0.8955    163566
   macro avg     0.8592    0.7571    0.8000    163566
weighted avg     0.8924    0.8955    0.8901    163566

F1-macro tok:  0.7999881707120639
F1-micro tok:  0.8954672731496766
**************************************************
dev_cost_sum: 42603.65539550781
dev_cost_avg: 38.69541816122417
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19137.0
dev_accuracy_tok: 0.8995487449468835
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06584362139917695
dev_label=N_precision_sent: 0.6526508226691042
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7323076923076923
dev_label=P_precision_sent: 0.6759259259259259
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.741869918699187
dev_precision_macro_sent: 0.6333351066745339
dev_recall_macro_sent: 0.5637062398071254
dev_f-score_macro_sent: 0.5133404108020188
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9057813394390384
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9398069784706756
dev_label=N_precision_tok: 0.821060382916053
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.6936236391912908
dev_label=P_precision_tok: 0.8986099754701553
dev_label=P_recall_tok: 0.6843088418430884
dev_label=P_f-score_tok: 0.7769529869211735
dev_precision_macro_tok: 0.8751505659417488
dev_recall_macro_tok: 0.7537427940854383
dev_f-score_macro_tok: 0.8034612015277133
dev_precision_micro_tok: 0.8995487449468835
dev_recall_micro_tok: 0.8995487449468835
dev_f-score_micro_tok: 0.8995487449468835
dev_time: 14.150075197219849
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0349    0.0658       229
           N     0.6527    0.8341    0.7323       428
           P     0.6759    0.8221    0.7419       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6333    0.5637    0.5133      1101
weighted avg     0.6451    0.6630    0.5975      1101

F1-macro sent:  0.5133404108020188
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9765    0.9398     16205
           N     0.8211    0.6004    0.6936      1857
           P     0.8986    0.6843    0.7770      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8752    0.7537    0.8035     21274
weighted avg     0.8973    0.8995    0.8937     21274

F1-macro tok:  0.8034612015277133
F1-micro tok:  0.8995487449468835
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.656100
train_cost_sum: 310636.1280517578
train_cost_avg: 36.35722472515892
train_count_sent: 8544.0
train_total_correct_sent: 5802.0
train_accuracy_sent: 0.6790730337078652
train_count_tok: 163566.0
train_total_correct_tok: 146762.0
train_accuracy_tok: 0.8972647127153565
train_label=O_precision_sent: 0.5091743119266054
train_label=O_recall_sent: 0.06834975369458128
train_label=O_f-score_sent: 0.12052117263843647
train_label=N_precision_sent: 0.6534077128304633
train_label=N_recall_sent: 0.8138972809667674
train_label=N_f-score_sent: 0.7248755549576215
train_label=P_precision_sent: 0.7130620985010707
train_label=P_recall_sent: 0.8301939058171746
train_label=P_f-score_sent: 0.7671829002943812
train_precision_macro_sent: 0.6252147077527132
train_recall_macro_sent: 0.5708136468261744
train_f-score_macro_sent: 0.5375265426301463
train_precision_micro_sent: 0.6790730337078652
train_recall_micro_sent: 0.6790730337078652
train_f-score_micro_sent: 0.6790730337078652
train_label=O_precision_tok: 0.9083017024315081
train_label=O_recall_tok: 0.9718368758393849
train_label=O_f-score_tok: 0.9389957729843973
train_label=N_precision_tok: 0.7975971235639744
train_label=N_recall_tok: 0.6404027601746233
train_label=N_f-score_tok: 0.7104081234133958
train_label=P_precision_tok: 0.8799037556229731
train_label=P_recall_tok: 0.6724227525282808
train_label=P_f-score_tok: 0.7622974963181148
train_precision_macro_tok: 0.8619341938728186
train_recall_macro_tok: 0.7615541295140963
train_f-score_macro_tok: 0.8039004642386359
train_precision_micro_tok: 0.8972647127153565
train_recall_micro_tok: 0.8972647127153565
train_f-score_micro_tok: 0.8972647127153565
train_time: 250.7151255607605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5092    0.0683    0.1205      1624
           N     0.6534    0.8139    0.7249      3310
           P     0.7131    0.8302    0.7672      3610

   micro avg     0.6791    0.6791    0.6791      8544
   macro avg     0.6252    0.5708    0.5375      8544
weighted avg     0.6512    0.6791    0.6279      8544

F1-macro sent:  0.5375265426301463
F1-micro sent:  0.6790730337078652
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9718    0.9390    124347
           N     0.7976    0.6404    0.7104     14202
           P     0.8799    0.6724    0.7623     25017

   micro avg     0.8973    0.8973    0.8973    163566
   macro avg     0.8619    0.7616    0.8039    163566
weighted avg     0.8943    0.8973    0.8921    163566

F1-macro tok:  0.8039004642386359
F1-micro tok:  0.8972647127153565
**************************************************
dev_cost_sum: 42526.20031738281
dev_cost_avg: 38.625068408158775
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19114.0
dev_accuracy_tok: 0.898467613048792
dev_label=O_precision_sent: 0.5454545454545454
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09561752988047809
dev_label=N_precision_sent: 0.6775510204081633
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7233115468409586
dev_label=P_precision_sent: 0.6485568760611206
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7395934172313648
dev_precision_macro_sent: 0.6238541473079432
dev_recall_macro_sent: 0.5628210138882301
dev_f-score_macro_sent: 0.5195074979842672
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9033857729138167
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9392278289727104
dev_label=N_precision_tok: 0.8320552147239264
dev_label=N_recall_tok: 0.5842757135164244
dev_label=N_f-score_tok: 0.6864916165770327
dev_label=P_precision_tok: 0.8985985160758451
dev_label=P_recall_tok: 0.6787048567870486
dev_label=P_f-score_tok: 0.7733238737140831
dev_precision_macro_tok: 0.8780131679045294
dev_recall_macro_tok: 0.7470040140238153
dev_f-score_macro_tok: 0.7996811064212753
dev_precision_micro_tok: 0.898467613048792
dev_recall_micro_tok: 0.898467613048792
dev_f-score_micro_tok: 0.8984676130487919
dev_time: 13.878288984298706
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.0524    0.0956       229
           N     0.6776    0.7757    0.7233       428
           P     0.6486    0.8604    0.7396       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.6239    0.5628    0.5195      1101
weighted avg     0.6384    0.6594    0.5993      1101

F1-macro sent:  0.5195074979842672
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9034    0.9780    0.9392     16205
           N     0.8321    0.5843    0.6865      1857
           P     0.8986    0.6787    0.7733      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8780    0.7470    0.7997     21274
weighted avg     0.8964    0.8985    0.8921     21274

F1-macro tok:  0.7996811064212753
F1-micro tok:  0.8984676130487919
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.656100
train_cost_sum: 309585.7633666992
train_cost_avg: 36.23428878355562
train_count_sent: 8544.0
train_total_correct_sent: 5858.0
train_accuracy_sent: 0.68562734082397
train_count_tok: 163566.0
train_total_correct_tok: 146737.0
train_accuracy_tok: 0.8971118692148735
train_label=O_precision_sent: 0.5219298245614035
train_label=O_recall_sent: 0.07327586206896551
train_label=O_f-score_sent: 0.12850971922246218
train_label=N_precision_sent: 0.645751331326696
train_label=N_recall_sent: 0.8425981873111782
train_label=N_f-score_sent: 0.7311574256127933
train_label=P_precision_sent: 0.7380535401551164
train_label=P_recall_sent: 0.817174515235457
train_label=P_f-score_sent: 0.7756014197449717
train_precision_macro_sent: 0.6352448986810719
train_recall_macro_sent: 0.5776828548718669
train_f-score_macro_sent: 0.5450895215267424
train_precision_micro_sent: 0.68562734082397
train_recall_micro_sent: 0.68562734082397
train_f-score_micro_sent: 0.68562734082397
train_label=O_precision_tok: 0.9084370885837878
train_label=O_recall_tok: 0.9711050527958053
train_label=O_f-score_tok: 0.9387263285549923
train_label=N_precision_tok: 0.7975206611570248
train_label=N_recall_tok: 0.638712857344036
train_label=N_f-score_tok: 0.7093368783234282
train_label=P_precision_tok: 0.8777702807909897
train_label=P_recall_tok: 0.6760203061917895
train_label=P_f-score_tok: 0.7637973082829013
train_precision_macro_tok: 0.8612426768439342
train_recall_macro_tok: 0.7619460721105437
train_f-score_macro_tok: 0.8039535050537738
train_precision_micro_tok: 0.8971118692148735
train_recall_micro_tok: 0.8971118692148735
train_f-score_micro_tok: 0.8971118692148736
train_time: 250.05559611320496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5219    0.0733    0.1285      1624
           N     0.6458    0.8426    0.7312      3310
           P     0.7381    0.8172    0.7756      3610

   micro avg     0.6856    0.6856    0.6856      8544
   macro avg     0.6352    0.5777    0.5451      8544
weighted avg     0.6612    0.6856    0.6354      8544

F1-macro sent:  0.5450895215267424
F1-micro sent:  0.68562734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9711    0.9387    124347
           N     0.7975    0.6387    0.7093     14202
           P     0.8778    0.6760    0.7638     25017

   micro avg     0.8971    0.8971    0.8971    163566
   macro avg     0.8612    0.7619    0.8040    163566
weighted avg     0.8941    0.8971    0.8921    163566

F1-macro tok:  0.8039535050537738
F1-micro tok:  0.8971118692148736
**************************************************
dev_cost_sum: 42501.20361328125
dev_cost_avg: 38.60236477137261
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19115.0
dev_accuracy_tok: 0.8985146187834916
dev_label=O_precision_sent: 0.5909090909090909
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10358565737051793
dev_label=N_precision_sent: 0.6517690875232774
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7253886010362695
dev_label=P_precision_sent: 0.6734317343173432
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7403651115618661
dev_precision_macro_sent: 0.6387033042499038
dev_recall_macro_sent: 0.5655325467899438
dev_f-score_macro_sent: 0.5231131233228845
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9056571330314668
dev_label=O_recall_tok: 0.9750694230175871
dev_label=O_f-score_tok: 0.9390823725187211
dev_label=N_precision_tok: 0.8155410312273057
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.6944959802102659
dev_label=P_precision_tok: 0.8942857142857142
dev_label=P_recall_tok: 0.6821295143212951
dev_label=P_f-score_tok: 0.7739314729777464
dev_precision_macro_tok: 0.8718279595148289
dev_recall_macro_tok: 0.7539792544674752
dev_f-score_macro_tok: 0.8025032752355777
dev_precision_micro_tok: 0.8985146187834916
dev_recall_micro_tok: 0.8985146187834916
dev_f-score_micro_tok: 0.8985146187834916
dev_time: 15.445149421691895
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5909    0.0568    0.1036       229
           N     0.6518    0.8178    0.7254       428
           P     0.6734    0.8221    0.7404       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6387    0.5655    0.5231      1101
weighted avg     0.6478    0.6612    0.6021      1101

F1-macro sent:  0.5231131233228845
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9057    0.9751    0.9391     16205
           N     0.8155    0.6047    0.6945      1857
           P     0.8943    0.6821    0.7739      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8718    0.7540    0.8025     21274
weighted avg     0.8961    0.8985    0.8928     21274

F1-macro tok:  0.8025032752355777
F1-micro tok:  0.8985146187834916
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 0.656100
train_cost_sum: 308360.89587402344
train_cost_avg: 36.09092882420686
train_count_sent: 8544.0
train_total_correct_sent: 5821.0
train_accuracy_sent: 0.6812968164794008
train_count_tok: 163566.0
train_total_correct_tok: 147128.0
train_accuracy_tok: 0.8995023415624274
train_label=O_precision_sent: 0.5121951219512195
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11481683980317113
train_label=N_precision_sent: 0.6497980517937753
train_label=N_recall_sent: 0.8262839879154078
train_label=N_f-score_sent: 0.7274903577603404
train_label=P_precision_sent: 0.7217917675544794
train_label=P_recall_sent: 0.8257617728531856
train_label=P_f-score_sent: 0.7702842377260982
train_precision_macro_sent: 0.6279283137664914
train_recall_macro_sent: 0.5722336443941288
train_f-score_macro_sent: 0.5375304784298699
train_precision_micro_sent: 0.6812968164794008
train_recall_micro_sent: 0.6812968164794008
train_f-score_micro_sent: 0.6812968164794008
train_label=O_precision_tok: 0.9110600120627261
train_label=O_recall_tok: 0.9718207918164491
train_label=O_f-score_tok: 0.9404600232696595
train_label=N_precision_tok: 0.7964815453604691
train_label=N_recall_tok: 0.6503309393043233
train_label=N_f-score_tok: 0.7160244980231025
train_label=P_precision_tok: 0.8819968960165546
train_label=P_recall_tok: 0.6814965823240197
train_label=P_f-score_tok: 0.7688907930637924
train_precision_macro_tok: 0.8631794844799167
train_recall_macro_tok: 0.7678827711482641
train_f-score_macro_tok: 0.8084584381188514
train_precision_micro_tok: 0.8995023415624274
train_recall_micro_tok: 0.8995023415624274
train_f-score_micro_tok: 0.8995023415624274
train_time: 250.27093529701233
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5122    0.0647    0.1148      1624
           N     0.6498    0.8263    0.7275      3310
           P     0.7218    0.8258    0.7703      3610

   micro avg     0.6813    0.6813    0.6813      8544
   macro avg     0.6279    0.5722    0.5375      8544
weighted avg     0.6541    0.6813    0.6291      8544

F1-macro sent:  0.5375304784298699
F1-micro sent:  0.6812968164794008
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9111    0.9718    0.9405    124347
           N     0.7965    0.6503    0.7160     14202
           P     0.8820    0.6815    0.7689     25017

   micro avg     0.8995    0.8995    0.8995    163566
   macro avg     0.8632    0.7679    0.8085    163566
weighted avg     0.8967    0.8995    0.8947    163566

F1-macro tok:  0.8084584381188514
F1-micro tok:  0.8995023415624274
**************************************************
dev_cost_sum: 42359.38720703125
dev_cost_avg: 38.473557862880334
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19156.0
dev_accuracy_tok: 0.9004418539061766
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0823045267489712
dev_label=N_precision_sent: 0.64
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7337986041874377
dev_label=P_precision_sent: 0.6953125
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7447698744769874
dev_precision_macro_sent: 0.6831994047619047
dev_recall_macro_sent: 0.5684276693948979
dev_f-score_macro_sent: 0.5202910018044654
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9117391556147565
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.9406668260038241
dev_label=N_precision_tok: 0.7973901098901099
dev_label=N_recall_tok: 0.6252019386106623
dev_label=N_f-score_tok: 0.7008753395713855
dev_label=P_precision_tok: 0.8827910623284986
dev_label=P_recall_tok: 0.701120797011208
dev_label=P_f-score_tok: 0.7815373937185494
dev_precision_macro_tok: 0.8639734426111216
dev_recall_macro_tok: 0.765937672133136
dev_f-score_macro_tok: 0.807693186431253
dev_precision_micro_tok: 0.9004418539061766
dev_recall_micro_tok: 0.9004418539061766
dev_f-score_micro_tok: 0.9004418539061767
dev_time: 15.34468150138855
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0437    0.0823       229
           N     0.6400    0.8598    0.7338       428
           P     0.6953    0.8018    0.7448       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6832    0.5684    0.5203      1101
weighted avg     0.6778    0.6667    0.6027      1101

F1-macro sent:  0.5202910018044654
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9117    0.9715    0.9407     16205
           N     0.7974    0.6252    0.7009      1857
           P     0.8828    0.7011    0.7815      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8640    0.7659    0.8077     21274
weighted avg     0.8974    0.9004    0.8957     21274

F1-macro tok:  0.807693186431253
F1-micro tok:  0.9004418539061767
**************************************************
Best epoch: 23
**************************************************

EPOCH: 25
Learning rate: 0.656100
train_cost_sum: 307039.7317504883
train_cost_avg: 35.93629819177063
train_count_sent: 8544.0
train_total_correct_sent: 5856.0
train_accuracy_sent: 0.6853932584269663
train_count_tok: 163566.0
train_total_correct_tok: 147291.0
train_accuracy_tok: 0.9004988811855764
train_label=O_precision_sent: 0.4859437751004016
train_label=O_recall_sent: 0.07450738916256158
train_label=O_f-score_sent: 0.12920448478376936
train_label=N_precision_sent: 0.6625886958649376
train_label=N_recall_sent: 0.8181268882175227
train_label=N_f-score_sent: 0.7321887251588483
train_label=P_precision_sent: 0.7193441064638784
train_label=P_recall_sent: 0.8385041551246537
train_label=P_f-score_sent: 0.7743668457405987
train_precision_macro_sent: 0.6226255258097392
train_recall_macro_sent: 0.577046144168246
train_f-score_macro_sent: 0.5452533518944054
train_precision_micro_sent: 0.6853932584269663
train_recall_micro_sent: 0.6853932584269663
train_f-score_micro_sent: 0.6853932584269663
train_label=O_precision_tok: 0.912029036907358
train_label=O_recall_tok: 0.9719816320458073
train_label=O_f-score_tok: 0.9410514349782768
train_label=N_precision_tok: 0.802610114192496
train_label=N_recall_tok: 0.6582171525137305
train_label=N_f-score_tok: 0.7232774962280939
train_label=P_precision_tok: 0.8805031446540881
train_label=P_recall_tok: 0.6827357396970061
train_label=P_f-score_tok: 0.7691095350669818
train_precision_macro_tok: 0.8650474319179807
train_recall_macro_tok: 0.7709781747521812
train_f-score_macro_tok: 0.8111461554244509
train_precision_micro_tok: 0.9004988811855764
train_recall_micro_tok: 0.9004988811855764
train_f-score_micro_tok: 0.9004988811855764
train_time: 220.7424602508545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4859    0.0745    0.1292      1624
           N     0.6626    0.8181    0.7322      3310
           P     0.7193    0.8385    0.7744      3610

   micro avg     0.6854    0.6854    0.6854      8544
   macro avg     0.6226    0.5770    0.5453      8544
weighted avg     0.6530    0.6854    0.6354      8544

F1-macro sent:  0.5452533518944054
F1-micro sent:  0.6853932584269663
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9120    0.9720    0.9411    124347
           N     0.8026    0.6582    0.7233     14202
           P     0.8805    0.6827    0.7691     25017

   micro avg     0.9005    0.9005    0.9005    163566
   macro avg     0.8650    0.7710    0.8111    163566
weighted avg     0.8977    0.9005    0.8958    163566

F1-macro tok:  0.8111461554244509
F1-micro tok:  0.9004988811855764
**************************************************
dev_cost_sum: 42327.644104003906
dev_cost_avg: 38.44472670663389
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19162.0
dev_accuracy_tok: 0.9007238883143743
dev_label=O_precision_sent: 0.5294117647058824
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07317073170731707
dev_label=N_precision_sent: 0.6485507246376812
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7306122448979593
dev_label=P_precision_sent: 0.6823308270676691
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7438524590163934
dev_precision_macro_sent: 0.6200977721370775
dev_recall_macro_sent: 0.5644391585806923
dev_f-score_macro_sent: 0.5158784785405566
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9042250313176176
dev_label=O_recall_tok: 0.9799444615859303
dev_label=O_f-score_tok: 0.940563271833447
dev_label=N_precision_tok: 0.814388489208633
dev_label=N_recall_tok: 0.6095853527194399
dev_label=N_f-score_tok: 0.697259008315368
dev_label=P_precision_tok: 0.9259259259259259
dev_label=P_recall_tok: 0.6693648816936488
dev_label=P_f-score_tok: 0.7770148174918685
dev_precision_macro_tok: 0.8815131488173922
dev_recall_macro_tok: 0.7529648986663396
dev_f-score_macro_tok: 0.8049456992135612
dev_precision_micro_tok: 0.9007238883143743
dev_recall_micro_tok: 0.9007238883143743
dev_f-score_micro_tok: 0.9007238883143743
dev_time: 11.97298002243042
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0393    0.0732       229
           N     0.6486    0.8364    0.7306       428
           P     0.6823    0.8176    0.7439       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6201    0.5644    0.5159      1101
weighted avg     0.6374    0.6630    0.5992      1101

F1-macro sent:  0.5158784785405566
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9799    0.9406     16205
           N     0.8144    0.6096    0.6973      1857
           P     0.9259    0.6694    0.7770      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8815    0.7530    0.8049     21274
weighted avg     0.8997    0.9007    0.8946     21274

F1-macro tok:  0.8049456992135612
F1-micro tok:  0.9007238883143743
**************************************************
Best epoch: 23
**************************************************

EPOCH: 26
Learning rate: 0.656100
train_cost_sum: 305974.08404541016
train_cost_avg: 35.81157350718752
train_count_sent: 8544.0
train_total_correct_sent: 5873.0
train_accuracy_sent: 0.6873829588014981
train_count_tok: 163566.0
train_total_correct_tok: 147484.0
train_accuracy_tok: 0.9016788330093051
train_label=O_precision_sent: 0.49034749034749037
train_label=O_recall_sent: 0.07820197044334976
train_label=O_f-score_sent: 0.13489113117365906
train_label=N_precision_sent: 0.6648910411622276
train_label=N_recall_sent: 0.829607250755287
train_label=N_f-score_sent: 0.7381720430107526
train_label=P_precision_sent: 0.7220216606498195
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.77269800386349
train_precision_macro_sent: 0.6257533973865125
train_recall_macro_sent: 0.5796113839821864
train_f-score_macro_sent: 0.5485870593493005
train_precision_micro_sent: 0.6873829588014981
train_recall_micro_sent: 0.6873829588014981
train_f-score_micro_sent: 0.6873829588014981
train_label=O_precision_tok: 0.91337183809855
train_label=O_recall_tok: 0.9716277835412194
train_label=O_f-score_tok: 0.9415996103263516
train_label=N_precision_tok: 0.805298353909465
train_label=N_recall_tok: 0.6613857203210816
train_label=N_f-score_tok: 0.7262816051960104
train_label=P_precision_tok: 0.8801467590705259
train_label=P_recall_tok: 0.6904105208458249
train_label=P_f-score_tok: 0.7738177908200982
train_precision_macro_tok: 0.8662723170261803
train_recall_macro_tok: 0.7744746749027085
train_f-score_macro_tok: 0.8138996687808201
train_precision_micro_tok: 0.9016788330093051
train_recall_micro_tok: 0.9016788330093051
train_f-score_micro_tok: 0.9016788330093051
train_time: 197.44664525985718
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4903    0.0782    0.1349      1624
           N     0.6649    0.8296    0.7382      3310
           P     0.7220    0.8310    0.7727      3610

   micro avg     0.6874    0.6874    0.6874      8544
   macro avg     0.6258    0.5796    0.5486      8544
weighted avg     0.6559    0.6874    0.6381      8544

F1-macro sent:  0.5485870593493005
F1-micro sent:  0.6873829588014981
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9134    0.9716    0.9416    124347
           N     0.8053    0.6614    0.7263     14202
           P     0.8801    0.6904    0.7738     25017

   micro avg     0.9017    0.9017    0.9017    163566
   macro avg     0.8663    0.7745    0.8139    163566
weighted avg     0.8989    0.9017    0.8972    163566

F1-macro tok:  0.8138996687808201
F1-micro tok:  0.9016788330093051
**************************************************
dev_cost_sum: 42234.05908203125
dev_cost_avg: 38.359726686676886
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19125.0
dev_accuracy_tok: 0.8989846761304879
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06666666666666667
dev_label=N_precision_sent: 0.6325823223570191
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7263681592039801
dev_label=P_precision_sent: 0.6978557504873294
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.748171368861024
dev_precision_macro_sent: 0.6859036000390253
dev_recall_macro_sent: 0.5646815141468857
dev_f-score_macro_sent: 0.5137353982438903
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9095425138632163
dev_label=O_recall_tok: 0.9716754088244369
dev_label=O_f-score_tok: 0.9395828982307486
dev_label=N_precision_tok: 0.7943603851444292
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.6976744186046512
dev_label=P_precision_tok: 0.886762360446571
dev_label=P_recall_tok: 0.6924034869240349
dev_label=P_f-score_tok: 0.7776223776223776
dev_precision_macro_tok: 0.8635550864847388
dev_recall_macro_tok: 0.7620166055295122
dev_f-score_macro_tok: 0.8049598981525925
dev_precision_micro_tok: 0.8989846761304879
dev_recall_micro_tok: 0.8989846761304879
dev_f-score_micro_tok: 0.8989846761304879
dev_time: 11.760383605957031
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0349    0.0667       229
           N     0.6326    0.8528    0.7264       428
           P     0.6979    0.8063    0.7482       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6859    0.5647    0.5137      1101
weighted avg     0.6786    0.6639    0.5979      1101

F1-macro sent:  0.5137353982438903
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9095    0.9717    0.9396     16205
           N     0.7944    0.6220    0.6977      1857
           P     0.8868    0.6924    0.7776      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8636    0.7620    0.8050     21274
weighted avg     0.8960    0.8990    0.8940     21274

F1-macro tok:  0.8049598981525925
F1-micro tok:  0.8989846761304879
**************************************************
Best epoch: 23
**************************************************

EPOCH: 27
Learning rate: 0.656100
train_cost_sum: 304733.4140625
train_cost_avg: 35.66636400544242
train_count_sent: 8544.0
train_total_correct_sent: 5818.0
train_accuracy_sent: 0.6809456928838952
train_count_tok: 163566.0
train_total_correct_tok: 147688.0
train_accuracy_tok: 0.9029260359732463
train_label=O_precision_sent: 0.4567307692307692
train_label=O_recall_sent: 0.058497536945812806
train_label=O_f-score_sent: 0.1037117903930131
train_label=N_precision_sent: 0.6475988700564972
train_label=N_recall_sent: 0.8311178247734139
train_label=N_f-score_sent: 0.7279703625297698
train_label=P_precision_sent: 0.7270058708414873
train_label=P_recall_sent: 0.8232686980609418
train_label=P_f-score_sent: 0.7721486100285788
train_precision_macro_sent: 0.6104451700429179
train_recall_macro_sent: 0.5709613532600563
train_f-score_macro_sent: 0.5346102543171206
train_precision_micro_sent: 0.6809456928838952
train_recall_micro_sent: 0.6809456928838952
train_f-score_micro_sent: 0.6809456928838952
train_label=O_precision_tok: 0.9148544689099555
train_label=O_recall_tok: 0.971659951587091
train_label=O_f-score_tok: 0.9424019655636371
train_label=N_precision_tok: 0.8066467831273967
train_label=N_recall_tok: 0.6665258414307844
train_label=N_f-score_tok: 0.7299225045302079
train_label=P_precision_tok: 0.8803825330162425
train_label=P_recall_tok: 0.6954870687932206
train_label=P_f-score_tok: 0.7770879857079053
train_precision_macro_tok: 0.8672945950178649
train_recall_macro_tok: 0.7778909539370321
train_f-score_macro_tok: 0.8164708186005835
train_precision_micro_tok: 0.9029260359732463
train_recall_micro_tok: 0.9029260359732463
train_f-score_micro_tok: 0.9029260359732463
train_time: 198.79505372047424
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4567    0.0585    0.1037      1624
           N     0.6476    0.8311    0.7280      3310
           P     0.7270    0.8233    0.7721      3610

   micro avg     0.6809    0.6809    0.6809      8544
   macro avg     0.6104    0.5710    0.5346      8544
weighted avg     0.6449    0.6809    0.6280      8544

F1-macro sent:  0.5346102543171206
F1-micro sent:  0.6809456928838952
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9149    0.9717    0.9424    124347
           N     0.8066    0.6665    0.7299     14202
           P     0.8804    0.6955    0.7771     25017

   micro avg     0.9029    0.9029    0.9029    163566
   macro avg     0.8673    0.7779    0.8165    163566
weighted avg     0.9002    0.9029    0.8987    163566

F1-macro tok:  0.8164708186005835
F1-micro tok:  0.9029260359732463
**************************************************
dev_cost_sum: 42208.94549560547
dev_cost_avg: 38.33691688974157
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19161.0
dev_accuracy_tok: 0.9006768825796747
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09716599190283401
dev_label=N_precision_sent: 0.6376068376068376
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7364264560710759
dev_label=P_precision_sent: 0.7068273092369478
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7473460721868365
dev_precision_macro_sent: 0.6703669378368172
dev_recall_macro_sent: 0.5722299555401625
dev_f-score_macro_sent: 0.5269795067202488
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9081351258186832
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9405849275534794
dev_label=N_precision_tok: 0.7962962962962963
dev_label=N_recall_tok: 0.6252019386106623
dev_label=N_f-score_tok: 0.7004524886877829
dev_label=P_precision_tok: 0.9099585062240664
dev_label=P_recall_tok: 0.6827521793275217
dev_label=P_f-score_tok: 0.7801494130202774
dev_precision_macro_tok: 0.8714633094463485
dev_recall_macro_tok: 0.7611312656831899
dev_f-score_macro_tok: 0.8070622764205132
dev_precision_micro_tok: 0.9006768825796747
dev_recall_micro_tok: 0.9006768825796747
dev_f-score_micro_tok: 0.9006768825796747
dev_time: 11.925228118896484
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0524    0.0972       229
           N     0.6376    0.8715    0.7364       428
           P     0.7068    0.7928    0.7473       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6704    0.5722    0.5270      1101
weighted avg     0.6716    0.6694    0.6079      1101

F1-macro sent:  0.5269795067202488
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9754    0.9406     16205
           N     0.7963    0.6252    0.7005      1857
           P     0.9100    0.6828    0.7801      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8715    0.7611    0.8071     21274
weighted avg     0.8986    0.9007    0.8954     21274

F1-macro tok:  0.8070622764205132
F1-micro tok:  0.9006768825796747
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 0.656100
train_cost_sum: 303616.4175415039
train_cost_avg: 35.53562939390261
train_count_sent: 8544.0
train_total_correct_sent: 5919.0
train_accuracy_sent: 0.6927668539325843
train_count_tok: 163566.0
train_total_correct_tok: 147978.0
train_accuracy_tok: 0.9046990205788489
train_label=O_precision_sent: 0.47651006711409394
train_label=O_recall_sent: 0.0874384236453202
train_label=O_f-score_sent: 0.14776274713839752
train_label=N_precision_sent: 0.6603995299647474
train_label=N_recall_sent: 0.8489425981873112
train_label=N_f-score_sent: 0.7428949107732981
train_label=P_precision_sent: 0.7434227010774243
train_label=P_recall_sent: 0.8218836565096953
train_label=P_f-score_sent: 0.7806867517431918
train_precision_macro_sent: 0.6267774327187552
train_recall_macro_sent: 0.5860882261141089
train_f-score_macro_sent: 0.5571148032182958
train_precision_micro_sent: 0.6927668539325843
train_recall_micro_sent: 0.6927668539325843
train_f-score_micro_sent: 0.6927668539325843
train_label=O_precision_tok: 0.9165541719122086
train_label=O_recall_tok: 0.9719172959540641
train_label=O_f-score_tok: 0.9434242110809703
train_label=N_precision_tok: 0.8109616848515605
train_label=N_recall_tok: 0.6751161808196029
train_label=N_f-score_tok: 0.7368299711815561
train_label=P_precision_tok: 0.881820467689213
train_label=P_recall_tok: 0.7009233721069673
train_label=P_f-score_tok: 0.7810342523718319
train_precision_macro_tok: 0.8697787748176607
train_recall_macro_tok: 0.7826522829602114
train_f-score_macro_tok: 0.8204294782114528
train_precision_micro_tok: 0.9046990205788489
train_recall_micro_tok: 0.9046990205788489
train_f-score_micro_tok: 0.9046990205788489
train_time: 171.76838850975037
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4765    0.0874    0.1478      1624
           N     0.6604    0.8489    0.7429      3310
           P     0.7434    0.8219    0.7807      3610

   micro avg     0.6928    0.6928    0.6928      8544
   macro avg     0.6268    0.5861    0.5571      8544
weighted avg     0.6605    0.6928    0.6457      8544

F1-macro sent:  0.5571148032182958
F1-micro sent:  0.6927668539325843
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9166    0.9719    0.9434    124347
           N     0.8110    0.6751    0.7368     14202
           P     0.8818    0.7009    0.7810     25017

   micro avg     0.9047    0.9047    0.9047    163566
   macro avg     0.8698    0.7827    0.8204    163566
weighted avg     0.9021    0.9047    0.9006    163566

F1-macro tok:  0.8204294782114528
F1-micro tok:  0.9046990205788489
**************************************************
dev_cost_sum: 42212.535888671875
dev_cost_avg: 38.340177918866374
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=O_precision_sent: 0.46153846153846156
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13432835820895525
dev_label=N_precision_sent: 0.6365217391304347
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7298105682951147
dev_label=P_precision_sent: 0.7207392197125256
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7540279269602578
dev_precision_macro_sent: 0.606266473460474
dev_recall_macro_sent: 0.5747611158479216
dev_f-score_macro_sent: 0.5393889511547759
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9072164948453608
dev_label=O_recall_tok: 0.9774760876272756
dev_label=O_f-score_tok: 0.9410366849844052
dev_label=N_precision_tok: 0.8009575923392613
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.7056342271768605
dev_label=P_precision_tok: 0.9226190476190477
dev_label=P_recall_tok: 0.6755915317559154
dev_label=P_f-score_tok: 0.7800143781452193
dev_precision_macro_tok: 0.8769310449345568
dev_recall_macro_tok: 0.7612181958705054
dev_f-score_macro_tok: 0.8088950967688283
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 7.2190916538238525
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0786    0.1343       229
           N     0.6365    0.8551    0.7298       428
           P     0.7207    0.7905    0.7540       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6063    0.5748    0.5394      1101
weighted avg     0.6341    0.6676    0.6157      1101

F1-macro sent:  0.5393889511547759
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9072    0.9775    0.9410     16205
           N     0.8010    0.6306    0.7056      1857
           P     0.9226    0.6756    0.7800      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8769    0.7612    0.8089     21274
weighted avg     0.9003    0.9016    0.8962     21274

F1-macro tok:  0.8088950967688283
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.656100
train_cost_sum: 302820.29541015625
train_cost_avg: 35.44245030549582
train_count_sent: 8544.0
train_total_correct_sent: 5950.0
train_accuracy_sent: 0.6963951310861424
train_count_tok: 163566.0
train_total_correct_tok: 148098.0
train_accuracy_tok: 0.9054326693811673
train_label=O_precision_sent: 0.5214521452145214
train_label=O_recall_sent: 0.09729064039408868
train_label=O_f-score_sent: 0.16398546964193048
train_label=N_precision_sent: 0.6633616619452314
train_label=N_recall_sent: 0.8489425981873112
train_label=N_f-score_sent: 0.7447654386429898
train_label=P_precision_sent: 0.7445692883895131
train_label=P_recall_sent: 0.8260387811634349
train_label=P_f-score_sent: 0.7831910702560735
train_precision_macro_sent: 0.6431276985164219
train_recall_macro_sent: 0.590757339914945
train_f-score_macro_sent: 0.5639806595136646
train_precision_micro_sent: 0.6963951310861424
train_recall_micro_sent: 0.6963951310861424
train_f-score_micro_sent: 0.6963951310861424
train_label=O_precision_tok: 0.9171982251886686
train_label=O_recall_tok: 0.9725043627912213
train_label=O_f-score_tok: 0.9440419685236073
train_label=N_precision_tok: 0.809608390425442
train_label=N_recall_tok: 0.6739895789325447
train_label=N_f-score_tok: 0.7356003842459174
train_label=P_precision_tok: 0.8844104935169363
train_label=P_recall_tok: 0.7034416596714235
train_label=P_f-score_tok: 0.7836134921518423
train_precision_macro_tok: 0.8704057030436824
train_recall_macro_tok: 0.7833118671317298
train_f-score_macro_tok: 0.8210852816404556
train_precision_micro_tok: 0.9054326693811673
train_recall_micro_tok: 0.9054326693811673
train_f-score_micro_tok: 0.9054326693811673
train_time: 144.90297865867615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5215    0.0973    0.1640      1624
           N     0.6634    0.8489    0.7448      3310
           P     0.7446    0.8260    0.7832      3610

   micro avg     0.6964    0.6964    0.6964      8544
   macro avg     0.6431    0.5908    0.5640      8544
weighted avg     0.6707    0.6964    0.6506      8544

F1-macro sent:  0.5639806595136646
F1-micro sent:  0.6963951310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9172    0.9725    0.9440    124347
           N     0.8096    0.6740    0.7356     14202
           P     0.8844    0.7034    0.7836     25017

   micro avg     0.9054    0.9054    0.9054    163566
   macro avg     0.8704    0.7833    0.8211    163566
weighted avg     0.9028    0.9054    0.9014    163566

F1-macro tok:  0.8210852816404556
F1-micro tok:  0.9054326693811673
**************************************************
dev_cost_sum: 42123.255310058594
dev_cost_avg: 38.25908747507592
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19154.0
dev_accuracy_tok: 0.9003478424367772
dev_label=O_precision_sent: 0.5333333333333333
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12355212355212353
dev_label=N_precision_sent: 0.679920477137177
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7346938775510206
dev_label=P_precision_sent: 0.6690140845070423
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7509881422924902
dev_precision_macro_sent: 0.6274226316591841
dev_recall_macro_sent: 0.5749300906832637
dev_f-score_macro_sent: 0.5364113811318781
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9091799688814615
dev_label=O_recall_tok: 0.9735883986423943
dev_label=O_f-score_tok: 0.9402824959771143
dev_label=N_precision_tok: 0.8106761565836299
dev_label=N_recall_tok: 0.613354873451804
dev_label=N_f-score_tok: 0.6983445738810545
dev_label=P_precision_tok: 0.8895071542130366
dev_label=P_recall_tok: 0.6967621419676214
dev_label=P_f-score_tok: 0.7814245810055866
dev_precision_macro_tok: 0.8697877598927093
dev_recall_macro_tok: 0.7612351380206066
dev_f-score_macro_tok: 0.8066838836212519
dev_precision_micro_tok: 0.9003478424367772
dev_recall_micro_tok: 0.9003478424367772
dev_f-score_micro_tok: 0.9003478424367772
dev_time: 7.1632068157196045
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5333    0.0699    0.1236       229
           N     0.6799    0.7991    0.7347       428
           P     0.6690    0.8559    0.7510       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6274    0.5749    0.5364      1101
weighted avg     0.6450    0.6703    0.6142      1101

F1-macro sent:  0.5364113811318781
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9736    0.9403     16205
           N     0.8107    0.6134    0.6983      1857
           P     0.8895    0.6968    0.7814      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8698    0.7612    0.8067     21274
weighted avg     0.8976    0.9003    0.8952     21274

F1-macro tok:  0.8066838836212519
F1-micro tok:  0.9003478424367772
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.656100
train_cost_sum: 301727.9812011719
train_cost_avg: 35.31460454133566
train_count_sent: 8544.0
train_total_correct_sent: 5916.0
train_accuracy_sent: 0.6924157303370787
train_count_tok: 163566.0
train_total_correct_tok: 148149.0
train_accuracy_tok: 0.9057444701221525
train_label=O_precision_sent: 0.48024316109422494
train_label=O_recall_sent: 0.09729064039408868
train_label=O_f-score_sent: 0.16180235535074247
train_label=N_precision_sent: 0.6633045148895294
train_label=N_recall_sent: 0.834441087613293
train_label=N_f-score_sent: 0.7390955311747391
train_label=P_precision_sent: 0.7395704764255739
train_label=P_recall_sent: 0.8299168975069252
train_label=P_f-score_sent: 0.7821433233259365
train_precision_macro_sent: 0.6277060508031094
train_recall_macro_sent: 0.587216208504769
train_f-score_macro_sent: 0.5610137366171394
train_precision_micro_sent: 0.6924157303370787
train_recall_micro_sent: 0.6924157303370787
train_f-score_micro_sent: 0.6924157303370787
train_label=O_precision_tok: 0.918423834110213
train_label=O_recall_tok: 0.9713221871054388
train_label=O_f-score_tok: 0.9441326371083735
train_label=N_precision_tok: 0.8141869095816464
train_label=N_recall_tok: 0.6796930009857767
train_label=N_f-score_tok: 0.7408857164786247
train_label=P_precision_tok: 0.8769367853076581
train_label=P_recall_tok: 0.7081184794339849
train_label=P_f-score_tok: 0.7835375293024902
train_precision_macro_tok: 0.8698491763331725
train_recall_macro_tok: 0.7863778891750668
train_f-score_macro_tok: 0.8228519609631628
train_precision_micro_tok: 0.9057444701221525
train_recall_micro_tok: 0.9057444701221525
train_f-score_micro_tok: 0.9057444701221525
train_time: 145.5845081806183
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4802    0.0973    0.1618      1624
           N     0.6633    0.8344    0.7391      3310
           P     0.7396    0.8299    0.7821      3610

   micro avg     0.6924    0.6924    0.6924      8544
   macro avg     0.6277    0.5872    0.5610      8544
weighted avg     0.6607    0.6924    0.6476      8544

F1-macro sent:  0.5610137366171394
F1-micro sent:  0.6924157303370787
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9713    0.9441    124347
           N     0.8142    0.6797    0.7409     14202
           P     0.8769    0.7081    0.7835     25017

   micro avg     0.9057    0.9057    0.9057    163566
   macro avg     0.8698    0.7864    0.8229    163566
weighted avg     0.9030    0.9057    0.9019    163566

F1-macro tok:  0.8228519609631628
F1-micro tok:  0.9057444701221525
**************************************************
dev_cost_sum: 42167.46203613281
dev_cost_avg: 38.299238906569315
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19195.0
dev_accuracy_tok: 0.9022750775594622
dev_label=O_precision_sent: 0.5517241379310345
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12403100775193798
dev_label=N_precision_sent: 0.6358974358974359
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.734452122408687
dev_label=P_precision_sent: 0.7125256673511293
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7454350161117078
dev_precision_macro_sent: 0.6333824137265333
dev_recall_macro_sent: 0.5735198018897973
dev_f-score_macro_sent: 0.5346393820907775
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9083042008138003
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9418791228382956
dev_label=N_precision_tok: 0.8186416184971098
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6991669237889541
dev_label=P_precision_tok: 0.9065956575174109
dev_label=P_recall_tok: 0.6889788293897883
dev_label=P_f-score_tok: 0.7829471077304087
dev_precision_macro_tok: 0.8778471589427737
dev_recall_macro_tok: 0.7590447189463224
dev_f-score_macro_tok: 0.8079977181192195
dev_precision_micro_tok: 0.9022750775594622
dev_recall_micro_tok: 0.9022750775594622
dev_f-score_micro_tok: 0.9022750775594622
dev_time: 8.428366661071777
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5517    0.0699    0.1240       229
           N     0.6359    0.8692    0.7345       428
           P     0.7125    0.7815    0.7454       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6334    0.5735    0.5346      1101
weighted avg     0.6493    0.6676    0.6119      1101

F1-macro sent:  0.5346393820907775
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9780    0.9419     16205
           N     0.8186    0.6101    0.6992      1857
           P     0.9066    0.6890    0.7829      3212

   micro avg     0.9023    0.9023    0.9023     21274
   macro avg     0.8778    0.7590    0.8080     21274
weighted avg     0.9002    0.9023    0.8967     21274

F1-macro tok:  0.8079977181192195
F1-micro tok:  0.9022750775594622
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.656100
train_cost_sum: 300615.2018432617
train_cost_avg: 35.18436351161771
train_count_sent: 8544.0
train_total_correct_sent: 5944.0
train_accuracy_sent: 0.6956928838951311
train_count_tok: 163566.0
train_total_correct_tok: 148415.0
train_accuracy_tok: 0.9073707249672915
train_label=O_precision_sent: 0.5058479532163743
train_label=O_recall_sent: 0.10652709359605911
train_label=O_f-score_sent: 0.17599186164801628
train_label=N_precision_sent: 0.6714320926793197
train_label=N_recall_sent: 0.8229607250755288
train_label=N_f-score_sent: 0.739514049138048
train_label=P_precision_sent: 0.735102533172497
train_label=P_recall_sent: 0.8440443213296399
train_label=P_f-score_sent: 0.7858156028368795
train_precision_macro_sent: 0.637460859689397
train_recall_macro_sent: 0.5911773800004093
train_f-score_macro_sent: 0.567107171207648
train_precision_micro_sent: 0.6956928838951311
train_recall_micro_sent: 0.6956928838951311
train_f-score_micro_sent: 0.6956928838951311
train_label=O_precision_tok: 0.9196535926822215
train_label=O_recall_tok: 0.9718610018737887
train_label=O_f-score_tok: 0.9450368128624101
train_label=N_precision_tok: 0.8161925601750547
train_label=N_recall_tok: 0.6828615687931278
train_label=N_f-score_tok: 0.743597607728876
train_label=P_precision_tok: 0.8812013019035407
train_label=P_recall_tok: 0.7142742934804333
train_label=P_f-score_tok: 0.7890054089855392
train_precision_macro_tok: 0.8723491515869389
train_recall_macro_tok: 0.7896656213824499
train_f-score_macro_tok: 0.8258799431922751
train_precision_micro_tok: 0.9073707249672915
train_recall_micro_tok: 0.9073707249672915
train_f-score_micro_tok: 0.9073707249672915
train_time: 145.51399493217468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5058    0.1065    0.1760      1624
           N     0.6714    0.8230    0.7395      3310
           P     0.7351    0.8440    0.7858      3610

   micro avg     0.6957    0.6957    0.6957      8544
   macro avg     0.6375    0.5912    0.5671      8544
weighted avg     0.6669    0.6957    0.6520      8544

F1-macro sent:  0.567107171207648
F1-micro sent:  0.6956928838951311
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9719    0.9450    124347
           N     0.8162    0.6829    0.7436     14202
           P     0.8812    0.7143    0.7890     25017

   micro avg     0.9074    0.9074    0.9074    163566
   macro avg     0.8723    0.7897    0.8259    163566
weighted avg     0.9048    0.9074    0.9037    163566

F1-macro tok:  0.8258799431922751
F1-micro tok:  0.9073707249672915
**************************************************
dev_cost_sum: 42100.677978515625
dev_cost_avg: 38.238581270223094
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19165.0
dev_accuracy_tok: 0.9008649055184732
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1509433962264151
dev_label=N_precision_sent: 0.6254237288135593
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.724950884086444
dev_label=P_precision_sent: 0.7221052631578947
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7464635473340587
dev_precision_macro_sent: 0.6343615158423366
dev_recall_macro_sent: 0.5740027665914292
dev_f-score_macro_sent: 0.5407859425489726
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.910624530591022
dev_label=O_recall_tok: 0.9726627584078988
dev_label=O_f-score_tok: 0.9406218296831175
dev_label=N_precision_tok: 0.7991775188485264
dev_label=N_recall_tok: 0.6278944534194938
dev_label=N_f-score_tok: 0.7032569360675514
dev_label=P_precision_tok: 0.8926576217079011
dev_label=P_recall_tok: 0.6964508094645081
dev_label=P_f-score_tok: 0.7824414130814971
dev_precision_macro_tok: 0.8674865570491498
dev_recall_macro_tok: 0.7656693404306335
dev_f-score_macro_tok: 0.8087733929440554
dev_precision_micro_tok: 0.9008649055184732
dev_recall_micro_tok: 0.9008649055184732
dev_f-score_micro_tok: 0.9008649055184732
dev_time: 8.477872371673584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0873    0.1509       229
           N     0.6254    0.8621    0.7250       428
           P     0.7221    0.7725    0.7465       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6344    0.5740    0.5408      1101
weighted avg     0.6499    0.6649    0.6142      1101

F1-macro sent:  0.5407859425489726
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9106    0.9727    0.9406     16205
           N     0.7992    0.6279    0.7033      1857
           P     0.8927    0.6965    0.7824      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8675    0.7657    0.8088     21274
weighted avg     0.8982    0.9009    0.8960     21274

F1-macro tok:  0.8087733929440554
F1-micro tok:  0.9008649055184732
**************************************************
Best epoch: 31
**************************************************

EPOCH: 32
Learning rate: 0.656100
train_cost_sum: 299603.3147583008
train_cost_avg: 35.06593103444531
train_count_sent: 8544.0
train_total_correct_sent: 5964.0
train_accuracy_sent: 0.6980337078651685
train_count_tok: 163566.0
train_total_correct_tok: 148764.0
train_accuracy_tok: 0.909504420234034
train_label=O_precision_sent: 0.4691358024691358
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15605749486652976
train_label=N_precision_sent: 0.6705825941021338
train_label=N_recall_sent: 0.8450151057401812
train_label=N_f-score_sent: 0.7477609945194493
train_label=P_precision_sent: 0.7446283032847617
train_label=P_recall_sent: 0.8351800554016621
train_label=P_f-score_sent: 0.7873090481786135
train_precision_macro_sent: 0.6281155666186771
train_recall_macro_sent: 0.5912637400850479
train_f-score_macro_sent: 0.5637091791881975
train_precision_micro_sent: 0.6980337078651685
train_recall_micro_sent: 0.6980337078651685
train_f-score_micro_sent: 0.6980337078651685
train_label=O_precision_tok: 0.9214046313223644
train_label=O_recall_tok: 0.9727777911811302
train_label=O_f-score_tok: 0.9463945514362723
train_label=N_precision_tok: 0.818796992481203
train_label=N_recall_tok: 0.6901140684410646
train_label=N_f-score_tok: 0.748968363136176
train_label=P_precision_tok: 0.8860504036227604
train_label=P_recall_tok: 0.7195507055202462
train_label=P_f-score_tok: 0.7941676041735601
train_precision_macro_tok: 0.8754173424754427
train_recall_macro_tok: 0.794147521714147
train_f-score_macro_tok: 0.8298435062486694
train_precision_micro_tok: 0.909504420234034
train_recall_micro_tok: 0.909504420234034
train_f-score_micro_tok: 0.909504420234034
train_time: 144.62605214118958
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4691    0.0936    0.1561      1624
           N     0.6706    0.8450    0.7478      3310
           P     0.7446    0.8352    0.7873      3610

   micro avg     0.6980    0.6980    0.6980      8544
   macro avg     0.6281    0.5913    0.5637      8544
weighted avg     0.6636    0.6980    0.6520      8544

F1-macro sent:  0.5637091791881975
F1-micro sent:  0.6980337078651685
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9214    0.9728    0.9464    124347
           N     0.8188    0.6901    0.7490     14202
           P     0.8861    0.7196    0.7942     25017

   micro avg     0.9095    0.9095    0.9095    163566
   macro avg     0.8754    0.7941    0.8298    163566
weighted avg     0.9071    0.9095    0.9060    163566

F1-macro tok:  0.8298435062486694
F1-micro tok:  0.909504420234034
**************************************************
dev_cost_sum: 42159.462646484375
dev_cost_avg: 38.291973339222864
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19129.0
dev_accuracy_tok: 0.8991726990692864
dev_label=O_precision_sent: 0.56
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11023622047244093
dev_label=N_precision_sent: 0.6961206896551724
dev_label=N_recall_sent: 0.7546728971962616
dev_label=N_f-score_sent: 0.7242152466367712
dev_label=P_precision_sent: 0.6372549019607843
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7386363636363635
dev_precision_macro_sent: 0.6311251972053189
dev_recall_macro_sent: 0.5647288822512264
dev_f-score_macro_sent: 0.5243626102485252
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9117220578852735
dev_label=O_recall_tok: 0.9700092564023449
dev_label=O_f-score_tok: 0.939962925312444
dev_label=N_precision_tok: 0.8115942028985508
dev_label=N_recall_tok: 0.6031233171782445
dev_label=N_f-score_tok: 0.6919987642879208
dev_label=P_precision_tok: 0.8631737655484357
dev_label=P_recall_tok: 0.7129514321295143
dev_label=P_f-score_tok: 0.7809036658141517
dev_precision_macro_tok: 0.8621633421107534
dev_recall_macro_tok: 0.762028001903368
dev_f-score_macro_tok: 0.8042884518048389
dev_precision_micro_tok: 0.8991726990692864
dev_recall_micro_tok: 0.8991726990692864
dev_f-score_micro_tok: 0.8991726990692864
dev_time: 8.437075138092041
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5600    0.0611    0.1102       229
           N     0.6961    0.7547    0.7242       428
           P     0.6373    0.8784    0.7386       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.6311    0.5647    0.5244      1101
weighted avg     0.6441    0.6603    0.6023      1101

F1-macro sent:  0.5243626102485252
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9117    0.9700    0.9400     16205
           N     0.8116    0.6031    0.6920      1857
           P     0.8632    0.7130    0.7809      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8622    0.7620    0.8043     21274
weighted avg     0.8957    0.8992    0.8943     21274

F1-macro tok:  0.8042884518048389
F1-micro tok:  0.8991726990692864
**************************************************
Best epoch: 31
**************************************************

EPOCH: 33
Learning rate: 0.656100
train_cost_sum: 298751.4571533203
train_cost_avg: 34.96622859940547
train_count_sent: 8544.0
train_total_correct_sent: 5987.0
train_accuracy_sent: 0.7007256554307116
train_count_tok: 163566.0
train_total_correct_tok: 148851.0
train_accuracy_tok: 0.9100363156157147
train_label=O_precision_sent: 0.46089385474860334
train_label=O_recall_sent: 0.10160098522167488
train_label=O_f-score_sent: 0.16649848637739656
train_label=N_precision_sent: 0.6792727272727273
train_label=N_recall_sent: 0.8465256797583082
train_label=N_f-score_sent: 0.7537323470073973
train_label=P_precision_sent: 0.7436591972420586
train_label=P_recall_sent: 0.8365650969529086
train_label=P_f-score_sent: 0.787381045496024
train_precision_macro_sent: 0.6279419264211298
train_recall_macro_sent: 0.5948972539776306
train_f-score_macro_sent: 0.5692039596269393
train_precision_micro_sent: 0.7007256554307116
train_recall_micro_sent: 0.7007256554307116
train_f-score_micro_sent: 0.7007256554307116
train_label=O_precision_tok: 0.9225902465084331
train_label=O_recall_tok: 0.9721746403210371
train_label=O_f-score_tok: 0.9467336525998816
train_label=N_precision_tok: 0.8180762852404644
train_label=N_recall_tok: 0.6946908886072384
train_label=N_f-score_tok: 0.7513517630035794
train_label=P_precision_tok: 0.8838640359445205
train_label=P_recall_tok: 0.723428068913139
train_label=P_f-score_tok: 0.7956388894994834
train_precision_macro_tok: 0.8748435225644725
train_recall_macro_tok: 0.7967645326138048
train_f-score_macro_tok: 0.8312414350343148
train_precision_micro_tok: 0.9100363156157147
train_recall_micro_tok: 0.9100363156157147
train_f-score_micro_tok: 0.9100363156157147
train_time: 202.81072902679443
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4609    0.1016    0.1665      1624
           N     0.6793    0.8465    0.7537      3310
           P     0.7437    0.8366    0.7874      3610

   micro avg     0.7007    0.7007    0.7007      8544
   macro avg     0.6279    0.5949    0.5692      8544
weighted avg     0.6650    0.7007    0.6563      8544

F1-macro sent:  0.5692039596269393
F1-micro sent:  0.7007256554307116
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9226    0.9722    0.9467    124347
           N     0.8181    0.6947    0.7514     14202
           P     0.8839    0.7234    0.7956     25017

   micro avg     0.9100    0.9100    0.9100    163566
   macro avg     0.8748    0.7968    0.8312    163566
weighted avg     0.9076    0.9100    0.9067    163566

F1-macro tok:  0.8312414350343148
F1-micro tok:  0.9100363156157147
**************************************************
dev_cost_sum: 42124.98095703125
dev_cost_avg: 38.260654820191874
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19153.0
dev_accuracy_tok: 0.9003008367020776
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.049792531120331954
dev_label=N_precision_sent: 0.6591337099811676
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7299270072992701
dev_label=P_precision_sent: 0.6720430107526881
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7485029940119761
dev_precision_macro_sent: 0.6103922402446186
dev_recall_macro_sent: 0.5628508257676115
dev_f-score_macro_sent: 0.509407510810526
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9129929720624964
dev_label=O_recall_tok: 0.9700092564023449
dev_label=O_f-score_tok: 0.9406379031775477
dev_label=N_precision_tok: 0.7689295039164491
dev_label=N_recall_tok: 0.6343564889606893
dev_label=N_f-score_tok: 0.6951903216287991
dev_label=P_precision_tok: 0.8934653465346535
dev_label=P_recall_tok: 0.7023661270236613
dev_label=P_f-score_tok: 0.7864737667770613
dev_precision_macro_tok: 0.8584626075045331
dev_recall_macro_tok: 0.7689106241288984
dev_f-score_macro_tok: 0.8074339971944694
dev_precision_micro_tok: 0.9003008367020776
dev_recall_micro_tok: 0.9003008367020776
dev_f-score_micro_tok: 0.9003008367020775
dev_time: 18.01598882675171
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0262    0.0498       229
           N     0.6591    0.8178    0.7299       428
           P     0.6720    0.8446    0.7485       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6104    0.5629    0.5094      1101
weighted avg     0.6312    0.6639    0.5960      1101

F1-macro sent:  0.509407510810526
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9130    0.9700    0.9406     16205
           N     0.7689    0.6344    0.6952      1857
           P     0.8935    0.7024    0.7865      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8585    0.7689    0.8074     21274
weighted avg     0.8975    0.9003    0.8959     21274

F1-macro tok:  0.8074339971944694
F1-micro tok:  0.9003008367020775
**************************************************
Best epoch: 31
**************************************************

EPOCH: 34
Learning rate: 0.656100
train_cost_sum: 297760.4606933594
train_cost_avg: 34.850241186020526
train_count_sent: 8544.0
train_total_correct_sent: 5952.0
train_accuracy_sent: 0.6966292134831461
train_count_tok: 163566.0
train_total_correct_tok: 149087.0
train_accuracy_tok: 0.9114791582602741
train_label=O_precision_sent: 0.5018315018315018
train_label=O_recall_sent: 0.08435960591133004
train_label=O_f-score_sent: 0.14443858724301525
train_label=N_precision_sent: 0.6631255901794145
train_label=N_recall_sent: 0.8486404833836858
train_label=N_f-score_sent: 0.7445003975616221
train_label=P_precision_sent: 0.7449814126394052
train_label=P_recall_sent: 0.8326869806094183
train_label=P_f-score_sent: 0.7863963374754742
train_precision_macro_sent: 0.6366461682167739
train_recall_macro_sent: 0.5885623566348114
train_f-score_macro_sent: 0.5584451074267038
train_precision_micro_sent: 0.6966292134831461
train_recall_micro_sent: 0.6966292134831461
train_f-score_micro_sent: 0.6966292134831461
train_label=O_precision_tok: 0.9241701451003776
train_label=O_recall_tok: 0.9721746403210371
train_label=O_f-score_tok: 0.9475647944566593
train_label=N_precision_tok: 0.8198183319570603
train_label=N_recall_tok: 0.6990564709195888
train_label=N_f-score_tok: 0.754636667680146
train_label=P_precision_tok: 0.8848426150121066
train_label=P_recall_tok: 0.7303833393292561
train_label=P_f-score_tok: 0.8002277355639741
train_precision_macro_tok: 0.8762770306898481
train_recall_macro_tok: 0.8005381501899606
train_f-score_macro_tok: 0.8341430659002599
train_precision_micro_tok: 0.9114791582602741
train_recall_micro_tok: 0.9114791582602741
train_f-score_micro_tok: 0.9114791582602743
train_time: 305.4083559513092
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5018    0.0844    0.1444      1624
           N     0.6631    0.8486    0.7445      3310
           P     0.7450    0.8327    0.7864      3610

   micro avg     0.6966    0.6966    0.6966      8544
   macro avg     0.6366    0.5886    0.5584      8544
weighted avg     0.6671    0.6966    0.6481      8544

F1-macro sent:  0.5584451074267038
F1-micro sent:  0.6966292134831461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9242    0.9722    0.9476    124347
           N     0.8198    0.6991    0.7546     14202
           P     0.8848    0.7304    0.8002     25017

   micro avg     0.9115    0.9115    0.9115    163566
   macro avg     0.8763    0.8005    0.8341    163566
weighted avg     0.9091    0.9115    0.9083    163566

F1-macro tok:  0.8341430659002599
F1-micro tok:  0.9114791582602743
**************************************************
dev_cost_sum: 42147.67639160156
dev_cost_avg: 38.28126829391604
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19139.0
dev_accuracy_tok: 0.8996427564162828
dev_label=O_precision_sent: 0.5483870967741935
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.13076923076923075
dev_label=N_precision_sent: 0.6611721611721612
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7412731006160165
dev_label=P_precision_sent: 0.7022900763358778
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7603305785123967
dev_precision_macro_sent: 0.6372831114274108
dev_recall_macro_sent: 0.5821741935381082
dev_f-score_macro_sent: 0.5441243032992147
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9115685706001739
dev_label=O_recall_tok: 0.9700709657513114
dev_label=O_f-score_tok: 0.9399103139013453
dev_label=N_precision_tok: 0.7747035573122529
dev_label=N_recall_tok: 0.6332794830371568
dev_label=N_f-score_tok: 0.6968888888888889
dev_label=P_precision_tok: 0.8932696136997212
dev_label=P_recall_tok: 0.6983188044831881
dev_label=P_f-score_tok: 0.7838546217019046
dev_precision_macro_tok: 0.8598472472040494
dev_recall_macro_tok: 0.7672230844238853
dev_f-score_macro_tok: 0.8068846081640463
dev_precision_micro_tok: 0.8996427564162828
dev_recall_micro_tok: 0.8996427564162828
dev_f-score_micro_tok: 0.8996427564162828
dev_time: 18.928001403808594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5484    0.0742    0.1308       229
           N     0.6612    0.8435    0.7413       428
           P     0.7023    0.8288    0.7603       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6373    0.5822    0.5441      1101
weighted avg     0.6543    0.6776    0.6220      1101

F1-macro sent:  0.5441243032992147
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9116    0.9701    0.9399     16205
           N     0.7747    0.6333    0.6969      1857
           P     0.8933    0.6983    0.7839      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8598    0.7672    0.8069     21274
weighted avg     0.8969    0.8996    0.8951     21274

F1-macro tok:  0.8068846081640463
F1-micro tok:  0.8996427564162828
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 0.656100
train_cost_sum: 296699.7275390625
train_cost_avg: 34.72609170635095
train_count_sent: 8544.0
train_total_correct_sent: 5978.0
train_accuracy_sent: 0.6996722846441947
train_count_tok: 163566.0
train_total_correct_tok: 149263.0
train_accuracy_tok: 0.9125551765036743
train_label=O_precision_sent: 0.4690265486725664
train_label=O_recall_sent: 0.0979064039408867
train_label=O_f-score_sent: 0.1619969434538971
train_label=N_precision_sent: 0.6777456647398844
train_label=N_recall_sent: 0.8501510574018127
train_label=N_f-score_sent: 0.7542213883677298
train_label=P_precision_sent: 0.7414261041204047
train_label=P_recall_sent: 0.832409972299169
train_label=P_f-score_sent: 0.7842881378050373
train_precision_macro_sent: 0.6293994391776184
train_recall_macro_sent: 0.5934891445472895
train_f-score_macro_sent: 0.5668354898755547
train_precision_micro_sent: 0.6996722846441947
train_recall_micro_sent: 0.6996722846441947
train_f-score_micro_sent: 0.6996722846441947
train_label=O_precision_tok: 0.9254143857902998
train_label=O_recall_tok: 0.9720620521604864
train_label=O_f-score_tok: 0.9481648245620916
train_label=N_precision_tok: 0.818732601932209
train_label=N_recall_tok: 0.7041261794113505
train_label=N_f-score_tok: 0.7571168988491822
train_label=P_precision_tok: 0.8868206587259488
train_label=P_recall_tok: 0.735100131910301
train_label=P_f-score_tok: 0.8038641430257464
train_precision_macro_tok: 0.8769892154828192
train_recall_macro_tok: 0.8037627878273792
train_f-score_macro_tok: 0.8363819554790067
train_precision_micro_tok: 0.9125551765036743
train_recall_micro_tok: 0.9125551765036743
train_f-score_micro_tok: 0.9125551765036743
train_time: 291.45188546180725
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4690    0.0979    0.1620      1624
           N     0.6777    0.8502    0.7542      3310
           P     0.7414    0.8324    0.7843      3610

   micro avg     0.6997    0.6997    0.6997      8544
   macro avg     0.6294    0.5935    0.5668      8544
weighted avg     0.6650    0.6997    0.6544      8544

F1-macro sent:  0.5668354898755547
F1-micro sent:  0.6996722846441947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9254    0.9721    0.9482    124347
           N     0.8187    0.7041    0.7571     14202
           P     0.8868    0.7351    0.8039     25017

   micro avg     0.9126    0.9126    0.9126    163566
   macro avg     0.8770    0.8038    0.8364    163566
weighted avg     0.9102    0.9126    0.9095    163566

F1-macro tok:  0.8363819554790067
F1-micro tok:  0.9125551765036743
**************************************************
dev_cost_sum: 42079.18634033203
dev_cost_avg: 38.21906116288105
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.46153846153846156
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.04958677685950413
dev_label=N_precision_sent: 0.6481481481481481
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7231404958677685
dev_label=P_precision_sent: 0.6733576642335767
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7439516129032258
dev_precision_macro_sent: 0.5943480913067288
dev_recall_macro_sent: 0.5583463212631069
dev_f-score_macro_sent: 0.5055596285434995
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9157950096417928
dev_label=O_recall_tok: 0.9671089170009256
dev_label=O_f-score_tok: 0.9407527462632812
dev_label=N_precision_tok: 0.7934272300469484
dev_label=N_recall_tok: 0.6370490037695208
dev_label=N_f-score_tok: 0.7066905615292712
dev_label=P_precision_tok: 0.8644194756554308
dev_label=P_recall_tok: 0.7185554171855542
dev_label=P_f-score_tok: 0.7847670860251615
dev_precision_macro_tok: 0.8578805717813908
dev_recall_macro_tok: 0.7742377793186668
dev_f-score_macro_tok: 0.810736797939238
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 17.735485792160034
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0262    0.0496       229
           N     0.6481    0.8178    0.7231       428
           P     0.6734    0.8311    0.7440       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.5943    0.5583    0.5056      1101
weighted avg     0.6195    0.6585    0.5914      1101

F1-macro sent:  0.5055596285434995
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9158    0.9671    0.9408     16205
           N     0.7934    0.6370    0.7067      1857
           P     0.8644    0.7186    0.7848      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8579    0.7742    0.8107     21274
weighted avg     0.8974    0.9008    0.8968     21274

F1-macro tok:  0.810736797939238
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 34
**************************************************

EPOCH: 36
Learning rate: 0.656100
train_cost_sum: 295584.9110107422
train_cost_avg: 34.595612243766645
train_count_sent: 8544.0
train_total_correct_sent: 5964.0
train_accuracy_sent: 0.6980337078651685
train_count_tok: 163566.0
train_total_correct_tok: 149504.0
train_accuracy_tok: 0.9140285878483303
train_label=O_precision_sent: 0.5331325301204819
train_label=O_recall_sent: 0.10899014778325124
train_label=O_f-score_sent: 0.18098159509202455
train_label=N_precision_sent: 0.6657875809158476
train_label=N_recall_sent: 0.8389728096676737
train_label=N_f-score_sent: 0.7424141157599252
train_label=P_precision_sent: 0.744865132392972
train_label=P_recall_sent: 0.8337950138504155
train_label=P_f-score_sent: 0.786825251601098
train_precision_macro_sent: 0.6479284144764338
train_recall_macro_sent: 0.5939193237671135
train_f-score_macro_sent: 0.5700736541510159
train_precision_micro_sent: 0.6980337078651685
train_recall_micro_sent: 0.6980337078651685
train_f-score_micro_sent: 0.6980337078651685
train_label=O_precision_tok: 0.9269876562140612
train_label=O_recall_tok: 0.9723354805503953
train_label=O_f-score_tok: 0.9491202110080581
train_label=N_precision_tok: 0.8235055560061644
train_label=N_recall_tok: 0.7148993099563442
train_label=N_f-score_tok: 0.7653688138404131
train_label=P_precision_tok: 0.8864324506175806
train_label=P_recall_tok: 0.7372586641084062
train_label=P_f-score_tok: 0.8049930167597764
train_precision_macro_tok: 0.8789752209459354
train_recall_macro_tok: 0.8081644848717152
train_f-score_macro_tok: 0.8398273472027492
train_precision_micro_tok: 0.9140285878483303
train_recall_micro_tok: 0.9140285878483303
train_f-score_micro_tok: 0.9140285878483303
train_time: 305.2565357685089
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5331    0.1090    0.1810      1624
           N     0.6658    0.8390    0.7424      3310
           P     0.7449    0.8338    0.7868      3610

   micro avg     0.6980    0.6980    0.6980      8544
   macro avg     0.6479    0.5939    0.5701      8544
weighted avg     0.6740    0.6980    0.6545      8544

F1-macro sent:  0.5700736541510159
F1-micro sent:  0.6980337078651685
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9270    0.9723    0.9491    124347
           N     0.8235    0.7149    0.7654     14202
           P     0.8864    0.7373    0.8050     25017

   micro avg     0.9140    0.9140    0.9140    163566
   macro avg     0.8790    0.8082    0.8398    163566
weighted avg     0.9118    0.9140    0.9111    163566

F1-macro tok:  0.8398273472027492
F1-micro tok:  0.9140285878483303
**************************************************
dev_cost_sum: 42184.97052001953
dev_cost_avg: 38.31514125342373
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.4838709677419355
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11538461538461538
dev_label=N_precision_sent: 0.664783427495292
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7361835245046925
dev_label=P_precision_sent: 0.6901669758812616
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7568667344862666
dev_precision_macro_sent: 0.6129404570394964
dev_recall_macro_sent: 0.5760354587947129
dev_f-score_macro_sent: 0.5361449581251915
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9118840579710145
dev_label=O_recall_tok: 0.970688059240975
dev_label=O_f-score_tok: 0.9403676580481243
dev_label=N_precision_tok: 0.8072033898305084
dev_label=N_recall_tok: 0.6155088852988692
dev_label=N_f-score_tok: 0.6984417965169568
dev_label=P_precision_tok: 0.8730828220858896
dev_label=P_recall_tok: 0.708904109589041
dev_label=P_f-score_tok: 0.7824742268041237
dev_precision_macro_tok: 0.8640567566291376
dev_recall_macro_tok: 0.7650336847096284
dev_f-score_macro_tok: 0.8070945604564016
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 16.934977769851685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4839    0.0655    0.1154       229
           N     0.6648    0.8248    0.7362       428
           P     0.6902    0.8378    0.7569       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6129    0.5760    0.5361      1101
weighted avg     0.6374    0.6721    0.6154      1101

F1-macro sent:  0.5361449581251915
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9707    0.9404     16205
           N     0.8072    0.6155    0.6984      1857
           P     0.8731    0.7089    0.7825      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8641    0.7650    0.8071     21274
weighted avg     0.8969    0.9002    0.8954     21274

F1-macro tok:  0.8070945604564016
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 34
**************************************************

EPOCH: 37
Learning rate: 0.656100
train_cost_sum: 294817.61346435547
train_cost_avg: 34.50580681933
train_count_sent: 8544.0
train_total_correct_sent: 5996.0
train_accuracy_sent: 0.7017790262172284
train_count_tok: 163566.0
train_total_correct_tok: 149705.0
train_accuracy_tok: 0.9152574495922136
train_label=O_precision_sent: 0.4913294797687861
train_label=O_recall_sent: 0.10467980295566502
train_label=O_f-score_sent: 0.17258883248730966
train_label=N_precision_sent: 0.6855873642645607
train_label=N_recall_sent: 0.8392749244712991
train_label=N_f-score_sent: 0.7546862265688671
train_label=P_precision_sent: 0.7351664254703328
train_label=P_recall_sent: 0.8443213296398892
train_label=P_f-score_sent: 0.7859721505930891
train_precision_macro_sent: 0.63736108983456
train_recall_macro_sent: 0.5960920190222844
train_f-score_macro_sent: 0.571082403216422
train_precision_micro_sent: 0.7017790262172284
train_recall_micro_sent: 0.7017790262172284
train_f-score_micro_sent: 0.7017790262172284
train_label=O_precision_tok: 0.9279812818840858
train_label=O_recall_tok: 0.9728180012384697
train_label=O_f-score_tok: 0.9498708294398944
train_label=N_precision_tok: 0.8282630029440629
train_label=N_recall_tok: 0.7131389945078158
train_label=N_f-score_tok: 0.7664018161180477
train_label=P_precision_tok: 0.886908449697374
train_label=P_recall_tok: 0.7438941519766559
train_label=P_f-score_tok: 0.8091304347826088
train_precision_macro_tok: 0.8810509115085076
train_recall_macro_tok: 0.8099503825743137
train_f-score_macro_tok: 0.8418010267801836
train_precision_micro_tok: 0.9152574495922136
train_recall_micro_tok: 0.9152574495922136
train_f-score_micro_tok: 0.9152574495922136
train_time: 295.76245975494385
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4913    0.1047    0.1726      1624
           N     0.6856    0.8393    0.7547      3310
           P     0.7352    0.8443    0.7860      3610

   micro avg     0.7018    0.7018    0.7018      8544
   macro avg     0.6374    0.5961    0.5711      8544
weighted avg     0.6696    0.7018    0.6573      8544

F1-macro sent:  0.571082403216422
F1-micro sent:  0.7017790262172284
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9280    0.9728    0.9499    124347
           N     0.8283    0.7131    0.7664     14202
           P     0.8869    0.7439    0.8091     25017

   micro avg     0.9153    0.9153    0.9153    163566
   macro avg     0.8811    0.8100    0.8418    163566
weighted avg     0.9130    0.9153    0.9124    163566

F1-macro tok:  0.8418010267801836
F1-micro tok:  0.9152574495922136
**************************************************
dev_cost_sum: 42018.860778808594
dev_cost_avg: 38.16426955386793
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19100.0
dev_accuracy_tok: 0.8978095327629971
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08032128514056225
dev_label=N_precision_sent: 0.7117903930131004
dev_label=N_recall_sent: 0.7616822429906542
dev_label=N_f-score_sent: 0.7358916478555304
dev_label=P_precision_sent: 0.6324237560192616
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.7385192127460168
dev_precision_macro_sent: 0.614738049677454
dev_recall_macro_sent: 0.5642459175495946
dev_f-score_macro_sent: 0.5182440485807032
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9172503089871108
dev_label=O_recall_tok: 0.9617402036408516
dev_label=O_f-score_tok: 0.9389685504277624
dev_label=N_precision_tok: 0.7496902106567535
dev_label=N_recall_tok: 0.6515885837372105
dev_label=N_f-score_tok: 0.6972054163065399
dev_label=P_precision_tok: 0.8636193330835519
dev_label=P_recall_tok: 0.7176214196762142
dev_label=P_f-score_tok: 0.7838802924672674
dev_precision_macro_tok: 0.8435199509091387
dev_recall_macro_tok: 0.7769834023514254
dev_f-score_macro_tok: 0.80668475306719
dev_precision_micro_tok: 0.8978095327629971
dev_recall_micro_tok: 0.8978095327629971
dev_f-score_micro_tok: 0.8978095327629971
dev_time: 18.99914002418518
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0437    0.0803       229
           N     0.7118    0.7617    0.7359       428
           P     0.6324    0.8874    0.7385       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6147    0.5642    0.5182      1101
weighted avg     0.6357    0.6630    0.6006      1101

F1-macro sent:  0.5182440485807032
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9173    0.9617    0.9390     16205
           N     0.7497    0.6516    0.6972      1857
           P     0.8636    0.7176    0.7839      3212

   micro avg     0.8978    0.8978    0.8978     21274
   macro avg     0.8435    0.7770    0.8067     21274
weighted avg     0.8945    0.8978    0.8944     21274

F1-macro tok:  0.80668475306719
F1-micro tok:  0.8978095327629971
**************************************************
Best epoch: 34
**************************************************

EPOCH: 38
Learning rate: 0.656100
train_cost_sum: 293698.0036621094
train_cost_avg: 34.37476634622067
train_count_sent: 8544.0
train_total_correct_sent: 6012.0
train_accuracy_sent: 0.7036516853932584
train_count_tok: 163566.0
train_total_correct_tok: 149809.0
train_accuracy_tok: 0.9158932785542228
train_label=O_precision_sent: 0.4831168831168831
train_label=O_recall_sent: 0.1145320197044335
train_label=O_f-score_sent: 0.18516674962667995
train_label=N_precision_sent: 0.6874536005939124
train_label=N_recall_sent: 0.8392749244712991
train_label=N_f-score_sent: 0.7558155353013194
train_label=P_precision_sent: 0.740165128703254
train_label=P_recall_sent: 0.8443213296398892
train_label=P_f-score_sent: 0.7888198757763976
train_precision_macro_sent: 0.6369118708046831
train_recall_macro_sent: 0.599376091271874
train_f-score_macro_sent: 0.576600720234799
train_precision_micro_sent: 0.7036516853932584
train_recall_micro_sent: 0.7036516853932584
train_f-score_micro_sent: 0.7036516853932584
train_label=O_precision_tok: 0.9297623352542451
train_label=O_recall_tok: 0.9718288338279171
train_label=O_f-score_tok: 0.9503302925448254
train_label=N_precision_tok: 0.8255339572834173
train_label=N_recall_tok: 0.7266582171525138
train_label=N_f-score_tok: 0.7729468599033816
train_label=P_precision_tok: 0.88398444908022
train_label=P_recall_tok: 0.745293200623576
train_label=P_f-score_tok: 0.8087358216400268
train_precision_macro_tok: 0.8797602472059608
train_recall_macro_tok: 0.8145934172013356
train_f-score_macro_tok: 0.8440043246960779
train_precision_micro_tok: 0.9158932785542228
train_recall_micro_tok: 0.9158932785542228
train_f-score_micro_tok: 0.9158932785542228
train_time: 300.37800335884094
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4831    0.1145    0.1852      1624
           N     0.6875    0.8393    0.7558      3310
           P     0.7402    0.8443    0.7888      3610

   micro avg     0.7037    0.7037    0.7037      8544
   macro avg     0.6369    0.5994    0.5766      8544
weighted avg     0.6709    0.7037    0.6613      8544

F1-macro sent:  0.576600720234799
F1-micro sent:  0.7036516853932584
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9298    0.9718    0.9503    124347
           N     0.8255    0.7267    0.7729     14202
           P     0.8840    0.7453    0.8087     25017

   micro avg     0.9159    0.9159    0.9159    163566
   macro avg     0.8798    0.8146    0.8440    163566
weighted avg     0.9137    0.9159    0.9133    163566

F1-macro tok:  0.8440043246960779
F1-micro tok:  0.9158932785542228
**************************************************
dev_cost_sum: 42022.200744628906
dev_cost_avg: 38.16730312863661
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19125.0
dev_accuracy_tok: 0.8989846761304879
dev_label=O_precision_sent: 0.5652173913043478
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10317460317460318
dev_label=N_precision_sent: 0.6262458471760798
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7320388349514564
dev_label=P_precision_sent: 0.7289915966386554
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7543478260869565
dev_precision_macro_sent: 0.640151611706361
dev_recall_macro_sent: 0.5730470706596079
dev_f-score_macro_sent: 0.529853754737672
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9183204758259231
dev_label=O_recall_tok: 0.9622955877815489
dev_label=O_f-score_tok: 0.9397938889893329
dev_label=N_precision_tok: 0.7676190476190476
dev_label=N_recall_tok: 0.6510500807754442
dev_label=N_f-score_tok: 0.7045454545454546
dev_label=P_precision_tok: 0.8543046357615894
dev_label=P_recall_tok: 0.7229140722291407
dev_label=P_f-score_tok: 0.7831365935919055
dev_precision_macro_tok: 0.8467480530688535
dev_recall_macro_tok: 0.7787532469287113
dev_f-score_macro_tok: 0.8091586457088976
dev_precision_micro_tok: 0.8989846761304879
dev_recall_micro_tok: 0.8989846761304879
dev_f-score_micro_tok: 0.8989846761304879
dev_time: 18.962873697280884
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5652    0.0568    0.1032       229
           N     0.6262    0.8808    0.7320       428
           P     0.7290    0.7815    0.7543       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6402    0.5730    0.5299      1101
weighted avg     0.6550    0.6694    0.6102      1101

F1-macro sent:  0.529853754737672
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9183    0.9623    0.9398     16205
           N     0.7676    0.6511    0.7045      1857
           P     0.8543    0.7229    0.7831      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8467    0.7788    0.8092     21274
weighted avg     0.8955    0.8990    0.8956     21274

F1-macro tok:  0.8091586457088976
F1-micro tok:  0.8989846761304879
**************************************************
Best epoch: 34
**************************************************

EPOCH: 39
Learning rate: 0.590490
train_cost_sum: 292560.43658447266
train_cost_avg: 34.241624132077796
train_count_sent: 8544.0
train_total_correct_sent: 6043.0
train_accuracy_sent: 0.7072799625468165
train_count_tok: 163566.0
train_total_correct_tok: 150102.0
train_accuracy_tok: 0.9176846043798833
train_label=O_precision_sent: 0.5136476426799007
train_label=O_recall_sent: 0.12746305418719212
train_label=O_f-score_sent: 0.20424272323630982
train_label=N_precision_sent: 0.6789410348977136
train_label=N_recall_sent: 0.8522658610271904
train_label=N_f-score_sent: 0.7557937039517749
train_label=P_precision_sent: 0.7563973908680381
train_label=P_recall_sent: 0.8351800554016621
train_label=P_f-score_sent: 0.7938388625592416
train_precision_macro_sent: 0.6496620228152175
train_recall_macro_sent: 0.6049696568720148
train_f-score_macro_sent: 0.5846250965824421
train_precision_micro_sent: 0.7072799625468165
train_recall_micro_sent: 0.7072799625468165
train_f-score_micro_sent: 0.7072799625468165
train_label=O_precision_tok: 0.9312526490193812
train_label=O_recall_tok: 0.9718288338279171
train_label=O_f-score_tok: 0.9511081727742098
train_label=N_precision_tok: 0.8288791384124452
train_label=N_recall_tok: 0.7315871004083931
train_label=N_f-score_tok: 0.7772001346448741
train_label=P_precision_tok: 0.8872378444465344
train_label=P_recall_tok: 0.7542071391453812
train_label=P_f-score_tok: 0.8153317632824147
train_precision_macro_tok: 0.8824565439594535
train_recall_macro_tok: 0.8192076911272305
train_f-score_macro_tok: 0.8478800235671663
train_precision_micro_tok: 0.9176846043798833
train_recall_micro_tok: 0.9176846043798833
train_f-score_micro_tok: 0.9176846043798833
train_time: 299.7065119743347
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5136    0.1275    0.2042      1624
           N     0.6789    0.8523    0.7558      3310
           P     0.7564    0.8352    0.7938      3610

   micro avg     0.7073    0.7073    0.7073      8544
   macro avg     0.6497    0.6050    0.5846      8544
weighted avg     0.6802    0.7073    0.6670      8544

F1-macro sent:  0.5846250965824421
F1-micro sent:  0.7072799625468165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9313    0.9718    0.9511    124347
           N     0.8289    0.7316    0.7772     14202
           P     0.8872    0.7542    0.8153     25017

   micro avg     0.9177    0.9177    0.9177    163566
   macro avg     0.8825    0.8192    0.8479    163566
weighted avg     0.9156    0.9177    0.9152    163566

F1-macro tok:  0.8478800235671663
F1-micro tok:  0.9176846043798833
**************************************************
dev_cost_sum: 42120.229431152344
dev_cost_avg: 38.25633917452529
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19104.0
dev_accuracy_tok: 0.8979975557017956
dev_label=O_precision_sent: 0.48333333333333334
dev_label=O_recall_sent: 0.12663755458515283
dev_label=O_f-score_sent: 0.20069204152249132
dev_label=N_precision_sent: 0.6834677419354839
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7337662337662337
dev_label=P_precision_sent: 0.6807339449541284
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7502527805864508
dev_precision_macro_sent: 0.6158450067409819
dev_recall_macro_sent: 0.5847597383123645
dev_f-score_macro_sent: 0.561570351958392
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9157530632584863
dev_label=O_recall_tok: 0.9639000308546745
dev_label=O_f-score_tok: 0.9392099092057002
dev_label=N_precision_tok: 0.7615433270082227
dev_label=N_recall_tok: 0.6483575659666129
dev_label=N_f-score_tok: 0.7004072134962188
dev_label=P_precision_tok: 0.8649468892261002
dev_label=P_recall_tok: 0.709838107098381
dev_label=P_f-score_tok: 0.7797537619699042
dev_precision_macro_tok: 0.847414426497603
dev_recall_macro_tok: 0.7740319013065561
dev_f-score_macro_tok: 0.8064569615572745
dev_precision_micro_tok: 0.8979975557017956
dev_recall_micro_tok: 0.8979975557017956
dev_f-score_micro_tok: 0.8979975557017955
dev_time: 19.07996702194214
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4833    0.1266    0.2007       229
           N     0.6835    0.7921    0.7338       428
           P     0.6807    0.8356    0.7503       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6158    0.5848    0.5616      1101
weighted avg     0.6407    0.6712    0.6295      1101

F1-macro sent:  0.561570351958392
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9158    0.9639    0.9392     16205
           N     0.7615    0.6484    0.7004      1857
           P     0.8649    0.7098    0.7798      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8474    0.7740    0.8065     21274
weighted avg     0.8946    0.8980    0.8943     21274

F1-macro tok:  0.8064569615572745
F1-micro tok:  0.8979975557017955
**************************************************
Best epoch: 39
**************************************************

EPOCH: 40
Learning rate: 0.590490
train_cost_sum: 291661.4635620117
train_cost_avg: 34.136407252108114
train_count_sent: 8544.0
train_total_correct_sent: 6076.0
train_accuracy_sent: 0.7111423220973783
train_count_tok: 163566.0
train_total_correct_tok: 150249.0
train_accuracy_tok: 0.9185833241627233
train_label=O_precision_sent: 0.48478260869565215
train_label=O_recall_sent: 0.1373152709359606
train_label=O_f-score_sent: 0.21401151631477927
train_label=N_precision_sent: 0.6926331508213042
train_label=N_recall_sent: 0.840785498489426
train_label=N_f-score_sent: 0.7595524017467249
train_label=P_precision_sent: 0.7550418101328087
train_label=P_recall_sent: 0.850415512465374
train_label=P_f-score_sent: 0.7998957790515894
train_precision_macro_sent: 0.6441525232165883
train_recall_macro_sent: 0.6095054272969201
train_f-score_macro_sent: 0.5911532323710311
train_precision_micro_sent: 0.7111423220973783
train_recall_micro_sent: 0.7111423220973783
train_f-score_micro_sent: 0.7111423220973784
train_label=O_precision_tok: 0.9321345126192331
train_label=O_recall_tok: 0.9721344302636975
train_label=O_f-score_tok: 0.9517143644451442
train_label=N_precision_tok: 0.82944
train_label=N_recall_tok: 0.7300380228136882
train_label=N_f-score_tok: 0.776571043367538
train_label=P_precision_tok: 0.8885095636720759
train_label=P_recall_tok: 0.7594435783667106
train_label=P_f-score_tok: 0.8189224137931034
train_precision_macro_tok: 0.8833613587637696
train_recall_macro_tok: 0.8205386771480322
train_f-score_macro_tok: 0.8490692738685953
train_precision_micro_tok: 0.9185833241627233
train_recall_micro_tok: 0.9185833241627233
train_f-score_micro_tok: 0.9185833241627233
train_time: 299.218798160553
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4848    0.1373    0.2140      1624
           N     0.6926    0.8408    0.7596      3310
           P     0.7550    0.8504    0.7999      3610

   micro avg     0.7111    0.7111    0.7111      8544
   macro avg     0.6442    0.6095    0.5912      8544
weighted avg     0.6795    0.7111    0.6729      8544

F1-macro sent:  0.5911532323710311
F1-micro sent:  0.7111423220973784
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9321    0.9721    0.9517    124347
           N     0.8294    0.7300    0.7766     14202
           P     0.8885    0.7594    0.8189     25017

   micro avg     0.9186    0.9186    0.9186    163566
   macro avg     0.8834    0.8205    0.8491    163566
weighted avg     0.9165    0.9186    0.9162    163566

F1-macro tok:  0.8490692738685953
F1-micro tok:  0.9185833241627233
**************************************************
dev_cost_sum: 42021.297119140625
dev_cost_avg: 38.16648239703962
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.5081967213114754
dev_label=O_recall_sent: 0.13537117903930132
dev_label=O_f-score_sent: 0.21379310344827587
dev_label=N_precision_sent: 0.6568807339449542
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7358684480986639
dev_label=P_precision_sent: 0.7212121212121212
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7603833865814698
dev_precision_macro_sent: 0.6287631921561836
dev_recall_macro_sent: 0.5919579437413988
dev_f-score_macro_sent: 0.5700149793761365
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9184384597212379
dev_label=O_recall_tok: 0.9596420857759951
dev_label=O_f-score_tok: 0.9385882849986421
dev_label=N_precision_tok: 0.7457212713936431
dev_label=N_recall_tok: 0.6569736133548735
dev_label=N_f-score_tok: 0.698539937016891
dev_label=P_precision_tok: 0.8540280857354028
dev_label=P_recall_tok: 0.7194894146948941
dev_label=P_f-score_tok: 0.7810070969922271
dev_precision_macro_tok: 0.8393959389500946
dev_recall_macro_tok: 0.7787017046085877
dev_f-score_macro_tok: 0.8060451063359201
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 17.306084871292114
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5082    0.1354    0.2138       229
           N     0.6569    0.8364    0.7359       428
           P     0.7212    0.8041    0.7604       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6288    0.5920    0.5700      1101
weighted avg     0.6519    0.6776    0.6372      1101

F1-macro sent:  0.5700149793761365
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9596    0.9386     16205
           N     0.7457    0.6570    0.6985      1857
           P     0.8540    0.7195    0.7810      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8394    0.7787    0.8060     21274
weighted avg     0.8936    0.8970    0.8938     21274

F1-macro tok:  0.8060451063359201
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 40
**************************************************

EPOCH: 41
Learning rate: 0.590490
train_cost_sum: 290871.7611694336
train_cost_avg: 34.04397953762097
train_count_sent: 8544.0
train_total_correct_sent: 6017.0
train_accuracy_sent: 0.7042368913857678
train_count_tok: 163566.0
train_total_correct_tok: 150538.0
train_accuracy_tok: 0.9203501950283066
train_label=O_precision_sent: 0.4745762711864407
train_label=O_recall_sent: 0.1206896551724138
train_label=O_f-score_sent: 0.19243986254295536
train_label=N_precision_sent: 0.6962628542763983
train_label=N_recall_sent: 0.8386706948640483
train_label=N_f-score_sent: 0.7608606276552009
train_label=P_precision_sent: 0.7347972972972973
train_label=P_recall_sent: 0.8434903047091413
train_label=P_f-score_sent: 0.7854010833118391
train_precision_macro_sent: 0.6352121409200454
train_recall_macro_sent: 0.6009502182485345
train_f-score_macro_sent: 0.5795671911699984
train_precision_micro_sent: 0.7042368913857678
train_recall_micro_sent: 0.7042368913857678
train_f-score_micro_sent: 0.7042368913857678
train_label=O_precision_tok: 0.9340385283557889
train_label=O_recall_tok: 0.9728582112958093
train_label=O_f-score_tok: 0.9530532336466268
train_label=N_precision_tok: 0.8325511096969215
train_label=N_recall_tok: 0.7369384593719195
train_label=N_f-score_tok: 0.7818324431330071
train_label=P_precision_tok: 0.8891992551210428
train_label=P_recall_tok: 0.7634808330335372
train_label=P_f-score_tok: 0.8215583801105447
train_precision_macro_tok: 0.885262964391251
train_recall_macro_tok: 0.8244258345670886
train_f-score_macro_tok: 0.8521480189633929
train_precision_micro_tok: 0.9203501950283066
train_recall_micro_tok: 0.9203501950283066
train_f-score_micro_tok: 0.9203501950283066
train_time: 303.27416467666626
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4746    0.1207    0.1924      1624
           N     0.6963    0.8387    0.7609      3310
           P     0.7348    0.8435    0.7854      3610

   micro avg     0.7042    0.7042    0.7042      8544
   macro avg     0.6352    0.6010    0.5796      8544
weighted avg     0.6704    0.7042    0.6632      8544

F1-macro sent:  0.5795671911699984
F1-micro sent:  0.7042368913857678
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9340    0.9729    0.9531    124347
           N     0.8326    0.7369    0.7818     14202
           P     0.8892    0.7635    0.8216     25017

   micro avg     0.9204    0.9204    0.9204    163566
   macro avg     0.8853    0.8244    0.8521    163566
weighted avg     0.9184    0.9204    0.9181    163566

F1-macro tok:  0.8521480189633929
F1-micro tok:  0.9203501950283066
**************************************************
dev_cost_sum: 42106.98016357422
dev_cost_avg: 38.244305325680486
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19120.0
dev_accuracy_tok: 0.8987496474569897
dev_label=O_precision_sent: 0.3783783783783784
dev_label=O_recall_sent: 0.1222707423580786
dev_label=O_f-score_sent: 0.18481848184818483
dev_label=N_precision_sent: 0.6991525423728814
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.7333333333333334
dev_label=P_precision_sent: 0.6792792792792792
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7547547547547546
dev_precision_macro_sent: 0.5856034000101796
dev_recall_macro_sent: 0.580799292946785
dev_f-score_macro_sent: 0.557635523312091
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9197494386006382
dev_label=O_recall_tok: 0.9604443073125578
dev_label=O_f-score_tok: 0.939656473571407
dev_label=N_precision_tok: 0.7775603392041748
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.7032448377581122
dev_label=P_precision_tok: 0.8385952465413267
dev_label=P_recall_tok: 0.7359900373599004
dev_label=P_f-score_tok: 0.7839495937655447
dev_precision_macro_tok: 0.8453016747820467
dev_recall_macro_tok: 0.7794432916992919
dev_f-score_macro_tok: 0.8089503016983546
dev_precision_micro_tok: 0.8987496474569897
dev_recall_micro_tok: 0.8987496474569897
dev_f-score_micro_tok: 0.8987496474569897
dev_time: 19.093247413635254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3784    0.1223    0.1848       229
           N     0.6992    0.7710    0.7333       428
           P     0.6793    0.8491    0.7548       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.5856    0.5808    0.5576      1101
weighted avg     0.6244    0.6676    0.6279      1101

F1-macro sent:  0.557635523312091
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9604    0.9397     16205
           N     0.7776    0.6419    0.7032      1857
           P     0.8386    0.7360    0.7839      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8453    0.7794    0.8090     21274
weighted avg     0.8951    0.8987    0.8955     21274

F1-macro tok:  0.8089503016983546
F1-micro tok:  0.8987496474569897
**************************************************
Best epoch: 40
**************************************************

EPOCH: 42
Learning rate: 0.590490
train_cost_sum: 289930.51818847656
train_cost_avg: 33.93381533104829
train_count_sent: 8544.0
train_total_correct_sent: 6034.0
train_accuracy_sent: 0.7062265917602997
train_count_tok: 163566.0
train_total_correct_tok: 150869.0
train_accuracy_tok: 0.9223738429747014
train_label=O_precision_sent: 0.48036951501154734
train_label=O_recall_sent: 0.12807881773399016
train_label=O_f-score_sent: 0.20223626640738943
train_label=N_precision_sent: 0.6863905325443787
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.7559055118110236
train_label=P_precision_sent: 0.7501849568434033
train_label=P_recall_sent: 0.8426592797783934
train_label=P_f-score_sent: 0.7937377690802347
train_precision_macro_sent: 0.6389816681331096
train_recall_macro_sent: 0.6039419036018117
train_f-score_macro_sent: 0.5839598490995493
train_precision_micro_sent: 0.7062265917602997
train_recall_micro_sent: 0.7062265917602997
train_f-score_micro_sent: 0.7062265917602997
train_label=O_precision_tok: 0.9358279257191031
train_label=O_recall_tok: 0.9730512195710391
train_label=O_f-score_tok: 0.9540766440624506
train_label=N_precision_tok: 0.834028816628612
train_label=N_recall_tok: 0.7458808618504436
train_label=N_f-score_tok: 0.7874958183102256
train_label=P_precision_tok: 0.8937511589096978
train_label=P_recall_tok: 0.7706759403605549
train_label=P_f-score_tok: 0.8276631822962502
train_precision_macro_tok: 0.8878693004191377
train_recall_macro_tok: 0.8298693405940125
train_f-score_macro_tok: 0.8564118815563089
train_precision_micro_tok: 0.9223738429747014
train_recall_micro_tok: 0.9223738429747014
train_f-score_micro_tok: 0.9223738429747014
train_time: 296.8592052459717
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4804    0.1281    0.2022      1624
           N     0.6864    0.8411    0.7559      3310
           P     0.7502    0.8427    0.7937      3610

   micro avg     0.7062    0.7062    0.7062      8544
   macro avg     0.6390    0.6039    0.5840      8544
weighted avg     0.6742    0.7062    0.6667      8544

F1-macro sent:  0.5839598490995493
F1-micro sent:  0.7062265917602997
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9358    0.9731    0.9541    124347
           N     0.8340    0.7459    0.7875     14202
           P     0.8938    0.7707    0.8277     25017

   micro avg     0.9224    0.9224    0.9224    163566
   macro avg     0.8879    0.8299    0.8564    163566
weighted avg     0.9206    0.9224    0.9203    163566

F1-macro tok:  0.8564118815563089
F1-micro tok:  0.9223738429747014
**************************************************
dev_cost_sum: 42349.98956298828
dev_cost_avg: 38.46502230970779
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19142.0
dev_accuracy_tok: 0.8997837736203816
dev_label=O_precision_sent: 0.423728813559322
dev_label=O_recall_sent: 0.1091703056768559
dev_label=O_f-score_sent: 0.1736111111111111
dev_label=N_precision_sent: 0.666023166023166
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7293868921775898
dev_label=P_precision_sent: 0.6965648854961832
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7541322314049588
dev_precision_macro_sent: 0.5954389550262238
dev_recall_macro_sent: 0.5791057147013561
dev_f-score_macro_sent: 0.5523767448978866
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9145373935363434
dev_label=O_recall_tok: 0.9674174637457574
dev_label=O_f-score_tok: 0.9402345038534201
dev_label=N_precision_tok: 0.815
dev_label=N_recall_tok: 0.6144318793753366
dev_label=N_f-score_tok: 0.7006447651212772
dev_label=P_precision_tok: 0.8506588579795022
dev_label=P_recall_tok: 0.7235367372353674
dev_label=P_f-score_tok: 0.7819650067294752
dev_precision_macro_tok: 0.8600654171719485
dev_recall_macro_tok: 0.7684620267854871
dev_f-score_macro_tok: 0.8076147585680574
dev_precision_micro_tok: 0.8997837736203816
dev_recall_micro_tok: 0.8997837736203816
dev_f-score_micro_tok: 0.8997837736203816
dev_time: 17.6101975440979
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4237    0.1092    0.1736       229
           N     0.6660    0.8061    0.7294       428
           P     0.6966    0.8221    0.7541       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.5954    0.5791    0.5524      1101
weighted avg     0.6279    0.6676    0.6238      1101

F1-macro sent:  0.5523767448978866
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9145    0.9674    0.9402     16205
           N     0.8150    0.6144    0.7006      1857
           P     0.8507    0.7235    0.7820      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8601    0.7685    0.8076     21274
weighted avg     0.8962    0.8998    0.8954     21274

F1-macro tok:  0.8076147585680574
F1-micro tok:  0.8997837736203816
**************************************************
Best epoch: 40
**************************************************

EPOCH: 43
Learning rate: 0.590490
train_cost_sum: 288806.73333740234
train_cost_avg: 33.80228620522031
train_count_sent: 8544.0
train_total_correct_sent: 6097.0
train_accuracy_sent: 0.7136001872659176
train_count_tok: 163566.0
train_total_correct_tok: 150999.0
train_accuracy_tok: 0.9231686291772129
train_label=O_precision_sent: 0.48253275109170307
train_label=O_recall_sent: 0.13608374384236452
train_label=O_f-score_sent: 0.21229586935638808
train_label=N_precision_sent: 0.6915704104202507
train_label=N_recall_sent: 0.8501510574018127
train_label=N_f-score_sent: 0.762704973573655
train_label=P_precision_sent: 0.7622603933283545
train_label=P_recall_sent: 0.8481994459833795
train_label=P_f-score_sent: 0.8029369345745379
train_precision_macro_sent: 0.6454545182801027
train_recall_macro_sent: 0.6114780824091856
train_f-score_macro_sent: 0.5926459258348603
train_precision_micro_sent: 0.7136001872659176
train_recall_micro_sent: 0.7136001872659176
train_f-score_micro_sent: 0.7136001872659176
train_label=O_precision_tok: 0.9368927525452094
train_label=O_recall_tok: 0.972448068710946
train_label=O_f-score_tok: 0.9543393590699768
train_label=N_precision_tok: 0.8409788338972382
train_label=N_recall_tok: 0.7525700605548514
train_label=N_f-score_tok: 0.794322024450968
train_label=P_precision_tok: 0.8898168968840346
train_label=P_recall_tok: 0.7750729503937323
train_label=P_f-score_tok: 0.8284908562638864
train_precision_macro_tok: 0.8892294944421608
train_recall_macro_tok: 0.8333636932198433
train_f-score_macro_tok: 0.8590507465949436
train_precision_micro_tok: 0.9231686291772129
train_recall_micro_tok: 0.9231686291772129
train_f-score_micro_tok: 0.9231686291772129
train_time: 305.89622235298157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4825    0.1361    0.2123      1624
           N     0.6916    0.8502    0.7627      3310
           P     0.7623    0.8482    0.8029      3610

   micro avg     0.7136    0.7136    0.7136      8544
   macro avg     0.6455    0.6115    0.5926      8544
weighted avg     0.6817    0.7136    0.6751      8544

F1-macro sent:  0.5926459258348603
F1-micro sent:  0.7136001872659176
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9369    0.9724    0.9543    124347
           N     0.8410    0.7526    0.7943     14202
           P     0.8898    0.7751    0.8285     25017

   micro avg     0.9232    0.9232    0.9232    163566
   macro avg     0.8892    0.8334    0.8591    163566
weighted avg     0.9214    0.9232    0.9212    163566

F1-macro tok:  0.8590507465949436
F1-micro tok:  0.9231686291772129
**************************************************
dev_cost_sum: 42310.960205078125
dev_cost_avg: 38.42957330161501
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19175.0
dev_accuracy_tok: 0.9013349628654695
dev_label=O_precision_sent: 0.5357142857142857
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11673151750972761
dev_label=N_precision_sent: 0.6487455197132617
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7342799188640974
dev_label=P_precision_sent: 0.6951456310679611
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7466110531803962
dev_precision_macro_sent: 0.6265351454985028
dev_recall_macro_sent: 0.5725342940785948
dev_f-score_macro_sent: 0.532540829851407
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9109917403107491
dev_label=O_recall_tok: 0.9732798518975625
dev_label=O_f-score_tok: 0.9411062712572349
dev_label=N_precision_tok: 0.8046875
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6940275650842267
dev_label=P_precision_tok: 0.8891500195848022
dev_label=P_recall_tok: 0.7067247820672479
dev_label=P_f-score_tok: 0.787510841283608
dev_precision_macro_tok: 0.8682764199651838
dev_recall_macro_tok: 0.7633761632153387
dev_f-score_macro_tok: 0.8075482258750233
dev_precision_micro_tok: 0.9013349628654695
dev_recall_micro_tok: 0.9013349628654695
dev_f-score_micro_tok: 0.9013349628654695
dev_time: 17.371307849884033
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5357    0.0655    0.1167       229
           N     0.6487    0.8458    0.7343       428
           P     0.6951    0.8063    0.7466       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6265    0.5725    0.5325      1101
weighted avg     0.6439    0.6676    0.6108      1101

F1-macro sent:  0.532540829851407
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9733    0.9411     16205
           N     0.8047    0.6101    0.6940      1857
           P     0.8892    0.7067    0.7875      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8683    0.7634    0.8075     21274
weighted avg     0.8984    0.9013    0.8963     21274

F1-macro tok:  0.8075482258750233
F1-micro tok:  0.9013349628654695
**************************************************
Best epoch: 40
**************************************************

EPOCH: 44
Learning rate: 0.590490
train_cost_sum: 288141.6536254883
train_cost_avg: 33.72444447863861
train_count_sent: 8544.0
train_total_correct_sent: 6091.0
train_accuracy_sent: 0.7128979400749064
train_count_tok: 163566.0
train_total_correct_tok: 151194.0
train_accuracy_tok: 0.9243608084809801
train_label=O_precision_sent: 0.4924406047516199
train_label=O_recall_sent: 0.14039408866995073
train_label=O_f-score_sent: 0.21849544801149975
train_label=N_precision_sent: 0.6976570289132602
train_label=N_recall_sent: 0.845619335347432
train_label=N_f-score_sent: 0.7645452062278065
train_label=P_precision_sent: 0.7530105677070533
train_label=P_recall_sent: 0.8487534626038781
train_label=P_f-score_sent: 0.7980205755957808
train_precision_macro_sent: 0.6477027337906445
train_recall_macro_sent: 0.611588962207087
train_f-score_macro_sent: 0.5936870766116957
train_precision_micro_sent: 0.7128979400749064
train_recall_micro_sent: 0.7128979400749064
train_f-score_micro_sent: 0.7128979400749064
train_label=O_precision_tok: 0.9385135869143505
train_label=O_recall_tok: 0.9726812870435153
train_label=O_f-score_tok: 0.9552920176446662
train_label=N_precision_tok: 0.8397386027695659
train_label=N_recall_tok: 0.7600337980566118
train_label=N_f-score_tok: 0.7979006505026611
train_label=P_precision_tok: 0.8906493268614342
train_label=P_recall_tok: 0.7774713195027382
train_label=P_f-score_tok: 0.8302208942482125
train_precision_macro_tok: 0.8896338388484502
train_recall_macro_tok: 0.8367288015342885
train_f-score_macro_tok: 0.8611378541318467
train_precision_micro_tok: 0.9243608084809801
train_recall_micro_tok: 0.9243608084809801
train_f-score_micro_tok: 0.9243608084809801
train_time: 255.7786214351654
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4924    0.1404    0.2185      1624
           N     0.6977    0.8456    0.7645      3310
           P     0.7530    0.8488    0.7980      3610

   micro avg     0.7129    0.7129    0.7129      8544
   macro avg     0.6477    0.6116    0.5937      8544
weighted avg     0.6820    0.7129    0.6749      8544

F1-macro sent:  0.5936870766116957
F1-micro sent:  0.7128979400749064
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9385    0.9727    0.9553    124347
           N     0.8397    0.7600    0.7979     14202
           P     0.8906    0.7775    0.8302     25017

   micro avg     0.9244    0.9244    0.9244    163566
   macro avg     0.8896    0.8367    0.8611    163566
weighted avg     0.9226    0.9244    0.9225    163566

F1-macro tok:  0.8611378541318467
F1-micro tok:  0.9243608084809801
**************************************************
dev_cost_sum: 42222.533142089844
dev_cost_avg: 38.34925807637588
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19146.0
dev_accuracy_tok: 0.8999717965591802
dev_label=O_precision_sent: 0.33636363636363636
dev_label=O_recall_sent: 0.1615720524017467
dev_label=O_f-score_sent: 0.21828908554572268
dev_label=N_precision_sent: 0.6666666666666666
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7130434782608696
dev_label=P_precision_sent: 0.7034068136272545
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7444326617179216
dev_precision_macro_sent: 0.5688123722191859
dev_recall_macro_sent: 0.5728225777097343
dev_f-score_macro_sent: 0.5585884085081713
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9181909074869141
dev_label=O_recall_tok: 0.9634063560629436
dev_label=O_f-score_tok: 0.9402553601541798
dev_label=N_precision_tok: 0.7765614938828075
dev_label=N_recall_tok: 0.6494345718901454
dev_label=N_f-score_tok: 0.7073313782991203
dev_label=P_precision_tok: 0.8565121412803532
dev_label=P_recall_tok: 0.7247820672478207
dev_label=P_f-score_tok: 0.7851602023608769
dev_precision_macro_tok: 0.8504215142166917
dev_recall_macro_tok: 0.7792076650669699
dev_f-score_macro_tok: 0.8109156469380591
dev_precision_micro_tok: 0.8999717965591802
dev_recall_micro_tok: 0.8999717965591802
dev_f-score_micro_tok: 0.8999717965591802
dev_time: 15.522943496704102
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3364    0.1616    0.2183       229
           N     0.6667    0.7664    0.7130       428
           P     0.7034    0.7905    0.7444       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.5688    0.5728    0.5586      1101
weighted avg     0.6128    0.6503    0.6228      1101

F1-macro sent:  0.5585884085081713
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9182    0.9634    0.9403     16205
           N     0.7766    0.6494    0.7073      1857
           P     0.8565    0.7248    0.7852      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8504    0.7792    0.8109     21274
weighted avg     0.8965    0.9000    0.8965     21274

F1-macro tok:  0.8109156469380591
F1-micro tok:  0.8999717965591802
**************************************************
Best epoch: 40
**************************************************

EPOCH: 45
Learning rate: 0.531441
train_cost_sum: 286905.13970947266
train_cost_avg: 33.5797214079439
train_count_sent: 8544.0
train_total_correct_sent: 6151.0
train_accuracy_sent: 0.7199204119850188
train_count_tok: 163566.0
train_total_correct_tok: 151519.0
train_accuracy_tok: 0.926347773987259
train_label=O_precision_sent: 0.5106382978723404
train_label=O_recall_sent: 0.1477832512315271
train_label=O_f-score_sent: 0.22922636103151864
train_label=N_precision_sent: 0.7017059708981435
train_label=N_recall_sent: 0.8450151057401812
train_label=N_f-score_sent: 0.7667214912280701
train_label=P_precision_sent: 0.7617416829745597
train_label=P_recall_sent: 0.8626038781163435
train_label=P_f-score_sent: 0.8090413094310211
train_precision_macro_sent: 0.6580286505816813
train_recall_macro_sent: 0.6184674116960173
train_f-score_macro_sent: 0.6016630538968699
train_precision_micro_sent: 0.7199204119850188
train_recall_micro_sent: 0.7199204119850188
train_f-score_micro_sent: 0.7199204119850188
train_label=O_precision_tok: 0.9397607198590094
train_label=O_recall_tok: 0.9734372361214987
train_label=O_f-score_tok: 0.9563025873987754
train_label=N_precision_tok: 0.8430900621118013
train_label=N_recall_tok: 0.7646106182227855
train_label=N_f-score_tok: 0.8019348644856363
train_label=P_precision_tok: 0.8964036009687886
train_label=P_recall_tok: 0.7841068073709877
train_label=P_f-score_tok: 0.836503198294243
train_precision_macro_tok: 0.8930847943131998
train_recall_macro_tok: 0.8407182205717573
train_f-score_macro_tok: 0.8649135500595516
train_precision_micro_tok: 0.926347773987259
train_recall_micro_tok: 0.926347773987259
train_f-score_micro_tok: 0.926347773987259
train_time: 246.38409185409546
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5106    0.1478    0.2292      1624
           N     0.7017    0.8450    0.7667      3310
           P     0.7617    0.8626    0.8090      3610

   micro avg     0.7199    0.7199    0.7199      8544
   macro avg     0.6580    0.6185    0.6017      8544
weighted avg     0.6908    0.7199    0.6824      8544

F1-macro sent:  0.6016630538968699
F1-micro sent:  0.7199204119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9398    0.9734    0.9563    124347
           N     0.8431    0.7646    0.8019     14202
           P     0.8964    0.7841    0.8365     25017

   micro avg     0.9263    0.9263    0.9263    163566
   macro avg     0.8931    0.8407    0.8649    163566
weighted avg     0.9247    0.9263    0.9246    163566

F1-macro tok:  0.8649135500595516
F1-micro tok:  0.926347773987259
**************************************************
dev_cost_sum: 42215.78112792969
dev_cost_avg: 38.34312545679354
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19066.0
dev_accuracy_tok: 0.8962113377832096
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.07874015748031496
dev_label=N_precision_sent: 0.6288135593220339
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7288801571709232
dev_label=P_precision_sent: 0.7263374485596708
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7591397849462366
dev_precision_macro_sent: 0.5850503359605682
dev_recall_macro_sent: 0.5685118657407765
dev_f-score_macro_sent: 0.5222533665324915
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9213142074876496
dev_label=O_recall_tok: 0.9551990126504165
dev_label=O_f-score_tok: 0.937950675634733
dev_label=N_precision_tok: 0.7374701670644391
dev_label=N_recall_tok: 0.6655896607431341
dev_label=N_f-score_tok: 0.6996886498726295
dev_label=P_precision_tok: 0.8405434393993565
dev_label=P_recall_tok: 0.7319427148194272
dev_label=P_f-score_tok: 0.7824929272757531
dev_precision_macro_tok: 0.8331092713171483
dev_recall_macro_tok: 0.7842437960709926
dev_f-score_macro_tok: 0.8067107509277052
dev_precision_micro_tok: 0.8962113377832096
dev_recall_micro_tok: 0.8962113377832096
dev_f-score_micro_tok: 0.8962113377832096
dev_time: 14.72572374343872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0437    0.0787       229
           N     0.6288    0.8668    0.7289       428
           P     0.7263    0.7950    0.7591       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.5851    0.5685    0.5223      1101
weighted avg     0.6206    0.6667    0.6059      1101

F1-macro sent:  0.5222533665324915
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9213    0.9552    0.9380     16205
           N     0.7375    0.6656    0.6997      1857
           P     0.8405    0.7319    0.7825      3212

   micro avg     0.8962    0.8962    0.8962     21274
   macro avg     0.8331    0.7842    0.8067     21274
weighted avg     0.8931    0.8962    0.8937     21274

F1-macro tok:  0.8067107509277052
F1-micro tok:  0.8962113377832096
**************************************************
Best epoch: 40
**************************************************

EPOCH: 46
Learning rate: 0.478297
train_cost_sum: 286327.5650024414
train_cost_avg: 33.51212137200859
train_count_sent: 8544.0
train_total_correct_sent: 6163.0
train_accuracy_sent: 0.7213249063670412
train_count_tok: 163566.0
train_total_correct_tok: 151492.0
train_accuracy_tok: 0.9261827030067373
train_label=O_precision_sent: 0.4967462039045553
train_label=O_recall_sent: 0.14100985221674878
train_label=O_f-score_sent: 0.2196642685851319
train_label=N_precision_sent: 0.6992628992628993
train_label=N_recall_sent: 0.8598187311178248
train_label=N_f-score_sent: 0.7712737127371274
train_label=P_precision_sent: 0.7694991278345378
train_label=P_recall_sent: 0.8554016620498615
train_label=P_f-score_sent: 0.8101797192706283
train_precision_macro_sent: 0.6551694103339974
train_recall_macro_sent: 0.618743415128145
train_f-score_macro_sent: 0.6003725668642959
train_precision_micro_sent: 0.7213249063670412
train_recall_micro_sent: 0.7213249063670412
train_f-score_micro_sent: 0.7213249063670412
train_label=O_precision_tok: 0.9403959611034676
train_label=O_recall_tok: 0.9729305893990204
train_label=O_f-score_tok: 0.9563866622397191
train_label=N_precision_tok: 0.841241443683883
train_label=N_recall_tok: 0.7615124630333756
train_label=N_f-score_tok: 0.7993938945967921
train_label=P_precision_tok: 0.8927972440052582
train_label=P_recall_tok: 0.7873046328496622
train_label=P_f-score_tok: 0.8367390288457455
train_precision_macro_tok: 0.8914782162642029
train_recall_macro_tok: 0.840582561760686
train_f-score_macro_tok: 0.8641731952274189
train_precision_micro_tok: 0.9261827030067373
train_recall_micro_tok: 0.9261827030067373
train_f-score_micro_tok: 0.9261827030067373
train_time: 252.57185006141663
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4967    0.1410    0.2197      1624
           N     0.6993    0.8598    0.7713      3310
           P     0.7695    0.8554    0.8102      3610

   micro avg     0.7213    0.7213    0.7213      8544
   macro avg     0.6552    0.6187    0.6004      8544
weighted avg     0.6904    0.7213    0.6829      8544

F1-macro sent:  0.6003725668642959
F1-micro sent:  0.7213249063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9404    0.9729    0.9564    124347
           N     0.8412    0.7615    0.7994     14202
           P     0.8928    0.7873    0.8367     25017

   micro avg     0.9262    0.9262    0.9262    163566
   macro avg     0.8915    0.8406    0.8642    163566
weighted avg     0.9245    0.9262    0.9245    163566

F1-macro tok:  0.8641731952274189
F1-micro tok:  0.9261827030067373
**************************************************
dev_cost_sum: 42144.64776611328
dev_cost_avg: 38.27851749874049
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19127.0
dev_accuracy_tok: 0.8990786875998872
dev_label=O_precision_sent: 0.4473684210526316
dev_label=O_recall_sent: 0.14847161572052403
dev_label=O_f-score_sent: 0.2229508196721312
dev_label=N_precision_sent: 0.6849894291754757
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.7192008879023307
dev_label=P_precision_sent: 0.677536231884058
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.751004016064257
dev_precision_macro_sent: 0.6032980273707218
dev_recall_macro_sent: 0.5826077679524196
dev_f-score_macro_sent: 0.5643852412129063
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9168622389110538
dev_label=O_recall_tok: 0.964331996297439
dev_label=O_f-score_tok: 0.9399981954344491
dev_label=N_precision_tok: 0.7787318361955086
dev_label=N_recall_tok: 0.6348949919224556
dev_label=N_f-score_tok: 0.6994956986057549
dev_label=P_precision_tok: 0.8545655375552282
dev_label=P_recall_tok: 0.7226027397260274
dev_label=P_f-score_tok: 0.7830634278002699
dev_precision_macro_tok: 0.8500532042205968
dev_recall_macro_tok: 0.7739432426486407
dev_f-score_macro_tok: 0.8075191072801579
dev_precision_micro_tok: 0.8990786875998872
dev_recall_micro_tok: 0.8990786875998872
dev_f-score_micro_tok: 0.8990786875998872
dev_time: 15.469706058502197
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4474    0.1485    0.2230       229
           N     0.6850    0.7570    0.7192       428
           P     0.6775    0.8423    0.7510       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6033    0.5826    0.5644      1101
weighted avg     0.6326    0.6649    0.6288      1101

F1-macro sent:  0.5643852412129063
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9169    0.9643    0.9400     16205
           N     0.7787    0.6349    0.6995      1857
           P     0.8546    0.7226    0.7831      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8501    0.7739    0.8075     21274
weighted avg     0.8954    0.8991    0.8953     21274

F1-macro tok:  0.8075191072801579
F1-micro tok:  0.8990786875998872
**************************************************
Best epoch: 40
**************************************************

EPOCH: 47
Learning rate: 0.430467
train_cost_sum: 285633.6993408203
train_cost_avg: 33.43091050337316
train_count_sent: 8544.0
train_total_correct_sent: 6120.0
train_accuracy_sent: 0.7162921348314607
train_count_tok: 163566.0
train_total_correct_tok: 151767.0
train_accuracy_tok: 0.9278639815120502
train_label=O_precision_sent: 0.4779270633397313
train_label=O_recall_sent: 0.15332512315270935
train_label=O_f-score_sent: 0.23216783216783216
train_label=N_precision_sent: 0.6941378464557273
train_label=N_recall_sent: 0.8549848942598187
train_label=N_f-score_sent: 0.7662109110599703
train_label=P_precision_sent: 0.7706538266599088
train_label=P_recall_sent: 0.842382271468144
train_label=P_f-score_sent: 0.8049232398094229
train_precision_macro_sent: 0.6475729121517891
train_recall_macro_sent: 0.6168974296268908
train_f-score_macro_sent: 0.6011006610124084
train_precision_micro_sent: 0.7162921348314607
train_recall_micro_sent: 0.7162921348314607
train_f-score_micro_sent: 0.7162921348314606
train_label=O_precision_tok: 0.942043091969507
train_label=O_recall_tok: 0.9729225473875526
train_label=O_f-score_tok: 0.9572338489535941
train_label=N_precision_tok: 0.8445336008024072
train_label=N_recall_tok: 0.7707365159836643
train_label=N_f-score_tok: 0.8059492692265213
train_label=P_precision_tok: 0.8944639798034443
train_label=P_recall_tok: 0.7931006915297598
train_label=P_f-score_tok: 0.8407381512320176
train_precision_macro_tok: 0.8936802241917862
train_recall_macro_tok: 0.8455865849669921
train_f-score_macro_tok: 0.8679737564707111
train_precision_micro_tok: 0.9278639815120502
train_recall_micro_tok: 0.9278639815120502
train_f-score_micro_tok: 0.9278639815120502
train_time: 247.30584955215454
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4779    0.1533    0.2322      1624
           N     0.6941    0.8550    0.7662      3310
           P     0.7707    0.8424    0.8049      3610

   micro avg     0.7163    0.7163    0.7163      8544
   macro avg     0.6476    0.6169    0.6011      8544
weighted avg     0.6854    0.7163    0.6811      8544

F1-macro sent:  0.6011006610124084
F1-micro sent:  0.7162921348314606
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9420    0.9729    0.9572    124347
           N     0.8445    0.7707    0.8059     14202
           P     0.8945    0.7931    0.8407     25017

   micro avg     0.9279    0.9279    0.9279    163566
   macro avg     0.8937    0.8456    0.8680    163566
weighted avg     0.9263    0.9279    0.9263    163566

F1-macro tok:  0.8679737564707111
F1-micro tok:  0.9278639815120502
**************************************************
dev_cost_sum: 42141.992736816406
dev_cost_avg: 38.27610602798947
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19142.0
dev_accuracy_tok: 0.8997837736203816
dev_label=O_precision_sent: 0.3880597014925373
dev_label=O_recall_sent: 0.11353711790393013
dev_label=O_f-score_sent: 0.17567567567567566
dev_label=N_precision_sent: 0.6673114119922631
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7301587301587302
dev_label=P_precision_sent: 0.6943907156673114
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7471383975026015
dev_precision_macro_sent: 0.5832539430507039
dev_recall_macro_sent: 0.576056814272543
dev_f-score_macro_sent: 0.550990934445669
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9165445701224872
dev_label=O_recall_tok: 0.9650725084850355
dev_label=O_f-score_tok: 0.940182758206084
dev_label=N_precision_tok: 0.783180026281209
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.7055341817105653
dev_label=P_precision_tok: 0.8594272963927111
dev_label=P_recall_tok: 0.7194894146948941
dev_label=P_f-score_tok: 0.7832570750720217
dev_precision_macro_tok: 0.8530506309321358
dev_recall_macro_tok: 0.7754858178684491
dev_f-score_macro_tok: 0.8096580049962236
dev_precision_micro_tok: 0.8997837736203816
dev_recall_micro_tok: 0.8997837736203816
dev_f-score_micro_tok: 0.8997837736203816
dev_time: 15.127219915390015
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3881    0.1135    0.1757       229
           N     0.6673    0.8061    0.7302       428
           P     0.6944    0.8086    0.7471       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.5833    0.5761    0.5510      1101
weighted avg     0.6201    0.6630    0.6217      1101

F1-macro sent:  0.550990934445669
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9165    0.9651    0.9402     16205
           N     0.7832    0.6419    0.7055      1857
           P     0.8594    0.7195    0.7833      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8531    0.7755    0.8097     21274
weighted avg     0.8963    0.8998    0.8960     21274

F1-macro tok:  0.8096580049962236
F1-micro tok:  0.8997837736203816
**************************************************
Best epoch: 40
**************************************************

test0_cost_sum: 42021.297119140625
test0_cost_avg: 38.16648239703962
test0_count_sent: 1101.0
test0_total_correct_sent: 746.0
test0_accuracy_sent: 0.6775658492279746
test0_count_tok: 21274.0
test0_total_correct_tok: 19082.0
test0_accuracy_tok: 0.8969634295384037
test0_label=O_precision_sent: 0.5081967213114754
test0_label=O_recall_sent: 0.13537117903930132
test0_label=O_f-score_sent: 0.21379310344827587
test0_label=N_precision_sent: 0.6568807339449542
test0_label=N_recall_sent: 0.8364485981308412
test0_label=N_f-score_sent: 0.7358684480986639
test0_label=P_precision_sent: 0.7212121212121212
test0_label=P_recall_sent: 0.8040540540540541
test0_label=P_f-score_sent: 0.7603833865814698
test0_precision_macro_sent: 0.6287631921561836
test0_recall_macro_sent: 0.5919579437413988
test0_f-score_macro_sent: 0.5700149793761365
test0_precision_micro_sent: 0.6775658492279746
test0_recall_micro_sent: 0.6775658492279746
test0_f-score_micro_sent: 0.6775658492279746
test0_label=O_precision_tok: 0.9184384597212379
test0_label=O_recall_tok: 0.9596420857759951
test0_label=O_f-score_tok: 0.9385882849986421
test0_label=N_precision_tok: 0.7457212713936431
test0_label=N_recall_tok: 0.6569736133548735
test0_label=N_f-score_tok: 0.698539937016891
test0_label=P_precision_tok: 0.8540280857354028
test0_label=P_recall_tok: 0.7194894146948941
test0_label=P_f-score_tok: 0.7810070969922271
test0_precision_macro_tok: 0.8393959389500946
test0_recall_macro_tok: 0.7787017046085877
test0_f-score_macro_tok: 0.8060451063359201
test0_precision_micro_tok: 0.8969634295384037
test0_recall_micro_tok: 0.8969634295384037
test0_f-score_micro_tok: 0.8969634295384037
test0_time: 13.925868034362793
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5082    0.1354    0.2138       229
           N     0.6569    0.8364    0.7359       428
           P     0.7212    0.8041    0.7604       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6288    0.5920    0.5700      1101
weighted avg     0.6519    0.6776    0.6372      1101

F1-macro sent:  0.5700149793761365
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9596    0.9386     16205
           N     0.7457    0.6570    0.6985      1857
           P     0.8540    0.7195    0.7810      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8394    0.7787    0.8060     21274
weighted avg     0.8936    0.8970    0.8938     21274

F1-macro tok:  0.8060451063359201
F1-micro tok:  0.8969634295384037
**************************************************
test1_cost_sum: 81120.21227836609
test1_cost_avg: 36.70597840650049
test1_count_sent: 2210.0
test1_total_correct_sent: 1560.0
test1_accuracy_sent: 0.7058823529411765
test1_count_tok: 42405.0
test1_total_correct_tok: 37849.0
test1_accuracy_tok: 0.8925598396415517
test1_label=O_precision_sent: 0.39823008849557523
test1_label=O_recall_sent: 0.11568123393316196
test1_label=O_f-score_sent: 0.17928286852589642
test1_label=N_precision_sent: 0.6886543535620053
test1_label=N_recall_sent: 0.8585526315789473
test1_label=N_f-score_sent: 0.7642752562225475
test1_label=P_precision_sent: 0.7625
test1_label=P_recall_sent: 0.8052805280528053
test1_label=P_f-score_sent: 0.78330658105939
test1_precision_macro_sent: 0.6164614806858602
test1_recall_macro_sent: 0.5931714645216383
test1_f-score_macro_sent: 0.5756215686026113
test1_precision_micro_sent: 0.7058823529411765
test1_recall_micro_sent: 0.7058823529411765
test1_f-score_micro_sent: 0.7058823529411765
test1_label=O_precision_tok: 0.910666232959754
test1_label=O_recall_tok: 0.9624351521970124
test1_label=O_f-score_tok: 0.9358352959051889
test1_label=N_precision_tok: 0.7491679273827534
test1_label=N_recall_tok: 0.6585106382978724
test1_label=N_f-score_tok: 0.7009200283085634
test1_label=P_precision_tok: 0.866363808442173
test1_label=P_recall_tok: 0.6885813148788927
test1_label=P_f-score_tok: 0.767309304274937
test1_precision_macro_tok: 0.8420659895948934
test1_recall_macro_tok: 0.7698423684579258
test1_f-score_macro_tok: 0.8013548761628965
test1_precision_micro_tok: 0.8925598396415517
test1_recall_micro_tok: 0.8925598396415517
test1_f-score_micro_tok: 0.8925598396415517
test1_time: 28.951250314712524
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3982    0.1157    0.1793       389
           N     0.6887    0.8586    0.7643       912
           P     0.7625    0.8053    0.7833       909

   micro avg     0.7059    0.7059    0.7059      2210
   macro avg     0.6165    0.5932    0.5756      2210
weighted avg     0.6679    0.7059    0.6691      2210

F1-macro sent:  0.5756215686026113
F1-micro sent:  0.7058823529411765
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9107    0.9624    0.9358     31998
           N     0.7492    0.6585    0.7009      3760
           P     0.8664    0.6886    0.7673      6647

   micro avg     0.8926    0.8926    0.8926     42405
   macro avg     0.8421    0.7698    0.8014     42405
weighted avg     0.8894    0.8926    0.8886     42405

F1-macro tok:  0.8013548761628965
F1-micro tok:  0.8925598396415517
**************************************************
