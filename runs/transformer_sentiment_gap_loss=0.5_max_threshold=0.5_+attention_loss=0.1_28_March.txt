to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.5_+attention_loss=0.1_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.5
sentence_composition: attention
random_seed: 100
{'O': 0, 'N': 1, 'P': 2}
{'O': 0, 'N': 1, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 23:17:51.441763: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 23:17:51.544251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 7.72GiB
2019-03-28 23:17:51.544433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 23:17:52.184550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 23:17:52.184601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 23:17:52.184616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 23:17:52.184829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428352.01599121094
train_cost_avg: 50.13483333230465
train_count_sent: 8544.0
train_total_correct_sent: 4309.0
train_accuracy_sent: 0.5043305243445693
train_count_tok: 163566.0
train_total_correct_tok: 126009.0
train_accuracy_tok: 0.7703862660944206
train_label=O_precision_sent: 0.26851851851851855
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.08932238193018481
train_label=N_precision_sent: 0.486848635235732
train_label=N_recall_sent: 0.592749244712991
train_label=N_f-score_sent: 0.5346049046321526
train_label=P_precision_sent: 0.5393794749403341
train_label=P_recall_sent: 0.6260387811634349
train_label=P_f-score_sent: 0.5794871794871794
train_precision_macro_sent: 0.4315822095648616
train_recall_macro_sent: 0.42411981814928484
train_f-score_macro_sent: 0.40113815534983893
train_precision_micro_sent: 0.5043305243445693
train_recall_micro_sent: 0.5043305243445693
train_f-score_micro_sent: 0.5043305243445693
train_label=O_precision_tok: 0.7950424634854243
train_label=O_recall_tok: 0.9538629802086098
train_label=O_f-score_tok: 0.8672413667039564
train_label=N_precision_tok: 0.5106003919472653
train_label=N_recall_tok: 0.20180256301929306
train_label=N_f-score_tok: 0.2892758011607368
train_label=P_precision_tok: 0.5171115674195756
train_label=P_recall_tok: 0.18119678618539392
train_label=P_f-score_tok: 0.268359825947962
train_precision_macro_tok: 0.6075848076174217
train_recall_macro_tok: 0.4456207764710989
train_f-score_macro_tok: 0.47495899793755175
train_precision_micro_tok: 0.7703862660944206
train_recall_micro_tok: 0.7703862660944206
train_f-score_micro_tok: 0.7703862660944206
train_time: 247.21940636634827
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2685    0.0536    0.0893      1624
           N     0.4868    0.5927    0.5346      3310
           P     0.5394    0.6260    0.5795      3610

   micro avg     0.5043    0.5043    0.5043      8544
   macro avg     0.4316    0.4241    0.4011      8544
weighted avg     0.4675    0.5043    0.4689      8544

F1-macro sent:  0.40113815534983893
F1-micro sent:  0.5043305243445693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7950    0.9539    0.8672    124347
           N     0.5106    0.2018    0.2893     14202
           P     0.5171    0.1812    0.2684     25017

   micro avg     0.7704    0.7704    0.7704    163566
   macro avg     0.6076    0.4456    0.4750    163566
weighted avg     0.7278    0.7704    0.7255    163566

F1-macro tok:  0.47495899793755175
F1-micro tok:  0.7703862660944206
**************************************************
dev_cost_sum: 50902.921142578125
dev_cost_avg: 46.23335253640157
dev_count_sent: 1101.0
dev_total_correct_sent: 654.0
dev_accuracy_sent: 0.5940054495912807
dev_count_tok: 21274.0
dev_total_correct_tok: 17499.0
dev_accuracy_tok: 0.8225533515088841
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5263870094722598
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.6666666666666667
dev_label=P_precision_sent: 0.7320441988950276
dev_label=P_recall_sent: 0.5968468468468469
dev_label=P_f-score_sent: 0.6575682382133996
dev_precision_macro_sent: 0.4194770694557624
dev_recall_macro_sent: 0.5019084505065813
dev_f-score_macro_sent: 0.4414116349600221
dev_precision_micro_sent: 0.5940054495912807
dev_recall_micro_sent: 0.5940054495912807
dev_f-score_micro_sent: 0.5940054495912807
dev_label=O_precision_tok: 0.8402321922638746
dev_label=O_recall_tok: 0.9557543967911138
dev_label=O_f-score_tok: 0.8942779606212831
dev_label=N_precision_tok: 0.6674641148325359
dev_label=N_recall_tok: 0.4507269789983845
dev_label=N_f-score_tok: 0.5380906460945034
dev_label=P_precision_tok: 0.739760554505356
dev_label=P_recall_tok: 0.3655043586550436
dev_label=P_f-score_tok: 0.4892685976245051
dev_precision_macro_tok: 0.7491522872005888
dev_recall_macro_tok: 0.590661911481514
dev_f-score_macro_tok: 0.6405457347800971
dev_precision_micro_tok: 0.8225533515088841
dev_recall_micro_tok: 0.8225533515088841
dev_f-score_micro_tok: 0.8225533515088841
dev_time: 17.988017797470093
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5264    0.9089    0.6667       428
           P     0.7320    0.5968    0.6576       444

   micro avg     0.5940    0.5940    0.5940      1101
   macro avg     0.4195    0.5019    0.4414      1101
weighted avg     0.4998    0.5940    0.5243      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.4414116349600221
F1-micro sent:  0.5940054495912807
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8402    0.9558    0.8943     16205
           N     0.6675    0.4507    0.5381      1857
           P     0.7398    0.3655    0.4893      3212

   micro avg     0.8226    0.8226    0.8226     21274
   macro avg     0.7492    0.5907    0.6405     21274
weighted avg     0.8100    0.8226    0.8020     21274

F1-macro tok:  0.6405457347800971
F1-micro tok:  0.8225533515088841
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378811.6776123047
train_cost_avg: 44.33657275424915
train_count_sent: 8544.0
train_total_correct_sent: 4874.0
train_accuracy_sent: 0.5704588014981273
train_count_tok: 163566.0
train_total_correct_tok: 132367.0
train_accuracy_tok: 0.8092574251372535
train_label=O_precision_sent: 0.3103448275862069
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.01088929219600726
train_label=N_precision_sent: 0.5358698143479257
train_label=N_recall_sent: 0.706344410876133
train_label=N_f-score_sent: 0.6094096181415352
train_label=P_precision_sent: 0.6086223506743738
train_label=P_recall_sent: 0.7
train_label=P_f-score_sent: 0.6511208451430044
train_precision_macro_sent: 0.4849456642028354
train_recall_macro_sent: 0.47062876093243844
train_f-score_macro_sent: 0.42380658516018227
train_precision_micro_sent: 0.5704588014981273
train_recall_micro_sent: 0.5704588014981273
train_f-score_micro_sent: 0.5704588014981273
train_label=O_precision_tok: 0.8295788237268227
train_label=O_recall_tok: 0.9542087867017298
train_label=O_f-score_tok: 0.8875399719495091
train_label=N_precision_tok: 0.6499508357915438
train_label=N_recall_tok: 0.3723419236727222
train_label=N_f-score_tok: 0.47345330826394494
train_label=P_precision_tok: 0.6794065473310756
train_label=P_recall_tok: 0.33681096854139186
train_label=P_f-score_tok: 0.4503594430636842
train_precision_macro_tok: 0.7196454022831474
train_recall_macro_tok: 0.5544538929719479
train_f-score_macro_tok: 0.6037842410923794
train_precision_micro_tok: 0.8092574251372535
train_recall_micro_tok: 0.8092574251372535
train_f-score_micro_tok: 0.8092574251372535
train_time: 303.7037880420685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3103    0.0055    0.0109      1624
           N     0.5359    0.7063    0.6094      3310
           P     0.6086    0.7000    0.6511      3610

   micro avg     0.5705    0.5705    0.5705      8544
   macro avg     0.4849    0.4706    0.4238      8544
weighted avg     0.5237    0.5705    0.5133      8544

F1-macro sent:  0.42380658516018227
F1-micro sent:  0.5704588014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8296    0.9542    0.8875    124347
           N     0.6500    0.3723    0.4735     14202
           P     0.6794    0.3368    0.4504     25017

   micro avg     0.8093    0.8093    0.8093    163566
   macro avg     0.7196    0.5545    0.6038    163566
weighted avg     0.7910    0.8093    0.7847    163566

F1-macro tok:  0.6037842410923794
F1-micro tok:  0.8092574251372535
**************************************************
dev_cost_sum: 49232.04504394531
dev_cost_avg: 44.71575390004116
dev_count_sent: 1101.0
dev_total_correct_sent: 601.0
dev_accuracy_sent: 0.5458673932788374
dev_count_tok: 21274.0
dev_total_correct_tok: 17731.0
dev_accuracy_tok: 0.833458681959199
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4663726571113561
dev_label=N_recall_sent: 0.9883177570093458
dev_label=N_f-score_sent: 0.6337078651685393
dev_label=P_precision_sent: 0.9175257731958762
dev_label=P_recall_sent: 0.4009009009009009
dev_label=P_f-score_sent: 0.5579937304075234
dev_precision_macro_sent: 0.46129947676907745
dev_recall_macro_sent: 0.4630728859700823
dev_f-score_macro_sent: 0.3972338651920209
dev_precision_micro_sent: 0.5458673932788374
dev_recall_micro_sent: 0.5458673932788374
dev_f-score_micro_sent: 0.5458673932788374
dev_label=O_precision_tok: 0.8412230909285637
dev_label=O_recall_tok: 0.9693921629126813
dev_label=O_f-score_tok: 0.9007712377075031
dev_label=N_precision_tok: 0.7051282051282052
dev_label=N_recall_tok: 0.47388260635433493
dev_label=N_f-score_tok: 0.5668276972624798
dev_label=P_precision_tok: 0.8446745562130178
dev_label=P_recall_tok: 0.35554171855541716
dev_label=P_f-score_tok: 0.5004382120946539
dev_precision_macro_tok: 0.7970086174232622
dev_recall_macro_tok: 0.5996054959408111
dev_f-score_macro_tok: 0.6560123823548789
dev_precision_micro_tok: 0.833458681959199
dev_recall_micro_tok: 0.833458681959199
dev_f-score_micro_tok: 0.8334586819591991
dev_time: 16.99175477027893
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4664    0.9883    0.6337       428
           P     0.9175    0.4009    0.5580       444

   micro avg     0.5459    0.5459    0.5459      1101
   macro avg     0.4613    0.4631    0.3972      1101
weighted avg     0.5513    0.5459    0.4714      1101

F1-macro sent:  0.3972338651920209
F1-micro sent:  0.5458673932788374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8412    0.9694    0.9008     16205
           N     0.7051    0.4739    0.5668      1857
           P     0.8447    0.3555    0.5004      3212

   micro avg     0.8335    0.8335    0.8335     21274
   macro avg     0.7970    0.5996    0.6560     21274
weighted avg     0.8299    0.8335    0.8112     21274

F1-macro tok:  0.6560123823548789
F1-micro tok:  0.8334586819591991
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369373.9571533203
train_cost_avg: 43.23197064060397
train_count_sent: 8544.0
train_total_correct_sent: 5025.0
train_accuracy_sent: 0.5881320224719101
train_count_tok: 163566.0
train_total_correct_tok: 135500.0
train_accuracy_tok: 0.8284117726177812
train_label=O_precision_sent: 0.3448275862068966
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012099213551119177
train_label=N_precision_sent: 0.5512908384738405
train_label=N_recall_sent: 0.7290030211480363
train_label=N_f-score_sent: 0.6278131911018603
train_label=P_precision_sent: 0.6288061865635572
train_label=P_recall_sent: 0.720775623268698
train_label=P_f-score_sent: 0.6716572018585442
train_precision_macro_sent: 0.508308203748098
train_recall_macro_sent: 0.4853120932949049
train_f-score_macro_sent: 0.43718986883717453
train_precision_micro_sent: 0.5881320224719101
train_recall_micro_sent: 0.5881320224719101
train_f-score_micro_sent: 0.5881320224719101
train_label=O_precision_tok: 0.8469143540942504
train_label=O_recall_tok: 0.9561951635343032
train_label=O_f-score_tok: 0.8982431753538391
train_label=N_precision_tok: 0.6836202990484821
train_label=N_recall_tok: 0.42494014927475005
train_label=N_f-score_tok: 0.5240990013026487
train_label=P_precision_tok: 0.7364422138575213
train_label=P_recall_tok: 0.42231282727745134
train_label=P_f-score_tok: 0.5367985163732439
train_precision_macro_tok: 0.7556589556667513
train_recall_macro_tok: 0.6011493800288349
train_f-score_macro_tok: 0.6530468976765773
train_precision_micro_tok: 0.8284117726177812
train_recall_micro_tok: 0.8284117726177812
train_f-score_micro_tok: 0.8284117726177813
train_time: 297.3514201641083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3448    0.0062    0.0121      1624
           N     0.5513    0.7290    0.6278      3310
           P     0.6288    0.7208    0.6717      3610

   micro avg     0.5881    0.5881    0.5881      8544
   macro avg     0.5083    0.4853    0.4372      8544
weighted avg     0.5448    0.5881    0.5293      8544

F1-macro sent:  0.43718986883717453
F1-micro sent:  0.5881320224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8469    0.9562    0.8982    124347
           N     0.6836    0.4249    0.5241     14202
           P     0.7364    0.4223    0.5368     25017

   micro avg     0.8284    0.8284    0.8284    163566
   macro avg     0.7557    0.6011    0.6530    163566
weighted avg     0.8158    0.8284    0.8105    163566

F1-macro tok:  0.6530468976765773
F1-micro tok:  0.8284117726177813
**************************************************
dev_cost_sum: 48363.10559082031
dev_cost_avg: 43.92652642218012
dev_count_sent: 1101.0
dev_total_correct_sent: 675.0
dev_accuracy_sent: 0.6130790190735694
dev_count_tok: 21274.0
dev_total_correct_tok: 18181.0
dev_accuracy_tok: 0.8546112625740341
dev_label=O_precision_sent: 0.45454545454545453
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.041666666666666664
dev_label=N_precision_sent: 0.5454545454545454
dev_label=N_recall_sent: 0.9252336448598131
dev_label=N_f-score_sent: 0.6863084922010398
dev_label=P_precision_sent: 0.7527472527472527
dev_label=P_recall_sent: 0.6171171171171171
dev_label=P_f-score_sent: 0.6782178217821782
dev_precision_macro_sent: 0.5842490842490843
dev_recall_macro_sent: 0.5213949410374338
dev_f-score_macro_sent: 0.46873099354996156
dev_precision_micro_sent: 0.6130790190735694
dev_recall_micro_sent: 0.6130790190735694
dev_f-score_micro_sent: 0.6130790190735694
dev_label=O_precision_tok: 0.8650591748700365
dev_label=O_recall_tok: 0.9652576365319346
dev_label=O_f-score_tok: 0.9124157844080847
dev_label=N_precision_tok: 0.7437092264678472
dev_label=N_recall_tok: 0.4297253634894992
dev_label=N_f-score_tok: 0.5447098976109215
dev_label=P_precision_tok: 0.8216139688532327
dev_label=P_recall_tok: 0.5420298879202988
dev_label=P_f-score_tok: 0.6531607578315513
dev_precision_macro_tok: 0.8101274567303722
dev_recall_macro_tok: 0.6456709626472442
dev_f-score_macro_tok: 0.703428813283519
dev_precision_micro_tok: 0.8546112625740341
dev_recall_micro_tok: 0.8546112625740341
dev_f-score_micro_tok: 0.8546112625740341
dev_time: 19.21865224838257
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.0218    0.0417       229
           N     0.5455    0.9252    0.6863       428
           P     0.7527    0.6171    0.6782       444

   micro avg     0.6131    0.6131    0.6131      1101
   macro avg     0.5842    0.5214    0.4687      1101
weighted avg     0.6101    0.6131    0.5490      1101

F1-macro sent:  0.46873099354996156
F1-micro sent:  0.6130790190735694
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8651    0.9653    0.9124     16205
           N     0.7437    0.4297    0.5447      1857
           P     0.8216    0.5420    0.6532      3212

   micro avg     0.8546    0.8546    0.8546     21274
   macro avg     0.8101    0.6457    0.7034     21274
weighted avg     0.8479    0.8546    0.8412     21274

F1-macro tok:  0.703428813283519
F1-micro tok:  0.8546112625740341
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362389.92041015625
train_cost_avg: 42.41455060980293
train_count_sent: 8544.0
train_total_correct_sent: 5121.0
train_accuracy_sent: 0.5993679775280899
train_count_tok: 163566.0
train_total_correct_tok: 137778.0
train_accuracy_tok: 0.8423388723817908
train_label=O_precision_sent: 0.16666666666666666
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004854368932038835
train_label=N_precision_sent: 0.5641668566218373
train_label=N_recall_sent: 0.7477341389728097
train_label=N_f-score_sent: 0.6431077043003768
train_label=P_precision_sent: 0.6392451004113235
train_label=P_recall_sent: 0.7318559556786703
train_label=P_f-score_sent: 0.6824228335270567
train_precision_macro_sent: 0.4566928745666092
train_recall_macro_sent: 0.4940177162795574
train_f-score_macro_sent: 0.4434616355864908
train_precision_micro_sent: 0.5993679775280899
train_recall_micro_sent: 0.5993679775280899
train_f-score_micro_sent: 0.5993679775280899
train_label=O_precision_tok: 0.8594150106394489
train_label=O_recall_tok: 0.9581654563439408
train_label=O_f-score_tok: 0.9061076423481454
train_label=N_precision_tok: 0.6986241537453592
train_label=N_recall_tok: 0.45049992958738205
train_label=N_f-score_tok: 0.5477739726027399
train_label=P_precision_tok: 0.7756926393203576
train_label=P_recall_tok: 0.48906743414478154
train_label=P_f-score_tok: 0.5999019367492032
train_precision_macro_tok: 0.7779106012350553
train_recall_macro_tok: 0.6325776066920349
train_f-score_macro_tok: 0.6845945172333628
train_precision_micro_tok: 0.8423388723817908
train_recall_micro_tok: 0.8423388723817908
train_f-score_micro_tok: 0.8423388723817908
train_time: 302.50063920021057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1667    0.0025    0.0049      1624
           N     0.5642    0.7477    0.6431      3310
           P     0.6392    0.7319    0.6824      3610

   micro avg     0.5994    0.5994    0.5994      8544
   macro avg     0.4567    0.4940    0.4435      8544
weighted avg     0.5203    0.5994    0.5384      8544

F1-macro sent:  0.4434616355864908
F1-micro sent:  0.5993679775280899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8594    0.9582    0.9061    124347
           N     0.6986    0.4505    0.5478     14202
           P     0.7757    0.4891    0.5999     25017

   micro avg     0.8423    0.8423    0.8423    163566
   macro avg     0.7779    0.6326    0.6846    163566
weighted avg     0.8326    0.8423    0.8282    163566

F1-macro tok:  0.6845945172333628
F1-micro tok:  0.8423388723817908
**************************************************
dev_cost_sum: 47603.83972167969
dev_cost_avg: 43.23691164548564
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18373.0
dev_accuracy_tok: 0.8636363636363636
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6006944444444444
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.6892430278884463
dev_label=P_precision_sent: 0.6571428571428571
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7120743034055727
dev_precision_macro_sent: 0.41927910052910056
dev_recall_macro_sent: 0.5284794139934327
dev_f-score_macro_sent: 0.4671057770980063
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.867090689768615
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9182707661934211
dev_label=N_precision_tok: 0.7876712328767124
dev_label=N_recall_tok: 0.4334948842218632
dev_label=N_f-score_tok: 0.5592219520666899
dev_label=P_precision_tok: 0.8709036742800397
dev_label=P_recall_tok: 0.5460772104607721
dev_label=P_f-score_tok: 0.6712590891695369
dev_precision_macro_tok: 0.8418885323084556
dev_recall_macro_tok: 0.6518145797455951
dev_f-score_macro_tok: 0.7162506024765493
dev_precision_micro_tok: 0.8636363636363636
dev_recall_micro_tok: 0.8636363636363636
dev_f-score_micro_tok: 0.8636363636363636
dev_time: 19.02127242088318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6007    0.8084    0.6892       428
           P     0.6571    0.7770    0.7121       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.4193    0.5285    0.4671      1101
weighted avg     0.4985    0.6276    0.5551      1101

F1-macro sent:  0.4671057770980063
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8671    0.9759    0.9183     16205
           N     0.7877    0.4335    0.5592      1857
           P     0.8709    0.5461    0.6713      3212

   micro avg     0.8636    0.8636    0.8636     21274
   macro avg     0.8419    0.6518    0.7163     21274
weighted avg     0.8607    0.8636    0.8496     21274

F1-macro tok:  0.7162506024765493
F1-micro tok:  0.8636363636363636
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 356868.53967285156
train_cost_avg: 41.76832159092364
train_count_sent: 8544.0
train_total_correct_sent: 5230.0
train_accuracy_sent: 0.612125468164794
train_count_tok: 163566.0
train_total_correct_tok: 139015.0
train_accuracy_tok: 0.849901568785689
train_label=O_precision_sent: 0.4444444444444444
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.0145366444579043
train_label=N_precision_sent: 0.575523202911738
train_label=N_recall_sent: 0.7643504531722054
train_label=N_f-score_sent: 0.6566311964702828
train_label=P_precision_sent: 0.6522688667799078
train_label=P_recall_sent: 0.7445983379501385
train_label=P_f-score_sent: 0.6953822273961972
train_precision_macro_sent: 0.5574121713786967
train_recall_macro_sent: 0.5054459845613067
train_f-score_macro_sent: 0.45551668944146134
train_precision_micro_sent: 0.612125468164794
train_recall_micro_sent: 0.612125468164794
train_f-score_micro_sent: 0.612125468164794
train_label=O_precision_tok: 0.864928978505511
train_label=O_recall_tok: 0.9617602354700958
train_label=O_f-score_tok: 0.9107781352931097
train_label=N_precision_tok: 0.7094376212023271
train_label=N_recall_tok: 0.4636670891423743
train_label=N_f-score_tok: 0.5608073582013285
train_label=P_precision_tok: 0.8015734265734266
train_label=P_recall_tok: 0.5131710436902907
train_label=P_f-score_tok: 0.6257402578412498
train_precision_macro_tok: 0.7919800087604215
train_recall_macro_tok: 0.6461994561009203
train_f-score_macro_tok: 0.6991085837785627
train_precision_micro_tok: 0.849901568785689
train_recall_micro_tok: 0.849901568785689
train_f-score_micro_tok: 0.849901568785689
train_time: 300.46487164497375
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.0074    0.0145      1624
           N     0.5755    0.7644    0.6566      3310
           P     0.6523    0.7446    0.6954      3610

   micro avg     0.6121    0.6121    0.6121      8544
   macro avg     0.5574    0.5054    0.4555      8544
weighted avg     0.5830    0.6121    0.5510      8544

F1-macro sent:  0.45551668944146134
F1-micro sent:  0.612125468164794
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8649    0.9618    0.9108    124347
           N     0.7094    0.4637    0.5608     14202
           P     0.8016    0.5132    0.6257     25017

   micro avg     0.8499    0.8499    0.8499    163566
   macro avg     0.7920    0.6462    0.6991    163566
weighted avg     0.8417    0.8499    0.8368    163566

F1-macro tok:  0.6991085837785627
F1-micro tok:  0.849901568785689
**************************************************
dev_cost_sum: 46947.579162597656
dev_cost_avg: 42.640853008717215
dev_count_sent: 1101.0
dev_total_correct_sent: 684.0
dev_accuracy_sent: 0.6212534059945504
dev_count_tok: 21274.0
dev_total_correct_tok: 18488.0
dev_accuracy_tok: 0.8690420231268214
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.609981515711645
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.6811145510835913
dev_label=P_precision_sent: 0.6321428571428571
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.7051792828685258
dev_precision_macro_sent: 0.4140414576181674
dev_recall_macro_sent: 0.5227751115601583
dev_f-score_macro_sent: 0.4620979446507057
dev_precision_micro_sent: 0.6212534059945504
dev_recall_micro_sent: 0.6212534059945504
dev_f-score_micro_sent: 0.6212534059945504
dev_label=O_precision_tok: 0.8786182184648116
dev_label=O_recall_tok: 0.9684048133292193
dev_label=O_f-score_tok: 0.9213291845241589
dev_label=N_precision_tok: 0.7349121466768526
dev_label=N_recall_tok: 0.5180398492191707
dev_label=N_f-score_tok: 0.607706885660139
dev_label=P_precision_tok: 0.8711977186311787
dev_label=P_recall_tok: 0.5706724782067247
dev_label=P_f-score_tok: 0.6896162528216704
dev_precision_macro_tok: 0.8282426945909477
dev_recall_macro_tok: 0.6857057135850383
dev_f-score_macro_tok: 0.7395507743353228
dev_precision_micro_tok: 0.8690420231268214
dev_recall_micro_tok: 0.8690420231268214
dev_f-score_micro_tok: 0.8690420231268214
dev_time: 18.916754484176636
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6100    0.7710    0.6811       428
           P     0.6321    0.7973    0.7052       444

   micro avg     0.6213    0.6213    0.6213      1101
   macro avg     0.4140    0.5228    0.4621      1101
weighted avg     0.4920    0.6213    0.5492      1101

F1-macro sent:  0.4620979446507057
F1-micro sent:  0.6212534059945504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8786    0.9684    0.9213     16205
           N     0.7349    0.5180    0.6077      1857
           P     0.8712    0.5707    0.6896      3212

   micro avg     0.8690    0.8690    0.8690     21274
   macro avg     0.8282    0.6857    0.7396     21274
weighted avg     0.8650    0.8690    0.8590     21274

F1-macro tok:  0.7395507743353228
F1-micro tok:  0.8690420231268214
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 352051.0880126953
train_cost_avg: 41.204481274894114
train_count_sent: 8544.0
train_total_correct_sent: 5302.0
train_accuracy_sent: 0.6205524344569289
train_count_tok: 163566.0
train_total_correct_tok: 140222.0
train_accuracy_tok: 0.8572808529890075
train_label=O_precision_sent: 0.4444444444444444
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.023966446974236073
train_label=N_precision_sent: 0.5783240223463687
train_label=N_recall_sent: 0.7818731117824773
train_label=N_f-score_sent: 0.6648683365446371
train_label=P_precision_sent: 0.6694831013916501
train_label=P_recall_sent: 0.7462603878116344
train_label=P_f-score_sent: 0.7057898873460833
train_precision_macro_sent: 0.5640838560608211
train_recall_macro_sent: 0.5134829235100241
train_f-score_macro_sent: 0.4648748902883188
train_precision_micro_sent: 0.6205524344569289
train_recall_micro_sent: 0.6205524344569289
train_f-score_micro_sent: 0.6205524344569289
train_label=O_precision_tok: 0.8709726653632869
train_label=O_recall_tok: 0.9637385702912012
train_label=O_f-score_tok: 0.9150104223136774
train_label=N_precision_tok: 0.7201283909712156
train_label=N_recall_tok: 0.4897197577805943
train_label=N_f-score_tok: 0.5829840737636212
train_label=P_precision_tok: 0.8230066801495373
train_label=P_recall_tok: 0.5367949794139985
train_label=P_f-score_tok: 0.6497798422606086
train_precision_macro_tok: 0.8047025788280132
train_recall_macro_tok: 0.6634177691619313
train_f-score_macro_tok: 0.715924779445969
train_precision_micro_tok: 0.8572808529890075
train_recall_micro_tok: 0.8572808529890075
train_f-score_micro_tok: 0.8572808529890075
train_time: 296.92907071113586
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.0123    0.0240      1624
           N     0.5783    0.7819    0.6649      3310
           P     0.6695    0.7463    0.7058      3610

   micro avg     0.6206    0.6206    0.6206      8544
   macro avg     0.5641    0.5135    0.4649      8544
weighted avg     0.5914    0.6206    0.5603      8544

F1-macro sent:  0.4648748902883188
F1-micro sent:  0.6205524344569289
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8710    0.9637    0.9150    124347
           N     0.7201    0.4897    0.5830     14202
           P     0.8230    0.5368    0.6498     25017

   micro avg     0.8573    0.8573    0.8573    163566
   macro avg     0.8047    0.6634    0.7159    163566
weighted avg     0.8505    0.8573    0.8456    163566

F1-macro tok:  0.715924779445969
F1-micro tok:  0.8572808529890075
**************************************************
dev_cost_sum: 46415.99621582031
dev_cost_avg: 42.158034710100196
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 18584.0
dev_accuracy_tok: 0.8735545736579863
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6105263157894737
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.6973947895791582
dev_label=P_precision_sent: 0.6572504708097928
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7158974358974357
dev_precision_macro_sent: 0.42259226219975554
dev_recall_macro_sent: 0.5330400493951896
dev_f-score_macro_sent: 0.471097408492198
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8795516645290805
dev_label=O_recall_tok: 0.9733415612465288
dev_label=O_f-score_tok: 0.9240728806608473
dev_label=N_precision_tok: 0.7702702702702703
dev_label=N_recall_tok: 0.5218093699515347
dev_label=N_f-score_tok: 0.62215088282504
dev_label=P_precision_tok: 0.884301488238118
dev_label=P_recall_tok: 0.5734744707347447
dev_label=P_f-score_tok: 0.6957507082152974
dev_precision_macro_tok: 0.8447078076791562
dev_recall_macro_tok: 0.6895418006442694
dev_f-score_macro_tok: 0.7473248239003949
dev_precision_micro_tok: 0.8735545736579863
dev_recall_micro_tok: 0.8735545736579863
dev_f-score_micro_tok: 0.8735545736579864
dev_time: 17.599642038345337
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6105    0.8131    0.6974       428
           P     0.6573    0.7860    0.7159       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.4226    0.5330    0.4711      1101
weighted avg     0.5024    0.6331    0.5598      1101

F1-macro sent:  0.471097408492198
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8796    0.9733    0.9241     16205
           N     0.7703    0.5218    0.6222      1857
           P     0.8843    0.5735    0.6958      3212

   micro avg     0.8736    0.8736    0.8736     21274
   macro avg     0.8447    0.6895    0.7473     21274
weighted avg     0.8707    0.8736    0.8632     21274

F1-macro tok:  0.7473248239003949
F1-micro tok:  0.8735545736579864
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347731.7289428711
train_cost_avg: 40.69893831260195
train_count_sent: 8544.0
train_total_correct_sent: 5365.0
train_accuracy_sent: 0.6279260299625468
train_count_tok: 163566.0
train_total_correct_tok: 141156.0
train_accuracy_tok: 0.8629910861670518
train_label=O_precision_sent: 0.4117647058823529
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.04866743916570104
train_label=N_precision_sent: 0.5938582313553452
train_label=N_recall_sent: 0.7770392749244713
train_label=N_f-score_sent: 0.6732103127862846
train_label=P_precision_sent: 0.6691802481148139
train_label=P_recall_sent: 0.7620498614958449
train_label=P_f-score_sent: 0.71260199456029
train_precision_macro_sent: 0.5582677284508374
train_recall_macro_sent: 0.5216504017952778
train_f-score_macro_sent: 0.47815991550409187
train_precision_micro_sent: 0.6279260299625468
train_recall_micro_sent: 0.6279260299625468
train_f-score_micro_sent: 0.6279260299625468
train_label=O_precision_tok: 0.8751138474989981
train_label=O_recall_tok: 0.9658857873531328
train_label=O_f-score_tok: 0.9182620263616624
train_label=N_precision_tok: 0.7374859822611887
train_label=N_recall_tok: 0.5093648781861709
train_label=N_f-score_tok: 0.6025571613010703
train_label=P_precision_tok: 0.8367853682170543
train_label=P_recall_tok: 0.5523044329855699
train_label=P_f-score_tok: 0.6654145296058177
train_precision_macro_tok: 0.8164617326590804
train_recall_macro_tok: 0.6758516995082912
train_f-score_macro_tok: 0.7287445724228502
train_precision_micro_tok: 0.8629910861670518
train_recall_micro_tok: 0.8629910861670518
train_f-score_micro_tok: 0.8629910861670518
train_time: 304.38726115226746
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4118    0.0259    0.0487      1624
           N     0.5939    0.7770    0.6732      3310
           P     0.6692    0.7620    0.7126      3610

   micro avg     0.6279    0.6279    0.6279      8544
   macro avg     0.5583    0.5217    0.4782      8544
weighted avg     0.5911    0.6279    0.5711      8544

F1-macro sent:  0.47815991550409187
F1-micro sent:  0.6279260299625468
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8751    0.9659    0.9183    124347
           N     0.7375    0.5094    0.6026     14202
           P     0.8368    0.5523    0.6654     25017

   micro avg     0.8630    0.8630    0.8630    163566
   macro avg     0.8165    0.6759    0.7287    163566
weighted avg     0.8573    0.8630    0.8522    163566

F1-macro tok:  0.7287445724228502
F1-micro tok:  0.8629910861670518
**************************************************
dev_cost_sum: 46065.40686035156
dev_cost_avg: 41.83960659432476
dev_count_sent: 1101.0
dev_total_correct_sent: 671.0
dev_accuracy_sent: 0.6094459582198002
dev_count_tok: 21274.0
dev_total_correct_tok: 18705.0
dev_accuracy_tok: 0.8792422675566419
dev_label=O_precision_sent: 0.42857142857142855
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02542372881355932
dev_label=N_precision_sent: 0.6923076923076923
dev_label=N_recall_sent: 0.6098130841121495
dev_label=N_f-score_sent: 0.6484472049689441
dev_label=P_precision_sent: 0.5676429567642957
dev_label=P_recall_sent: 0.9166666666666666
dev_label=P_f-score_sent: 0.7011197243755383
dev_precision_macro_sent: 0.5628406925478054
dev_recall_macro_sent: 0.513193395820013
dev_f-score_macro_sent: 0.4583302193860139
dev_precision_micro_sent: 0.6094459582198002
dev_recall_micro_sent: 0.6094459582198002
dev_f-score_micro_sent: 0.6094459582198002
dev_label=O_precision_tok: 0.8827497769848349
dev_label=O_recall_tok: 0.977044122184511
dev_label=O_f-score_tok: 0.9275065170908877
dev_label=N_precision_tok: 0.8262867647058824
dev_label=N_recall_tok: 0.4841141626278945
dev_label=N_f-score_tok: 0.6105263157894737
dev_label=P_precision_tok: 0.8768888888888889
dev_label=P_recall_tok: 0.6142590286425903
dev_label=P_f-score_tok: 0.7224459904796777
dev_precision_macro_tok: 0.8619751435265354
dev_recall_macro_tok: 0.6918057711516652
dev_f-score_macro_tok: 0.7534929411200131
dev_precision_micro_tok: 0.8792422675566419
dev_recall_micro_tok: 0.8792422675566419
dev_f-score_micro_tok: 0.8792422675566419
dev_time: 19.023272275924683
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0131    0.0254       229
           N     0.6923    0.6098    0.6484       428
           P     0.5676    0.9167    0.7011       444

   micro avg     0.6094    0.6094    0.6094      1101
   macro avg     0.5628    0.5132    0.4583      1101
weighted avg     0.5872    0.6094    0.5401      1101

F1-macro sent:  0.4583302193860139
F1-micro sent:  0.6094459582198002
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8827    0.9770    0.9275     16205
           N     0.8263    0.4841    0.6105      1857
           P     0.8769    0.6143    0.7224      3212

   micro avg     0.8792    0.8792    0.8792     21274
   macro avg     0.8620    0.6918    0.7535     21274
weighted avg     0.8769    0.8792    0.8689     21274

F1-macro tok:  0.7534929411200131
F1-micro tok:  0.8792422675566419
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 344216.6533203125
train_cost_avg: 40.28752964891298
train_count_sent: 8544.0
train_total_correct_sent: 5406.0
train_accuracy_sent: 0.6327247191011236
train_count_tok: 163566.0
train_total_correct_tok: 141612.0
train_accuracy_tok: 0.8657789516158615
train_label=O_precision_sent: 0.4444444444444444
train_label=O_recall_sent: 0.022167487684729065
train_label=O_f-score_sent: 0.04222873900293255
train_label=N_precision_sent: 0.603584729981378
train_label=N_recall_sent: 0.7833836858006042
train_label=N_f-score_sent: 0.6818301341046543
train_label=P_precision_sent: 0.6664266858651308
train_label=P_recall_sent: 0.7692520775623268
train_label=P_f-score_sent: 0.7141571299987143
train_precision_macro_sent: 0.5714852867636511
train_recall_macro_sent: 0.5249344170158867
train_f-score_macro_sent: 0.47940533436876703
train_precision_micro_sent: 0.6327247191011236
train_recall_micro_sent: 0.6327247191011236
train_f-score_micro_sent: 0.6327247191011236
train_label=O_precision_tok: 0.8786021473918258
train_label=O_recall_tok: 0.9660546695939588
train_label=O_f-score_tok: 0.9202554094480045
train_label=N_precision_tok: 0.7341570346751694
train_label=N_recall_tok: 0.518800168990283
train_label=N_f-score_tok: 0.6079709546992326
train_label=P_precision_tok: 0.8400571224562656
train_label=P_recall_tok: 0.5643362513490826
train_label=P_f-score_tok: 0.6751309088300695
train_precision_macro_tok: 0.817605434841087
train_recall_macro_tok: 0.6830636966444414
train_f-score_macro_tok: 0.7344524243257688
train_precision_micro_tok: 0.8657789516158615
train_recall_micro_tok: 0.8657789516158615
train_f-score_micro_tok: 0.8657789516158614
train_time: 295.39944767951965
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.0222    0.0422      1624
           N     0.6036    0.7834    0.6818      3310
           P     0.6664    0.7693    0.7142      3610

   micro avg     0.6327    0.6327    0.6327      8544
   macro avg     0.5715    0.5249    0.4794      8544
weighted avg     0.5999    0.6327    0.5739      8544

F1-macro sent:  0.47940533436876703
F1-micro sent:  0.6327247191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8786    0.9661    0.9203    124347
           N     0.7342    0.5188    0.6080     14202
           P     0.8401    0.5643    0.6751     25017

   micro avg     0.8658    0.8658    0.8658    163566
   macro avg     0.8176    0.6831    0.7345    163566
weighted avg     0.8602    0.8658    0.8556    163566

F1-macro tok:  0.7344524243257688
F1-micro tok:  0.8657789516158614
**************************************************
dev_cost_sum: 45565.602294921875
dev_cost_avg: 41.38565149402532
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18755.0
dev_accuracy_tok: 0.8815925542916235
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.5720653789004457
dev_label=N_recall_sent: 0.8995327102803738
dev_label=N_f-score_sent: 0.6993642143505903
dev_label=P_precision_sent: 0.7363420427553444
dev_label=P_recall_sent: 0.6981981981981982
dev_label=P_f-score_sent: 0.7167630057803469
dev_precision_macro_sent: 0.6742310453138348
dev_recall_macro_sent: 0.5398549898713144
dev_f-score_macro_sent: 0.48616670049562316
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.8866349117399832
dev_label=O_recall_tok: 0.9763653193458809
dev_label=O_f-score_tok: 0.9293392070484581
dev_label=N_precision_tok: 0.7492937853107344
dev_label=N_recall_tok: 0.5713516424340334
dev_label=N_f-score_tok: 0.6483348609838069
dev_label=P_precision_tok: 0.9299552906110283
dev_label=P_recall_tok: 0.5828144458281445
dev_label=P_f-score_tok: 0.7165550239234451
dev_precision_macro_tok: 0.8552946625539154
dev_recall_macro_tok: 0.7101771358693529
dev_f-score_macro_tok: 0.7647430306519034
dev_precision_micro_tok: 0.8815925542916235
dev_recall_micro_tok: 0.8815925542916235
dev_f-score_micro_tok: 0.8815925542916235
dev_time: 17.561690092086792
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.5721    0.8995    0.6994       428
           P     0.7363    0.6982    0.7168       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.6742    0.5399    0.4862      1101
weighted avg     0.6679    0.6358    0.5697      1101

F1-macro sent:  0.48616670049562316
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8866    0.9764    0.9293     16205
           N     0.7493    0.5714    0.6483      1857
           P     0.9300    0.5828    0.7166      3212

   micro avg     0.8816    0.8816    0.8816     21274
   macro avg     0.8553    0.7102    0.7647     21274
weighted avg     0.8812    0.8816    0.8727     21274

F1-macro tok:  0.7647430306519034
F1-micro tok:  0.8815925542916235
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 340579.68212890625
train_cost_avg: 39.86185418175401
train_count_sent: 8544.0
train_total_correct_sent: 5395.0
train_accuracy_sent: 0.631437265917603
train_count_tok: 163566.0
train_total_correct_tok: 142427.0
train_accuracy_tok: 0.8707616497316069
train_label=O_precision_sent: 0.5213675213675214
train_label=O_recall_sent: 0.037561576354679806
train_label=O_f-score_sent: 0.0700746697300402
train_label=N_precision_sent: 0.5959784895955109
train_label=N_recall_sent: 0.7700906344410876
train_label=N_f-score_sent: 0.6719388427573482
train_label=P_precision_sent: 0.6710843373493975
train_label=P_recall_sent: 0.7714681440443213
train_label=P_f-score_sent: 0.7177835051546392
train_precision_macro_sent: 0.5961434494374765
train_recall_macro_sent: 0.5263734516133629
train_f-score_macro_sent: 0.4865990058806758
train_precision_micro_sent: 0.631437265917603
train_recall_micro_sent: 0.631437265917603
train_f-score_micro_sent: 0.631437265917603
train_label=O_precision_tok: 0.8821055099991939
train_label=O_recall_tok: 0.9680410464265322
train_label=O_f-score_tok: 0.9230775129597252
train_label=N_precision_tok: 0.7473097241244375
train_label=N_recall_tok: 0.5378819884523307
train_label=N_f-score_tok: 0.6255322633475271
train_label=P_precision_tok: 0.8538174495054196
train_label=P_recall_tok: 0.5762081784386617
train_label=P_f-score_tok: 0.6880668257756563
train_precision_macro_tok: 0.8277442278763504
train_recall_macro_tok: 0.6940437377725083
train_f-score_macro_tok: 0.7455588673609695
train_precision_micro_tok: 0.8707616497316069
train_recall_micro_tok: 0.8707616497316069
train_f-score_micro_tok: 0.8707616497316069
train_time: 304.5662624835968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5214    0.0376    0.0701      1624
           N     0.5960    0.7701    0.6719      3310
           P     0.6711    0.7715    0.7178      3610

   micro avg     0.6314    0.6314    0.6314      8544
   macro avg     0.5961    0.5264    0.4866      8544
weighted avg     0.6135    0.6314    0.5769      8544

F1-macro sent:  0.4865990058806758
F1-micro sent:  0.631437265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8821    0.9680    0.9231    124347
           N     0.7473    0.5379    0.6255     14202
           P     0.8538    0.5762    0.6881     25017

   micro avg     0.8708    0.8708    0.8708    163566
   macro avg     0.8277    0.6940    0.7456    163566
weighted avg     0.8661    0.8708    0.8613    163566

F1-macro tok:  0.7455588673609695
F1-micro tok:  0.8707616497316069
**************************************************
dev_cost_sum: 45132.67431640625
dev_cost_avg: 40.99243807121367
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18845.0
dev_accuracy_tok: 0.8858230704145906
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05042016806722689
dev_label=N_precision_sent: 0.5868544600938967
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7029053420805998
dev_label=P_precision_sent: 0.7041942604856513
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7112597547380156
dev_precision_macro_sent: 0.6525717957487382
dev_recall_macro_sent: 0.540279188709993
dev_f-score_macro_sent: 0.4881950882952808
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.889987083731117
dev_label=O_recall_tok: 0.9779697624190065
dev_label=O_f-score_tok: 0.9319063859814183
dev_label=N_precision_tok: 0.7752976190476191
dev_label=N_recall_tok: 0.5611200861604739
dev_label=N_f-score_tok: 0.6510465479537645
dev_label=P_precision_tok: 0.9208666980687706
dev_label=P_recall_tok: 0.6086550435865504
dev_label=P_f-score_tok: 0.7328959700093721
dev_precision_macro_tok: 0.862050466949169
dev_recall_macro_tok: 0.7159149640553436
dev_f-score_macro_tok: 0.7719496346481849
dev_precision_micro_tok: 0.8858230704145906
dev_recall_micro_tok: 0.8858230704145906
dev_f-score_micro_tok: 0.8858230704145906
dev_time: 17.751920700073242
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0262    0.0504       229
           N     0.5869    0.8762    0.7029       428
           P     0.7042    0.7185    0.7113       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.6526    0.5403    0.4882      1101
weighted avg     0.6508    0.6358    0.5706      1101

F1-macro sent:  0.4881950882952808
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8900    0.9780    0.9319     16205
           N     0.7753    0.5611    0.6510      1857
           P     0.9209    0.6087    0.7329      3212

   micro avg     0.8858    0.8858    0.8858     21274
   macro avg     0.8621    0.7159    0.7719     21274
weighted avg     0.8846    0.8858    0.8773     21274

F1-macro tok:  0.7719496346481849
F1-micro tok:  0.8858230704145906
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 337471.9959716797
train_cost_avg: 39.49812686934453
train_count_sent: 8544.0
train_total_correct_sent: 5443.0
train_accuracy_sent: 0.6370552434456929
train_count_tok: 163566.0
train_total_correct_tok: 142742.0
train_accuracy_tok: 0.8726874778376924
train_label=O_precision_sent: 0.46601941747572817
train_label=O_recall_sent: 0.029556650246305417
train_label=O_f-score_sent: 0.05558772437753329
train_label=N_precision_sent: 0.6091981132075471
train_label=N_recall_sent: 0.7803625377643505
train_label=N_f-score_sent: 0.6842384105960264
train_label=P_precision_sent: 0.6693644370388003
train_label=P_recall_sent: 0.7789473684210526
train_label=P_f-score_sent: 0.7200102419664576
train_precision_macro_sent: 0.5815273225740253
train_recall_macro_sent: 0.5296221854772362
train_f-score_macro_sent: 0.48661212564667244
train_precision_micro_sent: 0.6370552434456929
train_recall_micro_sent: 0.6370552434456929
train_f-score_micro_sent: 0.6370552434456929
train_label=O_precision_tok: 0.8843387479520692
train_label=O_recall_tok: 0.9680169203921285
train_label=O_f-score_tok: 0.9242877985103278
train_label=N_precision_tok: 0.7505816207832493
train_label=N_recall_tok: 0.5452049007182087
train_label=N_f-score_tok: 0.6316175870788807
train_label=P_precision_tok: 0.8536499970823365
train_label=P_recall_tok: 0.584762361594116
train_label=P_f-score_tok: 0.6940741092185794
train_precision_macro_tok: 0.8295234552725517
train_recall_macro_tok: 0.6993280609014844
train_f-score_macro_tok: 0.7499931649359294
train_precision_micro_tok: 0.8726874778376924
train_recall_micro_tok: 0.8726874778376924
train_f-score_micro_tok: 0.8726874778376924
train_time: 296.4032850265503
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4660    0.0296    0.0556      1624
           N     0.6092    0.7804    0.6842      3310
           P     0.6694    0.7789    0.7200      3610

   micro avg     0.6371    0.6371    0.6371      8544
   macro avg     0.5815    0.5296    0.4866      8544
weighted avg     0.6074    0.6371    0.5799      8544

F1-macro sent:  0.48661212564667244
F1-micro sent:  0.6370552434456929
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8843    0.9680    0.9243    124347
           N     0.7506    0.5452    0.6316     14202
           P     0.8536    0.5848    0.6941     25017

   micro avg     0.8727    0.8727    0.8727    163566
   macro avg     0.8295    0.6993    0.7500    163566
weighted avg     0.8680    0.8727    0.8637    163566

F1-macro tok:  0.7499931649359294
F1-micro tok:  0.8726874778376924
**************************************************
dev_cost_sum: 45065.18688964844
dev_cost_avg: 40.931141589144815
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18760.0
dev_accuracy_tok: 0.8818275829651218
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5538674033149171
dev_label=N_recall_sent: 0.9369158878504673
dev_label=N_f-score_sent: 0.6961805555555555
dev_label=P_precision_sent: 0.774798927613941
dev_label=P_recall_sent: 0.6509009009009009
dev_label=P_f-score_sent: 0.7074663402692778
dev_precision_macro_sent: 0.692888776976286
dev_recall_macro_sent: 0.533639075144197
dev_f-score_macro_sent: 0.4764659895954022
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8767588283602519
dev_label=O_recall_tok: 0.9882135143474237
dev_label=O_f-score_tok: 0.9291557876414274
dev_label=N_precision_tok: 0.8363309352517986
dev_label=N_recall_tok: 0.5008077544426495
dev_label=N_f-score_tok: 0.6264735601212529
dev_label=P_precision_tok: 0.9573010015814444
dev_label=P_recall_tok: 0.5653798256537983
dev_label=P_f-score_tok: 0.7109023292229398
dev_precision_macro_tok: 0.8901302550644984
dev_recall_macro_tok: 0.6848003648146238
dev_f-score_macro_tok: 0.7555105589952067
dev_precision_micro_tok: 0.8818275829651218
dev_recall_micro_tok: 0.8818275829651218
dev_f-score_micro_tok: 0.8818275829651218
dev_time: 19.106443166732788
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5539    0.9369    0.6962       428
           P     0.7748    0.6509    0.7075       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.6929    0.5336    0.4765      1101
weighted avg     0.6838    0.6294    0.5613      1101

F1-macro sent:  0.4764659895954022
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8768    0.9882    0.9292     16205
           N     0.8363    0.5008    0.6265      1857
           P     0.9573    0.5654    0.7109      3212

   micro avg     0.8818    0.8818    0.8818     21274
   macro avg     0.8901    0.6848    0.7555     21274
weighted avg     0.8854    0.8818    0.8698     21274

F1-macro tok:  0.7555105589952067
F1-micro tok:  0.8818275829651218
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 334514.6433105469
train_cost_avg: 39.151994769492845
train_count_sent: 8544.0
train_total_correct_sent: 5497.0
train_accuracy_sent: 0.643375468164794
train_count_tok: 163566.0
train_total_correct_tok: 143284.0
train_accuracy_tok: 0.8760011249281635
train_label=O_precision_sent: 0.525
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.04929577464788733
train_label=N_precision_sent: 0.6028642873380313
train_label=N_recall_sent: 0.8012084592145015
train_label=N_f-score_sent: 0.6880269814502529
train_label=P_precision_sent: 0.6895448954489545
train_label=P_recall_sent: 0.7764542936288089
train_label=P_f-score_sent: 0.7304234527687298
train_precision_macro_sent: 0.6058030609289953
train_recall_macro_sent: 0.5345082739362759
train_f-score_macro_sent: 0.48924873628895665
train_precision_micro_sent: 0.643375468164794
train_recall_micro_sent: 0.643375468164794
train_f-score_micro_sent: 0.643375468164794
train_label=O_precision_tok: 0.8866510779728816
train_label=O_recall_tok: 0.9697137848118571
train_label=O_f-score_tok: 0.9263241185666602
train_label=N_precision_tok: 0.7628469887618865
train_label=N_recall_tok: 0.5592170116884946
train_label=N_f-score_tok: 0.6453500182830211
train_label=P_precision_tok: 0.8602482662159799
train_label=P_recall_tok: 0.590038773633929
train_label=P_f-score_tok: 0.6999715477996964
train_precision_macro_tok: 0.8365821109835827
train_recall_macro_tok: 0.7063231900447603
train_f-score_macro_tok: 0.7572152282164591
train_precision_micro_tok: 0.8760011249281635
train_recall_micro_tok: 0.8760011249281635
train_f-score_micro_tok: 0.8760011249281635
train_time: 296.9975097179413
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5250    0.0259    0.0493      1624
           N     0.6029    0.8012    0.6880      3310
           P     0.6895    0.7765    0.7304      3610

   micro avg     0.6434    0.6434    0.6434      8544
   macro avg     0.6058    0.5345    0.4892      8544
weighted avg     0.6247    0.6434    0.5845      8544

F1-macro sent:  0.48924873628895665
F1-micro sent:  0.643375468164794
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8867    0.9697    0.9263    124347
           N     0.7628    0.5592    0.6454     14202
           P     0.8602    0.5900    0.7000     25017

   micro avg     0.8760    0.8760    0.8760    163566
   macro avg     0.8366    0.7063    0.7572    163566
weighted avg     0.8719    0.8760    0.8673    163566

F1-macro tok:  0.7572152282164591
F1-micro tok:  0.8760011249281635
**************************************************
dev_cost_sum: 44539.457275390625
dev_cost_avg: 40.45363966883799
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18915.0
dev_accuracy_tok: 0.8891134718435649
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6385321100917432
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7153134635149023
dev_label=P_precision_sent: 0.6491862567811935
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7201604814443329
dev_precision_macro_sent: 0.7625727889576455
dev_recall_macro_sent: 0.5449143691297713
dev_f-score_macro_sent: 0.48711200464158416
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8948797736916548
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.93370720188902
dev_label=N_precision_tok: 0.7741007194244605
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6627656298121343
dev_label=P_precision_tok: 0.9153463105477592
dev_label=P_recall_tok: 0.6295143212951432
dev_label=P_f-score_tok: 0.7459878251245158
dev_precision_macro_tok: 0.8614422678879582
dev_recall_macro_tok: 0.7283334269189067
dev_f-score_macro_tok: 0.7808202189418901
dev_precision_micro_tok: 0.8891134718435649
dev_recall_micro_tok: 0.8891134718435649
dev_f-score_micro_tok: 0.8891134718435649
dev_time: 15.409611463546753
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6385    0.8131    0.7153       428
           P     0.6492    0.8086    0.7202       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.7626    0.5449    0.4871      1101
weighted avg     0.7180    0.6449    0.5739      1101

F1-macro sent:  0.48711200464158416
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9761    0.9337     16205
           N     0.7741    0.5794    0.6628      1857
           P     0.9153    0.6295    0.7460      3212

   micro avg     0.8891    0.8891    0.8891     21274
   macro avg     0.8614    0.7283    0.7808     21274
weighted avg     0.8874    0.8891    0.8817     21274

F1-macro tok:  0.7808202189418901
F1-micro tok:  0.8891134718435649
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 331902.61639404297
train_cost_avg: 38.84628000866608
train_count_sent: 8544.0
train_total_correct_sent: 5555.0
train_accuracy_sent: 0.6501638576779026
train_count_tok: 163566.0
train_total_correct_tok: 143663.0
train_accuracy_tok: 0.8783182323954856
train_label=O_precision_sent: 0.46
train_label=O_recall_sent: 0.042487684729064036
train_label=O_f-score_sent: 0.0777903043968433
train_label=N_precision_sent: 0.6049656395477722
train_label=N_recall_sent: 0.8244712990936556
train_label=N_f-score_sent: 0.697864723181179
train_label=P_precision_sent: 0.7100180272984805
train_label=P_recall_sent: 0.7637119113573407
train_label=P_f-score_sent: 0.7358868277058589
train_precision_macro_sent: 0.5916612222820842
train_recall_macro_sent: 0.5435569650600202
train_f-score_macro_sent: 0.5038472850946271
train_precision_micro_sent: 0.6501638576779026
train_recall_micro_sent: 0.6501638576779026
train_f-score_micro_sent: 0.6501638576779026
train_label=O_precision_tok: 0.8892199669577531
train_label=O_recall_tok: 0.9695770706169027
train_label=O_f-score_tok: 0.9276615717248038
train_label=N_precision_tok: 0.7603682262503559
train_label=N_recall_tok: 0.5641458949443741
train_label=N_f-score_tok: 0.6477222199765553
train_label=P_precision_tok: 0.8648323301805675
train_label=P_recall_tok: 0.6030699124595276
train_label=P_f-score_tok: 0.7106118411756392
train_precision_macro_tok: 0.8381401744628922
train_recall_macro_tok: 0.7122642926736015
train_f-score_macro_tok: 0.7619985442923328
train_precision_micro_tok: 0.8783182323954856
train_recall_micro_tok: 0.8783182323954856
train_f-score_micro_tok: 0.8783182323954856
train_time: 251.41782474517822
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4600    0.0425    0.0778      1624
           N     0.6050    0.8245    0.6979      3310
           P     0.7100    0.7637    0.7359      3610

   micro avg     0.6502    0.6502    0.6502      8544
   macro avg     0.5917    0.5436    0.5038      8544
weighted avg     0.6218    0.6502    0.5961      8544

F1-macro sent:  0.5038472850946271
F1-micro sent:  0.6501638576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8892    0.9696    0.9277    124347
           N     0.7604    0.5641    0.6477     14202
           P     0.8648    0.6031    0.7106     25017

   micro avg     0.8783    0.8783    0.8783    163566
   macro avg     0.8381    0.7123    0.7620    163566
weighted avg     0.8743    0.8783    0.8702    163566

F1-macro tok:  0.7619985442923328
F1-micro tok:  0.8783182323954856
**************************************************
dev_cost_sum: 44285.19384765625
dev_cost_avg: 40.22270104237625
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18953.0
dev_accuracy_tok: 0.890899689762151
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6203389830508474
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7190569744597249
dev_label=P_precision_sent: 0.6836935166994106
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7303252885624343
dev_precision_macro_sent: 0.768010833250086
dev_recall_macro_sent: 0.5492191983846068
dev_f-score_macro_sent: 0.4888994267793922
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8935140912414918
dev_label=O_recall_tok: 0.9801912989817957
dev_label=O_f-score_tok: 0.9348478606320992
dev_label=N_precision_tok: 0.7826398852223816
dev_label=N_recall_tok: 0.5875067312870221
dev_label=N_f-score_tok: 0.6711780990464473
dev_label=P_precision_tok: 0.9405611031859249
dev_label=P_recall_tok: 0.6158156911581569
dev_label=P_f-score_tok: 0.7443085606773283
dev_precision_macro_tok: 0.8722383598832661
dev_recall_macro_tok: 0.7278379071423249
dev_f-score_macro_tok: 0.783444840118625
dev_precision_micro_tok: 0.890899689762151
dev_recall_micro_tok: 0.890899689762151
dev_f-score_micro_tok: 0.890899689762151
dev_time: 15.510623216629028
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6203    0.8551    0.7191       428
           P     0.6837    0.7838    0.7303       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.7680    0.5492    0.4889      1101
weighted avg     0.7249    0.6503    0.5776      1101

F1-macro sent:  0.4888994267793922
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9802    0.9348     16205
           N     0.7826    0.5875    0.6712      1857
           P     0.9406    0.6158    0.7443      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8722    0.7278    0.7834     21274
weighted avg     0.8909    0.8909    0.8831     21274

F1-macro tok:  0.783444840118625
F1-micro tok:  0.890899689762151
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 329863.39825439453
train_cost_avg: 38.60760747359487
train_count_sent: 8544.0
train_total_correct_sent: 5525.0
train_accuracy_sent: 0.6466526217228464
train_count_tok: 163566.0
train_total_correct_tok: 143959.0
train_accuracy_tok: 0.8801278994412042
train_label=O_precision_sent: 0.48905109489051096
train_label=O_recall_sent: 0.04125615763546798
train_label=O_f-score_sent: 0.07609312890403179
train_label=N_precision_sent: 0.6234359961501443
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.694079828556121
train_label=P_precision_sent: 0.674429545989179
train_label=P_recall_sent: 0.7941828254847645
train_label=P_f-score_sent: 0.729423737437985
train_precision_macro_sent: 0.5956388790099448
train_recall_macro_sent: 0.539406146437862
train_f-score_macro_sent: 0.49986556496604595
train_precision_micro_sent: 0.6466526217228464
train_recall_micro_sent: 0.6466526217228464
train_f-score_micro_sent: 0.6466526217228464
train_label=O_precision_tok: 0.8909884687266845
train_label=O_recall_tok: 0.9699791711902981
train_label=O_f-score_tok: 0.9288073987940766
train_label=N_precision_tok: 0.7636073573573574
train_label=N_recall_tok: 0.5729474721870159
train_label=N_f-score_tok: 0.6546785743020356
train_label=P_precision_tok: 0.8670961856434233
train_label=P_recall_tok: 0.6079066234960228
train_label=P_f-score_tok: 0.7147288278973588
train_precision_macro_tok: 0.840564003909155
train_recall_macro_tok: 0.7169444222911122
train_f-score_macro_tok: 0.766071600331157
train_precision_micro_tok: 0.8801278994412042
train_recall_micro_tok: 0.8801278994412042
train_f-score_micro_tok: 0.8801278994412042
train_time: 247.00304985046387
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4891    0.0413    0.0761      1624
           N     0.6234    0.7828    0.6941      3310
           P     0.6744    0.7942    0.7294      3610

   micro avg     0.6467    0.6467    0.6467      8544
   macro avg     0.5956    0.5394    0.4999      8544
weighted avg     0.6194    0.6467    0.5915      8544

F1-macro sent:  0.49986556496604595
F1-micro sent:  0.6466526217228464
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8910    0.9700    0.9288    124347
           N     0.7636    0.5729    0.6547     14202
           P     0.8671    0.6079    0.7147     25017

   micro avg     0.8801    0.8801    0.8801    163566
   macro avg     0.8406    0.7169    0.7661    163566
weighted avg     0.8763    0.8801    0.8723    163566

F1-macro tok:  0.766071600331157
F1-micro tok:  0.8801278994412042
**************************************************
dev_cost_sum: 44043.17950439453
dev_cost_avg: 40.00288783323754
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 18985.0
dev_accuracy_tok: 0.8924038732725392
dev_label=O_precision_sent: 0.6956521739130435
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.126984126984127
dev_label=N_precision_sent: 0.6425855513307985
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7085953878406708
dev_label=P_precision_sent: 0.6521739130434783
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7228915662650603
dev_precision_macro_sent: 0.6634705460957734
dev_recall_macro_sent: 0.556799810870741
dev_f-score_macro_sent: 0.519490360363286
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8973879539917275
dev_label=O_recall_tok: 0.9773526689293428
dev_label=O_f-score_tok: 0.9356649140426538
dev_label=N_precision_tok: 0.821656050955414
dev_label=N_recall_tok: 0.555735056542811
dev_label=N_f-score_tok: 0.6630260199164792
dev_label=P_precision_tok: 0.8927817644575771
dev_label=P_recall_tok: 0.6584682440846824
dev_label=P_f-score_tok: 0.757928686615302
dev_precision_macro_tok: 0.8706085898015729
dev_recall_macro_tok: 0.7305186565189454
dev_f-score_macro_tok: 0.7855398735248117
dev_precision_micro_tok: 0.8924038732725392
dev_recall_micro_tok: 0.8924038732725392
dev_f-score_micro_tok: 0.8924038732725392
dev_time: 14.069157123565674
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6957    0.0699    0.1270       229
           N     0.6426    0.7897    0.7086       428
           P     0.6522    0.8108    0.7229       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.6635    0.5568    0.5195      1101
weighted avg     0.6575    0.6485    0.5934      1101

F1-macro sent:  0.519490360363286
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8974    0.9774    0.9357     16205
           N     0.8217    0.5557    0.6630      1857
           P     0.8928    0.6585    0.7579      3212

   micro avg     0.8924    0.8924    0.8924     21274
   macro avg     0.8706    0.7305    0.7855     21274
weighted avg     0.8901    0.8924    0.8850     21274

F1-macro tok:  0.7855398735248117
F1-micro tok:  0.8924038732725392
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 327639.06951904297
train_cost_avg: 38.34726937254717
train_count_sent: 8544.0
train_total_correct_sent: 5543.0
train_accuracy_sent: 0.6487593632958801
train_count_tok: 163566.0
train_total_correct_tok: 144284.0
train_accuracy_tok: 0.8821148649474829
train_label=O_precision_sent: 0.45
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.08071748878923768
train_label=N_precision_sent: 0.6103777878925808
train_label=N_recall_sent: 0.8102719033232628
train_label=N_f-score_sent: 0.6962616822429906
train_label=P_precision_sent: 0.6989974937343358
train_label=P_recall_sent: 0.7725761772853186
train_label=P_f-score_sent: 0.7339473684210527
train_precision_macro_sent: 0.5864584272089722
train_recall_macro_sent: 0.5423943519926798
train_f-score_macro_sent: 0.5036421798177603
train_precision_micro_sent: 0.6487593632958801
train_recall_micro_sent: 0.6487593632958801
train_f-score_micro_sent: 0.6487593632958801
train_label=O_precision_tok: 0.8927884330787901
train_label=O_recall_tok: 0.9703088936604823
train_label=O_f-score_tok: 0.9299359129989095
train_label=N_precision_tok: 0.7676625328823751
train_label=N_recall_tok: 0.5753415011970145
train_label=N_f-score_tok: 0.6577316268212188
train_label=P_precision_tok: 0.8695016312296097
train_label=P_recall_tok: 0.6178998281168805
train_label=P_f-score_tok: 0.7224208435564902
train_precision_macro_tok: 0.843317532396925
train_recall_macro_tok: 0.7211834076581258
train_f-score_macro_tok: 0.7700294611255395
train_precision_micro_tok: 0.8821148649474829
train_recall_micro_tok: 0.8821148649474829
train_f-score_micro_tok: 0.8821148649474829
train_time: 253.47476863861084
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4500    0.0443    0.0807      1624
           N     0.6104    0.8103    0.6963      3310
           P     0.6990    0.7726    0.7339      3610

   micro avg     0.6488    0.6488    0.6488      8544
   macro avg     0.5865    0.5424    0.5036      8544
weighted avg     0.6173    0.6488    0.5952      8544

F1-macro sent:  0.5036421798177603
F1-micro sent:  0.6487593632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8928    0.9703    0.9299    124347
           N     0.7677    0.5753    0.6577     14202
           P     0.8695    0.6179    0.7224     25017

   micro avg     0.8821    0.8821    0.8821    163566
   macro avg     0.8433    0.7212    0.7700    163566
weighted avg     0.8784    0.8821    0.8746    163566

F1-macro tok:  0.7700294611255395
F1-micro tok:  0.8821148649474829
**************************************************
dev_cost_sum: 43873.83135986328
dev_cost_avg: 39.8490748045988
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19005.0
dev_accuracy_tok: 0.8933439879665319
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6186440677966102
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7170923379174853
dev_label=P_precision_sent: 0.6817288801571709
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7282266526757607
dev_precision_macro_sent: 0.7667909826512603
dev_recall_macro_sent: 0.547689631434479
dev_f-score_macro_sent: 0.48754500263642103
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8995961089936857
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9361828084300261
dev_label=N_precision_tok: 0.8102796674225246
dev_label=N_recall_tok: 0.5772751750134626
dev_label=N_f-score_tok: 0.6742138364779874
dev_label=P_precision_tok: 0.8933389544688027
dev_label=P_recall_tok: 0.6597135740971357
dev_label=P_f-score_tok: 0.7589541547277937
dev_precision_macro_tok: 0.8677382436283376
dev_recall_macro_tok: 0.7376201312215828
dev_f-score_macro_tok: 0.7897835998786024
dev_precision_micro_tok: 0.8933439879665319
dev_recall_micro_tok: 0.8933439879665319
dev_f-score_micro_tok: 0.8933439879665319
dev_time: 15.564350128173828
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6186    0.8528    0.7171       428
           P     0.6817    0.7815    0.7282       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.7668    0.5477    0.4875      1101
weighted avg     0.7234    0.6485    0.5760      1101

F1-macro sent:  0.48754500263642103
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8996    0.9759    0.9362     16205
           N     0.8103    0.5773    0.6742      1857
           P     0.8933    0.6597    0.7590      3212

   micro avg     0.8933    0.8933    0.8933     21274
   macro avg     0.8677    0.7376    0.7898     21274
weighted avg     0.8909    0.8933    0.8866     21274

F1-macro tok:  0.7897835998786024
F1-micro tok:  0.8933439879665319
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 325184.58630371094
train_cost_avg: 38.05999371532197
train_count_sent: 8544.0
train_total_correct_sent: 5620.0
train_accuracy_sent: 0.6577715355805244
train_count_tok: 163566.0
train_total_correct_tok: 144634.0
train_accuracy_tok: 0.8842546739542447
train_label=O_precision_sent: 0.49206349206349204
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.07085714285714285
train_label=N_precision_sent: 0.6328087744396758
train_label=N_recall_sent: 0.8018126888217523
train_label=N_f-score_sent: 0.7073560767590619
train_label=P_precision_sent: 0.6875
train_label=P_recall_sent: 0.804432132963989
train_label=P_f-score_sent: 0.7413837120245086
train_precision_macro_sent: 0.6041240888343893
train_recall_macro_sent: 0.5481407205624064
train_f-score_macro_sent: 0.5065323105469045
train_precision_micro_sent: 0.6577715355805244
train_recall_micro_sent: 0.6577715355805244
train_f-score_micro_sent: 0.6577715355805244
train_label=O_precision_tok: 0.8944440740987638
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9312142383442066
train_label=N_precision_tok: 0.7765987154426138
train_label=N_recall_tok: 0.5874524714828897
train_label=N_f-score_tok: 0.6689116055321708
train_label=P_precision_tok: 0.8719546424160772
train_label=P_recall_tok: 0.6208977895031379
train_label=P_f-score_tok: 0.725315775956667
train_precision_macro_tok: 0.8476658106524849
train_recall_macro_tok: 0.7264958272759015
train_f-score_macro_tok: 0.7751472066110149
train_precision_micro_tok: 0.8842546739542447
train_recall_micro_tok: 0.8842546739542447
train_f-score_micro_tok: 0.8842546739542447
train_time: 235.95525217056274
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4921    0.0382    0.0709      1624
           N     0.6328    0.8018    0.7074      3310
           P     0.6875    0.8044    0.7414      3610

   micro avg     0.6578    0.6578    0.6578      8544
   macro avg     0.6041    0.5481    0.5065      8544
weighted avg     0.6292    0.6578    0.6008      8544

F1-macro sent:  0.5065323105469045
F1-micro sent:  0.6577715355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9711    0.9312    124347
           N     0.7766    0.5875    0.6689     14202
           P     0.8720    0.6209    0.7253     25017

   micro avg     0.8843    0.8843    0.8843    163566
   macro avg     0.8477    0.7265    0.7751    163566
weighted avg     0.8808    0.8843    0.8769    163566

F1-macro tok:  0.7751472066110149
F1-micro tok:  0.8842546739542447
**************************************************
dev_cost_sum: 43612.44512939453
dev_cost_avg: 39.611666784191215
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19036.0
dev_accuracy_tok: 0.8948011657422206
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02553191489361702
dev_label=N_precision_sent: 0.6431226765799256
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7163561076604554
dev_label=P_precision_sent: 0.6535008976660682
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7272727272727272
dev_precision_macro_sent: 0.5988745247486645
dev_recall_macro_sent: 0.5471104904847711
dev_f-score_macro_sent: 0.4897202499422666
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.8987707471817822
dev_label=O_recall_tok: 0.9790805307004011
dev_label=O_f-score_tok: 0.9372083407171128
dev_label=N_precision_tok: 0.7997076023391813
dev_label=N_recall_tok: 0.589122240172321
dev_label=N_f-score_tok: 0.6784496124031008
dev_label=P_precision_tok: 0.9214380825565912
dev_label=P_recall_tok: 0.6463262764632628
dev_label=P_f-score_tok: 0.759743824336688
dev_precision_macro_tok: 0.8733054773591848
dev_recall_macro_tok: 0.7381763491119949
dev_f-score_macro_tok: 0.7918005924856338
dev_precision_micro_tok: 0.8948011657422206
dev_recall_micro_tok: 0.8948011657422206
dev_f-score_micro_tok: 0.8948011657422205
dev_time: 11.945746183395386
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0131    0.0255       229
           N     0.6431    0.8084    0.7164       428
           P     0.6535    0.8198    0.7273       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.5989    0.5471    0.4897      1101
weighted avg     0.6175    0.6476    0.5771      1101

F1-macro sent:  0.4897202499422666
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8988    0.9791    0.9372     16205
           N     0.7997    0.5891    0.6784      1857
           P     0.9214    0.6463    0.7597      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8733    0.7382    0.7918     21274
weighted avg     0.8935    0.8948    0.8878     21274

F1-macro tok:  0.7918005924856338
F1-micro tok:  0.8948011657422205
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 323156.1026611328
train_cost_avg: 37.82257755865319
train_count_sent: 8544.0
train_total_correct_sent: 5634.0
train_accuracy_sent: 0.6594101123595506
train_count_tok: 163566.0
train_total_correct_tok: 144922.0
train_accuracy_tok: 0.8860154310798087
train_label=O_precision_sent: 0.3864406779661017
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.1188118811881188
train_label=N_precision_sent: 0.6372383930719269
train_label=N_recall_sent: 0.8003021148036253
train_label=N_f-score_sent: 0.7095218963439132
train_label=P_precision_sent: 0.7016129032258065
train_label=P_recall_sent: 0.7952908587257618
train_label=P_f-score_sent: 0.7455206439885744
train_precision_macro_sent: 0.5750973247546117
train_recall_macro_sent: 0.5552633392881208
train_f-score_macro_sent: 0.5246181405068687
train_precision_micro_sent: 0.6594101123595506
train_recall_micro_sent: 0.6594101123595506
train_f-score_micro_sent: 0.6594101123595506
train_label=O_precision_tok: 0.8965612002376708
train_label=O_recall_tok: 0.970775330325621
train_label=O_f-score_tok: 0.9321935077822439
train_label=N_precision_tok: 0.7794725719011302
train_label=N_recall_tok: 0.5973102379946487
train_label=N_f-score_tok: 0.6763404424955153
train_label=P_precision_tok: 0.8715845480241645
train_label=P_recall_tok: 0.6286125434704402
train_label=P_f-score_tok: 0.7304226660473758
train_precision_macro_tok: 0.8492061067209885
train_recall_macro_tok: 0.7322327039302365
train_f-score_macro_tok: 0.7796522054417117
train_precision_micro_tok: 0.8860154310798087
train_recall_micro_tok: 0.8860154310798087
train_f-score_micro_tok: 0.8860154310798087
train_time: 200.0845069885254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3864    0.0702    0.1188      1624
           N     0.6372    0.8003    0.7095      3310
           P     0.7016    0.7953    0.7455      3610

   micro avg     0.6594    0.6594    0.6594      8544
   macro avg     0.5751    0.5553    0.5246      8544
weighted avg     0.6168    0.6594    0.6125      8544

F1-macro sent:  0.5246181405068687
F1-micro sent:  0.6594101123595506
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9708    0.9322    124347
           N     0.7795    0.5973    0.6763     14202
           P     0.8716    0.6286    0.7304     25017

   micro avg     0.8860    0.8860    0.8860    163566
   macro avg     0.8492    0.7322    0.7797    163566
weighted avg     0.8826    0.8860    0.8791    163566

F1-macro tok:  0.7796522054417117
F1-micro tok:  0.8860154310798087
**************************************************
dev_cost_sum: 43508.26025390625
dev_cost_avg: 39.517039286018395
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19000.0
dev_accuracy_tok: 0.8931089592930338
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.6452205882352942
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7222222222222222
dev_label=P_precision_sent: 0.6672694394213382
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7402206619859578
dev_precision_macro_sent: 0.7708300092188775
dev_recall_macro_sent: 0.556213929311101
dev_f-score_macro_sent: 0.49892588271889265
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8991759022449559
dev_label=O_recall_tok: 0.9763036099969146
dev_label=O_f-score_tok: 0.936153846153846
dev_label=N_precision_tok: 0.7755385684503128
dev_label=N_recall_tok: 0.6009693053311793
dev_label=N_f-score_tok: 0.6771844660194175
dev_label=P_precision_tok: 0.9209821428571429
dev_label=P_recall_tok: 0.6422789539227896
dev_label=P_f-score_tok: 0.7567865003668379
dev_precision_macro_tok: 0.8652322045174706
dev_recall_macro_tok: 0.7398506230836279
dev_f-score_macro_tok: 0.7900416041800339
dev_precision_micro_tok: 0.8931089592930338
dev_recall_micro_tok: 0.8931089592930338
dev_f-score_micro_tok: 0.8931089592930339
dev_time: 11.133808851242065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.6452    0.8201    0.7222       428
           P     0.6673    0.8311    0.7402       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7708    0.5562    0.4989      1101
weighted avg     0.7279    0.6576    0.5864      1101

F1-macro sent:  0.49892588271889265
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9763    0.9362     16205
           N     0.7755    0.6010    0.6772      1857
           P     0.9210    0.6423    0.7568      3212

   micro avg     0.8931    0.8931    0.8931     21274
   macro avg     0.8652    0.7399    0.7900     21274
weighted avg     0.8917    0.8931    0.8865     21274

F1-macro tok:  0.7900416041800339
F1-micro tok:  0.8931089592930339
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 321108.1085205078
train_cost_avg: 37.58287786990962
train_count_sent: 8544.0
train_total_correct_sent: 5613.0
train_accuracy_sent: 0.6569522471910112
train_count_tok: 163566.0
train_total_correct_tok: 145139.0
train_accuracy_tok: 0.8873421126640011
train_label=O_precision_sent: 0.46788990825688076
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05885747259088287
train_label=N_precision_sent: 0.6185897435897436
train_label=N_recall_sent: 0.8163141993957704
train_label=N_f-score_sent: 0.7038291221672311
train_label=P_precision_sent: 0.7032210474551266
train_label=P_recall_sent: 0.7922437673130194
train_label=P_f-score_sent: 0.745082714602058
train_precision_macro_sent: 0.5965668997672503
train_recall_macro_sent: 0.5466539691984965
train_f-score_macro_sent: 0.502589769786724
train_precision_micro_sent: 0.6569522471910112
train_recall_micro_sent: 0.6569522471910112
train_f-score_micro_sent: 0.6569522471910112
train_label=O_precision_tok: 0.8983873248346022
train_label=O_recall_tok: 0.9708235823944285
train_label=O_f-score_tok: 0.9332019171304885
train_label=N_precision_tok: 0.7779198246735458
train_label=N_recall_tok: 0.5998450922405295
train_label=N_f-score_tok: 0.6773744682542838
train_label=P_precision_tok: 0.8716697730512005
train_label=P_recall_tok: 0.6356077867050406
train_label=P_f-score_tok: 0.7351533784877134
train_precision_macro_tok: 0.8493256408531162
train_recall_macro_tok: 0.7354254871133329
train_f-score_macro_tok: 0.7819099212908286
train_precision_micro_tok: 0.8873421126640011
train_recall_micro_tok: 0.8873421126640011
train_f-score_micro_tok: 0.8873421126640012
train_time: 194.5360472202301
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4679    0.0314    0.0589      1624
           N     0.6186    0.8163    0.7038      3310
           P     0.7032    0.7922    0.7451      3610

   micro avg     0.6570    0.6570    0.6570      8544
   macro avg     0.5966    0.5467    0.5026      8544
weighted avg     0.6257    0.6570    0.5987      8544

F1-macro sent:  0.502589769786724
F1-micro sent:  0.6569522471910112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8984    0.9708    0.9332    124347
           N     0.7779    0.5998    0.6774     14202
           P     0.8717    0.6356    0.7352     25017

   micro avg     0.8873    0.8873    0.8873    163566
   macro avg     0.8493    0.7354    0.7819    163566
weighted avg     0.8838    0.8873    0.8807    163566

F1-macro tok:  0.7819099212908286
F1-micro tok:  0.8873421126640012
**************************************************
dev_cost_sum: 43246.097900390625
dev_cost_avg: 39.27892634004598
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19055.0
dev_accuracy_tok: 0.8956942747015136
dev_label=O_precision_sent: 0.5666666666666667
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.1312741312741313
dev_label=N_precision_sent: 0.6338514680483592
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7288977159880834
dev_label=P_precision_sent: 0.7113821138211383
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7478632478632479
dev_precision_macro_sent: 0.6373000828453881
dev_recall_macro_sent: 0.5733335772208563
dev_f-score_macro_sent: 0.5360116983751542
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.8985007072135786
dev_label=O_recall_tok: 0.9800061709348966
dev_label=O_f-score_tok: 0.9374852420306966
dev_label=N_precision_tok: 0.8046477850399419
dev_label=N_recall_tok: 0.596661281637049
dev_label=N_f-score_tok: 0.6852195423623996
dev_label=P_precision_tok: 0.9297929792979298
dev_label=P_recall_tok: 0.6432129514321295
dev_label=P_f-score_tok: 0.7603974972396024
dev_precision_macro_tok: 0.8776471571838167
dev_recall_macro_tok: 0.7399601346680251
dev_f-score_macro_tok: 0.7943674272108995
dev_precision_micro_tok: 0.8956942747015136
dev_recall_micro_tok: 0.8956942747015136
dev_f-score_micro_tok: 0.8956942747015136
dev_time: 11.831509351730347
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5667    0.0742    0.1313       229
           N     0.6339    0.8575    0.7289       428
           P     0.7114    0.7883    0.7479       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6373    0.5733    0.5360      1101
weighted avg     0.6511    0.6667    0.6122      1101

F1-macro sent:  0.5360116983751542
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9800    0.9375     16205
           N     0.8046    0.5967    0.6852      1857
           P     0.9298    0.6432    0.7604      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8776    0.7400    0.7944     21274
weighted avg     0.8950    0.8957    0.8887     21274

F1-macro tok:  0.7943674272108995
F1-micro tok:  0.8956942747015136
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 319269.75842285156
train_cost_avg: 37.3677151712139
train_count_sent: 8544.0
train_total_correct_sent: 5636.0
train_accuracy_sent: 0.6596441947565543
train_count_tok: 163566.0
train_total_correct_tok: 145454.0
train_accuracy_tok: 0.8892679407700866
train_label=O_precision_sent: 0.45901639344262296
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.09297177642501382
train_label=N_precision_sent: 0.624655013799448
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.7093235831809871
train_label=P_precision_sent: 0.7067032145527037
train_label=P_recall_sent: 0.785595567867036
train_label=P_f-score_sent: 0.7440640167912895
train_precision_macro_sent: 0.5967915405982582
train_recall_macro_sent: 0.5526211708148654
train_f-score_macro_sent: 0.5154531254657635
train_precision_micro_sent: 0.6596441947565543
train_recall_micro_sent: 0.6596441947565543
train_f-score_micro_sent: 0.6596441947565543
train_label=O_precision_tok: 0.8998979310550352
train_label=O_recall_tok: 0.9713704391742463
train_label=O_f-score_tok: 0.9342692501063541
train_label=N_precision_tok: 0.7825262016624503
train_label=N_recall_tok: 0.6098436839881707
train_label=N_f-score_tok: 0.6854768500197863
train_label=P_precision_tok: 0.8758413132694939
train_label=P_recall_tok: 0.6398049326458009
train_label=P_f-score_tok: 0.7394437771412733
train_precision_macro_tok: 0.8527551486623265
train_recall_macro_tok: 0.7403396852694059
train_f-score_macro_tok: 0.7863966257558045
train_precision_micro_tok: 0.8892679407700866
train_recall_micro_tok: 0.8892679407700866
train_f-score_micro_tok: 0.8892679407700866
train_time: 195.93234872817993
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4590    0.0517    0.0930      1624
           N     0.6247    0.8205    0.7093      3310
           P     0.7067    0.7856    0.7441      3610

   micro avg     0.6596    0.6596    0.6596      8544
   macro avg     0.5968    0.5526    0.5155      8544
weighted avg     0.6278    0.6596    0.6068      8544

F1-macro sent:  0.5154531254657635
F1-micro sent:  0.6596441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8999    0.9714    0.9343    124347
           N     0.7825    0.6098    0.6855     14202
           P     0.8758    0.6398    0.7394     25017

   micro avg     0.8893    0.8893    0.8893    163566
   macro avg     0.8528    0.7403    0.7864    163566
weighted avg     0.8860    0.8893    0.8829    163566

F1-macro tok:  0.7863966257558045
F1-micro tok:  0.8892679407700866
**************************************************
dev_cost_sum: 43204.68896484375
dev_cost_avg: 39.24131604436308
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 19038.0
dev_accuracy_tok: 0.8948951772116198
dev_label=O_precision_sent: 0.2857142857142857
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.1437908496732026
dev_label=N_precision_sent: 0.640926640926641
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7019027484143764
dev_label=P_precision_sent: 0.6877470355731226
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7326315789473684
dev_precision_macro_sent: 0.5381293207380163
dev_recall_macro_sent: 0.5518515291196188
dev_f-score_macro_sent: 0.5261083923449825
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8979972844534962
dev_label=O_recall_tok: 0.9795124961431657
dev_label=O_f-score_tok: 0.9369853310114814
dev_label=N_precision_tok: 0.8026124818577649
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6837712519319938
dev_label=P_precision_tok: 0.9274774774774774
dev_label=P_recall_tok: 0.6410336239103362
dev_label=P_f-score_tok: 0.7581001472754051
dev_precision_macro_tok: 0.8760290812629128
dev_recall_macro_tok: 0.7387101319223395
dev_f-score_macro_tok: 0.7929522434062934
dev_precision_micro_tok: 0.8948951772116198
dev_recall_micro_tok: 0.8948951772116198
dev_f-score_micro_tok: 0.8948951772116199
dev_time: 11.827829599380493
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0961    0.1438       229
           N     0.6409    0.7757    0.7019       428
           P     0.6877    0.7838    0.7326       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.5381    0.5519    0.5261      1101
weighted avg     0.5859    0.6376    0.5982      1101

F1-macro sent:  0.5261083923449825
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8980    0.9795    0.9370     16205
           N     0.8026    0.5956    0.6838      1857
           P     0.9275    0.6410    0.7581      3212

   micro avg     0.8949    0.8949    0.8949     21274
   macro avg     0.8760    0.7387    0.7930     21274
weighted avg     0.8941    0.8949    0.8879     21274

F1-macro tok:  0.7929522434062934
F1-micro tok:  0.8948951772116199
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 317242.6184692383
train_cost_avg: 37.13045628151197
train_count_sent: 8544.0
train_total_correct_sent: 5724.0
train_accuracy_sent: 0.6699438202247191
train_count_tok: 163566.0
train_total_correct_tok: 145711.0
train_accuracy_tok: 0.8908391719550518
train_label=O_precision_sent: 0.4972677595628415
train_label=O_recall_sent: 0.05603448275862069
train_label=O_f-score_sent: 0.10071942446043165
train_label=N_precision_sent: 0.6412124060150376
train_label=N_recall_sent: 0.8244712990936556
train_label=N_f-score_sent: 0.7213851440655565
train_label=P_precision_sent: 0.7074299634591961
train_label=P_recall_sent: 0.804432132963989
train_label=P_f-score_sent: 0.7528191834089436
train_precision_macro_sent: 0.6153033763456918
train_recall_macro_sent: 0.5616459716054217
train_f-score_macro_sent: 0.5249745839783105
train_precision_micro_sent: 0.6699438202247191
train_recall_micro_sent: 0.6699438202247191
train_f-score_micro_sent: 0.6699438202247191
train_label=O_precision_tok: 0.9014953005905056
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9350212930700736
train_label=N_precision_tok: 0.7854004125190566
train_label=N_recall_tok: 0.6166737079284608
train_label=N_f-score_tok: 0.6908847079241116
train_label=P_precision_tok: 0.8772072364857545
train_label=P_recall_tok: 0.6473597953391693
train_label=P_f-score_tok: 0.7449573357252927
train_precision_macro_tok: 0.8547009831984389
train_recall_macro_tok: 0.7450569080364358
train_f-score_macro_tok: 0.7902877789064927
train_precision_micro_tok: 0.8908391719550518
train_recall_micro_tok: 0.8908391719550518
train_f-score_micro_tok: 0.8908391719550518
train_time: 199.41151070594788
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4973    0.0560    0.1007      1624
           N     0.6412    0.8245    0.7214      3310
           P     0.7074    0.8044    0.7528      3610

   micro avg     0.6699    0.6699    0.6699      8544
   macro avg     0.6153    0.5616    0.5250      8544
weighted avg     0.6418    0.6699    0.6167      8544

F1-macro sent:  0.5249745839783105
F1-micro sent:  0.6699438202247191
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9015    0.9711    0.9350    124347
           N     0.7854    0.6167    0.6909     14202
           P     0.8772    0.6474    0.7450     25017

   micro avg     0.8908    0.8908    0.8908    163566
   macro avg     0.8547    0.7451    0.7903    163566
weighted avg     0.8877    0.8908    0.8848    163566

F1-macro tok:  0.7902877789064927
F1-micro tok:  0.8908391719550518
**************************************************
dev_cost_sum: 43015.29541015625
dev_cost_avg: 39.06929646699024
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19075.0
dev_accuracy_tok: 0.8966343893955062
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6077170418006431
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.72
dev_label=P_precision_sent: 0.7073684210526315
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7312295973884657
dev_precision_macro_sent: 0.6883618209510916
dev_recall_macro_sent: 0.5510115878438125
dev_f-score_macro_sent: 0.49232689011661296
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9002724486320808
dev_label=O_recall_tok: 0.9787719839555693
dev_label=O_f-score_tok: 0.9378825059870503
dev_label=N_precision_tok: 0.822289156626506
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6857142857142857
dev_label=P_precision_tok: 0.9115120274914089
dev_label=P_recall_tok: 0.6606475716064757
dev_label=P_f-score_tok: 0.7660649819494584
dev_precision_macro_tok: 0.8780245442499987
dev_recall_macro_tok: 0.7424882632702777
dev_f-score_macro_tok: 0.7965539245502647
dev_precision_micro_tok: 0.8966343893955062
dev_recall_micro_tok: 0.8966343893955062
dev_f-score_micro_tok: 0.8966343893955062
dev_time: 11.971920013427734
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6077    0.8832    0.7200       428
           P     0.7074    0.7568    0.7312       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6884    0.5510    0.4923      1101
weighted avg     0.6775    0.6512    0.5801      1101

F1-macro sent:  0.49232689011661296
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9003    0.9788    0.9379     16205
           N     0.8223    0.5880    0.6857      1857
           P     0.9115    0.6606    0.7661      3212

   micro avg     0.8966    0.8966    0.8966     21274
   macro avg     0.8780    0.7425    0.7966     21274
weighted avg     0.8952    0.8966    0.8899     21274

F1-macro tok:  0.7965539245502647
F1-micro tok:  0.8966343893955062
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 315635.90075683594
train_cost_avg: 36.942404114798215
train_count_sent: 8544.0
train_total_correct_sent: 5725.0
train_accuracy_sent: 0.670060861423221
train_count_tok: 163566.0
train_total_correct_tok: 146077.0
train_accuracy_tok: 0.8930768008021227
train_label=O_precision_sent: 0.5223880597014925
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07963594994311718
train_label=N_precision_sent: 0.6396142084215479
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7192170347837589
train_label=P_precision_sent: 0.7059389276268334
train_label=P_recall_sent: 0.8132963988919668
train_label=P_f-score_sent: 0.7558244304286267
train_precision_macro_sent: 0.6226470652499579
train_recall_macro_sent: 0.5592833327417436
train_f-score_macro_sent: 0.5182258050518342
train_precision_micro_sent: 0.670060861423221
train_recall_micro_sent: 0.670060861423221
train_f-score_micro_sent: 0.670060861423221
train_label=O_precision_tok: 0.903575808333084
train_label=O_recall_tok: 0.9717725397476417
train_label=O_f-score_tok: 0.9364341926309384
train_label=N_precision_tok: 0.7906458797327395
train_label=N_recall_tok: 0.6249119842275735
train_label=N_f-score_tok: 0.6980768474456287
train_label=P_precision_tok: 0.8794131871674996
train_label=P_recall_tok: 0.6541551744813526
train_label=P_f-score_tok: 0.7502406821620135
train_precision_macro_tok: 0.8578782917444411
train_recall_macro_tok: 0.7502798994855225
train_f-score_macro_tok: 0.7949172407461935
train_precision_micro_tok: 0.8930768008021227
train_recall_micro_tok: 0.8930768008021227
train_f-score_micro_tok: 0.8930768008021227
train_time: 195.11438536643982
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5224    0.0431    0.0796      1624
           N     0.6396    0.8215    0.7192      3310
           P     0.7059    0.8133    0.7558      3610

   micro avg     0.6701    0.6701    0.6701      8544
   macro avg     0.6226    0.5593    0.5182      8544
weighted avg     0.6454    0.6701    0.6131      8544

F1-macro sent:  0.5182258050518342
F1-micro sent:  0.670060861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9036    0.9718    0.9364    124347
           N     0.7906    0.6249    0.6981     14202
           P     0.8794    0.6542    0.7502     25017

   micro avg     0.8931    0.8931    0.8931    163566
   macro avg     0.8579    0.7503    0.7949    163566
weighted avg     0.8901    0.8931    0.8873    163566

F1-macro tok:  0.7949172407461935
F1-micro tok:  0.8930768008021227
**************************************************
dev_cost_sum: 42876.187255859375
dev_cost_avg: 38.942949369536215
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19063.0
dev_accuracy_tok: 0.8960703205791106
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6025437201907791
dev_label=N_recall_sent: 0.8855140186915887
dev_label=N_f-score_sent: 0.7171239356669822
dev_label=P_precision_sent: 0.708779443254818
dev_label=P_recall_sent: 0.7454954954954955
dev_label=P_f-score_sent: 0.7266739846322722
dev_precision_macro_sent: 0.6371077211485323
dev_recall_macro_sent: 0.5480366502894357
dev_f-score_macro_sent: 0.4898129819800934
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.906118689921142
dev_label=O_recall_tok: 0.9714285714285714
dev_label=O_f-score_tok: 0.9376377389957711
dev_label=N_precision_tok: 0.7888965044551063
dev_label=N_recall_tok: 0.6198169089929995
dev_label=N_f-score_tok: 0.6942098914354645
dev_label=P_precision_tok: 0.8886158886158886
dev_label=P_recall_tok: 0.6755915317559154
dev_label=P_f-score_tok: 0.7675981605942696
dev_precision_macro_tok: 0.8612103609973789
dev_recall_macro_tok: 0.7556123373924954
dev_f-score_macro_tok: 0.7998152636751684
dev_precision_micro_tok: 0.8960703205791106
dev_recall_micro_tok: 0.8960703205791106
dev_f-score_micro_tok: 0.8960703205791106
dev_time: 12.054872512817383
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6025    0.8855    0.7171       428
           P     0.7088    0.7455    0.7267       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.6371    0.5480    0.4898      1101
weighted avg     0.6449    0.6476    0.5772      1101

F1-macro sent:  0.4898129819800934
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9061    0.9714    0.9376     16205
           N     0.7889    0.6198    0.6942      1857
           P     0.8886    0.6756    0.7676      3212

   micro avg     0.8961    0.8961    0.8961     21274
   macro avg     0.8612    0.7556    0.7998     21274
weighted avg     0.8932    0.8961    0.8907     21274

F1-macro tok:  0.7998152636751684
F1-micro tok:  0.8960703205791106
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 313928.67236328125
train_cost_avg: 36.74258805750014
train_count_sent: 8544.0
train_total_correct_sent: 5726.0
train_accuracy_sent: 0.6701779026217228
train_count_tok: 163566.0
train_total_correct_tok: 146273.0
train_accuracy_tok: 0.8942750938459093
train_label=O_precision_sent: 0.4897959183673469
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.08130999435347262
train_label=N_precision_sent: 0.6374678813361364
train_label=N_recall_sent: 0.8244712990936556
train_label=N_f-score_sent: 0.719009353181399
train_label=P_precision_sent: 0.7106413994169096
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.7571835361118302
train_precision_macro_sent: 0.6126350663734643
train_recall_macro_sent: 0.5596851939807794
train_f-score_macro_sent: 0.519167627882234
train_precision_micro_sent: 0.6701779026217228
train_recall_micro_sent: 0.6701779026217228
train_f-score_micro_sent: 0.6701779026217228
train_label=O_precision_tok: 0.9052771990827475
train_label=O_recall_tok: 0.9714910693462648
train_label=O_f-score_tok: 0.9372160953337806
train_label=N_precision_tok: 0.7919936513534962
train_label=N_recall_tok: 0.632446134347275
train_label=N_f-score_tok: 0.7032846572446463
train_label=P_precision_tok: 0.8778682851514668
train_label=P_recall_tok: 0.6591118039732982
train_label=P_f-score_tok: 0.7529223744292237
train_precision_macro_tok: 0.8583797118625701
train_recall_macro_tok: 0.7543496692222794
train_f-score_macro_tok: 0.7978077090025503
train_precision_micro_tok: 0.8942750938459093
train_recall_micro_tok: 0.8942750938459093
train_f-score_micro_tok: 0.8942750938459093
train_time: 199.5456018447876
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4898    0.0443    0.0813      1624
           N     0.6375    0.8245    0.7190      3310
           P     0.7106    0.8102    0.7572      3610

   micro avg     0.6702    0.6702    0.6702      8544
   macro avg     0.6126    0.5597    0.5192      8544
weighted avg     0.6403    0.6702    0.6139      8544

F1-macro sent:  0.519167627882234
F1-micro sent:  0.6701779026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9053    0.9715    0.9372    124347
           N     0.7920    0.6324    0.7033     14202
           P     0.8779    0.6591    0.7529     25017

   micro avg     0.8943    0.8943    0.8943    163566
   macro avg     0.8584    0.7543    0.7978    163566
weighted avg     0.8912    0.8943    0.8887    163566

F1-macro tok:  0.7978077090025503
F1-micro tok:  0.8942750938459093
**************************************************
dev_cost_sum: 42754.985595703125
dev_cost_avg: 38.83286611780483
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19106.0
dev_accuracy_tok: 0.8980915671711949
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042735042735042736
dev_label=N_precision_sent: 0.6868250539956804
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7138047138047138
dev_label=P_precision_sent: 0.6303317535545023
dev_label=P_recall_sent: 0.8986486486486487
dev_label=P_f-score_sent: 0.7409470752089137
dev_precision_macro_sent: 0.7723856025167276
dev_recall_macro_sent: 0.5544911213298759
dev_f-score_macro_sent: 0.49916227724955675
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9057804794127767
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.9389769045566685
dev_label=N_precision_tok: 0.7916381082933516
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.6966224366706876
dev_label=P_precision_tok: 0.9070256625999159
dev_label=P_recall_tok: 0.6712328767123288
dev_label=P_f-score_tok: 0.7715154768294866
dev_precision_macro_tok: 0.8681480834353481
dev_recall_macro_tok: 0.7559676548253941
dev_f-score_macro_tok: 0.8023716060189475
dev_precision_micro_tok: 0.8980915671711949
dev_recall_micro_tok: 0.8980915671711949
dev_f-score_micro_tok: 0.8980915671711949
dev_time: 11.921334505081177
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0218    0.0427       229
           N     0.6868    0.7430    0.7138       428
           P     0.6303    0.8986    0.7409       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7724    0.5545    0.4992      1101
weighted avg     0.7292    0.6558    0.5852      1101

F1-macro sent:  0.49916227724955675
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9747    0.9390     16205
           N     0.7916    0.6220    0.6966      1857
           P     0.9070    0.6712    0.7715      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8681    0.7560    0.8024     21274
weighted avg     0.8960    0.8981    0.8925     21274

F1-macro tok:  0.8023716060189475
F1-micro tok:  0.8980915671711949
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 311819.04650878906
train_cost_avg: 36.49567491909984
train_count_sent: 8544.0
train_total_correct_sent: 5796.0
train_accuracy_sent: 0.6783707865168539
train_count_tok: 163566.0
train_total_correct_tok: 146593.0
train_accuracy_tok: 0.8962314906520915
train_label=O_precision_sent: 0.48295454545454547
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.09444444444444446
train_label=N_precision_sent: 0.64375
train_label=N_recall_sent: 0.8401812688821753
train_label=N_f-score_sent: 0.7289646133682831
train_label=P_precision_sent: 0.7238142292490118
train_label=P_recall_sent: 0.8116343490304709
train_label=P_f-score_sent: 0.7652128493079133
train_precision_macro_sent: 0.6168395915678525
train_recall_macro_sent: 0.5680518397968263
train_f-score_macro_sent: 0.5295406357068803
train_precision_micro_sent: 0.6783707865168539
train_recall_micro_sent: 0.6783707865168539
train_f-score_micro_sent: 0.6783707865168539
train_label=O_precision_tok: 0.907528610825149
train_label=O_recall_tok: 0.9712578510136956
train_label=O_f-score_tok: 0.9383123693799383
train_label=N_precision_tok: 0.7953557140372238
train_label=N_recall_tok: 0.6439233910716801
train_label=N_f-score_tok: 0.7116731517509728
train_label=P_precision_tok: 0.8781399757754489
train_label=P_recall_tok: 0.6665467482112164
train_label=P_f-score_tok: 0.7578512021088033
train_precision_macro_tok: 0.8603414335459405
train_recall_macro_tok: 0.7605759967655307
train_f-score_macro_tok: 0.8026122410799048
train_precision_micro_tok: 0.8962314906520915
train_recall_micro_tok: 0.8962314906520915
train_f-score_micro_tok: 0.8962314906520915
train_time: 192.4326810836792
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4830    0.0523    0.0944      1624
           N     0.6438    0.8402    0.7290      3310
           P     0.7238    0.8116    0.7652      3610

   micro avg     0.6784    0.6784    0.6784      8544
   macro avg     0.6168    0.5681    0.5295      8544
weighted avg     0.6470    0.6784    0.6237      8544

F1-macro sent:  0.5295406357068803
F1-micro sent:  0.6783707865168539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9075    0.9713    0.9383    124347
           N     0.7954    0.6439    0.7117     14202
           P     0.8781    0.6665    0.7579     25017

   micro avg     0.8962    0.8962    0.8962    163566
   macro avg     0.8603    0.7606    0.8026    163566
weighted avg     0.8933    0.8962    0.8910    163566

F1-macro tok:  0.8026122410799048
F1-micro tok:  0.8962314906520915
**************************************************
dev_cost_sum: 42613.64733886719
dev_cost_avg: 38.70449349579218
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19140.0
dev_accuracy_tok: 0.8996897621509824
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.6117455138662317
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7204610951008645
dev_label=P_precision_sent: 0.7100840336134454
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.7347826086956522
dev_precision_macro_sent: 0.7183876269376701
dev_recall_macro_sent: 0.5603658692770229
dev_f-score_macro_sent: 0.5127437518879122
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9048380647740903
dev_label=O_recall_tok: 0.9775377969762419
dev_label=O_f-score_tok: 0.9397840531561462
dev_label=N_precision_tok: 0.8024079320113314
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6931783420006118
dev_label=P_precision_tok: 0.9197452229299363
dev_label=P_recall_tok: 0.674346201743462
dev_label=P_f-score_tok: 0.7781569965870307
dev_precision_macro_tok: 0.8756637399051194
dev_recall_macro_tok: 0.7540026181336367
dev_f-score_macro_tok: 0.8037064639145962
dev_precision_micro_tok: 0.8996897621509824
dev_recall_micro_tok: 0.8996897621509824
dev_f-score_micro_tok: 0.8996897621509824
dev_time: 11.36749267578125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.6117    0.8762    0.7205       428
           P     0.7101    0.7613    0.7348       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.7184    0.5604    0.5127      1101
weighted avg     0.6975    0.6567    0.5936      1101

F1-macro sent:  0.5127437518879122
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9775    0.9398     16205
           N     0.8024    0.6101    0.6932      1857
           P     0.9197    0.6743    0.7782      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8757    0.7540    0.8037     21274
weighted avg     0.8981    0.8997    0.8939     21274

F1-macro tok:  0.8037064639145962
F1-micro tok:  0.8996897621509824
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.810000
train_cost_sum: 310394.478515625
train_cost_avg: 36.32894177383251
train_count_sent: 8544.0
train_total_correct_sent: 5804.0
train_accuracy_sent: 0.6793071161048689
train_count_tok: 163566.0
train_total_correct_tok: 146865.0
train_accuracy_tok: 0.8978944279373464
train_label=O_precision_sent: 0.4549763033175355
train_label=O_recall_sent: 0.059113300492610835
train_label=O_f-score_sent: 0.10463215258855586
train_label=N_precision_sent: 0.6465677179962894
train_label=N_recall_sent: 0.8422960725075529
train_label=N_f-score_sent: 0.731566517974285
train_label=P_precision_sent: 0.7261875155433971
train_label=P_recall_sent: 0.8088642659279779
train_label=P_f-score_sent: 0.7652994365089766
train_precision_macro_sent: 0.6092438456190741
train_recall_macro_sent: 0.5700912129760473
train_f-score_macro_sent: 0.5338327023572725
train_precision_micro_sent: 0.6793071161048689
train_recall_micro_sent: 0.6793071161048689
train_f-score_micro_sent: 0.6793071161048689
train_label=O_precision_tok: 0.9086712329797072
train_label=O_recall_tok: 0.9719253379655319
train_label=O_f-score_tok: 0.9392345055372061
train_label=N_precision_tok: 0.801007556675063
train_label=N_recall_tok: 0.6493451626531475
train_label=N_f-score_tok: 0.7172467431460237
train_label=P_precision_tok: 0.8812073490813648
train_label=P_recall_tok: 0.6710237038813607
train_label=P_f-score_tok: 0.7618853110036988
train_precision_macro_tok: 0.8636287129120449
train_recall_macro_tok: 0.76409806816668
train_f-score_macro_tok: 0.8061221865623095
train_precision_micro_tok: 0.8978944279373464
train_recall_micro_tok: 0.8978944279373464
train_f-score_micro_tok: 0.8978944279373464
train_time: 198.54634070396423
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4550    0.0591    0.1046      1624
           N     0.6466    0.8423    0.7316      3310
           P     0.7262    0.8089    0.7653      3610

   micro avg     0.6793    0.6793    0.6793      8544
   macro avg     0.6092    0.5701    0.5338      8544
weighted avg     0.6438    0.6793    0.6267      8544

F1-macro sent:  0.5338327023572725
F1-micro sent:  0.6793071161048689
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9087    0.9719    0.9392    124347
           N     0.8010    0.6493    0.7172     14202
           P     0.8812    0.6710    0.7619     25017

   micro avg     0.8979    0.8979    0.8979    163566
   macro avg     0.8636    0.7641    0.8061    163566
weighted avg     0.8951    0.8979    0.8928    163566

F1-macro tok:  0.8061221865623095
F1-micro tok:  0.8978944279373464
**************************************************
dev_cost_sum: 42521.13641357422
dev_cost_avg: 38.62046904048521
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19127.0
dev_accuracy_tok: 0.8990786875998872
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.6744186046511628
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7372881355932203
dev_label=P_precision_sent: 0.6772486772486772
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7596439169139466
dev_precision_macro_sent: 0.6542594643369837
dev_recall_macro_sent: 0.5753279705040714
dev_f-score_macro_sent: 0.5286669594726994
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9036323202372127
dev_label=O_recall_tok: 0.9779080530700401
dev_label=O_f-score_tok: 0.9393041313496533
dev_label=N_precision_tok: 0.8279245283018868
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6895034569453173
dev_label=P_precision_tok: 0.9050580431177446
dev_label=P_recall_tok: 0.6796388542963886
dev_label=P_f-score_tok: 0.7763157894736842
dev_precision_macro_tok: 0.8788716305522813
dev_recall_macro_tok: 0.7494282188080161
dev_f-score_macro_tok: 0.8017077925895516
dev_precision_micro_tok: 0.8990786875998872
dev_recall_micro_tok: 0.8990786875998872
dev_f-score_micro_tok: 0.8990786875998872
dev_time: 11.280582189559937
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.6744    0.8131    0.7373       428
           P     0.6772    0.8649    0.7596       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6543    0.5753    0.5287      1101
weighted avg     0.6624    0.6748    0.6115      1101

F1-macro sent:  0.5286669594726994
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9036    0.9779    0.9393     16205
           N     0.8279    0.5907    0.6895      1857
           P     0.9051    0.6796    0.7763      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8789    0.7494    0.8017     21274
weighted avg     0.8972    0.8991    0.8929     21274

F1-macro tok:  0.8017077925895516
F1-micro tok:  0.8990786875998872
**************************************************
Best epoch: 16
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 308357.7420654297
train_cost_avg: 36.0905596986692
train_count_sent: 8544.0
train_total_correct_sent: 5853.0
train_accuracy_sent: 0.6850421348314607
train_count_tok: 163566.0
train_total_correct_tok: 147252.0
train_accuracy_tok: 0.900260445324823
train_label=O_precision_sent: 0.48514851485148514
train_label=O_recall_sent: 0.0603448275862069
train_label=O_f-score_sent: 0.10733844468784229
train_label=N_precision_sent: 0.6472081218274112
train_label=N_recall_sent: 0.8474320241691843
train_label=N_f-score_sent: 0.7339089481946625
train_label=P_precision_sent: 0.7360279441117764
train_label=P_recall_sent: 0.817174515235457
train_label=P_f-score_sent: 0.7744814912050407
train_precision_macro_sent: 0.6227948602635576
train_recall_macro_sent: 0.5749837889969495
train_f-score_macro_sent: 0.5385762946958484
train_precision_micro_sent: 0.6850421348314607
train_recall_micro_sent: 0.6850421348314607
train_f-score_micro_sent: 0.6850421348314607
train_label=O_precision_tok: 0.9109856904957463
train_label=O_recall_tok: 0.9722470184242483
train_label=O_f-score_tok: 0.9406199427362131
train_label=N_precision_tok: 0.8062451345039356
train_label=N_recall_tok: 0.6563160118293199
train_label=N_f-score_tok: 0.7235958545200482
train_label=P_precision_tok: 0.882825456053068
train_label=P_recall_tok: 0.6809369628652516
train_label=P_f-score_tok: 0.768848870534606
train_precision_macro_tok: 0.8666854270175833
train_recall_macro_tok: 0.7698333310396066
train_f-score_macro_tok: 0.8110215559302891
train_precision_micro_tok: 0.900260445324823
train_recall_micro_tok: 0.900260445324823
train_f-score_micro_tok: 0.900260445324823
train_time: 195.258220911026
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4851    0.0603    0.1073      1624
           N     0.6472    0.8474    0.7339      3310
           P     0.7360    0.8172    0.7745      3610

   micro avg     0.6850    0.6850    0.6850      8544
   macro avg     0.6228    0.5750    0.5386      8544
weighted avg     0.6539    0.6850    0.6320      8544

F1-macro sent:  0.5385762946958484
F1-micro sent:  0.6850421348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9722    0.9406    124347
           N     0.8062    0.6563    0.7236     14202
           P     0.8828    0.6809    0.7688     25017

   micro avg     0.9003    0.9003    0.9003    163566
   macro avg     0.8667    0.7698    0.8110    163566
weighted avg     0.8976    0.9003    0.8955    163566

F1-macro tok:  0.8110215559302891
F1-micro tok:  0.900260445324823
**************************************************
dev_cost_sum: 42523.62420654297
dev_cost_avg: 38.622728616296975
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19134.0
dev_accuracy_tok: 0.8994077277427847
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.7249417249417249
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.7257876312718786
dev_label=P_precision_sent: 0.608433734939759
dev_label=P_recall_sent: 0.9099099099099099
dev_label=P_f-score_sent: 0.7292418772563177
dev_precision_macro_sent: 0.6944584866271614
dev_recall_macro_sent: 0.5542487657636823
dev_f-score_macro_sent: 0.5018874733068671
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9085984324573536
dev_label=O_recall_tok: 0.9729095958037642
dev_label=O_f-score_tok: 0.9396549155168817
dev_label=N_precision_tok: 0.7935748462064252
dev_label=N_recall_tok: 0.6252019386106623
dev_label=N_f-score_tok: 0.6993975903614457
dev_label=P_precision_tok: 0.8975193167954453
dev_label=P_recall_tok: 0.6871108343711083
dev_label=P_f-score_tok: 0.7783459707282666
dev_precision_macro_tok: 0.8665641984864081
dev_recall_macro_tok: 0.7617407895951782
dev_f-score_macro_tok: 0.805799492202198
dev_precision_micro_tok: 0.8994077277427847
dev_recall_micro_tok: 0.8994077277427847
dev_f-score_micro_tok: 0.8994077277427848
dev_time: 11.811392068862915
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.7249    0.7266    0.7258       428
           P     0.6084    0.9099    0.7292       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6945    0.5542    0.5019      1101
weighted avg     0.6832    0.6549    0.5868      1101

F1-macro sent:  0.5018874733068671
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9086    0.9729    0.9397     16205
           N     0.7936    0.6252    0.6994      1857
           P     0.8975    0.6871    0.7783      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8666    0.7617    0.8058     21274
weighted avg     0.8969    0.8994    0.8943     21274

F1-macro tok:  0.805799492202198
F1-micro tok:  0.8994077277427848
**************************************************
Best epoch: 16
**************************************************

test0_cost_sum: 43246.09802246094
test0_cost_avg: 39.2789264509182
test0_count_sent: 1101.0
test0_total_correct_sent: 734.0
test0_accuracy_sent: 0.6666666666666666
test0_count_tok: 21274.0
test0_total_correct_tok: 19055.0
test0_accuracy_tok: 0.8956942747015136
test0_label=O_precision_sent: 0.5666666666666667
test0_label=O_recall_sent: 0.07423580786026202
test0_label=O_f-score_sent: 0.1312741312741313
test0_label=N_precision_sent: 0.6338514680483592
test0_label=N_recall_sent: 0.8574766355140186
test0_label=N_f-score_sent: 0.7288977159880834
test0_label=P_precision_sent: 0.7113821138211383
test0_label=P_recall_sent: 0.7882882882882883
test0_label=P_f-score_sent: 0.7478632478632479
test0_precision_macro_sent: 0.6373000828453881
test0_recall_macro_sent: 0.5733335772208563
test0_f-score_macro_sent: 0.5360116983751542
test0_precision_micro_sent: 0.6666666666666666
test0_recall_micro_sent: 0.6666666666666666
test0_f-score_micro_sent: 0.6666666666666666
test0_label=O_precision_tok: 0.8985007072135786
test0_label=O_recall_tok: 0.9800061709348966
test0_label=O_f-score_tok: 0.9374852420306966
test0_label=N_precision_tok: 0.8046477850399419
test0_label=N_recall_tok: 0.596661281637049
test0_label=N_f-score_tok: 0.6852195423623996
test0_label=P_precision_tok: 0.9297929792979298
test0_label=P_recall_tok: 0.6432129514321295
test0_label=P_f-score_tok: 0.7603974972396024
test0_precision_macro_tok: 0.8776471571838167
test0_recall_macro_tok: 0.7399601346680251
test0_f-score_macro_tok: 0.7943674272108995
test0_precision_micro_tok: 0.8956942747015136
test0_recall_micro_tok: 0.8956942747015136
test0_f-score_micro_tok: 0.8956942747015136
test0_time: 11.659180164337158
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5667    0.0742    0.1313       229
           N     0.6339    0.8575    0.7289       428
           P     0.7114    0.7883    0.7479       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6373    0.5733    0.5360      1101
weighted avg     0.6511    0.6667    0.6122      1101

F1-macro sent:  0.5360116983751542
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9800    0.9375     16205
           N     0.8046    0.5967    0.6852      1857
           P     0.9298    0.6432    0.7604      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8776    0.7400    0.7944     21274
weighted avg     0.8950    0.8957    0.8887     21274

F1-macro tok:  0.7943674272108995
F1-micro tok:  0.8956942747015136
**************************************************
test1_cost_sum: 83890.70125198364
test1_cost_avg: 37.95959332668943
test1_count_sent: 2210.0
test1_total_correct_sent: 1522.0
test1_accuracy_sent: 0.6886877828054299
test1_count_tok: 42405.0
test1_total_correct_tok: 37603.0
test1_accuracy_tok: 0.8867586369531895
test1_label=O_precision_sent: 0.5357142857142857
test1_label=O_recall_sent: 0.07712082262210797
test1_label=O_f-score_sent: 0.1348314606741573
test1_label=N_precision_sent: 0.6584953508030431
test1_label=N_recall_sent: 0.8541666666666666
test1_label=N_f-score_sent: 0.7436754176610977
test1_label=P_precision_sent: 0.7342945417095778
test1_label=P_recall_sent: 0.7843784378437844
test1_label=P_f-score_sent: 0.7585106382978724
test1_precision_macro_sent: 0.6428347260756356
test1_recall_macro_sent: 0.5718886423775197
test1_f-score_macro_sent: 0.5456725055443757
test1_precision_micro_sent: 0.6886877828054299
test1_recall_micro_sent: 0.6886877828054299
test1_f-score_micro_sent: 0.6886877828054299
test1_label=O_precision_tok: 0.8881182232539705
test1_label=O_recall_tok: 0.9804050253140821
test1_label=O_f-score_tok: 0.9319825908706051
test1_label=N_precision_tok: 0.7991376212720086
test1_label=N_recall_tok: 0.5914893617021276
test1_label=N_f-score_tok: 0.6798104844872382
test1_label=P_precision_tok: 0.9323098394975575
test1_label=P_recall_tok: 0.6029787874228976
test1_label=P_f-score_tok: 0.7323223095194592
test1_precision_macro_tok: 0.8731885613411788
test1_recall_macro_tok: 0.7249577248130358
test1_f-score_macro_tok: 0.7813717949591008
test1_precision_micro_tok: 0.8867586369531895
test1_recall_micro_tok: 0.8867586369531895
test1_f-score_micro_tok: 0.8867586369531895
test1_time: 24.053553581237793
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5357    0.0771    0.1348       389
           N     0.6585    0.8542    0.7437       912
           P     0.7343    0.7844    0.7585       909

   micro avg     0.6887    0.6887    0.6887      2210
   macro avg     0.6428    0.5719    0.5457      2210
weighted avg     0.6681    0.6887    0.6426      2210

F1-macro sent:  0.5456725055443757
F1-micro sent:  0.6886877828054299
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8881    0.9804    0.9320     31998
           N     0.7991    0.5915    0.6798      3760
           P     0.9323    0.6030    0.7323      6647

   micro avg     0.8868    0.8868    0.8868     42405
   macro avg     0.8732    0.7250    0.7814     42405
weighted avg     0.8872    0.8868    0.8783     42405

F1-macro tok:  0.7813717949591008
F1-micro tok:  0.8867586369531895
**************************************************
