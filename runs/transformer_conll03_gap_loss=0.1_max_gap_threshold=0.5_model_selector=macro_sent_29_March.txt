to_write_filename: runs/transformer_conll03_gap_loss=0.1_max_gap_threshold=0.5_model_selector=macro_sent_29_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.1
maximum_gap_threshold: 0.5
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'MISC': 2, 'O': 0, 'PER': 4, 'LOC': 1, 'ORG': 3}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-29 09:24:54.481737: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-29 09:24:54.584241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 81fa:00:00.0
totalMemory: 11.17GiB freeMemory: 7.72GiB
2019-03-29 09:24:54.584284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-29 09:24:55.156943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-29 09:24:55.156991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-29 09:24:55.157010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-29 09:24:55.157236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 81fa:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 9797652.
Parameter count without word embeddings: 3230652.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 453116.54248046875
train_cost_avg: 32.270959510039795
train_count_sent: 14041.0
train_total_correct_sent: 11778.0
train_accuracy_sent: 0.8388291432234172
train_count_tok: 203621.0
train_total_correct_tok: 186180.0
train_accuracy_tok: 0.9143457698370994
train_label=0_precision_sent: 0.667705088265836
train_label=0_recall_sent: 0.44207631488484017
train_label=0_f-score_sent: 0.5319544984488108
train_label=1_precision_sent: 0.8660338423442014
train_label=1_recall_sent: 0.9425080848005749
train_label=1_f-score_sent: 0.9026541059061384
train_precision_macro_sent: 0.7668694653050188
train_recall_macro_sent: 0.6922921998427075
train_f-score_macro_sent: 0.7173043021774745
train_precision_micro_sent: 0.8388291432234172
train_recall_micro_sent: 0.8388291432234172
train_f-score_micro_sent: 0.8388291432234172
train_label=O_precision_tok: 0.9452791405469246
train_label=O_recall_tok: 0.9817016358254019
train_label=O_f-score_tok: 0.9631461714252654
train_label=LOC_precision_tok: 0.7067680844458243
train_label=LOC_recall_tok: 0.5487525611666868
train_label=LOC_f-score_tok: 0.6178166768437479
train_label=MISC_precision_tok: 0.6101503759398497
train_label=MISC_recall_tok: 0.35336381450032656
train_label=MISC_f-score_tok: 0.44753894940024813
train_label=ORG_precision_tok: 0.6561893674815678
train_label=ORG_recall_tok: 0.5060349127182044
train_label=ORG_f-score_tok: 0.5714124802883532
train_label=PER_precision_tok: 0.7920569501686024
train_label=PER_recall_tok: 0.7598849748382459
train_label=PER_f-score_tok: 0.7756374977068429
train_precision_macro_tok: 0.7420887837165537
train_recall_macro_tok: 0.6299475798097731
train_f-score_macro_tok: 0.6751103551328914
train_precision_micro_tok: 0.9143457698370994
train_recall_micro_tok: 0.9143457698370994
train_f-score_micro_tok: 0.9143457698370994
train_time: 334.1118416786194
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6677    0.4421    0.5320      2909
           1     0.8660    0.9425    0.9027     11132

   micro avg     0.8388    0.8388    0.8388     14041
   macro avg     0.7669    0.6923    0.7173     14041
weighted avg     0.8249    0.8388    0.8259     14041

F1-macro sent:  0.7173043021774745
F1-micro sent:  0.8388291432234172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9453    0.9817    0.9631    169578
         LOC     0.7068    0.5488    0.6178      8297
        MISC     0.6102    0.3534    0.4475      4593
         ORG     0.6562    0.5060    0.5714     10025
         PER     0.7921    0.7599    0.7756     11128

   micro avg     0.9143    0.9143    0.9143    203621
   macro avg     0.7421    0.6299    0.6751    203621
weighted avg     0.9054    0.9143    0.9079    203621

F1-macro tok:  0.6751103551328914
F1-micro tok:  0.9143457698370994
**************************************************
dev_cost_sum: 101828.25247192383
dev_cost_avg: 31.331769991361178
dev_count_sent: 3250.0
dev_total_correct_sent: 2950.0
dev_accuracy_sent: 0.9076923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 49815.0
dev_accuracy_tok: 0.9698804563685215
dev_label=0_precision_sent: 0.9097387173396675
dev_label=0_recall_sent: 0.5937984496124031
dev_label=0_f-score_sent: 0.7185741088180113
dev_label=1_precision_sent: 0.9073877695298692
dev_label=1_recall_sent: 0.9854126679462571
dev_label=1_f-score_sent: 0.9447920500552079
dev_precision_macro_sent: 0.9085632434347684
dev_recall_macro_sent: 0.7896055587793301
dev_f-score_macro_sent: 0.8316830794366097
dev_precision_micro_sent: 0.9076923076923077
dev_recall_micro_sent: 0.9076923076923077
dev_f-score_micro_sent: 0.9076923076923076
dev_label=O_precision_tok: 0.9871343131345913
dev_label=O_recall_tok: 0.9958839074814659
dev_label=O_f-score_tok: 0.9914898075602174
dev_label=LOC_precision_tok: 0.8850630455868089
dev_label=LOC_recall_tok: 0.8715377268385864
dev_label=LOC_f-score_tok: 0.8782483156881618
dev_label=MISC_precision_tok: 0.8985976267529665
dev_label=MISC_recall_tok: 0.6569400630914827
dev_label=MISC_f-score_tok: 0.758997722095672
dev_label=ORG_precision_tok: 0.8594563331405437
dev_label=ORG_recall_tok: 0.7103250478011472
dev_label=ORG_f-score_tok: 0.7778068568437582
dev_label=PER_precision_tok: 0.8807758128921849
dev_label=PER_recall_tok: 0.9806287710384249
dev_label=PER_f-score_tok: 0.9280240420736288
dev_precision_macro_tok: 0.9022054263014191
dev_recall_macro_tok: 0.8430631032502214
dev_f-score_macro_tok: 0.8669133488522875
dev_precision_micro_tok: 0.9698804563685215
dev_recall_micro_tok: 0.9698804563685215
dev_f-score_micro_tok: 0.9698804563685215
dev_time: 32.89812731742859
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9097    0.5938    0.7186       645
           1     0.9074    0.9854    0.9448      2605

   micro avg     0.9077    0.9077    0.9077      3250
   macro avg     0.9086    0.7896    0.8317      3250
weighted avg     0.9079    0.9077    0.8999      3250

F1-macro sent:  0.8316830794366097
F1-micro sent:  0.9076923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9871    0.9959    0.9915     42759
         LOC     0.8851    0.8715    0.8782      2094
        MISC     0.8986    0.6569    0.7590      1268
         ORG     0.8595    0.7103    0.7778      2092
         PER     0.8808    0.9806    0.9280      3149

   micro avg     0.9699    0.9699    0.9699     51362
   macro avg     0.9022    0.8431    0.8669     51362
weighted avg     0.9691    0.9699    0.9685     51362

F1-macro tok:  0.8669133488522875
F1-micro tok:  0.9698804563685215
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 382982.0712890625
train_cost_avg: 27.27598257168738
train_count_sent: 14041.0
train_total_correct_sent: 12591.0
train_accuracy_sent: 0.8967310020653799
train_count_tok: 203621.0
train_total_correct_tok: 195969.0
train_accuracy_tok: 0.9624203790375256
train_label=0_precision_sent: 0.7796090456113454
train_label=0_recall_sent: 0.6992093502921967
train_label=0_f-score_sent: 0.7372236317506343
train_label=1_precision_sent: 0.9234604618614416
train_label=1_recall_sent: 0.9483471074380165
train_label=1_f-score_sent: 0.9357383442652012
train_precision_macro_sent: 0.8515347537363935
train_recall_macro_sent: 0.8237782288651065
train_f-score_macro_sent: 0.8364809880079178
train_precision_micro_sent: 0.8967310020653799
train_recall_micro_sent: 0.8967310020653799
train_f-score_micro_sent: 0.8967310020653799
train_label=O_precision_tok: 0.987335306136828
train_label=O_recall_tok: 0.9916321692672398
train_label=O_f-score_tok: 0.9894790728874295
train_label=LOC_precision_tok: 0.8377399492937342
train_label=LOC_recall_tok: 0.8363263830300108
train_label=LOC_f-score_tok: 0.8370325693606756
train_label=MISC_precision_tok: 0.7450682852807283
train_label=MISC_recall_tok: 0.6414108425865448
train_label=MISC_f-score_tok: 0.6893646893646893
train_label=ORG_precision_tok: 0.7841689203245268
train_label=ORG_recall_tok: 0.7520199501246883
train_label=ORG_f-score_tok: 0.7677580324863792
train_label=PER_precision_tok: 0.9067574646411733
train_label=PER_recall_tok: 0.9333213515456507
train_label=PER_f-score_tok: 0.9198476662828802
train_precision_macro_tok: 0.852213985135398
train_recall_macro_tok: 0.8309421393108268
train_f-score_macro_tok: 0.8406964060764107
train_precision_micro_tok: 0.9624203790375256
train_recall_micro_tok: 0.9624203790375256
train_f-score_micro_tok: 0.9624203790375256
train_time: 333.1717653274536
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7796    0.6992    0.7372      2909
           1     0.9235    0.9483    0.9357     11132

   micro avg     0.8967    0.8967    0.8967     14041
   macro avg     0.8515    0.8238    0.8365     14041
weighted avg     0.8937    0.8967    0.8946     14041

F1-macro sent:  0.8364809880079178
F1-micro sent:  0.8967310020653799
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9873    0.9916    0.9895    169578
         LOC     0.8377    0.8363    0.8370      8297
        MISC     0.7451    0.6414    0.6894      4593
         ORG     0.7842    0.7520    0.7678     10025
         PER     0.9068    0.9333    0.9198     11128

   micro avg     0.9624    0.9624    0.9624    203621
   macro avg     0.8522    0.8309    0.8407    203621
weighted avg     0.9614    0.9624    0.9618    203621

F1-macro tok:  0.8406964060764107
F1-micro tok:  0.9624203790375256
**************************************************
dev_cost_sum: 98934.6208190918
dev_cost_avg: 30.441421790489784
dev_count_sent: 3250.0
dev_total_correct_sent: 3073.0
dev_accuracy_sent: 0.9455384615384615
dev_count_tok: 51362.0
dev_total_correct_tok: 50064.0
dev_accuracy_tok: 0.9747283984268525
dev_label=0_precision_sent: 0.8441176470588235
dev_label=0_recall_sent: 0.889922480620155
dev_label=0_f-score_sent: 0.8664150943396226
dev_label=1_precision_sent: 0.9723735408560311
dev_label=1_recall_sent: 0.9593090211132438
dev_label=1_f-score_sent: 0.9657971014492753
dev_precision_macro_sent: 0.9082455939574273
dev_recall_macro_sent: 0.9246157508666994
dev_f-score_macro_sent: 0.916106097894449
dev_precision_micro_sent: 0.9455384615384615
dev_recall_micro_sent: 0.9455384615384615
dev_f-score_micro_sent: 0.9455384615384615
dev_label=O_precision_tok: 0.9938013145891325
dev_label=O_recall_tok: 0.9936153792184101
dev_label=O_f-score_tok: 0.9937083382060578
dev_label=LOC_precision_tok: 0.946078431372549
dev_label=LOC_recall_tok: 0.829512893982808
dev_label=LOC_f-score_tok: 0.8839694656488549
dev_label=MISC_precision_tok: 0.9391675560298826
dev_label=MISC_recall_tok: 0.694006309148265
dev_label=MISC_f-score_tok: 0.7981859410430838
dev_label=ORG_precision_tok: 0.7301343570057581
dev_label=ORG_recall_tok: 0.9091778202676865
dev_label=ORG_f-score_tok: 0.8098786459442197
dev_label=PER_precision_tok: 0.9461800185586143
dev_label=PER_recall_tok: 0.9714194982534138
dev_label=PER_f-score_tok: 0.9586336571607647
dev_precision_macro_tok: 0.9110723355111873
dev_recall_macro_tok: 0.8795463801741168
dev_f-score_macro_tok: 0.8888752096005961
dev_precision_micro_tok: 0.9747283984268525
dev_recall_micro_tok: 0.9747283984268525
dev_f-score_micro_tok: 0.9747283984268525
dev_time: 33.00682878494263
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8441    0.8899    0.8664       645
           1     0.9724    0.9593    0.9658      2605

   micro avg     0.9455    0.9455    0.9455      3250
   macro avg     0.9082    0.9246    0.9161      3250
weighted avg     0.9469    0.9455    0.9461      3250

F1-macro sent:  0.916106097894449
F1-micro sent:  0.9455384615384615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9938    0.9936    0.9937     42759
         LOC     0.9461    0.8295    0.8840      2094
        MISC     0.9392    0.6940    0.7982      1268
         ORG     0.7301    0.9092    0.8099      2092
         PER     0.9462    0.9714    0.9586      3149

   micro avg     0.9747    0.9747    0.9747     51362
   macro avg     0.9111    0.8795    0.8889     51362
weighted avg     0.9768    0.9747    0.9748     51362

F1-macro tok:  0.8888752096005961
F1-micro tok:  0.9747283984268525
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 371048.5893249512
train_cost_avg: 26.426080003201424
train_count_sent: 14041.0
train_total_correct_sent: 12840.0
train_accuracy_sent: 0.9144647817107043
train_count_tok: 203621.0
train_total_correct_tok: 197323.0
train_accuracy_tok: 0.9690699878696205
train_label=0_precision_sent: 0.807858687815429
train_label=0_recall_sent: 0.7703678239944999
train_label=0_f-score_sent: 0.7886679570649305
train_label=1_precision_sent: 0.9407118132599627
train_label=1_recall_sent: 0.9521200143729788
train_label=1_f-score_sent: 0.9463815348899504
train_precision_macro_sent: 0.8742852505376959
train_recall_macro_sent: 0.8612439191837393
train_f-score_macro_sent: 0.8675247459774404
train_precision_micro_sent: 0.9144647817107043
train_recall_micro_sent: 0.9144647817107043
train_f-score_micro_sent: 0.9144647817107042
train_label=O_precision_tok: 0.9898622440583935
train_label=O_recall_tok: 0.9932361509158028
train_label=O_f-score_tok: 0.9915463274208646
train_label=LOC_precision_tok: 0.8717544285367629
train_label=LOC_recall_tok: 0.8659756538507895
train_label=LOC_f-score_tok: 0.8688554326138218
train_label=MISC_precision_tok: 0.7877206065125528
train_label=MISC_recall_tok: 0.6899629871543653
train_label=MISC_f-score_tok: 0.7356081708449397
train_label=ORG_precision_tok: 0.814653425212809
train_label=ORG_recall_tok: 0.8018952618453865
train_label=ORG_f-score_tok: 0.8082239983913939
train_label=PER_precision_tok: 0.9264913519237558
train_label=PER_recall_tok: 0.9434759166067578
train_label=PER_f-score_tok: 0.934906500445236
train_precision_macro_tok: 0.8780964112488547
train_recall_macro_tok: 0.8589091940746204
train_f-score_macro_tok: 0.8678280859432512
train_precision_micro_tok: 0.9690699878696205
train_recall_micro_tok: 0.9690699878696205
train_f-score_micro_tok: 0.9690699878696205
train_time: 331.4897952079773
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8079    0.7704    0.7887      2909
           1     0.9407    0.9521    0.9464     11132

   micro avg     0.9145    0.9145    0.9145     14041
   macro avg     0.8743    0.8612    0.8675     14041
weighted avg     0.9132    0.9145    0.9137     14041

F1-macro sent:  0.8675247459774404
F1-micro sent:  0.9144647817107042
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9899    0.9932    0.9915    169578
         LOC     0.8718    0.8660    0.8689      8297
        MISC     0.7877    0.6900    0.7356      4593
         ORG     0.8147    0.8019    0.8082     10025
         PER     0.9265    0.9435    0.9349     11128

   micro avg     0.9691    0.9691    0.9691    203621
   macro avg     0.8781    0.8589    0.8678    203621
weighted avg     0.9684    0.9691    0.9687    203621

F1-macro tok:  0.8678280859432512
F1-micro tok:  0.9690699878696205
**************************************************
dev_cost_sum: 96402.0970916748
dev_cost_avg: 29.662183720515326
dev_count_sent: 3250.0
dev_total_correct_sent: 3009.0
dev_accuracy_sent: 0.9258461538461539
dev_count_tok: 51362.0
dev_total_correct_tok: 50343.0
dev_accuracy_tok: 0.9801604298898018
dev_label=0_precision_sent: 0.9902912621359223
dev_label=0_recall_sent: 0.6325581395348837
dev_label=0_f-score_sent: 0.771996215704825
dev_label=1_precision_sent: 0.9164904862579282
dev_label=1_recall_sent: 0.9984644913627639
dev_label=1_f-score_sent: 0.9557229469042807
dev_precision_macro_sent: 0.9533908741969253
dev_recall_macro_sent: 0.8155113154488238
dev_f-score_macro_sent: 0.8638595813045529
dev_precision_micro_sent: 0.9258461538461539
dev_recall_micro_sent: 0.9258461538461539
dev_f-score_micro_sent: 0.9258461538461539
dev_label=O_precision_tok: 0.9911656669921421
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9941123663623751
dev_label=LOC_precision_tok: 0.9132270168855535
dev_label=LOC_recall_tok: 0.9297994269340975
dev_label=LOC_f-score_tok: 0.9214387127307146
dev_label=MISC_precision_tok: 0.9315476190476191
dev_label=MISC_recall_tok: 0.7405362776025236
dev_label=MISC_f-score_tok: 0.8251318101933216
dev_label=ORG_precision_tok: 0.8681906614785992
dev_label=ORG_recall_tok: 0.8532504780114722
dev_label=ORG_f-score_tok: 0.860655737704918
dev_label=PER_precision_tok: 0.9638324873096447
dev_label=PER_recall_tok: 0.9647507145125437
dev_label=PER_f-score_tok: 0.9642913823202666
dev_precision_macro_tok: 0.9335926903427119
dev_recall_macro_tok: 0.897082707179381
dev_f-score_macro_tok: 0.9131260018623191
dev_precision_micro_tok: 0.9801604298898018
dev_recall_micro_tok: 0.9801604298898018
dev_f-score_micro_tok: 0.9801604298898018
dev_time: 32.720664978027344
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9903    0.6326    0.7720       645
           1     0.9165    0.9985    0.9557      2605

   micro avg     0.9258    0.9258    0.9258      3250
   macro avg     0.9534    0.8155    0.8639      3250
weighted avg     0.9311    0.9258    0.9193      3250

F1-macro sent:  0.8638595813045529
F1-micro sent:  0.9258461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9912    0.9971    0.9941     42759
         LOC     0.9132    0.9298    0.9214      2094
        MISC     0.9315    0.7405    0.8251      1268
         ORG     0.8682    0.8533    0.8607      2092
         PER     0.9638    0.9648    0.9643      3149

   micro avg     0.9802    0.9802    0.9802     51362
   macro avg     0.9336    0.8971    0.9131     51362
weighted avg     0.9798    0.9802    0.9797     51362

F1-macro tok:  0.9131260018623191
F1-micro tok:  0.9801604298898018
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361975.28213500977
train_cost_avg: 25.779879078057814
train_count_sent: 14041.0
train_total_correct_sent: 13042.0
train_accuracy_sent: 0.9288512214229756
train_count_tok: 203621.0
train_total_correct_tok: 198263.0
train_accuracy_tok: 0.9736864075905727
train_label=0_precision_sent: 0.8343837535014006
train_label=0_recall_sent: 0.8191818494327948
train_label=0_f-score_sent: 0.8267129228100608
train_label=1_precision_sent: 0.9529727313366115
train_label=1_recall_sent: 0.9575098814229249
train_label=1_f-score_sent: 0.9552359188062911
train_precision_macro_sent: 0.8936782424190061
train_recall_macro_sent: 0.8883458654278599
train_f-score_macro_sent: 0.890974420808176
train_precision_micro_sent: 0.9288512214229756
train_recall_micro_sent: 0.9288512214229756
train_f-score_micro_sent: 0.9288512214229756
train_label=O_precision_tok: 0.9915178965324549
train_label=O_recall_tok: 0.9940145537746642
train_label=O_f-score_tok: 0.9927646554745083
train_label=LOC_precision_tok: 0.8899336949969862
train_label=LOC_recall_tok: 0.8897191756056406
train_label=LOC_f-score_tok: 0.8898264223722275
train_label=MISC_precision_tok: 0.815055315055315
train_label=MISC_recall_tok: 0.7378619638580448
train_label=MISC_f-score_tok: 0.774540052565421
train_label=ORG_precision_tok: 0.8443520584060028
train_label=ORG_recall_tok: 0.8306234413965087
train_label=ORG_f-score_tok: 0.8374314879066725
train_label=PER_precision_tok: 0.9381470666312716
train_label=PER_recall_tok: 0.9527318475916606
train_label=PER_f-score_tok: 0.94538320923804
train_precision_macro_tok: 0.8958012063244061
train_recall_macro_tok: 0.8809901964453039
train_f-score_macro_tok: 0.8879891655113739
train_precision_micro_tok: 0.9736864075905727
train_recall_micro_tok: 0.9736864075905727
train_f-score_micro_tok: 0.9736864075905727
train_time: 329.88986229896545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8344    0.8192    0.8267      2909
           1     0.9530    0.9575    0.9552     11132

   micro avg     0.9289    0.9289    0.9289     14041
   macro avg     0.8937    0.8883    0.8910     14041
weighted avg     0.9284    0.9289    0.9286     14041

F1-macro sent:  0.890974420808176
F1-micro sent:  0.9288512214229756
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9915    0.9940    0.9928    169578
         LOC     0.8899    0.8897    0.8898      8297
        MISC     0.8151    0.7379    0.7745      4593
         ORG     0.8444    0.8306    0.8374     10025
         PER     0.9381    0.9527    0.9454     11128

   micro avg     0.9737    0.9737    0.9737    203621
   macro avg     0.8958    0.8810    0.8880    203621
weighted avg     0.9732    0.9737    0.9734    203621

F1-macro tok:  0.8879891655113739
F1-micro tok:  0.9736864075905727
**************************************************
dev_cost_sum: 94410.88633728027
dev_cost_avg: 29.04950348839393
dev_count_sent: 3250.0
dev_total_correct_sent: 3123.0
dev_accuracy_sent: 0.9609230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50458.0
dev_accuracy_tok: 0.9823994392741716
dev_label=0_precision_sent: 0.8808823529411764
dev_label=0_recall_sent: 0.9286821705426357
dev_label=0_f-score_sent: 0.9041509433962264
dev_label=1_precision_sent: 0.982101167315175
dev_label=1_recall_sent: 0.9689059500959692
dev_label=1_f-score_sent: 0.9754589371980675
dev_precision_macro_sent: 0.9314917601281758
dev_recall_macro_sent: 0.9487940603193025
dev_f-score_macro_sent: 0.9398049402971469
dev_precision_micro_sent: 0.9609230769230769
dev_recall_micro_sent: 0.9609230769230769
dev_f-score_micro_sent: 0.9609230769230769
dev_label=O_precision_tok: 0.9934512573119858
dev_label=O_recall_tok: 0.9969363175004092
dev_label=O_f-score_tok: 0.9951907363309519
dev_label=LOC_precision_tok: 0.9163926726162518
dev_label=LOC_recall_tok: 0.9317096466093601
dev_label=LOC_f-score_tok: 0.9239876864788066
dev_label=MISC_precision_tok: 0.9081908190819082
dev_label=MISC_recall_tok: 0.7957413249211357
dev_label=MISC_f-score_tok: 0.8482555695670451
dev_label=ORG_precision_tok: 0.900253164556962
dev_label=ORG_recall_tok: 0.8499043977055449
dev_label=ORG_f-score_tok: 0.874354561101549
dev_label=PER_precision_tok: 0.9549104385423101
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9682166901518711
dev_precision_macro_tok: 0.9346396704218837
dev_recall_macro_tok: 0.911238140459389
dev_f-score_macro_tok: 0.9220010487260447
dev_precision_micro_tok: 0.9823994392741716
dev_recall_micro_tok: 0.9823994392741716
dev_f-score_micro_tok: 0.9823994392741716
dev_time: 32.62964963912964
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8809    0.9287    0.9042       645
           1     0.9821    0.9689    0.9755      2605

   micro avg     0.9609    0.9609    0.9609      3250
   macro avg     0.9315    0.9488    0.9398      3250
weighted avg     0.9620    0.9609    0.9613      3250

F1-macro sent:  0.9398049402971469
F1-micro sent:  0.9609230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9935    0.9969    0.9952     42759
         LOC     0.9164    0.9317    0.9240      2094
        MISC     0.9082    0.7957    0.8483      1268
         ORG     0.9003    0.8499    0.8744      2092
         PER     0.9549    0.9819    0.9682      3149

   micro avg     0.9824    0.9824    0.9824     51362
   macro avg     0.9346    0.9112    0.9220     51362
weighted avg     0.9820    0.9824    0.9821     51362

F1-macro tok:  0.9220010487260447
F1-micro tok:  0.9823994392741716
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 354944.55001831055
train_cost_avg: 25.27915034672107
train_count_sent: 14041.0
train_total_correct_sent: 13179.0
train_accuracy_sent: 0.9386083612278328
train_count_tok: 203621.0
train_total_correct_tok: 198789.0
train_accuracy_tok: 0.976269638200382
train_label=0_precision_sent: 0.8552585907670948
train_label=0_recall_sent: 0.8470264695771743
train_label=0_f-score_sent: 0.8511226252158895
train_label=1_precision_sent: 0.9601254480286738
train_label=1_recall_sent: 0.9625404240028747
train_label=1_f-score_sent: 0.9613314193432622
train_precision_macro_sent: 0.9076920193978844
train_recall_macro_sent: 0.9047834467900244
train_f-score_macro_sent: 0.9062270222795759
train_precision_micro_sent: 0.9386083612278328
train_recall_micro_sent: 0.9386083612278328
train_f-score_micro_sent: 0.9386083612278328
train_label=O_precision_tok: 0.9921931073433032
train_label=O_recall_tok: 0.9945334890139051
train_label=O_f-score_tok: 0.9933619196833512
train_label=LOC_precision_tok: 0.8969864329451315
train_label=LOC_recall_tok: 0.9004459443172231
train_label=LOC_f-score_tok: 0.8987128593768795
train_label=MISC_precision_tok: 0.8390532544378698
train_label=MISC_recall_tok: 0.7718266927933812
train_label=MISC_f-score_tok: 0.8040371966432298
train_label=ORG_precision_tok: 0.8626233845527628
train_label=ORG_recall_tok: 0.8455860349127182
train_label=ORG_f-score_tok: 0.8540197461212975
train_label=PER_precision_tok: 0.9452139939619961
train_label=PER_recall_tok: 0.9565959741193386
train_label=PER_f-score_tok: 0.950870924519875
train_precision_macro_tok: 0.9072140346482126
train_recall_macro_tok: 0.8937976270313133
train_f-score_macro_tok: 0.9002005292689266
train_precision_micro_tok: 0.976269638200382
train_recall_micro_tok: 0.976269638200382
train_f-score_micro_tok: 0.976269638200382
train_time: 331.1116726398468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8553    0.8470    0.8511      2909
           1     0.9601    0.9625    0.9613     11132

   micro avg     0.9386    0.9386    0.9386     14041
   macro avg     0.9077    0.9048    0.9062     14041
weighted avg     0.9384    0.9386    0.9385     14041

F1-macro sent:  0.9062270222795759
F1-micro sent:  0.9386083612278328
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9922    0.9945    0.9934    169578
         LOC     0.8970    0.9004    0.8987      8297
        MISC     0.8391    0.7718    0.8040      4593
         ORG     0.8626    0.8456    0.8540     10025
         PER     0.9452    0.9566    0.9509     11128

   micro avg     0.9763    0.9763    0.9763    203621
   macro avg     0.9072    0.8938    0.9002    203621
weighted avg     0.9759    0.9763    0.9761    203621

F1-macro tok:  0.9002005292689266
F1-micro tok:  0.976269638200382
**************************************************
dev_cost_sum: 93057.0817565918
dev_cost_avg: 28.632948232797474
dev_count_sent: 3250.0
dev_total_correct_sent: 3162.0
dev_accuracy_sent: 0.9729230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50480.0
dev_accuracy_tok: 0.982827771504225
dev_label=0_precision_sent: 0.9175412293853074
dev_label=0_recall_sent: 0.9488372093023256
dev_label=0_f-score_sent: 0.9329268292682927
dev_label=1_precision_sent: 0.9872241579558653
dev_label=1_recall_sent: 0.9788867562380038
dev_label=1_f-score_sent: 0.9830377794911334
dev_precision_macro_sent: 0.9523826936705864
dev_recall_macro_sent: 0.9638619827701647
dev_f-score_macro_sent: 0.9579823043797131
dev_precision_micro_sent: 0.9729230769230769
dev_recall_micro_sent: 0.9729230769230769
dev_f-score_micro_sent: 0.9729230769230769
dev_label=O_precision_tok: 0.9944445741229196
dev_label=O_recall_tok: 0.996351645267663
dev_label=O_f-score_tok: 0.9953971962616822
dev_label=LOC_precision_tok: 0.9424564796905223
dev_label=LOC_recall_tok: 0.9307545367717287
dev_label=LOC_f-score_tok: 0.9365689572321
dev_label=MISC_precision_tok: 0.8581788879935536
dev_label=MISC_recall_tok: 0.8399053627760252
dev_label=MISC_f-score_tok: 0.8489438023116779
dev_label=ORG_precision_tok: 0.9180584551148225
dev_label=ORG_recall_tok: 0.8408221797323135
dev_label=ORG_f-score_tok: 0.8777445109780438
dev_label=PER_precision_tok: 0.941747572815534
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9632273079906905
dev_precision_macro_tok: 0.9309771939474704
dev_recall_macro_tok: 0.9187086947348874
dev_f-score_macro_tok: 0.9243763549548388
dev_precision_micro_tok: 0.982827771504225
dev_recall_micro_tok: 0.982827771504225
dev_f-score_micro_tok: 0.982827771504225
dev_time: 32.45390963554382
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9175    0.9488    0.9329       645
           1     0.9872    0.9789    0.9830      2605

   micro avg     0.9729    0.9729    0.9729      3250
   macro avg     0.9524    0.9639    0.9580      3250
weighted avg     0.9734    0.9729    0.9731      3250

F1-macro sent:  0.9579823043797131
F1-micro sent:  0.9729230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9944    0.9964    0.9954     42759
         LOC     0.9425    0.9308    0.9366      2094
        MISC     0.8582    0.8399    0.8489      1268
         ORG     0.9181    0.8408    0.8777      2092
         PER     0.9417    0.9857    0.9632      3149

   micro avg     0.9828    0.9828    0.9828     51362
   macro avg     0.9310    0.9187    0.9244     51362
weighted avg     0.9826    0.9828    0.9826     51362

F1-macro tok:  0.9243763549548388
F1-micro tok:  0.982827771504225
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 348601.61053466797
train_cost_avg: 24.827406205730927
train_count_sent: 14041.0
train_total_correct_sent: 13365.0
train_accuracy_sent: 0.9518552809628944
train_count_tok: 203621.0
train_total_correct_tok: 199263.0
train_accuracy_tok: 0.9785974924000963
train_label=0_precision_sent: 0.8859315589353612
train_label=0_recall_sent: 0.8810587830869715
train_label=0_f-score_sent: 0.8834884522578421
train_label=1_precision_sent: 0.9689630426982418
train_label=1_recall_sent: 0.9703557312252964
train_label=1_f-score_sent: 0.9696588868940753
train_precision_macro_sent: 0.9274473008168016
train_recall_macro_sent: 0.925707257156134
train_f-score_macro_sent: 0.9265736695759588
train_precision_micro_sent: 0.9518552809628944
train_recall_micro_sent: 0.9518552809628944
train_f-score_micro_sent: 0.9518552809628944
train_label=O_precision_tok: 0.9930031247609352
train_label=O_recall_tok: 0.9950819092099211
train_label=O_f-score_tok: 0.9940414301745747
train_label=LOC_precision_tok: 0.9095071695384986
train_label=LOC_recall_tok: 0.9097264071351091
train_label=LOC_f-score_tok: 0.9096167751265366
train_label=MISC_precision_tok: 0.8492672714584787
train_label=MISC_recall_tok: 0.7949052906596995
train_label=MISC_f-score_tok: 0.8211875843454791
train_label=ORG_precision_tok: 0.87420301588908
train_label=ORG_recall_tok: 0.8616458852867831
train_label=ORG_f-score_tok: 0.8678790314478046
train_label=PER_precision_tok: 0.9529842091176733
train_label=PER_recall_tok: 0.959920920201294
train_label=PER_f-score_tok: 0.9564399874647447
train_precision_macro_tok: 0.9157929581529333
train_recall_macro_tok: 0.9042560824985614
train_f-score_macro_tok: 0.9098329617118279
train_precision_micro_tok: 0.9785974924000963
train_recall_micro_tok: 0.9785974924000963
train_f-score_micro_tok: 0.9785974924000963
train_time: 329.92331433296204
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8859    0.8811    0.8835      2909
           1     0.9690    0.9704    0.9697     11132

   micro avg     0.9519    0.9519    0.9519     14041
   macro avg     0.9274    0.9257    0.9266     14041
weighted avg     0.9518    0.9519    0.9518     14041

F1-macro sent:  0.9265736695759588
F1-micro sent:  0.9518552809628944
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9930    0.9951    0.9940    169578
         LOC     0.9095    0.9097    0.9096      8297
        MISC     0.8493    0.7949    0.8212      4593
         ORG     0.8742    0.8616    0.8679     10025
         PER     0.9530    0.9599    0.9564     11128

   micro avg     0.9786    0.9786    0.9786    203621
   macro avg     0.9158    0.9043    0.9098    203621
weighted avg     0.9783    0.9786    0.9784    203621

F1-macro tok:  0.9098329617118279
F1-micro tok:  0.9785974924000963
**************************************************
dev_cost_sum: 91752.52503967285
dev_cost_avg: 28.231546166053185
dev_count_sent: 3250.0
dev_total_correct_sent: 3134.0
dev_accuracy_sent: 0.9643076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50524.0
dev_accuracy_tok: 0.9836844359643316
dev_label=0_precision_sent: 0.8638239339752407
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9154518950437318
dev_label=1_precision_sent: 0.9932619896948077
dev_label=1_recall_sent: 0.9619961612284069
dev_label=1_f-score_sent: 0.9773790951638065
dev_precision_macro_sent: 0.9285429618350243
dev_recall_macro_sent: 0.9678197860405601
dev_f-score_macro_sent: 0.9464154951037691
dev_precision_micro_sent: 0.9643076923076923
dev_recall_micro_sent: 0.9643076923076923
dev_f-score_micro_sent: 0.9643076923076923
dev_label=O_precision_tok: 0.993130428707822
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.995262654313785
dev_label=LOC_precision_tok: 0.9415148609779482
dev_label=LOC_recall_tok: 0.9379178605539638
dev_label=LOC_f-score_tok: 0.9397129186602872
dev_label=MISC_precision_tok: 0.8990342405618964
dev_label=MISC_recall_tok: 0.807570977917981
dev_label=MISC_f-score_tok: 0.8508516825924387
dev_label=ORG_precision_tok: 0.9223251028806584
dev_label=ORG_recall_tok: 0.857074569789675
dev_label=ORG_f-score_tok: 0.8885034687809713
dev_label=PER_precision_tok: 0.9523076923076923
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9673386466635412
dev_precision_macro_tok: 0.9416624650872034
dev_recall_macro_tok: 0.9165638325000549
dev_f-score_macro_tok: 0.9283338742022046
dev_precision_micro_tok: 0.9836844359643316
dev_recall_micro_tok: 0.9836844359643316
dev_f-score_micro_tok: 0.9836844359643316
dev_time: 32.541380643844604
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8638    0.9736    0.9155       645
           1     0.9933    0.9620    0.9774      2605

   micro avg     0.9643    0.9643    0.9643      3250
   macro avg     0.9285    0.9678    0.9464      3250
weighted avg     0.9676    0.9643    0.9651      3250

F1-macro sent:  0.9464154951037691
F1-micro sent:  0.9643076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9931    0.9974    0.9953     42759
         LOC     0.9415    0.9379    0.9397      2094
        MISC     0.8990    0.8076    0.8509      1268
         ORG     0.9223    0.8571    0.8885      2092
         PER     0.9523    0.9829    0.9673      3149

   micro avg     0.9837    0.9837    0.9837     51362
   macro avg     0.9417    0.9166    0.9283     51362
weighted avg     0.9833    0.9837    0.9834     51362

F1-macro tok:  0.9283338742022046
F1-micro tok:  0.9836844359643316
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 343363.9677429199
train_cost_avg: 24.45438129356313
train_count_sent: 14041.0
train_total_correct_sent: 13429.0
train_accuracy_sent: 0.9564133608717328
train_count_tok: 203621.0
train_total_correct_tok: 199634.0
train_accuracy_tok: 0.9804195048644295
train_label=0_precision_sent: 0.890248046211349
train_label=0_recall_sent: 0.9006531454107941
train_label=0_f-score_sent: 0.8954203691045797
train_label=1_precision_sent: 0.9739592719408903
train_label=1_recall_sent: 0.9709845490477902
train_label=1_f-score_sent: 0.9724696356275304
train_precision_macro_sent: 0.9321036590761196
train_recall_macro_sent: 0.9358188472292921
train_f-score_macro_sent: 0.933945002366055
train_precision_micro_sent: 0.9564133608717328
train_recall_micro_sent: 0.9564133608717328
train_f-score_micro_sent: 0.9564133608717328
train_label=O_precision_tok: 0.9935785000412012
train_label=O_recall_tok: 0.9954534196652868
train_label=O_f-score_tok: 0.9945150761762245
train_label=LOC_precision_tok: 0.9152766110644426
train_label=LOC_recall_tok: 0.9192479209352779
train_label=LOC_f-score_tok: 0.9172579675285629
train_label=MISC_precision_tok: 0.8574739281575898
train_label=MISC_recall_tok: 0.8055736991073372
train_label=MISC_f-score_tok: 0.8307139649753031
train_label=ORG_precision_tok: 0.8895774075579033
train_label=ORG_recall_tok: 0.8735162094763093
train_label=ORG_f-score_tok: 0.881473652423373
train_label=PER_precision_tok: 0.9565488380375746
train_label=PER_recall_tok: 0.9654025880661394
train_label=PER_f-score_tok: 0.960955320005367
train_precision_macro_tok: 0.9224910569717423
train_recall_macro_tok: 0.9118387674500701
train_f-score_macro_tok: 0.9169831962217663
train_precision_micro_tok: 0.9804195048644295
train_recall_micro_tok: 0.9804195048644295
train_f-score_micro_tok: 0.9804195048644295
train_time: 329.93302726745605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8902    0.9007    0.8954      2909
           1     0.9740    0.9710    0.9725     11132

   micro avg     0.9564    0.9564    0.9564     14041
   macro avg     0.9321    0.9358    0.9339     14041
weighted avg     0.9566    0.9564    0.9565     14041

F1-macro sent:  0.933945002366055
F1-micro sent:  0.9564133608717328
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9955    0.9945    169578
         LOC     0.9153    0.9192    0.9173      8297
        MISC     0.8575    0.8056    0.8307      4593
         ORG     0.8896    0.8735    0.8815     10025
         PER     0.9565    0.9654    0.9610     11128

   micro avg     0.9804    0.9804    0.9804    203621
   macro avg     0.9225    0.9118    0.9170    203621
weighted avg     0.9802    0.9804    0.9803    203621

F1-macro tok:  0.9169831962217663
F1-micro tok:  0.9804195048644295
**************************************************
dev_cost_sum: 90575.32082366943
dev_cost_avg: 27.86932948420598
dev_count_sent: 3250.0
dev_total_correct_sent: 3163.0
dev_accuracy_sent: 0.9732307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50617.0
dev_accuracy_tok: 0.985495113118648
dev_label=0_precision_sent: 0.8997134670487106
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9352196574832464
dev_label=1_precision_sent: 0.9933385579937304
dev_label=1_recall_sent: 0.9731285988483686
dev_label=1_f-score_sent: 0.9831297265852239
dev_precision_macro_sent: 0.9465260125212205
dev_recall_macro_sent: 0.9733860048505409
dev_f-score_macro_sent: 0.9591746920342352
dev_precision_micro_sent: 0.9732307692307692
dev_recall_micro_sent: 0.9732307692307692
dev_f-score_micro_sent: 0.9732307692307692
dev_label=O_precision_tok: 0.9950288234882255
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9960516786206575
dev_label=LOC_precision_tok: 0.9634634634634635
dev_label=LOC_recall_tok: 0.9192932187201528
dev_label=LOC_f-score_tok: 0.9408602150537634
dev_label=MISC_precision_tok: 0.897071129707113
dev_label=MISC_recall_tok: 0.8454258675078864
dev_label=MISC_f-score_tok: 0.8704831506293138
dev_label=ORG_precision_tok: 0.8901355773726041
dev_label=ORG_recall_tok: 0.9101338432122371
dev_label=ORG_f-score_tok: 0.9000236350744505
dev_label=PER_precision_tok: 0.9682689286836318
dev_label=PER_recall_tok: 0.9787234042553191
dev_label=PER_f-score_tok: 0.9734680985470625
dev_precision_macro_tok: 0.9427935845430074
dev_recall_macro_tok: 0.9301305945063728
dev_f-score_macro_tok: 0.9361773555850494
dev_precision_micro_tok: 0.985495113118648
dev_recall_micro_tok: 0.985495113118648
dev_f-score_micro_tok: 0.985495113118648
dev_time: 32.24273657798767
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8997    0.9736    0.9352       645
           1     0.9933    0.9731    0.9831      2605

   micro avg     0.9732    0.9732    0.9732      3250
   macro avg     0.9465    0.9734    0.9592      3250
weighted avg     0.9748    0.9732    0.9736      3250

F1-macro sent:  0.9591746920342352
F1-micro sent:  0.9732307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9950    0.9971    0.9961     42759
         LOC     0.9635    0.9193    0.9409      2094
        MISC     0.8971    0.8454    0.8705      1268
         ORG     0.8901    0.9101    0.9000      2092
         PER     0.9683    0.9787    0.9735      3149

   micro avg     0.9855    0.9855    0.9855     51362
   macro avg     0.9428    0.9301    0.9362     51362
weighted avg     0.9854    0.9855    0.9854     51362

F1-macro tok:  0.9361773555850494
F1-micro tok:  0.985495113118648
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 338551.411529541
train_cost_avg: 24.11163104690129
train_count_sent: 14041.0
train_total_correct_sent: 13517.0
train_accuracy_sent: 0.9626807207463856
train_count_tok: 203621.0
train_total_correct_tok: 200009.0
train_accuracy_tok: 0.9822611616680008
train_label=0_precision_sent: 0.9107819497071995
train_label=0_recall_sent: 0.908903403231351
train_label=0_f-score_sent: 0.9098417068134893
train_label=1_precision_sent: 0.9762075776620578
train_label=1_recall_sent: 0.9767337405677327
train_label=1_f-score_sent: 0.976470588235294
train_precision_macro_sent: 0.9434947636846287
train_recall_macro_sent: 0.9428185718995419
train_f-score_macro_sent: 0.9431561475243917
train_precision_micro_sent: 0.9626807207463856
train_recall_micro_sent: 0.9626807207463856
train_f-score_micro_sent: 0.9626807207463856
train_label=O_precision_tok: 0.9944292646158195
train_label=O_recall_tok: 0.9958249301206524
train_label=O_f-score_tok: 0.9951266080131057
train_label=LOC_precision_tok: 0.9272067714631197
train_label=LOC_recall_tok: 0.9241894660720742
train_label=LOC_f-score_tok: 0.9256956600470815
train_label=MISC_precision_tok: 0.8653061224489796
train_label=MISC_recall_tok: 0.8308295231874592
train_label=MISC_f-score_tok: 0.8477174275241586
train_label=ORG_precision_tok: 0.8968302039168181
train_label=ORG_recall_tok: 0.8861845386533665
train_label=ORG_f-score_tok: 0.8914755907882194
train_label=PER_precision_tok: 0.9600677422230145
train_label=PER_recall_tok: 0.9679187634795111
train_label=PER_f-score_tok: 0.963977267642189
train_precision_macro_tok: 0.9287680209335504
train_recall_macro_tok: 0.9209894443026126
train_f-score_macro_tok: 0.9247985108029508
train_precision_micro_tok: 0.9822611616680008
train_recall_micro_tok: 0.9822611616680008
train_f-score_micro_tok: 0.9822611616680008
train_time: 331.4057641029358
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9108    0.9089    0.9098      2909
           1     0.9762    0.9767    0.9765     11132

   micro avg     0.9627    0.9627    0.9627     14041
   macro avg     0.9435    0.9428    0.9432     14041
weighted avg     0.9627    0.9627    0.9627     14041

F1-macro sent:  0.9431561475243917
F1-micro sent:  0.9626807207463856
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9944    0.9958    0.9951    169578
         LOC     0.9272    0.9242    0.9257      8297
        MISC     0.8653    0.8308    0.8477      4593
         ORG     0.8968    0.8862    0.8915     10025
         PER     0.9601    0.9679    0.9640     11128

   micro avg     0.9823    0.9823    0.9823    203621
   macro avg     0.9288    0.9210    0.9248    203621
weighted avg     0.9821    0.9823    0.9822    203621

F1-macro tok:  0.9247985108029508
F1-micro tok:  0.9822611616680008
**************************************************
dev_cost_sum: 89714.03482055664
dev_cost_avg: 27.60431840632512
dev_count_sent: 3250.0
dev_total_correct_sent: 3147.0
dev_accuracy_sent: 0.9683076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50636.0
dev_accuracy_tok: 0.9858650364082395
dev_label=0_precision_sent: 0.9822064056939501
dev_label=0_recall_sent: 0.8558139534883721
dev_label=0_f-score_sent: 0.9146644573322287
dev_label=1_precision_sent: 0.9654017857142857
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9805403362932175
dev_precision_macro_sent: 0.9738040957041179
dev_recall_macro_sent: 0.9259875909476409
dev_f-score_macro_sent: 0.9476023968127231
dev_precision_micro_sent: 0.9683076923076923
dev_recall_micro_sent: 0.9683076923076923
dev_f-score_micro_sent: 0.9683076923076923
dev_label=O_precision_tok: 0.9963972394432097
dev_label=O_recall_tok: 0.9960710025959447
dev_label=O_f-score_tok: 0.9962340943113772
dev_label=LOC_precision_tok: 0.9408172851103804
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9486147288657353
dev_label=MISC_precision_tok: 0.8935993349958438
dev_label=MISC_recall_tok: 0.8477917981072555
dev_label=MISC_f-score_tok: 0.8700930797248078
dev_label=ORG_precision_tok: 0.9154447702834799
dev_label=ORG_recall_tok: 0.8953154875717018
dev_label=ORG_f-score_tok: 0.9052682455292411
dev_label=PER_precision_tok: 0.9552330966347639
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9686912961803382
dev_precision_macro_tok: 0.9402983452935356
dev_recall_macro_tok: 0.9356509856968414
dev_f-score_macro_tok: 0.9377802889222998
dev_precision_micro_tok: 0.9858650364082395
dev_recall_micro_tok: 0.9858650364082395
dev_f-score_micro_tok: 0.9858650364082395
dev_time: 32.12290573120117
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9822    0.8558    0.9147       645
           1     0.9654    0.9962    0.9805      2605

   micro avg     0.9683    0.9683    0.9683      3250
   macro avg     0.9738    0.9260    0.9476      3250
weighted avg     0.9687    0.9683    0.9675      3250

F1-macro sent:  0.9476023968127231
F1-micro sent:  0.9683076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9961    0.9962     42759
         LOC     0.9408    0.9565    0.9486      2094
        MISC     0.8936    0.8478    0.8701      1268
         ORG     0.9154    0.8953    0.9053      2092
         PER     0.9552    0.9825    0.9687      3149

   micro avg     0.9859    0.9859    0.9859     51362
   macro avg     0.9403    0.9357    0.9378     51362
weighted avg     0.9858    0.9859    0.9858     51362

F1-macro tok:  0.9377802889222998
F1-micro tok:  0.9858650364082395
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 334344.5425415039
train_cost_avg: 23.812017843565553
train_count_sent: 14041.0
train_total_correct_sent: 13528.0
train_accuracy_sent: 0.9634641407307172
train_count_tok: 203621.0
train_total_correct_tok: 200270.0
train_accuracy_tok: 0.9835429548032865
train_label=0_precision_sent: 0.9102739726027397
train_label=0_recall_sent: 0.9137160536266759
train_label=0_f-score_sent: 0.9119917653113742
train_label=1_precision_sent: 0.9774300872223721
train_label=1_recall_sent: 0.9764642472152354
train_label=1_f-score_sent: 0.976946928504022
train_precision_macro_sent: 0.9438520299125559
train_recall_macro_sent: 0.9450901504209557
train_f-score_macro_sent: 0.9444693469076981
train_precision_micro_sent: 0.9634641407307172
train_recall_micro_sent: 0.9634641407307172
train_f-score_micro_sent: 0.9634641407307172
train_label=O_precision_tok: 0.9948041237113402
train_label=O_recall_tok: 0.9958131361379424
train_label=O_f-score_tok: 0.9953083741984157
train_label=LOC_precision_tok: 0.9290345821325648
train_label=LOC_recall_tok: 0.9325057249608292
train_label=LOC_f-score_tok: 0.930766917293233
train_label=MISC_precision_tok: 0.8798098687188773
train_label=MISC_recall_tok: 0.8462878293054649
train_label=MISC_f-score_tok: 0.8627233381422708
train_label=ORG_precision_tok: 0.9042821158690176
train_label=ORG_recall_tok: 0.8952618453865336
train_label=ORG_f-score_tok: 0.8997493734335839
train_label=PER_precision_tok: 0.9645535714285715
train_label=PER_recall_tok: 0.9707943925233645
train_label=PER_f-score_tok: 0.967663919742028
train_precision_macro_tok: 0.9344968523720742
train_recall_macro_tok: 0.928132585662827
train_f-score_macro_tok: 0.9312423845619062
train_precision_micro_tok: 0.9835429548032865
train_recall_micro_tok: 0.9835429548032865
train_f-score_micro_tok: 0.9835429548032865
train_time: 331.49729657173157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9103    0.9137    0.9120      2909
           1     0.9774    0.9765    0.9769     11132

   micro avg     0.9635    0.9635    0.9635     14041
   macro avg     0.9439    0.9451    0.9445     14041
weighted avg     0.9635    0.9635    0.9635     14041

F1-macro sent:  0.9444693469076981
F1-micro sent:  0.9634641407307172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9948    0.9958    0.9953    169578
         LOC     0.9290    0.9325    0.9308      8297
        MISC     0.8798    0.8463    0.8627      4593
         ORG     0.9043    0.8953    0.8997     10025
         PER     0.9646    0.9708    0.9677     11128

   micro avg     0.9835    0.9835    0.9835    203621
   macro avg     0.9345    0.9281    0.9312    203621
weighted avg     0.9834    0.9835    0.9835    203621

F1-macro tok:  0.9312423845619062
F1-micro tok:  0.9835429548032865
**************************************************
dev_cost_sum: 88795.69104003906
dev_cost_avg: 27.321751089242788
dev_count_sent: 3250.0
dev_total_correct_sent: 3191.0
dev_accuracy_sent: 0.9818461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50697.0
dev_accuracy_tok: 0.9870526848642965
dev_label=0_precision_sent: 0.9535603715170279
dev_label=0_recall_sent: 0.9550387596899225
dev_label=0_f-score_sent: 0.95429899302866
dev_label=1_precision_sent: 0.988863287250384
dev_label=1_recall_sent: 0.9884836852207294
dev_label=1_f-score_sent: 0.9886734497984259
dev_precision_macro_sent: 0.971211829383706
dev_recall_macro_sent: 0.9717612224553259
dev_f-score_macro_sent: 0.9714862214135429
dev_precision_micro_sent: 0.9818461538461538
dev_recall_micro_sent: 0.9818461538461538
dev_f-score_micro_sent: 0.9818461538461538
dev_label=O_precision_tok: 0.9957960623116986
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9964709731700476
dev_label=LOC_precision_tok: 0.9531996179560649
dev_label=LOC_recall_tok: 0.9531996179560649
dev_label=LOC_f-score_tok: 0.9531996179560649
dev_label=MISC_precision_tok: 0.8938411669367909
dev_label=MISC_recall_tok: 0.8698738170347003
dev_label=MISC_f-score_tok: 0.8816946442845724
dev_label=ORG_precision_tok: 0.9266600594648167
dev_label=ORG_recall_tok: 0.8938814531548758
dev_label=ORG_f-score_tok: 0.9099756690997567
dev_label=PER_precision_tok: 0.9662394498280713
dev_label=PER_recall_tok: 0.9815814544299778
dev_label=PER_f-score_tok: 0.9738500315059863
dev_precision_macro_tok: 0.9471472712994885
dev_recall_macro_tok: 0.9391366284159635
dev_f-score_macro_tok: 0.9430381872032856
dev_precision_micro_tok: 0.9870526848642965
dev_recall_micro_tok: 0.9870526848642965
dev_f-score_micro_tok: 0.9870526848642965
dev_time: 31.968226671218872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9536    0.9550    0.9543       645
           1     0.9889    0.9885    0.9887      2605

   micro avg     0.9818    0.9818    0.9818      3250
   macro avg     0.9712    0.9718    0.9715      3250
weighted avg     0.9819    0.9818    0.9819      3250

F1-macro sent:  0.9714862214135429
F1-micro sent:  0.9818461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9971    0.9965     42759
         LOC     0.9532    0.9532    0.9532      2094
        MISC     0.8938    0.8699    0.8817      1268
         ORG     0.9267    0.8939    0.9100      2092
         PER     0.9662    0.9816    0.9739      3149

   micro avg     0.9871    0.9871    0.9871     51362
   macro avg     0.9471    0.9391    0.9430     51362
weighted avg     0.9869    0.9871    0.9870     51362

F1-macro tok:  0.9430381872032856
F1-micro tok:  0.9870526848642965
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 330844.44677734375
train_cost_avg: 23.562741028227602
train_count_sent: 14041.0
train_total_correct_sent: 13614.0
train_accuracy_sent: 0.9695890606082188
train_count_tok: 203621.0
train_total_correct_tok: 200444.0
train_accuracy_tok: 0.9843974835601436
train_label=0_precision_sent: 0.9276361130254996
train_label=0_recall_sent: 0.9254039188724648
train_label=0_f-score_sent: 0.9265186714851145
train_label=1_precision_sent: 0.9805188975671065
train_label=1_recall_sent: 0.9811354653251887
train_label=1_f-score_sent: 0.9808270845494141
train_precision_macro_sent: 0.9540775052963031
train_recall_macro_sent: 0.9532696920988267
train_f-score_macro_sent: 0.9536728780172643
train_precision_micro_sent: 0.9695890606082188
train_recall_micro_sent: 0.9695890606082188
train_f-score_micro_sent: 0.9695890606082188
train_label=O_precision_tok: 0.9951578414104701
train_label=O_recall_tok: 0.9962200285414382
train_label=O_f-score_tok: 0.9956886516943335
train_label=LOC_precision_tok: 0.9344025081393946
train_label=LOC_recall_tok: 0.9339520308545257
train_label=LOC_f-score_tok: 0.9341772151898734
train_label=MISC_precision_tok: 0.8843275119074621
train_label=MISC_recall_tok: 0.8489005007620292
train_label=MISC_f-score_tok: 0.8662519440124418
train_label=ORG_precision_tok: 0.9087528891568687
train_label=ORG_recall_tok: 0.9020448877805486
train_label=ORG_f-score_tok: 0.9053864637565079
train_label=PER_precision_tok: 0.9649388883932554
train_label=PER_recall_tok: 0.9719626168224299
train_label=PER_f-score_tok: 0.968438017638895
train_precision_macro_tok: 0.9375159278014902
train_recall_macro_tok: 0.9306160129521943
train_f-score_macro_tok: 0.9339884584584104
train_precision_micro_tok: 0.9843974835601436
train_recall_micro_tok: 0.9843974835601436
train_f-score_micro_tok: 0.9843974835601436
train_time: 330.9638695716858
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9276    0.9254    0.9265      2909
           1     0.9805    0.9811    0.9808     11132

   micro avg     0.9696    0.9696    0.9696     14041
   macro avg     0.9541    0.9533    0.9537     14041
weighted avg     0.9696    0.9696    0.9696     14041

F1-macro sent:  0.9536728780172643
F1-micro sent:  0.9695890606082188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9962    0.9957    169578
         LOC     0.9344    0.9340    0.9342      8297
        MISC     0.8843    0.8489    0.8663      4593
         ORG     0.9088    0.9020    0.9054     10025
         PER     0.9649    0.9720    0.9684     11128

   micro avg     0.9844    0.9844    0.9844    203621
   macro avg     0.9375    0.9306    0.9340    203621
weighted avg     0.9843    0.9844    0.9843    203621

F1-macro tok:  0.9339884584584104
F1-micro tok:  0.9843974835601436
**************************************************
dev_cost_sum: 88107.20553588867
dev_cost_avg: 27.109909395658054
dev_count_sent: 3250.0
dev_total_correct_sent: 3200.0
dev_accuracy_sent: 0.9846153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50698.0
dev_accuracy_tok: 0.9870721545111172
dev_label=0_precision_sent: 0.9869067103109657
dev_label=0_recall_sent: 0.9348837209302325
dev_label=0_f-score_sent: 0.9601910828025477
dev_label=1_precision_sent: 0.9840848806366048
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.990465293668955
dev_precision_macro_sent: 0.9854957954737853
dev_recall_macro_sent: 0.9659063518278802
dev_f-score_macro_sent: 0.9753281882357514
dev_precision_micro_sent: 0.9846153846153847
dev_recall_micro_sent: 0.9846153846153847
dev_f-score_micro_sent: 0.9846153846153847
dev_label=O_precision_tok: 0.9960956678278353
dev_label=O_recall_tok: 0.9964218059355925
dev_label=O_f-score_tok: 0.9962587101903381
dev_label=LOC_precision_tok: 0.9488636363636364
dev_label=LOC_recall_tok: 0.9570200573065902
dev_label=LOC_f-score_tok: 0.9529243937232524
dev_label=MISC_precision_tok: 0.8755905511811024
dev_label=MISC_recall_tok: 0.8769716088328076
dev_label=MISC_f-score_tok: 0.876280535855004
dev_label=ORG_precision_tok: 0.9305418719211823
dev_label=ORG_recall_tok: 0.902963671128107
dev_label=ORG_f-score_tok: 0.9165453663270258
dev_label=PER_precision_tok: 0.9716713881019831
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9759721783117293
dev_precision_macro_tok: 0.9445526230791479
dev_recall_macro_tok: 0.9427376706222009
dev_f-score_macro_tok: 0.94359623688147
dev_precision_micro_tok: 0.9870721545111172
dev_recall_micro_tok: 0.9870721545111172
dev_f-score_micro_tok: 0.9870721545111172
dev_time: 31.968160390853882
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9869    0.9349    0.9602       645
           1     0.9841    0.9969    0.9905      2605

   micro avg     0.9846    0.9846    0.9846      3250
   macro avg     0.9855    0.9659    0.9753      3250
weighted avg     0.9846    0.9846    0.9845      3250

F1-macro sent:  0.9753281882357514
F1-micro sent:  0.9846153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9964    0.9963     42759
         LOC     0.9489    0.9570    0.9529      2094
        MISC     0.8756    0.8770    0.8763      1268
         ORG     0.9305    0.9030    0.9165      2092
         PER     0.9717    0.9803    0.9760      3149

   micro avg     0.9871    0.9871    0.9871     51362
   macro avg     0.9446    0.9427    0.9436     51362
weighted avg     0.9870    0.9871    0.9870     51362

F1-macro tok:  0.94359623688147
F1-micro tok:  0.9870721545111172
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 327646.85079956055
train_cost_avg: 23.335008247244538
train_count_sent: 14041.0
train_total_correct_sent: 13644.0
train_accuracy_sent: 0.9717256605654868
train_count_tok: 203621.0
train_total_correct_tok: 200690.0
train_accuracy_tok: 0.9856056104232864
train_label=0_precision_sent: 0.929254955570745
train_label=0_recall_sent: 0.9346854589205913
train_label=0_f-score_sent: 0.9319622964867181
train_label=1_precision_sent: 0.9829059829059829
train_label=1_recall_sent: 0.981404958677686
train_label=1_f-score_sent: 0.9821548972895222
train_precision_macro_sent: 0.956080469238364
train_recall_macro_sent: 0.9580452087991387
train_f-score_macro_sent: 0.9570585968881202
train_precision_micro_sent: 0.9717256605654868
train_recall_micro_sent: 0.9717256605654868
train_f-score_micro_sent: 0.9717256605654868
train_label=O_precision_tok: 0.9953520977414376
train_label=O_recall_tok: 0.9963851442993784
train_label=O_f-score_tok: 0.995868353117301
train_label=LOC_precision_tok: 0.9401925391095066
train_label=LOC_recall_tok: 0.9416656622875739
train_label=LOC_f-score_tok: 0.9409285241163364
train_label=MISC_precision_tok: 0.8902164111812444
train_label=MISC_recall_tok: 0.8597866318310472
train_label=MISC_f-score_tok: 0.8747369586886699
train_label=ORG_precision_tok: 0.9170604202272041
train_label=ORG_recall_tok: 0.909925187032419
train_label=ORG_f-score_tok: 0.913478870418586
train_label=PER_precision_tok: 0.9701986754966887
train_label=PER_recall_tok: 0.9742092020129404
train_label=PER_f-score_tok: 0.9721998027082773
train_precision_macro_tok: 0.9426040287512162
train_recall_macro_tok: 0.9363943654926719
train_f-score_macro_tok: 0.939442501809834
train_precision_micro_tok: 0.9856056104232864
train_recall_micro_tok: 0.9856056104232864
train_f-score_micro_tok: 0.9856056104232864
train_time: 330.1993799209595
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9293    0.9347    0.9320      2909
           1     0.9829    0.9814    0.9822     11132

   micro avg     0.9717    0.9717    0.9717     14041
   macro avg     0.9561    0.9580    0.9571     14041
weighted avg     0.9718    0.9717    0.9718     14041

F1-macro sent:  0.9570585968881202
F1-micro sent:  0.9717256605654868
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9964    0.9959    169578
         LOC     0.9402    0.9417    0.9409      8297
        MISC     0.8902    0.8598    0.8747      4593
         ORG     0.9171    0.9099    0.9135     10025
         PER     0.9702    0.9742    0.9722     11128

   micro avg     0.9856    0.9856    0.9856    203621
   macro avg     0.9426    0.9364    0.9394    203621
weighted avg     0.9855    0.9856    0.9855    203621

F1-macro tok:  0.939442501809834
F1-micro tok:  0.9856056104232864
**************************************************
dev_cost_sum: 87558.28500366211
dev_cost_avg: 26.941010770357572
dev_count_sent: 3250.0
dev_total_correct_sent: 3200.0
dev_accuracy_sent: 0.9846153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50710.0
dev_accuracy_tok: 0.9873057902729645
dev_label=0_precision_sent: 0.9598145285935085
dev_label=0_recall_sent: 0.9627906976744186
dev_label=0_f-score_sent: 0.9613003095975232
dev_label=1_precision_sent: 0.9907798693814829
dev_label=1_recall_sent: 0.9900191938579654
dev_label=1_f-score_sent: 0.9903993855606759
dev_precision_macro_sent: 0.9752971989874957
dev_recall_macro_sent: 0.9764049457661921
dev_f-score_macro_sent: 0.9758498475790995
dev_precision_micro_sent: 0.9846153846153847
dev_recall_micro_sent: 0.9846153846153847
dev_f-score_micro_sent: 0.9846153846153847
dev_label=O_precision_tok: 0.9961204982588984
dev_label=O_recall_tok: 0.99681938305386
dev_label=O_f-score_tok: 0.9964698181138075
dev_label=LOC_precision_tok: 0.9535218016291327
dev_label=LOC_recall_tok: 0.9503342884431709
dev_label=LOC_f-score_tok: 0.9519253767041377
dev_label=MISC_precision_tok: 0.8940129449838188
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8825878594249201
dev_label=ORG_precision_tok: 0.9196342637151107
dev_label=ORG_recall_tok: 0.9134799235181644
dev_label=ORG_f-score_tok: 0.916546762589928
dev_label=PER_precision_tok: 0.9713114754098361
dev_label=PER_recall_tok: 0.9784058431248015
dev_label=PER_f-score_tok: 0.9748457522543902
dev_precision_macro_tok: 0.9469201967993592
dev_recall_macro_tok: 0.9420981084481888
dev_f-score_macro_tok: 0.9444751138174367
dev_precision_micro_tok: 0.9873057902729645
dev_recall_micro_tok: 0.9873057902729645
dev_f-score_micro_tok: 0.9873057902729645
dev_time: 31.825568199157715
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9598    0.9628    0.9613       645
           1     0.9908    0.9900    0.9904      2605

   micro avg     0.9846    0.9846    0.9846      3250
   macro avg     0.9753    0.9764    0.9758      3250
weighted avg     0.9846    0.9846    0.9846      3250

F1-macro sent:  0.9758498475790995
F1-micro sent:  0.9846153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9968    0.9965     42759
         LOC     0.9535    0.9503    0.9519      2094
        MISC     0.8940    0.8715    0.8826      1268
         ORG     0.9196    0.9135    0.9165      2092
         PER     0.9713    0.9784    0.9748      3149

   micro avg     0.9873    0.9873    0.9873     51362
   macro avg     0.9469    0.9421    0.9445     51362
weighted avg     0.9872    0.9873    0.9873     51362

F1-macro tok:  0.9444751138174367
F1-micro tok:  0.9873057902729645
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 324567.9138183594
train_cost_avg: 23.11572635982903
train_count_sent: 14041.0
train_total_correct_sent: 13656.0
train_accuracy_sent: 0.972580300548394
train_count_tok: 203621.0
train_total_correct_tok: 200876.0
train_accuracy_tok: 0.9865190721978578
train_label=0_precision_sent: 0.9336769759450172
train_label=0_recall_sent: 0.9339979374355448
train_label=0_f-score_sent: 0.9338374291115312
train_label=1_precision_sent: 0.9827508759320815
train_label=1_recall_sent: 0.9826625943226733
train_label=1_f-score_sent: 0.9827067331446794
train_precision_macro_sent: 0.9582139259385494
train_recall_macro_sent: 0.9583302658791091
train_f-score_macro_sent: 0.9582720811281054
train_precision_micro_sent: 0.972580300548394
train_recall_micro_sent: 0.972580300548394
train_f-score_micro_sent: 0.972580300548394
train_label=O_precision_tok: 0.9957816596459187
train_label=O_recall_tok: 0.996703581832549
train_label=O_f-score_tok: 0.9962424074527059
train_label=LOC_precision_tok: 0.9423888152344221
train_label=LOC_recall_tok: 0.9423888152344221
train_label=LOC_f-score_tok: 0.9423888152344221
train_label=MISC_precision_tok: 0.9016208914903197
train_label=MISC_recall_tok: 0.8719790986283474
train_label=MISC_f-score_tok: 0.8865522966242392
train_label=ORG_precision_tok: 0.9218655967903712
train_label=ORG_recall_tok: 0.9168079800498753
train_label=ORG_f-score_tok: 0.9193298324581145
train_label=PER_precision_tok: 0.9700277355283171
train_label=PER_recall_tok: 0.9742990654205608
train_label=PER_f-score_tok: 0.9721587088096839
train_precision_macro_tok: 0.9463369397378697
train_recall_macro_tok: 0.9404357082331509
train_f-score_macro_tok: 0.9433344121158331
train_precision_micro_tok: 0.9865190721978578
train_recall_micro_tok: 0.9865190721978578
train_f-score_micro_tok: 0.9865190721978578
train_time: 252.46010088920593
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9337    0.9340    0.9338      2909
           1     0.9828    0.9827    0.9827     11132

   micro avg     0.9726    0.9726    0.9726     14041
   macro avg     0.9582    0.9583    0.9583     14041
weighted avg     0.9726    0.9726    0.9726     14041

F1-macro sent:  0.9582720811281054
F1-micro sent:  0.972580300548394
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9967    0.9962    169578
         LOC     0.9424    0.9424    0.9424      8297
        MISC     0.9016    0.8720    0.8866      4593
         ORG     0.9219    0.9168    0.9193     10025
         PER     0.9700    0.9743    0.9722     11128

   micro avg     0.9865    0.9865    0.9865    203621
   macro avg     0.9463    0.9404    0.9433    203621
weighted avg     0.9864    0.9865    0.9865    203621

F1-macro tok:  0.9433344121158331
F1-micro tok:  0.9865190721978578
**************************************************
dev_cost_sum: 87091.92845153809
dev_cost_avg: 26.797516446627103
dev_count_sent: 3250.0
dev_total_correct_sent: 3172.0
dev_accuracy_sent: 0.976
dev_count_tok: 51362.0
dev_total_correct_tok: 50722.0
dev_accuracy_tok: 0.9875394260348117
dev_label=0_precision_sent: 0.902127659574468
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9422222222222222
dev_label=1_precision_sent: 0.9964636542239685
dev_label=1_recall_sent: 0.9735124760076775
dev_label=1_f-score_sent: 0.9848543689320388
dev_precision_macro_sent: 0.9492956568992184
dev_recall_macro_sent: 0.9797794938177923
dev_f-score_macro_sent: 0.9635382955771306
dev_precision_micro_sent: 0.976
dev_recall_micro_sent: 0.976
dev_f-score_micro_sent: 0.976
dev_label=O_precision_tok: 0.9949635087555669
dev_label=O_recall_tok: 0.9979419537407329
dev_label=O_f-score_tok: 0.9964505055694369
dev_label=LOC_precision_tok: 0.9421371908539431
dev_label=LOC_recall_tok: 0.9641833810888252
dev_label=LOC_f-score_tok: 0.9530328062308236
dev_label=MISC_precision_tok: 0.9303525365434222
dev_label=MISC_recall_tok: 0.8533123028391167
dev_label=MISC_f-score_tok: 0.8901686548745372
dev_label=ORG_precision_tok: 0.9337649402390438
dev_label=ORG_recall_tok: 0.8962715105162524
dev_label=ORG_f-score_tok: 0.9146341463414634
dev_label=PER_precision_tok: 0.9727934198038596
dev_label=PER_recall_tok: 0.9765004763416958
dev_label=PER_f-score_tok: 0.9746434231378763
dev_precision_macro_tok: 0.9548023192391671
dev_recall_macro_tok: 0.9376419249053246
dev_f-score_macro_tok: 0.9457859072308276
dev_precision_micro_tok: 0.9875394260348117
dev_recall_micro_tok: 0.9875394260348117
dev_f-score_micro_tok: 0.9875394260348117
dev_time: 24.554972648620605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9021    0.9860    0.9422       645
           1     0.9965    0.9735    0.9849      2605

   micro avg     0.9760    0.9760    0.9760      3250
   macro avg     0.9493    0.9798    0.9635      3250
weighted avg     0.9777    0.9760    0.9764      3250

F1-macro sent:  0.9635382955771306
F1-micro sent:  0.976
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9950    0.9979    0.9965     42759
         LOC     0.9421    0.9642    0.9530      2094
        MISC     0.9304    0.8533    0.8902      1268
         ORG     0.9338    0.8963    0.9146      2092
         PER     0.9728    0.9765    0.9746      3149

   micro avg     0.9875    0.9875    0.9875     51362
   macro avg     0.9548    0.9376    0.9458     51362
weighted avg     0.9874    0.9875    0.9874     51362

F1-macro tok:  0.9457859072308276
F1-micro tok:  0.9875394260348117
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 321962.7397155762
train_cost_avg: 22.930185863939617
train_count_sent: 14041.0
train_total_correct_sent: 13693.0
train_accuracy_sent: 0.9752154404956912
train_count_tok: 203621.0
train_total_correct_tok: 201006.0
train_accuracy_tok: 0.9871575132230959
train_label=0_precision_sent: 0.9410954185325525
train_label=0_recall_sent: 0.939154348573393
train_label=0_f-score_sent: 0.9401238816242258
train_label=1_precision_sent: 0.9841084575327707
train_label=1_recall_sent: 0.9846388789076536
train_label=1_f-score_sent: 0.984373596766951
train_precision_macro_sent: 0.9626019380326616
train_recall_macro_sent: 0.9618966137405233
train_f-score_macro_sent: 0.9622487391955884
train_precision_micro_sent: 0.9752154404956912
train_recall_micro_sent: 0.9752154404956912
train_f-score_micro_sent: 0.9752154404956912
train_label=O_precision_tok: 0.9960044316628165
train_label=O_recall_tok: 0.9966505089103539
train_label=O_f-score_tok: 0.9963273655479771
train_label=LOC_precision_tok: 0.943307655272027
train_label=LOC_recall_tok: 0.9445582740749668
train_label=LOC_f-score_tok: 0.9439325504366155
train_label=MISC_precision_tok: 0.905338716913414
train_label=MISC_recall_tok: 0.8787284998911387
train_label=MISC_f-score_tok: 0.8918351563363164
train_label=ORG_precision_tok: 0.9277265437048917
train_label=ORG_recall_tok: 0.9231920199501247
train_label=ORG_f-score_tok: 0.9254537273136343
train_label=PER_precision_tok: 0.9711375212224108
train_label=PER_recall_tok: 0.9766355140186916
train_label=PER_f-score_tok: 0.9738787580088714
train_precision_macro_tok: 0.948702973755112
train_recall_macro_tok: 0.9439529633690551
train_f-score_macro_tok: 0.946285511528683
train_precision_micro_tok: 0.9871575132230959
train_recall_micro_tok: 0.9871575132230959
train_f-score_micro_tok: 0.9871575132230959
train_time: 242.12460064888
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9411    0.9392    0.9401      2909
           1     0.9841    0.9846    0.9844     11132

   micro avg     0.9752    0.9752    0.9752     14041
   macro avg     0.9626    0.9619    0.9622     14041
weighted avg     0.9752    0.9752    0.9752     14041

F1-macro sent:  0.9622487391955884
F1-micro sent:  0.9752154404956912
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9967    0.9963    169578
         LOC     0.9433    0.9446    0.9439      8297
        MISC     0.9053    0.8787    0.8918      4593
         ORG     0.9277    0.9232    0.9255     10025
         PER     0.9711    0.9766    0.9739     11128

   micro avg     0.9872    0.9872    0.9872    203621
   macro avg     0.9487    0.9440    0.9463    203621
weighted avg     0.9871    0.9872    0.9871    203621

F1-macro tok:  0.946285511528683
F1-micro tok:  0.9871575132230959
**************************************************
dev_cost_sum: 86519.56574249268
dev_cost_avg: 26.6214048438439
dev_count_sent: 3250.0
dev_total_correct_sent: 3202.0
dev_accuracy_sent: 0.9852307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50688.0
dev_accuracy_tok: 0.986877458042911
dev_label=0_precision_sent: 0.9776
dev_label=0_recall_sent: 0.9472868217054263
dev_label=0_f-score_sent: 0.9622047244094488
dev_label=1_precision_sent: 0.9870476190476191
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9908221797323137
dev_precision_macro_sent: 0.9823238095238096
dev_recall_macro_sent: 0.9709562707375501
dev_f-score_macro_sent: 0.9765134520708812
dev_precision_micro_sent: 0.9852307692307692
dev_recall_micro_sent: 0.9852307692307692
dev_f-score_micro_sent: 0.9852307692307692
dev_label=O_precision_tok: 0.9966771189217017
dev_label=O_recall_tok: 0.9960943894852545
dev_label=O_f-score_tok: 0.9963856690021405
dev_label=LOC_precision_tok: 0.9353348729792148
dev_label=LOC_recall_tok: 0.9670487106017192
dev_label=LOC_f-score_tok: 0.9509274477576896
dev_label=MISC_precision_tok: 0.8623853211009175
dev_label=MISC_recall_tok: 0.889589905362776
dev_label=MISC_f-score_tok: 0.875776397515528
dev_label=ORG_precision_tok: 0.9424350483953133
dev_label=ORG_recall_tok: 0.884321223709369
dev_label=ORG_f-score_tok: 0.9124537607891493
dev_label=PER_precision_tok: 0.9689849624060151
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9755559060085159
dev_precision_macro_tok: 0.9411634647606325
dev_recall_macro_tok: 0.9438541611700264
dev_f-score_macro_tok: 0.9422198362146046
dev_precision_micro_tok: 0.986877458042911
dev_recall_micro_tok: 0.986877458042911
dev_f-score_micro_tok: 0.986877458042911
dev_time: 24.697741508483887
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9776    0.9473    0.9622       645
           1     0.9870    0.9946    0.9908      2605

   micro avg     0.9852    0.9852    0.9852      3250
   macro avg     0.9823    0.9710    0.9765      3250
weighted avg     0.9852    0.9852    0.9851      3250

F1-macro sent:  0.9765134520708812
F1-micro sent:  0.9852307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9961    0.9964     42759
         LOC     0.9353    0.9670    0.9509      2094
        MISC     0.8624    0.8896    0.8758      1268
         ORG     0.9424    0.8843    0.9125      2092
         PER     0.9690    0.9822    0.9756      3149

   micro avg     0.9869    0.9869    0.9869     51362
   macro avg     0.9412    0.9439    0.9422     51362
weighted avg     0.9870    0.9869    0.9869     51362

F1-macro tok:  0.9422198362146046
F1-micro tok:  0.986877458042911
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
2019-03-29 10:42:19.111038: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.00G (2147483648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:42:19.120459: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.80G (1932735232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:42:19.129921: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.62G (1739461632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:42:19.139991: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.46G (1565515520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:42:19.150832: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.31G (1408964096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:42:19.160943: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.18G (1268067840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
train_cost_sum: 319325.9108276367
train_cost_avg: 22.742390914296468
train_count_sent: 14041.0
train_total_correct_sent: 13707.0
train_accuracy_sent: 0.9762125204757496
train_count_tok: 203621.0
train_total_correct_tok: 201094.0
train_accuracy_tok: 0.9875896886863339
train_label=0_precision_sent: 0.9438124784557049
train_label=0_recall_sent: 0.9412169130285322
train_label=0_f-score_sent: 0.942512908777969
train_label=1_precision_sent: 0.9846499102333932
train_label=1_recall_sent: 0.9853575278476464
train_label=1_f-score_sent: 0.9850035919540229
train_precision_macro_sent: 0.9642311943445491
train_recall_macro_sent: 0.9632872204380893
train_f-score_macro_sent: 0.9637582503659959
train_precision_micro_sent: 0.9762125204757496
train_recall_micro_sent: 0.9762125204757496
train_f-score_micro_sent: 0.9762125204757496
train_label=O_precision_tok: 0.9959699988805553
train_label=O_recall_tok: 0.9968451096250693
train_label=O_f-score_tok: 0.996407362107838
train_label=LOC_precision_tok: 0.9470190683079894
train_label=LOC_recall_tok: 0.9457635289863806
train_label=LOC_f-score_tok: 0.9463908822287886
train_label=MISC_precision_tok: 0.908012533572068
train_label=MISC_recall_tok: 0.8833006749401263
train_label=MISC_f-score_tok: 0.8954861494316301
train_label=ORG_precision_tok: 0.9305708839169259
train_label=ORG_recall_tok: 0.9251870324189526
train_label=ORG_f-score_tok: 0.9278711484593838
train_label=PER_precision_tok: 0.9730600554909156
train_label=PER_recall_tok: 0.9769949676491733
train_label=PER_f-score_tok: 0.9750235415452222
train_precision_macro_tok: 0.9509265080336908
train_recall_macro_tok: 0.9456182627239403
train_f-score_macro_tok: 0.9482358167545726
train_precision_micro_tok: 0.9875896886863339
train_recall_micro_tok: 0.9875896886863339
train_f-score_micro_tok: 0.9875896886863339
train_time: 242.2457525730133
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9438    0.9412    0.9425      2909
           1     0.9846    0.9854    0.9850     11132

   micro avg     0.9762    0.9762    0.9762     14041
   macro avg     0.9642    0.9633    0.9638     14041
weighted avg     0.9762    0.9762    0.9762     14041

F1-macro sent:  0.9637582503659959
F1-micro sent:  0.9762125204757496
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9968    0.9964    169578
         LOC     0.9470    0.9458    0.9464      8297
        MISC     0.9080    0.8833    0.8955      4593
         ORG     0.9306    0.9252    0.9279     10025
         PER     0.9731    0.9770    0.9750     11128

   micro avg     0.9876    0.9876    0.9876    203621
   macro avg     0.9509    0.9456    0.9482    203621
weighted avg     0.9875    0.9876    0.9875    203621

F1-macro tok:  0.9482358167545726
F1-micro tok:  0.9875896886863339
**************************************************
dev_cost_sum: 86011.44526672363
dev_cost_avg: 26.46506008206881
dev_count_sent: 3250.0
dev_total_correct_sent: 3202.0
dev_accuracy_sent: 0.9852307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50750.0
dev_accuracy_tok: 0.9880845761457887
dev_label=0_precision_sent: 0.9671361502347418
dev_label=0_recall_sent: 0.958139534883721
dev_label=0_f-score_sent: 0.9626168224299065
dev_label=1_precision_sent: 0.9896591344312524
dev_label=1_recall_sent: 0.9919385796545106
dev_label=1_f-score_sent: 0.99079754601227
dev_precision_macro_sent: 0.9783976423329971
dev_recall_macro_sent: 0.9750390572691158
dev_f-score_macro_sent: 0.9767071842210883
dev_precision_micro_sent: 0.9852307692307692
dev_recall_micro_sent: 0.9852307692307692
dev_f-score_micro_sent: 0.9852307692307692
dev_label=O_precision_tok: 0.996654501216545
dev_label=O_recall_tok: 0.9963048714890432
dev_label=O_f-score_tok: 0.9964796556845958
dev_label=LOC_precision_tok: 0.9572852396772663
dev_label=LOC_recall_tok: 0.9632282712511939
dev_label=LOC_f-score_tok: 0.9602475601047371
dev_label=MISC_precision_tok: 0.8767441860465116
dev_label=MISC_recall_tok: 0.8919558359621451
dev_label=MISC_f-score_tok: 0.8842845973416732
dev_label=ORG_precision_tok: 0.9383629191321499
dev_label=ORG_recall_tok: 0.9096558317399618
dev_label=ORG_f-score_tok: 0.9237864077669903
dev_label=PER_precision_tok: 0.9702474162229878
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9769788710186061
dev_precision_macro_tok: 0.9478588524590922
dev_recall_macro_tok: 0.9489898385571889
dev_f-score_macro_tok: 0.9483554183833205
dev_precision_micro_tok: 0.9880845761457887
dev_recall_micro_tok: 0.9880845761457887
dev_f-score_micro_tok: 0.9880845761457887
dev_time: 24.222325325012207
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9671    0.9581    0.9626       645
           1     0.9897    0.9919    0.9908      2605

   micro avg     0.9852    0.9852    0.9852      3250
   macro avg     0.9784    0.9750    0.9767      3250
weighted avg     0.9852    0.9852    0.9852      3250

F1-macro sent:  0.9767071842210883
F1-micro sent:  0.9852307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9963    0.9965     42759
         LOC     0.9573    0.9632    0.9602      2094
        MISC     0.8767    0.8920    0.8843      1268
         ORG     0.9384    0.9097    0.9238      2092
         PER     0.9702    0.9838    0.9770      3149

   micro avg     0.9881    0.9881    0.9881     51362
   macro avg     0.9479    0.9490    0.9484     51362
weighted avg     0.9881    0.9881    0.9881     51362

F1-macro tok:  0.9483554183833205
F1-micro tok:  0.9880845761457887
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 316838.16174316406
train_cost_avg: 22.565213428043876
train_count_sent: 14041.0
train_total_correct_sent: 13733.0
train_accuracy_sent: 0.9780642404387152
train_count_tok: 203621.0
train_total_correct_tok: 201327.0
train_accuracy_tok: 0.988733971446953
train_label=0_precision_sent: 0.9427987742594485
train_label=0_recall_sent: 0.9518734960467514
train_label=0_f-score_sent: 0.9473144030106055
train_label=1_precision_sent: 0.9873919308357348
train_label=1_recall_sent: 0.9849083722601509
train_label=1_f-score_sent: 0.9861485878755172
train_precision_macro_sent: 0.9650953525475916
train_recall_macro_sent: 0.9683909341534511
train_f-score_macro_sent: 0.9667314954430614
train_precision_micro_sent: 0.9780642404387152
train_recall_micro_sent: 0.9780642404387152
train_f-score_micro_sent: 0.9780642404387152
train_label=O_precision_tok: 0.9964344858882256
train_label=O_recall_tok: 0.9970397103397847
train_label=O_f-score_tok: 0.9967370062400703
train_label=LOC_precision_tok: 0.9535585042219542
train_label=LOC_recall_tok: 0.9527540074725804
train_label=LOC_f-score_tok: 0.9531560860915175
train_label=MISC_precision_tok: 0.9154428126390743
train_label=MISC_recall_tok: 0.8957108643588069
train_label=MISC_f-score_tok: 0.9054693518212831
train_label=ORG_precision_tok: 0.9340121792951982
train_label=ORG_recall_tok: 0.9332668329177057
train_label=ORG_f-score_tok: 0.9336393573495659
train_label=PER_precision_tok: 0.9763892629499955
train_label=PER_recall_tok: 0.9773544212796549
train_label=PER_f-score_tok: 0.9768716037185071
train_precision_macro_tok: 0.9551674489988896
train_recall_macro_tok: 0.9512251672737065
train_f-score_macro_tok: 0.9531746810441888
train_precision_micro_tok: 0.988733971446953
train_recall_micro_tok: 0.988733971446953
train_f-score_micro_tok: 0.988733971446953
train_time: 240.376229763031
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9428    0.9519    0.9473      2909
           1     0.9874    0.9849    0.9861     11132

   micro avg     0.9781    0.9781    0.9781     14041
   macro avg     0.9651    0.9684    0.9667     14041
weighted avg     0.9782    0.9781    0.9781     14041

F1-macro sent:  0.9667314954430614
F1-micro sent:  0.9780642404387152
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9970    0.9967    169578
         LOC     0.9536    0.9528    0.9532      8297
        MISC     0.9154    0.8957    0.9055      4593
         ORG     0.9340    0.9333    0.9336     10025
         PER     0.9764    0.9774    0.9769     11128

   micro avg     0.9887    0.9887    0.9887    203621
   macro avg     0.9552    0.9512    0.9532    203621
weighted avg     0.9887    0.9887    0.9887    203621

F1-macro tok:  0.9531746810441888
F1-micro tok:  0.988733971446953
**************************************************
dev_cost_sum: 85573.84295654297
dev_cost_avg: 26.330413217397837
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50759.0
dev_accuracy_tok: 0.9882598029671742
dev_label=0_precision_sent: 0.9751166407465007
dev_label=0_recall_sent: 0.9720930232558139
dev_label=0_f-score_sent: 0.9736024844720497
dev_label=1_precision_sent: 0.9930955120828538
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9934765924788949
dev_precision_macro_sent: 0.9841060764146773
dev_recall_macro_sent: 0.9829754943534348
dev_f-score_macro_sent: 0.9835395384754723
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9960297071325144
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9967164074459259
dev_label=LOC_precision_tok: 0.9562529719448407
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9583035501548726
dev_label=MISC_precision_tok: 0.9282094594594594
dev_label=MISC_recall_tok: 0.8667192429022083
dev_label=MISC_f-score_tok: 0.8964110929853182
dev_label=ORG_precision_tok: 0.9127548601232812
dev_label=ORG_recall_tok: 0.9201720841300192
dev_label=ORG_f-score_tok: 0.9164484646512735
dev_label=PER_precision_tok: 0.97712833545108
dev_label=PER_recall_tok: 0.9768180374722134
dev_label=PER_f-score_tok: 0.9769731618230904
dev_precision_macro_tok: 0.9540750668222351
dev_recall_macro_tok: 0.9442952723058694
dev_f-score_macro_tok: 0.9489705354120961
dev_precision_micro_tok: 0.9882598029671742
dev_recall_micro_tok: 0.9882598029671742
dev_f-score_micro_tok: 0.9882598029671742
dev_time: 24.366377592086792
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9751    0.9721    0.9736       645
           1     0.9931    0.9939    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9841    0.9830    0.9835      3250
weighted avg     0.9895    0.9895    0.9895      3250

F1-macro sent:  0.9835395384754723
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9974    0.9967     42759
         LOC     0.9563    0.9604    0.9583      2094
        MISC     0.9282    0.8667    0.8964      1268
         ORG     0.9128    0.9202    0.9164      2092
         PER     0.9771    0.9768    0.9770      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9541    0.9443    0.9490     51362
weighted avg     0.9882    0.9883    0.9882     51362

F1-macro tok:  0.9489705354120961
F1-micro tok:  0.9882598029671742
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 314545.1661376953
train_cost_avg: 22.401906284288536
train_count_sent: 14041.0
train_total_correct_sent: 13763.0
train_accuracy_sent: 0.9802008403959832
train_count_tok: 203621.0
train_total_correct_tok: 201447.0
train_accuracy_tok: 0.9893233016240958
train_label=0_precision_sent: 0.9515962924819773
train_label=0_recall_sent: 0.9529047782743211
train_label=0_f-score_sent: 0.9522500858811406
train_label=1_precision_sent: 0.9876887131560029
train_label=1_recall_sent: 0.9873338124326266
train_label=1_f-score_sent: 0.9875112309074573
train_precision_macro_sent: 0.9696425028189901
train_recall_macro_sent: 0.9701192953534739
train_f-score_macro_sent: 0.9698806583942989
train_precision_micro_sent: 0.9802008403959832
train_recall_micro_sent: 0.9802008403959832
train_f-score_micro_sent: 0.9802008403959832
train_label=O_precision_tok: 0.9966525815785907
train_label=O_recall_tok: 0.99726969300263
train_label=O_f-score_tok: 0.9969610417937811
train_label=LOC_precision_tok: 0.9547811407210901
train_label=LOC_recall_tok: 0.9543208388574184
train_label=LOC_f-score_tok: 0.9545509342977697
train_label=MISC_precision_tok: 0.9195274186357557
train_label=MISC_recall_tok: 0.8981058131939909
train_label=MISC_f-score_tok: 0.9086903844035688
train_label=ORG_precision_tok: 0.9399519615692554
train_label=ORG_recall_tok: 0.936857855361596
train_label=ORG_f-score_tok: 0.9384023579957036
train_label=PER_precision_tok: 0.9758216172651563
train_label=PER_recall_tok: 0.9792415528396837
train_label=PER_f-score_tok: 0.9775285938551245
train_precision_macro_tok: 0.9573469439539697
train_recall_macro_tok: 0.9531591506510638
train_f-score_macro_tok: 0.9552266624691894
train_precision_micro_tok: 0.9893233016240958
train_recall_micro_tok: 0.9893233016240958
train_f-score_micro_tok: 0.9893233016240958
train_time: 242.5303201675415
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9516    0.9529    0.9523      2909
           1     0.9877    0.9873    0.9875     11132

   micro avg     0.9802    0.9802    0.9802     14041
   macro avg     0.9696    0.9701    0.9699     14041
weighted avg     0.9802    0.9802    0.9802     14041

F1-macro sent:  0.9698806583942989
F1-micro sent:  0.9802008403959832
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9973    0.9970    169578
         LOC     0.9548    0.9543    0.9546      8297
        MISC     0.9195    0.8981    0.9087      4593
         ORG     0.9400    0.9369    0.9384     10025
         PER     0.9758    0.9792    0.9775     11128

   micro avg     0.9893    0.9893    0.9893    203621
   macro avg     0.9573    0.9532    0.9552    203621
weighted avg     0.9893    0.9893    0.9893    203621

F1-macro tok:  0.9552266624691894
F1-micro tok:  0.9893233016240958
**************************************************
dev_cost_sum: 85150.9725112915
dev_cost_avg: 26.20029923424354
dev_count_sent: 3250.0
dev_total_correct_sent: 3212.0
dev_accuracy_sent: 0.9883076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50760.0
dev_accuracy_tok: 0.9882792726139947
dev_label=0_precision_sent: 0.9619482496194824
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9708141321044548
dev_label=1_precision_sent: 0.9949865021210953
dev_label=1_recall_sent: 0.9904030710172744
dev_label=1_f-score_sent: 0.9926894959599847
dev_precision_macro_sent: 0.9784673758702889
dev_recall_macro_sent: 0.9851240161287922
dev_f-score_macro_sent: 0.9817518140322197
dev_precision_micro_sent: 0.9883076923076923
dev_recall_micro_sent: 0.9883076923076923
dev_f-score_micro_sent: 0.9883076923076923
dev_label=O_precision_tok: 0.9963086699530407
dev_label=O_recall_tok: 0.9973338946186767
dev_label=O_f-score_tok: 0.9968210186765153
dev_label=LOC_precision_tok: 0.9579148732663797
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9572281959378733
dev_label=MISC_precision_tok: 0.8874015748031496
dev_label=MISC_recall_tok: 0.888801261829653
dev_label=MISC_f-score_tok: 0.8881008668242711
dev_label=ORG_precision_tok: 0.9499494438827099
dev_label=ORG_recall_tok: 0.8981835564053537
dev_label=ORG_f-score_tok: 0.9233415233415234
dev_label=PER_precision_tok: 0.9645962732919254
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9753493484063432
dev_precision_macro_tok: 0.9512341670394411
dev_recall_macro_tok: 0.9454412173258401
dev_f-score_macro_tok: 0.9481681906373053
dev_precision_micro_tok: 0.9882792726139947
dev_recall_micro_tok: 0.9882792726139947
dev_f-score_micro_tok: 0.9882792726139947
dev_time: 24.3606379032135
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9619    0.9798    0.9708       645
           1     0.9950    0.9904    0.9927      2605

   micro avg     0.9883    0.9883    0.9883      3250
   macro avg     0.9785    0.9851    0.9818      3250
weighted avg     0.9884    0.9883    0.9883      3250

F1-macro sent:  0.9817518140322197
F1-micro sent:  0.9883076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9973    0.9968     42759
         LOC     0.9579    0.9565    0.9572      2094
        MISC     0.8874    0.8888    0.8881      1268
         ORG     0.9499    0.8982    0.9233      2092
         PER     0.9646    0.9863    0.9753      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9512    0.9454    0.9482     51362
weighted avg     0.9882    0.9883    0.9882     51362

F1-macro tok:  0.9481681906373053
F1-micro tok:  0.9882792726139947
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 312301.073638916
train_cost_avg: 22.24208201972196
train_count_sent: 14041.0
train_total_correct_sent: 13795.0
train_accuracy_sent: 0.9824798803504023
train_count_tok: 203621.0
train_total_correct_tok: 201625.0
train_accuracy_tok: 0.9901974747201909
train_label=0_precision_sent: 0.9552136752136752
train_label=0_recall_sent: 0.9604675146098316
train_label=0_f-score_sent: 0.9578333904696607
train_label=1_precision_sent: 0.9896545519971213
train_label=1_recall_sent: 0.9882321236076177
train_label=1_f-score_sent: 0.988942826321467
train_precision_macro_sent: 0.9724341136053982
train_recall_macro_sent: 0.9743498191087246
train_f-score_macro_sent: 0.9733881083955638
train_precision_micro_sent: 0.9824798803504023
train_recall_micro_sent: 0.9824798803504023
train_f-score_micro_sent: 0.9824798803504023
train_label=O_precision_tok: 0.9969999528479819
train_label=O_recall_tok: 0.9975055726568305
train_label=O_f-score_tok: 0.9972526986634911
train_label=LOC_precision_tok: 0.957480125271019
train_label=LOC_recall_tok: 0.958057129082801
train_label=LOC_f-score_tok: 0.9577685402735105
train_label=MISC_precision_tok: 0.9279519679786524
train_label=MISC_recall_tok: 0.9085564990202482
train_label=MISC_f-score_tok: 0.918151815181518
train_label=ORG_precision_tok: 0.9439991985574033
train_label=ORG_recall_tok: 0.9399501246882793
train_label=ORG_f-score_tok: 0.941970310391363
train_label=PER_precision_tok: 0.9775411596277738
train_label=PER_recall_tok: 0.9817577282530554
train_label=PER_f-score_tok: 0.979644906743185
train_precision_macro_tok: 0.960794480856566
train_recall_macro_tok: 0.9571654107402429
train_f-score_macro_tok: 0.9589576542506135
train_precision_micro_tok: 0.9901974747201909
train_recall_micro_tok: 0.9901974747201909
train_f-score_micro_tok: 0.9901974747201908
train_time: 241.84878730773926
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9552    0.9605    0.9578      2909
           1     0.9897    0.9882    0.9889     11132

   micro avg     0.9825    0.9825    0.9825     14041
   macro avg     0.9724    0.9743    0.9734     14041
weighted avg     0.9825    0.9825    0.9825     14041

F1-macro sent:  0.9733881083955638
F1-micro sent:  0.9824798803504023
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9975    0.9973    169578
         LOC     0.9575    0.9581    0.9578      8297
        MISC     0.9280    0.9086    0.9182      4593
         ORG     0.9440    0.9400    0.9420     10025
         PER     0.9775    0.9818    0.9796     11128

   micro avg     0.9902    0.9902    0.9902    203621
   macro avg     0.9608    0.9572    0.9590    203621
weighted avg     0.9902    0.9902    0.9902    203621

F1-macro tok:  0.9589576542506135
F1-micro tok:  0.9901974747201908
**************************************************
dev_cost_sum: 84799.22109222412
dev_cost_avg: 26.09206802837665
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50780.0
dev_accuracy_tok: 0.9886686655504069
dev_label=0_precision_sent: 0.9873417721518988
dev_label=0_recall_sent: 0.9674418604651163
dev_label=0_f-score_sent: 0.9772905246671887
dev_label=1_precision_sent: 0.9919786096256684
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9944476354585488
dev_precision_macro_sent: 0.9896601908887837
dev_recall_macro_sent: 0.9821854215953221
dev_f-score_macro_sent: 0.9858690800628687
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9960063524685879
dev_label=O_recall_tok: 0.9973806683972964
dev_label=O_f-score_tok: 0.9966930366804164
dev_label=LOC_precision_tok: 0.9601918465227818
dev_label=LOC_recall_tok: 0.956064947468959
dev_label=LOC_f-score_tok: 0.9581239530988275
dev_label=MISC_precision_tok: 0.8926332288401254
dev_label=MISC_recall_tok: 0.8982649842271293
dev_label=MISC_f-score_tok: 0.895440251572327
dev_label=ORG_precision_tok: 0.9408284023668639
dev_label=ORG_recall_tok: 0.9120458891013384
dev_label=ORG_f-score_tok: 0.9262135922330097
dev_label=PER_precision_tok: 0.9774960380348653
dev_label=PER_recall_tok: 0.9793585265163544
dev_label=PER_f-score_tok: 0.9784263959390863
dev_precision_macro_tok: 0.953431173646645
dev_recall_macro_tok: 0.9486230031422155
dev_f-score_macro_tok: 0.9509794459047335
dev_precision_micro_tok: 0.9886686655504069
dev_recall_micro_tok: 0.9886686655504069
dev_f-score_micro_tok: 0.9886686655504069
dev_time: 24.618998050689697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9873    0.9674    0.9773       645
           1     0.9920    0.9969    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9897    0.9822    0.9859      3250
weighted avg     0.9911    0.9911    0.9910      3250

F1-macro sent:  0.9858690800628687
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9974    0.9967     42759
         LOC     0.9602    0.9561    0.9581      2094
        MISC     0.8926    0.8983    0.8954      1268
         ORG     0.9408    0.9120    0.9262      2092
         PER     0.9775    0.9794    0.9784      3149

   micro avg     0.9887    0.9887    0.9887     51362
   macro avg     0.9534    0.9486    0.9510     51362
weighted avg     0.9886    0.9887    0.9886     51362

F1-macro tok:  0.9509794459047335
F1-micro tok:  0.9886686655504069
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 310431.9221801758
train_cost_avg: 22.108961055492898
train_count_sent: 14041.0
train_total_correct_sent: 13819.0
train_accuracy_sent: 0.9841891603162168
train_count_tok: 203621.0
train_total_correct_tok: 201654.0
train_accuracy_tok: 0.9903398961796671
train_label=0_precision_sent: 0.963116166839021
train_label=0_recall_sent: 0.9604675146098316
train_label=0_f-score_sent: 0.9617900172117039
train_label=1_precision_sent: 0.9896768402154399
train_label=1_recall_sent: 0.9903880704275961
train_label=1_f-score_sent: 0.9900323275862069
train_precision_macro_sent: 0.9763965035272304
train_recall_macro_sent: 0.9754277925187138
train_f-score_macro_sent: 0.9759111723989553
train_precision_micro_sent: 0.9841891603162168
train_recall_micro_sent: 0.9841891603162168
train_f-score_micro_sent: 0.9841891603162168
train_label=O_precision_tok: 0.9969466728754914
train_label=O_recall_tok: 0.9973758388470203
train_label=O_f-score_tok: 0.9971612096843134
train_label=LOC_precision_tok: 0.9584437484943387
train_label=LOC_recall_tok: 0.959021333011932
train_label=LOC_f-score_tok: 0.9587324537622749
train_label=MISC_precision_tok: 0.9316522893165229
train_label=MISC_recall_tok: 0.9170476812540823
train_label=MISC_f-score_tok: 0.924292297564187
train_label=ORG_precision_tok: 0.9441995592065718
train_label=ORG_recall_tok: 0.940149625935162
train_label=ORG_f-score_tok: 0.9421702404158544
train_label=PER_precision_tok: 0.9786833855799373
train_label=PER_recall_tok: 0.9819374550682962
train_label=PER_f-score_tok: 0.98030771991208
train_precision_macro_tok: 0.9619851310945725
train_recall_macro_tok: 0.9591063868232986
train_f-score_macro_tok: 0.9605327842677418
train_precision_micro_tok: 0.9903398961796671
train_recall_micro_tok: 0.9903398961796671
train_f-score_micro_tok: 0.9903398961796671
train_time: 241.8429455757141
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9631    0.9605    0.9618      2909
           1     0.9897    0.9904    0.9900     11132

   micro avg     0.9842    0.9842    0.9842     14041
   macro avg     0.9764    0.9754    0.9759     14041
weighted avg     0.9842    0.9842    0.9842     14041

F1-macro sent:  0.9759111723989553
F1-micro sent:  0.9841891603162168
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9974    0.9972    169578
         LOC     0.9584    0.9590    0.9587      8297
        MISC     0.9317    0.9170    0.9243      4593
         ORG     0.9442    0.9401    0.9422     10025
         PER     0.9787    0.9819    0.9803     11128

   micro avg     0.9903    0.9903    0.9903    203621
   macro avg     0.9620    0.9591    0.9605    203621
weighted avg     0.9903    0.9903    0.9903    203621

F1-macro tok:  0.9605327842677418
F1-micro tok:  0.9903398961796671
**************************************************
dev_cost_sum: 84561.12641525269
dev_cost_avg: 26.018808127770058
dev_count_sent: 3250.0
dev_total_correct_sent: 3193.0
dev_accuracy_sent: 0.9824615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50773.0
dev_accuracy_tok: 0.9885323780226627
dev_label=0_precision_sent: 0.9427710843373494
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9564553093964859
dev_label=1_precision_sent: 0.9926527455529776
dev_label=1_recall_sent: 0.9854126679462571
dev_label=1_f-score_sent: 0.9890194567520708
dev_precision_macro_sent: 0.9677119149451634
dev_recall_macro_sent: 0.977977651802586
dev_f-score_macro_sent: 0.9727373830742784
dev_precision_micro_sent: 0.9824615384615385
dev_recall_micro_sent: 0.9824615384615385
dev_f-score_micro_sent: 0.9824615384615385
dev_label=O_precision_tok: 0.9950800942010399
dev_label=O_recall_tok: 0.9980588881872822
dev_label=O_f-score_tok: 0.9965672652546528
dev_label=LOC_precision_tok: 0.9730127576054955
dev_label=LOC_recall_tok: 0.9469914040114613
dev_label=LOC_f-score_tok: 0.9598257502420136
dev_label=MISC_precision_tok: 0.9282094594594594
dev_label=MISC_recall_tok: 0.8667192429022083
dev_label=MISC_f-score_tok: 0.8964110929853182
dev_label=ORG_precision_tok: 0.927536231884058
dev_label=ORG_recall_tok: 0.9177820267686424
dev_label=ORG_f-score_tok: 0.9226333493512734
dev_label=PER_precision_tok: 0.9723531259817781
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9775742261528744
dev_precision_macro_tok: 0.9592383338263663
dev_recall_macro_tok: 0.9424806521643285
dev_f-score_macro_tok: 0.9506023367972265
dev_precision_micro_tok: 0.9885323780226627
dev_recall_micro_tok: 0.9885323780226627
dev_f-score_micro_tok: 0.9885323780226627
dev_time: 24.359041929244995
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9428    0.9705    0.9565       645
           1     0.9927    0.9854    0.9890      2605

   micro avg     0.9825    0.9825    0.9825      3250
   macro avg     0.9677    0.9780    0.9727      3250
weighted avg     0.9828    0.9825    0.9826      3250

F1-macro sent:  0.9727373830742784
F1-micro sent:  0.9824615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9951    0.9981    0.9966     42759
         LOC     0.9730    0.9470    0.9598      2094
        MISC     0.9282    0.8667    0.8964      1268
         ORG     0.9275    0.9178    0.9226      2092
         PER     0.9724    0.9829    0.9776      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9592    0.9425    0.9506     51362
weighted avg     0.9884    0.9885    0.9884     51362

F1-macro tok:  0.9506023367972265
F1-micro tok:  0.9885323780226627
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 308742.7904663086
train_cost_avg: 21.988661097237276
train_count_sent: 14041.0
train_total_correct_sent: 13838.0
train_accuracy_sent: 0.9855423402891532
train_count_tok: 203621.0
train_total_correct_tok: 201739.0
train_accuracy_tok: 0.9907573383884767
train_label=0_precision_sent: 0.9646291208791209
train_label=0_recall_sent: 0.9656239257476796
train_label=0_f-score_sent: 0.965126266964439
train_label=1_precision_sent: 0.9910144667085992
train_label=1_recall_sent: 0.9907473948975926
train_label=1_f-score_sent: 0.9908809128071515
train_precision_macro_sent: 0.97782179379386
train_recall_macro_sent: 0.9781856603226361
train_f-score_macro_sent: 0.9780035898857953
train_precision_micro_sent: 0.9855423402891532
train_recall_micro_sent: 0.9855423402891532
train_f-score_micro_sent: 0.9855423402891532
train_label=O_precision_tok: 0.9971114451616706
train_label=O_recall_tok: 0.9974466027432803
train_label=O_f-score_tok: 0.9972789957932037
train_label=LOC_precision_tok: 0.9600964436407474
train_label=LOC_recall_tok: 0.9598650114499216
train_label=LOC_f-score_tok: 0.9599807135969142
train_label=MISC_precision_tok: 0.9346866725507502
train_label=MISC_recall_tok: 0.922273024167211
train_label=MISC_f-score_tok: 0.9284383561643835
train_label=ORG_precision_tok: 0.9448268981342911
train_label=ORG_recall_tok: 0.944638403990025
train_label=ORG_f-score_tok: 0.9447326416600159
train_label=PER_precision_tok: 0.9809626436781609
train_label=PER_recall_tok: 0.9816678648454349
train_label=PER_f-score_tok: 0.9813151275601869
train_precision_macro_tok: 0.963536820633124
train_recall_macro_tok: 0.9611781814391746
train_f-score_macro_tok: 0.9623491669549409
train_precision_micro_tok: 0.9907573383884767
train_recall_micro_tok: 0.9907573383884767
train_f-score_micro_tok: 0.9907573383884767
train_time: 242.4168381690979
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9646    0.9656    0.9651      2909
           1     0.9910    0.9907    0.9909     11132

   micro avg     0.9855    0.9855    0.9855     14041
   macro avg     0.9778    0.9782    0.9780     14041
weighted avg     0.9855    0.9855    0.9855     14041

F1-macro sent:  0.9780035898857953
F1-micro sent:  0.9855423402891532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9974    0.9973    169578
         LOC     0.9601    0.9599    0.9600      8297
        MISC     0.9347    0.9223    0.9284      4593
         ORG     0.9448    0.9446    0.9447     10025
         PER     0.9810    0.9817    0.9813     11128

   micro avg     0.9908    0.9908    0.9908    203621
   macro avg     0.9635    0.9612    0.9623    203621
weighted avg     0.9907    0.9908    0.9907    203621

F1-macro tok:  0.9623491669549409
F1-micro tok:  0.9907573383884767
**************************************************
dev_cost_sum: 84189.85012054443
dev_cost_avg: 25.904569267859827
dev_count_sent: 3250.0
dev_total_correct_sent: 3215.0
dev_accuracy_sent: 0.9892307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50782.0
dev_accuracy_tok: 0.9887076048440482
dev_label=0_precision_sent: 0.9593373493975904
dev_label=0_recall_sent: 0.9875968992248062
dev_label=0_f-score_sent: 0.9732620320855616
dev_label=1_precision_sent: 0.9969064191802011
dev_label=1_recall_sent: 0.9896353166986565
dev_label=1_f-score_sent: 0.9932575611635522
dev_precision_macro_sent: 0.9781218842888957
dev_recall_macro_sent: 0.9886161079617313
dev_f-score_macro_sent: 0.9832597966245569
dev_precision_micro_sent: 0.9892307692307692
dev_recall_micro_sent: 0.9892307692307692
dev_f-score_micro_sent: 0.9892307692307692
dev_label=O_precision_tok: 0.9964706432311145
dev_label=O_recall_tok: 0.9970532519469585
dev_label=O_f-score_tok: 0.9967618624551394
dev_label=LOC_precision_tok: 0.9585516912815627
dev_label=LOC_recall_tok: 0.9608404966571156
dev_label=LOC_f-score_tok: 0.9596947293107561
dev_label=MISC_precision_tok: 0.8970125786163522
dev_label=MISC_recall_tok: 0.8998422712933754
dev_label=MISC_f-score_tok: 0.8984251968503937
dev_label=ORG_precision_tok: 0.9418777943368107
dev_label=ORG_recall_tok: 0.9063097514340345
dev_label=ORG_f-score_tok: 0.9237515225334958
dev_label=PER_precision_tok: 0.9705698184095178
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9774554627148038
dev_precision_macro_tok: 0.9528965051750717
dev_recall_macro_tok: 0.9496970551872241
dev_f-score_macro_tok: 0.9512177547729177
dev_precision_micro_tok: 0.9887076048440482
dev_recall_micro_tok: 0.9887076048440482
dev_f-score_micro_tok: 0.9887076048440482
dev_time: 24.560404539108276
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9593    0.9876    0.9733       645
           1     0.9969    0.9896    0.9933      2605

   micro avg     0.9892    0.9892    0.9892      3250
   macro avg     0.9781    0.9886    0.9833      3250
weighted avg     0.9895    0.9892    0.9893      3250

F1-macro sent:  0.9832597966245569
F1-micro sent:  0.9892307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9971    0.9968     42759
         LOC     0.9586    0.9608    0.9597      2094
        MISC     0.8970    0.8998    0.8984      1268
         ORG     0.9419    0.9063    0.9238      2092
         PER     0.9706    0.9844    0.9775      3149

   micro avg     0.9887    0.9887    0.9887     51362
   macro avg     0.9529    0.9497    0.9512     51362
weighted avg     0.9887    0.9887    0.9887     51362

F1-macro tok:  0.9512177547729177
F1-micro tok:  0.9887076048440482
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 307124.3090515137
train_cost_avg: 21.873392853180945
train_count_sent: 14041.0
train_total_correct_sent: 13817.0
train_accuracy_sent: 0.9840467203190656
train_count_tok: 203621.0
train_total_correct_tok: 201805.0
train_accuracy_tok: 0.9910814699859052
train_label=0_precision_sent: 0.9624526352049604
train_label=0_recall_sent: 0.9604675146098316
train_label=0_f-score_sent: 0.9614590502408809
train_label=1_precision_sent: 0.9896749865325911
train_label=1_recall_sent: 0.9902084081925979
train_label=1_f-score_sent: 0.9899416255051638
train_precision_macro_sent: 0.9760638108687758
train_recall_macro_sent: 0.9753379614012148
train_f-score_macro_sent: 0.9757003378730223
train_precision_micro_sent: 0.9840467203190656
train_recall_micro_sent: 0.9840467203190656
train_f-score_micro_sent: 0.9840467203190656
train_label=O_precision_tok: 0.9971709122629165
train_label=O_recall_tok: 0.9976883793888358
train_label=O_f-score_tok: 0.9974295787103088
train_label=LOC_precision_tok: 0.9613253012048193
train_label=LOC_recall_tok: 0.9616728938170424
train_label=LOC_f-score_tok: 0.9614990660962826
train_label=MISC_precision_tok: 0.9347489493474895
train_label=MISC_recall_tok: 0.9200957979534073
train_label=MISC_f-score_tok: 0.9273644941847706
train_label=ORG_precision_tok: 0.9488948894889488
train_label=ORG_recall_tok: 0.9464339152119701
train_label=ORG_f-score_tok: 0.9476628046344386
train_label=PER_precision_tok: 0.9812303547373148
train_label=PER_recall_tok: 0.9818475916606758
train_label=PER_f-score_tok: 0.9815388761622423
train_precision_macro_tok: 0.9646740814082978
train_recall_macro_tok: 0.9615477156063863
train_f-score_macro_tok: 0.9630989639576086
train_precision_micro_tok: 0.9910814699859052
train_recall_micro_tok: 0.9910814699859052
train_f-score_micro_tok: 0.9910814699859052
train_time: 242.7207314968109
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9625    0.9605    0.9615      2909
           1     0.9897    0.9902    0.9899     11132

   micro avg     0.9840    0.9840    0.9840     14041
   macro avg     0.9761    0.9753    0.9757     14041
weighted avg     0.9840    0.9840    0.9840     14041

F1-macro sent:  0.9757003378730223
F1-micro sent:  0.9840467203190656
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9977    0.9974    169578
         LOC     0.9613    0.9617    0.9615      8297
        MISC     0.9347    0.9201    0.9274      4593
         ORG     0.9489    0.9464    0.9477     10025
         PER     0.9812    0.9818    0.9815     11128

   micro avg     0.9911    0.9911    0.9911    203621
   macro avg     0.9647    0.9615    0.9631    203621
weighted avg     0.9911    0.9911    0.9911    203621

F1-macro tok:  0.9630989639576086
F1-micro tok:  0.9910814699859052
**************************************************
dev_cost_sum: 83850.84257125854
dev_cost_avg: 25.800259252694936
dev_count_sent: 3250.0
dev_total_correct_sent: 3207.0
dev_accuracy_sent: 0.9867692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50785.0
dev_accuracy_tok: 0.9887660137845099
dev_label=0_precision_sent: 0.9519519519519519
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9672006102212052
dev_label=1_precision_sent: 0.9957430340557275
dev_label=1_recall_sent: 0.9877159309021113
dev_label=1_f-score_sent: 0.9917132395451917
dev_precision_macro_sent: 0.9738474930038397
dev_recall_macro_sent: 0.9853308336681099
dev_f-score_macro_sent: 0.9794569248831985
dev_precision_micro_sent: 0.9867692307692307
dev_recall_micro_sent: 0.9867692307692307
dev_f-score_micro_sent: 0.9867692307692307
dev_label=O_precision_tok: 0.9960769661871848
dev_label=O_recall_tok: 0.9975911504010851
dev_label=O_f-score_tok: 0.9968334832852319
dev_label=LOC_precision_tok: 0.9395477618827872
dev_label=LOC_recall_tok: 0.9723018147086915
dev_label=LOC_f-score_tok: 0.955644214973011
dev_label=MISC_precision_tok: 0.9207920792079208
dev_label=MISC_recall_tok: 0.8801261829652997
dev_label=MISC_f-score_tok: 0.8999999999999999
dev_label=ORG_precision_tok: 0.9505050505050505
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9243614931237721
dev_label=PER_precision_tok: 0.9735765964139667
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9781921618204803
dev_precision_macro_tok: 0.956099690839382
dev_recall_macro_tok: 0.9464976875698609
dev_f-score_macro_tok: 0.9510062706404991
dev_precision_micro_tok: 0.9887660137845099
dev_recall_micro_tok: 0.9887660137845099
dev_f-score_micro_tok: 0.9887660137845099
dev_time: 24.82257080078125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9520    0.9829    0.9672       645
           1     0.9957    0.9877    0.9917      2605

   micro avg     0.9868    0.9868    0.9868      3250
   macro avg     0.9738    0.9853    0.9795      3250
weighted avg     0.9871    0.9868    0.9868      3250

F1-macro sent:  0.9794569248831985
F1-micro sent:  0.9867692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9976    0.9968     42759
         LOC     0.9395    0.9723    0.9556      2094
        MISC     0.9208    0.8801    0.9000      1268
         ORG     0.9505    0.8996    0.9244      2092
         PER     0.9736    0.9829    0.9782      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9561    0.9465    0.9510     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9510062706404991
F1-micro tok:  0.9887660137845099
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 305379.3610839844
train_cost_avg: 21.749117661419014
train_count_sent: 14041.0
train_total_correct_sent: 13845.0
train_accuracy_sent: 0.9860408802791824
train_count_tok: 203621.0
train_total_correct_tok: 201959.0
train_accuracy_tok: 0.9918377770465718
train_label=0_precision_sent: 0.9669535283993115
train_label=0_recall_sent: 0.9656239257476796
train_label=0_f-score_sent: 0.9662882696938424
train_label=1_precision_sent: 0.9910201149425287
train_label=1_recall_sent: 0.9913762127200862
train_label=1_f-score_sent: 0.9911981318483923
train_precision_macro_sent: 0.9789868216709201
train_recall_macro_sent: 0.978500069233883
train_f-score_macro_sent: 0.9787432007711174
train_precision_micro_sent: 0.9860408802791824
train_recall_micro_sent: 0.9860408802791824
train_f-score_micro_sent: 0.9860408802791824
train_label=O_precision_tok: 0.997547560235104
train_label=O_recall_tok: 0.9978358041727111
train_label=O_f-score_tok: 0.9976916613847084
train_label=LOC_precision_tok: 0.9680260617760618
train_label=LOC_recall_tok: 0.9669760154272629
train_label=LOC_f-score_tok: 0.9675007536930963
train_label=MISC_precision_tok: 0.9383833922261484
train_label=MISC_recall_tok: 0.9251034182451556
train_label=MISC_f-score_tok: 0.9316960859554874
train_label=ORG_precision_tok: 0.9514534012586155
train_label=ORG_recall_tok: 0.9501246882793017
train_label=ORG_f-score_tok: 0.950788580555001
train_label=PER_precision_tok: 0.980657293812125
train_label=PER_recall_tok: 0.9840941768511862
train_label=PER_f-score_tok: 0.9823727293115048
train_precision_macro_tok: 0.967213541861611
train_recall_macro_tok: 0.9648268205951235
train_f-score_macro_tok: 0.9660099621799596
train_precision_micro_tok: 0.9918377770465718
train_recall_micro_tok: 0.9918377770465718
train_f-score_micro_tok: 0.9918377770465718
train_time: 241.23844647407532
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9670    0.9656    0.9663      2909
           1     0.9910    0.9914    0.9912     11132

   micro avg     0.9860    0.9860    0.9860     14041
   macro avg     0.9790    0.9785    0.9787     14041
weighted avg     0.9860    0.9860    0.9860     14041

F1-macro sent:  0.9787432007711174
F1-micro sent:  0.9860408802791824
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9975    0.9978    0.9977    169578
         LOC     0.9680    0.9670    0.9675      8297
        MISC     0.9384    0.9251    0.9317      4593
         ORG     0.9515    0.9501    0.9508     10025
         PER     0.9807    0.9841    0.9824     11128

   micro avg     0.9918    0.9918    0.9918    203621
   macro avg     0.9672    0.9648    0.9660    203621
weighted avg     0.9918    0.9918    0.9918    203621

F1-macro tok:  0.9660099621799596
F1-micro tok:  0.9918377770465718
**************************************************
dev_cost_sum: 83645.23070526123
dev_cost_avg: 25.7369940631573
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50814.0
dev_accuracy_tok: 0.9893306335423075
dev_label=0_precision_sent: 0.9738461538461538
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9776061776061776
dev_label=1_precision_sent: 0.9953846153846154
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9944284341978867
dev_precision_macro_sent: 0.9846153846153847
dev_recall_macro_sent: 0.987434718564478
dev_f-score_macro_sent: 0.9860173059020322
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9960316533999393
dev_label=O_recall_tok: 0.9978951799621132
dev_label=O_f-score_tok: 0.9969625458538751
dev_label=LOC_precision_tok: 0.9640632486823191
dev_label=LOC_recall_tok: 0.9608404966571156
dev_label=LOC_f-score_tok: 0.9624491748385553
dev_label=MISC_precision_tok: 0.9356223175965666
dev_label=MISC_recall_tok: 0.8596214511041009
dev_label=MISC_f-score_tok: 0.896013152486642
dev_label=ORG_precision_tok: 0.9281294621608758
dev_label=ORG_recall_tok: 0.9321223709369025
dev_label=ORG_f-score_tok: 0.9301216312902457
dev_label=PER_precision_tok: 0.9757097791798107
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9789523658806774
dev_precision_macro_tok: 0.9599112922039023
dev_recall_macro_tok: 0.946539215070249
dev_f-score_macro_tok: 0.952899774069999
dev_precision_micro_tok: 0.9893306335423075
dev_recall_micro_tok: 0.9893306335423075
dev_f-score_micro_tok: 0.9893306335423075
dev_time: 24.475684881210327
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9738    0.9814    0.9776       645
           1     0.9954    0.9935    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9846    0.9874    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9860173059020322
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9979    0.9970     42759
         LOC     0.9641    0.9608    0.9624      2094
        MISC     0.9356    0.8596    0.8960      1268
         ORG     0.9281    0.9321    0.9301      2092
         PER     0.9757    0.9822    0.9790      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9599    0.9465    0.9529     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.952899774069999
F1-micro tok:  0.9893306335423075
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 303911.76837158203
train_cost_avg: 21.64459571053216
train_count_sent: 14041.0
train_total_correct_sent: 13841.0
train_accuracy_sent: 0.98575600028488
train_count_tok: 203621.0
train_total_correct_tok: 201965.0
train_accuracy_tok: 0.991867243555429
train_label=0_precision_sent: 0.9618138424821002
train_label=0_recall_sent: 0.969749054657958
train_label=0_f-score_sent: 0.9657651489216021
train_label=1_precision_sent: 0.992077781778898
train_label=1_recall_sent: 0.9899389148401007
train_label=1_f-score_sent: 0.9910071942446043
train_precision_macro_sent: 0.9769458121304991
train_recall_macro_sent: 0.9798439847490293
train_f-score_macro_sent: 0.9783861715831033
train_precision_micro_sent: 0.98575600028488
train_recall_micro_sent: 0.98575600028488
train_f-score_micro_sent: 0.98575600028488
train_label=O_precision_tok: 0.9975650738437049
train_label=O_recall_tok: 0.997782731250516
train_label=O_f-score_tok: 0.9976738906758099
train_label=LOC_precision_tok: 0.9653512993262753
train_label=LOC_recall_tok: 0.9670965409184042
train_label=LOC_f-score_tok: 0.9662231320368476
train_label=MISC_precision_tok: 0.9379947229551451
train_label=MISC_recall_tok: 0.9288047028086218
train_label=MISC_f-score_tok: 0.9333770922218575
train_label=ORG_precision_tok: 0.9539815926370548
train_label=ORG_recall_tok: 0.9512219451371571
train_label=ORG_f-score_tok: 0.9525997702412465
train_label=PER_precision_tok: 0.980896860986547
train_label=PER_recall_tok: 0.9828360891445004
train_label=PER_f-score_tok: 0.9818655175509471
train_precision_macro_tok: 0.9671579099497455
train_recall_macro_tok: 0.9655484018518399
train_f-score_macro_tok: 0.9663478805453417
train_precision_micro_tok: 0.991867243555429
train_recall_micro_tok: 0.991867243555429
train_f-score_micro_tok: 0.991867243555429
train_time: 242.54011368751526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9618    0.9697    0.9658      2909
           1     0.9921    0.9899    0.9910     11132

   micro avg     0.9858    0.9858    0.9858     14041
   macro avg     0.9769    0.9798    0.9784     14041
weighted avg     0.9858    0.9858    0.9858     14041

F1-macro sent:  0.9783861715831033
F1-micro sent:  0.98575600028488
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9978    0.9977    169578
         LOC     0.9654    0.9671    0.9662      8297
        MISC     0.9380    0.9288    0.9334      4593
         ORG     0.9540    0.9512    0.9526     10025
         PER     0.9809    0.9828    0.9819     11128

   micro avg     0.9919    0.9919    0.9919    203621
   macro avg     0.9672    0.9655    0.9663    203621
weighted avg     0.9919    0.9919    0.9919    203621

F1-macro tok:  0.9663478805453417
F1-micro tok:  0.991867243555429
**************************************************
dev_cost_sum: 83337.08854675293
dev_cost_avg: 25.642181091308593
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50774.0
dev_accuracy_tok: 0.9885518476694832
dev_label=0_precision_sent: 0.973724884080371
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9752321981424149
dev_label=1_precision_sent: 0.9942374183634268
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9938556067588327
dev_precision_macro_sent: 0.9839811512218989
dev_recall_macro_sent: 0.9851091371691292
dev_f-score_macro_sent: 0.9845439024506237
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9963562469343423
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.9969849950918525
dev_label=LOC_precision_tok: 0.936405529953917
dev_label=LOC_recall_tok: 0.9703915950334289
dev_label=LOC_f-score_tok: 0.9530956848030019
dev_label=MISC_precision_tok: 0.9335038363171355
dev_label=MISC_recall_tok: 0.863564668769716
dev_label=MISC_f-score_tok: 0.8971732896353953
dev_label=ORG_precision_tok: 0.945281124497992
dev_label=ORG_recall_tok: 0.9000956022944551
dev_label=ORG_f-score_tok: 0.9221351616062684
dev_label=PER_precision_tok: 0.9667081518357187
dev_label=PER_recall_tok: 0.9866624325182598
dev_label=PER_f-score_tok: 0.9765833726229765
dev_precision_macro_tok: 0.955650977907821
dev_recall_macro_tok: 0.943665767181251
dev_f-score_macro_tok: 0.9491945007518989
dev_precision_micro_tok: 0.9885518476694832
dev_recall_micro_tok: 0.9885518476694832
dev_f-score_micro_tok: 0.9885518476694831
dev_time: 24.56498646736145
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9737    0.9767    0.9752       645
           1     0.9942    0.9935    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9840    0.9851    0.9845      3250
weighted avg     0.9902    0.9902    0.9902      3250

F1-macro sent:  0.9845439024506237
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9976    0.9970     42759
         LOC     0.9364    0.9704    0.9531      2094
        MISC     0.9335    0.8636    0.8972      1268
         ORG     0.9453    0.9001    0.9221      2092
         PER     0.9667    0.9867    0.9766      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9557    0.9437    0.9492     51362
weighted avg     0.9885    0.9886    0.9884     51362

F1-macro tok:  0.9491945007518989
F1-micro tok:  0.9885518476694831
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 302336.59799194336
train_cost_avg: 21.532412078337966
train_count_sent: 14041.0
train_total_correct_sent: 13867.0
train_accuracy_sent: 0.9876077202478456
train_count_tok: 203621.0
train_total_correct_tok: 202085.0
train_accuracy_tok: 0.9924565737325718
train_label=0_precision_sent: 0.9694473051836594
train_label=0_recall_sent: 0.9707803368855277
train_label=0_f-score_sent: 0.970113363105462
train_label=1_precision_sent: 0.9923616103522646
train_label=1_recall_sent: 0.9920050305425799
train_label=1_f-score_sent: 0.9921832884097036
train_precision_macro_sent: 0.980904457767962
train_recall_macro_sent: 0.9813926837140539
train_f-score_macro_sent: 0.9811483257575828
train_precision_micro_sent: 0.9876077202478456
train_recall_micro_sent: 0.9876077202478456
train_f-score_micro_sent: 0.9876077202478456
train_label=O_precision_tok: 0.9975771795068293
train_label=O_recall_tok: 0.9979242590430363
train_label=O_f-score_tok: 0.9977506890909895
train_label=LOC_precision_tok: 0.9703185328185329
train_label=LOC_recall_tok: 0.969265999758949
train_label=LOC_f-score_tok: 0.9697919807054567
train_label=MISC_precision_tok: 0.9447987684187377
train_label=MISC_recall_tok: 0.9353363814500326
train_label=MISC_f-score_tok: 0.9400437636761488
train_label=ORG_precision_tok: 0.9558176729308276
train_label=ORG_recall_tok: 0.9538154613466334
train_label=ORG_f-score_tok: 0.9548155174996255
train_label=PER_precision_tok: 0.9833109017496635
train_label=PER_recall_tok: 0.9848130841121495
train_label=PER_f-score_tok: 0.9840614196560858
train_precision_macro_tok: 0.9703646110849181
train_recall_macro_tok: 0.9682310371421601
train_f-score_macro_tok: 0.9692926741256611
train_precision_micro_tok: 0.9924565737325718
train_recall_micro_tok: 0.9924565737325718
train_f-score_micro_tok: 0.9924565737325718
train_time: 243.6111626625061
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9694    0.9708    0.9701      2909
           1     0.9924    0.9920    0.9922     11132

   micro avg     0.9876    0.9876    0.9876     14041
   macro avg     0.9809    0.9814    0.9811     14041
weighted avg     0.9876    0.9876    0.9876     14041

F1-macro sent:  0.9811483257575828
F1-micro sent:  0.9876077202478456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9979    0.9978    169578
         LOC     0.9703    0.9693    0.9698      8297
        MISC     0.9448    0.9353    0.9400      4593
         ORG     0.9558    0.9538    0.9548     10025
         PER     0.9833    0.9848    0.9841     11128

   micro avg     0.9925    0.9925    0.9925    203621
   macro avg     0.9704    0.9682    0.9693    203621
weighted avg     0.9924    0.9925    0.9924    203621

F1-macro tok:  0.9692926741256611
F1-micro tok:  0.9924565737325718
**************************************************
dev_cost_sum: 83044.22806549072
dev_cost_avg: 25.552070173997144
dev_count_sent: 3250.0
dev_total_correct_sent: 3198.0
dev_accuracy_sent: 0.984
dev_count_tok: 51362.0
dev_total_correct_tok: 50802.0
dev_accuracy_tok: 0.9890969977804602
dev_label=0_precision_sent: 0.9405646359583952
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.960546282245827
dev_label=1_precision_sent: 0.9953434225844005
dev_label=1_recall_sent: 0.9846449136276392
dev_label=1_f-score_sent: 0.9899652643766885
dev_precision_macro_sent: 0.9679540292713978
dev_recall_macro_sent: 0.9830201312324243
dev_f-score_macro_sent: 0.9752557733112578
dev_precision_micro_sent: 0.984
dev_recall_micro_sent: 0.984
dev_f-score_micro_sent: 0.984
dev_label=O_precision_tok: 0.9965867913500877
dev_label=O_recall_tok: 0.9969597043897191
dev_label=O_f-score_tok: 0.9967732129913252
dev_label=LOC_precision_tok: 0.9650047938638543
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9631578947368421
dev_label=MISC_precision_tok: 0.9129032258064517
dev_label=MISC_recall_tok: 0.8927444794952681
dev_label=MISC_f-score_tok: 0.9027113237639554
dev_label=ORG_precision_tok: 0.9385665529010239
dev_label=ORG_recall_tok: 0.9201720841300192
dev_label=ORG_f-score_tok: 0.9292783007482501
dev_label=PER_precision_tok: 0.9666666666666667
dev_label=PER_recall_tok: 0.9853921879961892
dev_label=PER_f-score_tok: 0.9759396131467212
dev_precision_macro_tok: 0.9559456061176169
dev_recall_macro_tok: 0.9513173015174254
dev_f-score_macro_tok: 0.9535720690774188
dev_precision_micro_tok: 0.9890969977804602
dev_recall_micro_tok: 0.9890969977804602
dev_f-score_micro_tok: 0.9890969977804602
dev_time: 24.292171716690063
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9406    0.9814    0.9605       645
           1     0.9953    0.9846    0.9900      2605

   micro avg     0.9840    0.9840    0.9840      3250
   macro avg     0.9680    0.9830    0.9753      3250
weighted avg     0.9845    0.9840    0.9841      3250

F1-macro sent:  0.9752557733112578
F1-micro sent:  0.984
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9970    0.9968     42759
         LOC     0.9650    0.9613    0.9632      2094
        MISC     0.9129    0.8927    0.9027      1268
         ORG     0.9386    0.9202    0.9293      2092
         PER     0.9667    0.9854    0.9759      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9559    0.9513    0.9536     51362
weighted avg     0.9890    0.9891    0.9891     51362

F1-macro tok:  0.9535720690774188
F1-micro tok:  0.9890969977804602
**************************************************
Best epoch: 20
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 300837.270904541
train_cost_avg: 21.42563000530881
train_count_sent: 14041.0
train_total_correct_sent: 13872.0
train_accuracy_sent: 0.9879638202407236
train_count_tok: 203621.0
train_total_correct_tok: 202179.0
train_accuracy_tok: 0.992918215704667
train_label=0_precision_sent: 0.9691780821917808
train_label=0_recall_sent: 0.9728429013406669
train_label=0_f-score_sent: 0.9710070337965345
train_label=1_precision_sent: 0.9928963222731769
train_label=1_recall_sent: 0.9919151994250809
train_label=1_f-score_sent: 0.9924055183570755
train_precision_macro_sent: 0.9810372022324789
train_recall_macro_sent: 0.9823790503828739
train_f-score_macro_sent: 0.9817062760768049
train_precision_micro_sent: 0.9879638202407236
train_recall_micro_sent: 0.9879638202407236
train_f-score_micro_sent: 0.9879638202407236
train_label=O_precision_tok: 0.9977538555864736
train_label=O_recall_tok: 0.9980245078960714
train_label=O_f-score_tok: 0.9978891633893668
train_label=LOC_precision_tok: 0.9700591573101534
train_label=LOC_recall_tok: 0.9684223213209594
train_label=LOC_f-score_tok: 0.9692400482509047
train_label=MISC_precision_tok: 0.9476117103235747
train_label=MISC_recall_tok: 0.9372958850424559
train_label=MISC_f-score_tok: 0.9424255691768826
train_label=ORG_precision_tok: 0.959609055550015
train_label=ORG_recall_tok: 0.9598004987531172
train_label=ORG_f-score_tok: 0.959704767604229
train_label=PER_precision_tok: 0.9847451543431442
train_label=PER_recall_tok: 0.9861610352264558
train_label=PER_f-score_tok: 0.9854525862068966
train_precision_macro_tok: 0.9719557866226722
train_recall_macro_tok: 0.9699408496478119
train_f-score_macro_tok: 0.9709424269256559
train_precision_micro_tok: 0.992918215704667
train_recall_micro_tok: 0.992918215704667
train_f-score_micro_tok: 0.992918215704667
train_time: 242.73446226119995
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9692    0.9728    0.9710      2909
           1     0.9929    0.9919    0.9924     11132

   micro avg     0.9880    0.9880    0.9880     14041
   macro avg     0.9810    0.9824    0.9817     14041
weighted avg     0.9880    0.9880    0.9880     14041

F1-macro sent:  0.9817062760768049
F1-micro sent:  0.9879638202407236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9978    0.9980    0.9979    169578
         LOC     0.9701    0.9684    0.9692      8297
        MISC     0.9476    0.9373    0.9424      4593
         ORG     0.9596    0.9598    0.9597     10025
         PER     0.9847    0.9862    0.9855     11128

   micro avg     0.9929    0.9929    0.9929    203621
   macro avg     0.9720    0.9699    0.9709    203621
weighted avg     0.9929    0.9929    0.9929    203621

F1-macro tok:  0.9709424269256559
F1-micro tok:  0.992918215704667
**************************************************
dev_cost_sum: 82889.53072357178
dev_cost_avg: 25.50447099186824
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50791.0
dev_accuracy_tok: 0.9888828316654336
dev_label=0_precision_sent: 0.9889064976228209
dev_label=0_recall_sent: 0.9674418604651163
dev_label=0_f-score_sent: 0.9780564263322883
dev_label=1_precision_sent: 0.9919816723940436
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9946401225114855
dev_precision_macro_sent: 0.9904440850084322
dev_recall_macro_sent: 0.9823773601749766
dev_f-score_macro_sent: 0.9863482744218869
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9961923894508165
dev_label=O_recall_tok: 0.9973572815079866
dev_label=O_f-score_tok: 0.9967744951383696
dev_label=LOC_precision_tok: 0.9520225776105362
dev_label=LOC_recall_tok: 0.9665711556829035
dev_label=LOC_f-score_tok: 0.9592417061611374
dev_label=MISC_precision_tok: 0.9103392568659128
dev_label=MISC_recall_tok: 0.888801261829653
dev_label=MISC_f-score_tok: 0.899441340782123
dev_label=ORG_precision_tok: 0.9464464464464465
dev_label=ORG_recall_tok: 0.9039196940726577
dev_label=ORG_f-score_tok: 0.9246943765281174
dev_label=PER_precision_tok: 0.9724224381071764
dev_label=PER_recall_tok: 0.9853921879961892
dev_label=PER_f-score_tok: 0.9788643533123029
dev_precision_macro_tok: 0.9554846216961776
dev_recall_macro_tok: 0.948408316217878
dev_f-score_macro_tok: 0.95180325438441
dev_precision_micro_tok: 0.9888828316654336
dev_recall_micro_tok: 0.9888828316654336
dev_f-score_micro_tok: 0.9888828316654336
dev_time: 24.389711380004883
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9889    0.9674    0.9781       645
           1     0.9920    0.9973    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9904    0.9824    0.9863      3250
weighted avg     0.9914    0.9914    0.9913      3250

F1-macro sent:  0.9863482744218869
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9974    0.9968     42759
         LOC     0.9520    0.9666    0.9592      2094
        MISC     0.9103    0.8888    0.8994      1268
         ORG     0.9464    0.9039    0.9247      2092
         PER     0.9724    0.9854    0.9789      3149

   micro avg     0.9889    0.9889    0.9889     51362
   macro avg     0.9555    0.9484    0.9518     51362
weighted avg     0.9888    0.9889    0.9888     51362

F1-macro tok:  0.95180325438441
F1-micro tok:  0.9888828316654336
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 299789.3557434082
train_cost_avg: 21.350997489025584
train_count_sent: 14041.0
train_total_correct_sent: 13875.0
train_accuracy_sent: 0.9881774802364504
train_count_tok: 203621.0
train_total_correct_tok: 202186.0
train_accuracy_tok: 0.9929525932983336
train_label=0_precision_sent: 0.969530982540226
train_label=0_recall_sent: 0.9735304228257133
train_label=0_f-score_sent: 0.9715265866209263
train_label=1_precision_sent: 0.9930755395683454
train_label=1_recall_sent: 0.9920050305425799
train_label=1_f-score_sent: 0.9925399964048176
train_precision_macro_sent: 0.9813032610542857
train_recall_macro_sent: 0.9827677266841466
train_f-score_macro_sent: 0.982033291512872
train_precision_micro_sent: 0.9881774802364504
train_recall_micro_sent: 0.9881774802364504
train_f-score_micro_sent: 0.9881774802364504
train_label=O_precision_tok: 0.9977950063378829
train_label=O_recall_tok: 0.9980127139133614
train_label=O_f-score_tok: 0.9979038482515854
train_label=LOC_precision_tok: 0.9721216509775525
train_label=LOC_recall_tok: 0.9708328311437869
train_label=LOC_f-score_tok: 0.9714768136042935
train_label=MISC_precision_tok: 0.9473453268977622
train_label=MISC_recall_tok: 0.9401262791204006
train_label=MISC_f-score_tok: 0.9437219975958911
train_label=ORG_precision_tok: 0.9598120563830851
train_label=ORG_recall_tok: 0.9577057356608479
train_label=ORG_f-score_tok: 0.9587577391651688
train_label=PER_precision_tok: 0.9831526122412403
train_label=PER_recall_tok: 0.9858914450035945
train_label=PER_f-score_tok: 0.9845201238390092
train_precision_macro_tok: 0.9720453305675045
train_recall_macro_tok: 0.9705138009683981
train_f-score_macro_tok: 0.9712761044911897
train_precision_micro_tok: 0.9929525932983336
train_recall_micro_tok: 0.9929525932983336
train_f-score_micro_tok: 0.9929525932983336
train_time: 205.02735209465027
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9695    0.9735    0.9715      2909
           1     0.9931    0.9920    0.9925     11132

   micro avg     0.9882    0.9882    0.9882     14041
   macro avg     0.9813    0.9828    0.9820     14041
weighted avg     0.9882    0.9882    0.9882     14041

F1-macro sent:  0.982033291512872
F1-micro sent:  0.9881774802364504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9978    0.9980    0.9979    169578
         LOC     0.9721    0.9708    0.9715      8297
        MISC     0.9473    0.9401    0.9437      4593
         ORG     0.9598    0.9577    0.9588     10025
         PER     0.9832    0.9859    0.9845     11128

   micro avg     0.9930    0.9930    0.9930    203621
   macro avg     0.9720    0.9705    0.9713    203621
weighted avg     0.9929    0.9930    0.9929    203621

F1-macro tok:  0.9712761044911897
F1-micro tok:  0.9929525932983336
**************************************************
dev_cost_sum: 82673.69175720215
dev_cost_avg: 25.438059002216047
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50799.0
dev_accuracy_tok: 0.9890385888399984
dev_label=0_precision_sent: 0.9665653495440729
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9762087490406753
dev_label=1_precision_sent: 0.9965277777777778
dev_label=1_recall_sent: 0.9915547024952015
dev_label=1_f-score_sent: 0.9940350202039638
dev_precision_macro_sent: 0.9815465636609253
dev_recall_macro_sent: 0.9888006070615543
dev_f-score_macro_sent: 0.9851218846223195
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9960766913430327
dev_label=O_recall_tok: 0.9975209897331556
dev_label=O_f-score_tok: 0.9967983173638701
dev_label=LOC_precision_tok: 0.9604950023798191
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9620977353992848
dev_label=MISC_precision_tok: 0.9145646867371847
dev_label=MISC_recall_tok: 0.886435331230284
dev_label=MISC_f-score_tok: 0.9002803364036844
dev_label=ORG_precision_tok: 0.9395577395577396
dev_label=ORG_recall_tok: 0.9139579349904398
dev_label=ORG_f-score_tok: 0.9265810516113399
dev_label=PER_precision_tok: 0.9735516372795969
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.977707509881423
dev_precision_macro_tok: 0.9568491514594747
dev_recall_macro_tok: 0.9487038195368769
dev_f-score_macro_tok: 0.9526929901319203
dev_precision_micro_tok: 0.9890385888399984
dev_recall_micro_tok: 0.9890385888399984
dev_f-score_micro_tok: 0.9890385888399984
dev_time: 14.615755319595337
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9666    0.9860    0.9762       645
           1     0.9965    0.9916    0.9940      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9815    0.9888    0.9851      3250
weighted avg     0.9906    0.9905    0.9905      3250

F1-macro sent:  0.9851218846223195
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9975    0.9968     42759
         LOC     0.9605    0.9637    0.9621      2094
        MISC     0.9146    0.8864    0.9003      1268
         ORG     0.9396    0.9140    0.9266      2092
         PER     0.9736    0.9819    0.9777      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9568    0.9487    0.9527     51362
weighted avg     0.9889    0.9890    0.9890     51362

F1-macro tok:  0.9526929901319203
F1-micro tok:  0.9890385888399984
**************************************************
Best epoch: 23
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 298222.5827636719
train_cost_avg: 21.23941191964047
train_count_sent: 14041.0
train_total_correct_sent: 13883.0
train_accuracy_sent: 0.9887472402250552
train_count_tok: 203621.0
train_total_correct_tok: 202304.0
train_accuracy_tok: 0.9935321013058575
train_label=0_precision_sent: 0.9734939759036144
train_label=0_recall_sent: 0.9721553798556205
train_label=0_f-score_sent: 0.9728242174062607
train_label=1_precision_sent: 0.9927262931034483
train_label=1_recall_sent: 0.9930830039525692
train_label=1_f-score_sent: 0.9929046164900305
train_precision_macro_sent: 0.9831101345035314
train_recall_macro_sent: 0.9826191919040949
train_f-score_macro_sent: 0.9828644169481455
train_precision_micro_sent: 0.9887472402250552
train_recall_micro_sent: 0.9887472402250552
train_f-score_micro_sent: 0.9887472402250552
train_label=O_precision_tok: 0.9979718057414406
train_label=O_recall_tok: 0.9981542417058816
train_label=O_f-score_tok: 0.9980630153867924
train_label=LOC_precision_tok: 0.9704925930386608
train_label=LOC_recall_tok: 0.971194407617211
train_label=LOC_f-score_tok: 0.970843373493976
train_label=MISC_precision_tok: 0.9550438596491229
train_label=MISC_recall_tok: 0.948182016111474
train_label=MISC_f-score_tok: 0.9516005681197423
train_label=ORG_precision_tok: 0.965068561705535
train_label=ORG_recall_tok: 0.9617955112219452
train_label=ORG_f-score_tok: 0.9634292565947242
train_label=PER_precision_tok: 0.9844058074923822
train_label=PER_recall_tok: 0.98705966930266
train_label=PER_f-score_tok: 0.9857309521672799
train_precision_macro_tok: 0.9745965255254283
train_recall_macro_tok: 0.9732771691918345
train_f-score_macro_tok: 0.9739334331525029
train_precision_micro_tok: 0.9935321013058575
train_recall_micro_tok: 0.9935321013058575
train_f-score_micro_tok: 0.9935321013058575
train_time: 159.4771864414215
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9735    0.9722    0.9728      2909
           1     0.9927    0.9931    0.9929     11132

   micro avg     0.9887    0.9887    0.9887     14041
   macro avg     0.9831    0.9826    0.9829     14041
weighted avg     0.9887    0.9887    0.9887     14041

F1-macro sent:  0.9828644169481455
F1-micro sent:  0.9887472402250552
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9982    0.9981    169578
         LOC     0.9705    0.9712    0.9708      8297
        MISC     0.9550    0.9482    0.9516      4593
         ORG     0.9651    0.9618    0.9634     10025
         PER     0.9844    0.9871    0.9857     11128

   micro avg     0.9935    0.9935    0.9935    203621
   macro avg     0.9746    0.9733    0.9739    203621
weighted avg     0.9935    0.9935    0.9935    203621

F1-macro tok:  0.9739334331525029
F1-micro tok:  0.9935321013058575
**************************************************
dev_cost_sum: 82410.4702835083
dev_cost_avg: 25.357067779541016
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50804.0
dev_accuracy_tok: 0.9891359370741015
dev_label=0_precision_sent: 0.962178517397882
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9739663093415007
dev_label=1_precision_sent: 0.996523754345307
dev_label=1_recall_sent: 0.9904030710172744
dev_label=1_f-score_sent: 0.993453985367732
dev_precision_macro_sent: 0.9793511358715945
dev_recall_macro_sent: 0.9882247913225908
dev_f-score_macro_sent: 0.9837101473546164
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9971693920041172
dev_label=O_recall_tok: 0.9968895437217896
dev_label=O_f-score_tok: 0.9970294482258555
dev_label=LOC_precision_tok: 0.9421831637372803
dev_label=LOC_recall_tok: 0.9727793696275072
dev_label=LOC_f-score_tok: 0.9572368421052633
dev_label=MISC_precision_tok: 0.8991399530883503
dev_label=MISC_recall_tok: 0.9069400630914827
dev_label=MISC_f-score_tok: 0.9030231645072635
dev_label=ORG_precision_tok: 0.9470793809286071
dev_label=ORG_recall_tok: 0.9067877629063098
dev_label=ORG_f-score_tok: 0.9264957264957264
dev_label=PER_precision_tok: 0.9757174392935982
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9791139240506329
dev_precision_macro_tok: 0.9522578658103906
dev_recall_macro_tok: 0.9531861754337239
dev_f-score_macro_tok: 0.9525798210769484
dev_precision_micro_tok: 0.9891359370741015
dev_recall_micro_tok: 0.9891359370741015
dev_f-score_micro_tok: 0.9891359370741015
dev_time: 14.802797317504883
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9622    0.9860    0.9740       645
           1     0.9965    0.9904    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9794    0.9882    0.9837      3250
weighted avg     0.9897    0.9895    0.9896      3250

F1-macro sent:  0.9837101473546164
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9969    0.9970     42759
         LOC     0.9422    0.9728    0.9572      2094
        MISC     0.8991    0.9069    0.9030      1268
         ORG     0.9471    0.9068    0.9265      2092
         PER     0.9757    0.9825    0.9791      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9523    0.9532    0.9526     51362
weighted avg     0.9892    0.9891    0.9891     51362

F1-macro tok:  0.9525798210769484
F1-micro tok:  0.9891359370741015
**************************************************
Best epoch: 23
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 296975.1242980957
train_cost_avg: 21.15056792949902
train_count_sent: 14041.0
train_total_correct_sent: 13890.0
train_accuracy_sent: 0.9892457802150844
train_count_tok: 203621.0
train_total_correct_tok: 202369.0
train_accuracy_tok: 0.9938513218184765
train_label=0_precision_sent: 0.9738831615120275
train_label=0_recall_sent: 0.9742179443107597
train_label=0_f-score_sent: 0.974050524145042
train_label=1_precision_sent: 0.9932620609109694
train_label=1_recall_sent: 0.9931728350700683
train_label=1_f-score_sent: 0.9932174459866147
train_precision_macro_sent: 0.9835726112114984
train_recall_macro_sent: 0.9836953896904139
train_f-score_macro_sent: 0.9836339850658283
train_precision_micro_sent: 0.9892457802150844
train_recall_micro_sent: 0.9892457802150844
train_f-score_micro_sent: 0.9892457802150844
train_label=O_precision_tok: 0.9980954739498573
train_label=O_recall_tok: 0.9982014176367218
train_label=O_f-score_tok: 0.9981484429820682
train_label=LOC_precision_tok: 0.9756567847674138
train_label=LOC_recall_tok: 0.9757743762805834
train_label=LOC_f-score_tok: 0.9757155769810184
train_label=MISC_precision_tok: 0.9529152915291529
train_label=MISC_recall_tok: 0.9429566731983453
train_label=MISC_f-score_tok: 0.9479098270956445
train_label=ORG_precision_tok: 0.9657445321082593
train_label=ORG_recall_tok: 0.9645885286783042
train_label=ORG_f-score_tok: 0.9651661842499252
train_label=PER_precision_tok: 0.984779299847793
train_label=PER_recall_tok: 0.9884076204169662
train_label=PER_f-score_tok: 0.9865901242319594
train_precision_macro_tok: 0.9754382764404953
train_recall_macro_tok: 0.973985723242184
train_f-score_macro_tok: 0.9747060311081231
train_precision_micro_tok: 0.9938513218184765
train_recall_micro_tok: 0.9938513218184765
train_f-score_micro_tok: 0.9938513218184765
train_time: 159.3128674030304
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9739    0.9742    0.9741      2909
           1     0.9933    0.9932    0.9932     11132

   micro avg     0.9892    0.9892    0.9892     14041
   macro avg     0.9836    0.9837    0.9836     14041
weighted avg     0.9892    0.9892    0.9892     14041

F1-macro sent:  0.9836339850658283
F1-micro sent:  0.9892457802150844
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9981    0.9982    0.9981    169578
         LOC     0.9757    0.9758    0.9757      8297
        MISC     0.9529    0.9430    0.9479      4593
         ORG     0.9657    0.9646    0.9652     10025
         PER     0.9848    0.9884    0.9866     11128

   micro avg     0.9939    0.9939    0.9939    203621
   macro avg     0.9754    0.9740    0.9747    203621
weighted avg     0.9938    0.9939    0.9938    203621

F1-macro tok:  0.9747060311081231
F1-micro tok:  0.9938513218184765
**************************************************
dev_cost_sum: 82444.29678344727
dev_cost_avg: 25.36747593336839
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50815.0
dev_accuracy_tok: 0.9893501031891282
dev_label=0_precision_sent: 0.9813374805598756
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9798136645962734
dev_label=1_precision_sent: 0.9946298427311085
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9950115118956254
dev_precision_macro_sent: 0.987983661645492
dev_recall_macro_sent: 0.9868440238658513
dev_f-score_macro_sent: 0.9874125882459495
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9960554570068154
dev_label=O_recall_tok: 0.9980355012979724
dev_label=O_f-score_tok: 0.9970444961041085
dev_label=LOC_precision_tok: 0.9595815501664289
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9616392661424827
dev_label=MISC_precision_tok: 0.9073482428115016
dev_label=MISC_recall_tok: 0.8958990536277602
dev_label=MISC_f-score_tok: 0.9015873015873016
dev_label=ORG_precision_tok: 0.9514661274014156
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9248157248157248
dev_label=PER_precision_tok: 0.9745682888540032
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9801073571203032
dev_precision_macro_tok: 0.957803933248033
dev_recall_macro_tok: 0.9485935442089257
dev_f-score_macro_tok: 0.9530388291539842
dev_precision_micro_tok: 0.9893501031891282
dev_recall_micro_tok: 0.9893501031891282
dev_f-score_micro_tok: 0.9893501031891282
dev_time: 14.792762279510498
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9813    0.9783    0.9798       645
           1     0.9946    0.9954    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9880    0.9868    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874125882459495
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9980    0.9970     42759
         LOC     0.9596    0.9637    0.9616      2094
        MISC     0.9073    0.8959    0.9016      1268
         ORG     0.9515    0.8996    0.9248      2092
         PER     0.9746    0.9857    0.9801      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9578    0.9486    0.9530     51362
weighted avg     0.9892    0.9894    0.9893     51362

F1-macro tok:  0.9530388291539842
F1-micro tok:  0.9893501031891282
**************************************************
Best epoch: 26
**************************************************

EPOCH: 27
Learning rate: 1.000000
train_cost_sum: 295866.04165649414
train_cost_avg: 21.071579065343933
train_count_sent: 14041.0
train_total_correct_sent: 13902.0
train_accuracy_sent: 0.9901004201979916
train_count_tok: 203621.0
train_total_correct_tok: 202387.0
train_accuracy_tok: 0.9939397213450479
train_label=0_precision_sent: 0.9762723521320495
train_label=0_recall_sent: 0.9759367480233757
train_label=0_f-score_sent: 0.9761045212308751
train_label=1_precision_sent: 0.9937123865984011
train_label=1_recall_sent: 0.993801652892562
train_label=1_f-score_sent: 0.9937570177408489
train_precision_macro_sent: 0.9849923693652254
train_recall_macro_sent: 0.9848692004579689
train_f-score_macro_sent: 0.984930769485862
train_precision_micro_sent: 0.9901004201979916
train_recall_micro_sent: 0.9901004201979916
train_f-score_micro_sent: 0.9901004201979916
train_label=O_precision_tok: 0.9981073894355775
train_label=O_recall_tok: 0.9982780785243369
train_label=O_f-score_tok: 0.9981927266830786
train_label=LOC_precision_tok: 0.9732035568372988
train_label=LOC_recall_tok: 0.9761359527540074
train_label=LOC_f-score_tok: 0.9746675491906853
train_label=MISC_precision_tok: 0.9551648351648352
train_label=MISC_recall_tok: 0.9462225125190508
train_label=MISC_f-score_tok: 0.9506726457399104
train_label=ORG_precision_tok: 0.9663932786557311
train_label=ORG_recall_tok: 0.9637905236907731
train_label=ORG_f-score_tok: 0.9650901463317184
train_label=PER_precision_tok: 0.9865398420674802
train_label=PER_recall_tok: 0.9879583033788641
train_label=PER_f-score_tok: 0.9872485632183908
train_precision_macro_tok: 0.9758817804321847
train_recall_macro_tok: 0.9744770741734066
train_f-score_macro_tok: 0.9751743262327567
train_precision_micro_tok: 0.9939397213450479
train_recall_micro_tok: 0.9939397213450479
train_f-score_micro_tok: 0.9939397213450479
train_time: 160.0140380859375
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9763    0.9759    0.9761      2909
           1     0.9937    0.9938    0.9938     11132

   micro avg     0.9901    0.9901    0.9901     14041
   macro avg     0.9850    0.9849    0.9849     14041
weighted avg     0.9901    0.9901    0.9901     14041

F1-macro sent:  0.984930769485862
F1-micro sent:  0.9901004201979916
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9981    0.9983    0.9982    169578
         LOC     0.9732    0.9761    0.9747      8297
        MISC     0.9552    0.9462    0.9507      4593
         ORG     0.9664    0.9638    0.9651     10025
         PER     0.9865    0.9880    0.9872     11128

   micro avg     0.9939    0.9939    0.9939    203621
   macro avg     0.9759    0.9745    0.9752    203621
weighted avg     0.9939    0.9939    0.9939    203621

F1-macro tok:  0.9751743262327567
F1-micro tok:  0.9939397213450479
**************************************************
dev_cost_sum: 82147.20283508301
dev_cost_avg: 25.276062410794772
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50788.0
dev_accuracy_tok: 0.9888244227249717
dev_label=0_precision_sent: 0.9782608695652174
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9775019394879751
dev_label=1_precision_sent: 0.9942440521872602
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9944348493571291
dev_precision_macro_sent: 0.9862524608762389
dev_recall_macro_sent: 0.9856849529080927
dev_f-score_macro_sent: 0.9859683944225521
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9959379012489786
dev_label=O_recall_tok: 0.9977080848476344
dev_label=O_f-score_tok: 0.9968222071640535
dev_label=LOC_precision_tok: 0.9424059451927543
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.9554979985872382
dev_label=MISC_precision_tok: 0.9337803855825649
dev_label=MISC_recall_tok: 0.8785488958990536
dev_label=MISC_f-score_tok: 0.905323039414872
dev_label=ORG_precision_tok: 0.94214463840399
dev_label=ORG_recall_tok: 0.902963671128107
dev_label=ORG_f-score_tok: 0.9221381498657555
dev_label=PER_precision_tok: 0.9744962216624685
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9786561264822135
dev_precision_macro_tok: 0.9577530184181512
dev_recall_macro_tok: 0.946206256220765
dev_f-score_macro_tok: 0.9516875043028264
dev_precision_micro_tok: 0.9888244227249717
dev_recall_micro_tok: 0.9888244227249717
dev_f-score_micro_tok: 0.9888244227249717
dev_time: 14.833220720291138
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9783    0.9767    0.9775       645
           1     0.9942    0.9946    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9863    0.9857    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9859683944225521
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9977    0.9968     42759
         LOC     0.9424    0.9690    0.9555      2094
        MISC     0.9338    0.8785    0.9053      1268
         ORG     0.9421    0.9030    0.9221      2092
         PER     0.9745    0.9829    0.9787      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9578    0.9462    0.9517     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9516875043028264
F1-micro tok:  0.9888244227249717
**************************************************
Best epoch: 26
**************************************************

EPOCH: 28
Learning rate: 1.000000
train_cost_sum: 294787.5365905762
train_cost_avg: 20.994767936085477
train_count_sent: 14041.0
train_total_correct_sent: 13907.0
train_accuracy_sent: 0.9904565201908696
train_count_tok: 203621.0
train_total_correct_tok: 202462.0
train_accuracy_tok: 0.9943080527057622
train_label=0_precision_sent: 0.9776247848537005
train_label=0_recall_sent: 0.9762805087658989
train_label=0_f-score_sent: 0.9769521843825248
train_label=1_precision_sent: 0.9938038793103449
train_label=1_recall_sent: 0.9941609773625584
train_label=1_f-score_sent: 0.9939823962636969
train_precision_macro_sent: 0.9857143320820227
train_recall_macro_sent: 0.9852207430642286
train_f-score_macro_sent: 0.9854672903231109
train_precision_micro_sent: 0.9904565201908696
train_recall_micro_sent: 0.9904565201908696
train_f-score_micro_sent: 0.9904565201908696
train_label=O_precision_tok: 0.9981370341111413
train_label=O_recall_tok: 0.9983960183514371
train_label=O_f-score_tok: 0.9982665094339623
train_label=LOC_precision_tok: 0.9763627592860589
train_label=LOC_recall_tok: 0.9757743762805834
train_label=LOC_f-score_tok: 0.976068479112665
train_label=MISC_precision_tok: 0.9603786044464011
train_label=MISC_recall_tok: 0.9499237970825168
train_label=MISC_f-score_tok: 0.9551225919439581
train_label=ORG_precision_tok: 0.9670921420023934
train_label=ORG_recall_tok: 0.9673815461346633
train_label=ORG_f-score_tok: 0.9672368224205854
train_label=PER_precision_tok: 0.9876975574712644
train_label=PER_recall_tok: 0.9884076204169662
train_label=PER_f-score_tok: 0.9880524613726195
train_precision_macro_tok: 0.9779336194634517
train_recall_macro_tok: 0.9759766716532333
train_f-score_macro_tok: 0.9769493728567582
train_precision_micro_tok: 0.9943080527057622
train_recall_micro_tok: 0.9943080527057622
train_f-score_micro_tok: 0.9943080527057622
train_time: 160.41327571868896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9776    0.9763    0.9770      2909
           1     0.9938    0.9942    0.9940     11132

   micro avg     0.9905    0.9905    0.9905     14041
   macro avg     0.9857    0.9852    0.9855     14041
weighted avg     0.9905    0.9905    0.9905     14041

F1-macro sent:  0.9854672903231109
F1-micro sent:  0.9904565201908696
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9981    0.9984    0.9983    169578
         LOC     0.9764    0.9758    0.9761      8297
        MISC     0.9604    0.9499    0.9551      4593
         ORG     0.9671    0.9674    0.9672     10025
         PER     0.9877    0.9884    0.9881     11128

   micro avg     0.9943    0.9943    0.9943    203621
   macro avg     0.9779    0.9760    0.9769    203621
weighted avg     0.9943    0.9943    0.9943    203621

F1-macro tok:  0.9769493728567582
F1-micro tok:  0.9943080527057622
**************************************************
dev_cost_sum: 81822.75661087036
dev_cost_avg: 25.17623280334473
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50800.0
dev_accuracy_tok: 0.989058058486819
dev_label=0_precision_sent: 0.9665144596651446
dev_label=0_recall_sent: 0.9844961240310077
dev_label=0_f-score_sent: 0.9754224270353302
dev_label=1_precision_sent: 0.9961434631700733
dev_label=1_recall_sent: 0.9915547024952015
dev_label=1_f-score_sent: 0.993843786071566
dev_precision_macro_sent: 0.981328961417609
dev_recall_macro_sent: 0.9880254132631046
dev_f-score_macro_sent: 0.9846331065534482
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9966577852568598
dev_label=O_recall_tok: 0.9972871208400571
dev_label=O_f-score_tok: 0.9969723537319539
dev_label=LOC_precision_tok: 0.9658981748318924
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9631226053639848
dev_label=MISC_precision_tok: 0.8826219512195121
dev_label=MISC_recall_tok: 0.9132492113564669
dev_label=MISC_f-score_tok: 0.8976744186046511
dev_label=ORG_precision_tok: 0.950530035335689
dev_label=ORG_recall_tok: 0.9000956022944551
dev_label=ORG_f-score_tok: 0.9246255831082739
dev_label=PER_precision_tok: 0.9700093720712277
dev_label=PER_recall_tok: 0.9860273102572246
dev_label=PER_f-score_tok: 0.9779527559055119
dev_precision_macro_tok: 0.9531434637430362
dev_recall_macro_tok: 0.9514044372973007
dev_f-score_macro_tok: 0.9520695433428751
dev_precision_micro_tok: 0.989058058486819
dev_recall_micro_tok: 0.989058058486819
dev_f-score_micro_tok: 0.989058058486819
dev_time: 14.60504937171936
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9665    0.9845    0.9754       645
           1     0.9961    0.9916    0.9938      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9813    0.9880    0.9846      3250
weighted avg     0.9903    0.9902    0.9902      3250

F1-macro sent:  0.9846331065534482
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9973    0.9970     42759
         LOC     0.9659    0.9604    0.9631      2094
        MISC     0.8826    0.9132    0.8977      1268
         ORG     0.9505    0.9001    0.9246      2092
         PER     0.9700    0.9860    0.9780      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9531    0.9514    0.9521     51362
weighted avg     0.9891    0.9891    0.9890     51362

F1-macro tok:  0.9520695433428751
F1-micro tok:  0.989058058486819
**************************************************
Best epoch: 26
**************************************************

EPOCH: 29
Learning rate: 1.000000
train_cost_sum: 293697.95782470703
train_cost_avg: 20.917168137932272
train_count_sent: 14041.0
train_total_correct_sent: 13898.0
train_accuracy_sent: 0.9898155402036892
train_count_tok: 203621.0
train_total_correct_tok: 202518.0
train_accuracy_tok: 0.9945830734550954
train_label=0_precision_sent: 0.9755845942228336
train_label=0_recall_sent: 0.9752492265383294
train_label=0_f-score_sent: 0.9754168815540658
train_label=1_precision_sent: 0.9935327405012127
train_label=1_recall_sent: 0.9936219906575637
train_label=1_f-score_sent: 0.9935773635751178
train_precision_macro_sent: 0.9845586673620231
train_recall_macro_sent: 0.9844356085979465
train_f-score_macro_sent: 0.9844971225645918
train_precision_micro_sent: 0.9898155402036892
train_recall_micro_sent: 0.9898155402036892
train_f-score_micro_sent: 0.9898155402036892
train_label=O_precision_tok: 0.9983371857163074
train_label=O_recall_tok: 0.9984196063168571
train_label=O_f-score_tok: 0.998378394315535
train_label=LOC_precision_tok: 0.9767329716696805
train_label=LOC_recall_tok: 0.9764975292274316
train_label=LOC_f-score_tok: 0.9766152362584377
train_label=MISC_precision_tok: 0.9597197898423818
train_label=MISC_recall_tok: 0.9544959721315045
train_label=MISC_f-score_tok: 0.957100753192883
train_label=ORG_precision_tok: 0.9693043651584612
train_label=ORG_recall_tok: 0.9701745635910225
train_label=ORG_f-score_tok: 0.9697392691559897
train_label=PER_precision_tok: 0.9877829680201222
train_label=PER_recall_tok: 0.988138030194105
train_label=PER_f-score_tok: 0.9879604672057503
train_precision_macro_tok: 0.9783754560813905
train_recall_macro_tok: 0.977545140292184
train_f-score_macro_tok: 0.9779588240257191
train_precision_micro_tok: 0.9945830734550954
train_recall_micro_tok: 0.9945830734550954
train_f-score_micro_tok: 0.9945830734550954
train_time: 159.65717029571533
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9756    0.9752    0.9754      2909
           1     0.9935    0.9936    0.9936     11132

   micro avg     0.9898    0.9898    0.9898     14041
   macro avg     0.9846    0.9844    0.9845     14041
weighted avg     0.9898    0.9898    0.9898     14041

F1-macro sent:  0.9844971225645918
F1-micro sent:  0.9898155402036892
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9984    0.9984    169578
         LOC     0.9767    0.9765    0.9766      8297
        MISC     0.9597    0.9545    0.9571      4593
         ORG     0.9693    0.9702    0.9697     10025
         PER     0.9878    0.9881    0.9880     11128

   micro avg     0.9946    0.9946    0.9946    203621
   macro avg     0.9784    0.9775    0.9780    203621
weighted avg     0.9946    0.9946    0.9946    203621

F1-macro tok:  0.9779588240257191
F1-micro tok:  0.9945830734550954
**************************************************
dev_cost_sum: 81773.64965820312
dev_cost_avg: 25.161122971754807
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50810.0
dev_accuracy_tok: 0.9892527549550251
dev_label=0_precision_sent: 0.9798449612403101
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9798449612403101
dev_label=1_precision_sent: 0.9950095969289827
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9950095969289827
dev_precision_macro_sent: 0.9874272790846463
dev_recall_macro_sent: 0.9874272790846463
dev_f-score_macro_sent: 0.9874272790846463
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.996031746031746
dev_label=O_recall_tok: 0.9979185668514231
dev_label=O_f-score_tok: 0.9969742637180341
dev_label=LOC_precision_tok: 0.9572649572649573
dev_label=LOC_recall_tok: 0.9627507163323782
dev_label=LOC_f-score_tok: 0.96
dev_label=MISC_precision_tok: 0.921681780708986
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.9012494961708988
dev_label=ORG_precision_tok: 0.9443892750744787
dev_label=ORG_recall_tok: 0.9091778202676865
dev_label=ORG_f-score_tok: 0.9264490988796883
dev_label=PER_precision_tok: 0.9733458764502979
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9794887977279899
dev_precision_macro_tok: 0.9585427271060933
dev_recall_macro_tok: 0.9474520645219482
dev_f-score_macro_tok: 0.9528323312993223
dev_precision_micro_tok: 0.9892527549550251
dev_recall_micro_tok: 0.9892527549550251
dev_f-score_micro_tok: 0.9892527549550251
dev_time: 14.612037181854248
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9798    0.9798    0.9798       645
           1     0.9950    0.9950    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9874    0.9874    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874272790846463
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9979    0.9970     42759
         LOC     0.9573    0.9628    0.9600      2094
        MISC     0.9217    0.8817    0.9012      1268
         ORG     0.9444    0.9092    0.9264      2092
         PER     0.9733    0.9857    0.9795      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9585    0.9475    0.9528     51362
weighted avg     0.9891    0.9893    0.9892     51362

F1-macro tok:  0.9528323312993223
F1-micro tok:  0.9892527549550251
**************************************************
Best epoch: 29
**************************************************

EPOCH: 30
Learning rate: 1.000000
train_cost_sum: 292662.600189209
train_cost_avg: 20.843429968606866
train_count_sent: 14041.0
train_total_correct_sent: 13918.0
train_accuracy_sent: 0.9912399401752012
train_count_tok: 203621.0
train_total_correct_tok: 202535.0
train_accuracy_tok: 0.9946665618968574
train_label=0_precision_sent: 0.980013783597519
train_label=0_recall_sent: 0.9776555517359917
train_label=0_f-score_sent: 0.9788332472896232
train_label=1_precision_sent: 0.9941646467366909
train_label=1_recall_sent: 0.9947897951850521
train_label=1_f-score_sent: 0.9944771227156392
train_precision_macro_sent: 0.9870892151671049
train_recall_macro_sent: 0.986222673460522
train_f-score_macro_sent: 0.9866551850026312
train_precision_micro_sent: 0.9912399401752012
train_recall_micro_sent: 0.9912399401752012
train_f-score_micro_sent: 0.9912399401752012
train_label=O_precision_tok: 0.9982430695579374
train_label=O_recall_tok: 0.9984549882649872
train_label=O_f-score_tok: 0.998349017665511
train_label=LOC_precision_tok: 0.9772398843930635
train_label=LOC_recall_tok: 0.9780643606122695
train_label=LOC_f-score_tok: 0.9776519486777905
train_label=MISC_precision_tok: 0.9635325131810193
train_label=MISC_recall_tok: 0.9549314173742652
train_label=MISC_f-score_tok: 0.959212684527064
train_label=ORG_precision_tok: 0.9697302697302698
train_label=ORG_recall_tok: 0.9682793017456359
train_label=ORG_f-score_tok: 0.9690042425754928
train_label=PER_precision_tok: 0.9883313885647608
train_label=PER_recall_tok: 0.9894859813084113
train_label=PER_f-score_tok: 0.9889083479276123
train_precision_macro_tok: 0.9794154250854101
train_recall_macro_tok: 0.977843209861114
train_f-score_macro_tok: 0.978625248274694
train_precision_micro_tok: 0.9946665618968574
train_recall_micro_tok: 0.9946665618968574
train_f-score_micro_tok: 0.9946665618968574
train_time: 160.12224578857422
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9800    0.9777    0.9788      2909
           1     0.9942    0.9948    0.9945     11132

   micro avg     0.9912    0.9912    0.9912     14041
   macro avg     0.9871    0.9862    0.9867     14041
weighted avg     0.9912    0.9912    0.9912     14041

F1-macro sent:  0.9866551850026312
F1-micro sent:  0.9912399401752012
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9985    0.9983    169578
         LOC     0.9772    0.9781    0.9777      8297
        MISC     0.9635    0.9549    0.9592      4593
         ORG     0.9697    0.9683    0.9690     10025
         PER     0.9883    0.9895    0.9889     11128

   micro avg     0.9947    0.9947    0.9947    203621
   macro avg     0.9794    0.9778    0.9786    203621
weighted avg     0.9947    0.9947    0.9947    203621

F1-macro tok:  0.978625248274694
F1-micro tok:  0.9946665618968574
**************************************************
dev_cost_sum: 81558.48568725586
dev_cost_avg: 25.094918673001803
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50840.0
dev_accuracy_tok: 0.9898368443596434
dev_label=0_precision_sent: 0.9889240506329114
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.9788566953797964
dev_label=1_precision_sent: 0.9923605805958747
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9948305571510626
dev_precision_macro_sent: 0.9906423156143931
dev_recall_macro_sent: 0.9831525539734262
dev_f-score_macro_sent: 0.9868436262654294
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9964265695067265
dev_label=O_recall_tok: 0.9977548586262541
dev_label=O_f-score_tok: 0.9970902716914988
dev_label=LOC_precision_tok: 0.9617590822179732
dev_label=LOC_recall_tok: 0.9608404966571156
dev_label=LOC_f-score_tok: 0.9612995699952223
dev_label=MISC_precision_tok: 0.9375520399666945
dev_label=MISC_recall_tok: 0.88801261829653
dev_label=MISC_f-score_tok: 0.9121101660591334
dev_label=ORG_precision_tok: 0.9374090247452693
dev_label=ORG_recall_tok: 0.9235181644359465
dev_label=ORG_f-score_tok: 0.930411750541777
dev_label=PER_precision_tok: 0.9733709273182958
dev_label=PER_recall_tok: 0.9866624325182598
dev_label=PER_f-score_tok: 0.9799716133102034
dev_precision_macro_tok: 0.961303528750992
dev_recall_macro_tok: 0.9513577141068211
dev_f-score_macro_tok: 0.9561766743195669
dev_precision_micro_tok: 0.9898368443596434
dev_recall_micro_tok: 0.9898368443596434
dev_f-score_micro_tok: 0.9898368443596434
dev_time: 14.67573881149292
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9889    0.9690    0.9789       645
           1     0.9924    0.9973    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9906    0.9832    0.9868      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9868436262654294
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9978    0.9971     42759
         LOC     0.9618    0.9608    0.9613      2094
        MISC     0.9376    0.8880    0.9121      1268
         ORG     0.9374    0.9235    0.9304      2092
         PER     0.9734    0.9867    0.9800      3149

   micro avg     0.9898    0.9898    0.9898     51362
   macro avg     0.9613    0.9514    0.9562     51362
weighted avg     0.9897    0.9898    0.9898     51362

F1-macro tok:  0.9561766743195669
F1-micro tok:  0.9898368443596434
**************************************************
Best epoch: 29
**************************************************

EPOCH: 31
Learning rate: 1.000000
train_cost_sum: 291659.456451416
train_cost_avg: 20.771986073030128
train_count_sent: 14041.0
train_total_correct_sent: 13920.0
train_accuracy_sent: 0.9913823801723524
train_count_tok: 203621.0
train_total_correct_tok: 202558.0
train_accuracy_tok: 0.9947795168474765
train_label=0_precision_sent: 0.9777244688142563
train_label=0_recall_sent: 0.9807493984187006
train_label=0_f-score_sent: 0.9792345975630684
train_label=1_precision_sent: 0.9949653870358716
train_label=1_recall_sent: 0.9941609773625584
train_label=1_f-score_sent: 0.9945630195461693
train_precision_macro_sent: 0.986344927925064
train_recall_macro_sent: 0.9874551878906295
train_f-score_macro_sent: 0.9868988085546189
train_precision_micro_sent: 0.9913823801723524
train_recall_micro_sent: 0.9913823801723524
train_f-score_micro_sent: 0.9913823801723524
train_label=O_precision_tok: 0.9983962736947614
train_label=O_recall_tok: 0.9985552371180224
train_label=O_f-score_tok: 0.9984757490794055
train_label=LOC_precision_tok: 0.9782268735715145
train_label=LOC_recall_tok: 0.9801132939616729
train_label=LOC_f-score_tok: 0.9791691751956652
train_label=MISC_precision_tok: 0.9606420404573439
train_label=MISC_recall_tok: 0.951230132810799
train_label=MISC_f-score_tok: 0.9559129198118368
train_label=ORG_precision_tok: 0.970638170378508
train_label=ORG_recall_tok: 0.9694763092269326
train_label=ORG_f-score_tok: 0.9700568919053798
train_label=PER_precision_tok: 0.9877041823730031
train_label=PER_recall_tok: 0.9889468008626887
train_label=PER_f-score_tok: 0.9883251010327795
train_precision_macro_tok: 0.9791215080950261
train_recall_macro_tok: 0.9776643547960232
train_f-score_macro_tok: 0.9783879674050133
train_precision_micro_tok: 0.9947795168474765
train_recall_micro_tok: 0.9947795168474765
train_f-score_micro_tok: 0.9947795168474765
train_time: 159.95848298072815
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9777    0.9807    0.9792      2909
           1     0.9950    0.9942    0.9946     11132

   micro avg     0.9914    0.9914    0.9914     14041
   macro avg     0.9863    0.9875    0.9869     14041
weighted avg     0.9914    0.9914    0.9914     14041

F1-macro sent:  0.9868988085546189
F1-micro sent:  0.9913823801723524
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9986    0.9985    169578
         LOC     0.9782    0.9801    0.9792      8297
        MISC     0.9606    0.9512    0.9559      4593
         ORG     0.9706    0.9695    0.9701     10025
         PER     0.9877    0.9889    0.9883     11128

   micro avg     0.9948    0.9948    0.9948    203621
   macro avg     0.9791    0.9777    0.9784    203621
weighted avg     0.9948    0.9948    0.9948    203621

F1-macro tok:  0.9783879674050133
F1-micro tok:  0.9947795168474765
**************************************************
dev_cost_sum: 81271.57586288452
dev_cost_avg: 25.00663872704139
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50813.0
dev_accuracy_tok: 0.9893111638954869
dev_label=0_precision_sent: 0.9783616692426584
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9798761609907122
dev_label=1_precision_sent: 0.9953899346907414
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9950076804915514
dev_precision_macro_sent: 0.9868758019666999
dev_recall_macro_sent: 0.9880105343034415
dev_f-score_macro_sent: 0.9874419207411318
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9964037177151931
dev_label=O_recall_tok: 0.9978717930728034
dev_label=O_f-score_tok: 0.9971372150360478
dev_label=LOC_precision_tok: 0.9476879962634283
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.9582054309327036
dev_label=MISC_precision_tok: 0.897736143637783
dev_label=MISC_recall_tok: 0.9069400630914827
dev_label=MISC_f-score_tok: 0.9023146331894861
dev_label=ORG_precision_tok: 0.9557477110885045
dev_label=ORG_recall_tok: 0.8981835564053537
dev_label=ORG_f-score_tok: 0.9260719566288811
dev_label=PER_precision_tok: 0.9793781725888325
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9798444691318838
dev_precision_macro_tok: 0.9553907482587484
dev_recall_macro_tok: 0.9504531105509058
dev_f-score_macro_tok: 0.9527147409838005
dev_precision_micro_tok: 0.9893111638954869
dev_recall_micro_tok: 0.9893111638954869
dev_f-score_micro_tok: 0.9893111638954869
dev_time: 14.646677494049072
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9784    0.9814    0.9799       645
           1     0.9954    0.9946    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9869    0.9880    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874419207411318
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9979    0.9971     42759
         LOC     0.9477    0.9690    0.9582      2094
        MISC     0.8977    0.9069    0.9023      1268
         ORG     0.9557    0.8982    0.9261      2092
         PER     0.9794    0.9803    0.9798      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9554    0.9505    0.9527     51362
weighted avg     0.9893    0.9893    0.9893     51362

F1-macro tok:  0.9527147409838005
F1-micro tok:  0.9893111638954869
**************************************************
Best epoch: 31
**************************************************

EPOCH: 32
Learning rate: 1.000000
train_cost_sum: 290758.07821655273
train_cost_avg: 20.70778991642709
train_count_sent: 14041.0
train_total_correct_sent: 13932.0
train_accuracy_sent: 0.9922370201552596
train_count_tok: 203621.0
train_total_correct_tok: 202571.0
train_accuracy_tok: 0.9948433609500003
train_label=0_precision_sent: 0.9814305364511692
train_label=0_recall_sent: 0.9810931591612237
train_label=0_f-score_sent: 0.9812618188069451
train_label=1_precision_sent: 0.9950597323273151
train_label=1_recall_sent: 0.9951491196550485
train_label=1_f-score_sent: 0.995104423983831
train_precision_macro_sent: 0.9882451343892422
train_recall_macro_sent: 0.9881211394081362
train_f-score_macro_sent: 0.988183121395388
train_precision_micro_sent: 0.9922370201552596
train_recall_micro_sent: 0.9922370201552596
train_f-score_micro_sent: 0.9922370201552596
train_label=O_precision_tok: 0.9982608080462684
train_label=O_recall_tok: 0.9985021641958273
train_label=O_f-score_tok: 0.9983814715342412
train_label=LOC_precision_tok: 0.9791641575334217
train_label=LOC_recall_tok: 0.9798722429793901
train_label=LOC_f-score_tok: 0.9795180722891565
train_label=MISC_precision_tok: 0.9616143891204212
train_label=MISC_recall_tok: 0.9544959721315045
train_label=MISC_f-score_tok: 0.958041958041958
train_label=ORG_precision_tok: 0.9732946589317863
train_label=ORG_recall_tok: 0.9706733167082294
train_label=ORG_f-score_tok: 0.9719822204464866
train_label=PER_precision_tok: 0.9874349308921199
train_label=PER_recall_tok: 0.9886772106398275
train_label=PER_f-score_tok: 0.9880556802873821
train_precision_macro_tok: 0.9799537889048036
train_recall_macro_tok: 0.9784441813309558
train_f-score_macro_tok: 0.9791958805198447
train_precision_micro_tok: 0.9948433609500003
train_recall_micro_tok: 0.9948433609500003
train_f-score_micro_tok: 0.9948433609500003
train_time: 107.28593277931213
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9814    0.9811    0.9813      2909
           1     0.9951    0.9951    0.9951     11132

   micro avg     0.9922    0.9922    0.9922     14041
   macro avg     0.9882    0.9881    0.9882     14041
weighted avg     0.9922    0.9922    0.9922     14041

F1-macro sent:  0.988183121395388
F1-micro sent:  0.9922370201552596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9985    0.9984    169578
         LOC     0.9792    0.9799    0.9795      8297
        MISC     0.9616    0.9545    0.9580      4593
         ORG     0.9733    0.9707    0.9720     10025
         PER     0.9874    0.9887    0.9881     11128

   micro avg     0.9948    0.9948    0.9948    203621
   macro avg     0.9800    0.9784    0.9792    203621
weighted avg     0.9948    0.9948    0.9948    203621

F1-macro tok:  0.9791958805198447
F1-micro tok:  0.9948433609500003
**************************************************
dev_cost_sum: 81234.46249389648
dev_cost_avg: 24.995219228891226
dev_count_sent: 3250.0
dev_total_correct_sent: 3226.0
dev_accuracy_sent: 0.9926153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50819.0
dev_accuracy_tok: 0.9894279817764106
dev_label=0_precision_sent: 0.9920760697305864
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9811912225705329
dev_label=1_precision_sent: 0.9927453226422298
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9954058192955589
dev_precision_macro_sent: 0.9924106961864081
dev_recall_macro_sent: 0.9843116249311847
dev_f-score_macro_sent: 0.9882985209330459
dev_precision_micro_sent: 0.9926153846153846
dev_recall_micro_sent: 0.9926153846153846
dev_f-score_micro_sent: 0.9926153846153846
dev_label=O_precision_tok: 0.995684023889511
dev_label=O_recall_tok: 0.9981290488552118
dev_label=O_f-score_tok: 0.9969050371979491
dev_label=LOC_precision_tok: 0.9591642924976258
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9619047619047619
dev_label=MISC_precision_tok: 0.9262634631317316
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.9034343434343434
dev_label=ORG_precision_tok: 0.9435922810489856
dev_label=ORG_recall_tok: 0.9115678776290631
dev_label=ORG_f-score_tok: 0.9273036712861659
dev_label=PER_precision_tok: 0.9781921618204804
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9805163947410106
dev_precision_macro_tok: 0.9605792444776668
dev_recall_macro_tok: 0.9477826062951019
dev_f-score_macro_tok: 0.9540128417128463
dev_precision_micro_tok: 0.9894279817764106
dev_recall_micro_tok: 0.9894279817764106
dev_f-score_micro_tok: 0.9894279817764106
dev_time: 6.874793767929077
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9921    0.9705    0.9812       645
           1     0.9927    0.9981    0.9954      2605

   micro avg     0.9926    0.9926    0.9926      3250
   macro avg     0.9924    0.9843    0.9883      3250
weighted avg     0.9926    0.9926    0.9926      3250

F1-macro sent:  0.9882985209330459
F1-micro sent:  0.9926153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9981    0.9969     42759
         LOC     0.9592    0.9647    0.9619      2094
        MISC     0.9263    0.8817    0.9034      1268
         ORG     0.9436    0.9116    0.9273      2092
         PER     0.9782    0.9829    0.9805      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9606    0.9478    0.9540     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9540128417128463
F1-micro tok:  0.9894279817764106
**************************************************
Best epoch: 32
**************************************************

EPOCH: 33
Learning rate: 1.000000
train_cost_sum: 289835.423828125
train_cost_avg: 20.642078472197493
train_count_sent: 14041.0
train_total_correct_sent: 13928.0
train_accuracy_sent: 0.9919521401609572
train_count_tok: 203621.0
train_total_correct_tok: 202662.0
train_accuracy_tok: 0.9952902696676669
train_label=0_precision_sent: 0.9797529169526424
train_label=0_recall_sent: 0.981436919903747
train_label=0_f-score_sent: 0.980594195431908
train_label=1_precision_sent: 0.9951469398759774
train_label=1_recall_sent: 0.994699964067553
train_label=1_f-score_sent: 0.9949234017700707
train_precision_macro_sent: 0.9874499284143099
train_recall_macro_sent: 0.98806844198565
train_f-score_macro_sent: 0.9877587986009893
train_precision_micro_sent: 0.9919521401609572
train_recall_micro_sent: 0.9919521401609572
train_f-score_micro_sent: 0.9919521401609572
train_label=O_precision_tok: 0.9984200907858279
train_label=O_recall_tok: 0.9987262498673177
train_label=O_f-score_tok: 0.998573146859744
train_label=LOC_precision_tok: 0.9804866297277764
train_label=LOC_recall_tok: 0.9810774978908039
train_label=LOC_f-score_tok: 0.9807819748177601
train_label=MISC_precision_tok: 0.9674080598987007
train_label=MISC_recall_tok: 0.9564554757239278
train_label=MISC_f-score_tok: 0.9619005911977229
train_label=ORG_precision_tok: 0.9749275796623714
train_label=ORG_recall_tok: 0.97356608478803
train_label=ORG_f-score_tok: 0.9742463565581952
train_label=PER_precision_tok: 0.9883271976295233
train_label=PER_recall_tok: 0.9891265276779295
train_label=PER_f-score_tok: 0.9887267011003816
train_precision_macro_tok: 0.98191391154084
train_recall_macro_tok: 0.9797903671896018
train_f-score_macro_tok: 0.9808457541067608
train_precision_micro_tok: 0.9952902696676669
train_recall_micro_tok: 0.9952902696676669
train_f-score_micro_tok: 0.9952902696676669
train_time: 83.9336724281311
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9798    0.9814    0.9806      2909
           1     0.9951    0.9947    0.9949     11132

   micro avg     0.9920    0.9920    0.9920     14041
   macro avg     0.9874    0.9881    0.9878     14041
weighted avg     0.9920    0.9920    0.9920     14041

F1-macro sent:  0.9877587986009893
F1-micro sent:  0.9919521401609572
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9987    0.9986    169578
         LOC     0.9805    0.9811    0.9808      8297
        MISC     0.9674    0.9565    0.9619      4593
         ORG     0.9749    0.9736    0.9742     10025
         PER     0.9883    0.9891    0.9887     11128

   micro avg     0.9953    0.9953    0.9953    203621
   macro avg     0.9819    0.9798    0.9808    203621
weighted avg     0.9953    0.9953    0.9953    203621

F1-macro tok:  0.9808457541067608
F1-micro tok:  0.9952902696676669
**************************************************
dev_cost_sum: 81135.31385040283
dev_cost_avg: 24.964711953970102
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50836.0
dev_accuracy_tok: 0.9897589657723609
dev_label=0_precision_sent: 0.9678899082568807
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9745958429561201
dev_label=1_precision_sent: 0.9953775038520801
dev_label=1_recall_sent: 0.9919385796545106
dev_label=1_f-score_sent: 0.9936550663333974
dev_precision_macro_sent: 0.9816337060544804
dev_recall_macro_sent: 0.9866669642458599
dev_f-score_macro_sent: 0.9841254546447588
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.99689099791954
dev_label=O_recall_tok: 0.9973572815079866
dev_label=O_f-score_tok: 0.9971240852018985
dev_label=LOC_precision_tok: 0.9608778625954199
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.9613365155131265
dev_label=MISC_precision_tok: 0.9156626506024096
dev_label=MISC_recall_tok: 0.8990536277602523
dev_label=MISC_f-score_tok: 0.9072821329088737
dev_label=ORG_precision_tok: 0.9374090247452693
dev_label=ORG_recall_tok: 0.9235181644359465
dev_label=ORG_f-score_tok: 0.930411750541777
dev_label=PER_precision_tok: 0.9757937755422823
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9807266982622432
dev_precision_macro_tok: 0.9573268622809842
dev_recall_macro_tok: 0.953486885865128
dev_f-score_macro_tok: 0.9553762364855837
dev_precision_micro_tok: 0.9897589657723609
dev_recall_micro_tok: 0.9897589657723609
dev_f-score_micro_tok: 0.9897589657723609
dev_time: 6.850472927093506
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9679    0.9814    0.9746       645
           1     0.9954    0.9919    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9816    0.9867    0.9841      3250
weighted avg     0.9899    0.9898    0.9899      3250

F1-macro sent:  0.9841254546447588
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9974    0.9971     42759
         LOC     0.9609    0.9618    0.9613      2094
        MISC     0.9157    0.8991    0.9073      1268
         ORG     0.9374    0.9235    0.9304      2092
         PER     0.9758    0.9857    0.9807      3149

   micro avg     0.9898    0.9898    0.9898     51362
   macro avg     0.9573    0.9535    0.9554     51362
weighted avg     0.9897    0.9898    0.9897     51362

F1-macro tok:  0.9553762364855837
F1-micro tok:  0.9897589657723609
**************************************************
Best epoch: 32
**************************************************

EPOCH: 34
Learning rate: 1.000000
train_cost_sum: 288969.4892272949
train_cost_avg: 20.580406611159813
train_count_sent: 14041.0
train_total_correct_sent: 13929.0
train_accuracy_sent: 0.9920233601595329
train_count_tok: 203621.0
train_total_correct_tok: 202648.0
train_accuracy_tok: 0.9952215144803336
train_label=0_precision_sent: 0.9791024323398424
train_label=0_recall_sent: 0.9824682021313166
train_label=0_f-score_sent: 0.9807824296499656
train_label=1_precision_sent: 0.9954144937960798
train_label=1_recall_sent: 0.9945203018325548
train_label=1_f-score_sent: 0.994967196908421
train_precision_macro_sent: 0.9872584630679611
train_recall_macro_sent: 0.9884942519819357
train_f-score_macro_sent: 0.9878748132791932
train_precision_micro_sent: 0.9920233601595329
train_recall_micro_sent: 0.9920233601595329
train_f-score_micro_sent: 0.9920233601595329
train_label=O_precision_tok: 0.9985965326099776
train_label=O_recall_tok: 0.9986083100402174
train_label=O_f-score_tok: 0.998602421290372
train_label=LOC_precision_tok: 0.9783601827362347
train_label=LOC_recall_tok: 0.9808364469085211
train_label=LOC_f-score_tok: 0.9795967499247668
train_label=MISC_precision_tok: 0.9666812801402893
train_label=MISC_recall_tok: 0.9601567602873938
train_label=MISC_f-score_tok: 0.9634079737848171
train_label=ORG_precision_tok: 0.9728407388916626
train_label=ORG_recall_tok: 0.9718703241895262
train_label=ORG_f-score_tok: 0.9723552894211578
train_label=PER_precision_tok: 0.9882469047191818
train_label=PER_recall_tok: 0.9898454349388929
train_label=PER_f-score_tok: 0.9890455239292447
train_precision_macro_tok: 0.9809451278194693
train_recall_macro_tok: 0.9802634552729103
train_f-score_macro_tok: 0.9806015916700718
train_precision_micro_tok: 0.9952215144803336
train_recall_micro_tok: 0.9952215144803336
train_f-score_micro_tok: 0.9952215144803336
train_time: 84.2002341747284
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9791    0.9825    0.9808      2909
           1     0.9954    0.9945    0.9950     11132

   micro avg     0.9920    0.9920    0.9920     14041
   macro avg     0.9873    0.9885    0.9879     14041
weighted avg     0.9920    0.9920    0.9920     14041

F1-macro sent:  0.9878748132791932
F1-micro sent:  0.9920233601595329
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9986    0.9986    0.9986    169578
         LOC     0.9784    0.9808    0.9796      8297
        MISC     0.9667    0.9602    0.9634      4593
         ORG     0.9728    0.9719    0.9724     10025
         PER     0.9882    0.9898    0.9890     11128

   micro avg     0.9952    0.9952    0.9952    203621
   macro avg     0.9809    0.9803    0.9806    203621
weighted avg     0.9952    0.9952    0.9952    203621

F1-macro tok:  0.9806015916700718
F1-micro tok:  0.9952215144803336
**************************************************
dev_cost_sum: 80905.47500610352
dev_cost_avg: 24.89399230957031
dev_count_sent: 3250.0
dev_total_correct_sent: 3226.0
dev_accuracy_sent: 0.9926153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50825.0
dev_accuracy_tok: 0.9895447996573342
dev_label=0_precision_sent: 0.988976377952756
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9812500000000001
dev_label=1_precision_sent: 0.9934990439770555
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9954022988505747
dev_precision_macro_sent: 0.9912377109649058
dev_recall_macro_sent: 0.985478135368775
dev_f-score_macro_sent: 0.9883261494252874
dev_precision_micro_sent: 0.9926153846153846
dev_recall_micro_sent: 0.9926153846153846
dev_f-score_micro_sent: 0.9926153846153846
dev_label=O_precision_tok: 0.9967289719626168
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9972066059678117
dev_label=LOC_precision_tok: 0.9503512880562061
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.9595649089619296
dev_label=MISC_precision_tok: 0.9078740157480315
dev_label=MISC_recall_tok: 0.9093059936908517
dev_label=MISC_f-score_tok: 0.9085894405043341
dev_label=ORG_precision_tok: 0.9538773441459706
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9259532595325952
dev_label=PER_precision_tok: 0.9739321608040201
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9793147007737248
dev_precision_macro_tok: 0.956552756143369
dev_recall_macro_tok: 0.9520648556966984
dev_f-score_macro_tok: 0.9541257831480792
dev_precision_micro_tok: 0.9895447996573342
dev_recall_micro_tok: 0.9895447996573342
dev_f-score_micro_tok: 0.9895447996573342
dev_time: 6.876402378082275
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9890    0.9736    0.9813       645
           1     0.9935    0.9973    0.9954      2605

   micro avg     0.9926    0.9926    0.9926      3250
   macro avg     0.9912    0.9855    0.9883      3250
weighted avg     0.9926    0.9926    0.9926      3250

F1-macro sent:  0.9883261494252874
F1-micro sent:  0.9926153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9977    0.9972     42759
         LOC     0.9504    0.9690    0.9596      2094
        MISC     0.9079    0.9093    0.9086      1268
         ORG     0.9539    0.8996    0.9260      2092
         PER     0.9739    0.9848    0.9793      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9566    0.9521    0.9541     51362
weighted avg     0.9895    0.9895    0.9895     51362

F1-macro tok:  0.9541257831480792
F1-micro tok:  0.9895447996573342
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 1.000000
train_cost_sum: 287986.1173400879
train_cost_avg: 20.510370866753643
train_count_sent: 14041.0
train_total_correct_sent: 13935.0
train_accuracy_sent: 0.9924506801509864
train_count_tok: 203621.0
train_total_correct_tok: 202728.0
train_accuracy_tok: 0.9956144012650955
train_label=0_precision_sent: 0.9801301815690305
train_label=0_recall_sent: 0.9834994843588862
train_label=0_f-score_sent: 0.981811942347289
train_label=1_precision_sent: 0.995684229455134
train_label=1_recall_sent: 0.9947897951850521
train_label=1_f-score_sent: 0.9952368113597555
train_precision_macro_sent: 0.9879072055120823
train_recall_macro_sent: 0.9891446397719692
train_f-score_macro_sent: 0.9885243768535222
train_precision_micro_sent: 0.9924506801509864
train_recall_micro_sent: 0.9924506801509864
train_f-score_micro_sent: 0.9924506801509864
train_label=O_precision_tok: 0.9986438119497857
train_label=O_recall_tok: 0.9987321468586727
train_label=O_f-score_tok: 0.9986879774509024
train_label=LOC_precision_tok: 0.9810957254665864
train_label=LOC_recall_tok: 0.9820417018199349
train_label=LOC_f-score_tok: 0.9815684857246114
train_label=MISC_precision_tok: 0.9657130377811749
train_label=MISC_recall_tok: 0.9627694317439582
train_label=MISC_f-score_tok: 0.9642389882250326
train_label=ORG_precision_tok: 0.9765164384930549
train_label=ORG_recall_tok: 0.9747630922693267
train_label=ORG_f-score_tok: 0.9756389776357828
train_label=PER_precision_tok: 0.9897638502289665
train_label=PER_recall_tok: 0.9905643421998562
train_label=PER_f-score_tok: 0.9901639344262295
train_precision_macro_tok: 0.9823465727839137
train_recall_macro_tok: 0.9817741429783498
train_f-score_macro_tok: 0.9820596726925117
train_precision_micro_tok: 0.9956144012650955
train_recall_micro_tok: 0.9956144012650955
train_f-score_micro_tok: 0.9956144012650955
train_time: 84.77049326896667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9801    0.9835    0.9818      2909
           1     0.9957    0.9948    0.9952     11132

   micro avg     0.9925    0.9925    0.9925     14041
   macro avg     0.9879    0.9891    0.9885     14041
weighted avg     0.9925    0.9925    0.9925     14041

F1-macro sent:  0.9885243768535222
F1-micro sent:  0.9924506801509864
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9986    0.9987    0.9987    169578
         LOC     0.9811    0.9820    0.9816      8297
        MISC     0.9657    0.9628    0.9642      4593
         ORG     0.9765    0.9748    0.9756     10025
         PER     0.9898    0.9906    0.9902     11128

   micro avg     0.9956    0.9956    0.9956    203621
   macro avg     0.9823    0.9818    0.9821    203621
weighted avg     0.9956    0.9956    0.9956    203621

F1-macro tok:  0.9820596726925117
F1-micro tok:  0.9956144012650955
**************************************************
dev_cost_sum: 80860.69108581543
dev_cost_avg: 24.880212641789363
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50821.0
dev_accuracy_tok: 0.9894669210700517
dev_label=0_precision_sent: 0.9606060606060606
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.971647509578544
dev_label=1_precision_sent: 0.9957528957528957
dev_label=1_recall_sent: 0.9900191938579654
dev_label=1_f-score_sent: 0.9928777670837343
dev_precision_macro_sent: 0.9781794781794781
dev_recall_macro_sent: 0.986482465146037
dev_f-score_macro_sent: 0.9822626383311391
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9967513497090238
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9970775956795176
dev_label=LOC_precision_tok: 0.9476635514018692
dev_label=LOC_recall_tok: 0.9684813753581661
dev_label=LOC_f-score_tok: 0.9579593764761455
dev_label=MISC_precision_tok: 0.9140562248995984
dev_label=MISC_recall_tok: 0.8974763406940063
dev_label=MISC_f-score_tok: 0.9056904098686829
dev_label=ORG_precision_tok: 0.948654037886341
dev_label=ORG_recall_tok: 0.9096558317399618
dev_label=ORG_f-score_tok: 0.928745729624207
dev_label=PER_precision_tok: 0.9748743718592965
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9802621190588978
dev_precision_macro_tok: 0.9563999071512258
dev_recall_macro_tok: 0.9517454704410895
dev_f-score_macro_tok: 0.9539470461414903
dev_precision_micro_tok: 0.9894669210700517
dev_recall_micro_tok: 0.9894669210700517
dev_f-score_micro_tok: 0.9894669210700517
dev_time: 6.881565809249878
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9606    0.9829    0.9716       645
           1     0.9958    0.9900    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9782    0.9865    0.9823      3250
weighted avg     0.9888    0.9886    0.9887      3250

F1-macro sent:  0.9822626383311391
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9974    0.9971     42759
         LOC     0.9477    0.9685    0.9580      2094
        MISC     0.9141    0.8975    0.9057      1268
         ORG     0.9487    0.9097    0.9287      2092
         PER     0.9749    0.9857    0.9803      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9564    0.9517    0.9539     51362
weighted avg     0.9894    0.9895    0.9894     51362

F1-macro tok:  0.9539470461414903
F1-micro tok:  0.9894669210700517
**************************************************
Best epoch: 34
**************************************************

EPOCH: 36
Learning rate: 1.000000
train_cost_sum: 287304.4039001465
train_cost_avg: 20.461819236532047
train_count_sent: 14041.0
train_total_correct_sent: 13939.0
train_accuracy_sent: 0.9927355601452887
train_count_tok: 203621.0
train_total_correct_tok: 202699.0
train_accuracy_tok: 0.9954719798056193
train_label=0_precision_sent: 0.9811450119986287
train_label=0_recall_sent: 0.9838432451014094
train_label=0_f-score_sent: 0.9824922760041195
train_label=1_precision_sent: 0.9957749011147069
train_label=1_recall_sent: 0.9950592885375494
train_label=1_f-score_sent: 0.9954169662113588
train_precision_macro_sent: 0.9884599565566679
train_recall_macro_sent: 0.9894512668194795
train_f-score_macro_sent: 0.9889546211077391
train_precision_micro_sent: 0.9927355601452887
train_recall_micro_sent: 0.9927355601452887
train_f-score_micro_sent: 0.9927355601452887
train_label=O_precision_tok: 0.9985612359219294
train_label=O_recall_tok: 0.9986318980056376
train_label=O_f-score_tok: 0.9985965657137466
train_label=LOC_precision_tok: 0.9812093471452662
train_label=LOC_recall_tok: 0.9818006508376521
train_label=LOC_f-score_tok: 0.9815049099343334
train_label=MISC_precision_tok: 0.9700087565674256
train_label=MISC_recall_tok: 0.9647289353363815
train_label=MISC_f-score_tok: 0.9673616417421679
train_label=ORG_precision_tok: 0.9734769169408715
train_label=ORG_recall_tok: 0.9738653366583541
train_label=ORG_f-score_tok: 0.9736710880622319
train_label=PER_precision_tok: 0.9893100970176069
train_label=PER_recall_tok: 0.9896657081236521
train_label=PER_f-score_tok: 0.9894878706199461
train_precision_macro_tok: 0.9825132707186199
train_recall_macro_tok: 0.9817385057923355
train_f-score_macro_tok: 0.9821244152144851
train_precision_micro_tok: 0.9954719798056193
train_recall_micro_tok: 0.9954719798056193
train_f-score_micro_tok: 0.9954719798056193
train_time: 84.04089522361755
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9811    0.9838    0.9825      2909
           1     0.9958    0.9951    0.9954     11132

   micro avg     0.9927    0.9927    0.9927     14041
   macro avg     0.9885    0.9895    0.9890     14041
weighted avg     0.9927    0.9927    0.9927     14041

F1-macro sent:  0.9889546211077391
F1-micro sent:  0.9927355601452887
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9986    0.9986    0.9986    169578
         LOC     0.9812    0.9818    0.9815      8297
        MISC     0.9700    0.9647    0.9674      4593
         ORG     0.9735    0.9739    0.9737     10025
         PER     0.9893    0.9897    0.9895     11128

   micro avg     0.9955    0.9955    0.9955    203621
   macro avg     0.9825    0.9817    0.9821    203621
weighted avg     0.9955    0.9955    0.9955    203621

F1-macro tok:  0.9821244152144851
F1-micro tok:  0.9954719798056193
**************************************************
dev_cost_sum: 80830.50482177734
dev_cost_avg: 24.870924560546875
dev_count_sent: 3250.0
dev_total_correct_sent: 3228.0
dev_accuracy_sent: 0.9932307692307693
dev_count_tok: 51362.0
dev_total_correct_tok: 50849.0
dev_accuracy_tok: 0.9900120711810287
dev_label=0_precision_sent: 0.989010989010989
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.982839313572543
dev_label=1_precision_sent: 0.9942594718714122
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9957838252203909
dev_precision_macro_sent: 0.9916352304412006
dev_recall_macro_sent: 0.9870285229656742
dev_f-score_macro_sent: 0.9893115693964669
dev_precision_micro_sent: 0.9932307692307693
dev_recall_micro_sent: 0.9932307692307693
dev_f-score_micro_sent: 0.9932307692307693
dev_label=O_precision_tok: 0.9965431868080534
dev_label=O_recall_tok: 0.9978250192941837
dev_label=O_f-score_tok: 0.9971836911175254
dev_label=LOC_precision_tok: 0.9562146892655368
dev_label=LOC_recall_tok: 0.9699140401146131
dev_label=LOC_f-score_tok: 0.9630156472261735
dev_label=MISC_precision_tok: 0.9241323648103309
dev_label=MISC_recall_tok: 0.9029968454258676
dev_label=MISC_f-score_tok: 0.9134423613881133
dev_label=ORG_precision_tok: 0.9513052208835341
dev_label=ORG_recall_tok: 0.905831739961759
dev_label=ORG_f-score_tok: 0.9280117531831537
dev_label=PER_precision_tok: 0.9746320075164422
dev_label=PER_recall_tok: 0.9882502381708479
dev_label=PER_f-score_tok: 0.9813938820561336
dev_precision_macro_tok: 0.9605654938567796
dev_recall_macro_tok: 0.9529635765934543
dev_f-score_macro_tok: 0.9566094669942199
dev_precision_micro_tok: 0.9900120711810287
dev_recall_micro_tok: 0.9900120711810287
dev_f-score_micro_tok: 0.9900120711810287
dev_time: 6.904455661773682
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9890    0.9767    0.9828       645
           1     0.9943    0.9973    0.9958      2605

   micro avg     0.9932    0.9932    0.9932      3250
   macro avg     0.9916    0.9870    0.9893      3250
weighted avg     0.9932    0.9932    0.9932      3250

F1-macro sent:  0.9893115693964669
F1-micro sent:  0.9932307692307693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9978    0.9972     42759
         LOC     0.9562    0.9699    0.9630      2094
        MISC     0.9241    0.9030    0.9134      1268
         ORG     0.9513    0.9058    0.9280      2092
         PER     0.9746    0.9883    0.9814      3149

   micro avg     0.9900    0.9900    0.9900     51362
   macro avg     0.9606    0.9530    0.9566     51362
weighted avg     0.9899    0.9900    0.9899     51362

F1-macro tok:  0.9566094669942199
F1-micro tok:  0.9900120711810287
**************************************************
Best epoch: 36
**************************************************

EPOCH: 37
Learning rate: 1.000000
train_cost_sum: 286363.33795166016
train_cost_avg: 20.394796521021306
train_count_sent: 14041.0
train_total_correct_sent: 13938.0
train_accuracy_sent: 0.9926643401467132
train_count_tok: 203621.0
train_total_correct_tok: 202767.0
train_accuracy_tok: 0.9958059335726669
train_label=0_precision_sent: 0.9804794520547945
train_label=0_recall_sent: 0.9841870058439326
train_label=0_f-score_sent: 0.9823297306570594
train_label=1_precision_sent: 0.995863681323622
train_label=1_recall_sent: 0.9948796263025512
train_label=1_f-score_sent: 0.9953714105963242
train_precision_macro_sent: 0.9881715666892082
train_recall_macro_sent: 0.9895333160732419
train_f-score_macro_sent: 0.9888505706266918
train_precision_micro_sent: 0.9926643401467132
train_recall_micro_sent: 0.9926643401467132
train_f-score_micro_sent: 0.9926643401467132
train_label=O_precision_tok: 0.9988383201047281
train_label=O_recall_tok: 0.9988618806684829
train_label=O_f-score_tok: 0.9988501002476707
train_label=LOC_precision_tok: 0.9799133990858793
train_label=LOC_recall_tok: 0.9819211763287935
train_label=LOC_f-score_tok: 0.9809162603094334
train_label=MISC_precision_tok: 0.9721307877989905
train_label=MISC_recall_tok: 0.9645112127150011
train_label=MISC_f-score_tok: 0.9683060109289618
train_label=ORG_precision_tok: 0.974810832337714
train_label=ORG_recall_tok: 0.9766583541147132
train_label=ORG_f-score_tok: 0.9757337186705866
train_label=PER_precision_tok: 0.990111470693995
train_label=PER_recall_tok: 0.9897555715312725
train_label=PER_f-score_tok: 0.9899334891245731
train_precision_macro_tok: 0.9831609620042613
train_recall_macro_tok: 0.9823416390716526
train_f-score_macro_tok: 0.9827479158562451
train_precision_micro_tok: 0.9958059335726669
train_recall_micro_tok: 0.9958059335726669
train_f-score_micro_tok: 0.9958059335726669
train_time: 84.27833652496338
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9805    0.9842    0.9823      2909
           1     0.9959    0.9949    0.9954     11132

   micro avg     0.9927    0.9927    0.9927     14041
   macro avg     0.9882    0.9895    0.9889     14041
weighted avg     0.9927    0.9927    0.9927     14041

F1-macro sent:  0.9888505706266918
F1-micro sent:  0.9926643401467132
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9989    0.9989    169578
         LOC     0.9799    0.9819    0.9809      8297
        MISC     0.9721    0.9645    0.9683      4593
         ORG     0.9748    0.9767    0.9757     10025
         PER     0.9901    0.9898    0.9899     11128

   micro avg     0.9958    0.9958    0.9958    203621
   macro avg     0.9832    0.9823    0.9827    203621
weighted avg     0.9958    0.9958    0.9958    203621

F1-macro tok:  0.9827479158562451
F1-micro tok:  0.9958059335726669
**************************************************
dev_cost_sum: 80617.50646972656
dev_cost_avg: 24.80538660606971
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50834.0
dev_accuracy_tok: 0.9897200264787197
dev_label=0_precision_sent: 0.9723502304147466
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9768518518518517
dev_label=1_precision_sent: 0.9953828395536745
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9942352036894696
dev_precision_macro_sent: 0.9838665349842105
dev_recall_macro_sent: 0.9872427799848235
dev_f-score_macro_sent: 0.9855435277706607
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9965893428644848
dev_label=O_recall_tok: 0.9977080848476344
dev_label=O_f-score_tok: 0.9971484000654466
dev_label=LOC_precision_tok: 0.9552309142318567
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9615749525616698
dev_label=MISC_precision_tok: 0.9282178217821783
dev_label=MISC_recall_tok: 0.887223974763407
dev_label=MISC_f-score_tok: 0.907258064516129
dev_label=ORG_precision_tok: 0.9511709018435476
dev_label=ORG_recall_tok: 0.9125239005736138
dev_label=ORG_f-score_tok: 0.9314466943156867
dev_label=PER_precision_tok: 0.9682638456751711
dev_label=PER_recall_tok: 0.9882502381708479
dev_label=PER_f-score_tok: 0.9781549583529782
dev_precision_macro_tok: 0.9598945652794477
dev_recall_macro_tok: 0.9507420037589707
dev_f-score_macro_tok: 0.955116613962382
dev_precision_micro_tok: 0.9897200264787197
dev_recall_micro_tok: 0.9897200264787197
dev_f-score_micro_tok: 0.9897200264787197
dev_time: 6.933494806289673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9724    0.9814    0.9769       645
           1     0.9954    0.9931    0.9942      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9839    0.9872    0.9855      3250
weighted avg     0.9908    0.9908    0.9908      3250

F1-macro sent:  0.9855435277706607
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9977    0.9971     42759
         LOC     0.9552    0.9680    0.9616      2094
        MISC     0.9282    0.8872    0.9073      1268
         ORG     0.9512    0.9125    0.9314      2092
         PER     0.9683    0.9883    0.9782      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9599    0.9507    0.9551     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.955116613962382
F1-micro tok:  0.9897200264787197
**************************************************
Best epoch: 36
**************************************************

EPOCH: 38
Learning rate: 1.000000
train_cost_sum: 285521.17306518555
train_cost_avg: 20.334817539006163
train_count_sent: 14041.0
train_total_correct_sent: 13946.0
train_accuracy_sent: 0.993234100135318
train_count_tok: 203621.0
train_total_correct_tok: 202832.0
train_accuracy_tok: 0.9961251540852859
train_label=0_precision_sent: 0.9821795750514051
train_label=0_recall_sent: 0.9852182880715022
train_label=0_f-score_sent: 0.983696584863566
train_label=1_precision_sent: 0.9961341364739729
train_label=1_recall_sent: 0.9953287818900467
train_label=1_f-score_sent: 0.9957312963379016
train_precision_macro_sent: 0.989156855762689
train_recall_macro_sent: 0.9902735349807745
train_f-score_macro_sent: 0.9897139406007338
train_precision_micro_sent: 0.993234100135318
train_recall_micro_sent: 0.993234100135318
train_f-score_micro_sent: 0.993234100135318
train_label=O_precision_tok: 0.9988500459981601
train_label=O_recall_tok: 0.9988147047376429
train_label=O_f-score_tok: 0.9988323750552852
train_label=LOC_precision_tok: 0.9861228430071196
train_label=LOC_recall_tok: 0.984934313607328
train_label=LOC_f-score_tok: 0.9855282199710564
train_label=MISC_precision_tok: 0.9713598600787058
train_label=MISC_recall_tok: 0.9673416067929458
train_label=MISC_f-score_tok: 0.9693465692156649
train_label=ORG_precision_tok: 0.9763019018221647
train_label=ORG_recall_tok: 0.9780548628428928
train_label=ORG_f-score_tok: 0.9771775961730118
train_label=PER_precision_tok: 0.9901301031852848
train_label=PER_recall_tok: 0.9916427030913012
train_label=PER_f-score_tok: 0.9908858258878462
train_precision_macro_tok: 0.9845529508182869
train_recall_macro_tok: 0.9841576382144221
train_f-score_macro_tok: 0.9843541172605729
train_precision_micro_tok: 0.9961251540852859
train_recall_micro_tok: 0.9961251540852859
train_f-score_micro_tok: 0.9961251540852859
train_time: 84.99278569221497
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9822    0.9852    0.9837      2909
           1     0.9961    0.9953    0.9957     11132

   micro avg     0.9932    0.9932    0.9932     14041
   macro avg     0.9892    0.9903    0.9897     14041
weighted avg     0.9932    0.9932    0.9932     14041

F1-macro sent:  0.9897139406007338
F1-micro sent:  0.993234100135318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9989    0.9988    0.9988    169578
         LOC     0.9861    0.9849    0.9855      8297
        MISC     0.9714    0.9673    0.9693      4593
         ORG     0.9763    0.9781    0.9772     10025
         PER     0.9901    0.9916    0.9909     11128

   micro avg     0.9961    0.9961    0.9961    203621
   macro avg     0.9846    0.9842    0.9844    203621
weighted avg     0.9961    0.9961    0.9961    203621

F1-macro tok:  0.9843541172605729
F1-micro tok:  0.9961251540852859
**************************************************
dev_cost_sum: 80641.59700012207
dev_cost_avg: 24.812799076960637
dev_count_sent: 3250.0
dev_total_correct_sent: 3227.0
dev_accuracy_sent: 0.9929230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50828.0
dev_accuracy_tok: 0.989603208597796
dev_label=0_precision_sent: 0.9755351681957186
dev_label=0_recall_sent: 0.9891472868217054
dev_label=0_f-score_sent: 0.9822940723633563
dev_label=1_precision_sent: 0.9973035439137135
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9955777735050952
dev_precision_macro_sent: 0.9864193560547161
dev_recall_macro_sent: 0.9915026261363805
dev_f-score_macro_sent: 0.9889359229342258
dev_precision_micro_sent: 0.9929230769230769
dev_recall_micro_sent: 0.9929230769230769
dev_f-score_micro_sent: 0.9929230769230769
dev_label=O_precision_tok: 0.995776652588842
dev_label=O_recall_tok: 0.9980588881872822
dev_label=O_f-score_tok: 0.9969164642122967
dev_label=LOC_precision_tok: 0.9687199230028873
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9650047938638542
dev_label=MISC_precision_tok: 0.9122383252818036
dev_label=MISC_recall_tok: 0.8935331230283912
dev_label=MISC_f-score_tok: 0.9027888446215139
dev_label=ORG_precision_tok: 0.9455175829618623
dev_label=ORG_recall_tok: 0.9125239005736138
dev_label=ORG_f-score_tok: 0.9287278034541474
dev_label=PER_precision_tok: 0.97820593809223
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9808392715756137
dev_precision_macro_tok: 0.9600916843855251
dev_recall_macro_tok: 0.9497841569156604
dev_f-score_macro_tok: 0.9548554355454852
dev_precision_micro_tok: 0.989603208597796
dev_recall_micro_tok: 0.989603208597796
dev_f-score_micro_tok: 0.989603208597796
dev_time: 6.927048444747925
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9755    0.9891    0.9823       645
           1     0.9973    0.9939    0.9956      2605

   micro avg     0.9929    0.9929    0.9929      3250
   macro avg     0.9864    0.9915    0.9889      3250
weighted avg     0.9930    0.9929    0.9929      3250

F1-macro sent:  0.9889359229342258
F1-micro sent:  0.9929230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9981    0.9969     42759
         LOC     0.9687    0.9613    0.9650      2094
        MISC     0.9122    0.8935    0.9028      1268
         ORG     0.9455    0.9125    0.9287      2092
         PER     0.9782    0.9835    0.9808      3149

   micro avg     0.9896    0.9896    0.9896     51362
   macro avg     0.9601    0.9498    0.9549     51362
weighted avg     0.9895    0.9896    0.9895     51362

F1-macro tok:  0.9548554355454852
F1-micro tok:  0.989603208597796
**************************************************
Best epoch: 36
**************************************************

EPOCH: 39
Learning rate: 1.000000
train_cost_sum: 284805.1851196289
train_cost_avg: 20.283824878543474
train_count_sent: 14041.0
train_total_correct_sent: 13973.0
train_accuracy_sent: 0.9951570400968592
train_count_tok: 203621.0
train_total_correct_tok: 202826.0
train_accuracy_tok: 0.9960956875764287
train_label=0_precision_sent: 0.9893213916637961
train_label=0_recall_sent: 0.9872808525266414
train_label=0_f-score_sent: 0.9883000688231246
train_label=1_precision_sent: 0.9966780391452684
train_label=1_recall_sent: 0.9972152353575279
train_label=1_f-score_sent: 0.9969465648854962
train_precision_macro_sent: 0.9929997154045322
train_recall_macro_sent: 0.9922480439420847
train_f-score_macro_sent: 0.9926233168543104
train_precision_micro_sent: 0.9951570400968592
train_recall_micro_sent: 0.9951570400968592
train_f-score_micro_sent: 0.9951570400968592
train_label=O_precision_tok: 0.9986851337566849
train_label=O_recall_tok: 0.9988088077462879
train_label=O_f-score_tok: 0.998746966922875
train_label=LOC_precision_tok: 0.98336748222249
train_label=LOC_recall_tok: 0.98336748222249
train_label=LOC_f-score_tok: 0.98336748222249
train_label=MISC_precision_tok: 0.9717786042441479
train_label=MISC_recall_tok: 0.9671238841715655
train_label=MISC_f-score_tok: 0.9694456569183763
train_label=ORG_precision_tok: 0.979351620947631
train_label=ORG_recall_tok: 0.979351620947631
train_label=ORG_f-score_tok: 0.979351620947631
train_label=PER_precision_tok: 0.9911941773744272
train_label=PER_recall_tok: 0.9912832494608196
train_label=PER_f-score_tok: 0.9912387114166329
train_precision_macro_tok: 0.9848754037090762
train_recall_macro_tok: 0.9839870089097588
train_f-score_macro_tok: 0.984430087685601
train_precision_micro_tok: 0.9960956875764287
train_recall_micro_tok: 0.9960956875764287
train_f-score_micro_tok: 0.9960956875764287
train_time: 84.44069862365723
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9893    0.9873    0.9883      2909
           1     0.9967    0.9972    0.9969     11132

   micro avg     0.9952    0.9952    0.9952     14041
   macro avg     0.9930    0.9922    0.9926     14041
weighted avg     0.9952    0.9952    0.9952     14041

F1-macro sent:  0.9926233168543104
F1-micro sent:  0.9951570400968592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9987    0.9988    0.9987    169578
         LOC     0.9834    0.9834    0.9834      8297
        MISC     0.9718    0.9671    0.9694      4593
         ORG     0.9794    0.9794    0.9794     10025
         PER     0.9912    0.9913    0.9912     11128

   micro avg     0.9961    0.9961    0.9961    203621
   macro avg     0.9849    0.9840    0.9844    203621
weighted avg     0.9961    0.9961    0.9961    203621

F1-macro tok:  0.984430087685601
F1-micro tok:  0.9960956875764287
**************************************************
dev_cost_sum: 80363.2900390625
dev_cost_avg: 24.727166165865384
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50839.0
dev_accuracy_tok: 0.9898173747128227
dev_label=0_precision_sent: 0.9858267716535433
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.978125
dev_label=1_precision_sent: 0.9927342256214149
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9946360153256705
dev_precision_macro_sent: 0.989280498637479
dev_recall_macro_sent: 0.9835438706125668
dev_f-score_macro_sent: 0.9863805076628352
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9964027936745229
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.9970082973004558
dev_label=LOC_precision_tok: 0.9659635666347076
dev_label=LOC_recall_tok: 0.9622731614135626
dev_label=LOC_f-score_tok: 0.9641148325358851
dev_label=MISC_precision_tok: 0.9210740439381611
dev_label=MISC_recall_tok: 0.8927444794952681
dev_label=MISC_f-score_tok: 0.9066880256307568
dev_label=ORG_precision_tok: 0.9419512195121951
dev_label=ORG_recall_tok: 0.9230401529636711
dev_label=ORG_f-score_tok: 0.932399806856591
dev_label=PER_precision_tok: 0.9742623979912115
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9799526440410418
dev_precision_macro_tok: 0.9599308043501595
dev_recall_macro_tok: 0.9522764160579207
dev_f-score_macro_tok: 0.9560327212729461
dev_precision_micro_tok: 0.9898173747128227
dev_recall_micro_tok: 0.9898173747128227
dev_f-score_micro_tok: 0.9898173747128227
dev_time: 6.879789352416992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9858    0.9705    0.9781       645
           1     0.9927    0.9965    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9893    0.9835    0.9864      3250
weighted avg     0.9914    0.9914    0.9914      3250

F1-macro sent:  0.9863805076628352
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9976    0.9970     42759
         LOC     0.9660    0.9623    0.9641      2094
        MISC     0.9211    0.8927    0.9067      1268
         ORG     0.9420    0.9230    0.9324      2092
         PER     0.9743    0.9857    0.9800      3149

   micro avg     0.9898    0.9898    0.9898     51362
   macro avg     0.9599    0.9523    0.9560     51362
weighted avg     0.9897    0.9898    0.9898     51362

F1-macro tok:  0.9560327212729461
F1-micro tok:  0.9898173747128227
**************************************************
Best epoch: 36
**************************************************

EPOCH: 40
Learning rate: 1.000000
train_cost_sum: 284143.1589355469
train_cost_avg: 20.23667537465614
train_count_sent: 14041.0
train_total_correct_sent: 13954.0
train_accuracy_sent: 0.9938038601239227
train_count_tok: 203621.0
train_total_correct_tok: 202828.0
train_accuracy_tok: 0.9961055097460478
train_label=0_precision_sent: 0.9848797250859107
train_label=0_recall_sent: 0.9852182880715022
train_label=0_f-score_sent: 0.9850489774875408
train_label=1_precision_sent: 0.9961369149222891
train_label=1_recall_sent: 0.9960474308300395
train_label=1_f-score_sent: 0.9960921708664601
train_precision_macro_sent: 0.9905083200040998
train_recall_macro_sent: 0.990632859450771
train_f-score_macro_sent: 0.9905705741770005
train_precision_micro_sent: 0.9938038601239227
train_recall_micro_sent: 0.9938038601239227
train_f-score_micro_sent: 0.9938038601239227
train_label=O_precision_tok: 0.998791237949232
train_label=O_recall_tok: 0.998891365625258
train_label=O_f-score_tok: 0.9988412992779496
train_label=LOC_precision_tok: 0.9844146429865893
train_label=LOC_recall_tok: 0.9820417018199349
train_label=LOC_f-score_tok: 0.9832267406781706
train_label=MISC_precision_tok: 0.9724529951902056
train_label=MISC_recall_tok: 0.9684302198998476
train_label=MISC_f-score_tok: 0.970437438638595
train_label=ORG_precision_tok: 0.9775807094459944
train_label=ORG_recall_tok: 0.9786533665835412
train_label=ORG_f-score_tok: 0.9781167439310103
train_label=PER_precision_tok: 0.9903043361163479
train_label=PER_recall_tok: 0.9912832494608196
train_label=PER_f-score_tok: 0.9907935509947456
train_precision_macro_tok: 0.984708784337674
train_recall_macro_tok: 0.9838599806778803
train_f-score_macro_tok: 0.9842831547040942
train_precision_micro_tok: 0.9961055097460478
train_recall_micro_tok: 0.9961055097460478
train_f-score_micro_tok: 0.9961055097460478
train_time: 84.42149066925049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9849    0.9852    0.9850      2909
           1     0.9961    0.9960    0.9961     11132

   micro avg     0.9938    0.9938    0.9938     14041
   macro avg     0.9905    0.9906    0.9906     14041
weighted avg     0.9938    0.9938    0.9938     14041

F1-macro sent:  0.9905705741770005
F1-micro sent:  0.9938038601239227
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9989    0.9988    169578
         LOC     0.9844    0.9820    0.9832      8297
        MISC     0.9725    0.9684    0.9704      4593
         ORG     0.9776    0.9787    0.9781     10025
         PER     0.9903    0.9913    0.9908     11128

   micro avg     0.9961    0.9961    0.9961    203621
   macro avg     0.9847    0.9839    0.9843    203621
weighted avg     0.9961    0.9961    0.9961    203621

F1-macro tok:  0.9842831547040942
F1-micro tok:  0.9961055097460478
**************************************************
dev_cost_sum: 80166.49077606201
dev_cost_avg: 24.666612546480618
dev_count_sent: 3250.0
dev_total_correct_sent: 3214.0
dev_accuracy_sent: 0.9889230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50864.0
dev_accuracy_tok: 0.9903041158833379
dev_label=0_precision_sent: 0.9750390015600624
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.9720062208398133
dev_label=1_precision_sent: 0.9923342276734382
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9930955120828538
dev_precision_macro_sent: 0.9836866146167502
dev_recall_macro_sent: 0.9814251067565356
dev_f-score_macro_sent: 0.9825508664613336
dev_precision_micro_sent: 0.9889230769230769
dev_recall_micro_sent: 0.9889230769230769
dev_f-score_micro_sent: 0.9889230769230769
dev_label=O_precision_tok: 0.996334173904922
dev_label=O_recall_tok: 0.9979419537407329
dev_label=O_f-score_tok: 0.9971374157290243
dev_label=LOC_precision_tok: 0.9655502392344497
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9646271510516252
dev_label=MISC_precision_tok: 0.9296235679214403
dev_label=MISC_recall_tok: 0.8958990536277602
dev_label=MISC_f-score_tok: 0.9124497991967871
dev_label=ORG_precision_tok: 0.9418886198547215
dev_label=ORG_recall_tok: 0.9297323135755258
dev_label=ORG_f-score_tok: 0.9357709886937694
dev_label=PER_precision_tok: 0.9800443458980045
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9812876625436092
dev_precision_macro_tok: 0.9626881893627075
dev_recall_macro_tok: 0.9539626569871118
dev_f-score_macro_tok: 0.958254603442963
dev_precision_micro_tok: 0.9903041158833379
dev_recall_micro_tok: 0.9903041158833379
dev_f-score_micro_tok: 0.9903041158833379
dev_time: 6.958779573440552
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9750    0.9690    0.9720       645
           1     0.9923    0.9939    0.9931      2605

   micro avg     0.9889    0.9889    0.9889      3250
   macro avg     0.9837    0.9814    0.9826      3250
weighted avg     0.9889    0.9889    0.9889      3250

F1-macro sent:  0.9825508664613336
F1-micro sent:  0.9889230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9979    0.9971     42759
         LOC     0.9656    0.9637    0.9646      2094
        MISC     0.9296    0.8959    0.9124      1268
         ORG     0.9419    0.9297    0.9358      2092
         PER     0.9800    0.9825    0.9813      3149

   micro avg     0.9903    0.9903    0.9903     51362
   macro avg     0.9627    0.9540    0.9583     51362
weighted avg     0.9902    0.9903    0.9903     51362

F1-macro tok:  0.958254603442963
F1-micro tok:  0.9903041158833379
**************************************************
Best epoch: 36
**************************************************

EPOCH: 41
Learning rate: 0.900000
train_cost_sum: 283365.1149902344
train_cost_avg: 20.181263085979232
train_count_sent: 14041.0
train_total_correct_sent: 13965.0
train_accuracy_sent: 0.9945872801082544
train_count_tok: 203621.0
train_total_correct_tok: 202846.0
train_accuracy_tok: 0.9961939092726192
train_label=0_precision_sent: 0.9862684517679369
train_label=0_recall_sent: 0.9876246132691646
train_label=0_f-score_sent: 0.986946066643765
train_label=1_precision_sent: 0.996764917325665
train_label=1_recall_sent: 0.996406755300036
train_label=1_f-score_sent: 0.9965858041329739
train_precision_macro_sent: 0.9915166845468009
train_recall_macro_sent: 0.9920156842846003
train_f-score_macro_sent: 0.9917659353883694
train_precision_micro_sent: 0.9945872801082544
train_recall_micro_sent: 0.9945872801082544
train_f-score_micro_sent: 0.9945872801082544
train_label=O_precision_tok: 0.9987559842463977
train_label=O_recall_tok: 0.9989562325301631
train_label=O_f-score_tok: 0.9988560983519561
train_label=LOC_precision_tok: 0.9830222757375076
train_label=LOC_recall_tok: 0.983970109678197
train_label=LOC_f-score_tok: 0.9834959643416457
train_label=MISC_precision_tok: 0.97148497477517
train_label=MISC_recall_tok: 0.9642934900936208
train_label=MISC_f-score_tok: 0.9678758741258742
train_label=ORG_precision_tok: 0.9790628115653041
train_label=ORG_recall_tok: 0.9795511221945137
train_label=ORG_f-score_tok: 0.9793069060084767
train_label=PER_precision_tok: 0.9925326135852451
train_label=PER_recall_tok: 0.99137311286844
train_label=PER_f-score_tok: 0.9919525243896956
train_precision_macro_tok: 0.984971731981925
train_recall_macro_tok: 0.9836288134729869
train_f-score_macro_tok: 0.9842974734435297
train_precision_micro_tok: 0.9961939092726192
train_recall_micro_tok: 0.9961939092726192
train_f-score_micro_tok: 0.9961939092726192
train_time: 84.97428154945374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9863    0.9876    0.9869      2909
           1     0.9968    0.9964    0.9966     11132

   micro avg     0.9946    0.9946    0.9946     14041
   macro avg     0.9915    0.9920    0.9918     14041
weighted avg     0.9946    0.9946    0.9946     14041

F1-macro sent:  0.9917659353883694
F1-micro sent:  0.9945872801082544
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9990    0.9989    169578
         LOC     0.9830    0.9840    0.9835      8297
        MISC     0.9715    0.9643    0.9679      4593
         ORG     0.9791    0.9796    0.9793     10025
         PER     0.9925    0.9914    0.9920     11128

   micro avg     0.9962    0.9962    0.9962    203621
   macro avg     0.9850    0.9836    0.9843    203621
weighted avg     0.9962    0.9962    0.9962    203621

F1-macro tok:  0.9842974734435297
F1-micro tok:  0.9961939092726192
**************************************************
dev_cost_sum: 80226.46493530273
dev_cost_avg: 24.6850661339393
dev_count_sent: 3250.0
dev_total_correct_sent: 3232.0
dev_accuracy_sent: 0.9944615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50881.0
dev_accuracy_tok: 0.9906350998792882
dev_label=0_precision_sent: 0.9906103286384976
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9859813084112149
dev_label=1_precision_sent: 0.9954040597472232
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.9965490797546013
dev_precision_macro_sent: 0.9930071941928604
dev_recall_macro_sent: 0.9895460429406775
dev_f-score_macro_sent: 0.991265194082908
dev_precision_micro_sent: 0.9944615384615385
dev_recall_micro_sent: 0.9944615384615385
dev_f-score_micro_sent: 0.9944615384615385
dev_label=O_precision_tok: 0.9965905375741442
dev_label=O_recall_tok: 0.9980588881872822
dev_label=O_f-score_tok: 0.9973241724214486
dev_label=LOC_precision_tok: 0.9683301343570058
dev_label=LOC_recall_tok: 0.9637058261700095
dev_label=LOC_f-score_tok: 0.9660124461464816
dev_label=MISC_precision_tok: 0.9314845024469821
dev_label=MISC_recall_tok: 0.9006309148264984
dev_label=MISC_f-score_tok: 0.9157979149959903
dev_label=ORG_precision_tok: 0.9436071949440933
dev_label=ORG_recall_tok: 0.9278202676864244
dev_label=ORG_f-score_tok: 0.9356471438900941
dev_label=PER_precision_tok: 0.978254018279231
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.981967731730465
dev_precision_macro_tok: 0.9636532775202913
dev_recall_macro_tok: 0.9551851291993841
dev_f-score_macro_tok: 0.9593498818368958
dev_precision_micro_tok: 0.9906350998792882
dev_recall_micro_tok: 0.9906350998792882
dev_f-score_micro_tok: 0.9906350998792882
dev_time: 6.8485095500946045
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9906    0.9814    0.9860       645
           1     0.9954    0.9977    0.9965      2605

   micro avg     0.9945    0.9945    0.9945      3250
   macro avg     0.9930    0.9895    0.9913      3250
weighted avg     0.9945    0.9945    0.9945      3250

F1-macro sent:  0.991265194082908
F1-micro sent:  0.9944615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9981    0.9973     42759
         LOC     0.9683    0.9637    0.9660      2094
        MISC     0.9315    0.9006    0.9158      1268
         ORG     0.9436    0.9278    0.9356      2092
         PER     0.9783    0.9857    0.9820      3149

   micro avg     0.9906    0.9906    0.9906     51362
   macro avg     0.9637    0.9552    0.9593     51362
weighted avg     0.9905    0.9906    0.9906     51362

F1-macro tok:  0.9593498818368958
F1-micro tok:  0.9906350998792882
**************************************************
Best epoch: 41
**************************************************

EPOCH: 42
Learning rate: 0.900000
train_cost_sum: 282650.69720458984
train_cost_avg: 20.130382252303242
train_count_sent: 14041.0
train_total_correct_sent: 13952.0
train_accuracy_sent: 0.9936614201267716
train_count_tok: 203621.0
train_total_correct_tok: 202885.0
train_accuracy_tok: 0.9963854415801906
train_label=0_precision_sent: 0.9825462012320328
train_label=0_recall_sent: 0.9869370917841183
train_label=0_f-score_sent: 0.9847367518435945
train_label=1_precision_sent: 0.9965824264772012
train_label=1_recall_sent: 0.9954186130075459
train_label=1_f-score_sent: 0.9960001797672015
train_precision_macro_sent: 0.9895643138546171
train_recall_macro_sent: 0.9911778523958321
train_f-score_macro_sent: 0.990368465805398
train_precision_micro_sent: 0.9936614201267716
train_recall_micro_sent: 0.9936614201267716
train_f-score_micro_sent: 0.9936614201267716
train_label=O_precision_tok: 0.9988031577768214
train_label=O_recall_tok: 0.9990093054523582
train_label=O_f-score_tok: 0.9989062209787406
train_label=LOC_precision_tok: 0.9858644436389996
train_label=LOC_recall_tok: 0.9834880077136314
train_label=LOC_f-score_tok: 0.9846747918426451
train_label=MISC_precision_tok: 0.9765915554583242
train_label=MISC_recall_tok: 0.9719137818419333
train_label=MISC_f-score_tok: 0.9742470536883457
train_label=ORG_precision_tok: 0.977760047870749
train_label=ORG_recall_tok: 0.9779551122194514
train_label=ORG_f-score_tok: 0.9778575703171755
train_label=PER_precision_tok: 0.9922752178208929
train_label=PER_recall_tok: 0.9927210639827462
train_label=PER_f-score_tok: 0.9924980908314991
train_precision_macro_tok: 0.9862588845131575
train_recall_macro_tok: 0.9850174542420241
train_f-score_macro_tok: 0.9856367455316812
train_precision_micro_tok: 0.9963854415801906
train_recall_micro_tok: 0.9963854415801906
train_f-score_micro_tok: 0.9963854415801906
train_time: 84.51213264465332
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9825    0.9869    0.9847      2909
           1     0.9966    0.9954    0.9960     11132

   micro avg     0.9937    0.9937    0.9937     14041
   macro avg     0.9896    0.9912    0.9904     14041
weighted avg     0.9937    0.9937    0.9937     14041

F1-macro sent:  0.990368465805398
F1-micro sent:  0.9936614201267716
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9990    0.9989    169578
         LOC     0.9859    0.9835    0.9847      8297
        MISC     0.9766    0.9719    0.9742      4593
         ORG     0.9778    0.9780    0.9779     10025
         PER     0.9923    0.9927    0.9925     11128

   micro avg     0.9964    0.9964    0.9964    203621
   macro avg     0.9863    0.9850    0.9856    203621
weighted avg     0.9964    0.9964    0.9964    203621

F1-macro tok:  0.9856367455316812
F1-micro tok:  0.9963854415801906
**************************************************
dev_cost_sum: 80207.35877990723
dev_cost_avg: 24.67918731689453
dev_count_sent: 3250.0
dev_total_correct_sent: 3226.0
dev_accuracy_sent: 0.9926153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50851.0
dev_accuracy_tok: 0.99005101047467
dev_label=0_precision_sent: 0.9874411302982732
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9812792511700468
dev_label=1_precision_sent: 0.993876769996173
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9954005366040628
dev_precision_macro_sent: 0.9906589501472232
dev_recall_macro_sent: 0.9860613905875701
dev_f-score_macro_sent: 0.9883398938870548
dev_precision_micro_sent: 0.9926153846153846
dev_recall_micro_sent: 0.9926153846153846
dev_f-score_micro_sent: 0.9926153846153846
dev_label=O_precision_tok: 0.9970543541788428
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9972408632824374
dev_label=LOC_precision_tok: 0.9597918637653737
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.9643536121673003
dev_label=MISC_precision_tok: 0.8905053598774885
dev_label=MISC_recall_tok: 0.917192429022082
dev_label=MISC_f-score_tok: 0.9036519036519036
dev_label=ORG_precision_tok: 0.9557788944723619
dev_label=ORG_recall_tok: 0.9091778202676865
dev_label=ORG_f-score_tok: 0.9318961293483586
dev_label=PER_precision_tok: 0.9782813975448537
dev_label=PER_recall_tok: 0.9869799936487774
dev_label=PER_f-score_tok: 0.9826114448308567
dev_precision_macro_tok: 0.956282373967784
dev_recall_macro_tok: 0.9559473230782889
dev_f-score_macro_tok: 0.9559507906561713
dev_precision_micro_tok: 0.99005101047467
dev_recall_micro_tok: 0.99005101047467
dev_f-score_micro_tok: 0.99005101047467
dev_time: 6.87063455581665
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9874    0.9752    0.9813       645
           1     0.9939    0.9969    0.9954      2605

   micro avg     0.9926    0.9926    0.9926      3250
   macro avg     0.9907    0.9861    0.9883      3250
weighted avg     0.9926    0.9926    0.9926      3250

F1-macro sent:  0.9883398938870548
F1-micro sent:  0.9926153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9974    0.9972     42759
         LOC     0.9598    0.9690    0.9644      2094
        MISC     0.8905    0.9172    0.9037      1268
         ORG     0.9558    0.9092    0.9319      2092
         PER     0.9783    0.9870    0.9826      3149

   micro avg     0.9901    0.9901    0.9901     51362
   macro avg     0.9563    0.9559    0.9560     51362
weighted avg     0.9901    0.9901    0.9900     51362

F1-macro tok:  0.9559507906561713
F1-micro tok:  0.99005101047467
**************************************************
Best epoch: 41
**************************************************

EPOCH: 43
Learning rate: 0.900000
train_cost_sum: 282085.1515197754
train_cost_avg: 20.09010408943632
train_count_sent: 14041.0
train_total_correct_sent: 13958.0
train_accuracy_sent: 0.9940887401182252
train_count_tok: 203621.0
train_total_correct_tok: 202839.0
train_accuracy_tok: 0.9961595316789525
train_label=0_precision_sent: 0.9862353750860289
train_label=0_recall_sent: 0.9852182880715022
train_label=0_f-score_sent: 0.9857265692175409
train_label=1_precision_sent: 0.996138302649304
train_label=1_recall_sent: 0.996406755300036
train_label=1_f-score_sent: 0.9962725108905556
train_precision_macro_sent: 0.9911868388676665
train_recall_macro_sent: 0.990812521685769
train_f-score_macro_sent: 0.9909995400540482
train_precision_micro_sent: 0.9940887401182252
train_recall_micro_sent: 0.9940887401182252
train_f-score_micro_sent: 0.9940887401182252
train_label=O_precision_tok: 0.9988206017289979
train_label=O_recall_tok: 0.9988206017289979
train_label=O_f-score_tok: 0.9988206017289979
train_label=LOC_precision_tok: 0.9850277710697899
train_label=LOC_recall_tok: 0.9832469567313487
train_label=LOC_f-score_tok: 0.9841365582966404
train_label=MISC_precision_tok: 0.9713848842289209
train_label=MISC_recall_tok: 0.9682124972784673
train_label=MISC_f-score_tok: 0.9697960963907971
train_label=ORG_precision_tok: 0.97712353292222
train_label=ORG_recall_tok: 0.9799501246882794
train_label=ORG_f-score_tok: 0.9785347875890233
train_label=PER_precision_tok: 0.9912840327073412
train_label=PER_recall_tok: 0.99137311286844
train_label=PER_f-score_tok: 0.9913285707867188
train_precision_macro_tok: 0.9847281645314541
train_recall_macro_tok: 0.9843206586591066
train_f-score_macro_tok: 0.9845233229584356
train_precision_micro_tok: 0.9961595316789525
train_recall_micro_tok: 0.9961595316789525
train_f-score_micro_tok: 0.9961595316789525
train_time: 84.64555168151855
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9862    0.9852    0.9857      2909
           1     0.9961    0.9964    0.9963     11132

   micro avg     0.9941    0.9941    0.9941     14041
   macro avg     0.9912    0.9908    0.9910     14041
weighted avg     0.9941    0.9941    0.9941     14041

F1-macro sent:  0.9909995400540482
F1-micro sent:  0.9940887401182252
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9988    0.9988    169578
         LOC     0.9850    0.9832    0.9841      8297
        MISC     0.9714    0.9682    0.9698      4593
         ORG     0.9771    0.9800    0.9785     10025
         PER     0.9913    0.9914    0.9913     11128

   micro avg     0.9962    0.9962    0.9962    203621
   macro avg     0.9847    0.9843    0.9845    203621
weighted avg     0.9962    0.9962    0.9962    203621

F1-macro tok:  0.9845233229584356
F1-micro tok:  0.9961595316789525
**************************************************
dev_cost_sum: 79914.14222717285
dev_cost_avg: 24.58896683913011
dev_count_sent: 3250.0
dev_total_correct_sent: 3227.0
dev_accuracy_sent: 0.9929230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50859.0
dev_accuracy_tok: 0.9902067676492349
dev_label=0_precision_sent: 0.9859375
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9821011673151752
dev_label=1_precision_sent: 0.9946360153256705
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9955896452540748
dev_precision_macro_sent: 0.9902867576628352
dev_recall_macro_sent: 0.9874198396048148
dev_f-score_macro_sent: 0.988845406284625
dev_precision_micro_sent: 0.9929230769230769
dev_recall_micro_sent: 0.9929230769230769
dev_f-score_micro_sent: 0.9929230769230769
dev_label=O_precision_tok: 0.9971015170285874
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.9973579611877484
dev_label=LOC_precision_tok: 0.95929957406531
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9636320418350368
dev_label=MISC_precision_tok: 0.9129746835443038
dev_label=MISC_recall_tok: 0.9100946372239748
dev_label=MISC_f-score_tok: 0.9115323854660349
dev_label=ORG_precision_tok: 0.9484893511639425
dev_label=ORG_recall_tok: 0.9153919694072657
dev_label=ORG_f-score_tok: 0.9316468012648991
dev_label=PER_precision_tok: 0.9751962323390895
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9807388695926745
dev_precision_macro_tok: 0.9586122716282468
dev_recall_macro_tok: 0.9554899671497455
dev_f-score_macro_tok: 0.9569816118692789
dev_precision_micro_tok: 0.9902067676492349
dev_recall_micro_tok: 0.9902067676492349
dev_f-score_micro_tok: 0.9902067676492349
dev_time: 6.917452096939087
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9859    0.9783    0.9821       645
           1     0.9946    0.9965    0.9956      2605

   micro avg     0.9929    0.9929    0.9929      3250
   macro avg     0.9903    0.9874    0.9888      3250
weighted avg     0.9929    0.9929    0.9929      3250

F1-macro sent:  0.988845406284625
F1-micro sent:  0.9929230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9976    0.9974     42759
         LOC     0.9593    0.9680    0.9636      2094
        MISC     0.9130    0.9101    0.9115      1268
         ORG     0.9485    0.9154    0.9316      2092
         PER     0.9752    0.9863    0.9807      3149

   micro avg     0.9902    0.9902    0.9902     51362
   macro avg     0.9586    0.9555    0.9570     51362
weighted avg     0.9902    0.9902    0.9902     51362

F1-macro tok:  0.9569816118692789
F1-micro tok:  0.9902067676492349
**************************************************
Best epoch: 41
**************************************************

EPOCH: 44
Learning rate: 0.900000
train_cost_sum: 281442.6274108887
train_cost_avg: 20.04434352331662
train_count_sent: 14041.0
train_total_correct_sent: 13976.0
train_accuracy_sent: 0.995370700092586
train_count_tok: 203621.0
train_total_correct_tok: 202915.0
train_accuracy_tok: 0.9965327741244764
train_label=0_precision_sent: 0.9896694214876033
train_label=0_recall_sent: 0.9879683740116879
train_label=0_f-score_sent: 0.9888181661792533
train_label=1_precision_sent: 0.9968573224387178
train_label=1_recall_sent: 0.9973050664750269
train_label=1_f-score_sent: 0.997081144191477
train_precision_macro_sent: 0.9932633719631605
train_recall_macro_sent: 0.9926367202433575
train_f-score_macro_sent: 0.9929496551853652
train_precision_micro_sent: 0.995370700092586
train_recall_micro_sent: 0.995370700092586
train_f-score_micro_sent: 0.995370700092586
train_label=O_precision_tok: 0.9989326886222248
train_label=O_recall_tok: 0.9989739235042281
train_label=O_f-score_tok: 0.9989533056377021
train_label=LOC_precision_tok: 0.9869801084990958
train_label=LOC_recall_tok: 0.9867421959744486
train_label=LOC_f-score_tok: 0.9868611378977821
train_label=MISC_precision_tok: 0.9735865531543331
train_label=MISC_recall_tok: 0.971042891356412
train_label=MISC_f-score_tok: 0.972313058643994
train_label=ORG_precision_tok: 0.9800339422980933
train_label=ORG_recall_tok: 0.9792518703241895
train_label=ORG_f-score_tok: 0.9796427502245284
train_label=PER_precision_tok: 0.9913847258368482
train_label=PER_recall_tok: 0.9927210639827462
train_label=PER_f-score_tok: 0.9920524448834808
train_precision_macro_tok: 0.9861836036821192
train_recall_macro_tok: 0.9857463890284048
train_f-score_macro_tok: 0.9859645394574974
train_precision_micro_tok: 0.9965327741244764
train_recall_micro_tok: 0.9965327741244764
train_f-score_micro_tok: 0.9965327741244764
train_time: 84.29226994514465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9897    0.9880    0.9888      2909
           1     0.9969    0.9973    0.9971     11132

   micro avg     0.9954    0.9954    0.9954     14041
   macro avg     0.9933    0.9926    0.9929     14041
weighted avg     0.9954    0.9954    0.9954     14041

F1-macro sent:  0.9929496551853652
F1-micro sent:  0.995370700092586
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9989    0.9990    0.9990    169578
         LOC     0.9870    0.9867    0.9869      8297
        MISC     0.9736    0.9710    0.9723      4593
         ORG     0.9800    0.9793    0.9796     10025
         PER     0.9914    0.9927    0.9921     11128

   micro avg     0.9965    0.9965    0.9965    203621
   macro avg     0.9862    0.9857    0.9860    203621
weighted avg     0.9965    0.9965    0.9965    203621

F1-macro tok:  0.9859645394574974
F1-micro tok:  0.9965327741244764
**************************************************
dev_cost_sum: 79939.87142181396
dev_cost_avg: 24.596883514404297
dev_count_sent: 3250.0
dev_total_correct_sent: 3231.0
dev_accuracy_sent: 0.9941538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50832.0
dev_accuracy_tok: 0.9896810871850784
dev_label=0_precision_sent: 0.9845201238390093
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9852827265685515
dev_label=1_precision_sent: 0.9965437788018433
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9963524668842387
dev_precision_macro_sent: 0.9905319513204263
dev_recall_macro_sent: 0.9911038700174084
dev_f-score_macro_sent: 0.9908175967263951
dev_precision_micro_sent: 0.9941538461538462
dev_recall_micro_sent: 0.9941538461538462
dev_f-score_micro_sent: 0.9941538461538463
dev_label=O_precision_tok: 0.9967753242201192
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.997194754190336
dev_label=LOC_precision_tok: 0.945631970260223
dev_label=LOC_recall_tok: 0.9718242597898759
dev_label=LOC_f-score_tok: 0.9585492227979274
dev_label=MISC_precision_tok: 0.9132856006364359
dev_label=MISC_recall_tok: 0.9053627760252366
dev_label=MISC_f-score_tok: 0.9093069306930693
dev_label=ORG_precision_tok: 0.9508278976417461
dev_label=ORG_recall_tok: 0.905831739961759
dev_label=ORG_f-score_tok: 0.9277845777233782
dev_label=PER_precision_tok: 0.9785150078988941
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9809946151409565
dev_precision_macro_tok: 0.9570071601314837
dev_recall_macro_tok: 0.9528240268560701
dev_f-score_macro_tok: 0.9547660201091336
dev_precision_micro_tok: 0.9896810871850784
dev_recall_micro_tok: 0.9896810871850784
dev_f-score_micro_tok: 0.9896810871850784
dev_time: 6.91483211517334
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9845    0.9860    0.9853       645
           1     0.9965    0.9962    0.9964      2605

   micro avg     0.9942    0.9942    0.9942      3250
   macro avg     0.9905    0.9911    0.9908      3250
weighted avg     0.9942    0.9942    0.9942      3250

F1-macro sent:  0.9908175967263951
F1-micro sent:  0.9941538461538463
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9976    0.9972     42759
         LOC     0.9456    0.9718    0.9585      2094
        MISC     0.9133    0.9054    0.9093      1268
         ORG     0.9508    0.9058    0.9278      2092
         PER     0.9785    0.9835    0.9810      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9570    0.9528    0.9548     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.9547660201091336
F1-micro tok:  0.9896810871850784
**************************************************
Best epoch: 41
**************************************************

EPOCH: 45
Learning rate: 0.900000
train_cost_sum: 280959.99420166016
train_cost_avg: 20.009970386842827
train_count_sent: 14041.0
train_total_correct_sent: 13969.0
train_accuracy_sent: 0.9948721601025567
train_count_tok: 203621.0
train_total_correct_tok: 202902.0
train_accuracy_tok: 0.9964689300219526
train_label=0_precision_sent: 0.9862872814535482
train_label=0_recall_sent: 0.9889996562392575
train_label=0_f-score_sent: 0.9876416065911431
train_label=1_precision_sent: 0.9971233369291622
train_label=1_recall_sent: 0.996406755300036
train_label=1_f-score_sent: 0.996764917325665
train_precision_macro_sent: 0.9917053091913552
train_recall_macro_sent: 0.9927032057696468
train_f-score_macro_sent: 0.992203261958404
train_precision_micro_sent: 0.9948721601025567
train_recall_micro_sent: 0.9948721601025567
train_f-score_micro_sent: 0.9948721601025567
train_label=O_precision_tok: 0.9989208442182608
train_label=O_recall_tok: 0.9989149535906781
train_label=O_f-score_tok: 0.9989178988957852
train_label=LOC_precision_tok: 0.9854216867469879
train_label=LOC_recall_tok: 0.9857779920453176
train_label=LOC_f-score_tok: 0.9855998071940713
train_label=MISC_precision_tok: 0.9748688811188811
train_label=MISC_recall_tok: 0.9712606139777923
train_label=MISC_f-score_tok: 0.9730614025520776
train_label=ORG_precision_tok: 0.9793660287081339
train_label=ORG_recall_tok: 0.9800498753117207
train_label=ORG_f-score_tok: 0.9797078326768709
train_label=PER_precision_tok: 0.9916487068965517
train_label=PER_recall_tok: 0.9923616103522646
train_label=PER_f-score_tok: 0.99200503054258
train_precision_macro_tok: 0.9860452295377631
train_recall_macro_tok: 0.9856730090555545
train_f-score_macro_tok: 0.9858583943722771
train_precision_micro_tok: 0.9964689300219526
train_recall_micro_tok: 0.9964689300219526
train_f-score_micro_tok: 0.9964689300219526
train_time: 84.13114094734192
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9863    0.9890    0.9876      2909
           1     0.9971    0.9964    0.9968     11132

   micro avg     0.9949    0.9949    0.9949     14041
   macro avg     0.9917    0.9927    0.9922     14041
weighted avg     0.9949    0.9949    0.9949     14041

F1-macro sent:  0.992203261958404
F1-micro sent:  0.9948721601025567
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9989    0.9989    0.9989    169578
         LOC     0.9854    0.9858    0.9856      8297
        MISC     0.9749    0.9713    0.9731      4593
         ORG     0.9794    0.9800    0.9797     10025
         PER     0.9916    0.9924    0.9920     11128

   micro avg     0.9965    0.9965    0.9965    203621
   macro avg     0.9860    0.9857    0.9859    203621
weighted avg     0.9965    0.9965    0.9965    203621

F1-macro tok:  0.9858583943722771
F1-micro tok:  0.9964689300219526
**************************************************
dev_cost_sum: 79885.25540924072
dev_cost_avg: 24.580078587458683
dev_count_sent: 3250.0
dev_total_correct_sent: 3228.0
dev_accuracy_sent: 0.9932307692307693
dev_count_tok: 51362.0
dev_total_correct_tok: 50837.0
dev_accuracy_tok: 0.9897784354191815
dev_label=0_precision_sent: 0.9921011058451816
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9827856025039123
dev_label=1_precision_sent: 0.9935040122277417
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9957870547682879
dev_precision_macro_sent: 0.9928025590364616
dev_recall_macro_sent: 0.985862012528084
dev_f-score_macro_sent: 0.9892863286361001
dev_precision_micro_sent: 0.9932307692307693
dev_recall_micro_sent: 0.9932307692307693
dev_f-score_micro_sent: 0.9932307692307693
dev_label=O_precision_tok: 0.9963804497583074
dev_label=O_recall_tok: 0.9978717930728034
dev_label=O_f-score_tok: 0.9971255637867776
dev_label=LOC_precision_tok: 0.959639126305793
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9623809523809523
dev_label=MISC_precision_tok: 0.9028213166144201
dev_label=MISC_recall_tok: 0.9085173501577287
dev_label=MISC_f-score_tok: 0.9056603773584906
dev_label=ORG_precision_tok: 0.9594114662607813
dev_label=ORG_recall_tok: 0.9039196940726577
dev_label=ORG_f-score_tok: 0.9308392813192223
dev_label=PER_precision_tok: 0.9745762711864406
dev_label=PER_recall_tok: 0.9860273102572246
dev_label=PER_f-score_tok: 0.9802683504340963
dev_precision_macro_tok: 0.9585657260251483
dev_recall_macro_tok: 0.9522949276973742
dev_f-score_macro_tok: 0.9552549050559078
dev_precision_micro_tok: 0.9897784354191815
dev_recall_micro_tok: 0.9897784354191815
dev_f-score_micro_tok: 0.9897784354191815
dev_time: 6.888732194900513
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9921    0.9736    0.9828       645
           1     0.9935    0.9981    0.9958      2605

   micro avg     0.9932    0.9932    0.9932      3250
   macro avg     0.9928    0.9859    0.9893      3250
weighted avg     0.9932    0.9932    0.9932      3250

F1-macro sent:  0.9892863286361001
F1-micro sent:  0.9932307692307693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9979    0.9971     42759
         LOC     0.9596    0.9651    0.9624      2094
        MISC     0.9028    0.9085    0.9057      1268
         ORG     0.9594    0.9039    0.9308      2092
         PER     0.9746    0.9860    0.9803      3149

   micro avg     0.9898    0.9898    0.9898     51362
   macro avg     0.9586    0.9523    0.9553     51362
weighted avg     0.9897    0.9898    0.9897     51362

F1-macro tok:  0.9552549050559078
F1-micro tok:  0.9897784354191815
**************************************************
Best epoch: 41
**************************************************

EPOCH: 46
Learning rate: 0.810000
train_cost_sum: 280380.03302001953
train_cost_avg: 19.96866555231248
train_count_sent: 14041.0
train_total_correct_sent: 13976.0
train_accuracy_sent: 0.995370700092586
train_count_tok: 203621.0
train_total_correct_tok: 202945.0
train_accuracy_tok: 0.9966801066687621
train_label=0_precision_sent: 0.9876543209876543
train_label=0_recall_sent: 0.9900309384668271
train_label=0_f-score_sent: 0.9888412017167382
train_label=1_precision_sent: 0.9973932584269662
train_label=1_recall_sent: 0.9967660797700323
train_label=1_f-score_sent: 0.9970795704722109
train_precision_macro_sent: 0.9925237897073103
train_recall_macro_sent: 0.9933985091184296
train_f-score_macro_sent: 0.9929603860944745
train_precision_micro_sent: 0.995370700092586
train_recall_micro_sent: 0.995370700092586
train_f-score_micro_sent: 0.995370700092586
train_label=O_precision_tok: 0.998991650155675
train_label=O_recall_tok: 0.9990269964264232
train_label=O_f-score_tok: 0.9990093229783997
train_label=LOC_precision_tok: 0.9848320693391116
train_label=LOC_recall_tok: 0.9860190430276004
train_label=LOC_f-score_tok: 0.9854251987472897
train_label=MISC_precision_tok: 0.9776951672862454
train_label=MISC_recall_tok: 0.973437840191596
train_label=MISC_f-score_tok: 0.975561859044294
train_label=ORG_precision_tok: 0.9813447725458898
train_label=ORG_recall_tok: 0.9812468827930174
train_label=ORG_f-score_tok: 0.9812958252281909
train_label=PER_precision_tok: 0.9919159256265158
train_label=PER_recall_tok: 0.9923616103522646
train_label=PER_f-score_tok: 0.9921387179371995
train_precision_macro_tok: 0.9869559169906875
train_recall_macro_tok: 0.9864184745581802
train_f-score_macro_tok: 0.9866861847870748
train_precision_micro_tok: 0.9966801066687621
train_recall_micro_tok: 0.9966801066687621
train_f-score_micro_tok: 0.9966801066687621
train_time: 84.28770160675049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9877    0.9900    0.9888      2909
           1     0.9974    0.9968    0.9971     11132

   micro avg     0.9954    0.9954    0.9954     14041
   macro avg     0.9925    0.9934    0.9930     14041
weighted avg     0.9954    0.9954    0.9954     14041

F1-macro sent:  0.9929603860944745
F1-micro sent:  0.995370700092586
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9990    0.9990    0.9990    169578
         LOC     0.9848    0.9860    0.9854      8297
        MISC     0.9777    0.9734    0.9756      4593
         ORG     0.9813    0.9812    0.9813     10025
         PER     0.9919    0.9924    0.9921     11128

   micro avg     0.9967    0.9967    0.9967    203621
   macro avg     0.9870    0.9864    0.9867    203621
weighted avg     0.9967    0.9967    0.9967    203621

F1-macro tok:  0.9866861847870748
F1-micro tok:  0.9966801066687621
**************************************************
dev_cost_sum: 79771.75681304932
dev_cost_avg: 24.54515594247671
dev_count_sent: 3250.0
dev_total_correct_sent: 3227.0
dev_accuracy_sent: 0.9929230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50847.0
dev_accuracy_tok: 0.9899731318873876
dev_label=0_precision_sent: 0.987460815047022
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9820732657833204
dev_label=1_precision_sent: 0.9942572741194488
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9955913360168679
dev_precision_macro_sent: 0.9908590445832354
dev_recall_macro_sent: 0.9868365843860197
dev_f-score_macro_sent: 0.9888323009000941
dev_precision_micro_sent: 0.9929230769230769
dev_recall_micro_sent: 0.9929230769230769
dev_f-score_micro_sent: 0.9929230769230769
dev_label=O_precision_tok: 0.9964026256161088
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9969848541510846
dev_label=LOC_precision_tok: 0.963315864697475
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.9644645838301932
dev_label=MISC_precision_tok: 0.9126984126984127
dev_label=MISC_recall_tok: 0.9069400630914827
dev_label=MISC_f-score_tok: 0.9098101265822786
dev_label=ORG_precision_tok: 0.9518610421836228
dev_label=ORG_recall_tok: 0.9168260038240917
dev_label=ORG_f-score_tok: 0.9340150961772582
dev_label=PER_precision_tok: 0.9757785467128027
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.9804045512010112
dev_precision_macro_tok: 0.9600112983816844
dev_recall_macro_tok: 0.9544049006276587
dev_f-score_macro_tok: 0.9571358423883651
dev_precision_micro_tok: 0.9899731318873876
dev_recall_micro_tok: 0.9899731318873876
dev_f-score_micro_tok: 0.9899731318873876
dev_time: 6.893563985824585
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9875    0.9767    0.9821       645
           1     0.9943    0.9969    0.9956      2605

   micro avg     0.9929    0.9929    0.9929      3250
   macro avg     0.9909    0.9868    0.9888      3250
weighted avg     0.9929    0.9929    0.9929      3250

F1-macro sent:  0.9888323009000941
F1-micro sent:  0.9929230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9976    0.9970     42759
         LOC     0.9633    0.9656    0.9645      2094
        MISC     0.9127    0.9069    0.9098      1268
         ORG     0.9519    0.9168    0.9340      2092
         PER     0.9758    0.9851    0.9804      3149

   micro avg     0.9900    0.9900    0.9900     51362
   macro avg     0.9600    0.9544    0.9571     51362
weighted avg     0.9899    0.9900    0.9899     51362

F1-macro tok:  0.9571358423883651
F1-micro tok:  0.9899731318873876
**************************************************
Best epoch: 41
**************************************************

EPOCH: 47
Learning rate: 0.729000
train_cost_sum: 279589.8023071289
train_cost_avg: 19.912385322066015
train_count_sent: 14041.0
train_total_correct_sent: 13981.0
train_accuracy_sent: 0.995726800085464
train_count_tok: 203621.0
train_total_correct_tok: 203023.0
train_accuracy_tok: 0.9970631712839049
train_label=0_precision_sent: 0.9890147614143495
train_label=0_recall_sent: 0.9903746992093503
train_label=0_f-score_sent: 0.9896942631398145
train_label=1_precision_sent: 0.9974838245866283
train_label=1_recall_sent: 0.9971254042400287
train_label=1_f-score_sent: 0.9973045822102425
train_precision_macro_sent: 0.9932492930004889
train_recall_macro_sent: 0.9937500517246896
train_f-score_macro_sent: 0.9934994226750284
train_precision_micro_sent: 0.995726800085464
train_recall_micro_sent: 0.995726800085464
train_f-score_micro_sent: 0.995726800085464
train_label=O_precision_tok: 0.9991096593120202
train_label=O_recall_tok: 0.9992274941324936
train_label=O_f-score_tok: 0.9991685732481072
train_label=LOC_precision_tok: 0.98854041013269
train_label=LOC_recall_tok: 0.9877063999035796
train_label=LOC_f-score_tok: 0.9881232290347862
train_label=MISC_precision_tok: 0.9785979471500328
train_label=MISC_recall_tok: 0.9756150664053995
train_label=MISC_f-score_tok: 0.9771042302660271
train_label=ORG_precision_tok: 0.9815590111642744
train_label=ORG_recall_tok: 0.9822443890274314
train_label=ORG_f-score_tok: 0.9819015804955875
train_label=PER_precision_tok: 0.9937960798417551
train_label=PER_recall_tok: 0.9932602444284687
train_label=PER_f-score_tok: 0.9935280898876404
train_precision_macro_tok: 0.9883206215201545
train_recall_macro_tok: 0.9876107187794746
train_f-score_macro_tok: 0.9879651405864298
train_precision_micro_tok: 0.9970631712839049
train_recall_micro_tok: 0.9970631712839049
train_f-score_micro_tok: 0.9970631712839049
train_time: 84.52370572090149
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9890    0.9904    0.9897      2909
           1     0.9975    0.9971    0.9973     11132

   micro avg     0.9957    0.9957    0.9957     14041
   macro avg     0.9932    0.9938    0.9935     14041
weighted avg     0.9957    0.9957    0.9957     14041

F1-macro sent:  0.9934994226750284
F1-micro sent:  0.995726800085464
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9991    0.9992    0.9992    169578
         LOC     0.9885    0.9877    0.9881      8297
        MISC     0.9786    0.9756    0.9771      4593
         ORG     0.9816    0.9822    0.9819     10025
         PER     0.9938    0.9933    0.9935     11128

   micro avg     0.9971    0.9971    0.9971    203621
   macro avg     0.9883    0.9876    0.9880    203621
weighted avg     0.9971    0.9971    0.9971    203621

F1-macro tok:  0.9879651405864298
F1-micro tok:  0.9970631712839049
**************************************************
dev_cost_sum: 79749.19174194336
dev_cost_avg: 24.53821284367488
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50851.0
dev_accuracy_tok: 0.99005101047467
dev_label=0_precision_sent: 0.9873817034700315
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.978889757623143
dev_label=1_precision_sent: 0.992737003058104
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9948285769009768
dev_precision_macro_sent: 0.9900593532640678
dev_recall_macro_sent: 0.9837358091922213
dev_f-score_macro_sent: 0.9868591672620599
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9971473332242149
dev_label=O_recall_tok: 0.9973338946186767
dev_label=O_f-score_tok: 0.9972406051960807
dev_label=LOC_precision_tok: 0.9677884615384615
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9645424053665549
dev_label=MISC_precision_tok: 0.8975950349107835
dev_label=MISC_recall_tok: 0.9124605678233438
dev_label=MISC_f-score_tok: 0.9049667579194369
dev_label=ORG_precision_tok: 0.9452590420332356
dev_label=ORG_recall_tok: 0.9244741873804971
dev_label=ORG_f-score_tok: 0.9347510874818754
dev_label=PER_precision_tok: 0.9754716981132076
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.9802496444936007
dev_precision_macro_tok: 0.9566523139639808
dev_recall_macro_tok: 0.956132265652824
dev_f-score_macro_tok: 0.9563501000915098
dev_precision_micro_tok: 0.99005101047467
dev_recall_micro_tok: 0.99005101047467
dev_f-score_micro_tok: 0.99005101047467
dev_time: 6.892340183258057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9874    0.9705    0.9789       645
           1     0.9927    0.9969    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9901    0.9837    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9868591672620599
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9973    0.9972     42759
         LOC     0.9678    0.9613    0.9645      2094
        MISC     0.8976    0.9125    0.9050      1268
         ORG     0.9453    0.9245    0.9348      2092
         PER     0.9755    0.9851    0.9802      3149

   micro avg     0.9901    0.9901    0.9901     51362
   macro avg     0.9567    0.9561    0.9564     51362
weighted avg     0.9901    0.9901    0.9900     51362

F1-macro tok:  0.9563501000915098
F1-micro tok:  0.99005101047467
**************************************************
Best epoch: 41
**************************************************

EPOCH: 48
Learning rate: 0.656100
train_cost_sum: 278969.08462524414
train_cost_avg: 19.86817780964633
train_count_sent: 14041.0
train_total_correct_sent: 13985.0
train_accuracy_sent: 0.9960116800797664
train_count_tok: 203621.0
train_total_correct_tok: 203056.0
train_accuracy_tok: 0.9972252370826192
train_label=0_precision_sent: 0.9903746992093503
train_label=0_recall_sent: 0.9903746992093503
train_label=0_f-score_sent: 0.9903746992093503
train_label=1_precision_sent: 0.9974847287100251
train_label=1_recall_sent: 0.9974847287100251
train_label=1_f-score_sent: 0.9974847287100251
train_precision_macro_sent: 0.9939297139596877
train_recall_macro_sent: 0.9939297139596877
train_f-score_macro_sent: 0.9939297139596877
train_precision_micro_sent: 0.9960116800797664
train_recall_micro_sent: 0.9960116800797664
train_f-score_micro_sent: 0.9960116800797664
train_label=O_precision_tok: 0.9990978507621098
train_label=O_recall_tok: 0.9991980091757185
train_label=O_f-score_tok: 0.9991479274588485
train_label=LOC_precision_tok: 0.9880852088097244
train_label=LOC_recall_tok: 0.9895142822707003
train_label=LOC_f-score_tok: 0.9887992291942671
train_label=MISC_precision_tok: 0.9801310043668122
train_label=MISC_recall_tok: 0.9773568473764425
train_label=MISC_f-score_tok: 0.9787419601002944
train_label=ORG_precision_tok: 0.9864864864864865
train_label=ORG_recall_tok: 0.9830423940149626
train_label=ORG_f-score_tok: 0.9847614289283039
train_label=PER_precision_tok: 0.9921952094734009
train_label=PER_recall_tok: 0.9938892882818117
train_label=PER_f-score_tok: 0.9930415263748597
train_precision_macro_tok: 0.9891991519797066
train_recall_macro_tok: 0.9886001642239272
train_f-score_macro_tok: 0.9888984144113147
train_precision_micro_tok: 0.9972252370826192
train_recall_micro_tok: 0.9972252370826192
train_f-score_micro_tok: 0.9972252370826192
train_time: 84.3327145576477
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9904    0.9904    0.9904      2909
           1     0.9975    0.9975    0.9975     11132

   micro avg     0.9960    0.9960    0.9960     14041
   macro avg     0.9939    0.9939    0.9939     14041
weighted avg     0.9960    0.9960    0.9960     14041

F1-macro sent:  0.9939297139596877
F1-micro sent:  0.9960116800797664
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9991    0.9992    0.9991    169578
         LOC     0.9881    0.9895    0.9888      8297
        MISC     0.9801    0.9774    0.9787      4593
         ORG     0.9865    0.9830    0.9848     10025
         PER     0.9922    0.9939    0.9930     11128

   micro avg     0.9972    0.9972    0.9972    203621
   macro avg     0.9892    0.9886    0.9889    203621
weighted avg     0.9972    0.9972    0.9972    203621

F1-macro tok:  0.9888984144113147
F1-micro tok:  0.9972252370826192
**************************************************
dev_cost_sum: 79688.29759979248
dev_cost_avg: 24.519476184551532
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50856.0
dev_accuracy_tok: 0.990148358708773
dev_label=0_precision_sent: 0.9768875192604006
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9799072642967541
dev_label=1_precision_sent: 0.9957708573625529
dev_label=1_recall_sent: 0.9942418426103646
dev_label=1_f-score_sent: 0.9950057625816365
dev_precision_macro_sent: 0.9863291883114768
dev_recall_macro_sent: 0.9885937895222365
dev_f-score_macro_sent: 0.9874565134391953
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9963338314963572
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.9970905436827407
dev_label=LOC_precision_tok: 0.9574870099196977
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9627166943718832
dev_label=MISC_precision_tok: 0.9238866396761134
dev_label=MISC_recall_tok: 0.8998422712933754
dev_label=MISC_f-score_tok: 0.9117059528565722
dev_label=ORG_precision_tok: 0.9501972386587771
dev_label=ORG_recall_tok: 0.9211281070745698
dev_label=ORG_f-score_tok: 0.9354368932038836
dev_label=PER_precision_tok: 0.9797340088663711
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9811320754716981
dev_precision_macro_tok: 0.9615277457234633
dev_recall_macro_tok: 0.9538713485624639
dev_f-score_macro_tok: 0.9576164319173556
dev_precision_micro_tok: 0.990148358708773
dev_recall_micro_tok: 0.990148358708773
dev_f-score_micro_tok: 0.990148358708773
dev_time: 6.871073484420776
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9769    0.9829    0.9799       645
           1     0.9958    0.9942    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9863    0.9886    0.9875      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874565134391953
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9971     42759
         LOC     0.9575    0.9680    0.9627      2094
        MISC     0.9239    0.8998    0.9117      1268
         ORG     0.9502    0.9211    0.9354      2092
         PER     0.9797    0.9825    0.9811      3149

   micro avg     0.9901    0.9901    0.9901     51362
   macro avg     0.9615    0.9539    0.9576     51362
weighted avg     0.9901    0.9901    0.9901     51362

F1-macro tok:  0.9576164319173556
F1-micro tok:  0.990148358708773
**************************************************
Best epoch: 41
**************************************************

test0_cost_sum: 80226.46475982666
test0_cost_avg: 24.685066079946665
test0_count_sent: 3250.0
test0_total_correct_sent: 3232.0
test0_accuracy_sent: 0.9944615384615385
test0_count_tok: 51362.0
test0_total_correct_tok: 50881.0
test0_accuracy_tok: 0.9906350998792882
test0_label=0_precision_sent: 0.9906103286384976
test0_label=0_recall_sent: 0.9813953488372092
test0_label=0_f-score_sent: 0.9859813084112149
test0_label=1_precision_sent: 0.9954040597472232
test0_label=1_recall_sent: 0.9976967370441459
test0_label=1_f-score_sent: 0.9965490797546013
test0_precision_macro_sent: 0.9930071941928604
test0_recall_macro_sent: 0.9895460429406775
test0_f-score_macro_sent: 0.991265194082908
test0_precision_micro_sent: 0.9944615384615385
test0_recall_micro_sent: 0.9944615384615385
test0_f-score_micro_sent: 0.9944615384615385
test0_label=O_precision_tok: 0.9965905375741442
test0_label=O_recall_tok: 0.9980588881872822
test0_label=O_f-score_tok: 0.9973241724214486
test0_label=LOC_precision_tok: 0.9683301343570058
test0_label=LOC_recall_tok: 0.9637058261700095
test0_label=LOC_f-score_tok: 0.9660124461464816
test0_label=MISC_precision_tok: 0.9314845024469821
test0_label=MISC_recall_tok: 0.9006309148264984
test0_label=MISC_f-score_tok: 0.9157979149959903
test0_label=ORG_precision_tok: 0.9436071949440933
test0_label=ORG_recall_tok: 0.9278202676864244
test0_label=ORG_f-score_tok: 0.9356471438900941
test0_label=PER_precision_tok: 0.978254018279231
test0_label=PER_recall_tok: 0.9857097491267068
test0_label=PER_f-score_tok: 0.981967731730465
test0_precision_macro_tok: 0.9636532775202913
test0_recall_macro_tok: 0.9551851291993841
test0_f-score_macro_tok: 0.9593498818368958
test0_precision_micro_tok: 0.9906350998792882
test0_recall_micro_tok: 0.9906350998792882
test0_f-score_micro_tok: 0.9906350998792882
test0_time: 6.883309602737427
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9906    0.9814    0.9860       645
           1     0.9954    0.9977    0.9965      2605

   micro avg     0.9945    0.9945    0.9945      3250
   macro avg     0.9930    0.9895    0.9913      3250
weighted avg     0.9945    0.9945    0.9945      3250

F1-macro sent:  0.991265194082908
F1-micro sent:  0.9944615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9981    0.9973     42759
         LOC     0.9683    0.9637    0.9660      2094
        MISC     0.9315    0.9006    0.9158      1268
         ORG     0.9436    0.9278    0.9356      2092
         PER     0.9783    0.9857    0.9820      3149

   micro avg     0.9906    0.9906    0.9906     51362
   macro avg     0.9637    0.9552    0.9593     51362
weighted avg     0.9905    0.9906    0.9906     51362

F1-macro tok:  0.9593498818368958
F1-micro tok:  0.9906350998792882
**************************************************
test1_cost_sum: 72307.62298583984
test1_cost_avg: 20.940522150547306
test1_count_sent: 3453.0
test1_total_correct_sent: 3358.0
test1_accuracy_sent: 0.9724876918621489
test1_count_tok: 46435.0
test1_total_correct_tok: 45474.0
test1_accuracy_tok: 0.9793044040055993
test1_label=0_precision_sent: 0.9588414634146342
test1_label=0_recall_sent: 0.9024390243902439
test1_label=0_f-score_sent: 0.9297856614929786
test1_label=1_precision_sent: 0.9756882373972113
test1_label=1_recall_sent: 0.9902031930333817
test1_label=1_f-score_sent: 0.9828921303799748
test1_precision_macro_sent: 0.9672648504059227
test1_recall_macro_sent: 0.9463211087118129
test1_f-score_macro_sent: 0.9563388959364767
test1_precision_micro_sent: 0.9724876918621489
test1_recall_micro_sent: 0.9724876918621489
test1_f-score_micro_sent: 0.9724876918621489
test1_label=O_precision_tok: 0.9943796727139645
test1_label=O_recall_tok: 0.992589306682671
test1_label=O_f-score_tok: 0.993483683090223
test1_label=LOC_precision_tok: 0.9130658436213992
test1_label=LOC_recall_tok: 0.922077922077922
test1_label=LOC_f-score_tok: 0.9175497544585164
test1_label=MISC_precision_tok: 0.7846638655462185
test1_label=MISC_recall_tok: 0.8137254901960784
test1_label=MISC_f-score_tok: 0.7989304812834225
test1_label=ORG_precision_tok: 0.8764356435643564
test1_label=ORG_recall_tok: 0.8866185897435898
test1_label=ORG_f-score_tok: 0.8814977096195977
test1_label=PER_precision_tok: 0.9782608695652174
test1_label=PER_recall_tok: 0.9736747205192932
test1_label=PER_f-score_tok: 0.9759624073739382
test1_precision_macro_tok: 0.9093611790022311
test1_recall_macro_tok: 0.9177372058439109
test1_f-score_macro_tok: 0.9134848071651396
test1_precision_micro_tok: 0.9793044040055993
test1_recall_micro_tok: 0.9793044040055993
test1_f-score_micro_tok: 0.9793044040055993
test1_time: 6.5146167278289795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9588    0.9024    0.9298       697
           1     0.9757    0.9902    0.9829      2756

   micro avg     0.9725    0.9725    0.9725      3453
   macro avg     0.9673    0.9463    0.9563      3453
weighted avg     0.9723    0.9725    0.9722      3453

F1-macro sent:  0.9563388959364767
F1-micro sent:  0.9724876918621489
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9944    0.9926    0.9935     38323
         LOC     0.9131    0.9221    0.9175      1925
        MISC     0.7847    0.8137    0.7989       918
         ORG     0.8764    0.8866    0.8815      2496
         PER     0.9783    0.9737    0.9760      2773

   micro avg     0.9793    0.9793    0.9793     46435
   macro avg     0.9094    0.9177    0.9135     46435
weighted avg     0.9796    0.9793    0.9794     46435

F1-macro tok:  0.9134848071651396
F1-micro tok:  0.9793044040055993
*************************************************
