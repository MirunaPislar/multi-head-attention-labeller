to_write_filename: runs/transformer_sentiment_model_selector_MICRO_0.7*tok+0.3*sent_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_micro_sent:dev_f-score_micro_tok:high
model_selector_ratio: 0.7:0.3
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'O': 0, 'P': 2, 'N': 1}
{'O': 0, 'P': 2, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 20:57:29.958524: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 20:57:30.043489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 9.98GiB
2019-03-28 20:57:30.043534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 20:57:30.433492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 20:57:30.433543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 20:57:30.433558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 20:57:30.433789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 427405.7830810547
train_cost_avg: 50.02408509843805
train_count_sent: 8544.0
train_total_correct_sent: 4234.0
train_accuracy_sent: 0.4955524344569288
train_count_tok: 163566.0
train_total_correct_tok: 125866.0
train_accuracy_tok: 0.769512001271658
train_label=O_precision_sent: 0.21022727272727273
train_label=O_recall_sent: 0.022783251231527094
train_label=O_f-score_sent: 0.04111111111111111
train_label=N_precision_sent: 0.4848564656307611
train_label=N_recall_sent: 0.5561933534743202
train_label=N_f-score_sent: 0.5180807654425215
train_label=P_precision_sent: 0.5154233209363378
train_label=P_recall_sent: 0.6526315789473685
train_label=P_f-score_sent: 0.5759687079819094
train_precision_macro_sent: 0.4035023530981239
train_recall_macro_sent: 0.4105360612177386
train_f-score_macro_sent: 0.3783868615118473
train_precision_micro_sent: 0.4955524344569288
train_recall_micro_sent: 0.4955524344569288
train_f-score_micro_sent: 0.4955524344569288
train_label=O_precision_tok: 0.7978511658136324
train_label=O_recall_tok: 0.9477430094815316
train_label=O_f-score_tok: 0.8663615812978994
train_label=N_precision_tok: 0.48642145067033343
train_label=N_recall_tok: 0.19926770877341218
train_label=N_f-score_tok: 0.2827172827172827
train_label=P_precision_tok: 0.5166334661354581
train_label=P_recall_tok: 0.207339009473558
train_label=P_f-score_tok: 0.29591807627577943
train_precision_macro_tok: 0.600302027539808
train_recall_macro_tok: 0.45144990924283396
train_f-score_macro_tok: 0.4816656467636538
train_precision_micro_tok: 0.769512001271658
train_recall_micro_tok: 0.769512001271658
train_f-score_micro_tok: 0.7695120012716581
train_time: 95.73619937896729
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2102    0.0228    0.0411      1624
           N     0.4849    0.5562    0.5181      3310
           P     0.5154    0.6526    0.5760      3610

   micro avg     0.4956    0.4956    0.4956      8544
   macro avg     0.4035    0.4105    0.3784      8544
weighted avg     0.4456    0.4956    0.4519      8544

F1-macro sent:  0.3783868615118473
F1-micro sent:  0.4955524344569288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7979    0.9477    0.8664    124347
           N     0.4864    0.1993    0.2827     14202
           P     0.5166    0.2073    0.2959     25017

   micro avg     0.7695    0.7695    0.7695    163566
   macro avg     0.6003    0.4514    0.4817    163566
weighted avg     0.7278    0.7695    0.7284    163566

F1-macro tok:  0.4816656467636538
F1-micro tok:  0.7695120012716581
**************************************************
dev_cost_sum: 50614.713623046875
dev_cost_avg: 45.971583672158836
dev_count_sent: 1101.0
dev_total_correct_sent: 555.0
dev_accuracy_sent: 0.5040871934604905
dev_count_tok: 21274.0
dev_total_correct_tok: 17541.0
dev_accuracy_tok: 0.8245275923662687
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7515151515151515
dev_label=N_recall_sent: 0.2897196261682243
dev_label=N_f-score_sent: 0.418212478920742
dev_label=P_precision_sent: 0.46047008547008544
dev_label=P_recall_sent: 0.9707207207207207
dev_label=P_f-score_sent: 0.6246376811594202
dev_precision_macro_sent: 0.40399507899507897
dev_recall_macro_sent: 0.42014678229631497
dev_f-score_macro_sent: 0.34761672002672067
dev_precision_micro_sent: 0.5040871934604905
dev_recall_micro_sent: 0.5040871934604905
dev_f-score_micro_sent: 0.5040871934604905
dev_label=O_precision_tok: 0.8484915582618323
dev_label=O_recall_tok: 0.9458809009564949
dev_label=O_f-score_tok: 0.8945433323606653
dev_label=N_precision_tok: 0.7061657032755299
dev_label=N_recall_tok: 0.3947226709746904
dev_label=N_f-score_tok: 0.5063903281519861
dev_label=P_precision_tok: 0.6817134960847536
dev_label=P_recall_tok: 0.46077210460772106
dev_label=P_f-score_tok: 0.5498792494891325
dev_precision_macro_tok: 0.7454569192073719
dev_recall_macro_tok: 0.6004585588463022
dev_f-score_macro_tok: 0.6502709700005946
dev_precision_micro_tok: 0.8245275923662687
dev_recall_micro_tok: 0.8245275923662687
dev_f-score_micro_tok: 0.8245275923662687
dev_time: 5.631593227386475
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7515    0.2897    0.4182       428
           P     0.4605    0.9707    0.6246       444

   micro avg     0.5041    0.5041    0.5041      1101
   macro avg     0.4040    0.4201    0.3476      1101
weighted avg     0.4778    0.5041    0.4145      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.34761672002672067
F1-micro sent:  0.5040871934604905
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8485    0.9459    0.8945     16205
           N     0.7062    0.3947    0.5064      1857
           P     0.6817    0.4608    0.5499      3212

   micro avg     0.8245    0.8245    0.8245     21274
   macro avg     0.7455    0.6005    0.6503     21274
weighted avg     0.8109    0.8245    0.8086     21274

F1-macro tok:  0.6502709700005946
F1-micro tok:  0.8245275923662687
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378460.7127685547
train_cost_avg: 44.295495408304625
train_count_sent: 8544.0
train_total_correct_sent: 4863.0
train_accuracy_sent: 0.5691713483146067
train_count_tok: 163566.0
train_total_correct_tok: 132341.0
train_accuracy_tok: 0.8090984678967511
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012285012285012285
train_label=N_precision_sent: 0.5433108758421559
train_label=N_recall_sent: 0.6821752265861027
train_label=N_f-score_sent: 0.6048754353067238
train_label=P_precision_sent: 0.593978102189781
train_label=P_recall_sent: 0.7213296398891966
train_label=P_f-score_sent: 0.6514886164623467
train_precision_macro_sent: 0.46242965934397895
train_recall_macro_sent: 0.4680402100073658
train_f-score_macro_sent: 0.4191975176658573
train_precision_micro_sent: 0.5691713483146067
train_recall_micro_sent: 0.5691713483146067
train_f-score_micro_sent: 0.5691713483146067
train_label=O_precision_tok: 0.8319633159351689
train_label=O_recall_tok: 0.9498661005090593
train_label=O_f-score_tok: 0.8870139233091516
train_label=N_precision_tok: 0.6417963224893918
train_label=N_recall_tok: 0.38339670468948034
train_label=N_f-score_tok: 0.48003173763554613
train_label=P_precision_tok: 0.6697933348585373
train_label=P_recall_tok: 0.3510812647399768
train_label=P_f-score_tok: 0.4606871230002623
train_precision_macro_tok: 0.7145176577610326
train_recall_macro_tok: 0.5614480233128388
train_f-score_macro_tok: 0.6092442613149867
train_precision_micro_tok: 0.8090984678967511
train_recall_micro_tok: 0.8090984678967511
train_f-score_micro_tok: 0.8090984678967511
train_time: 94.3120265007019
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0006    0.0012      1624
           N     0.5433    0.6822    0.6049      3310
           P     0.5940    0.7213    0.6515      3610

   micro avg     0.5692    0.5692    0.5692      8544
   macro avg     0.4624    0.4680    0.4192      8544
weighted avg     0.5090    0.5692    0.5098      8544

F1-macro sent:  0.4191975176658573
F1-micro sent:  0.5691713483146067
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8320    0.9499    0.8870    124347
           N     0.6418    0.3834    0.4800     14202
           P     0.6698    0.3511    0.4607     25017

   micro avg     0.8091    0.8091    0.8091    163566
   macro avg     0.7145    0.5614    0.6092    163566
weighted avg     0.7906    0.8091    0.7865    163566

F1-macro tok:  0.6092442613149867
F1-micro tok:  0.8090984678967511
**************************************************
dev_cost_sum: 49088.78857421875
dev_cost_avg: 44.58563903198797
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 17798.0
dev_accuracy_tok: 0.8366080661840745
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5587349397590361
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.6794871794871795
dev_label=P_precision_sent: 0.700228832951945
dev_label=P_recall_sent: 0.6891891891891891
dev_label=P_f-score_sent: 0.6946651532349601
dev_precision_macro_sent: 0.41965459090366036
dev_recall_macro_sent: 0.518670539698577
dev_f-score_macro_sent: 0.45805077757404655
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8471027430611914
dev_label=O_recall_tok: 0.9661832767664301
dev_label=O_f-score_tok: 0.9027329335793358
dev_label=N_precision_tok: 0.6949152542372882
dev_label=N_recall_tok: 0.4857296715131933
dev_label=N_f-score_tok: 0.5717908082408876
dev_label=P_precision_tok: 0.8298727394507702
dev_label=P_recall_tok: 0.3857409713574097
dev_label=P_f-score_tok: 0.5266737513283741
dev_precision_macro_tok: 0.7906302455830833
dev_recall_macro_tok: 0.6125513065456777
dev_f-score_macro_tok: 0.6670658310495327
dev_precision_micro_tok: 0.8366080661840745
dev_recall_micro_tok: 0.8366080661840745
dev_f-score_micro_tok: 0.8366080661840745
dev_time: 5.140506029129028
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5587    0.8668    0.6795       428
           P     0.7002    0.6892    0.6947       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4197    0.5187    0.4581      1101
weighted avg     0.4996    0.6149    0.5443      1101

F1-macro sent:  0.45805077757404655
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8471    0.9662    0.9027     16205
           N     0.6949    0.4857    0.5718      1857
           P     0.8299    0.3857    0.5267      3212

   micro avg     0.8366    0.8366    0.8366     21274
   macro avg     0.7906    0.6126    0.6671     21274
weighted avg     0.8312    0.8366    0.8171     21274

F1-macro tok:  0.6670658310495327
F1-micro tok:  0.8366080661840745
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368479.86364746094
train_cost_avg: 43.12732486510545
train_count_sent: 8544.0
train_total_correct_sent: 5025.0
train_accuracy_sent: 0.5881320224719101
train_count_tok: 163566.0
train_total_correct_tok: 135619.0
train_accuracy_tok: 0.8291393076800803
train_label=O_precision_sent: 0.3
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003671970624235006
train_label=N_precision_sent: 0.5510940672230995
train_label=N_recall_sent: 0.7380664652567975
train_label=N_f-score_sent: 0.6310215678677515
train_label=P_precision_sent: 0.6288710070714459
train_label=P_recall_sent: 0.714404432132964
train_label=P_f-score_sent: 0.6689145376734534
train_precision_macro_sent: 0.4933216914315152
train_recall_macro_sent: 0.4847727293433852
train_f-score_macro_sent: 0.43453602538847996
train_precision_micro_sent: 0.5881320224719101
train_recall_micro_sent: 0.5881320224719101
train_f-score_micro_sent: 0.5881320224719101
train_label=O_precision_tok: 0.8492984881147629
train_label=O_recall_tok: 0.9536619299219121
train_label=O_f-score_tok: 0.89845969678832
train_label=N_precision_tok: 0.6777728580916538
train_label=N_recall_tok: 0.4311364596535699
train_label=N_f-score_tok: 0.5270270270270271
train_label=P_precision_tok: 0.7320362294532036
train_label=P_recall_tok: 0.43614342247271853
train_label=P_f-score_tok: 0.5466159010069636
train_precision_macro_tok: 0.7530358585532068
train_recall_macro_tok: 0.6069806040160669
train_f-score_macro_tok: 0.6573675416074368
train_precision_micro_tok: 0.8291393076800803
train_recall_micro_tok: 0.8291393076800803
train_f-score_micro_tok: 0.8291393076800803
train_time: 94.34608721733093
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3000    0.0018    0.0037      1624
           N     0.5511    0.7381    0.6310      3310
           P     0.6289    0.7144    0.6689      3610

   micro avg     0.5881    0.5881    0.5881      8544
   macro avg     0.4933    0.4848    0.4345      8544
weighted avg     0.5362    0.5881    0.5278      8544

F1-macro sent:  0.43453602538847996
F1-micro sent:  0.5881320224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8493    0.9537    0.8985    124347
           N     0.6778    0.4311    0.5270     14202
           P     0.7320    0.4361    0.5466     25017

   micro avg     0.8291    0.8291    0.8291    163566
   macro avg     0.7530    0.6070    0.6574    163566
weighted avg     0.8165    0.8291    0.8124    163566

F1-macro tok:  0.6573675416074368
F1-micro tok:  0.8291393076800803
**************************************************
dev_cost_sum: 48049.84020996094
dev_cost_avg: 43.64199837416979
dev_count_sent: 1101.0
dev_total_correct_sent: 681.0
dev_accuracy_sent: 0.6185286103542235
dev_count_tok: 21274.0
dev_total_correct_tok: 18286.0
dev_accuracy_tok: 0.8595468647174955
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5855704697986577
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.681640625
dev_label=P_precision_sent: 0.6574257425742575
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.6996838777660696
dev_precision_macro_sent: 0.4143320707909717
dev_recall_macro_sent: 0.5210561028318038
dev_f-score_macro_sent: 0.46044150092202313
dev_precision_micro_sent: 0.6185286103542235
dev_recall_micro_sent: 0.6185286103542235
dev_f-score_micro_sent: 0.6185286103542235
dev_label=O_precision_tok: 0.8688188714768259
dev_label=O_recall_tok: 0.9682196852823203
dev_label=O_f-score_tok: 0.9158300256829326
dev_label=N_precision_tok: 0.7649769585253456
dev_label=N_recall_tok: 0.44695745826602046
dev_label=N_f-score_tok: 0.5642420122365738
dev_label=P_precision_tok: 0.8291079812206573
dev_label=P_recall_tok: 0.549813200498132
dev_label=P_f-score_tok: 0.6611755896667915
dev_precision_macro_tok: 0.8209679370742763
dev_recall_macro_tok: 0.6549967813488242
dev_f-score_macro_tok: 0.7137492091954326
dev_precision_micro_tok: 0.8595468647174955
dev_recall_micro_tok: 0.8595468647174955
dev_f-score_micro_tok: 0.8595468647174955
dev_time: 5.253493309020996
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5856    0.8154    0.6816       428
           P     0.6574    0.7477    0.6997       444

   micro avg     0.6185    0.6185    0.6185      1101
   macro avg     0.4143    0.5211    0.4604      1101
weighted avg     0.4928    0.6185    0.5471      1101

F1-macro sent:  0.46044150092202313
F1-micro sent:  0.6185286103542235
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8688    0.9682    0.9158     16205
           N     0.7650    0.4470    0.5642      1857
           P     0.8291    0.5498    0.6612      3212

   micro avg     0.8595    0.8595    0.8595     21274
   macro avg     0.8210    0.6550    0.7137     21274
weighted avg     0.8538    0.8595    0.8467     21274

F1-macro tok:  0.7137492091954326
F1-micro tok:  0.8595468647174955
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361725.6687011719
train_cost_avg: 42.33680579367648
train_count_sent: 8544.0
train_total_correct_sent: 5091.0
train_accuracy_sent: 0.5958567415730337
train_count_tok: 163566.0
train_total_correct_tok: 137680.0
train_accuracy_tok: 0.8417397258598975
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.001229256299938537
train_label=N_precision_sent: 0.5625712331889674
train_label=N_recall_sent: 0.7456193353474321
train_label=N_f-score_sent: 0.6412888138235676
train_label=P_precision_sent: 0.6311988444872412
train_label=P_recall_sent: 0.7263157894736842
train_label=P_f-score_sent: 0.6754250386398764
train_precision_macro_sent: 0.5090344703365139
train_recall_macro_sent: 0.49085029612263814
train_f-score_macro_sent: 0.43931436958779413
train_precision_micro_sent: 0.5958567415730337
train_recall_micro_sent: 0.5958567415730337
train_f-score_micro_sent: 0.5958567415730337
train_label=O_precision_tok: 0.8603839694214397
train_label=O_recall_tok: 0.9557930629609078
train_label=O_f-score_tok: 0.9055824567686288
train_label=N_precision_tok: 0.6952257786399396
train_label=N_recall_tok: 0.4542317983382622
train_label=N_f-score_tok: 0.5494655253183425
train_label=P_precision_tok: 0.7664540895300601
train_label=P_recall_tok: 0.4948235200063957
train_label=P_f-score_tok: 0.6013894286824719
train_precision_macro_tok: 0.7740212791971465
train_recall_macro_tok: 0.6349494604351886
train_f-score_macro_tok: 0.6854791369231478
train_precision_micro_tok: 0.8417397258598975
train_recall_micro_tok: 0.8417397258598975
train_f-score_micro_tok: 0.8417397258598976
train_time: 95.5736472606659
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0006    0.0012      1624
           N     0.5626    0.7456    0.6413      3310
           P     0.6312    0.7263    0.6754      3610

   micro avg     0.5959    0.5959    0.5959      8544
   macro avg     0.5090    0.4909    0.4393      8544
weighted avg     0.5480    0.5959    0.5341      8544

F1-macro sent:  0.43931436958779413
F1-micro sent:  0.5958567415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8604    0.9558    0.9056    124347
           N     0.6952    0.4542    0.5495     14202
           P     0.7665    0.4948    0.6014     25017

   micro avg     0.8417    0.8417    0.8417    163566
   macro avg     0.7740    0.6349    0.6855    163566
weighted avg     0.8317    0.8417    0.8281    163566

F1-macro tok:  0.6854791369231478
F1-micro tok:  0.8417397258598976
**************************************************
dev_cost_sum: 47513.82409667969
dev_cost_avg: 43.15515358463187
dev_count_sent: 1101.0
dev_total_correct_sent: 635.0
dev_accuracy_sent: 0.5767484105358764
dev_count_tok: 21274.0
dev_total_correct_tok: 18381.0
dev_accuracy_tok: 0.8640124095139607
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6837349397590361
dev_label=N_recall_sent: 0.530373831775701
dev_label=N_f-score_sent: 0.5973684210526317
dev_label=P_precision_sent: 0.5305591677503251
dev_label=P_recall_sent: 0.918918918918919
dev_label=P_f-score_sent: 0.6727122835943941
dev_precision_macro_sent: 0.4047647025031204
dev_recall_macro_sent: 0.48309758356487337
dev_f-score_macro_sent: 0.4233602348823419
dev_precision_micro_sent: 0.5767484105358764
dev_recall_micro_sent: 0.5767484105358764
dev_f-score_micro_sent: 0.5767484105358764
dev_label=O_precision_tok: 0.8723817989888327
dev_label=O_recall_tok: 0.9689601974699167
dev_label=O_f-score_tok: 0.9181382294468484
dev_label=N_precision_tok: 0.7878495660559306
dev_label=N_recall_tok: 0.4399569197630587
dev_label=N_f-score_tok: 0.5646164478230823
dev_label=P_precision_tok: 0.8319928507596068
dev_label=P_recall_tok: 0.5797011207970112
dev_label=P_f-score_tok: 0.6833027522935781
dev_precision_macro_tok: 0.8307414052681233
dev_recall_macro_tok: 0.6628727460099956
dev_f-score_macro_tok: 0.7220191431878362
dev_precision_micro_tok: 0.8640124095139607
dev_recall_micro_tok: 0.8640124095139607
dev_f-score_micro_tok: 0.8640124095139607
dev_time: 4.785463571548462
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6837    0.5304    0.5974       428
           P     0.5306    0.9189    0.6727       444

   micro avg     0.5767    0.5767    0.5767      1101
   macro avg     0.4048    0.4831    0.4234      1101
weighted avg     0.4798    0.5767    0.5035      1101

F1-macro sent:  0.4233602348823419
F1-micro sent:  0.5767484105358764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8724    0.9690    0.9181     16205
           N     0.7878    0.4400    0.5646      1857
           P     0.8320    0.5797    0.6833      3212

   micro avg     0.8640    0.8640    0.8640     21274
   macro avg     0.8307    0.6629    0.7220     21274
weighted avg     0.8589    0.8640    0.8518     21274

F1-macro tok:  0.7220191431878362
F1-micro tok:  0.8640124095139607
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355821.52770996094
train_cost_avg: 41.64577805594112
train_count_sent: 8544.0
train_total_correct_sent: 5223.0
train_accuracy_sent: 0.6113061797752809
train_count_tok: 163566.0
train_total_correct_tok: 139198.0
train_accuracy_tok: 0.8510203832092245
train_label=O_precision_sent: 0.37142857142857144
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015672091621458713
train_label=N_precision_sent: 0.5843907110366292
train_label=N_recall_sent: 0.7374622356495468
train_label=N_f-score_sent: 0.6520635768665688
train_label=P_precision_sent: 0.639196675900277
train_label=P_recall_sent: 0.7670360110803324
train_label=P_f-score_sent: 0.6973054646184839
train_precision_macro_sent: 0.5316719861218259
train_recall_macro_sent: 0.5041677242794179
train_f-score_macro_sent: 0.45501371103550375
train_precision_micro_sent: 0.6113061797752809
train_recall_micro_sent: 0.6113061797752809
train_f-score_micro_sent: 0.6113061797752809
train_label=O_precision_tok: 0.8671709794859497
train_label=O_recall_tok: 0.9596853965113754
train_label=O_f-score_tok: 0.9110856619331195
train_label=N_precision_tok: 0.7174051303794785
train_label=N_recall_tok: 0.47655259822560203
train_label=N_f-score_tok: 0.5726857336266712
train_label=P_precision_tok: 0.7927840668321327
train_label=P_recall_tok: 0.5234840308590158
train_label=P_f-score_tok: 0.6305855161787365
train_precision_macro_tok: 0.7924533922325203
train_recall_macro_tok: 0.6532406751986645
train_f-score_macro_tok: 0.7047856372461757
train_precision_micro_tok: 0.8510203832092245
train_recall_micro_tok: 0.8510203832092245
train_f-score_micro_tok: 0.8510203832092245
train_time: 95.3381130695343
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3714    0.0080    0.0157      1624
           N     0.5844    0.7375    0.6521      3310
           P     0.6392    0.7670    0.6973      3610

   micro avg     0.6113    0.6113    0.6113      8544
   macro avg     0.5317    0.5042    0.4550      8544
weighted avg     0.5671    0.6113    0.5502      8544

F1-macro sent:  0.45501371103550375
F1-micro sent:  0.6113061797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8672    0.9597    0.9111    124347
           N     0.7174    0.4766    0.5727     14202
           P     0.7928    0.5235    0.6306     25017

   micro avg     0.8510    0.8510    0.8510    163566
   macro avg     0.7925    0.6532    0.7048    163566
weighted avg     0.8428    0.8510    0.8388    163566

F1-macro tok:  0.7047856372461757
F1-micro tok:  0.8510203832092245
**************************************************
dev_cost_sum: 46767.17102050781
dev_cost_avg: 42.47699456903525
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18506.0
dev_accuracy_tok: 0.8698881263514149
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6247689463955638
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.6976264189886481
dev_label=P_precision_sent: 0.6339285714285714
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7071713147410359
dev_precision_macro_sent: 0.41956583927471175
dev_recall_macro_sent: 0.5297563919059246
dev_f-score_macro_sent: 0.468265911243228
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8828147060484555
dev_label=O_recall_tok: 0.9646405430422709
dev_label=O_f-score_tok: 0.9219155461193678
dev_label=N_precision_tok: 0.7173295454545454
dev_label=N_recall_tok: 0.5438879913839526
dev_label=N_f-score_tok: 0.6186830015313936
dev_label=P_precision_tok: 0.8633626679018064
dev_label=P_recall_tok: 0.5803237858032378
dev_label=P_f-score_tok: 0.6940979333457457
dev_precision_macro_tok: 0.8211689731349358
dev_recall_macro_tok: 0.6962841067431538
dev_f-score_macro_tok: 0.7448988269988357
dev_precision_micro_tok: 0.8698881263514149
dev_recall_micro_tok: 0.8698881263514149
dev_f-score_micro_tok: 0.8698881263514149
dev_time: 4.834343910217285
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6248    0.7897    0.6976       428
           P     0.6339    0.7995    0.7072       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.4196    0.5298    0.4683      1101
weighted avg     0.4985    0.6294    0.5564      1101

F1-macro sent:  0.468265911243228
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8828    0.9646    0.9219     16205
           N     0.7173    0.5439    0.6187      1857
           P     0.8634    0.5803    0.6941      3212

   micro avg     0.8699    0.8699    0.8699     21274
   macro avg     0.8212    0.6963    0.7449     21274
weighted avg     0.8654    0.8699    0.8611     21274

F1-macro tok:  0.7448988269988357
F1-micro tok:  0.8698881263514149
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351151.7150878906
train_cost_avg: 41.09921758987484
train_count_sent: 8544.0
train_total_correct_sent: 5285.0
train_accuracy_sent: 0.618562734082397
train_count_tok: 163566.0
train_total_correct_tok: 140218.0
train_accuracy_tok: 0.8572563980289302
train_label=O_precision_sent: 0.43478260869565216
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012143290831815423
train_label=N_precision_sent: 0.5798281320669381
train_label=N_recall_sent: 0.7746223564954683
train_label=N_f-score_sent: 0.6632177961717537
train_label=P_precision_sent: 0.6613808245913637
train_label=P_recall_sent: 0.7509695290858726
train_label=P_f-score_sent: 0.7033337657283694
train_precision_macro_sent: 0.5586638551179847
train_recall_macro_sent: 0.510583173683107
train_f-score_macro_sent: 0.45956495091064614
train_precision_micro_sent: 0.618562734082397
train_recall_micro_sent: 0.618562734082397
train_f-score_micro_sent: 0.618562734082397
train_label=O_precision_tok: 0.8727418765972983
train_label=O_recall_tok: 0.9611972946673422
train_label=O_f-score_tok: 0.9148363739346413
train_label=N_precision_tok: 0.7202733020599633
train_label=N_recall_tok: 0.4973243205182369
train_label=N_f-score_tok: 0.5883872042652449
train_label=P_precision_tok: 0.8110053539559786
train_label=P_recall_tok: 0.5449494343846185
train_label=P_f-score_tok: 0.651875582757549
train_precision_macro_tok: 0.8013401775377468
train_recall_macro_tok: 0.6678236831900658
train_f-score_macro_tok: 0.7183663869858118
train_precision_micro_tok: 0.8572563980289302
train_recall_micro_tok: 0.8572563980289302
train_f-score_micro_tok: 0.8572563980289302
train_time: 95.96187472343445
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4348    0.0062    0.0121      1624
           N     0.5798    0.7746    0.6632      3310
           P     0.6614    0.7510    0.7033      3610

   micro avg     0.6186    0.6186    0.6186      8544
   macro avg     0.5587    0.5106    0.4596      8544
weighted avg     0.5867    0.6186    0.5564      8544

F1-macro sent:  0.45956495091064614
F1-micro sent:  0.618562734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8727    0.9612    0.9148    124347
           N     0.7203    0.4973    0.5884     14202
           P     0.8110    0.5449    0.6519     25017

   micro avg     0.8573    0.8573    0.8573    163566
   macro avg     0.8013    0.6678    0.7184    163566
weighted avg     0.8501    0.8573    0.8463    163566

F1-macro tok:  0.7183663869858118
F1-micro tok:  0.8572563980289302
**************************************************
dev_cost_sum: 46263.53967285156
dev_cost_avg: 42.019563735560006
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18589.0
dev_accuracy_tok: 0.8737896023314844
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5620437956204379
dev_label=N_recall_sent: 0.8995327102803738
dev_label=N_f-score_sent: 0.6918238993710691
dev_label=P_precision_sent: 0.7403846153846154
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7162790697674419
dev_precision_macro_sent: 0.4341428036683512
dev_recall_macro_sent: 0.5310754679913559
dev_f-score_macro_sent: 0.46936765637950373
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8771540976339558
dev_label=O_recall_tok: 0.9768589941376119
dev_label=O_f-score_tok: 0.9243255868270466
dev_label=N_precision_tok: 0.7883149872988993
dev_label=N_recall_tok: 0.5013462574044157
dev_label=N_f-score_tok: 0.6129032258064515
dev_label=P_precision_tok: 0.8934506353861192
dev_label=P_recall_tok: 0.5691158156911582
dev_label=P_f-score_tok: 0.6953214149866869
dev_precision_macro_tok: 0.8529732401063247
dev_recall_macro_tok: 0.6824403557443953
dev_f-score_macro_tok: 0.7441834092067282
dev_precision_micro_tok: 0.8737896023314844
dev_recall_micro_tok: 0.8737896023314844
dev_f-score_micro_tok: 0.8737896023314844
dev_time: 4.302611589431763
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5620    0.8995    0.6918       428
           P     0.7404    0.6937    0.7163       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.4341    0.5311    0.4694      1101
weighted avg     0.5171    0.6294    0.5578      1101

F1-macro sent:  0.46936765637950373
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8772    0.9769    0.9243     16205
           N     0.7883    0.5013    0.6129      1857
           P     0.8935    0.5691    0.6953      3212

   micro avg     0.8738    0.8738    0.8738     21274
   macro avg     0.8530    0.6824    0.7442     21274
weighted avg     0.8719    0.8738    0.8626     21274

F1-macro tok:  0.7441834092067282
F1-micro tok:  0.8737896023314844
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347059.8618774414
train_cost_avg: 40.62030218603013
train_count_sent: 8544.0
train_total_correct_sent: 5356.0
train_accuracy_sent: 0.62687265917603
train_count_tok: 163566.0
train_total_correct_tok: 141011.0
train_accuracy_tok: 0.8621045938642505
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008547008547008548
train_label=N_precision_sent: 0.5891156462585034
train_label=N_recall_sent: 0.7848942598187311
train_label=N_f-score_sent: 0.6730569948186528
train_label=P_precision_sent: 0.6677184466019418
train_label=P_recall_sent: 0.7620498614958449
train_label=P_f-score_sent: 0.7117723156532989
train_precision_macro_sent: 0.585611364286815
train_recall_macro_sent: 0.5170848220473874
train_f-score_macro_sent: 0.46445877300632005
train_precision_micro_sent: 0.62687265917603
train_recall_micro_sent: 0.62687265917603
train_f-score_micro_sent: 0.62687265917603
train_label=O_precision_tok: 0.8759544355221721
train_label=O_recall_tok: 0.9641085028187251
train_label=O_f-score_tok: 0.9179198186885548
train_label=N_precision_tok: 0.7358700040371418
train_label=N_recall_tok: 0.5133783974088156
train_label=N_f-score_tok: 0.6048112816258814
train_label=P_precision_tok: 0.8237185211644936
train_label=P_recall_tok: 0.553063916536755
train_label=P_f-score_tok: 0.6617879179222271
train_precision_macro_tok: 0.8118476535746025
train_recall_macro_tok: 0.6768502722547654
train_f-score_macro_tok: 0.7281730060788877
train_precision_micro_tok: 0.8621045938642505
train_recall_micro_tok: 0.8621045938642505
train_f-score_micro_tok: 0.8621045938642505
train_time: 95.54386377334595
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0043    0.0085      1624
           N     0.5891    0.7849    0.6731      3310
           P     0.6677    0.7620    0.7118      3610

   micro avg     0.6269    0.6269    0.6269      8544
   macro avg     0.5856    0.5171    0.4645      8544
weighted avg     0.6054    0.6269    0.5631      8544

F1-macro sent:  0.46445877300632005
F1-micro sent:  0.62687265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8760    0.9641    0.9179    124347
           N     0.7359    0.5134    0.6048     14202
           P     0.8237    0.5531    0.6618     25017

   micro avg     0.8621    0.8621    0.8621    163566
   macro avg     0.8118    0.6769    0.7282    163566
weighted avg     0.8558    0.8621    0.8516    163566

F1-macro tok:  0.7281730060788877
F1-micro tok:  0.8621045938642505
**************************************************
dev_cost_sum: 45936.45275878906
dev_cost_avg: 41.722482069744835
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18657.0
dev_accuracy_tok: 0.8769859922910596
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6337209302325582
dev_label=N_recall_sent: 0.764018691588785
dev_label=N_f-score_sent: 0.6927966101694916
dev_label=P_precision_sent: 0.6256410256410256
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7113702623906706
dev_precision_macro_sent: 0.41978731862452795
dev_recall_macro_sent: 0.5294476719710365
dev_f-score_macro_sent: 0.4680556241867207
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8783955739972338
dev_label=O_recall_tok: 0.9797593335390312
dev_label=O_f-score_tok: 0.9263127187864644
dev_label=N_precision_tok: 0.844776119402985
dev_label=N_recall_tok: 0.45718901453957994
dev_label=N_f-score_tok: 0.5932914046121592
dev_label=P_precision_tok: 0.8801276207839562
dev_label=P_recall_tok: 0.6011830635118306
dev_label=P_f-score_tok: 0.7143914169441361
dev_precision_macro_tok: 0.8677664380613916
dev_recall_macro_tok: 0.6793771371968139
dev_f-score_macro_tok: 0.7446651801142532
dev_precision_micro_tok: 0.8769859922910596
dev_recall_micro_tok: 0.8769859922910596
dev_f-score_micro_tok: 0.8769859922910596
dev_time: 4.156773328781128
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6337    0.7640    0.6928       428
           P     0.6256    0.8243    0.7114       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.4198    0.5294    0.4681      1101
weighted avg     0.4987    0.6294    0.5562      1101

F1-macro sent:  0.4680556241867207
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8784    0.9798    0.9263     16205
           N     0.8448    0.4572    0.5933      1857
           P     0.8801    0.6012    0.7144      3212

   micro avg     0.8770    0.8770    0.8770     21274
   macro avg     0.8678    0.6794    0.7447     21274
weighted avg     0.8757    0.8770    0.8652     21274

F1-macro tok:  0.7446651801142532
F1-micro tok:  0.8769859922910596
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342922.6085205078
train_cost_avg: 40.13607309462872
train_count_sent: 8544.0
train_total_correct_sent: 5438.0
train_accuracy_sent: 0.6364700374531835
train_count_tok: 163566.0
train_total_correct_tok: 141711.0
train_accuracy_tok: 0.8663842118777741
train_label=O_precision_sent: 0.36363636363636365
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.01448400724200362
train_label=N_precision_sent: 0.6046240074731434
train_label=N_recall_sent: 0.7821752265861027
train_label=N_f-score_sent: 0.6820337197049526
train_label=P_precision_sent: 0.670844171198865
train_label=P_recall_sent: 0.7858725761772853
train_label=P_f-score_sent: 0.7238168133690521
train_precision_macro_sent: 0.5463681807694574
train_recall_macro_sent: 0.5251456551083215
train_f-score_macro_sent: 0.47344484677200277
train_precision_micro_sent: 0.6364700374531835
train_recall_micro_sent: 0.6364700374531835
train_f-score_micro_sent: 0.6364700374531835
train_label=O_precision_tok: 0.8796170832997634
train_label=O_recall_tok: 0.9658053672384537
train_label=O_f-score_tok: 0.9206985640797614
train_label=N_precision_tok: 0.7371179903075858
train_label=N_recall_tok: 0.5247852415152795
train_label=N_f-score_tok: 0.6130876485830625
train_label=P_precision_tok: 0.8368588986055306
train_label=P_recall_tok: 0.566135028180837
train_label=P_f-score_tok: 0.6753773157530818
train_precision_macro_tok: 0.8178646574042934
train_recall_macro_tok: 0.6855752123115234
train_f-score_macro_tok: 0.736387842805302
train_precision_micro_tok: 0.8663842118777741
train_recall_micro_tok: 0.8663842118777741
train_f-score_micro_tok: 0.8663842118777741
train_time: 96.15878462791443
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3636    0.0074    0.0145      1624
           N     0.6046    0.7822    0.6820      3310
           P     0.6708    0.7859    0.7238      3610

   micro avg     0.6365    0.6365    0.6365      8544
   macro avg     0.5464    0.5251    0.4734      8544
weighted avg     0.5868    0.6365    0.5728      8544

F1-macro sent:  0.47344484677200277
F1-micro sent:  0.6364700374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8796    0.9658    0.9207    124347
           N     0.7371    0.5248    0.6131     14202
           P     0.8369    0.5661    0.6754     25017

   micro avg     0.8664    0.8664    0.8664    163566
   macro avg     0.8179    0.6856    0.7364    163566
weighted avg     0.8607    0.8664    0.8565    163566

F1-macro tok:  0.736387842805302
F1-micro tok:  0.8663842118777741
**************************************************
dev_cost_sum: 45350.94842529297
dev_cost_avg: 41.1906888513106
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18798.0
dev_accuracy_tok: 0.8836138008837078
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6132879045996593
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7093596059113301
dev_label=P_precision_sent: 0.6686274509803921
dev_label=P_recall_sent: 0.7680180180180181
dev_label=P_f-score_sent: 0.7148846960167714
dev_precision_macro_sent: 0.6773051185266837
dev_recall_macro_sent: 0.5407466500087812
dev_f-score_macro_sent: 0.483331791629825
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8891262790959181
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9304815980700774
dev_label=N_precision_tok: 0.7796352583586627
dev_label=N_recall_tok: 0.5525040387722132
dev_label=N_f-score_tok: 0.6467065868263473
dev_label=P_precision_tok: 0.9014732965009208
dev_label=P_recall_tok: 0.6095890410958904
dev_label=P_f-score_tok: 0.7273402674591382
dev_precision_macro_tok: 0.8567449446518339
dev_recall_macro_tok: 0.7126549081407512
dev_f-score_macro_tok: 0.7681761507851875
dev_precision_micro_tok: 0.8836138008837078
dev_recall_micro_tok: 0.8836138008837078
dev_f-score_micro_tok: 0.8836138008837078
dev_time: 3.9180843830108643
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6133    0.8411    0.7094       428
           P     0.6686    0.7680    0.7149       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6773    0.5407    0.4833      1101
weighted avg     0.6640    0.6394    0.5694      1101

F1-macro sent:  0.483331791629825
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8891    0.9759    0.9305     16205
           N     0.7796    0.5525    0.6467      1857
           P     0.9015    0.6096    0.7273      3212

   micro avg     0.8836    0.8836    0.8836     21274
   macro avg     0.8567    0.7127    0.7682     21274
weighted avg     0.8814    0.8836    0.8750     21274

F1-macro tok:  0.7681761507851875
F1-micro tok:  0.8836138008837078
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339285.49395751953
train_cost_avg: 39.71038084708796
train_count_sent: 8544.0
train_total_correct_sent: 5407.0
train_accuracy_sent: 0.6328417602996255
train_count_tok: 163566.0
train_total_correct_tok: 142400.0
train_accuracy_tok: 0.8705965787510852
train_label=O_precision_sent: 0.14285714285714285
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036474164133738596
train_label=N_precision_sent: 0.5991219963031423
train_label=N_recall_sent: 0.7833836858006042
train_label=N_f-score_sent: 0.6789735532862007
train_label=P_precision_sent: 0.6700834326579261
train_label=P_recall_sent: 0.7786703601108034
train_label=P_f-score_sent: 0.7203074951953876
train_precision_macro_sent: 0.4706875239394038
train_recall_macro_sent: 0.5213004455172673
train_f-score_macro_sent: 0.4676428216316541
train_precision_micro_sent: 0.6328417602996255
train_recall_micro_sent: 0.6328417602996255
train_f-score_micro_sent: 0.6328417602996255
train_label=O_precision_tok: 0.8824474759853527
train_label=O_recall_tok: 0.9670679630389153
train_label=O_f-score_tok: 0.9228219079265438
train_label=N_precision_tok: 0.7513258691809075
train_label=N_recall_tok: 0.5386565272496832
train_label=N_f-score_tok: 0.6274606299212598
train_label=P_precision_tok: 0.8471921930695963
train_label=P_recall_tok: 0.5795259223727866
train_label=P_f-score_tok: 0.6882506527415144
train_precision_macro_tok: 0.8269885127452854
train_recall_macro_tok: 0.6950834708871283
train_f-score_macro_tok: 0.7461777301964393
train_precision_micro_tok: 0.8705965787510852
train_recall_micro_tok: 0.8705965787510852
train_f-score_micro_tok: 0.8705965787510851
train_time: 96.2204954624176
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1429    0.0018    0.0036      1624
           N     0.5991    0.7834    0.6790      3310
           P     0.6701    0.7787    0.7203      3610

   micro avg     0.6328    0.6328    0.6328      8544
   macro avg     0.4707    0.5213    0.4676      8544
weighted avg     0.5424    0.6328    0.5681      8544

F1-macro sent:  0.4676428216316541
F1-micro sent:  0.6328417602996255
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8824    0.9671    0.9228    124347
           N     0.7513    0.5387    0.6275     14202
           P     0.8472    0.5795    0.6883     25017

   micro avg     0.8706    0.8706    0.8706    163566
   macro avg     0.8270    0.6951    0.7462    163566
weighted avg     0.8657    0.8706    0.8613    163566

F1-macro tok:  0.7461777301964393
F1-micro tok:  0.8705965787510851
**************************************************
dev_cost_sum: 45064.1298828125
dev_cost_avg: 40.93018154660536
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18790.0
dev_accuracy_tok: 0.8832377550061108
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6156462585034014
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7125984251968503
dev_label=P_precision_sent: 0.6744639376218323
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.723092998955068
dev_precision_macro_sent: 0.4300367320417446
dev_recall_macro_sent: 0.5416912239342145
dev_f-score_macro_sent: 0.4785638080506394
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8869784374124895
dev_label=O_recall_tok: 0.9772909595803764
dev_label=O_f-score_tok: 0.9299471520845566
dev_label=N_precision_tok: 0.7766990291262136
dev_label=N_recall_tok: 0.5600430802369413
dev_label=N_f-score_tok: 0.6508135168961201
dev_label=P_precision_tok: 0.9197115384615384
dev_label=P_recall_tok: 0.5955790784557908
dev_label=P_f-score_tok: 0.7229780801209372
dev_precision_macro_tok: 0.8611296683334139
dev_recall_macro_tok: 0.7109710394243695
dev_f-score_macro_tok: 0.7679129163672047
dev_precision_micro_tok: 0.8832377550061108
dev_recall_micro_tok: 0.8832377550061108
dev_f-score_micro_tok: 0.8832377550061108
dev_time: 4.055931091308594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6156    0.8458    0.7126       428
           P     0.6745    0.7793    0.7231       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.4300    0.5417    0.4786      1101
weighted avg     0.5113    0.6431    0.5686      1101

F1-macro sent:  0.4785638080506394
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8870    0.9773    0.9299     16205
           N     0.7767    0.5600    0.6508      1857
           P     0.9197    0.5956    0.7230      3212

   micro avg     0.8832    0.8832    0.8832     21274
   macro avg     0.8611    0.7110    0.7679     21274
weighted avg     0.8823    0.8832    0.8743     21274

F1-macro tok:  0.7679129163672047
F1-micro tok:  0.8832377550061108
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336032.43829345703
train_cost_avg: 39.32963931337278
train_count_sent: 8544.0
train_total_correct_sent: 5444.0
train_accuracy_sent: 0.6371722846441947
train_count_tok: 163566.0
train_total_correct_tok: 142758.0
train_accuracy_tok: 0.8727852976780015
train_label=O_precision_sent: 0.2692307692307692
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008484848484848486
train_label=N_precision_sent: 0.5961754780652418
train_label=N_recall_sent: 0.8006042296072508
train_label=N_f-score_sent: 0.6834300451321728
train_label=P_precision_sent: 0.6842622145838448
train_label=P_recall_sent: 0.77202216066482
train_label=P_f-score_sent: 0.7254978524014057
train_precision_macro_sent: 0.516556153959952
train_recall_macro_sent: 0.5256455783665523
train_f-score_macro_sent: 0.4724709153394757
train_precision_micro_sent: 0.6371722846441947
train_recall_micro_sent: 0.6371722846441947
train_f-score_micro_sent: 0.6371722846441947
train_label=O_precision_tok: 0.8848603877953335
train_label=O_recall_tok: 0.9674137695320354
train_label=O_f-score_tok: 0.9242974317601182
train_label=N_precision_tok: 0.7530399536768964
train_label=N_recall_tok: 0.5494296577946768
train_label=N_f-score_tok: 0.6353199804592086
train_label=P_precision_tok: 0.8495595734816875
train_label=P_recall_tok: 0.5860015189671024
train_label=P_f-score_tok: 0.6935869230951199
train_precision_macro_tok: 0.8291533049846391
train_recall_macro_tok: 0.7009483154312716
train_f-score_macro_tok: 0.7510681117714822
train_precision_micro_tok: 0.8727852976780015
train_recall_micro_tok: 0.8727852976780015
train_f-score_micro_tok: 0.8727852976780015
train_time: 95.9260585308075
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2692    0.0043    0.0085      1624
           N     0.5962    0.8006    0.6834      3310
           P     0.6843    0.7720    0.7255      3610

   micro avg     0.6372    0.6372    0.6372      8544
   macro avg     0.5166    0.5256    0.4725      8544
weighted avg     0.5712    0.6372    0.5729      8544

F1-macro sent:  0.4724709153394757
F1-micro sent:  0.6371722846441947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8849    0.9674    0.9243    124347
           N     0.7530    0.5494    0.6353     14202
           P     0.8496    0.5860    0.6936     25017

   micro avg     0.8728    0.8728    0.8728    163566
   macro avg     0.8292    0.7009    0.7511    163566
weighted avg     0.8680    0.8728    0.8639    163566

F1-macro tok:  0.7510681117714822
F1-micro tok:  0.8727852976780015
**************************************************
dev_cost_sum: 44769.78796386719
dev_cost_avg: 40.66284102076947
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18841.0
dev_accuracy_tok: 0.885635047475792
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6042345276872965
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7120921305182343
dev_label=P_precision_sent: 0.6894409937888198
dev_label=P_recall_sent: 0.75
dev_label=P_f-score_sent: 0.7184466019417475
dev_precision_macro_sent: 0.6812251738253722
dev_recall_macro_sent: 0.5433076221959215
dev_f-score_macro_sent: 0.4854299351404517
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8835612646032889
dev_label=O_recall_tok: 0.984757790805307
dev_label=O_f-score_tok: 0.9314188992003736
dev_label=N_precision_tok: 0.8308759757155247
dev_label=N_recall_tok: 0.5158858373721056
dev_label=N_f-score_tok: 0.6365448504983389
dev_label=P_precision_tok: 0.9344660194174758
dev_label=P_recall_tok: 0.5993150684931506
dev_label=P_f-score_tok: 0.7302731411229134
dev_precision_macro_tok: 0.8829677532454298
dev_recall_macro_tok: 0.699986232223521
dev_f-score_macro_tok: 0.7660789636072086
dev_precision_micro_tok: 0.885635047475792
dev_recall_micro_tok: 0.885635047475792
dev_f-score_micro_tok: 0.885635047475792
dev_time: 3.5544991493225098
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6042    0.8668    0.7121       428
           P     0.6894    0.7500    0.7184       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6812    0.5433    0.4854      1101
weighted avg     0.6689    0.6421    0.5719      1101

F1-macro sent:  0.4854299351404517
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8836    0.9848    0.9314     16205
           N     0.8309    0.5159    0.6365      1857
           P     0.9345    0.5993    0.7303      3212

   micro avg     0.8856    0.8856    0.8856     21274
   macro avg     0.8830    0.7000    0.7661     21274
weighted avg     0.8866    0.8856    0.8753     21274

F1-macro tok:  0.7660789636072086
F1-micro tok:  0.885635047475792
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333316.72161865234
train_cost_avg: 39.01178857896212
train_count_sent: 8544.0
train_total_correct_sent: 5469.0
train_accuracy_sent: 0.6400983146067416
train_count_tok: 163566.0
train_total_correct_tok: 143198.0
train_accuracy_tok: 0.8754753432865021
train_label=O_precision_sent: 0.47959183673469385
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.0545876887340302
train_label=N_precision_sent: 0.6105337742087861
train_label=N_recall_sent: 0.7809667673716012
train_label=N_f-score_sent: 0.6853128313891834
train_label=P_precision_sent: 0.6735517568850902
train_label=P_recall_sent: 0.7858725761772853
train_label=P_f-score_sent: 0.7253899258501662
train_precision_macro_sent: 0.5878924559428567
train_recall_macro_sent: 0.5319267434161313
train_f-score_macro_sent: 0.4884301486577933
train_precision_micro_sent: 0.6400983146067416
train_recall_micro_sent: 0.6400983146067416
train_f-score_micro_sent: 0.6400983146067416
train_label=O_precision_tok: 0.8871314699945485
train_label=O_recall_tok: 0.9684270629769918
train_label=O_f-score_tok: 0.9259984082371804
train_label=N_precision_tok: 0.7532800912721049
train_label=N_recall_tok: 0.557879171947613
train_label=N_f-score_tok: 0.6410194174757281
train_label=P_precision_tok: 0.8583150352478909
train_label=P_recall_tok: 0.593756245752888
train_label=P_f-score_tok: 0.7019351180209342
train_precision_macro_tok: 0.8329088655048481
train_recall_macro_tok: 0.7066874935591643
train_f-score_macro_tok: 0.7563176479112809
train_precision_micro_tok: 0.8754753432865021
train_recall_micro_tok: 0.8754753432865021
train_f-score_micro_tok: 0.8754753432865021
train_time: 96.26737689971924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4796    0.0289    0.0546      1624
           N     0.6105    0.7810    0.6853      3310
           P     0.6736    0.7859    0.7254      3610

   micro avg     0.6401    0.6401    0.6401      8544
   macro avg     0.5879    0.5319    0.4884      8544
weighted avg     0.6123    0.6401    0.5824      8544

F1-macro sent:  0.4884301486577933
F1-micro sent:  0.6400983146067416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8871    0.9684    0.9260    124347
           N     0.7533    0.5579    0.6410     14202
           P     0.8583    0.5938    0.7019     25017

   micro avg     0.8755    0.8755    0.8755    163566
   macro avg     0.8329    0.7067    0.7563    163566
weighted avg     0.8711    0.8755    0.8670    163566

F1-macro tok:  0.7563176479112809
F1-micro tok:  0.8754753432865021
**************************************************
dev_cost_sum: 44373.11413574219
dev_cost_avg: 40.302555981600534
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18928.0
dev_accuracy_tok: 0.8897245463946601
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6789587852494577
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.7041619797525308
dev_label=P_precision_sent: 0.6046875
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.7140221402214022
dev_precision_macro_sent: 0.4278820950831526
dev_recall_macro_sent: 0.534310010945525
dev_f-score_macro_sent: 0.472728039991311
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.891826653194117
dev_label=O_recall_tok: 0.9803764270286949
dev_label=O_f-score_tok: 0.9340074664158265
dev_label=N_precision_tok: 0.8023076923076923
dev_label=N_recall_tok: 0.5616585891222402
dev_label=N_f-score_tok: 0.6607538802660754
dev_label=P_precision_tok: 0.925
dev_label=P_recall_tok: 0.6220423412204235
dev_label=P_f-score_tok: 0.7438570364854804
dev_precision_macro_tok: 0.8730447818339364
dev_recall_macro_tok: 0.7213591191237861
dev_f-score_macro_tok: 0.7795394610557942
dev_precision_micro_tok: 0.8897245463946601
dev_recall_micro_tok: 0.8897245463946601
dev_f-score_micro_tok: 0.8897245463946601
dev_time: 3.562615394592285
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6790    0.7313    0.7042       428
           P     0.6047    0.8716    0.7140       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.4279    0.5343    0.4727      1101
weighted avg     0.5078    0.6358    0.5617      1101

F1-macro sent:  0.472728039991311
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9804    0.9340     16205
           N     0.8023    0.5617    0.6608      1857
           P     0.9250    0.6220    0.7439      3212

   micro avg     0.8897    0.8897    0.8897     21274
   macro avg     0.8730    0.7214    0.7795     21274
weighted avg     0.8890    0.8897    0.8814     21274

F1-macro tok:  0.7795394610557942
F1-micro tok:  0.8897245463946601
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330871.7572631836
train_cost_avg: 38.7256270205037
train_count_sent: 8544.0
train_total_correct_sent: 5489.0
train_accuracy_sent: 0.642439138576779
train_count_tok: 163566.0
train_total_correct_tok: 143473.0
train_accuracy_tok: 0.877156621791815
train_label=O_precision_sent: 0.4230769230769231
train_label=O_recall_sent: 0.020320197044334975
train_label=O_f-score_sent: 0.038777908343125736
train_label=N_precision_sent: 0.6201063315611407
train_label=N_recall_sent: 0.775226586102719
train_label=N_f-score_sent: 0.6890440386680988
train_label=P_precision_sent: 0.6677449168207024
train_label=P_recall_sent: 0.8005540166204986
train_label=P_f-score_sent: 0.72814310909549
train_precision_macro_sent: 0.5703093904862554
train_recall_macro_sent: 0.5320335999225175
train_f-score_macro_sent: 0.48532168536890485
train_precision_micro_sent: 0.642439138576779
train_recall_micro_sent: 0.642439138576779
train_f-score_micro_sent: 0.642439138576779
train_label=O_precision_tok: 0.8884536508358046
train_label=O_recall_tok: 0.9685557351604783
train_label=O_f-score_tok: 0.9267770916296338
train_label=N_precision_tok: 0.7658802177858439
train_label=N_recall_tok: 0.5645683706520208
train_label=N_f-score_tok: 0.6499939199870293
train_label=P_precision_tok: 0.8562631849022179
train_label=P_recall_tok: 0.6003117879841707
train_label=P_f-score_tok: 0.7057994172384623
train_precision_macro_tok: 0.8368656845079555
train_recall_macro_tok: 0.7111452979322234
train_f-score_macro_tok: 0.7608568096183751
train_precision_micro_tok: 0.877156621791815
train_recall_micro_tok: 0.877156621791815
train_f-score_micro_tok: 0.877156621791815
train_time: 96.70551037788391
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4231    0.0203    0.0388      1624
           N     0.6201    0.7752    0.6890      3310
           P     0.6677    0.8006    0.7281      3610

   micro avg     0.6424    0.6424    0.6424      8544
   macro avg     0.5703    0.5320    0.4853      8544
weighted avg     0.6028    0.6424    0.5820      8544

F1-macro sent:  0.48532168536890485
F1-micro sent:  0.642439138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8885    0.9686    0.9268    124347
           N     0.7659    0.5646    0.6500     14202
           P     0.8563    0.6003    0.7058     25017

   micro avg     0.8772    0.8772    0.8772    163566
   macro avg     0.8369    0.7111    0.7609    163566
weighted avg     0.8729    0.8772    0.8689    163566

F1-macro tok:  0.7608568096183751
F1-micro tok:  0.877156621791815
**************************************************
dev_cost_sum: 44183.981506347656
dev_cost_avg: 40.1307733935946
dev_count_sent: 1101.0
dev_total_correct_sent: 676.0
dev_accuracy_sent: 0.6139872842870118
dev_count_tok: 21274.0
dev_total_correct_tok: 18929.0
dev_accuracy_tok: 0.8897715521293598
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.7073170731707317
dev_label=N_recall_sent: 0.6098130841121495
dev_label=N_f-score_sent: 0.6549560853199498
dev_label=P_precision_sent: 0.5657534246575342
dev_label=P_recall_sent: 0.9301801801801802
dev_label=P_f-score_sent: 0.7035775127768313
dev_precision_macro_sent: 0.7576901659427553
dev_recall_macro_sent: 0.5162422962488261
dev_f-score_macro_sent: 0.4586165384709328
dev_precision_micro_sent: 0.6139872842870118
dev_recall_micro_sent: 0.6139872842870118
dev_f-score_micro_sent: 0.6139872842870118
dev_label=O_precision_tok: 0.8912567999551343
dev_label=O_recall_tok: 0.9806849737735267
dev_label=O_f-score_tok: 0.9338347631919144
dev_label=N_precision_tok: 0.8183319570602807
dev_label=N_recall_tok: 0.5336564351103931
dev_label=N_f-score_tok: 0.6460234680573663
dev_label=P_precision_tok: 0.9166666666666666
dev_label=P_recall_tok: 0.636986301369863
dev_label=P_f-score_tok: 0.75165319617928
dev_precision_macro_tok: 0.8754184745606938
dev_recall_macro_tok: 0.7171092367512609
dev_f-score_macro_tok: 0.7771704758095203
dev_precision_micro_tok: 0.8897715521293598
dev_recall_micro_tok: 0.8897715521293598
dev_f-score_micro_tok: 0.8897715521293598
dev_time: 4.32248330116272
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.7073    0.6098    0.6550       428
           P     0.5658    0.9302    0.7036       444

   micro avg     0.6140    0.6140    0.6140      1101
   macro avg     0.7577    0.5162    0.4586      1101
weighted avg     0.7111    0.6140    0.5419      1101

F1-macro sent:  0.4586165384709328
F1-micro sent:  0.6139872842870118
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8913    0.9807    0.9338     16205
           N     0.8183    0.5337    0.6460      1857
           P     0.9167    0.6370    0.7517      3212

   micro avg     0.8898    0.8898    0.8898     21274
   macro avg     0.8754    0.7171    0.7772     21274
weighted avg     0.8887    0.8898    0.8812     21274

F1-macro tok:  0.7771704758095203
F1-micro tok:  0.8897715521293598
**************************************************
Best epoch: 9
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328109.5065307617
train_cost_avg: 38.40232988421837
train_count_sent: 8544.0
train_total_correct_sent: 5543.0
train_accuracy_sent: 0.6487593632958801
train_count_tok: 163566.0
train_total_correct_tok: 144031.0
train_accuracy_tok: 0.8805680887225952
train_label=O_precision_sent: 0.5058823529411764
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.05032182562902282
train_label=N_precision_sent: 0.626602176541717
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.6960376091336468
train_label=P_precision_sent: 0.6727567067530065
train_label=P_recall_sent: 0.8058171745152355
train_label=P_f-score_sent: 0.7332997227123771
train_precision_macro_sent: 0.6017470787453
train_recall_macro_sent: 0.5383581544069681
train_f-score_macro_sent: 0.4932197191583489
train_precision_micro_sent: 0.6487593632958801
train_recall_micro_sent: 0.6487593632958801
train_f-score_micro_sent: 0.6487593632958801
train_label=O_precision_tok: 0.8914716077486493
train_label=O_recall_tok: 0.9700032972247018
train_label=O_f-score_tok: 0.9290809095390682
train_label=N_precision_tok: 0.7699007304738715
train_label=N_recall_tok: 0.5788621320940712
train_label=N_f-score_tok: 0.6608520900321544
train_label=P_precision_tok: 0.8638767271279922
train_label=P_recall_tok: 0.6073070312187713
train_label=P_f-score_tok: 0.7132194160172753
train_precision_macro_tok: 0.8417496884501711
train_recall_macro_tok: 0.7187241535125147
train_f-score_macro_tok: 0.7677174718628326
train_precision_micro_tok: 0.8805680887225952
train_recall_micro_tok: 0.8805680887225952
train_f-score_micro_tok: 0.8805680887225952
train_time: 95.68565154075623
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5059    0.0265    0.0503      1624
           N     0.6266    0.7828    0.6960      3310
           P     0.6728    0.8058    0.7333      3610

   micro avg     0.6488    0.6488    0.6488      8544
   macro avg     0.6017    0.5384    0.4932      8544
weighted avg     0.6232    0.6488    0.5890      8544

F1-macro sent:  0.4932197191583489
F1-micro sent:  0.6487593632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8915    0.9700    0.9291    124347
           N     0.7699    0.5789    0.6609     14202
           P     0.8639    0.6073    0.7132     25017

   micro avg     0.8806    0.8806    0.8806    163566
   macro avg     0.8417    0.7187    0.7677    163566
weighted avg     0.8767    0.8806    0.8728    163566

F1-macro tok:  0.7677174718628326
F1-micro tok:  0.8805680887225952
**************************************************
dev_cost_sum: 43837.71258544922
dev_cost_avg: 39.81626937824634
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 18954.0
dev_accuracy_tok: 0.8909466954968506
dev_label=O_precision_sent: 0.2916666666666667
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05533596837944663
dev_label=N_precision_sent: 0.6195286195286195
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7201565557729941
dev_label=P_precision_sent: 0.6956521739130435
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7249190938511327
dev_precision_macro_sent: 0.5356158200361099
dev_recall_macro_sent: 0.5490458421528087
dev_f-score_macro_sent: 0.5001372060011912
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.8954000904159132
dev_label=O_recall_tok: 0.9777846343721074
dev_label=O_f-score_tok: 0.9347806849355477
dev_label=N_precision_tok: 0.8183279742765274
dev_label=N_recall_tok: 0.5481960150780829
dev_label=N_f-score_tok: 0.6565623992260562
dev_label=P_precision_tok: 0.8958868894601543
dev_label=P_recall_tok: 0.6509962640099627
dev_label=P_f-score_tok: 0.7540569780021638
dev_precision_macro_tok: 0.8698716513841983
dev_recall_macro_tok: 0.7256589711533842
dev_f-score_macro_tok: 0.7818000207212559
dev_precision_micro_tok: 0.8909466954968506
dev_recall_micro_tok: 0.8909466954968506
dev_f-score_micro_tok: 0.8909466954968506
dev_time: 3.6122262477874756
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2917    0.0306    0.0553       229
           N     0.6195    0.8598    0.7202       428
           P     0.6957    0.7568    0.7249       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.5356    0.5490    0.5001      1101
weighted avg     0.5820    0.6458    0.5838      1101

F1-macro sent:  0.5001372060011912
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8954    0.9778    0.9348     16205
           N     0.8183    0.5482    0.6566      1857
           P     0.8959    0.6510    0.7541      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8699    0.7257    0.7818     21274
weighted avg     0.8887    0.8909    0.8832     21274

F1-macro tok:  0.7818000207212559
F1-micro tok:  0.8909466954968506
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325759.0387573242
train_cost_avg: 38.12722831897521
train_count_sent: 8544.0
train_total_correct_sent: 5538.0
train_accuracy_sent: 0.6481741573033708
train_count_tok: 163566.0
train_total_correct_tok: 144325.0
train_accuracy_tok: 0.8823655282882751
train_label=O_precision_sent: 0.3979591836734694
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.045296167247386755
train_label=N_precision_sent: 0.6121646623496763
train_label=N_recall_sent: 0.7996978851963746
train_label=N_f-score_sent: 0.6934765522661777
train_label=P_precision_sent: 0.6918971373119844
train_label=P_recall_sent: 0.7900277008310249
train_label=P_f-score_sent: 0.7377133988618726
train_precision_macro_sent: 0.5673403277783767
train_recall_macro_sent: 0.5379134547841743
train_f-score_macro_sent: 0.492162039458479
train_precision_micro_sent: 0.6481741573033708
train_recall_micro_sent: 0.6481741573033708
train_f-score_micro_sent: 0.6481741573033708
train_label=O_precision_tok: 0.8930721218986695
train_label=O_recall_tok: 0.9700354652705735
train_label=O_f-score_tok: 0.9299641494159825
train_label=N_precision_tok: 0.7727867015315651
train_label=N_recall_tok: 0.5826644134628925
train_label=N_f-score_tok: 0.6643918105178643
train_label=P_precision_tok: 0.8670413037370048
train_label=P_recall_tok: 0.616740616380861
train_label=P_f-score_tok: 0.7207792207792207
train_precision_macro_tok: 0.8443000423890799
train_recall_macro_tok: 0.7231468317047757
train_f-score_macro_tok: 0.7717117269043557
train_precision_micro_tok: 0.8823655282882751
train_recall_micro_tok: 0.8823655282882751
train_f-score_micro_tok: 0.8823655282882751
train_time: 95.99398946762085
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3980    0.0240    0.0453      1624
           N     0.6122    0.7997    0.6935      3310
           P     0.6919    0.7900    0.7377      3610

   micro avg     0.6482    0.6482    0.6482      8544
   macro avg     0.5673    0.5379    0.4922      8544
weighted avg     0.6051    0.6482    0.5890      8544

F1-macro sent:  0.492162039458479
F1-micro sent:  0.6481741573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8931    0.9700    0.9300    124347
           N     0.7728    0.5827    0.6644     14202
           P     0.8670    0.6167    0.7208     25017

   micro avg     0.8824    0.8824    0.8824    163566
   macro avg     0.8443    0.7231    0.7717    163566
weighted avg     0.8786    0.8824    0.8749    163566

F1-macro tok:  0.7717117269043557
F1-micro tok:  0.8823655282882751
**************************************************
dev_cost_sum: 43709.2275390625
dev_cost_avg: 39.69957088016576
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 18985.0
dev_accuracy_tok: 0.8924038732725392
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6467181467181468
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7082452431289641
dev_label=P_precision_sent: 0.6454388984509466
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7317073170731707
dev_precision_macro_sent: 0.7640523483896978
dev_recall_macro_sent: 0.5453461664741917
dev_f-score_macro_sent: 0.4857561925060507
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.8966628959276018
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9356942599970489
dev_label=N_precision_tok: 0.8086560364464692
dev_label=N_recall_tok: 0.5735056542810986
dev_label=N_f-score_tok: 0.6710775047258979
dev_label=P_precision_tok: 0.9077733860342556
dev_label=P_recall_tok: 0.6435242839352429
dev_label=P_f-score_tok: 0.7531426489342322
dev_precision_macro_tok: 0.8710307728027754
dev_recall_macro_tok: 0.7317694157933933
dev_f-score_macro_tok: 0.7866381378857263
dev_precision_micro_tok: 0.8924038732725392
dev_recall_micro_tok: 0.8924038732725392
dev_f-score_micro_tok: 0.8924038732725392
dev_time: 4.174933910369873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6467    0.7827    0.7082       428
           P     0.6454    0.8446    0.7317       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.7641    0.5453    0.4858      1101
weighted avg     0.7197    0.6467    0.5740      1101

F1-macro sent:  0.4857561925060507
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8967    0.9783    0.9357     16205
           N     0.8087    0.5735    0.6711      1857
           P     0.9078    0.6435    0.7531      3212

   micro avg     0.8924    0.8924    0.8924     21274
   macro avg     0.8710    0.7318    0.7866     21274
weighted avg     0.8907    0.8924    0.8850     21274

F1-macro tok:  0.7866381378857263
F1-micro tok:  0.8924038732725392
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323498.5272216797
train_cost_avg: 37.86265533961607
train_count_sent: 8544.0
train_total_correct_sent: 5581.0
train_accuracy_sent: 0.6532069288389513
train_count_tok: 163566.0
train_total_correct_tok: 144700.0
train_accuracy_tok: 0.8846581807955198
train_label=O_precision_sent: 0.5045045045045045
train_label=O_recall_sent: 0.034482758620689655
train_label=O_f-score_sent: 0.06455331412103747
train_label=N_precision_sent: 0.6150703586019065
train_label=N_recall_sent: 0.8187311178247734
train_label=N_f-score_sent: 0.7024364955935718
train_label=P_precision_sent: 0.6990315371244102
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7372004713892889
train_precision_macro_sent: 0.6062021334102737
train_recall_macro_sent: 0.5443307565990878
train_f-score_macro_sent: 0.5013967603679661
train_precision_micro_sent: 0.6532069288389513
train_recall_micro_sent: 0.6532069288389513
train_f-score_micro_sent: 0.6532069288389513
train_label=O_precision_tok: 0.89521959321682
train_label=O_recall_tok: 0.9709281285435113
train_label=O_f-score_tok: 0.9315381351028124
train_label=N_precision_tok: 0.7793353137764575
train_label=N_recall_tok: 0.5911139276158287
train_label=N_f-score_tok: 0.6722991911588051
train_label=P_precision_tok: 0.8684959009536557
train_label=P_recall_tok: 0.6224967022424751
train_label=P_f-score_tok: 0.725202570550433
train_precision_macro_tok: 0.8476836026489778
train_recall_macro_tok: 0.7281795861339383
train_f-score_macro_tok: 0.7763466322706835
train_precision_micro_tok: 0.8846581807955198
train_recall_micro_tok: 0.8846581807955198
train_f-score_micro_tok: 0.8846581807955198
train_time: 95.42406272888184
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5045    0.0345    0.0646      1624
           N     0.6151    0.8187    0.7024      3310
           P     0.6990    0.7798    0.7372      3610

   micro avg     0.6532    0.6532    0.6532      8544
   macro avg     0.6062    0.5443    0.5014      8544
weighted avg     0.6295    0.6532    0.5959      8544

F1-macro sent:  0.5013967603679661
F1-micro sent:  0.6532069288389513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8952    0.9709    0.9315    124347
           N     0.7793    0.5911    0.6723     14202
           P     0.8685    0.6225    0.7252     25017

   micro avg     0.8847    0.8847    0.8847    163566
   macro avg     0.8477    0.7282    0.7763    163566
weighted avg     0.8811    0.8847    0.8775    163566

F1-macro tok:  0.7763466322706835
F1-micro tok:  0.8846581807955198
**************************************************
dev_cost_sum: 43407.4892578125
dev_cost_avg: 39.42551249574251
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19026.0
dev_accuracy_tok: 0.8943311083952242
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05809128630705394
dev_label=N_precision_sent: 0.6
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.7168391345249294
dev_label=P_precision_sent: 0.7224669603524229
dev_label=P_recall_sent: 0.7387387387387387
dev_label=P_f-score_sent: 0.7305122494432073
dev_precision_macro_sent: 0.6352667645619188
dev_recall_macro_sent: 0.553164446738703
dev_f-score_macro_sent: 0.5018142234250635
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9024515686610664
dev_label=O_recall_tok: 0.9745140388768898
dev_label=O_f-score_tok: 0.9370994540707335
dev_label=N_precision_tok: 0.7558900523560209
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.6824224519940916
dev_label=P_precision_tok: 0.9252336448598131
dev_label=P_recall_tok: 0.6472602739726028
dev_label=P_f-score_tok: 0.7616779629968858
dev_precision_macro_tok: 0.8611917552923001
dev_recall_macro_tok: 0.747915077896519
dev_f-score_macro_tok: 0.793733289687237
dev_precision_micro_tok: 0.8943311083952242
dev_recall_micro_tok: 0.8943311083952242
dev_f-score_micro_tok: 0.8943311083952242
dev_time: 3.4747202396392822
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0306    0.0581       229
           N     0.6000    0.8902    0.7168       428
           P     0.7225    0.7387    0.7305       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6353    0.5532    0.5018      1101
weighted avg     0.6459    0.6503    0.5853      1101

F1-macro sent:  0.5018142234250635
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9745    0.9371     16205
           N     0.7559    0.6220    0.6824      1857
           P     0.9252    0.6473    0.7617      3212

   micro avg     0.8943    0.8943    0.8943     21274
   macro avg     0.8612    0.7479    0.7937     21274
weighted avg     0.8931    0.8943    0.8884     21274

F1-macro tok:  0.793733289687237
F1-micro tok:  0.8943311083952242
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321350.12939453125
train_cost_avg: 37.6112042830678
train_count_sent: 8544.0
train_total_correct_sent: 5643.0
train_accuracy_sent: 0.6604634831460674
train_count_tok: 163566.0
train_total_correct_tok: 145000.0
train_accuracy_tok: 0.8864923028013156
train_label=O_precision_sent: 0.46153846153846156
train_label=O_recall_sent: 0.059113300492610835
train_label=O_f-score_sent: 0.10480349344978165
train_label=N_precision_sent: 0.6282292155941757
train_label=N_recall_sent: 0.8081570996978852
train_label=N_f-score_sent: 0.7069238900634249
train_label=P_precision_sent: 0.7042667974497303
train_label=P_recall_sent: 0.7955678670360111
train_label=P_f-score_sent: 0.7471383975026015
train_precision_macro_sent: 0.5980114915274558
train_recall_macro_sent: 0.5542794224088358
train_f-score_macro_sent: 0.5196219270052693
train_precision_micro_sent: 0.6604634831460674
train_recall_micro_sent: 0.6604634831460674
train_f-score_micro_sent: 0.6604634831460674
train_label=O_precision_tok: 0.8969910846953938
train_label=O_recall_tok: 0.970952254577915
train_label=O_f-score_tok: 0.9325074242991809
train_label=N_precision_tok: 0.7791850220264317
train_label=N_recall_tok: 0.5978031263202366
train_label=N_f-score_tok: 0.676547932106144
train_label=P_precision_tok: 0.8729939125622579
train_label=P_recall_tok: 0.6305712115761283
train_label=P_f-score_tok: 0.7322394225636504
train_precision_macro_tok: 0.8497233397613612
train_recall_macro_tok: 0.7331088641580933
train_f-score_macro_tok: 0.7804315929896584
train_precision_micro_tok: 0.8864923028013156
train_recall_micro_tok: 0.8864923028013156
train_f-score_micro_tok: 0.8864923028013156
train_time: 96.24810242652893
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0591    0.1048      1624
           N     0.6282    0.8082    0.7069      3310
           P     0.7043    0.7956    0.7471      3610

   micro avg     0.6605    0.6605    0.6605      8544
   macro avg     0.5980    0.5543    0.5196      8544
weighted avg     0.6287    0.6605    0.6095      8544

F1-macro sent:  0.5196219270052693
F1-micro sent:  0.6604634831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9710    0.9325    124347
           N     0.7792    0.5978    0.6765     14202
           P     0.8730    0.6306    0.7322     25017

   micro avg     0.8865    0.8865    0.8865    163566
   macro avg     0.8497    0.7331    0.7804    163566
weighted avg     0.8831    0.8865    0.8797    163566

F1-macro tok:  0.7804315929896584
F1-micro tok:  0.8864923028013156
**************************************************
dev_cost_sum: 43258.23083496094
dev_cost_avg: 39.28994626245317
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19033.0
dev_accuracy_tok: 0.8946601485381217
dev_label=O_precision_sent: 0.65
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10441767068273092
dev_label=N_precision_sent: 0.6239316239316239
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7206317867719645
dev_label=P_precision_sent: 0.6935483870967742
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7319148936170213
dev_precision_macro_sent: 0.6558266703427994
dev_recall_macro_sent: 0.5614490240148323
dev_f-score_macro_sent: 0.5189881170239056
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.8983118060276456
dev_label=O_recall_tok: 0.9785251465597038
dev_label=O_f-score_tok: 0.9367043742800603
dev_label=N_precision_tok: 0.798980335032775
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6792569659442724
dev_label=P_precision_tok: 0.9244108492663407
dev_label=P_recall_tok: 0.6472602739726028
dev_label=P_f-score_tok: 0.7613990111701154
dev_precision_macro_tok: 0.8739009967755872
dev_recall_macro_tok: 0.7388410565299756
dev_f-score_macro_tok: 0.7924534504648161
dev_precision_micro_tok: 0.8946601485381217
dev_recall_micro_tok: 0.8946601485381217
dev_f-score_micro_tok: 0.8946601485381217
dev_time: 3.7293834686279297
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6500    0.0568    0.1044       229
           N     0.6239    0.8528    0.7206       428
           P     0.6935    0.7748    0.7319       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6558    0.5614    0.5190      1101
weighted avg     0.6574    0.6558    0.5970      1101

F1-macro sent:  0.5189881170239056
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8983    0.9785    0.9367     16205
           N     0.7990    0.5907    0.6793      1857
           P     0.9244    0.6473    0.7614      3212

   micro avg     0.8947    0.8947    0.8947     21274
   macro avg     0.8739    0.7388    0.7925     21274
weighted avg     0.8936    0.8947    0.8878     21274

F1-macro tok:  0.7924534504648161
F1-micro tok:  0.8946601485381217
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319524.61529541016
train_cost_avg: 37.3975439250246
train_count_sent: 8544.0
train_total_correct_sent: 5626.0
train_accuracy_sent: 0.6584737827715356
train_count_tok: 163566.0
train_total_correct_tok: 145245.0
train_accuracy_tok: 0.8879901691060489
train_label=O_precision_sent: 0.4666666666666667
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07163160886867538
train_label=N_precision_sent: 0.6182771194165907
train_label=N_recall_sent: 0.8196374622356496
train_label=N_f-score_sent: 0.7048584047804625
train_label=P_precision_sent: 0.7087789107187267
train_label=P_recall_sent: 0.7894736842105263
train_label=P_f-score_sent: 0.7469532171406108
train_precision_macro_sent: 0.5979075656006613
train_recall_macro_sent: 0.5493014166314839
train_f-score_macro_sent: 0.5078144102632495
train_precision_micro_sent: 0.6584737827715356
train_recall_micro_sent: 0.6584737827715356
train_f-score_micro_sent: 0.6584737827715356
train_label=O_precision_tok: 0.8985487842069637
train_label=O_recall_tok: 0.9714749853233291
train_label=O_f-score_tok: 0.9335899159923643
train_label=N_precision_tok: 0.7818578440283585
train_label=N_recall_tok: 0.6056893395296438
train_label=N_f-score_tok: 0.6825900650690366
train_label=P_precision_tok: 0.8740965517241379
train_label=P_recall_tok: 0.6332893632330016
train_label=P_f-score_tok: 0.7344583004960363
train_precision_macro_tok: 0.8515010599864867
train_recall_macro_tok: 0.7368178960286581
train_f-score_macro_tok: 0.783546093852479
train_precision_micro_tok: 0.8879901691060489
train_recall_micro_tok: 0.8879901691060489
train_f-score_micro_tok: 0.8879901691060489
train_time: 95.64674234390259
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0388    0.0716      1624
           N     0.6183    0.8196    0.7049      3310
           P     0.7088    0.7895    0.7470      3610

   micro avg     0.6585    0.6585    0.6585      8544
   macro avg     0.5979    0.5493    0.5078      8544
weighted avg     0.6277    0.6585    0.6023      8544

F1-macro sent:  0.5078144102632495
F1-micro sent:  0.6584737827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9715    0.9336    124347
           N     0.7819    0.6057    0.6826     14202
           P     0.8741    0.6333    0.7345     25017

   micro avg     0.8880    0.8880    0.8880    163566
   macro avg     0.8515    0.7368    0.7835    163566
weighted avg     0.8847    0.8880    0.8813    163566

F1-macro tok:  0.783546093852479
F1-micro tok:  0.8879901691060489
**************************************************
dev_cost_sum: 43035.53234863281
dev_cost_avg: 39.08767697423507
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19069.0
dev_accuracy_tok: 0.8963523549873085
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.6511194029850746
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7240663900414938
dev_label=P_precision_sent: 0.6642728904847397
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7392607392607392
dev_precision_macro_sent: 0.6884640978232714
dev_recall_macro_sent: 0.5583182558144807
dev_f-score_macro_sent: 0.5046533468982127
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.8986711902742437
dev_label=O_recall_tok: 0.980746683122493
dev_label=O_f-score_tok: 0.9379167896134553
dev_label=N_precision_tok: 0.8171557562076749
dev_label=N_recall_tok: 0.5848142164781907
dev_label=N_f-score_tok: 0.6817325800376648
dev_label=P_precision_tok: 0.9247787610619469
dev_label=P_recall_tok: 0.6506849315068494
dev_label=P_f-score_tok: 0.7638888888888891
dev_precision_macro_tok: 0.8802019025146217
dev_recall_macro_tok: 0.7387486103691777
dev_f-score_macro_tok: 0.7945127528466697
dev_precision_micro_tok: 0.8963523549873085
dev_recall_micro_tok: 0.8963523549873085
dev_f-score_micro_tok: 0.8963523549873085
dev_time: 3.911463737487793
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.6511    0.8154    0.7241       428
           P     0.6643    0.8333    0.7393       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6885    0.5583    0.5047      1101
weighted avg     0.6770    0.6585    0.5901      1101

F1-macro sent:  0.5046533468982127
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8987    0.9807    0.9379     16205
           N     0.8172    0.5848    0.6817      1857
           P     0.9248    0.6507    0.7639      3212

   micro avg     0.8964    0.8964    0.8964     21274
   macro avg     0.8802    0.7387    0.7945     21274
weighted avg     0.8955    0.8964    0.8893     21274

F1-macro tok:  0.7945127528466697
F1-micro tok:  0.8963523549873085
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317384.85931396484
train_cost_avg: 37.14710432045469
train_count_sent: 8544.0
train_total_correct_sent: 5684.0
train_accuracy_sent: 0.6652621722846442
train_count_tok: 163566.0
train_total_correct_tok: 145561.0
train_accuracy_tok: 0.8899221109521539
train_label=O_precision_sent: 0.4601226993865031
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08393956351426972
train_label=N_precision_sent: 0.642041312272175
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.7116498316498316
train_label=P_precision_sent: 0.6954992967651196
train_label=P_recall_sent: 0.8218836565096953
train_label=P_f-score_sent: 0.7534281361097004
train_precision_macro_sent: 0.5992211028079325
train_recall_macro_sent: 0.5554177445659317
train_f-score_macro_sent: 0.5163391770912672
train_precision_micro_sent: 0.6652621722846442
train_recall_micro_sent: 0.6652621722846442
train_f-score_micro_sent: 0.6652621722846442
train_label=O_precision_tok: 0.9005232480135955
train_label=O_recall_tok: 0.9716036575068157
train_label=O_f-score_tok: 0.9347140718504965
train_label=N_precision_tok: 0.7878705466412836
train_label=N_recall_tok: 0.6119560625264048
train_label=N_f-score_tok: 0.6888598264177863
train_label=P_precision_tok: 0.873782180373374
train_label=P_recall_tok: 0.6417236279330055
train_label=P_f-score_tok: 0.7399861719290158
train_precision_macro_tok: 0.8540586583427511
train_recall_macro_tok: 0.741761115988742
train_f-score_macro_tok: 0.787853356732433
train_precision_micro_tok: 0.8899221109521539
train_recall_micro_tok: 0.8899221109521539
train_f-score_micro_tok: 0.8899221109521539
train_time: 95.73014497756958
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4601    0.0462    0.0839      1624
           N     0.6420    0.7982    0.7116      3310
           P     0.6955    0.8219    0.7534      3610

   micro avg     0.6653    0.6653    0.6653      8544
   macro avg     0.5992    0.5554    0.5163      8544
weighted avg     0.6301    0.6653    0.6100      8544

F1-macro sent:  0.5163391770912672
F1-micro sent:  0.6652621722846442
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9005    0.9716    0.9347    124347
           N     0.7879    0.6120    0.6889     14202
           P     0.8738    0.6417    0.7400     25017

   micro avg     0.8899    0.8899    0.8899    163566
   macro avg     0.8541    0.7418    0.7879    163566
weighted avg     0.8867    0.8899    0.8836    163566

F1-macro tok:  0.787853356732433
F1-micro tok:  0.8899221109521539
**************************************************
dev_cost_sum: 43095.71984863281
dev_cost_avg: 39.14234318676913
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.033898305084745756
dev_label=N_precision_sent: 0.6640625
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.7234042553191489
dev_label=P_precision_sent: 0.654639175257732
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7426900584795322
dev_precision_macro_sent: 0.6300434155621012
dev_recall_macro_sent: 0.5566559601269637
dev_f-score_macro_sent: 0.49999753962780896
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.8950683236799191
dev_label=O_recall_tok: 0.982227707497686
dev_label=O_f-score_tok: 0.9366246910674356
dev_label=N_precision_tok: 0.8119723714504988
dev_label=N_recall_tok: 0.5697361335487345
dev_label=N_f-score_tok: 0.669620253164557
dev_label=P_precision_tok: 0.9328153564899452
dev_label=P_recall_tok: 0.6354296388542964
dev_label=P_f-score_tok: 0.7559259259259259
dev_precision_macro_tok: 0.8799520172067877
dev_recall_macro_tok: 0.7291311599669056
dev_f-score_macro_tok: 0.7873902900526395
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 4.7409303188323975
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0175    0.0339       229
           N     0.6641    0.7944    0.7234       428
           P     0.6546    0.8581    0.7427       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6300    0.5567    0.5000      1101
weighted avg     0.6410    0.6585    0.5878      1101

F1-macro sent:  0.49999753962780896
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8951    0.9822    0.9366     16205
           N     0.8120    0.5697    0.6696      1857
           P     0.9328    0.6354    0.7559      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8800    0.7291    0.7874     21274
weighted avg     0.8935    0.8939    0.8860     21274

F1-macro tok:  0.7873902900526395
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315351.91357421875
train_cost_avg: 36.90916591458553
train_count_sent: 8544.0
train_total_correct_sent: 5727.0
train_accuracy_sent: 0.6702949438202247
train_count_tok: 163566.0
train_total_correct_tok: 145871.0
train_accuracy_tok: 0.8918173703581429
train_label=O_precision_sent: 0.424
train_label=O_recall_sent: 0.03263546798029557
train_label=O_f-score_sent: 0.060606060606060615
train_label=N_precision_sent: 0.644545237526856
train_label=N_recall_sent: 0.8157099697885196
train_label=N_f-score_sent: 0.7200960128017069
train_label=P_precision_sent: 0.7030732860520095
train_label=P_recall_sent: 0.8238227146814404
train_label=P_f-score_sent: 0.7586734693877552
train_precision_macro_sent: 0.5905395078596218
train_recall_macro_sent: 0.5573893841500852
train_f-score_macro_sent: 0.5131251809318409
train_precision_micro_sent: 0.6702949438202247
train_recall_micro_sent: 0.6702949438202247
train_f-score_micro_sent: 0.6702949438202247
train_label=O_precision_tok: 0.9026584378128782
train_label=O_recall_tok: 0.9715554054380081
train_label=O_f-score_tok: 0.9358405794294788
train_label=N_precision_tok: 0.7892231701841042
train_label=N_recall_tok: 0.6187860864666949
train_label=N_f-score_tok: 0.6936890713186249
train_label=P_precision_tok: 0.8752218576883773
train_label=P_recall_tok: 0.650477675180877
train_label=P_f-score_tok: 0.7462967209355652
train_precision_macro_tok: 0.8557011552284534
train_recall_macro_tok: 0.74693972236186
train_f-score_macro_tok: 0.7919421238945562
train_precision_micro_tok: 0.8918173703581429
train_recall_micro_tok: 0.8918173703581429
train_f-score_micro_tok: 0.8918173703581429
train_time: 169.2814610004425
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4240    0.0326    0.0606      1624
           N     0.6445    0.8157    0.7201      3310
           P     0.7031    0.8238    0.7587      3610

   micro avg     0.6703    0.6703    0.6703      8544
   macro avg     0.5905    0.5574    0.5131      8544
weighted avg     0.6274    0.6703    0.6110      8544

F1-macro sent:  0.5131251809318409
F1-micro sent:  0.6702949438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9027    0.9716    0.9358    124347
           N     0.7892    0.6188    0.6937     14202
           P     0.8752    0.6505    0.7463     25017

   micro avg     0.8918    0.8918    0.8918    163566
   macro avg     0.8557    0.7469    0.7919    163566
weighted avg     0.8886    0.8918    0.8858    163566

F1-macro tok:  0.7919421238945562
F1-micro tok:  0.8918173703581429
**************************************************
dev_cost_sum: 42779.118713378906
dev_cost_avg: 38.854785389081655
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19089.0
dev_accuracy_tok: 0.8972924696813012
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6027820710973725
dev_label=N_recall_sent: 0.9112149532710281
dev_label=N_f-score_sent: 0.7255813953488374
dev_label=P_precision_sent: 0.7333333333333333
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.738255033557047
dev_precision_macro_sent: 0.6953718014769019
dev_recall_macro_sent: 0.5558528777318313
dev_f-score_macro_sent: 0.4965291672890859
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9024265208475735
dev_label=O_recall_tok: 0.9776612156741746
dev_label=O_f-score_tok: 0.9385385503983887
dev_label=N_precision_tok: 0.8153618906942393
dev_label=N_recall_tok: 0.5945072697899838
dev_label=N_f-score_tok: 0.6876362503892868
dev_label=P_precision_tok: 0.9060913705583756
dev_label=P_recall_tok: 0.6668742216687422
dev_label=P_f-score_tok: 0.7682926829268293
dev_precision_macro_tok: 0.874626594033396
dev_recall_macro_tok: 0.7463475690443002
dev_f-score_macro_tok: 0.7981558279048349
dev_precision_micro_tok: 0.8972924696813012
dev_recall_micro_tok: 0.8972924696813012
dev_f-score_micro_tok: 0.8972924696813012
dev_time: 10.924199104309082
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6028    0.9112    0.7256       428
           P     0.7333    0.7432    0.7383       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6954    0.5559    0.4965      1101
weighted avg     0.6860    0.6567    0.5851      1101

F1-macro sent:  0.4965291672890859
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9777    0.9385     16205
           N     0.8154    0.5945    0.6876      1857
           P     0.9061    0.6669    0.7683      3212

   micro avg     0.8973    0.8973    0.8973     21274
   macro avg     0.8746    0.7463    0.7982     21274
weighted avg     0.8954    0.8973    0.8909     21274

F1-macro tok:  0.7981558279048349
F1-micro tok:  0.8972924696813012
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313944.8244628906
train_cost_avg: 36.74447851859675
train_count_sent: 8544.0
train_total_correct_sent: 5664.0
train_accuracy_sent: 0.6629213483146067
train_count_tok: 163566.0
train_total_correct_tok: 146016.0
train_accuracy_tok: 0.8927038626609443
train_label=O_precision_sent: 0.4594594594594595
train_label=O_recall_sent: 0.04187192118226601
train_label=O_f-score_sent: 0.07674943566591422
train_label=N_precision_sent: 0.6257149393731412
train_label=N_recall_sent: 0.8262839879154078
train_label=N_f-score_sent: 0.7121468558781409
train_label=P_precision_sent: 0.710807453416149
train_label=P_recall_sent: 0.7925207756232687
train_label=P_f-score_sent: 0.7494433529796987
train_precision_macro_sent: 0.5986606174162499
train_recall_macro_sent: 0.5535588949069808
train_f-score_macro_sent: 0.5127798815079179
train_precision_micro_sent: 0.6629213483146067
train_recall_micro_sent: 0.6629213483146067
train_f-score_micro_sent: 0.6629213483146067
train_label=O_precision_tok: 0.9040323908455448
train_label=O_recall_tok: 0.9714347752659895
train_label=O_f-score_tok: 0.9365223964491307
train_label=N_precision_tok: 0.789065287192294
train_label=N_recall_tok: 0.6229404309252218
train_label=N_f-score_tok: 0.6962304241756512
train_label=P_precision_tok: 0.873932536293766
train_label=P_recall_tok: 0.6545149298477035
train_label=P_f-score_tok: 0.7484743903275204
train_precision_macro_tok: 0.8556767381105349
train_recall_macro_tok: 0.7496300453463048
train_f-score_macro_tok: 0.7937424036507674
train_precision_micro_tok: 0.8927038626609443
train_recall_micro_tok: 0.8927038626609443
train_f-score_micro_tok: 0.8927038626609443
train_time: 197.1483118534088
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4595    0.0419    0.0767      1624
           N     0.6257    0.8263    0.7121      3310
           P     0.7108    0.7925    0.7494      3610

   micro avg     0.6629    0.6629    0.6629      8544
   macro avg     0.5987    0.5536    0.5128      8544
weighted avg     0.6301    0.6629    0.6071      8544

F1-macro sent:  0.5127798815079179
F1-micro sent:  0.6629213483146067
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9040    0.9714    0.9365    124347
           N     0.7891    0.6229    0.6962     14202
           P     0.8739    0.6545    0.7485     25017

   micro avg     0.8927    0.8927    0.8927    163566
   macro avg     0.8557    0.7496    0.7937    163566
weighted avg     0.8894    0.8927    0.8869    163566

F1-macro tok:  0.7937424036507674
F1-micro tok:  0.8927038626609443
**************************************************
dev_cost_sum: 42687.28234863281
dev_cost_avg: 38.77137361365378
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19088.0
dev_accuracy_tok: 0.8972454639466015
dev_label=O_precision_sent: 0.4782608695652174
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08730158730158731
dev_label=N_precision_sent: 0.6578449905482041
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7272727272727272
dev_label=P_precision_sent: 0.6648451730418944
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7351460221550856
dev_precision_macro_sent: 0.6003170110517719
dev_recall_macro_sent: 0.5610637062398071
dev_f-score_macro_sent: 0.5165734455764667
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.906347016212487
dev_label=O_recall_tok: 0.9728478864547979
dev_label=O_f-score_tok: 0.9384207863329266
dev_label=N_precision_tok: 0.8036723163841808
dev_label=N_recall_tok: 0.6128163704900377
dev_label=N_f-score_tok: 0.6953864955698136
dev_label=P_precision_tok: 0.8867694805194806
dev_label=P_recall_tok: 0.6802615193026152
dev_label=P_f-score_tok: 0.7699083861874559
dev_precision_macro_tok: 0.8655962710387163
dev_recall_macro_tok: 0.7553085920824837
dev_f-score_macro_tok: 0.8012385560300653
dev_precision_micro_tok: 0.8972454639466015
dev_recall_micro_tok: 0.8972454639466015
dev_f-score_micro_tok: 0.8972454639466015
dev_time: 10.916024684906006
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4783    0.0480    0.0873       229
           N     0.6578    0.8131    0.7273       428
           P     0.6648    0.8221    0.7351       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6003    0.5611    0.5166      1101
weighted avg     0.6233    0.6576    0.5973      1101

F1-macro sent:  0.5165734455764667
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9728    0.9384     16205
           N     0.8037    0.6128    0.6954      1857
           P     0.8868    0.6803    0.7699      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8656    0.7553    0.8012     21274
weighted avg     0.8944    0.8972    0.8918     21274

F1-macro tok:  0.8012385560300653
F1-micro tok:  0.8972454639466015
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 312035.40380859375
train_cost_avg: 36.520997636773615
train_count_sent: 8544.0
train_total_correct_sent: 5756.0
train_accuracy_sent: 0.673689138576779
train_count_tok: 163566.0
train_total_correct_tok: 146423.0
train_accuracy_tok: 0.8951921548488072
train_label=O_precision_sent: 0.47337278106508873
train_label=O_recall_sent: 0.04926108374384237
train_label=O_f-score_sent: 0.08923591745677635
train_label=N_precision_sent: 0.6432584269662921
train_label=N_recall_sent: 0.8302114803625378
train_label=N_f-score_sent: 0.7248747032445264
train_label=P_precision_sent: 0.7136241774311479
train_label=P_recall_sent: 0.8110803324099723
train_label=P_f-score_sent: 0.7592376507195644
train_precision_macro_sent: 0.6100851284875096
train_recall_macro_sent: 0.5635176321721175
train_f-score_macro_sent: 0.5244494238069558
train_precision_micro_sent: 0.673689138576779
train_recall_micro_sent: 0.673689138576779
train_f-score_micro_sent: 0.673689138576779
train_label=O_precision_tok: 0.905986430258275
train_label=O_recall_tok: 0.9718368758393849
train_label=O_f-score_tok: 0.937757049958872
train_label=N_precision_tok: 0.7968513741883839
train_label=N_recall_tok: 0.630826644134629
train_label=N_f-score_tok: 0.7041854981332285
train_label=P_precision_tok: 0.8775477875171612
train_label=P_recall_tok: 0.6643082703761443
train_label=P_f-score_tok: 0.7561824593334093
train_precision_macro_tok: 0.8601285306546066
train_recall_macro_tok: 0.7556572634500527
train_f-score_macro_tok: 0.7993750024751699
train_precision_micro_tok: 0.8951921548488072
train_recall_micro_tok: 0.8951921548488072
train_f-score_micro_tok: 0.8951921548488072
train_time: 196.62031364440918
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4734    0.0493    0.0892      1624
           N     0.6433    0.8302    0.7249      3310
           P     0.7136    0.8111    0.7592      3610

   micro avg     0.6737    0.6737    0.6737      8544
   macro avg     0.6101    0.5635    0.5244      8544
weighted avg     0.6407    0.6737    0.6186      8544

F1-macro sent:  0.5244494238069558
F1-micro sent:  0.673689138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9060    0.9718    0.9378    124347
           N     0.7969    0.6308    0.7042     14202
           P     0.8775    0.6643    0.7562     25017

   micro avg     0.8952    0.8952    0.8952    163566
   macro avg     0.8601    0.7557    0.7994    163566
weighted avg     0.8922    0.8952    0.8897    163566

F1-macro tok:  0.7993750024751699
F1-micro tok:  0.8951921548488072
**************************************************
dev_cost_sum: 42558.99609375
dev_cost_avg: 38.65485567098093
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.649812734082397
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7214137214137214
dev_label=P_precision_sent: 0.6601423487544484
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7375745526838966
dev_precision_macro_sent: 0.7033183609456152
dev_recall_macro_sent: 0.5546001660150948
dev_f-score_macro_sent: 0.4977254360952174
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9079432787641226
dev_label=O_recall_tok: 0.9719839555692688
dev_label=O_f-score_tok: 0.9388728280630645
dev_label=N_precision_tok: 0.7711864406779662
dev_label=N_recall_tok: 0.6370490037695208
dev_label=N_f-score_tok: 0.6977292833972281
dev_label=P_precision_tok: 0.9025919732441472
dev_label=P_recall_tok: 0.6721668742216688
dev_label=P_f-score_tok: 0.7705210563882942
dev_precision_macro_tok: 0.8605738975620786
dev_recall_macro_tok: 0.7603999445201528
dev_f-score_macro_tok: 0.8023743892828622
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 11.086282730102539
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6498    0.8107    0.7214       428
           P     0.6601    0.8356    0.7376       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7033    0.5546    0.4977      1101
weighted avg     0.6852    0.6558    0.5850      1101

F1-macro sent:  0.4977254360952174
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9079    0.9720    0.9389     16205
           N     0.7712    0.6370    0.6977      1857
           P     0.9026    0.6722    0.7705      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8606    0.7604    0.8024     21274
weighted avg     0.8952    0.8975    0.8924     21274

F1-macro tok:  0.8023743892828622
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 310180.17919921875
train_cost_avg: 36.30385992500219
train_count_sent: 8544.0
train_total_correct_sent: 5772.0
train_accuracy_sent: 0.675561797752809
train_count_tok: 163566.0
train_total_correct_tok: 146650.0
train_accuracy_tok: 0.8965799738331928
train_label=O_precision_sent: 0.46634615384615385
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10589519650655022
train_label=N_precision_sent: 0.6422423819492905
train_label=N_recall_sent: 0.8341389728096676
train_label=N_f-score_sent: 0.7257195426468654
train_label=P_precision_sent: 0.7218231359920734
train_label=P_recall_sent: 0.807202216066482
train_label=P_f-score_sent: 0.7621289394533803
train_precision_macro_sent: 0.6101372239291726
train_recall_macro_sent: 0.5670234176385195
train_f-score_macro_sent: 0.531247892868932
train_precision_micro_sent: 0.675561797752809
train_recall_micro_sent: 0.675561797752809
train_f-score_micro_sent: 0.675561797752809
train_label=O_precision_tok: 0.9073223453120778
train_label=O_recall_tok: 0.972182682332505
train_label=O_f-score_tok: 0.9386333725439956
train_label=N_precision_tok: 0.7982440737489025
train_label=N_recall_tok: 0.6401915223207999
train_label=N_f-score_tok: 0.7105345420443888
train_label=P_precision_tok: 0.8801478352692714
train_label=P_recall_tok: 0.6663468841187992
train_label=P_f-score_tok: 0.7584685033100531
train_precision_macro_tok: 0.8619047514434173
train_recall_macro_tok: 0.7595736962573681
train_f-score_macro_tok: 0.8025454726328126
train_precision_micro_tok: 0.8965799738331928
train_recall_micro_tok: 0.8965799738331928
train_f-score_micro_tok: 0.8965799738331928
train_time: 197.74433064460754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4663    0.0597    0.1059      1624
           N     0.6422    0.8341    0.7257      3310
           P     0.7218    0.8072    0.7621      3610

   micro avg     0.6756    0.6756    0.6756      8544
   macro avg     0.6101    0.5670    0.5312      8544
weighted avg     0.6424    0.6756    0.6233      8544

F1-macro sent:  0.531247892868932
F1-micro sent:  0.675561797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9073    0.9722    0.9386    124347
           N     0.7982    0.6402    0.7105     14202
           P     0.8801    0.6663    0.7585     25017

   micro avg     0.8966    0.8966    0.8966    163566
   macro avg     0.8619    0.7596    0.8025    163566
weighted avg     0.8937    0.8966    0.8913    163566

F1-macro tok:  0.8025454726328126
F1-micro tok:  0.8965799738331928
**************************************************
dev_cost_sum: 42500.53576660156
dev_cost_avg: 38.60175818946554
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19113.0
dev_accuracy_tok: 0.8984206073140923
dev_label=O_precision_sent: 0.875
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05907172995780591
dev_label=N_precision_sent: 0.6305841924398625
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7267326732673267
dev_label=P_precision_sent: 0.6947162426614482
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7434554973821991
dev_precision_macro_sent: 0.7334334783671036
dev_recall_macro_sent: 0.562531290217696
dev_f-score_macro_sent: 0.5097533002024438
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9034207525655644
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9391613572381095
dev_label=N_precision_tok: 0.8192592592592592
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6897411911443717
dev_label=P_precision_tok: 0.9064597315436241
dev_label=P_recall_tok: 0.6727895392278954
dev_label=P_f-score_tok: 0.7723373838456039
dev_precision_macro_tok: 0.8763799144561494
dev_recall_macro_tok: 0.7487400528874951
dev_f-score_macro_tok: 0.8004133107426951
dev_precision_micro_tok: 0.8984206073140923
dev_recall_micro_tok: 0.8984206073140923
dev_f-score_micro_tok: 0.8984206073140923
dev_time: 11.330586194992065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8750    0.0306    0.0591       229
           N     0.6306    0.8575    0.7267       428
           P     0.6947    0.7995    0.7435       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.7334    0.5625    0.5098      1101
weighted avg     0.7073    0.6621    0.5946      1101

F1-macro sent:  0.5097533002024438
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9034    0.9778    0.9392     16205
           N     0.8193    0.5956    0.6897      1857
           P     0.9065    0.6728    0.7723      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8764    0.7487    0.8004     21274
weighted avg     0.8965    0.8984    0.8922     21274

F1-macro tok:  0.8004133107426951
F1-micro tok:  0.8984206073140923
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 308685.2176513672
train_cost_avg: 36.12888783372743
train_count_sent: 8544.0
train_total_correct_sent: 5813.0
train_accuracy_sent: 0.6803604868913857
train_count_tok: 163566.0
train_total_correct_tok: 146915.0
train_accuracy_tok: 0.8982001149383123
train_label=O_precision_sent: 0.4532710280373832
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10554951033732318
train_label=N_precision_sent: 0.6517068512771544
train_label=N_recall_sent: 0.824773413897281
train_label=N_f-score_sent: 0.7280970796106148
train_label=P_precision_sent: 0.7210818642839893
train_label=P_recall_sent: 0.8271468144044322
train_label=P_f-score_sent: 0.7704812282286156
train_precision_macro_sent: 0.6086865811995089
train_recall_macro_sent: 0.5705497641137073
train_f-score_macro_sent: 0.5347092727255179
train_precision_micro_sent: 0.6803604868913857
train_recall_micro_sent: 0.6803604868913857
train_f-score_micro_sent: 0.6803604868913857
train_label=O_precision_tok: 0.9090909090909091
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.9394361051297797
train_label=N_precision_tok: 0.8014834205933682
train_label=N_recall_tok: 0.6467398957893254
train_label=N_f-score_tok: 0.7158444392486946
train_label=P_precision_tok: 0.8804965833811486
train_label=P_recall_tok: 0.6747411760003198
train_label=P_f-score_tok: 0.764008328052865
train_precision_macro_tok: 0.8636903043551419
train_recall_macro_tok: 0.7644527192287899
train_f-score_macro_tok: 0.8064296241437797
train_precision_micro_tok: 0.8982001149383123
train_recall_micro_tok: 0.8982001149383123
train_f-score_micro_tok: 0.8982001149383123
train_time: 196.6099922657013
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4533    0.0597    0.1055      1624
           N     0.6517    0.8248    0.7281      3310
           P     0.7211    0.8271    0.7705      3610

   micro avg     0.6804    0.6804    0.6804      8544
   macro avg     0.6087    0.5705    0.5347      8544
weighted avg     0.6433    0.6804    0.6277      8544

F1-macro sent:  0.5347092727255179
F1-micro sent:  0.6803604868913857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9091    0.9719    0.9394    124347
           N     0.8015    0.6467    0.7158     14202
           P     0.8805    0.6747    0.7640     25017

   micro avg     0.8982    0.8982    0.8982    163566
   macro avg     0.8637    0.7645    0.8064    163566
weighted avg     0.8954    0.8982    0.8932    163566

F1-macro tok:  0.8064296241437797
F1-micro tok:  0.8982001149383123
**************************************************
dev_cost_sum: 42355.072509765625
dev_cost_avg: 38.46963897344743
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19112.0
dev_accuracy_tok: 0.8983736015793927
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1509433962264151
dev_label=N_precision_sent: 0.6629422718808193
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7378238341968911
dev_label=P_precision_sent: 0.6912878787878788
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7510288065843621
dev_precision_macro_sent: 0.6365952354080845
dev_recall_macro_sent: 0.5803946725160455
dev_f-score_macro_sent: 0.5465986790025561
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9017669450599398
dev_label=O_recall_tok: 0.9794507867941993
dev_label=O_f-score_tok: 0.9390049103709401
dev_label=N_precision_tok: 0.84
dev_label=N_recall_tok: 0.5767366720516963
dev_label=N_f-score_tok: 0.6839080459770115
dev_label=P_precision_tok: 0.9045037531276063
dev_label=P_recall_tok: 0.675280199252802
dev_label=P_f-score_tok: 0.7732620320855615
dev_precision_macro_tok: 0.8820902327291821
dev_recall_macro_tok: 0.7438225526995659
dev_f-score_macro_tok: 0.7987249961445043
dev_precision_micro_tok: 0.8983736015793927
dev_recall_micro_tok: 0.8983736015793927
dev_f-score_micro_tok: 0.8983736015793927
dev_time: 11.10974383354187
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0873    0.1509       229
           N     0.6629    0.8318    0.7378       428
           P     0.6913    0.8221    0.7510       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6366    0.5804    0.5466      1101
weighted avg     0.6520    0.6730    0.6211      1101

F1-macro sent:  0.5465986790025561
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9795    0.9390     16205
           N     0.8400    0.5767    0.6839      1857
           P     0.9045    0.6753    0.7733      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8821    0.7438    0.7987     21274
weighted avg     0.8968    0.8984    0.8917     21274

F1-macro tok:  0.7987249961445043
F1-micro tok:  0.8983736015793927
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 307137.75079345703
train_cost_avg: 35.9477704580357
train_count_sent: 8544.0
train_total_correct_sent: 5806.0
train_accuracy_sent: 0.6795411985018727
train_count_tok: 163566.0
train_total_correct_tok: 147099.0
train_accuracy_tok: 0.8993250431018671
train_label=O_precision_sent: 0.504950495049505
train_label=O_recall_sent: 0.06280788177339902
train_label=O_f-score_sent: 0.11171960569550932
train_label=N_precision_sent: 0.6465376544649102
train_label=N_recall_sent: 0.8377643504531722
train_label=N_f-score_sent: 0.729832872746414
train_label=P_precision_sent: 0.7231680236861584
train_label=P_recall_sent: 0.8119113573407202
train_label=P_f-score_sent: 0.7649745530471095
train_precision_macro_sent: 0.6248853910668578
train_recall_macro_sent: 0.5708278631890972
train_f-score_macro_sent: 0.5355090104963443
train_precision_micro_sent: 0.6795411985018727
train_recall_micro_sent: 0.6795411985018727
train_f-score_micro_sent: 0.6795411985018727
train_label=O_precision_tok: 0.9104801355676897
train_label=O_recall_tok: 0.9721907243439729
train_label=O_f-score_tok: 0.9403240485061566
train_label=N_precision_tok: 0.8033516627389369
train_label=N_recall_tok: 0.648077735530207
train_label=N_f-score_tok: 0.7174090962235473
train_label=P_precision_tok: 0.8795903589531395
train_label=P_recall_tok: 0.6797777511292321
train_label=P_f-score_tok: 0.7668823701833104
train_precision_macro_tok: 0.864474052419922
train_recall_macro_tok: 0.7666820703344707
train_f-score_macro_tok: 0.8082051716376714
train_precision_micro_tok: 0.8993250431018671
train_recall_micro_tok: 0.8993250431018671
train_f-score_micro_tok: 0.899325043101867
train_time: 197.21128487586975
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5050    0.0628    0.1117      1624
           N     0.6465    0.8378    0.7298      3310
           P     0.7232    0.8119    0.7650      3610

   micro avg     0.6795    0.6795    0.6795      8544
   macro avg     0.6249    0.5708    0.5355      8544
weighted avg     0.6520    0.6795    0.6272      8544

F1-macro sent:  0.5355090104963443
F1-micro sent:  0.6795411985018727
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9722    0.9403    124347
           N     0.8034    0.6481    0.7174     14202
           P     0.8796    0.6798    0.7669     25017

   micro avg     0.8993    0.8993    0.8993    163566
   macro avg     0.8645    0.7667    0.8082    163566
weighted avg     0.8965    0.8993    0.8944    163566

F1-macro tok:  0.8082051716376714
F1-micro tok:  0.899325043101867
**************************************************
dev_cost_sum: 42430.4609375
dev_cost_avg: 38.53811165985468
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 19063.0
dev_accuracy_tok: 0.8960703205791106
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04184100418410041
dev_label=N_precision_sent: 0.7319034852546917
dev_label=N_recall_sent: 0.6378504672897196
dev_label=N_f-score_sent: 0.6816479400749064
dev_label=P_precision_sent: 0.5779944289693594
dev_label=P_recall_sent: 0.9346846846846847
dev_label=P_f-score_sent: 0.7142857142857143
dev_precision_macro_sent: 0.6032993047413503
dev_recall_macro_sent: 0.5314564043699251
dev_f-score_macro_sent: 0.47925821951490705
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.9099883855981417
dev_label=O_recall_tok: 0.9669854983029929
dev_label=O_f-score_tok: 0.9376215407629019
dev_label=N_precision_tok: 0.7955953200275292
dev_label=N_recall_tok: 0.6225094238018309
dev_label=N_f-score_tok: 0.698489425981873
dev_label=P_precision_tok: 0.8600538254517494
dev_label=P_recall_tok: 0.6964508094645081
dev_label=P_f-score_tok: 0.7696542232926199
dev_precision_macro_tok: 0.85521251035914
dev_recall_macro_tok: 0.7619819105231107
dev_f-score_macro_tok: 0.8019217300124649
dev_precision_micro_tok: 0.8960703205791106
dev_recall_micro_tok: 0.8960703205791106
dev_f-score_micro_tok: 0.8960703205791106
dev_time: 11.517086744308472
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0218    0.0418       229
           N     0.7319    0.6379    0.6816       428
           P     0.5780    0.9347    0.7143       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.6033    0.5315    0.4793      1101
weighted avg     0.6216    0.6294    0.5617      1101

F1-macro sent:  0.47925821951490705
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9100    0.9670    0.9376     16205
           N     0.7956    0.6225    0.6985      1857
           P     0.8601    0.6965    0.7697      3212

   micro avg     0.8961    0.8961    0.8961     21274
   macro avg     0.8552    0.7620    0.8019     21274
weighted avg     0.8925    0.8961    0.8914     21274

F1-macro tok:  0.8019217300124649
F1-micro tok:  0.8960703205791106
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 305589.3203125
train_cost_avg: 35.76654029874766
train_count_sent: 8544.0
train_total_correct_sent: 5737.0
train_accuracy_sent: 0.6714653558052435
train_count_tok: 163566.0
train_total_correct_tok: 147296.0
train_accuracy_tok: 0.9005294498856731
train_label=O_precision_sent: 0.43197278911564624
train_label=O_recall_sent: 0.07820197044334976
train_label=O_f-score_sent: 0.13242961418143898
train_label=N_precision_sent: 0.651831817064175
train_label=N_recall_sent: 0.8009063444108762
train_label=N_f-score_sent: 0.7187203470245358
train_label=P_precision_sent: 0.7073870427922544
train_label=P_recall_sent: 0.8196675900277008
train_label=P_f-score_sent: 0.7593994610547927
train_precision_macro_sent: 0.5970638829906919
train_recall_macro_sent: 0.5662586349606422
train_f-score_macro_sent: 0.5368498074202558
train_precision_micro_sent: 0.6714653558052435
train_recall_micro_sent: 0.6714653558052435
train_f-score_micro_sent: 0.6714653558052435
train_label=O_precision_tok: 0.9121059982635612
train_label=O_recall_tok: 0.9715795314724118
train_label=O_f-score_tok: 0.9409038870413781
train_label=N_precision_tok: 0.8050444847542542
train_label=N_recall_tok: 0.6562455992113787
train_label=N_f-score_tok: 0.7230691648240816
train_label=P_precision_tok: 0.8786218900378827
train_label=P_recall_tok: 0.6860534836311308
train_label=P_f-score_tok: 0.7704877556059347
train_precision_macro_tok: 0.8652574576852327
train_recall_macro_tok: 0.7712928714383072
train_f-score_macro_tok: 0.811486935823798
train_precision_micro_tok: 0.9005294498856731
train_recall_micro_tok: 0.9005294498856731
train_f-score_micro_tok: 0.9005294498856731
train_time: 197.3422451019287
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4320    0.0782    0.1324      1624
           N     0.6518    0.8009    0.7187      3310
           P     0.7074    0.8197    0.7594      3610

   micro avg     0.6715    0.6715    0.6715      8544
   macro avg     0.5971    0.5663    0.5368      8544
weighted avg     0.6335    0.6715    0.6245      8544

F1-macro sent:  0.5368498074202558
F1-micro sent:  0.6714653558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9121    0.9716    0.9409    124347
           N     0.8050    0.6562    0.7231     14202
           P     0.8786    0.6861    0.7705     25017

   micro avg     0.9005    0.9005    0.9005    163566
   macro avg     0.8653    0.7713    0.8115    163566
weighted avg     0.8977    0.9005    0.8959    163566

F1-macro tok:  0.811486935823798
F1-micro tok:  0.9005294498856731
**************************************************
dev_cost_sum: 42260.59619140625
dev_cost_avg: 38.383829419987514
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19120.0
dev_accuracy_tok: 0.8987496474569897
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.6355785837651122
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.730883813306852
dev_label=P_precision_sent: 0.6951456310679611
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7466110531803962
dev_precision_macro_sent: 0.7292890239919768
dev_recall_macro_sent: 0.5641067545936337
dev_f-score_macro_sent: 0.5094474413714556
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9107091088305213
dev_label=O_recall_tok: 0.9692687442147485
dev_label=O_f-score_tok: 0.939076886284826
dev_label=N_precision_tok: 0.8096249115357396
dev_label=N_recall_tok: 0.6160473882606354
dev_label=N_f-score_tok: 0.6996941896024466
dev_label=P_precision_tok: 0.868018362662586
dev_label=P_recall_tok: 0.7064134495641345
dev_label=P_f-score_tok: 0.7789220734637831
dev_precision_macro_tok: 0.8627841276762823
dev_recall_macro_tok: 0.7639098606798395
dev_f-score_macro_tok: 0.8058977164503519
dev_precision_micro_tok: 0.8987496474569897
dev_recall_micro_tok: 0.8987496474569897
dev_f-score_micro_tok: 0.8987496474569897
dev_time: 11.667596101760864
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.6356    0.8598    0.7309       428
           P     0.6951    0.8063    0.7466       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7293    0.5641    0.5094      1101
weighted avg     0.7057    0.6649    0.5958      1101

F1-macro sent:  0.5094474413714556
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9107    0.9693    0.9391     16205
           N     0.8096    0.6160    0.6997      1857
           P     0.8680    0.7064    0.7789      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8628    0.7639    0.8059     21274
weighted avg     0.8954    0.8987    0.8940     21274

F1-macro tok:  0.8058977164503519
F1-micro tok:  0.8987496474569897
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.900000
train_cost_sum: 304214.22454833984
train_cost_avg: 35.605597442455505
train_count_sent: 8544.0
train_total_correct_sent: 5815.0
train_accuracy_sent: 0.6805945692883895
train_count_tok: 163566.0
train_total_correct_tok: 147572.0
train_accuracy_tok: 0.9022168421310052
train_label=O_precision_sent: 0.4601449275362319
train_label=O_recall_sent: 0.07820197044334976
train_label=O_f-score_sent: 0.1336842105263158
train_label=N_precision_sent: 0.6535869041887338
train_label=N_recall_sent: 0.8202416918429003
train_label=N_f-score_sent: 0.7274919614147911
train_label=P_precision_sent: 0.722654350996597
train_label=P_recall_sent: 0.8235457063711912
train_label=P_f-score_sent: 0.7698083894355257
train_precision_macro_sent: 0.6121287275738542
train_recall_macro_sent: 0.5739964562191471
train_f-score_macro_sent: 0.5436615204588775
train_precision_micro_sent: 0.6805945692883895
train_recall_micro_sent: 0.6805945692883895
train_f-score_micro_sent: 0.6805945692883895
train_label=O_precision_tok: 0.9136234468998459
train_label=O_recall_tok: 0.9721746403210371
train_label=O_f-score_tok: 0.9419900803777718
train_label=N_precision_tok: 0.8089423903697335
train_label=N_recall_tok: 0.6624419095901986
train_label=N_f-score_tok: 0.7283988851037474
train_label=P_precision_tok: 0.8805810397553517
train_label=P_recall_tok: 0.690610384938242
train_label=P_f-score_tok: 0.774111163384636
train_precision_macro_tok: 0.8677156256749771
train_recall_macro_tok: 0.7750756449498258
train_f-score_macro_tok: 0.8148333762887184
train_precision_micro_tok: 0.9022168421310052
train_recall_micro_tok: 0.9022168421310052
train_f-score_micro_tok: 0.9022168421310052
train_time: 197.51610255241394
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4601    0.0782    0.1337      1624
           N     0.6536    0.8202    0.7275      3310
           P     0.7227    0.8235    0.7698      3610

   micro avg     0.6806    0.6806    0.6806      8544
   macro avg     0.6121    0.5740    0.5437      8544
weighted avg     0.6460    0.6806    0.6325      8544

F1-macro sent:  0.5436615204588775
F1-micro sent:  0.6805945692883895
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9722    0.9420    124347
           N     0.8089    0.6624    0.7284     14202
           P     0.8806    0.6906    0.7741     25017

   micro avg     0.9022    0.9022    0.9022    163566
   macro avg     0.8677    0.7751    0.8148    163566
weighted avg     0.8995    0.9022    0.8978    163566

F1-macro tok:  0.8148333762887184
F1-micro tok:  0.9022168421310052
**************************************************
dev_cost_sum: 42136.59930419922
dev_cost_avg: 38.27120736076223
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19126.0
dev_accuracy_tok: 0.8990316818651876
dev_label=O_precision_sent: 0.43243243243243246
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12030075187969926
dev_label=N_precision_sent: 0.6918238993710691
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.7292817679558011
dev_label=P_precision_sent: 0.6695059625212947
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.7623666343355964
dev_precision_macro_sent: 0.5979207647749321
dev_recall_macro_sent: 0.5753440560505002
dev_f-score_macro_sent: 0.5373163847236989
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9076577872389391
dev_label=O_recall_tok: 0.973526689293428
dev_label=O_f-score_tok: 0.9394390519859466
dev_label=N_precision_tok: 0.787940379403794
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.697869786978698
dev_label=P_precision_tok: 0.9048407116259827
dev_label=P_recall_tok: 0.6808841843088418
dev_label=P_f-score_tok: 0.7770474329365784
dev_precision_macro_tok: 0.8668129594229054
dev_recall_macro_tok: 0.7602299393788217
dev_f-score_macro_tok: 0.8047854239670743
dev_precision_micro_tok: 0.8990316818651876
dev_recall_micro_tok: 0.8990316818651876
dev_f-score_micro_tok: 0.8990316818651876
dev_time: 11.625942468643188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4324    0.0699    0.1203       229
           N     0.6918    0.7710    0.7293       428
           P     0.6695    0.8851    0.7624       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.5979    0.5753    0.5373      1101
weighted avg     0.6289    0.6712    0.6160      1101

F1-macro sent:  0.5373163847236989
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9077    0.9735    0.9394     16205
           N     0.7879    0.6263    0.6979      1857
           P     0.9048    0.6809    0.7770      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8668    0.7602    0.8048     21274
weighted avg     0.8968    0.8990    0.8938     21274

F1-macro tok:  0.8047854239670743
F1-micro tok:  0.8990316818651876
**************************************************
Best epoch: 22
**************************************************

EPOCH: 26
Learning rate: 0.900000
train_cost_sum: 302620.79400634766
train_cost_avg: 35.419100422091255
train_count_sent: 8544.0
train_total_correct_sent: 5879.0
train_accuracy_sent: 0.6880852059925093
train_count_tok: 163566.0
train_total_correct_tok: 147929.0
train_accuracy_tok: 0.9043994473179022
train_label=O_precision_sent: 0.40978593272171254
train_label=O_recall_sent: 0.08251231527093596
train_label=O_f-score_sent: 0.1373654536135315
train_label=N_precision_sent: 0.6677222898903776
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7393122049898854
train_label=P_precision_sent: 0.730544747081712
train_label=P_recall_sent: 0.8321329639889197
train_label=P_f-score_sent: 0.7780367780367781
train_precision_macro_sent: 0.6026843232312674
train_recall_macro_sent: 0.5809139853323386
train_f-score_macro_sent: 0.551571478880065
train_precision_micro_sent: 0.6880852059925093
train_recall_micro_sent: 0.6880852059925093
train_f-score_micro_sent: 0.6880852059925093
train_label=O_precision_tok: 0.916252871297637
train_label=O_recall_tok: 0.9719735900343394
train_label=O_f-score_tok: 0.9432910839160839
train_label=N_precision_tok: 0.8099447513812155
train_label=N_recall_tok: 0.6709618363610759
train_label=N_f-score_tok: 0.7339315284784533
train_label=P_precision_tok: 0.8816609692338628
train_label=P_recall_tok: 0.7010432905624175
train_label=P_f-score_tok: 0.7810461154779665
train_precision_macro_tok: 0.8692861973042385
train_recall_macro_tok: 0.7813262389859442
train_f-score_macro_tok: 0.8194229092908346
train_precision_micro_tok: 0.9043994473179022
train_recall_micro_tok: 0.9043994473179022
train_f-score_micro_tok: 0.9043994473179022
train_time: 198.38621759414673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4098    0.0825    0.1374      1624
           N     0.6677    0.8281    0.7393      3310
           P     0.7305    0.8321    0.7780      3610

   micro avg     0.6881    0.6881    0.6881      8544
   macro avg     0.6027    0.5809    0.5516      8544
weighted avg     0.6452    0.6881    0.6413      8544

F1-macro sent:  0.551571478880065
F1-micro sent:  0.6880852059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9163    0.9720    0.9433    124347
           N     0.8099    0.6710    0.7339     14202
           P     0.8817    0.7010    0.7810     25017

   micro avg     0.9044    0.9044    0.9044    163566
   macro avg     0.8693    0.7813    0.8194    163566
weighted avg     0.9017    0.9044    0.9003    163566

F1-macro tok:  0.8194229092908346
F1-micro tok:  0.9043994473179022
**************************************************
dev_cost_sum: 42073.771911621094
dev_cost_avg: 38.21414342563224
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19111.0
dev_accuracy_tok: 0.8983265958446931
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5948406676783005
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.7212511499540017
dev_label=P_precision_sent: 0.7420091324200914
dev_label=P_recall_sent: 0.7319819819819819
dev_label=P_f-score_sent: 0.7369614512471655
dev_precision_macro_sent: 0.6956166000327973
dev_recall_macro_sent: 0.5536567563768314
dev_f-score_macro_sent: 0.4946545580541802
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.9084299809589752
dev_label=O_recall_tok: 0.9715519901265042
dev_label=O_f-score_tok: 0.9389312977099236
dev_label=N_precision_tok: 0.7954388389771941
dev_label=N_recall_tok: 0.6198169089929995
dev_label=N_f-score_tok: 0.6967312348668281
dev_label=P_precision_tok: 0.8878205128205128
dev_label=P_recall_tok: 0.6899128268991283
dev_label=P_f-score_tok: 0.7764540995094603
dev_precision_macro_tok: 0.8638964442522274
dev_recall_macro_tok: 0.7604272420062106
dev_f-score_macro_tok: 0.8040388773620707
dev_precision_micro_tok: 0.8983265958446931
dev_recall_micro_tok: 0.8983265958446931
dev_f-score_micro_tok: 0.8983265958446931
dev_time: 15.12825083732605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5948    0.9159    0.7213       428
           P     0.7420    0.7320    0.7370       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6956    0.5537    0.4947      1101
weighted avg     0.6865    0.6540    0.5829      1101

F1-macro sent:  0.4946545580541802
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9716    0.9389     16205
           N     0.7954    0.6198    0.6967      1857
           P     0.8878    0.6899    0.7765      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8639    0.7604    0.8040     21274
weighted avg     0.8955    0.8983    0.8933     21274

F1-macro tok:  0.8040388773620707
F1-micro tok:  0.8983265958446931
**************************************************
Best epoch: 22
**************************************************

EPOCH: 27
Learning rate: 0.810000
train_cost_sum: 301254.4411621094
train_cost_avg: 35.25918084762516
train_count_sent: 8544.0
train_total_correct_sent: 5908.0
train_accuracy_sent: 0.6914794007490637
train_count_tok: 163566.0
train_total_correct_tok: 148128.0
train_accuracy_tok: 0.9056160815817468
train_label=O_precision_sent: 0.4805194805194805
train_label=O_recall_sent: 0.06834975369458128
train_label=O_f-score_sent: 0.11967654986522912
train_label=N_precision_sent: 0.6665864227250843
train_label=N_recall_sent: 0.8365558912386707
train_label=N_f-score_sent: 0.7419614147909969
train_label=P_precision_sent: 0.7280596297186823
train_label=P_recall_sent: 0.838781163434903
train_label=P_f-score_sent: 0.7795083022267987
train_precision_macro_sent: 0.6250551776544157
train_recall_macro_sent: 0.5812289361227183
train_f-score_macro_sent: 0.5470487556276749
train_precision_micro_sent: 0.6914794007490637
train_recall_micro_sent: 0.6914794007490637
train_f-score_micro_sent: 0.6914794007490637
train_label=O_precision_tok: 0.9175905114809865
train_label=O_recall_tok: 0.9718207918164491
train_label=O_f-score_tok: 0.9439273871966818
train_label=N_precision_tok: 0.8163109756097561
train_label=N_recall_tok: 0.6787072243346007
train_label=N_f-score_tok: 0.7411764705882353
train_label=P_precision_tok: 0.8795733226996312
train_label=P_recall_tok: 0.7053603549586281
train_label=P_f-score_tok: 0.7828922558175647
train_precision_macro_tok: 0.8711582699301245
train_recall_macro_tok: 0.785296123703226
train_f-score_macro_tok: 0.8226653712008273
train_precision_micro_tok: 0.9056160815817468
train_recall_micro_tok: 0.9056160815817468
train_f-score_micro_tok: 0.9056160815817468
train_time: 249.1593587398529
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4805    0.0683    0.1197      1624
           N     0.6666    0.8366    0.7420      3310
           P     0.7281    0.8388    0.7795      3610

   micro avg     0.6915    0.6915    0.6915      8544
   macro avg     0.6251    0.5812    0.5470      8544
weighted avg     0.6572    0.6915    0.6395      8544

F1-macro sent:  0.5470487556276749
F1-micro sent:  0.6914794007490637
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9176    0.9718    0.9439    124347
           N     0.8163    0.6787    0.7412     14202
           P     0.8796    0.7054    0.7829     25017

   micro avg     0.9056    0.9056    0.9056    163566
   macro avg     0.8712    0.7853    0.8227    163566
weighted avg     0.9030    0.9056    0.9017    163566

F1-macro tok:  0.8226653712008273
F1-micro tok:  0.9056160815817468
**************************************************
dev_cost_sum: 42081.56787109375
dev_cost_avg: 38.221224224426656
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19142.0
dev_accuracy_tok: 0.8997837736203816
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6846307385229541
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7384284176533907
dev_label=P_precision_sent: 0.6542372881355932
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7466150870406191
dev_precision_macro_sent: 0.7129560088861825
dev_recall_macro_sent: 0.5685685787816138
dev_f-score_macro_sent: 0.5173297037961901
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9080816796088582
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.9399821375409347
dev_label=N_precision_tok: 0.8097595473833098
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.7000917150718434
dev_label=P_precision_tok: 0.8929292929292929
dev_label=P_recall_tok: 0.6880448318804483
dev_label=P_f-score_tok: 0.7772111834007386
dev_precision_macro_tok: 0.8702568399738203
dev_recall_macro_tok: 0.7596120717449693
dev_f-score_macro_tok: 0.8057616786711722
dev_precision_micro_tok: 0.8997837736203816
dev_recall_micro_tok: 0.8997837736203816
dev_f-score_micro_tok: 0.8997837736203816
dev_time: 13.549586057662964
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6846    0.8014    0.7384       428
           P     0.6542    0.8694    0.7466       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.7130    0.5686    0.5173      1101
weighted avg     0.6964    0.6694    0.6021      1101

F1-macro sent:  0.5173297037961901
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9742    0.9400     16205
           N     0.8098    0.6166    0.7001      1857
           P     0.8929    0.6880    0.7772      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8703    0.7596    0.8058     21274
weighted avg     0.8972    0.8998    0.8945     21274

F1-macro tok:  0.8057616786711722
F1-micro tok:  0.8997837736203816
**************************************************
Best epoch: 22
**************************************************

EPOCH: 28
Learning rate: 0.729000
train_cost_sum: 299746.2836303711
train_cost_avg: 35.082664282580886
train_count_sent: 8544.0
train_total_correct_sent: 5939.0
train_accuracy_sent: 0.6951076779026217
train_count_tok: 163566.0
train_total_correct_tok: 148399.0
train_accuracy_tok: 0.9072729051269823
train_label=O_precision_sent: 0.47417840375586856
train_label=O_recall_sent: 0.062192118226600986
train_label=O_f-score_sent: 0.10996189439303211
train_label=N_precision_sent: 0.6654761904761904
train_label=N_recall_sent: 0.8444108761329305
train_label=N_f-score_sent: 0.7443408788282291
train_label=P_precision_sent: 0.7366255144032922
train_label=P_recall_sent: 0.8429362880886426
train_label=P_f-score_sent: 0.7862033329027257
train_precision_macro_sent: 0.6254267028784505
train_recall_macro_sent: 0.583179760816058
train_f-score_macro_sent: 0.5468353687079955
train_precision_micro_sent: 0.6951076779026217
train_recall_micro_sent: 0.6951076779026217
train_f-score_micro_sent: 0.6951076779026217
train_label=O_precision_tok: 0.9195105805008332
train_label=O_recall_tok: 0.9718207918164491
train_label=O_f-score_tok: 0.944942291451628
train_label=N_precision_tok: 0.8143167390578016
train_label=N_recall_tok: 0.6864526123081256
train_label=N_f-score_tok: 0.7449377244593872
train_label=P_precision_tok: 0.8827145194071283
train_label=P_recall_tok: 0.7117959787344605
train_label=P_f-score_tok: 0.7880947112192963
train_precision_macro_tok: 0.8721806129885877
train_recall_macro_tok: 0.7900231276196784
train_f-score_macro_tok: 0.8259915757101038
train_precision_micro_tok: 0.9072729051269823
train_recall_micro_tok: 0.9072729051269823
train_f-score_micro_tok: 0.9072729051269823
train_time: 158.3493754863739
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4742    0.0622    0.1100      1624
           N     0.6655    0.8444    0.7443      3310
           P     0.7366    0.8429    0.7862      3610

   micro avg     0.6951    0.6951    0.6951      8544
   macro avg     0.6254    0.5832    0.5468      8544
weighted avg     0.6592    0.6951    0.6414      8544

F1-macro sent:  0.5468353687079955
F1-micro sent:  0.6951076779026217
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9195    0.9718    0.9449    124347
           N     0.8143    0.6865    0.7449     14202
           P     0.8827    0.7118    0.7881     25017

   micro avg     0.9073    0.9073    0.9073    163566
   macro avg     0.8722    0.7900    0.8260    163566
weighted avg     0.9047    0.9073    0.9036    163566

F1-macro tok:  0.8259915757101038
F1-micro tok:  0.9072729051269823
**************************************************
dev_cost_sum: 42064.340576171875
dev_cost_avg: 38.20557727172741
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.14869888475836432
dev_label=N_precision_sent: 0.6718446601941748
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.733828207847296
dev_label=P_precision_sent: 0.6904761904761905
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7616161616161615
dev_precision_macro_sent: 0.6207736168901218
dev_recall_macro_sent: 0.581615519531285
dev_f-score_macro_sent: 0.548047751407274
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9092272202998847
dev_label=O_recall_tok: 0.9729095958037642
dev_label=O_f-score_tok: 0.9399910567893874
dev_label=N_precision_tok: 0.8071780436312456
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.699816961561928
dev_label=P_precision_tok: 0.8901711102268205
dev_label=P_recall_tok: 0.6964508094645081
dev_label=P_f-score_tok: 0.7814847161572053
dev_precision_macro_tok: 0.8688587913859837
dev_recall_macro_tok: 0.7623411008047355
dev_f-score_macro_tok: 0.807097578169507
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 7.599740028381348
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0873    0.1487       229
           N     0.6718    0.8084    0.7338       428
           P     0.6905    0.8491    0.7616       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6208    0.5816    0.5480      1101
weighted avg     0.6436    0.6748    0.6233      1101

F1-macro sent:  0.548047751407274
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9729    0.9400     16205
           N     0.8072    0.6177    0.6998      1857
           P     0.8902    0.6965    0.7815      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8689    0.7623    0.8071     21274
weighted avg     0.8974    0.9002    0.8951     21274

F1-macro tok:  0.807097578169507
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.729000
train_cost_sum: 298254.2643432617
train_cost_avg: 34.908036557029696
train_count_sent: 8544.0
train_total_correct_sent: 5969.0
train_accuracy_sent: 0.6986189138576779
train_count_tok: 163566.0
train_total_correct_tok: 148774.0
train_accuracy_tok: 0.9095655576342272
train_label=O_precision_sent: 0.48859934853420195
train_label=O_recall_sent: 0.09236453201970443
train_label=O_f-score_sent: 0.15535991714137753
train_label=N_precision_sent: 0.682496270512183
train_label=N_recall_sent: 0.8293051359516617
train_label=N_f-score_sent: 0.7487725040916531
train_label=P_precision_sent: 0.729300118623962
train_label=P_recall_sent: 0.8515235457063712
train_label=P_f-score_sent: 0.7856869009584665
train_precision_macro_sent: 0.6334652458901157
train_recall_macro_sent: 0.5910644045592458
train_f-score_macro_sent: 0.5632731073971656
train_precision_micro_sent: 0.6986189138576779
train_recall_micro_sent: 0.6986189138576779
train_f-score_micro_sent: 0.6986189138576779
train_label=O_precision_tok: 0.9221476919789687
train_label=O_recall_tok: 0.9718047077935134
train_label=O_f-score_tok: 0.9463252280825405
train_label=N_precision_tok: 0.8206062613881067
train_label=N_recall_tok: 0.6976482185607661
train_label=N_f-score_tok: 0.7541482721875474
train_label=P_precision_tok: 0.8814611961465109
train_label=P_recall_tok: 0.7205100531638485
train_label=P_f-score_tok: 0.7929001891523337
train_precision_macro_tok: 0.8747383831711955
train_recall_macro_tok: 0.7966543265060427
train_f-score_macro_tok: 0.8311245631408072
train_precision_micro_tok: 0.9095655576342272
train_recall_micro_tok: 0.9095655576342272
train_f-score_micro_tok: 0.9095655576342272
train_time: 145.44939756393433
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4886    0.0924    0.1554      1624
           N     0.6825    0.8293    0.7488      3310
           P     0.7293    0.8515    0.7857      3610

   micro avg     0.6986    0.6986    0.6986      8544
   macro avg     0.6335    0.5911    0.5633      8544
weighted avg     0.6654    0.6986    0.6516      8544

F1-macro sent:  0.5632731073971656
F1-micro sent:  0.6986189138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9221    0.9718    0.9463    124347
           N     0.8206    0.6976    0.7541     14202
           P     0.8815    0.7205    0.7929     25017

   micro avg     0.9096    0.9096    0.9096    163566
   macro avg     0.8747    0.7967    0.8311    163566
weighted avg     0.9071    0.9096    0.9062    163566

F1-macro tok:  0.8311245631408072
F1-micro tok:  0.9095655576342272
**************************************************
dev_cost_sum: 41928.555603027344
dev_cost_avg: 38.08224850411203
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19138.0
dev_accuracy_tok: 0.8995957506815832
dev_label=O_precision_sent: 0.5142857142857142
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13636363636363635
dev_label=N_precision_sent: 0.6843177189409368
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7312295973884657
dev_label=P_precision_sent: 0.6678260869565218
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7536800785083416
dev_precision_macro_sent: 0.622143173394391
dev_recall_macro_sent: 0.5761714046413879
dev_f-score_macro_sent: 0.5404244374201479
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9136665501572877
dev_label=O_recall_tok: 0.967849429188522
dev_label=O_f-score_tok: 0.9399778250576848
dev_label=N_precision_tok: 0.7909029192124916
dev_label=N_recall_tok: 0.6273559504577275
dev_label=N_f-score_tok: 0.6996996996996997
dev_label=P_precision_tok: 0.8686907020872865
dev_label=P_recall_tok: 0.712640099626401
dev_label=P_f-score_tok: 0.7829656233966137
dev_precision_macro_tok: 0.8577533904856885
dev_recall_macro_tok: 0.7692818264242168
dev_f-score_macro_tok: 0.8075477160513328
dev_precision_micro_tok: 0.8995957506815832
dev_recall_micro_tok: 0.8995957506815832
dev_f-score_micro_tok: 0.8995957506815832
dev_time: 7.3343188762664795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5143    0.0786    0.1364       229
           N     0.6843    0.7850    0.7312       428
           P     0.6678    0.8649    0.7537       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6221    0.5762    0.5404      1101
weighted avg     0.6423    0.6703    0.6166      1101

F1-macro sent:  0.5404244374201479
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9137    0.9678    0.9400     16205
           N     0.7909    0.6274    0.6997      1857
           P     0.8687    0.7126    0.7830      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8578    0.7693    0.8075     21274
weighted avg     0.8962    0.8996    0.8953     21274

F1-macro tok:  0.8075477160513328
F1-micro tok:  0.8995957506815832
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.729000
train_cost_sum: 297149.1414794922
train_cost_avg: 34.77869165256229
train_count_sent: 8544.0
train_total_correct_sent: 5980.0
train_accuracy_sent: 0.6999063670411985
train_count_tok: 163566.0
train_total_correct_tok: 149025.0
train_accuracy_tok: 0.9111001063790763
train_label=O_precision_sent: 0.5070921985815603
train_label=O_recall_sent: 0.08805418719211823
train_label=O_f-score_sent: 0.15005246589716684
train_label=N_precision_sent: 0.6754090471607315
train_label=N_recall_sent: 0.8480362537764351
train_label=N_f-score_sent: 0.7519421376908654
train_label=P_precision_sent: 0.7379444715051144
train_label=P_recall_sent: 0.8393351800554016
train_label=P_f-score_sent: 0.7853810264385691
train_precision_macro_sent: 0.640148572415802
train_recall_macro_sent: 0.5918085403413184
train_f-score_macro_sent: 0.5624585433422005
train_precision_micro_sent: 0.6999063670411985
train_recall_micro_sent: 0.6999063670411985
train_f-score_micro_sent: 0.6999063670411985
train_label=O_precision_tok: 0.9232266485508629
train_label=O_recall_tok: 0.9726893290549833
train_label=O_f-score_tok: 0.947312771190025
train_label=N_precision_tok: 0.8247456786039202
train_label=N_recall_tok: 0.7021546261089987
train_label=N_f-score_tok: 0.7585288860152893
train_label=P_precision_tok: 0.8844913515098212
train_label=P_recall_tok: 0.7235879601870728
train_label=P_f-score_tok: 0.7959897104412637
train_precision_macro_tok: 0.8774878928882014
train_recall_macro_tok: 0.7994773051170183
train_f-score_macro_tok: 0.833943789215526
train_precision_micro_tok: 0.9111001063790763
train_recall_micro_tok: 0.9111001063790763
train_f-score_micro_tok: 0.9111001063790763
train_time: 145.82524466514587
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5071    0.0881    0.1501      1624
           N     0.6754    0.8480    0.7519      3310
           P     0.7379    0.8393    0.7854      3610

   micro avg     0.6999    0.6999    0.6999      8544
   macro avg     0.6401    0.5918    0.5625      8544
weighted avg     0.6698    0.6999    0.6517      8544

F1-macro sent:  0.5624585433422005
F1-micro sent:  0.6999063670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9232    0.9727    0.9473    124347
           N     0.8247    0.7022    0.7585     14202
           P     0.8845    0.7236    0.7960     25017

   micro avg     0.9111    0.9111    0.9111    163566
   macro avg     0.8775    0.7995    0.8339    163566
weighted avg     0.9088    0.9111    0.9078    163566

F1-macro tok:  0.833943789215526
F1-micro tok:  0.9111001063790763
**************************************************
dev_cost_sum: 42026.83630371094
dev_cost_avg: 38.17151344569567
dev_count_sent: 1101.0
dev_total_correct_sent: 751.0
dev_accuracy_sent: 0.6821071752951862
dev_count_tok: 21274.0
dev_total_correct_tok: 19147.0
dev_accuracy_tok: 0.9000188022938799
dev_label=O_precision_sent: 0.5909090909090909
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10358565737051793
dev_label=N_precision_sent: 0.6716981132075471
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7432150313152399
dev_label=P_precision_sent: 0.6958105646630237
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7693856998992952
dev_precision_macro_sent: 0.6528059229265539
dev_recall_macro_sent: 0.5829682067489683
dev_f-score_macro_sent: 0.5387287961950177
dev_precision_micro_sent: 0.6821071752951862
dev_recall_micro_sent: 0.6821071752951862
dev_f-score_micro_sent: 0.6821071752951862
dev_label=O_precision_tok: 0.9083688269828479
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.9399922570654279
dev_label=N_precision_tok: 0.8215586307356154
dev_label=N_recall_tok: 0.6074313408723748
dev_label=N_f-score_tok: 0.698452012383901
dev_label=P_precision_tok: 0.8852394143252869
dev_label=P_recall_tok: 0.6964508094645081
dev_label=P_f-score_tok: 0.7795783237497822
dev_precision_macro_tok: 0.8717222906812502
dev_recall_macro_tok: 0.7592596985747031
dev_f-score_macro_tok: 0.8060075310663702
dev_precision_micro_tok: 0.9000188022938799
dev_recall_micro_tok: 0.9000188022938799
dev_f-score_micro_tok: 0.9000188022938799
dev_time: 7.239715337753296
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5909    0.0568    0.1036       229
           N     0.6717    0.8318    0.7432       428
           P     0.6958    0.8604    0.7694       444

   micro avg     0.6821    0.6821    0.6821      1101
   macro avg     0.6528    0.5830    0.5387      1101
weighted avg     0.6646    0.6821    0.6207      1101

F1-macro sent:  0.5387287961950177
F1-micro sent:  0.6821071752951862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9739    0.9400     16205
           N     0.8216    0.6074    0.6985      1857
           P     0.8852    0.6965    0.7796      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8717    0.7593    0.8060     21274
weighted avg     0.8973    0.9000    0.8947     21274

F1-macro tok:  0.8060075310663702
F1-micro tok:  0.9000188022938799
**************************************************
Best epoch: 30
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 295886.3955078125
train_cost_avg: 34.63089835063349
train_count_sent: 8544.0
train_total_correct_sent: 5972.0
train_accuracy_sent: 0.6989700374531835
train_count_tok: 163566.0
train_total_correct_tok: 149222.0
train_accuracy_tok: 0.9123045131628823
train_label=O_precision_sent: 0.4116161616161616
train_label=O_recall_sent: 0.10036945812807882
train_label=O_f-score_sent: 0.1613861386138614
train_label=N_precision_sent: 0.6761651774933591
train_label=N_recall_sent: 0.8459214501510574
train_label=N_f-score_sent: 0.7515769695342908
train_label=P_precision_sent: 0.7509358622410781
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7900748326112642
train_precision_macro_sent: 0.612905733783533
train_recall_macro_sent: 0.5932696379397675
train_f-score_macro_sent: 0.5676793135864721
train_precision_micro_sent: 0.6989700374531835
train_recall_micro_sent: 0.6989700374531835
train_f-score_micro_sent: 0.6989700374531835
train_label=O_precision_tok: 0.9250472568091896
train_label=O_recall_tok: 0.9720781361834222
train_label=O_f-score_tok: 0.9479797346048876
train_label=N_precision_tok: 0.8236217869245392
train_label=N_recall_tok: 0.7016617377834108
train_label=N_f-score_tok: 0.7577658644158017
train_label=P_precision_tok: 0.8838349841330897
train_label=P_recall_tok: 0.7347803493624335
train_label=P_f-score_tok: 0.80244461420932
train_precision_macro_tok: 0.8775013426222729
train_recall_macro_tok: 0.8028400744430888
train_f-score_macro_tok: 0.8360634044100032
train_precision_micro_tok: 0.9123045131628823
train_recall_micro_tok: 0.9123045131628823
train_f-score_micro_tok: 0.9123045131628823
train_time: 146.22223114967346
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4116    0.1004    0.1614      1624
           N     0.6762    0.8459    0.7516      3310
           P     0.7509    0.8335    0.7901      3610

   micro avg     0.6990    0.6990    0.6990      8544
   macro avg     0.6129    0.5933    0.5677      8544
weighted avg     0.6575    0.6990    0.6557      8544

F1-macro sent:  0.5676793135864721
F1-micro sent:  0.6989700374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9250    0.9721    0.9480    124347
           N     0.8236    0.7017    0.7578     14202
           P     0.8838    0.7348    0.8024     25017

   micro avg     0.9123    0.9123    0.9123    163566
   macro avg     0.8775    0.8028    0.8361    163566
weighted avg     0.9099    0.9123    0.9092    163566

F1-macro tok:  0.8360634044100032
F1-micro tok:  0.9123045131628823
**************************************************
dev_cost_sum: 41978.107666015625
dev_cost_avg: 38.12725491917859
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19114.0
dev_accuracy_tok: 0.898467613048792
dev_label=O_precision_sent: 0.65
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10441767068273092
dev_label=N_precision_sent: 0.6568265682656826
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.734020618556701
dev_label=P_precision_sent: 0.686456400742115
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7527975584944049
dev_precision_macro_sent: 0.6644276563359325
dev_recall_macro_sent: 0.5739591977399593
dev_f-score_macro_sent: 0.5304119492446122
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9122898854184842
dev_label=O_recall_tok: 0.9679111385374884
dev_label=O_f-score_tok: 0.9392778010659321
dev_label=N_precision_tok: 0.7962835512732278
dev_label=N_recall_tok: 0.6230479267635972
dev_label=N_f-score_tok: 0.699093655589124
dev_label=P_precision_tok: 0.8645357686453576
dev_label=P_recall_tok: 0.7073474470734745
dev_label=P_f-score_tok: 0.7780821917808218
dev_precision_macro_tok: 0.8577030684456899
dev_recall_macro_tok: 0.7661021707915201
dev_f-score_macro_tok: 0.805484549478626
dev_precision_micro_tok: 0.898467613048792
dev_recall_micro_tok: 0.898467613048792
dev_f-score_micro_tok: 0.8984676130487919
dev_time: 7.109439849853516
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6500    0.0568    0.1044       229
           N     0.6568    0.8318    0.7340       428
           P     0.6865    0.8333    0.7528       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6644    0.5740    0.5304      1101
weighted avg     0.6674    0.6712    0.6106      1101

F1-macro sent:  0.5304119492446122
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9679    0.9393     16205
           N     0.7963    0.6230    0.6991      1857
           P     0.8645    0.7073    0.7781      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8577    0.7661    0.8055     21274
weighted avg     0.8950    0.8985    0.8940     21274

F1-macro tok:  0.805484549478626
F1-micro tok:  0.8984676130487919
**************************************************
Best epoch: 30
**************************************************

EPOCH: 32
Learning rate: 0.729000
train_cost_sum: 295092.34130859375
train_cost_avg: 34.53796129548148
train_count_sent: 8544.0
train_total_correct_sent: 6029.0
train_accuracy_sent: 0.7056413857677902
train_count_tok: 163566.0
train_total_correct_tok: 149438.0
train_accuracy_tok: 0.9136250810070553
train_label=O_precision_sent: 0.5140845070422535
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.1530398322851153
train_label=N_precision_sent: 0.6736591179976162
train_label=N_recall_sent: 0.8537764350453172
train_label=N_f-score_sent: 0.7530979347101933
train_label=P_precision_sent: 0.752029520295203
train_label=P_recall_sent: 0.846814404432133
train_label=P_f-score_sent: 0.7966123778501628
train_precision_macro_sent: 0.6465910484450242
train_recall_macro_sent: 0.5968307724366542
train_f-score_macro_sent: 0.5675833816151571
train_precision_micro_sent: 0.7056413857677902
train_recall_micro_sent: 0.7056413857677902
train_f-score_micro_sent: 0.7056413857677902
train_label=O_precision_tok: 0.9265633744508928
train_label=O_recall_tok: 0.9719575060114036
train_label=O_f-score_tok: 0.9487177474429521
train_label=N_precision_tok: 0.8254908323868246
train_label=N_recall_tok: 0.7164483875510491
train_label=N_f-score_tok: 0.7671139927623642
train_label=P_precision_tok: 0.8847170809095717
train_label=P_recall_tok: 0.7356197785505856
train_label=P_f-score_tok: 0.8033087432886639
train_precision_macro_tok: 0.8789237625824297
train_recall_macro_tok: 0.8080085573710128
train_f-score_macro_tok: 0.8397134944979934
train_precision_micro_tok: 0.9136250810070553
train_recall_micro_tok: 0.9136250810070553
train_f-score_micro_tok: 0.9136250810070553
train_time: 146.75206089019775
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5141    0.0899    0.1530      1624
           N     0.6737    0.8538    0.7531      3310
           P     0.7520    0.8468    0.7966      3610

   micro avg     0.7056    0.7056    0.7056      8544
   macro avg     0.6466    0.5968    0.5676      8544
weighted avg     0.6764    0.7056    0.6574      8544

F1-macro sent:  0.5675833816151571
F1-micro sent:  0.7056413857677902
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9266    0.9720    0.9487    124347
           N     0.8255    0.7164    0.7671     14202
           P     0.8847    0.7356    0.8033     25017

   micro avg     0.9136    0.9136    0.9136    163566
   macro avg     0.8789    0.8080    0.8397    163566
weighted avg     0.9114    0.9136    0.9107    163566

F1-macro tok:  0.8397134944979934
F1-micro tok:  0.9136250810070553
**************************************************
dev_cost_sum: 41964.22180175781
dev_cost_avg: 38.114642871714636
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19122.0
dev_accuracy_tok: 0.8988436589263891
dev_label=O_precision_sent: 0.34615384615384615
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07058823529411766
dev_label=N_precision_sent: 0.6227045075125208
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7263875365141188
dev_label=P_precision_sent: 0.7163865546218487
dev_label=P_recall_sent: 0.7680180180180181
dev_label=P_f-score_sent: 0.741304347826087
dev_precision_macro_sent: 0.5617483027627386
dev_recall_macro_sent: 0.55960488505483
dev_f-score_macro_sent: 0.5127600398781078
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9125123611191903
dev_label=O_recall_tok: 0.9680345572354212
dev_label=O_f-score_tok: 0.9394538268056055
dev_label=N_precision_tok: 0.786479250334672
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.7012831990450612
dev_label=P_precision_tok: 0.872923908845114
dev_label=P_recall_tok: 0.7036114570361146
dev_label=P_f-score_tok: 0.7791760041372177
dev_precision_macro_tok: 0.8573051734329921
dev_recall_macro_tok: 0.7681289981156421
dev_f-score_macro_tok: 0.8066376766626281
dev_precision_micro_tok: 0.8988436589263891
dev_recall_micro_tok: 0.8988436589263891
dev_f-score_micro_tok: 0.8988436589263891
dev_time: 7.046109914779663
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3462    0.0393    0.0706       229
           N     0.6227    0.8715    0.7264       428
           P     0.7164    0.7680    0.7413       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.5617    0.5596    0.5128      1101
weighted avg     0.6030    0.6567    0.5960      1101

F1-macro sent:  0.5127600398781078
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9680    0.9395     16205
           N     0.7865    0.6327    0.7013      1857
           P     0.8729    0.7036    0.7792      3212

   micro avg     0.8988    0.8988    0.8988     21274
   macro avg     0.8573    0.7681    0.8066     21274
weighted avg     0.8955    0.8988    0.8945     21274

F1-macro tok:  0.8066376766626281
F1-micro tok:  0.8988436589263891
**************************************************
Best epoch: 30
**************************************************

EPOCH: 33
Learning rate: 0.729000
train_cost_sum: 294054.30584716797
train_cost_avg: 34.41646838098876
train_count_sent: 8544.0
train_total_correct_sent: 5978.0
train_accuracy_sent: 0.6996722846441947
train_count_tok: 163566.0
train_total_correct_tok: 149766.0
train_accuracy_tok: 0.915630387733392
train_label=O_precision_sent: 0.4272151898734177
train_label=O_recall_sent: 0.08312807881773399
train_label=O_f-score_sent: 0.13917525773195874
train_label=N_precision_sent: 0.6781332691845081
train_label=N_recall_sent: 0.8516616314199396
train_label=N_f-score_sent: 0.7550555778759875
train_label=P_precision_sent: 0.7428150331613854
train_label=P_recall_sent: 0.8376731301939058
train_label=P_f-score_sent: 0.7873974742872021
train_precision_macro_sent: 0.6160544974064371
train_recall_macro_sent: 0.5908209468105264
train_f-score_macro_sent: 0.5605427699650495
train_precision_micro_sent: 0.6996722846441947
train_recall_micro_sent: 0.6996722846441947
train_f-score_micro_sent: 0.6996722846441947
train_label=O_precision_tok: 0.9285560692398667
train_label=O_recall_tok: 0.9723676485962669
train_label=O_f-score_tok: 0.9499569847698588
train_label=N_precision_tok: 0.8292426083434589
train_label=N_recall_tok: 0.7208139698633995
train_label=N_f-score_tok: 0.7712359211963687
train_label=P_precision_tok: 0.8862760032370163
train_label=P_recall_tok: 0.7442139345245233
train_label=P_f-score_tok: 0.8090561446201981
train_precision_macro_tok: 0.881358226940114
train_recall_macro_tok: 0.8124651843280631
train_f-score_macro_tok: 0.8434163501954752
train_precision_micro_tok: 0.915630387733392
train_recall_micro_tok: 0.915630387733392
train_f-score_micro_tok: 0.915630387733392
train_time: 145.53683924674988
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4272    0.0831    0.1392      1624
           N     0.6781    0.8517    0.7551      3310
           P     0.7428    0.8377    0.7874      3610

   micro avg     0.6997    0.6997    0.6997      8544
   macro avg     0.6161    0.5908    0.5605      8544
weighted avg     0.6578    0.6997    0.6517      8544

F1-macro sent:  0.5605427699650495
F1-micro sent:  0.6996722846441947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9286    0.9724    0.9500    124347
           N     0.8292    0.7208    0.7712     14202
           P     0.8863    0.7442    0.8091     25017

   micro avg     0.9156    0.9156    0.9156    163566
   macro avg     0.8814    0.8125    0.8434    163566
weighted avg     0.9135    0.9156    0.9129    163566

F1-macro tok:  0.8434163501954752
F1-micro tok:  0.915630387733392
**************************************************
dev_cost_sum: 41930.50909423828
dev_cost_avg: 38.08402279222369
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19180.0
dev_accuracy_tok: 0.9015699915389678
dev_label=O_precision_sent: 0.5333333333333333
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12355212355212353
dev_label=N_precision_sent: 0.6882591093117408
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.737527114967462
dev_label=P_precision_sent: 0.6689774696707106
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7561214495592556
dev_precision_macro_sent: 0.6301899707719283
dev_recall_macro_sent: 0.5778769627890143
dev_f-score_macro_sent: 0.5390668960262804
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9124036846069173
dev_label=O_recall_tok: 0.971860536871336
dev_label=O_f-score_tok: 0.941194047690193
dev_label=N_precision_tok: 0.7945762711864407
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.7034813925570227
dev_label=P_precision_tok: 0.8900709219858156
dev_label=P_recall_tok: 0.7033001245330013
dev_label=P_f-score_tok: 0.7857391304347826
dev_precision_macro_tok: 0.8656836259263913
dev_recall_macro_tok: 0.768762044198143
dev_f-score_macro_tok: 0.8101381902273328
dev_precision_micro_tok: 0.9015699915389678
dev_recall_micro_tok: 0.9015699915389678
dev_f-score_micro_tok: 0.9015699915389677
dev_time: 7.151633977890015
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5333    0.0699    0.1236       229
           N     0.6883    0.7944    0.7375       428
           P     0.6690    0.8694    0.7561       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6302    0.5779    0.5391      1101
weighted avg     0.6483    0.6739    0.6173      1101

F1-macro sent:  0.5390668960262804
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9124    0.9719    0.9412     16205
           N     0.7946    0.6311    0.7035      1857
           P     0.8901    0.7033    0.7857      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8657    0.7688    0.8101     21274
weighted avg     0.8987    0.9016    0.8970     21274

F1-macro tok:  0.8101381902273328
F1-micro tok:  0.9015699915389677
**************************************************
Best epoch: 30
**************************************************

EPOCH: 34
Learning rate: 0.729000
train_cost_sum: 293033.0213623047
train_cost_avg: 34.296936020869
train_count_sent: 8544.0
train_total_correct_sent: 6069.0
train_accuracy_sent: 0.7103230337078652
train_count_tok: 163566.0
train_total_correct_tok: 149770.0
train_accuracy_tok: 0.9156548426934693
train_label=O_precision_sent: 0.4837837837837838
train_label=O_recall_sent: 0.1102216748768473
train_label=O_f-score_sent: 0.17953861584754266
train_label=N_precision_sent: 0.6831036983321247
train_label=N_recall_sent: 0.8537764350453172
train_label=N_f-score_sent: 0.7589633409426614
train_label=P_precision_sent: 0.7589794401783503
train_label=P_recall_sent: 0.8487534626038781
train_label=P_f-score_sent: 0.8013600104616188
train_precision_macro_sent: 0.641955640764753
train_recall_macro_sent: 0.6042505241753475
train_f-score_macro_sent: 0.5799539890839409
train_precision_micro_sent: 0.7103230337078652
train_recall_micro_sent: 0.7103230337078652
train_f-score_micro_sent: 0.7103230337078652
train_label=O_precision_tok: 0.9291542028405989
train_label=O_recall_tok: 0.9717162456673664
train_label=O_f-score_tok: 0.9499587247926413
train_label=N_precision_tok: 0.8306608357628765
train_label=N_recall_tok: 0.7222222222222222
train_label=N_f-score_tok: 0.7726553672316383
train_label=P_precision_tok: 0.8823140495867768
train_label=P_recall_tok: 0.7468121677259464
train_label=P_f-score_tok: 0.8089279528922757
train_precision_macro_tok: 0.8807096960634174
train_recall_macro_tok: 0.8135835452051783
train_f-score_macro_tok: 0.8438473483055184
train_precision_micro_tok: 0.9156548426934693
train_recall_micro_tok: 0.9156548426934693
train_f-score_micro_tok: 0.9156548426934693
train_time: 145.0830020904541
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4838    0.1102    0.1795      1624
           N     0.6831    0.8538    0.7590      3310
           P     0.7590    0.8488    0.8014      3610

   micro avg     0.7103    0.7103    0.7103      8544
   macro avg     0.6420    0.6043    0.5800      8544
weighted avg     0.6773    0.7103    0.6667      8544

F1-macro sent:  0.5799539890839409
F1-micro sent:  0.7103230337078652
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9292    0.9717    0.9500    124347
           N     0.8307    0.7222    0.7727     14202
           P     0.8823    0.7468    0.8089     25017

   micro avg     0.9157    0.9157    0.9157    163566
   macro avg     0.8807    0.8136    0.8438    163566
weighted avg     0.9134    0.9157    0.9130    163566

F1-macro tok:  0.8438473483055184
F1-micro tok:  0.9156548426934693
**************************************************
dev_cost_sum: 41933.33172607422
dev_cost_avg: 38.08658649053063
dev_count_sent: 1101.0
dev_total_correct_sent: 747.0
dev_accuracy_sent: 0.6784741144414169
dev_count_tok: 21274.0
dev_total_correct_tok: 19101.0
dev_accuracy_tok: 0.8978565384976968
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.10480349344978165
dev_label=O_f-score_sent: 0.1791044776119403
dev_label=N_precision_sent: 0.6723484848484849
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7426778242677825
dev_label=P_precision_sent: 0.6891385767790262
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.752556237218814
dev_precision_macro_sent: 0.6589572256707088
dev_recall_macro_sent: 0.5876905248716864
dev_f-score_macro_sent: 0.558112846366179
dev_precision_micro_sent: 0.6784741144414169
dev_recall_micro_sent: 0.6784741144414169
dev_f-score_micro_sent: 0.6784741144414169
dev_label=O_precision_tok: 0.9124308588064046
dev_label=O_recall_tok: 0.9670472076519593
dev_label=O_f-score_tok: 0.9389454763331335
dev_label=N_precision_tok: 0.7923344947735191
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6907654921020656
dev_label=P_precision_tok: 0.8607357357357357
dev_label=P_recall_tok: 0.7138854296388543
dev_label=P_f-score_tok: 0.7804628999319264
dev_precision_macro_tok: 0.8551670297718864
dev_recall_macro_tok: 0.7644035016063616
dev_f-score_macro_tok: 0.8033912894557086
dev_precision_micro_tok: 0.8978565384976968
dev_recall_micro_tok: 0.8978565384976968
dev_f-score_micro_tok: 0.8978565384976968
dev_time: 7.701543807983398
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.1048    0.1791       229
           N     0.6723    0.8294    0.7427       428
           P     0.6891    0.8288    0.7526       444

   micro avg     0.6785    0.6785    0.6785      1101
   macro avg     0.6590    0.5877    0.5581      1101
weighted avg     0.6673    0.6785    0.6294      1101

F1-macro sent:  0.558112846366179
F1-micro sent:  0.6784741144414169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9124    0.9670    0.9389     16205
           N     0.7923    0.6123    0.6908      1857
           P     0.8607    0.7139    0.7805      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8552    0.7644    0.8034     21274
weighted avg     0.8941    0.8979    0.8934     21274

F1-macro tok:  0.8033912894557086
F1-micro tok:  0.8978565384976968
**************************************************
Best epoch: 30
**************************************************

EPOCH: 35
Learning rate: 0.656100
train_cost_sum: 291702.27001953125
train_cost_avg: 34.141183288802814
train_count_sent: 8544.0
train_total_correct_sent: 6052.0
train_accuracy_sent: 0.7083333333333334
train_count_tok: 163566.0
train_total_correct_tok: 150166.0
train_accuracy_tok: 0.9180758837411198
train_label=O_precision_sent: 0.47527472527472525
train_label=O_recall_sent: 0.10652709359605911
train_label=O_f-score_sent: 0.17404426559356137
train_label=N_precision_sent: 0.6820599613152805
train_label=N_recall_sent: 0.8522658610271904
train_label=N_f-score_sent: 0.7577222669889874
train_label=P_precision_sent: 0.7561819980217607
train_label=P_recall_sent: 0.8470914127423823
train_label=P_f-score_sent: 0.7990593153906455
train_precision_macro_sent: 0.6378388948705888
train_recall_macro_sent: 0.6019614557885439
train_f-score_macro_sent: 0.576941949324398
train_precision_micro_sent: 0.7083333333333334
train_recall_micro_sent: 0.7083333333333334
train_f-score_micro_sent: 0.7083333333333334
train_label=O_precision_tok: 0.9314204282853181
train_label=O_recall_tok: 0.9724159006650743
train_label=O_f-score_tok: 0.9514767849484789
train_label=N_precision_tok: 0.82984
train_label=N_recall_tok: 0.7303900859033939
train_label=N_f-score_tok: 0.7769455471500263
train_label=P_precision_tok: 0.888449590511155
train_label=P_recall_tok: 0.7545269216932486
train_label=P_f-score_tok: 0.8160300888398937
train_precision_macro_tok: 0.8832366729321577
train_recall_macro_tok: 0.8191109694205724
train_f-score_macro_tok: 0.8481508069794663
train_precision_micro_tok: 0.9180758837411198
train_recall_micro_tok: 0.9180758837411198
train_f-score_micro_tok: 0.9180758837411198
train_time: 144.0241072177887
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4753    0.1065    0.1740      1624
           N     0.6821    0.8523    0.7577      3310
           P     0.7562    0.8471    0.7991      3610

   micro avg     0.7083    0.7083    0.7083      8544
   macro avg     0.6378    0.6020    0.5769      8544
weighted avg     0.6741    0.7083    0.6642      8544

F1-macro sent:  0.576941949324398
F1-micro sent:  0.7083333333333334
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9314    0.9724    0.9515    124347
           N     0.8298    0.7304    0.7769     14202
           P     0.8884    0.7545    0.8160     25017

   micro avg     0.9181    0.9181    0.9181    163566
   macro avg     0.8832    0.8191    0.8482    163566
weighted avg     0.9160    0.9181    0.9156    163566

F1-macro tok:  0.8481508069794663
F1-micro tok:  0.9180758837411198
**************************************************
dev_cost_sum: 41942.794921875
dev_cost_avg: 38.09518158208447
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19101.0
dev_accuracy_tok: 0.8978565384976968
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05809128630705394
dev_label=N_precision_sent: 0.6811881188118812
dev_label=N_recall_sent: 0.8037383177570093
dev_label=N_f-score_sent: 0.737406216505895
dev_label=P_precision_sent: 0.6626712328767124
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.7529182879377432
dev_precision_macro_sent: 0.6423975616739757
dev_recall_macro_sent: 0.5686425416560502
dev_f-score_macro_sent: 0.5161385969168973
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9175160549107406
dev_label=O_recall_tok: 0.9609996914532551
dev_label=O_f-score_tok: 0.9387545964193141
dev_label=N_precision_tok: 0.7822368421052631
dev_label=N_recall_tok: 0.6402800215401184
dev_label=N_f-score_tok: 0.7041753035238377
dev_label=P_precision_tok: 0.84106436533621
dev_label=P_recall_tok: 0.7282067247820673
dev_label=P_f-score_tok: 0.7805773402302686
dev_precision_macro_tok: 0.846939087450738
dev_recall_macro_tok: 0.7764954792584803
dev_f-score_macro_tok: 0.8078357467244736
dev_precision_micro_tok: 0.8978565384976968
dev_recall_micro_tok: 0.8978565384976968
dev_f-score_micro_tok: 0.8978565384976968
dev_time: 8.117446422576904
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0306    0.0581       229
           N     0.6812    0.8037    0.7374       428
           P     0.6627    0.8716    0.7529       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6424    0.5686    0.5161      1101
weighted avg     0.6534    0.6703    0.6024      1101

F1-macro sent:  0.5161385969168973
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9175    0.9610    0.9388     16205
           N     0.7822    0.6403    0.7042      1857
           P     0.8411    0.7282    0.7806      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8469    0.7765    0.8078     21274
weighted avg     0.8942    0.8979    0.8944     21274

F1-macro tok:  0.8078357467244736
F1-micro tok:  0.8978565384976968
**************************************************
Best epoch: 30
**************************************************

EPOCH: 36
Learning rate: 0.590490
train_cost_sum: 290677.8073730469
train_cost_avg: 34.02127895283788
train_count_sent: 8544.0
train_total_correct_sent: 6046.0
train_accuracy_sent: 0.7076310861423221
train_count_tok: 163566.0
train_total_correct_tok: 150249.0
train_accuracy_tok: 0.9185833241627233
train_label=O_precision_sent: 0.5018315018315018
train_label=O_recall_sent: 0.08435960591133004
train_label=O_f-score_sent: 0.14443858724301525
train_label=N_precision_sent: 0.6802200430519014
train_label=N_recall_sent: 0.859214501510574
train_label=N_f-score_sent: 0.7593111734080896
train_label=P_precision_sent: 0.7493887530562348
train_label=P_recall_sent: 0.8490304709141274
train_label=P_f-score_sent: 0.7961038961038961
train_precision_macro_sent: 0.643813432646546
train_recall_macro_sent: 0.5975348594453438
train_f-score_macro_sent: 0.5666178855850004
train_precision_micro_sent: 0.7076310861423221
train_recall_micro_sent: 0.7076310861423221
train_f-score_micro_sent: 0.7076310861423221
train_label=O_precision_tok: 0.9320921479859017
train_label=O_recall_tok: 0.9719253379655319
train_label=O_f-score_tok: 0.9515920758401311
train_label=N_precision_tok: 0.8301356666934254
train_label=N_recall_tok: 0.7281368821292775
train_label=N_f-score_tok: 0.7757980419370568
train_label=P_precision_tok: 0.8882879522566207
train_label=P_recall_tok: 0.7615621377463325
train_label=P_f-score_tok: 0.8200581082535241
train_precision_macro_tok: 0.883505255645316
train_recall_macro_tok: 0.820541452613714
train_f-score_macro_tok: 0.8491494086769039
train_precision_micro_tok: 0.9185833241627233
train_recall_micro_tok: 0.9185833241627233
train_f-score_micro_tok: 0.9185833241627233
train_time: 145.5492022037506
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5018    0.0844    0.1444      1624
           N     0.6802    0.8592    0.7593      3310
           P     0.7494    0.8490    0.7961      3610

   micro avg     0.7076    0.7076    0.7076      8544
   macro avg     0.6438    0.5975    0.5666      8544
weighted avg     0.6755    0.7076    0.6580      8544

F1-macro sent:  0.5666178855850004
F1-micro sent:  0.7076310861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9321    0.9719    0.9516    124347
           N     0.8301    0.7281    0.7758     14202
           P     0.8883    0.7616    0.8201     25017

   micro avg     0.9186    0.9186    0.9186    163566
   macro avg     0.8835    0.8205    0.8491    163566
weighted avg     0.9165    0.9186    0.9162    163566

F1-macro tok:  0.8491494086769039
F1-micro tok:  0.9185833241627233
**************************************************
dev_cost_sum: 42044.89685058594
dev_cost_avg: 38.187917212157984
dev_count_sent: 1101.0
dev_total_correct_sent: 753.0
dev_accuracy_sent: 0.6839237057220708
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11857707509881421
dev_label=N_precision_sent: 0.691089108910891
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7481243301178992
dev_label=P_precision_sent: 0.6800699300699301
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.7657480314960631
dev_precision_macro_sent: 0.6653863463269404
dev_recall_macro_sent: 0.5856829567599678
dev_f-score_macro_sent: 0.5441498122375922
dev_precision_micro_sent: 0.6839237057220708
dev_recall_micro_sent: 0.6839237057220708
dev_f-score_micro_sent: 0.6839237057220708
dev_label=O_precision_tok: 0.9102608494921515
dev_label=O_recall_tok: 0.9733415612465288
dev_label=O_f-score_tok: 0.9407449378224437
dev_label=N_precision_tok: 0.8064743138634765
dev_label=N_recall_tok: 0.617124394184168
dev_label=N_f-score_tok: 0.6992068334350213
dev_label=P_precision_tok: 0.8887128712871287
dev_label=P_recall_tok: 0.6986301369863014
dev_label=P_f-score_tok: 0.7822903956771833
dev_precision_macro_tok: 0.8684826782142522
dev_recall_macro_tok: 0.7630320308056661
dev_f-score_macro_tok: 0.8074140556448827
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 8.275444507598877
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0655    0.1186       229
           N     0.6911    0.8154    0.7481       428
           P     0.6801    0.8761    0.7657       444

   micro avg     0.6839    0.6839    0.6839      1101
   macro avg     0.6654    0.5857    0.5441      1101
weighted avg     0.6729    0.6839    0.6243      1101

F1-macro sent:  0.5441498122375922
F1-micro sent:  0.6839237057220708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9103    0.9733    0.9407     16205
           N     0.8065    0.6171    0.6992      1857
           P     0.8887    0.6986    0.7823      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8685    0.7630    0.8074     21274
weighted avg     0.8979    0.9008    0.8957     21274

F1-macro tok:  0.8074140556448827
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 36
**************************************************

EPOCH: 37
Learning rate: 0.590490
train_cost_sum: 289707.5499267578
train_cost_avg: 33.90771885846885
train_count_sent: 8544.0
train_total_correct_sent: 6010.0
train_accuracy_sent: 0.7034176029962547
train_count_tok: 163566.0
train_total_correct_tok: 150595.0
train_accuracy_tok: 0.9206986782094079
train_label=O_precision_sent: 0.43990384615384615
train_label=O_recall_sent: 0.11268472906403941
train_label=O_f-score_sent: 0.17941176470588235
train_label=N_precision_sent: 0.6859975216852541
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.753710006807352
train_label=P_precision_sent: 0.7473735646225262
train_label=P_recall_sent: 0.8473684210526315
train_label=P_f-score_sent: 0.7942360119433985
train_precision_macro_sent: 0.6244249774872088
train_recall_macro_sent: 0.5987689755172387
train_f-score_macro_sent: 0.5757859278188776
train_precision_micro_sent: 0.7034176029962547
train_recall_micro_sent: 0.7034176029962547
train_f-score_micro_sent: 0.7034176029962547
train_label=O_precision_tok: 0.9341047249020956
train_label=O_recall_tok: 0.972536530837093
train_label=O_f-score_tok: 0.9529332965604194
train_label=N_precision_tok: 0.8364389233954451
train_label=N_recall_tok: 0.7396141388536825
train_label=N_f-score_tok: 0.785052316890882
train_label=P_precision_tok: 0.8892550475748433
train_label=P_recall_tok: 0.7658392293240597
train_label=P_f-score_tok: 0.8229457497530175
train_precision_macro_tok: 0.8865995652907946
train_recall_macro_tok: 0.825996633004945
train_f-score_macro_tok: 0.853643787734773
train_precision_micro_tok: 0.9206986782094079
train_recall_micro_tok: 0.9206986782094079
train_f-score_micro_tok: 0.9206986782094079
train_time: 144.2316071987152
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4399    0.1127    0.1794      1624
           N     0.6860    0.8363    0.7537      3310
           P     0.7474    0.8474    0.7942      3610

   micro avg     0.7034    0.7034    0.7034      8544
   macro avg     0.6244    0.5988    0.5758      8544
weighted avg     0.6652    0.7034    0.6617      8544

F1-macro sent:  0.5757859278188776
F1-micro sent:  0.7034176029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9341    0.9725    0.9529    124347
           N     0.8364    0.7396    0.7851     14202
           P     0.8893    0.7658    0.8229     25017

   micro avg     0.9207    0.9207    0.9207    163566
   macro avg     0.8866    0.8260    0.8536    163566
weighted avg     0.9188    0.9207    0.9185    163566

F1-macro tok:  0.853643787734773
F1-micro tok:  0.9206986782094079
**************************************************
dev_cost_sum: 41893.8876953125
dev_cost_avg: 38.05076084951181
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19101.0
dev_accuracy_tok: 0.8978565384976968
dev_label=O_precision_sent: 0.7368421052631579
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11290322580645161
dev_label=N_precision_sent: 0.643598615916955
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7395626242544733
dev_label=P_precision_sent: 0.7142857142857143
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.759493670886076
dev_precision_macro_sent: 0.6982421451552757
dev_recall_macro_sent: 0.5803683534981744
dev_f-score_macro_sent: 0.5373198403156669
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9158790724977987
dev_label=O_recall_tok: 0.9627892625732799
dev_label=O_f-score_tok: 0.938748495788207
dev_label=N_precision_tok: 0.7747216764898494
dev_label=N_recall_tok: 0.6370490037695208
dev_label=N_f-score_tok: 0.6991725768321513
dev_label=P_precision_tok: 0.8539823008849557
dev_label=P_recall_tok: 0.7210460772104608
dev_label=P_f-score_tok: 0.7819041188386227
dev_precision_macro_tok: 0.8481943499575345
dev_recall_macro_tok: 0.7736281145177539
dev_f-score_macro_tok: 0.8066083971529935
dev_precision_micro_tok: 0.8978565384976968
dev_recall_micro_tok: 0.8978565384976968
dev_f-score_micro_tok: 0.8978565384976968
dev_time: 8.319664478302002
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7368    0.0611    0.1129       229
           N     0.6436    0.8692    0.7396       428
           P     0.7143    0.8108    0.7595       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6982    0.5804    0.5373      1101
weighted avg     0.6915    0.6776    0.6173      1101

F1-macro sent:  0.5373198403156669
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9159    0.9628    0.9387     16205
           N     0.7747    0.6370    0.6992      1857
           P     0.8540    0.7210    0.7819      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8482    0.7736    0.8066     21274
weighted avg     0.8942    0.8979    0.8942     21274

F1-macro tok:  0.8066083971529935
F1-micro tok:  0.8978565384976968
**************************************************
Best epoch: 36
**************************************************

EPOCH: 38
Learning rate: 0.590490
train_cost_sum: 288783.9475708008
train_cost_avg: 33.79961933178848
train_count_sent: 8544.0
train_total_correct_sent: 6092.0
train_accuracy_sent: 0.7130149812734082
train_count_tok: 163566.0
train_total_correct_tok: 150788.0
train_accuracy_tok: 0.9218786300331365
train_label=O_precision_sent: 0.46035805626598464
train_label=O_recall_sent: 0.11083743842364532
train_label=O_f-score_sent: 0.17866004962779158
train_label=N_precision_sent: 0.6915933528836755
train_label=N_recall_sent: 0.8549848942598187
train_label=N_f-score_sent: 0.764658200486355
train_label=P_precision_sent: 0.7589263728145776
train_label=P_recall_sent: 0.8537396121883657
train_label=P_f-score_sent: 0.803545821926737
train_precision_macro_sent: 0.636959260654746
train_recall_macro_sent: 0.6065206482906099
train_f-score_macro_sent: 0.5822880240136278
train_precision_micro_sent: 0.7130149812734082
train_recall_micro_sent: 0.7130149812734082
train_f-score_micro_sent: 0.7130149812734083
train_label=O_precision_tok: 0.9353600990175601
train_label=O_recall_tok: 0.9723917746306706
train_label=O_f-score_tok: 0.953516522946017
train_label=N_precision_tok: 0.8391939944685894
train_label=N_recall_tok: 0.7477820025348543
train_label=N_f-score_tok: 0.7908552705067581
train_label=P_precision_tok: 0.8897001062797468
train_label=P_recall_tok: 0.7696366470799856
train_label=P_f-score_tok: 0.8253247031591582
train_precision_macro_tok: 0.8880847332552988
train_recall_macro_tok: 0.8299368080818367
train_f-score_macro_tok: 0.8565654988706445
train_precision_micro_tok: 0.9218786300331365
train_recall_micro_tok: 0.9218786300331365
train_f-score_micro_tok: 0.9218786300331365
train_time: 191.13733315467834
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4604    0.1108    0.1787      1624
           N     0.6916    0.8550    0.7647      3310
           P     0.7589    0.8537    0.8035      3610

   micro avg     0.7130    0.7130    0.7130      8544
   macro avg     0.6370    0.6065    0.5823      8544
weighted avg     0.6761    0.7130    0.6697      8544

F1-macro sent:  0.5822880240136278
F1-micro sent:  0.7130149812734083
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9354    0.9724    0.9535    124347
           N     0.8392    0.7478    0.7909     14202
           P     0.8897    0.7696    0.8253     25017

   micro avg     0.9219    0.9219    0.9219    163566
   macro avg     0.8881    0.8299    0.8566    163566
weighted avg     0.9200    0.9219    0.9198    163566

F1-macro tok:  0.8565654988706445
F1-micro tok:  0.9218786300331365
**************************************************
dev_cost_sum: 41967.682861328125
dev_cost_avg: 38.117786431724
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19121.0
dev_accuracy_tok: 0.8987966531916893
dev_label=O_precision_sent: 0.52
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10236220472440945
dev_label=N_precision_sent: 0.6535008976660682
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.7390862944162436
dev_label=P_precision_sent: 0.7032755298651252
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7580477673935617
dev_precision_macro_sent: 0.6255921425103979
dev_recall_macro_sent: 0.5764359735812211
dev_f-score_macro_sent: 0.5331654221780716
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9166422072204286
dev_label=O_recall_tok: 0.9635914841098426
dev_label=O_f-score_tok: 0.9395306859205775
dev_label=N_precision_tok: 0.7899388171312033
dev_label=N_recall_tok: 0.6257404415724287
dev_label=N_f-score_tok: 0.6983173076923077
dev_label=P_precision_tok: 0.846820809248555
dev_label=P_recall_tok: 0.7297633872976339
dev_label=P_f-score_tok: 0.7839464882943145
dev_precision_macro_tok: 0.8511339445333955
dev_recall_macro_tok: 0.7730317709933017
dev_f-score_macro_tok: 0.8072648273023999
dev_precision_micro_tok: 0.8987966531916893
dev_recall_micro_tok: 0.8987966531916893
dev_f-score_micro_tok: 0.8987966531916893
dev_time: 15.276233911514282
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5200    0.0568    0.1024       229
           N     0.6535    0.8505    0.7391       428
           P     0.7033    0.8221    0.7580       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6256    0.5764    0.5332      1101
weighted avg     0.6458    0.6739    0.6143      1101

F1-macro sent:  0.5331654221780716
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9166    0.9636    0.9395     16205
           N     0.7899    0.6257    0.6983      1857
           P     0.8468    0.7298    0.7839      3212

   micro avg     0.8988    0.8988    0.8988     21274
   macro avg     0.8511    0.7730    0.8073     21274
weighted avg     0.8950    0.8988    0.8950     21274

F1-macro tok:  0.8072648273023999
F1-micro tok:  0.8987966531916893
**************************************************
Best epoch: 36
**************************************************

EPOCH: 39
Learning rate: 0.590490
train_cost_sum: 288039.48693847656
train_cost_avg: 33.712486767143794
train_count_sent: 8544.0
train_total_correct_sent: 6066.0
train_accuracy_sent: 0.7099719101123596
train_count_tok: 163566.0
train_total_correct_tok: 150950.0
train_accuracy_tok: 0.9228690559162662
train_label=O_precision_sent: 0.44390243902439025
train_label=O_recall_sent: 0.11206896551724138
train_label=O_f-score_sent: 0.17895771878072764
train_label=N_precision_sent: 0.6881380651434127
train_label=N_recall_sent: 0.8552870090634441
train_label=N_f-score_sent: 0.7626616379310345
train_label=P_precision_sent: 0.7594527363184079
train_label=P_recall_sent: 0.8457063711911358
train_label=P_f-score_sent: 0.800262123197903
train_precision_macro_sent: 0.630497746828737
train_recall_macro_sent: 0.6043541152572738
train_f-score_macro_sent: 0.5806271599698883
train_precision_micro_sent: 0.7099719101123596
train_recall_micro_sent: 0.7099719101123596
train_f-score_micro_sent: 0.7099719101123596
train_label=O_precision_tok: 0.936628771451583
train_label=O_recall_tok: 0.9726410769861757
train_label=O_f-score_tok: 0.954295295394023
train_label=N_precision_tok: 0.8389763779527559
train_label=N_recall_tok: 0.750246444162794
train_label=N_f-score_tok: 0.7921344137982307
train_label=P_precision_tok: 0.8901462876069556
train_label=P_recall_tok: 0.773474037654395
train_label=P_f-score_tok: 0.8277189605389799
train_precision_macro_tok: 0.8885838123370982
train_recall_macro_tok: 0.8321205196011215
train_f-score_macro_tok: 0.8580495565770779
train_precision_micro_tok: 0.9228690559162662
train_recall_micro_tok: 0.9228690559162662
train_f-score_micro_tok: 0.9228690559162663
train_time: 247.90769219398499
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4439    0.1121    0.1790      1624
           N     0.6881    0.8553    0.7627      3310
           P     0.7595    0.8457    0.8003      3610

   micro avg     0.7100    0.7100    0.7100      8544
   macro avg     0.6305    0.6044    0.5806      8544
weighted avg     0.6718    0.7100    0.6676      8544

F1-macro sent:  0.5806271599698883
F1-micro sent:  0.7099719101123596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9366    0.9726    0.9543    124347
           N     0.8390    0.7502    0.7921     14202
           P     0.8901    0.7735    0.8277     25017

   micro avg     0.9229    0.9229    0.9229    163566
   macro avg     0.8886    0.8321    0.8580    163566
weighted avg     0.9210    0.9229    0.9209    163566

F1-macro tok:  0.8580495565770779
F1-micro tok:  0.9228690559162663
**************************************************
dev_cost_sum: 41981.99774169922
dev_cost_avg: 38.13078813959965
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19116.0
dev_accuracy_tok: 0.8985616245181912
dev_label=O_precision_sent: 0.4722222222222222
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.12830188679245283
dev_label=N_precision_sent: 0.679920477137177
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7346938775510206
dev_label=P_precision_sent: 0.6797153024911032
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7594433399602386
dev_precision_macro_sent: 0.6106193339501674
dev_recall_macro_sent: 0.5778871962604567
dev_f-score_macro_sent: 0.540813034767904
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9174117647058824
dev_label=O_recall_tok: 0.9624190064794816
dev_label=O_f-score_tok: 0.9393765999096522
dev_label=N_precision_tok: 0.7557921102066374
dev_label=N_recall_tok: 0.6499730748519117
dev_label=N_f-score_tok: 0.6988998262883613
dev_label=P_precision_tok: 0.8640268957788569
dev_label=P_recall_tok: 0.7201120797011208
dev_label=P_f-score_tok: 0.7855323484462557
dev_precision_macro_tok: 0.8457435902304589
dev_recall_macro_tok: 0.777501387010838
dev_f-score_macro_tok: 0.8079362582147565
dev_precision_micro_tok: 0.8985616245181912
dev_recall_micro_tok: 0.8985616245181912
dev_f-score_micro_tok: 0.8985616245181912
dev_time: 15.115538358688354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4722    0.0742    0.1283       229
           N     0.6799    0.7991    0.7347       428
           P     0.6797    0.8604    0.7594       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6106    0.5779    0.5408      1101
weighted avg     0.6366    0.6730    0.6185      1101

F1-macro sent:  0.540813034767904
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9174    0.9624    0.9394     16205
           N     0.7558    0.6500    0.6989      1857
           P     0.8640    0.7201    0.7855      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8457    0.7775    0.8079     21274
weighted avg     0.8952    0.8986    0.8952     21274

F1-macro tok:  0.8079362582147565
F1-micro tok:  0.8985616245181912
**************************************************
Best epoch: 36
**************************************************

EPOCH: 40
Learning rate: 0.590490
train_cost_sum: 287191.6774902344
train_cost_avg: 33.61325813322031
train_count_sent: 8544.0
train_total_correct_sent: 6102.0
train_accuracy_sent: 0.714185393258427
train_count_tok: 163566.0
train_total_correct_tok: 151086.0
train_accuracy_tok: 0.9237005245588936
train_label=O_precision_sent: 0.44396551724137934
train_label=O_recall_sent: 0.1268472906403941
train_label=O_f-score_sent: 0.19731800766283525
train_label=N_precision_sent: 0.6972072513473787
train_label=N_recall_sent: 0.8598187311178248
train_label=N_f-score_sent: 0.770021645021645
train_label=P_precision_sent: 0.7628814407203601
train_label=P_recall_sent: 0.8448753462603878
train_label=P_f-score_sent: 0.8017875920084122
train_precision_macro_sent: 0.6346847364363727
train_recall_macro_sent: 0.6105137893395356
train_f-score_macro_sent: 0.5897090815642975
train_precision_micro_sent: 0.714185393258427
train_recall_micro_sent: 0.714185393258427
train_f-score_micro_sent: 0.714185393258427
train_label=O_precision_tok: 0.9377641957976871
train_label=O_recall_tok: 0.9723193965274595
train_label=O_f-score_tok: 0.9547292281937492
train_label=N_precision_tok: 0.8428156635015303
train_label=N_recall_tok: 0.7562315166877904
train_label=N_f-score_tok: 0.7971794395991835
train_label=P_precision_tok: 0.8879601717365488
train_label=P_recall_tok: 0.7771115641363873
train_label=P_f-score_tok: 0.8288461128519964
train_precision_macro_tok: 0.8895133436785887
train_recall_macro_tok: 0.8352208257838791
train_f-score_macro_tok: 0.8602515935483096
train_precision_micro_tok: 0.9237005245588936
train_recall_micro_tok: 0.9237005245588936
train_f-score_micro_tok: 0.9237005245588936
train_time: 248.65936136245728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4440    0.1268    0.1973      1624
           N     0.6972    0.8598    0.7700      3310
           P     0.7629    0.8449    0.8018      3610

   micro avg     0.7142    0.7142    0.7142      8544
   macro avg     0.6347    0.6105    0.5897      8544
weighted avg     0.6768    0.7142    0.6746      8544

F1-macro sent:  0.5897090815642975
F1-micro sent:  0.714185393258427
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9378    0.9723    0.9547    124347
           N     0.8428    0.7562    0.7972     14202
           P     0.8880    0.7771    0.8288     25017

   micro avg     0.9237    0.9237    0.9237    163566
   macro avg     0.8895    0.8352    0.8603    163566
weighted avg     0.9219    0.9237    0.9218    163566

F1-macro tok:  0.8602515935483096
F1-micro tok:  0.9237005245588936
**************************************************
dev_cost_sum: 41850.58721923828
dev_cost_avg: 38.0114325333681
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.425531914893617
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.14492753623188404
dev_label=N_precision_sent: 0.6358974358974359
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.734452122408687
dev_label=P_precision_sent: 0.7313432835820896
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7513691128148959
dev_precision_macro_sent: 0.5975908781243807
dev_recall_macro_sent: 0.57633921518956
dev_f-score_macro_sent: 0.5435829238184889
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9158444914258868
dev_label=O_recall_tok: 0.9623572971305153
dev_label=O_f-score_tok: 0.9385249601299912
dev_label=N_precision_tok: 0.7619663648124192
dev_label=N_recall_tok: 0.6343564889606893
dev_label=N_f-score_tok: 0.6923302967969439
dev_label=P_precision_tok: 0.8551851851851852
dev_label=P_recall_tok: 0.7188667496886675
dev_label=P_f-score_tok: 0.7811231393775373
dev_precision_macro_tok: 0.8443320138078304
dev_recall_macro_tok: 0.7718601785932907
dev_f-score_macro_tok: 0.8039927987681574
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 15.239129543304443
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4255    0.0873    0.1449       229
           N     0.6359    0.8692    0.7345       428
           P     0.7313    0.7725    0.7514       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.5976    0.5763    0.5436      1101
weighted avg     0.6306    0.6676    0.6187      1101

F1-macro sent:  0.5435829238184889
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9158    0.9624    0.9385     16205
           N     0.7620    0.6344    0.6923      1857
           P     0.8552    0.7189    0.7811      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8443    0.7719    0.8040     21274
weighted avg     0.8933    0.8970    0.8933     21274

F1-macro tok:  0.8039927987681574
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 36
**************************************************

EPOCH: 41
Learning rate: 0.531441
train_cost_sum: 286060.44006347656
train_cost_avg: 33.480856749002406
train_count_sent: 8544.0
train_total_correct_sent: 6087.0
train_accuracy_sent: 0.7124297752808989
train_count_tok: 163566.0
train_total_correct_tok: 151428.0
train_accuracy_tok: 0.9257914236455009
train_label=O_precision_sent: 0.4364754098360656
train_label=O_recall_sent: 0.1311576354679803
train_label=O_f-score_sent: 0.20170454545454544
train_label=N_precision_sent: 0.6949194547707559
train_label=N_recall_sent: 0.8471299093655589
train_label=N_f-score_sent: 0.763512593601089
train_label=P_precision_sent: 0.7634916687391197
train_label=P_recall_sent: 0.850415512465374
train_label=P_f-score_sent: 0.8046127637269035
train_precision_macro_sent: 0.6316288444486471
train_recall_macro_sent: 0.6095676857663044
train_f-score_macro_sent: 0.5899433009275127
train_precision_micro_sent: 0.7124297752808989
train_recall_micro_sent: 0.7124297752808989
train_f-score_micro_sent: 0.7124297752808989
train_label=O_precision_tok: 0.9397305821848635
train_label=O_recall_tok: 0.972793875204066
train_label=O_f-score_tok: 0.9559764333047509
train_label=N_precision_tok: 0.8432928727046374
train_label=N_recall_tok: 0.7631319532460217
train_label=N_f-score_tok: 0.8012123900347454
train_label=P_precision_tok: 0.8924154237904692
train_label=P_recall_tok: 0.7845065355558221
train_label=P_f-score_tok: 0.8349890446510242
train_precision_macro_tok: 0.89181295955999
train_recall_macro_tok: 0.8401441213353031
train_f-score_macro_tok: 0.8640592893301736
train_precision_micro_tok: 0.9257914236455009
train_recall_micro_tok: 0.9257914236455009
train_f-score_micro_tok: 0.9257914236455009
train_time: 246.78080654144287
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4365    0.1312    0.2017      1624
           N     0.6949    0.8471    0.7635      3310
           P     0.7635    0.8504    0.8046      3610

   micro avg     0.7124    0.7124    0.7124      8544
   macro avg     0.6316    0.6096    0.5899      8544
weighted avg     0.6748    0.7124    0.6741      8544

F1-macro sent:  0.5899433009275127
F1-micro sent:  0.7124297752808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9397    0.9728    0.9560    124347
           N     0.8433    0.7631    0.8012     14202
           P     0.8924    0.7845    0.8350     25017

   micro avg     0.9258    0.9258    0.9258    163566
   macro avg     0.8918    0.8401    0.8641    163566
weighted avg     0.9241    0.9258    0.9240    163566

F1-macro tok:  0.8640592893301736
F1-micro tok:  0.9257914236455009
**************************************************
dev_cost_sum: 42062.625427246094
dev_cost_avg: 38.204019461622245
dev_count_sent: 1101.0
dev_total_correct_sent: 749.0
dev_accuracy_sent: 0.6802906448683016
dev_count_tok: 21274.0
dev_total_correct_tok: 19083.0
dev_accuracy_tok: 0.8970104352731033
dev_label=O_precision_sent: 0.4603174603174603
dev_label=O_recall_sent: 0.12663755458515283
dev_label=O_f-score_sent: 0.19863013698630136
dev_label=N_precision_sent: 0.6575591985428051
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7389969293756397
dev_label=P_precision_sent: 0.7341513292433538
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7695605573419078
dev_precision_macro_sent: 0.6173426627012063
dev_recall_macro_sent: 0.5928846856896484
dev_f-score_macro_sent: 0.5690625412346163
dev_precision_micro_sent: 0.6802906448683016
dev_recall_micro_sent: 0.6802906448683016
dev_f-score_micro_sent: 0.6802906448683016
dev_label=O_precision_tok: 0.9194694457603032
dev_label=O_recall_tok: 0.9582227707497686
dev_label=O_f-score_tok: 0.9384461970809537
dev_label=N_precision_tok: 0.7733507511430437
dev_label=N_recall_tok: 0.6375875067312871
dev_label=N_f-score_tok: 0.6989374262101535
dev_label=P_precision_tok: 0.8304728546409808
dev_label=P_recall_tok: 0.7381693648816936
dev_label=P_f-score_tok: 0.7816054062963573
dev_precision_macro_tok: 0.8410976838481092
dev_recall_macro_tok: 0.7779932141209164
dev_f-score_macro_tok: 0.8063296765291549
dev_precision_micro_tok: 0.8970104352731033
dev_recall_micro_tok: 0.8970104352731033
dev_f-score_micro_tok: 0.8970104352731033
dev_time: 15.27316665649414
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4603    0.1266    0.1986       229
           N     0.6576    0.8435    0.7390       428
           P     0.7342    0.8086    0.7696       444

   micro avg     0.6803    0.6803    0.6803      1101
   macro avg     0.6173    0.5929    0.5691      1101
weighted avg     0.6474    0.6803    0.6389      1101

F1-macro sent:  0.5690625412346163
F1-micro sent:  0.6802906448683016
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9195    0.9582    0.9384     16205
           N     0.7734    0.6376    0.6989      1857
           P     0.8305    0.7382    0.7816      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8411    0.7780    0.8063     21274
weighted avg     0.8933    0.8970    0.8939     21274

F1-macro tok:  0.8063296765291549
F1-micro tok:  0.8970104352731033
**************************************************
Best epoch: 36
**************************************************

EPOCH: 42
Learning rate: 0.478297
train_cost_sum: 285240.36083984375
train_cost_avg: 33.384873693801936
train_count_sent: 8544.0
train_total_correct_sent: 6148.0
train_accuracy_sent: 0.7195692883895131
train_count_tok: 163566.0
train_total_correct_tok: 151577.0
train_accuracy_tok: 0.9267023709083795
train_label=O_precision_sent: 0.5043103448275862
train_label=O_recall_sent: 0.1440886699507389
train_label=O_f-score_sent: 0.22413793103448276
train_label=N_precision_sent: 0.693229039354681
train_label=N_recall_sent: 0.856797583081571
train_label=N_f-score_sent: 0.7663829212268612
train_label=P_precision_sent: 0.7716219603910754
train_label=P_recall_sent: 0.8526315789473684
train_label=P_f-score_sent: 0.8101065929727596
train_precision_macro_sent: 0.6563871148577809
train_recall_macro_sent: 0.6178392773265594
train_f-score_macro_sent: 0.6002091484113679
train_precision_micro_sent: 0.7195692883895131
train_recall_micro_sent: 0.7195692883895131
train_f-score_micro_sent: 0.719569288389513
train_label=O_precision_tok: 0.9403591660385275
train_label=O_recall_tok: 0.9731798917545257
train_label=O_f-score_tok: 0.9564880608930025
train_label=N_precision_tok: 0.849711433473717
train_label=N_recall_tok: 0.7671454724686664
train_label=N_f-score_tok: 0.8063203078744818
train_label=P_precision_tok: 0.8917803871786735
train_label=P_recall_tok: 0.7862653395690931
train_label=P_f-score_tok: 0.8357054849810938
train_precision_macro_tok: 0.8939503288969727
train_recall_macro_tok: 0.842196901264095
train_f-score_macro_tok: 0.8661712845828594
train_precision_micro_tok: 0.9267023709083795
train_recall_micro_tok: 0.9267023709083795
train_f-score_micro_tok: 0.9267023709083795
train_time: 248.55151891708374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5043    0.1441    0.2241      1624
           N     0.6932    0.8568    0.7664      3310
           P     0.7716    0.8526    0.8101      3610

   micro avg     0.7196    0.7196    0.7196      8544
   macro avg     0.6564    0.6178    0.6002      8544
weighted avg     0.6904    0.7196    0.6818      8544

F1-macro sent:  0.6002091484113679
F1-micro sent:  0.719569288389513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9404    0.9732    0.9565    124347
           N     0.8497    0.7671    0.8063     14202
           P     0.8918    0.7863    0.8357     25017

   micro avg     0.9267    0.9267    0.9267    163566
   macro avg     0.8940    0.8422    0.8662    163566
weighted avg     0.9251    0.9267    0.9250    163566

F1-macro tok:  0.8661712845828594
F1-micro tok:  0.9267023709083795
**************************************************
dev_cost_sum: 42199.277404785156
dev_cost_avg: 38.32813569916908
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19117.0
dev_accuracy_tok: 0.8986086302528908
dev_label=O_precision_sent: 0.3670886075949367
dev_label=O_recall_sent: 0.12663755458515283
dev_label=O_f-score_sent: 0.1883116883116883
dev_label=N_precision_sent: 0.6969072164948453
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7404162102957283
dev_label=P_precision_sent: 0.6983240223463687
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.764525993883792
dev_precision_macro_sent: 0.5874399488120502
dev_recall_macro_sent: 0.5869839251159906
dev_f-score_macro_sent: 0.5644179641637362
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9160265056001876
dev_label=O_recall_tok: 0.9639617402036409
dev_label=O_f-score_tok: 0.9393830055926394
dev_label=N_precision_tok: 0.805574912891986
dev_label=N_recall_tok: 0.6225094238018309
dev_label=N_f-score_tok: 0.7023086269744836
dev_label=P_precision_tok: 0.8399138549892319
dev_label=P_recall_tok: 0.7285180572851806
dev_label=P_f-score_tok: 0.7802600866955652
dev_precision_macro_tok: 0.8538384244938019
dev_recall_macro_tok: 0.7716630737635507
dev_f-score_macro_tok: 0.8073172397542293
dev_precision_micro_tok: 0.8986086302528908
dev_recall_micro_tok: 0.8986086302528908
dev_f-score_micro_tok: 0.8986086302528908
dev_time: 15.296561241149902
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3671    0.1266    0.1883       229
           N     0.6969    0.7897    0.7404       428
           P     0.6983    0.8446    0.7645       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.5874    0.5870    0.5644      1101
weighted avg     0.6289    0.6739    0.6353      1101

F1-macro sent:  0.5644179641637362
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9160    0.9640    0.9394     16205
           N     0.8056    0.6225    0.7023      1857
           P     0.8399    0.7285    0.7803      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8538    0.7717    0.8073     21274
weighted avg     0.8949    0.8986    0.8947     21274

F1-macro tok:  0.8073172397542293
F1-micro tok:  0.8986086302528908
**************************************************
Best epoch: 36
**************************************************

EPOCH: 43
Learning rate: 0.430467
train_cost_sum: 284407.78802490234
train_cost_avg: 33.28742837370112
train_count_sent: 8544.0
train_total_correct_sent: 6187.0
train_accuracy_sent: 0.7241338951310862
train_count_tok: 163566.0
train_total_correct_tok: 151832.0
train_accuracy_tok: 0.9282613746133059
train_label=O_precision_sent: 0.4686411149825784
train_label=O_recall_sent: 0.16564039408866996
train_label=O_f-score_sent: 0.24476797088262056
train_label=N_precision_sent: 0.7054879562950087
train_label=N_recall_sent: 0.8583081570996979
train_label=N_f-score_sent: 0.7744309663350144
train_label=P_precision_sent: 0.7803702764392595
train_label=P_recall_sent: 0.8523545706371192
train_label=P_f-score_sent: 0.8147755858599233
train_precision_macro_sent: 0.6514997825722822
train_recall_macro_sent: 0.625434373941829
train_f-score_macro_sent: 0.6113248410258527
train_precision_micro_sent: 0.7241338951310862
train_recall_micro_sent: 0.7241338951310862
train_f-score_micro_sent: 0.7241338951310863
train_label=O_precision_tok: 0.9418779218556749
train_label=O_recall_tok: 0.9737669585916829
train_label=O_f-score_tok: 0.9575570176825989
train_label=N_precision_tok: 0.8482330097087378
train_label=N_recall_tok: 0.7689762005351359
train_label=N_f-score_tok: 0.8066624810724969
train_label=P_precision_tok: 0.8957260323484233
train_label=P_recall_tok: 0.7925010992525083
train_label=P_f-score_tok: 0.8409577739602554
train_precision_macro_tok: 0.8952789879709453
train_recall_macro_tok: 0.8450814194597758
train_f-score_macro_tok: 0.8683924242384503
train_precision_micro_tok: 0.9282613746133059
train_recall_micro_tok: 0.9282613746133059
train_f-score_micro_tok: 0.9282613746133059
train_time: 249.56513023376465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4686    0.1656    0.2448      1624
           N     0.7055    0.8583    0.7744      3310
           P     0.7804    0.8524    0.8148      3610

   micro avg     0.7241    0.7241    0.7241      8544
   macro avg     0.6515    0.6254    0.6113      8544
weighted avg     0.6921    0.7241    0.6908      8544

F1-macro sent:  0.6113248410258527
F1-micro sent:  0.7241338951310863
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9419    0.9738    0.9576    124347
           N     0.8482    0.7690    0.8067     14202
           P     0.8957    0.7925    0.8410     25017

   micro avg     0.9283    0.9283    0.9283    163566
   macro avg     0.8953    0.8451    0.8684    163566
weighted avg     0.9267    0.9283    0.9266    163566

F1-macro tok:  0.8683924242384503
F1-micro tok:  0.9282613746133059
**************************************************
dev_cost_sum: 42148.76013183594
dev_cost_avg: 38.282252617471336
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19131.0
dev_accuracy_tok: 0.8992667105386857
dev_label=O_precision_sent: 0.45454545454545453
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1465201465201465
dev_label=N_precision_sent: 0.6730769230769231
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7383966244725739
dev_label=P_precision_sent: 0.6927374301675978
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7584097859327217
dev_precision_macro_sent: 0.6067866025966585
dev_recall_macro_sent: 0.5809770305750389
dev_f-score_macro_sent: 0.5477755189751473
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.91636854143452
dev_label=O_recall_tok: 0.9642085775995063
dev_label=O_f-score_tok: 0.9396800577339427
dev_label=N_precision_tok: 0.7904953145917001
dev_label=N_recall_tok: 0.6359719978459881
dev_label=N_f-score_tok: 0.7048642196359295
dev_label=P_precision_tok: 0.8519604250641261
dev_label=P_recall_tok: 0.7238480697384807
dev_label=P_f-score_tok: 0.7826965157380913
dev_precision_macro_tok: 0.8529414270301153
dev_recall_macro_tok: 0.774676215061325
dev_f-score_macro_tok: 0.8090802643693212
dev_precision_micro_tok: 0.8992667105386857
dev_recall_micro_tok: 0.8992667105386857
dev_f-score_micro_tok: 0.8992667105386858
dev_time: 15.312947273254395
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.0873    0.1465       229
           N     0.6731    0.8178    0.7384       428
           P     0.6927    0.8378    0.7584       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6068    0.5810    0.5478      1101
weighted avg     0.6356    0.6739    0.6234      1101

F1-macro sent:  0.5477755189751473
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9164    0.9642    0.9397     16205
           N     0.7905    0.6360    0.7049      1857
           P     0.8520    0.7238    0.7827      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8529    0.7747    0.8091     21274
weighted avg     0.8957    0.8993    0.8955     21274

F1-macro tok:  0.8090802643693212
F1-micro tok:  0.8992667105386858
**************************************************
Best epoch: 36
**************************************************

test0_cost_sum: 42044.89697265625
test0_cost_avg: 38.1879173230302
test0_count_sent: 1101.0
test0_total_correct_sent: 753.0
test0_accuracy_sent: 0.6839237057220708
test0_count_tok: 21274.0
test0_total_correct_tok: 19163.0
test0_accuracy_tok: 0.900770894049074
test0_label=O_precision_sent: 0.625
test0_label=O_recall_sent: 0.06550218340611354
test0_label=O_f-score_sent: 0.11857707509881421
test0_label=N_precision_sent: 0.691089108910891
test0_label=N_recall_sent: 0.8154205607476636
test0_label=N_f-score_sent: 0.7481243301178992
test0_label=P_precision_sent: 0.6800699300699301
test0_label=P_recall_sent: 0.8761261261261262
test0_label=P_f-score_sent: 0.7657480314960631
test0_precision_macro_sent: 0.6653863463269404
test0_recall_macro_sent: 0.5856829567599678
test0_f-score_macro_sent: 0.5441498122375922
test0_precision_micro_sent: 0.6839237057220708
test0_recall_micro_sent: 0.6839237057220708
test0_f-score_micro_sent: 0.6839237057220708
test0_label=O_precision_tok: 0.9102608494921515
test0_label=O_recall_tok: 0.9733415612465288
test0_label=O_f-score_tok: 0.9407449378224437
test0_label=N_precision_tok: 0.8064743138634765
test0_label=N_recall_tok: 0.617124394184168
test0_label=N_f-score_tok: 0.6992068334350213
test0_label=P_precision_tok: 0.8887128712871287
test0_label=P_recall_tok: 0.6986301369863014
test0_label=P_f-score_tok: 0.7822903956771833
test0_precision_macro_tok: 0.8684826782142522
test0_recall_macro_tok: 0.7630320308056661
test0_f-score_macro_tok: 0.8074140556448827
test0_precision_micro_tok: 0.900770894049074
test0_recall_micro_tok: 0.900770894049074
test0_f-score_micro_tok: 0.900770894049074
test0_time: 14.555197477340698
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0655    0.1186       229
           N     0.6911    0.8154    0.7481       428
           P     0.6801    0.8761    0.7657       444

   micro avg     0.6839    0.6839    0.6839      1101
   macro avg     0.6654    0.5857    0.5441      1101
weighted avg     0.6729    0.6839    0.6243      1101

F1-macro sent:  0.5441498122375922
F1-micro sent:  0.6839237057220708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9103    0.9733    0.9407     16205
           N     0.8065    0.6171    0.6992      1857
           P     0.8887    0.6986    0.7823      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8685    0.7630    0.8074     21274
weighted avg     0.8979    0.9008    0.8957     21274

F1-macro tok:  0.8074140556448827
F1-micro tok:  0.900770894049074
**************************************************
test1_cost_sum: 81234.73998832703
test1_cost_avg: 36.75780089969549
test1_count_sent: 2210.0
test1_total_correct_sent: 1534.0
test1_accuracy_sent: 0.6941176470588235
test1_count_tok: 42405.0
test1_total_correct_tok: 37982.0
test1_accuracy_tok: 0.8956962622332272
test1_label=O_precision_sent: 0.35555555555555557
test1_label=O_recall_sent: 0.04113110539845758
test1_label=O_f-score_sent: 0.0737327188940092
test1_label=N_precision_sent: 0.7141434262948207
test1_label=N_recall_sent: 0.7861842105263158
test1_label=N_f-score_sent: 0.7484342379958246
test1_label=P_precision_sent: 0.689922480620155
test1_label=P_recall_sent: 0.8811881188118812
test1_label=P_f-score_sent: 0.7739130434782608
test1_precision_macro_sent: 0.5865404874901771
test1_recall_macro_sent: 0.5695011449122181
test1_f-score_macro_sent: 0.5320266667893648
test1_precision_micro_sent: 0.6941176470588235
test1_recall_micro_sent: 0.6941176470588235
test1_f-score_micro_sent: 0.6941176470588235
test1_label=O_precision_tok: 0.9029578606158833
test1_label=O_recall_tok: 0.9750296893555848
test1_label=O_f-score_tok: 0.9376108189331331
test1_label=N_precision_tok: 0.8091629348949363
test1_label=N_recall_tok: 0.6247340425531915
test1_label=N_f-score_tok: 0.705087798289059
test1_label=P_precision_tok: 0.8957575757575758
test1_label=P_recall_tok: 0.667067850157966
test1_label=P_f-score_tok: 0.7646805208243511
test1_precision_macro_tok: 0.8692927904227984
test1_recall_macro_tok: 0.7556105273555808
test1_f-score_macro_tok: 0.8024597126821811
test1_precision_micro_tok: 0.8956962622332272
test1_recall_micro_tok: 0.8956962622332272
test1_f-score_micro_tok: 0.8956962622332272
test1_time: 27.749343395233154
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3556    0.0411    0.0737       389
           N     0.7141    0.7862    0.7484       912
           P     0.6899    0.8812    0.7739       909

   micro avg     0.6941    0.6941    0.6941      2210
   macro avg     0.5865    0.5695    0.5320      2210
weighted avg     0.6411    0.6941    0.6402      2210

F1-macro sent:  0.5320266667893648
F1-micro sent:  0.6941176470588235
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9030    0.9750    0.9376     31998
           N     0.8092    0.6247    0.7051      3760
           P     0.8958    0.6671    0.7647      6647

   micro avg     0.8957    0.8957    0.8957     42405
   macro avg     0.8693    0.7556    0.8025     42405
weighted avg     0.8935    0.8957    0.8899     42405

F1-macro tok:  0.8024597126821811
F1-micro tok:  0.8956962622332272
**************************************************
