debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'P': 2, 'O': 0}
{'N': 1, 'P': 2, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 20:00:41.607900: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 20:00:41.753049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-14 20:00:41.753094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 20:00:42.040250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 20:00:42.040309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 20:00:42.040324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 20:00:42.040579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428191.14587402344
train_cost_avg: 50.11600490098589
train_count_sent: 8544.0
train_total_correct_sent: 4288.0
train_accuracy_sent: 0.50187265917603
train_count_tok: 163566.0
train_total_correct_tok: 126007.0
train_accuracy_tok: 0.7703740386143819
train_label=O_precision_sent: 0.26855123674911663
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.07970634504457262
train_label=N_precision_sent: 0.49046529366895497
train_label=N_recall_sent: 0.5827794561933535
train_label=N_f-score_sent: 0.5326522159326246
train_label=P_precision_sent: 0.5274953789279113
train_label=P_recall_sent: 0.632409972299169
train_label=P_f-score_sent: 0.5752078609221467
train_precision_macro_sent: 0.42883730311532764
train_recall_macro_sent: 0.42066248601639095
train_f-score_macro_sent: 0.39585547396644793
train_precision_micro_sent: 0.50187265917603
train_recall_micro_sent: 0.50187265917603
train_f-score_micro_sent: 0.50187265917603
train_label=O_precision_tok: 0.7969642796910311
train_label=O_recall_tok: 0.950067150795757
train_label=O_f-score_tok: 0.8668070525566617
train_label=N_precision_tok: 0.4950294860994103
train_label=N_recall_tok: 0.20687227151105478
train_label=N_f-score_tok: 0.2918011620400258
train_label=P_precision_tok: 0.5247977862920392
train_label=P_recall_tok: 0.19710596794179958
train_label=P_f-score_tok: 0.2865777467817395
train_precision_macro_tok: 0.6055971840274935
train_recall_macro_tok: 0.45134846341620377
train_f-score_macro_tok: 0.481728653792809
train_precision_micro_tok: 0.7703740386143819
train_recall_micro_tok: 0.7703740386143819
train_f-score_micro_tok: 0.7703740386143818
train_time: 53.02421307563782
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2686    0.0468    0.0797      1624
           N     0.4905    0.5828    0.5327      3310
           P     0.5275    0.6324    0.5752      3610

   micro avg     0.5019    0.5019    0.5019      8544
   macro avg     0.4288    0.4207    0.3959      8544
weighted avg     0.4639    0.5019    0.4645      8544

F1-macro sent:  0.39585547396644793
F1-micro sent:  0.50187265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7970    0.9501    0.8668    124347
           N     0.4950    0.2069    0.2918     14202
           P     0.5248    0.1971    0.2866     25017

   micro avg     0.7704    0.7704    0.7704    163566
   macro avg     0.6056    0.4513    0.4817    163566
weighted avg     0.7291    0.7704    0.7281    163566

F1-macro tok:  0.481728653792809
F1-micro tok:  0.7703740386143818
**************************************************
dev_cost_sum: 50260.38037109375
dev_cost_avg: 45.649755105443916
dev_count_sent: 1101.0
dev_total_correct_sent: 635.0
dev_accuracy_sent: 0.5767484105358764
dev_count_tok: 21274.0
dev_total_correct_tok: 17488.0
dev_accuracy_tok: 0.8220362884271881
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6527777777777778
dev_label=N_recall_sent: 0.5490654205607477
dev_label=N_f-score_sent: 0.5964467005076143
dev_label=P_precision_sent: 0.5398110661268556
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.6751054852320676
dev_precision_macro_sent: 0.39752961463487785
dev_recall_macro_sent: 0.4833221071538829
dev_f-score_macro_sent: 0.423850728579894
dev_precision_micro_sent: 0.5767484105358764
dev_recall_micro_sent: 0.5767484105358764
dev_f-score_micro_sent: 0.5767484105358764
dev_label=O_precision_tok: 0.8339382940108893
dev_label=O_recall_tok: 0.9640851589015735
dev_label=O_f-score_tok: 0.8943014968945876
dev_label=N_precision_tok: 0.6916742909423604
dev_label=N_recall_tok: 0.407108239095315
dev_label=N_f-score_tok: 0.512542372881356
dev_label=P_precision_tok: 0.7664132688320664
dev_label=P_recall_tok: 0.34526774595267745
dev_label=P_f-score_tok: 0.4760678257136725
dev_precision_macro_tok: 0.7640086179284387
dev_recall_macro_tok: 0.5721537146498553
dev_f-score_macro_tok: 0.6276372318298721
dev_precision_micro_tok: 0.8220362884271881
dev_recall_micro_tok: 0.8220362884271881
dev_f-score_micro_tok: 0.8220362884271881
dev_time: 2.8974592685699463
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6528    0.5491    0.5964       428
           P     0.5398    0.9009    0.6751       444

   micro avg     0.5767    0.5767    0.5767      1101
   macro avg     0.3975    0.4833    0.4239      1101
weighted avg     0.4714    0.5767    0.5041      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.423850728579894
F1-micro sent:  0.5767484105358764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8339    0.9641    0.8943     16205
           N     0.6917    0.4071    0.5125      1857
           P     0.7664    0.3453    0.4761      3212

   micro avg     0.8220    0.8220    0.8220     21274
   macro avg     0.7640    0.5722    0.6276     21274
weighted avg     0.8113    0.8220    0.7978     21274

F1-macro tok:  0.6276372318298721
F1-micro tok:  0.8220362884271881
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378403.93115234375
train_cost_avg: 44.28884961989042
train_count_sent: 8544.0
train_total_correct_sent: 4806.0
train_accuracy_sent: 0.5625
train_count_tok: 163566.0
train_total_correct_tok: 132311.0
train_accuracy_tok: 0.8089150556961716
train_label=O_precision_sent: 0.1951219512195122
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.00960960960960961
train_label=N_precision_sent: 0.5331164303973972
train_label=N_recall_sent: 0.6930513595166163
train_label=N_f-score_sent: 0.6026533561014056
train_label=P_precision_sent: 0.5961904761904762
train_label=P_recall_sent: 0.6936288088642659
train_label=P_f-score_sent: 0.6412291933418693
train_precision_macro_sent: 0.4414762859357952
train_recall_macro_sent: 0.4638687589184222
train_f-score_macro_sent: 0.4178307196842949
train_precision_micro_sent: 0.5625
train_recall_micro_sent: 0.5625
train_f-score_micro_sent: 0.5625
train_label=O_precision_tok: 0.8321790653599836
train_label=O_recall_tok: 0.949898268554931
train_label=O_f-score_tok: 0.8871505610551141
train_label=N_precision_tok: 0.6411819887429644
train_label=N_recall_tok: 0.38501619490212646
train_label=N_f-score_tok: 0.4811262648482182
train_label=P_precision_tok: 0.6660560262575376
train_label=P_recall_tok: 0.3488028140864212
train_label=P_f-score_tok: 0.4578414397397555
train_precision_macro_tok: 0.7131390267868286
train_recall_macro_tok: 0.5612390925144929
train_f-score_macro_tok: 0.6087060885476959
train_precision_micro_tok: 0.8089150556961716
train_recall_micro_tok: 0.8089150556961716
train_f-score_micro_tok: 0.8089150556961716
train_time: 51.5245258808136
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1951    0.0049    0.0096      1624
           N     0.5331    0.6931    0.6027      3310
           P     0.5962    0.6936    0.6412      3610

   micro avg     0.5625    0.5625    0.5625      8544
   macro avg     0.4415    0.4639    0.4178      8544
weighted avg     0.4955    0.5625    0.5062      8544

F1-macro sent:  0.4178307196842949
F1-micro sent:  0.5625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8322    0.9499    0.8872    124347
           N     0.6412    0.3850    0.4811     14202
           P     0.6661    0.3488    0.4578     25017

   micro avg     0.8089    0.8089    0.8089    163566
   macro avg     0.7131    0.5612    0.6087    163566
weighted avg     0.7902    0.8089    0.7862    163566

F1-macro tok:  0.6087060885476959
F1-micro tok:  0.8089150556961716
**************************************************
dev_cost_sum: 49002.42041015625
dev_cost_avg: 44.50719383302112
dev_count_sent: 1101.0
dev_total_correct_sent: 672.0
dev_accuracy_sent: 0.6103542234332425
dev_count_tok: 21274.0
dev_total_correct_tok: 17770.0
dev_accuracy_tok: 0.8352919056124847
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.538787023977433
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.671943711521548
dev_label=P_precision_sent: 0.7397959183673469
dev_label=P_recall_sent: 0.6531531531531531
dev_label=P_f-score_sent: 0.6937799043062202
dev_precision_macro_sent: 0.4261943141149267
dev_recall_macro_sent: 0.5152255058797115
dev_f-score_macro_sent: 0.4552412052759227
dev_precision_micro_sent: 0.6103542234332425
dev_recall_micro_sent: 0.6103542234332425
dev_f-score_micro_sent: 0.6103542234332425
dev_label=O_precision_tok: 0.8421616410476139
dev_label=O_recall_tok: 0.9703178031471767
dev_label=O_f-score_tok: 0.901708911572428
dev_label=N_precision_tok: 0.7204486626402071
dev_label=N_recall_tok: 0.44964997307485194
dev_label=N_f-score_tok: 0.5537135278514589
dev_label=P_precision_tok: 0.8386426592797784
dev_label=P_recall_tok: 0.3770236612702366
dev_label=P_f-score_tok: 0.520189003436426
dev_precision_macro_tok: 0.8004176543225331
dev_recall_macro_tok: 0.5989971458307551
dev_f-score_macro_tok: 0.6585371476201044
dev_precision_micro_tok: 0.8352919056124847
dev_recall_micro_tok: 0.8352919056124847
dev_f-score_micro_tok: 0.8352919056124847
dev_time: 2.4952476024627686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5388    0.8925    0.6719       428
           P     0.7398    0.6532    0.6938       444

   micro avg     0.6104    0.6104    0.6104      1101
   macro avg     0.4262    0.5152    0.4552      1101
weighted avg     0.5078    0.6104    0.5410      1101

F1-macro sent:  0.4552412052759227
F1-micro sent:  0.6103542234332425
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8422    0.9703    0.9017     16205
           N     0.7204    0.4496    0.5537      1857
           P     0.8386    0.3770    0.5202      3212

   micro avg     0.8353    0.8353    0.8353     21274
   macro avg     0.8004    0.5990    0.6585     21274
weighted avg     0.8310    0.8353    0.8137     21274

F1-macro tok:  0.6585371476201044
F1-micro tok:  0.8352919056124847
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368223.349609375
train_cost_avg: 43.09730215465532
train_count_sent: 8544.0
train_total_correct_sent: 4995.0
train_accuracy_sent: 0.5846207865168539
train_count_tok: 163566.0
train_total_correct_tok: 135502.0
train_accuracy_tok: 0.8284240000978198
train_label=O_precision_sent: 0.23076923076923078
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010823812387251955
train_label=N_precision_sent: 0.5532509904451177
train_label=N_recall_sent: 0.7172205438066466
train_label=N_f-score_sent: 0.6246546507038548
train_label=P_precision_sent: 0.6198386331276696
train_label=P_recall_sent: 0.7235457063711911
train_label=P_f-score_sent: 0.6676891615541922
train_precision_macro_sent: 0.46795295144733934
train_recall_macro_sent: 0.48210270736634
train_f-score_macro_sent: 0.4343892082150997
train_precision_micro_sent: 0.5846207865168539
train_recall_micro_sent: 0.5846207865168539
train_f-score_micro_sent: 0.5846207865168539
train_label=O_precision_tok: 0.8493375584296406
train_label=O_recall_tok: 0.9527290565916346
train_label=O_f-score_tok: 0.8980673234002069
train_label=N_precision_tok: 0.6753147235905856
train_label=N_recall_tok: 0.43437544007886214
train_label=N_f-score_tok: 0.5286883489737326
train_label=P_precision_tok: 0.7268348163511072
train_label=P_recall_tok: 0.4342647000039973
train_label=P_f-score_tok: 0.5436893203883496
train_precision_macro_tok: 0.7504956994571113
train_recall_macro_tok: 0.6071230655581648
train_f-score_macro_tok: 0.6568149975874298
train_precision_micro_tok: 0.8284240000978198
train_recall_micro_tok: 0.8284240000978198
train_f-score_micro_tok: 0.8284240000978198
train_time: 91.25653386116028
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2308    0.0055    0.0108      1624
           N     0.5533    0.7172    0.6247      3310
           P     0.6198    0.7235    0.6677      3610

   micro avg     0.5846    0.5846    0.5846      8544
   macro avg     0.4680    0.4821    0.4344      8544
weighted avg     0.5201    0.5846    0.5262      8544

F1-macro sent:  0.4343892082150997
F1-micro sent:  0.5846207865168539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8493    0.9527    0.8981    124347
           N     0.6753    0.4344    0.5287     14202
           P     0.7268    0.4343    0.5437     25017

   micro avg     0.8284    0.8284    0.8284    163566
   macro avg     0.7505    0.6071    0.6568    163566
weighted avg     0.8155    0.8284    0.8118    163566

F1-macro tok:  0.6568149975874298
F1-micro tok:  0.8284240000978198
**************************************************
dev_cost_sum: 48031.750915527344
dev_cost_avg: 43.62556849730004
dev_count_sent: 1101.0
dev_total_correct_sent: 670.0
dev_accuracy_sent: 0.6085376930063578
dev_count_tok: 21274.0
dev_total_correct_tok: 18243.0
dev_accuracy_tok: 0.8575256181254113
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6373626373626373
dev_label=N_recall_sent: 0.677570093457944
dev_label=N_f-score_sent: 0.6568516421291054
dev_label=P_precision_sent: 0.5882352941176471
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.6972477064220184
dev_precision_macro_sent: 0.4085326438267615
dev_recall_macro_sent: 0.5111419831045999
dev_f-score_macro_sent: 0.45136644951704125
dev_precision_micro_sent: 0.6085376930063578
dev_recall_micro_sent: 0.6085376930063578
dev_f-score_micro_sent: 0.6085376930063578
dev_label=O_precision_tok: 0.8673791461321225
dev_label=O_recall_tok: 0.9666152422091947
dev_label=O_f-score_tok: 0.9143123978519729
dev_label=N_precision_tok: 0.7604846225535881
dev_label=N_recall_tok: 0.4394184168012924
dev_label=N_f-score_tok: 0.5569965870307167
dev_label=P_precision_tok: 0.823062558356676
dev_label=P_recall_tok: 0.548879202988792
dev_label=P_f-score_tok: 0.6585730295106462
dev_precision_macro_tok: 0.8169754423474623
dev_recall_macro_tok: 0.6516376206664264
dev_f-score_macro_tok: 0.7099606714644452
dev_precision_micro_tok: 0.8575256181254113
dev_recall_micro_tok: 0.8575256181254113
dev_f-score_micro_tok: 0.8575256181254113
dev_time: 5.167163133621216
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6374    0.6776    0.6569       428
           P     0.5882    0.8559    0.6972       444

   micro avg     0.6085    0.6085    0.6085      1101
   macro avg     0.4085    0.5111    0.4514      1101
weighted avg     0.4850    0.6085    0.5365      1101

F1-macro sent:  0.45136644951704125
F1-micro sent:  0.6085376930063578
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8674    0.9666    0.9143     16205
           N     0.7605    0.4394    0.5570      1857
           P     0.8231    0.5489    0.6586      3212

   micro avg     0.8575    0.8575    0.8575     21274
   macro avg     0.8170    0.6516    0.7100     21274
weighted avg     0.8514    0.8575    0.8445     21274

F1-macro tok:  0.7099606714644452
F1-micro tok:  0.8575256181254113
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 360986.8845214844
train_cost_avg: 42.250337607851634
train_count_sent: 8544.0
train_total_correct_sent: 5153.0
train_accuracy_sent: 0.6031132958801498
train_count_tok: 163566.0
train_total_correct_tok: 137822.0
train_accuracy_tok: 0.8426078769426409
train_label=O_precision_sent: 0.3230769230769231
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.02486678507992895
train_label=N_precision_sent: 0.570774163994503
train_label=N_recall_sent: 0.7528700906344411
train_label=N_f-score_sent: 0.6492965085982283
train_label=P_precision_sent: 0.6418672501823487
train_label=P_recall_sent: 0.7313019390581718
train_label=P_f-score_sent: 0.6836721481289655
train_precision_macro_sent: 0.5119061124179249
train_recall_macro_sent: 0.49903435472512386
train_f-score_macro_sent: 0.45261181393570754
train_precision_micro_sent: 0.6031132958801498
train_recall_micro_sent: 0.6031132958801498
train_f-score_micro_sent: 0.6031132958801498
train_label=O_precision_tok: 0.8611978016408043
train_label=O_recall_tok: 0.9564685919242121
train_label=O_f-score_tok: 0.9063364450371498
train_label=N_precision_tok: 0.692242023263259
train_label=N_recall_tok: 0.45676665258414306
train_label=N_f-score_tok: 0.5503754295168202
train_label=P_precision_tok: 0.7706313696246582
train_label=P_recall_tok: 0.4957029220130311
train_label=P_f-score_tok: 0.603322873336739
train_precision_macro_tok: 0.7746903981762405
train_recall_macro_tok: 0.6363127221737954
train_f-score_macro_tok: 0.6866782492969029
train_precision_micro_tok: 0.8426078769426409
train_recall_micro_tok: 0.8426078769426409
train_f-score_micro_tok: 0.8426078769426409
train_time: 95.70866823196411
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3231    0.0129    0.0249      1624
           N     0.5708    0.7529    0.6493      3310
           P     0.6419    0.7313    0.6837      3610

   micro avg     0.6031    0.6031    0.6031      8544
   macro avg     0.5119    0.4990    0.4526      8544
weighted avg     0.5537    0.6031    0.5451      8544

F1-macro sent:  0.45261181393570754
F1-micro sent:  0.6031132958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8612    0.9565    0.9063    124347
           N     0.6922    0.4568    0.5504     14202
           P     0.7706    0.4957    0.6033     25017

   micro avg     0.8426    0.8426    0.8426    163566
   macro avg     0.7747    0.6363    0.6867    163566
weighted avg     0.8327    0.8426    0.8291    163566

F1-macro tok:  0.6866782492969029
F1-micro tok:  0.8426078769426409
**************************************************
dev_cost_sum: 47489.988708496094
dev_cost_avg: 43.13350473069582
dev_count_sent: 1101.0
dev_total_correct_sent: 624.0
dev_accuracy_sent: 0.5667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 18402.0
dev_accuracy_tok: 0.8649995299426531
dev_label=O_precision_sent: 0.18181818181818182
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.016666666666666666
dev_label=N_precision_sent: 0.7040816326530612
dev_label=N_recall_sent: 0.48364485981308414
dev_label=N_f-score_sent: 0.5734072022160666
dev_label=P_precision_sent: 0.5213567839195979
dev_label=P_recall_sent: 0.9346846846846847
dev_label=P_f-score_sent: 0.6693548387096774
dev_precision_macro_sent: 0.46908553279694704
dev_recall_macro_sent: 0.47568772298397244
dev_f-score_macro_sent: 0.4198095691974702
dev_precision_micro_sent: 0.5667574931880109
dev_recall_micro_sent: 0.5667574931880109
dev_f-score_micro_sent: 0.5667574931880109
dev_label=O_precision_tok: 0.8746654772524531
dev_label=O_recall_tok: 0.9680962665843875
dev_label=O_f-score_tok: 0.9190123312146686
dev_label=N_precision_tok: 0.778584392014519
dev_label=N_recall_tok: 0.4620355411954766
dev_label=N_f-score_tok: 0.5799256505576207
dev_label=P_precision_tok: 0.8300536672629696
dev_label=P_recall_tok: 0.5778331257783312
dev_label=P_f-score_tok: 0.6813509544787077
dev_precision_macro_tok: 0.8277678455099805
dev_recall_macro_tok: 0.6693216445193985
dev_f-score_macro_tok: 0.7267629787503324
dev_precision_micro_tok: 0.8649995299426531
dev_recall_micro_tok: 0.8649995299426531
dev_f-score_micro_tok: 0.8649995299426531
dev_time: 5.041107892990112
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1818    0.0087    0.0167       229
           N     0.7041    0.4836    0.5734       428
           P     0.5214    0.9347    0.6694       444

   micro avg     0.5668    0.5668    0.5668      1101
   macro avg     0.4691    0.4757    0.4198      1101
weighted avg     0.5218    0.5668    0.4963      1101

F1-macro sent:  0.4198095691974702
F1-micro sent:  0.5667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8747    0.9681    0.9190     16205
           N     0.7786    0.4620    0.5799      1857
           P     0.8301    0.5778    0.6814      3212

   micro avg     0.8650    0.8650    0.8650     21274
   macro avg     0.8278    0.6693    0.7268     21274
weighted avg     0.8595    0.8650    0.8535     21274

F1-macro tok:  0.7267629787503324
F1-micro tok:  0.8649995299426531
**************************************************
Best epoch: 1
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355124.3933105469
train_cost_avg: 41.564184610316815
train_count_sent: 8544.0
train_total_correct_sent: 5188.0
train_accuracy_sent: 0.6072097378277154
train_count_tok: 163566.0
train_total_correct_tok: 139257.0
train_accuracy_tok: 0.8513810938703642
train_label=O_precision_sent: 0.358974358974359
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.01683704149128082
train_label=N_precision_sent: 0.576769339289913
train_label=N_recall_sent: 0.7410876132930514
train_label=N_f-score_sent: 0.648684384503504
train_label=P_precision_sent: 0.639934148635936
train_label=P_recall_sent: 0.7537396121883656
train_label=P_f-score_sent: 0.692190282370898
train_precision_macro_sent: 0.525225948966736
train_recall_macro_sent: 0.5011493050455298
train_f-score_macro_sent: 0.45257056945522756
train_precision_micro_sent: 0.6072097378277154
train_recall_micro_sent: 0.6072097378277154
train_f-score_micro_sent: 0.6072097378277154
train_label=O_precision_tok: 0.8675853848222528
train_label=O_recall_tok: 0.9599346988668805
train_label=O_f-score_tok: 0.9114267170618106
train_label=N_precision_tok: 0.7129823825503355
train_label=N_recall_tok: 0.47873538938177723
train_label=N_f-score_tok: 0.5728368017524643
train_label=P_precision_tok: 0.7960722320179972
train_label=P_recall_tok: 0.5233641124035656
train_label=P_f-score_tok: 0.6315357900829635
train_precision_macro_tok: 0.7922133331301952
train_recall_macro_tok: 0.6540114002174078
train_f-score_macro_tok: 0.7052664362990795
train_precision_micro_tok: 0.8513810938703642
train_recall_micro_tok: 0.8513810938703642
train_f-score_micro_tok: 0.8513810938703642
train_time: 96.00095415115356
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3590    0.0086    0.0168      1624
           N     0.5768    0.7411    0.6487      3310
           P     0.6399    0.7537    0.6922      3610

   micro avg     0.6072    0.6072    0.6072      8544
   macro avg     0.5252    0.5011    0.4526      8544
weighted avg     0.5621    0.6072    0.5470      8544

F1-macro sent:  0.45257056945522756
F1-micro sent:  0.6072097378277154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8676    0.9599    0.9114    124347
           N     0.7130    0.4787    0.5728     14202
           P     0.7961    0.5234    0.6315     25017

   micro avg     0.8514    0.8514    0.8514    163566
   macro avg     0.7922    0.6540    0.7053    163566
weighted avg     0.8432    0.8514    0.8392    163566

F1-macro tok:  0.7052664362990795
F1-micro tok:  0.8513810938703642
**************************************************
dev_cost_sum: 46655.49206542969
dev_cost_avg: 42.375560459064204
dev_count_sent: 1101.0
dev_total_correct_sent: 683.0
dev_accuracy_sent: 0.620345140781108
dev_count_tok: 21274.0
dev_total_correct_tok: 18523.0
dev_accuracy_tok: 0.8706872238413086
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6506276150627615
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.6865342163355408
dev_label=P_precision_sent: 0.5971107544141252
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.6972820993439551
dev_precision_macro_sent: 0.4159127898256289
dev_recall_macro_sent: 0.5214911172855098
dev_f-score_macro_sent: 0.4612721052264986
dev_precision_micro_sent: 0.620345140781108
dev_recall_micro_sent: 0.620345140781108
dev_f-score_micro_sent: 0.620345140781108
dev_label=O_precision_tok: 0.8804061255399114
dev_label=O_recall_tok: 0.9685282320271521
dev_label=O_f-score_tok: 0.9223671838269865
dev_label=N_precision_tok: 0.7513725490196078
dev_label=N_recall_tok: 0.5158858373721056
dev_label=N_f-score_tok: 0.611749680715198
dev_label=P_precision_tok: 0.8609576427255985
dev_label=P_recall_tok: 0.5821917808219178
dev_label=P_f-score_tok: 0.6946508172362557
dev_precision_macro_tok: 0.8309121057617058
dev_recall_macro_tok: 0.6888686167403918
dev_f-score_macro_tok: 0.7429225605928135
dev_precision_micro_tok: 0.8706872238413086
dev_recall_micro_tok: 0.8706872238413086
dev_f-score_micro_tok: 0.8706872238413085
dev_time: 5.160911560058594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6506    0.7266    0.6865       428
           P     0.5971    0.8378    0.6973       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.4159    0.5215    0.4613      1101
weighted avg     0.4937    0.6203    0.5481      1101

F1-macro sent:  0.4612721052264986
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9685    0.9224     16205
           N     0.7514    0.5159    0.6117      1857
           P     0.8610    0.5822    0.6947      3212

   micro avg     0.8707    0.8707    0.8707     21274
   macro avg     0.8309    0.6889    0.7429     21274
weighted avg     0.8662    0.8707    0.8609     21274

F1-macro tok:  0.7429225605928135
F1-micro tok:  0.8706872238413085
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350716.7489013672
train_cost_avg: 41.04830862609635
train_count_sent: 8544.0
train_total_correct_sent: 5263.0
train_accuracy_sent: 0.6159878277153558
train_count_tok: 163566.0
train_total_correct_tok: 140152.0
train_accuracy_tok: 0.8568528911876552
train_label=O_precision_sent: 0.38461538461538464
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.02386634844868735
train_label=N_precision_sent: 0.5835838150289018
train_label=N_recall_sent: 0.7625377643504532
train_label=N_f-score_sent: 0.6611656843483956
train_label=P_precision_sent: 0.65250779937605
train_label=P_recall_sent: 0.753185595567867
train_label=P_f-score_sent: 0.6992413527066993
train_precision_macro_sent: 0.5402356663401121
train_recall_macro_sent: 0.5093462102847602
train_f-score_macro_sent: 0.4614244618345941
train_precision_micro_sent: 0.6159878277153558
train_recall_micro_sent: 0.6159878277153558
train_f-score_micro_sent: 0.6159878277153558
train_label=O_precision_tok: 0.8719079019272105
train_label=O_recall_tok: 0.9623473023072531
train_label=O_f-score_tok: 0.9148980091134286
train_label=N_precision_tok: 0.7193903820409845
train_label=N_recall_tok: 0.4919025489367695
train_label=N_f-score_tok: 0.5842846986994522
train_label=P_precision_tok: 0.8128236002408188
train_label=P_recall_tok: 0.5396730223448055
train_label=P_f-score_tok: 0.6486655295841641
train_precision_macro_tok: 0.8013739614030045
train_recall_macro_tok: 0.6646409578629426
train_f-score_macro_tok: 0.7159494124656817
train_precision_micro_tok: 0.8568528911876552
train_recall_micro_tok: 0.8568528911876552
train_f-score_micro_tok: 0.8568528911876552
train_time: 95.20284628868103
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.0123    0.0239      1624
           N     0.5836    0.7625    0.6612      3310
           P     0.6525    0.7532    0.6992      3610

   micro avg     0.6160    0.6160    0.6160      8544
   macro avg     0.5402    0.5093    0.4614      8544
weighted avg     0.5749    0.6160    0.5561      8544

F1-macro sent:  0.4614244618345941
F1-micro sent:  0.6159878277153558
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8719    0.9623    0.9149    124347
           N     0.7194    0.4919    0.5843     14202
           P     0.8128    0.5397    0.6487     25017

   micro avg     0.8569    0.8569    0.8569    163566
   macro avg     0.8014    0.6646    0.7159    163566
weighted avg     0.8496    0.8569    0.8455    163566

F1-macro tok:  0.7159494124656817
F1-micro tok:  0.8568528911876552
**************************************************
dev_cost_sum: 46225.309326171875
dev_cost_avg: 41.984840441573
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18627.0
dev_accuracy_tok: 0.8755758202500705
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6345381526104418
dev_label=N_recall_sent: 0.7383177570093458
dev_label=N_f-score_sent: 0.6825053995680346
dev_label=P_precision_sent: 0.6169154228855721
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7106017191977076
dev_precision_macro_sent: 0.4171511918320046
dev_recall_macro_sent: 0.5253851982823945
dev_f-score_macro_sent: 0.4643690395885807
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8807160383671648
dev_label=O_recall_tok: 0.9745757482258562
dev_label=O_f-score_tok: 0.9252716993291735
dev_label=N_precision_tok: 0.7767145135566188
dev_label=N_recall_tok: 0.5245018847603662
dev_label=N_f-score_tok: 0.6261652201864353
dev_label=P_precision_tok: 0.8908045977011494
dev_label=P_recall_tok: 0.5790784557907845
dev_label=P_f-score_tok: 0.7018867924528303
dev_precision_macro_tok: 0.8494117165416443
dev_recall_macro_tok: 0.6927186962590023
dev_f-score_macro_tok: 0.7511079039894796
dev_precision_micro_tok: 0.8755758202500705
dev_recall_micro_tok: 0.8755758202500705
dev_f-score_micro_tok: 0.8755758202500705
dev_time: 5.147524118423462
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6345    0.7383    0.6825       428
           P     0.6169    0.8378    0.7106       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.4172    0.5254    0.4644      1101
weighted avg     0.4955    0.6249    0.5519      1101

F1-macro sent:  0.4643690395885807
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8807    0.9746    0.9253     16205
           N     0.7767    0.5245    0.6262      1857
           P     0.8908    0.5791    0.7019      3212

   micro avg     0.8756    0.8756    0.8756     21274
   macro avg     0.8494    0.6927    0.7511     21274
weighted avg     0.8732    0.8756    0.8654     21274

F1-macro tok:  0.7511079039894796
F1-micro tok:  0.8755758202500705
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346462.2053222656
train_cost_avg: 40.55035174651985
train_count_sent: 8544.0
train_total_correct_sent: 5320.0
train_accuracy_sent: 0.6226591760299626
train_count_tok: 163566.0
train_total_correct_tok: 141066.0
train_accuracy_tok: 0.8624408495653131
train_label=O_precision_sent: 0.45714285714285713
train_label=O_recall_sent: 0.019704433497536946
train_label=O_f-score_sent: 0.03778040141676505
train_label=N_precision_sent: 0.598644396030017
train_label=N_recall_sent: 0.7471299093655589
train_label=N_f-score_sent: 0.6646956054293777
train_label=P_precision_sent: 0.6481694681096016
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7079089651703758
train_precision_macro_sent: 0.5679855737608253
train_recall_macro_sent: 0.5155375787382988
train_f-score_macro_sent: 0.47012832400550614
train_precision_micro_sent: 0.6226591760299626
train_recall_micro_sent: 0.6226591760299626
train_f-score_micro_sent: 0.6226591760299626
train_label=O_precision_tok: 0.8762268066852287
train_label=O_recall_tok: 0.9642532590251474
train_label=O_f-score_tok: 0.9181349689493311
train_label=N_precision_tok: 0.7314469841909174
train_label=N_recall_tok: 0.511477256724405
train_label=N_f-score_tok: 0.6019972651555962
train_label=P_precision_tok: 0.8275779947606573
train_label=P_recall_tok: 0.5556221769196946
train_label=P_f-score_tok: 0.6648649941405783
train_precision_macro_tok: 0.8117505952122678
train_recall_macro_tok: 0.6771175642230823
train_f-score_macro_tok: 0.7283324094151685
train_precision_micro_tok: 0.8624408495653131
train_recall_micro_tok: 0.8624408495653131
train_f-score_micro_tok: 0.8624408495653131
train_time: 94.83506226539612
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4571    0.0197    0.0378      1624
           N     0.5986    0.7471    0.6647      3310
           P     0.6482    0.7798    0.7079      3610

   micro avg     0.6227    0.6227    0.6227      8544
   macro avg     0.5680    0.5155    0.4701      8544
weighted avg     0.5927    0.6227    0.5638      8544

F1-macro sent:  0.47012832400550614
F1-micro sent:  0.6226591760299626
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8762    0.9643    0.9181    124347
           N     0.7314    0.5115    0.6020     14202
           P     0.8276    0.5556    0.6649     25017

   micro avg     0.8624    0.8624    0.8624    163566
   macro avg     0.8118    0.6771    0.7283    163566
weighted avg     0.8562    0.8624    0.8519    163566

F1-macro tok:  0.7283324094151685
F1-micro tok:  0.8624408495653131
**************************************************
dev_cost_sum: 45939.36730957031
dev_cost_avg: 41.725129254832254
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18653.0
dev_accuracy_tok: 0.876797969352261
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6587982832618026
dev_label=N_recall_sent: 0.7172897196261683
dev_label=N_f-score_sent: 0.6868008948545861
dev_label=P_precision_sent: 0.6018957345971564
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7075208913649025
dev_precision_macro_sent: 0.7535646726196529
dev_recall_macro_sent: 0.5280438173961416
dev_f-score_macro_sent: 0.4705459345118353
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8772288158984267
dev_label=O_recall_tok: 0.9806232644245603
dev_label=O_f-score_tok: 0.926048951048951
dev_label=N_precision_tok: 0.8491335372069317
dev_label=N_recall_tok: 0.44857296715131934
dev_label=N_f-score_tok: 0.587033121916843
dev_label=P_precision_tok: 0.8856749311294766
dev_label=P_recall_tok: 0.6005603985056039
dev_label=P_f-score_tok: 0.715769944341373
dev_precision_macro_tok: 0.8706790947449451
dev_recall_macro_tok: 0.6765855433604945
dev_f-score_macro_tok: 0.7429506724357223
dev_precision_micro_tok: 0.876797969352261
dev_recall_micro_tok: 0.876797969352261
dev_f-score_micro_tok: 0.876797969352261
dev_time: 5.137898921966553
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6588    0.7173    0.6868       428
           P     0.6019    0.8581    0.7075       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.7536    0.5280    0.4705      1101
weighted avg     0.7068    0.6267    0.5559      1101

F1-macro sent:  0.4705459345118353
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8772    0.9806    0.9260     16205
           N     0.8491    0.4486    0.5870      1857
           P     0.8857    0.6006    0.7158      3212

   micro avg     0.8768    0.8768    0.8768     21274
   macro avg     0.8707    0.6766    0.7430     21274
weighted avg     0.8761    0.8768    0.8647     21274

F1-macro tok:  0.7429506724357223
F1-micro tok:  0.876797969352261
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342627.16760253906
train_cost_avg: 40.10149433550317
train_count_sent: 8544.0
train_total_correct_sent: 5380.0
train_accuracy_sent: 0.6296816479400749
train_count_tok: 163566.0
train_total_correct_tok: 141719.0
train_accuracy_tok: 0.8664331217979286
train_label=O_precision_sent: 0.48717948717948717
train_label=O_recall_sent: 0.023399014778325122
train_label=O_f-score_sent: 0.04465334900117508
train_label=N_precision_sent: 0.5994844152800562
train_label=N_recall_sent: 0.7728096676737161
train_label=N_f-score_sent: 0.6752012669922133
train_label=P_precision_sent: 0.6630150035722792
train_label=P_recall_sent: 0.771191135734072
train_label=P_f-score_sent: 0.7130234344986555
train_precision_macro_sent: 0.5832263020106075
train_recall_macro_sent: 0.5224666060620377
train_f-score_macro_sent: 0.47762601683068134
train_precision_micro_sent: 0.6296816479400749
train_recall_micro_sent: 0.6296816479400749
train_f-score_micro_sent: 0.6296816479400749
train_label=O_precision_tok: 0.8788885312106757
train_label=O_recall_tok: 0.9660868376398305
train_label=O_f-score_tok: 0.920427075711314
train_label=N_precision_tok: 0.742665465104636
train_label=N_recall_tok: 0.5222503872693987
train_label=N_f-score_tok: 0.6132539584108478
train_label=P_precision_tok: 0.8388280556377626
train_label=P_recall_tok: 0.566494783547188
train_label=P_f-score_tok: 0.6762740981103265
train_precision_macro_tok: 0.8201273506510248
train_recall_macro_tok: 0.6849440028188057
train_f-score_macro_tok: 0.7366517107441628
train_precision_micro_tok: 0.8664331217979286
train_recall_micro_tok: 0.8664331217979286
train_f-score_micro_tok: 0.8664331217979286
train_time: 95.61304187774658
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4872    0.0234    0.0447      1624
           N     0.5995    0.7728    0.6752      3310
           P     0.6630    0.7712    0.7130      3610

   micro avg     0.6297    0.6297    0.6297      8544
   macro avg     0.5832    0.5225    0.4776      8544
weighted avg     0.6050    0.6297    0.5713      8544

F1-macro sent:  0.47762601683068134
F1-micro sent:  0.6296816479400749
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8789    0.9661    0.9204    124347
           N     0.7427    0.5223    0.6133     14202
           P     0.8388    0.5665    0.6763     25017

   micro avg     0.8664    0.8664    0.8664    163566
   macro avg     0.8201    0.6849    0.7367    163566
weighted avg     0.8609    0.8664    0.8564    163566

F1-macro tok:  0.7366517107441628
F1-micro tok:  0.8664331217979286
**************************************************
dev_cost_sum: 45349.33837890625
dev_cost_avg: 41.18922650218551
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 18767.0
dev_accuracy_tok: 0.8821566231080192
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.5849923430321593
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.7067530064754858
dev_label=P_precision_sent: 0.7278911564625851
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.7254237288135594
dev_precision_macro_sent: 0.7233421188792005
dev_recall_macro_sent: 0.5472324036071332
dev_f-score_macro_sent: 0.49434139763872126
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.889490302210194
dev_label=O_recall_tok: 0.973526689293428
dev_label=O_f-score_tok: 0.9296131522347604
dev_label=N_precision_tok: 0.7444598337950139
dev_label=N_recall_tok: 0.5788906838987614
dev_label=N_f-score_tok: 0.6513177824901545
dev_label=P_precision_tok: 0.9149952244508118
dev_label=P_recall_tok: 0.5965130759651308
dev_label=P_f-score_tok: 0.7222012815680362
dev_precision_macro_tok: 0.84964845348534
dev_recall_macro_tok: 0.7163101497191068
dev_f-score_macro_tok: 0.767710738764317
dev_precision_micro_tok: 0.8821566231080192
dev_recall_micro_tok: 0.8821566231080192
dev_f-score_micro_tok: 0.8821566231080192
dev_time: 5.0959632396698
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.5850    0.8925    0.7068       428
           P     0.7279    0.7230    0.7254       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.7233    0.5472    0.4943      1101
weighted avg     0.6992    0.6440    0.5779      1101

F1-macro sent:  0.49434139763872126
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8895    0.9735    0.9296     16205
           N     0.7445    0.5789    0.6513      1857
           P     0.9150    0.5965    0.7222      3212

   micro avg     0.8822    0.8822    0.8822     21274
   macro avg     0.8496    0.7163    0.7677     21274
weighted avg     0.8807    0.8822    0.8740     21274

F1-macro tok:  0.767710738764317
F1-micro tok:  0.8821566231080192
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339113.72540283203
train_cost_avg: 39.6902768495824
train_count_sent: 8544.0
train_total_correct_sent: 5391.0
train_accuracy_sent: 0.6309691011235955
train_count_tok: 163566.0
train_total_correct_tok: 142344.0
train_accuracy_tok: 0.8702542093100033
train_label=O_precision_sent: 0.41935483870967744
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.0454280722189866
train_label=N_precision_sent: 0.5994844152800562
train_label=N_recall_sent: 0.7728096676737161
train_label=N_f-score_sent: 0.6752012669922133
train_label=P_precision_sent: 0.6677820267686424
train_label=P_recall_sent: 0.7739612188365651
train_label=P_f-score_sent: 0.7169617654606106
train_precision_macro_sent: 0.5622070935861254
train_recall_macro_sent: 0.5235952216118015
train_f-score_macro_sent: 0.47919703489060356
train_precision_micro_sent: 0.6309691011235955
train_recall_micro_sent: 0.6309691011235955
train_f-score_micro_sent: 0.6309691011235955
train_label=O_precision_tok: 0.8820295146143526
train_label=O_recall_tok: 0.9675746097613935
train_label=O_f-score_tok: 0.9228238109482501
train_label=N_precision_tok: 0.7490393142181496
train_label=N_recall_tok: 0.5352767215885087
train_label=N_f-score_tok: 0.6243686090920291
train_label=P_precision_tok: 0.8481481481481481
train_label=P_recall_tok: 0.5766878522604629
train_label=P_f-score_tok: 0.6865586408737241
train_precision_macro_tok: 0.8264056589935501
train_recall_macro_tok: 0.6931797278701217
train_f-score_macro_tok: 0.7445836869713345
train_precision_micro_tok: 0.8702542093100033
train_recall_micro_tok: 0.8702542093100033
train_f-score_micro_tok: 0.8702542093100033
train_time: 94.64819121360779
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4194    0.0240    0.0454      1624
           N     0.5995    0.7728    0.6752      3310
           P     0.6678    0.7740    0.7170      3610

   micro avg     0.6310    0.6310    0.6310      8544
   macro avg     0.5622    0.5236    0.4792      8544
weighted avg     0.5941    0.6310    0.5731      8544

F1-macro sent:  0.47919703489060356
F1-micro sent:  0.6309691011235955
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8820    0.9676    0.9228    124347
           N     0.7490    0.5353    0.6244     14202
           P     0.8481    0.5767    0.6866     25017

   micro avg     0.8703    0.8703    0.8703    163566
   macro avg     0.8264    0.6932    0.7446    163566
weighted avg     0.8653    0.8703    0.8608    163566

F1-macro tok:  0.7445836869713345
F1-micro tok:  0.8702542093100033
**************************************************
dev_cost_sum: 45113.384521484375
dev_cost_avg: 40.974917821511696
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18785.0
dev_accuracy_tok: 0.8830027263326126
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6009933774834437
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7034883720930233
dev_label=P_precision_sent: 0.6767676767676768
dev_label=P_recall_sent: 0.7545045045045045
dev_label=P_f-score_sent: 0.7135250266240681
dev_precision_macro_sent: 0.7592536847503735
dev_recall_macro_sent: 0.5371229900267162
dev_f-score_macro_sent: 0.4781098053443696
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.887524530417718
dev_label=O_recall_tok: 0.9767972847886455
dev_label=O_f-score_tok: 0.9300235017626323
dev_label=N_precision_tok: 0.7547974413646056
dev_label=N_recall_tok: 0.5718901453957996
dev_label=N_f-score_tok: 0.650735294117647
dev_label=P_precision_tok: 0.9320866141732284
dev_label=P_recall_tok: 0.5896637608966376
dev_label=P_f-score_tok: 0.7223493516399695
dev_precision_macro_tok: 0.8581361953185173
dev_recall_macro_tok: 0.7127837303603609
dev_f-score_macro_tok: 0.767702715840083
dev_precision_micro_tok: 0.8830027263326126
dev_recall_micro_tok: 0.8830027263326126
dev_f-score_micro_tok: 0.8830027263326126
dev_time: 5.0564188957214355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6010    0.8481    0.7035       428
           P     0.6768    0.7545    0.7135       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.7593    0.5371    0.4781      1101
weighted avg     0.7145    0.6358    0.5648      1101

F1-macro sent:  0.4781098053443696
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8875    0.9768    0.9300     16205
           N     0.7548    0.5719    0.6507      1857
           P     0.9321    0.5897    0.7223      3212

   micro avg     0.8830    0.8830    0.8830     21274
   macro avg     0.8581    0.7128    0.7677     21274
weighted avg     0.8827    0.8830    0.8743     21274

F1-macro tok:  0.767702715840083
F1-micro tok:  0.8830027263326126
**************************************************
Best epoch: 7
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 335885.1919555664
train_cost_avg: 39.31240542551105
train_count_sent: 8544.0
train_total_correct_sent: 5475.0
train_accuracy_sent: 0.6408005617977528
train_count_tok: 163566.0
train_total_correct_tok: 142772.0
train_accuracy_tok: 0.872870890038272
train_label=O_precision_sent: 0.5172413793103449
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.05260081823495032
train_label=N_precision_sent: 0.608849140974347
train_label=N_recall_sent: 0.781570996978852
train_label=N_f-score_sent: 0.6844820743484589
train_label=P_precision_sent: 0.6756178707224335
train_label=P_recall_sent: 0.7875346260387812
train_label=P_f-score_sent: 0.7272959836275262
train_precision_macro_sent: 0.6005694636690418
train_recall_macro_sent: 0.5322716608745148
train_f-score_macro_sent: 0.4881262920703118
train_precision_micro_sent: 0.6408005617977528
train_recall_micro_sent: 0.6408005617977528
train_f-score_micro_sent: 0.6408005617977528
train_label=O_precision_tok: 0.8846959859408663
train_label=O_recall_tok: 0.9675826517728614
train_label=O_f-score_tok: 0.9242847924284792
train_label=N_precision_tok: 0.754846839860411
train_label=N_recall_tok: 0.5483030559076186
train_label=N_f-score_tok: 0.6352067868504773
train_label=P_precision_tok: 0.8502289456906046
train_label=P_recall_tok: 0.5863612743334532
train_label=P_f-score_tok: 0.6940619824934942
train_precision_macro_tok: 0.8299239238306272
train_recall_macro_tok: 0.7007489940046444
train_f-score_macro_tok: 0.7511845205908169
train_precision_micro_tok: 0.872870890038272
train_recall_micro_tok: 0.872870890038272
train_f-score_micro_tok: 0.872870890038272
train_time: 96.40241432189941
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5172    0.0277    0.0526      1624
           N     0.6088    0.7816    0.6845      3310
           P     0.6756    0.7875    0.7273      3610

   micro avg     0.6408    0.6408    0.6408      8544
   macro avg     0.6006    0.5323    0.4881      8544
weighted avg     0.6196    0.6408    0.5825      8544

F1-macro sent:  0.4881262920703118
F1-micro sent:  0.6408005617977528
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9676    0.9243    124347
           N     0.7548    0.5483    0.6352     14202
           P     0.8502    0.5864    0.6941     25017

   micro avg     0.8729    0.8729    0.8729    163566
   macro avg     0.8299    0.7007    0.7512    163566
weighted avg     0.8681    0.8729    0.8640    163566

F1-macro tok:  0.7511845205908169
F1-micro tok:  0.872870890038272
**************************************************
dev_cost_sum: 44754.20233154297
dev_cost_avg: 40.64868513309988
dev_count_sent: 1101.0
dev_total_correct_sent: 695.0
dev_accuracy_sent: 0.631244323342416
dev_count_tok: 21274.0
dev_total_correct_tok: 18835.0
dev_accuracy_tok: 0.8853530130675943
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.565028901734104
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.6982142857142856
dev_label=P_precision_sent: 0.7413793103448276
dev_label=P_recall_sent: 0.6779279279279279
dev_label=P_f-score_sent: 0.7082352941176471
dev_precision_macro_sent: 0.7688027373596439
dev_recall_macro_sent: 0.5348599221594365
dev_f-score_macro_sent: 0.47743721626581664
dev_precision_micro_sent: 0.631244323342416
dev_recall_micro_sent: 0.631244323342416
dev_f-score_micro_sent: 0.631244323342416
dev_label=O_precision_tok: 0.8832419863809998
dev_label=O_recall_tok: 0.9845109534094415
dev_label=O_f-score_tok: 0.9311310843936034
dev_label=N_precision_tok: 0.8164291701592624
dev_label=N_recall_tok: 0.5245018847603662
dev_label=N_f-score_tok: 0.6386885245901639
dev_label=P_precision_tok: 0.9449950445986125
dev_label=P_recall_tok: 0.5937110834371109
dev_label=P_f-score_tok: 0.7292543021032506
dev_precision_macro_tok: 0.881555400379625
dev_recall_macro_tok: 0.7009079738689729
dev_f-score_macro_tok: 0.7663579703623392
dev_precision_micro_tok: 0.8853530130675943
dev_recall_micro_tok: 0.8853530130675943
dev_f-score_micro_tok: 0.8853530130675943
dev_time: 5.079178810119629
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.5650    0.9136    0.6982       428
           P     0.7414    0.6779    0.7082       444

   micro avg     0.6312    0.6312    0.6312      1101
   macro avg     0.7688    0.5349    0.4774      1101
weighted avg     0.7266    0.6312    0.5624      1101

F1-macro sent:  0.47743721626581664
F1-micro sent:  0.631244323342416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8832    0.9845    0.9311     16205
           N     0.8164    0.5245    0.6387      1857
           P     0.9450    0.5937    0.7293      3212

   micro avg     0.8854    0.8854    0.8854     21274
   macro avg     0.8816    0.7009    0.7664     21274
weighted avg     0.8867    0.8854    0.8751     21274

F1-macro tok:  0.7663579703623392
F1-micro tok:  0.8853530130675943
**************************************************
Best epoch: 7
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333100.7581176758
train_cost_avg: 38.98651195197516
train_count_sent: 8544.0
train_total_correct_sent: 5538.0
train_accuracy_sent: 0.6481741573033708
train_count_tok: 163566.0
train_total_correct_tok: 143197.0
train_accuracy_tok: 0.8754692295464828
train_label=O_precision_sent: 0.4818181818181818
train_label=O_recall_sent: 0.03263546798029557
train_label=O_f-score_sent: 0.06113033448673587
train_label=N_precision_sent: 0.6212735511566897
train_label=N_recall_sent: 0.7870090634441088
train_label=N_f-score_sent: 0.6943889111022258
train_label=P_precision_sent: 0.6790851214336241
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.7336645013374092
train_precision_macro_sent: 0.5940589514694986
train_recall_macro_sent: 0.53914282164747
train_f-score_macro_sent: 0.4963945823087903
train_precision_micro_sent: 0.6481741573033708
train_recall_micro_sent: 0.6481741573033708
train_f-score_micro_sent: 0.6481741573033708
train_label=O_precision_tok: 0.8868738633267802
train_label=O_recall_tok: 0.9686522392980932
train_label=O_f-score_tok: 0.9259609471094711
train_label=N_precision_tok: 0.757705887966409
train_label=N_recall_tok: 0.5590761864526123
train_label=N_f-score_tok: 0.6434099104574368
train_label=P_precision_tok: 0.8572420979506773
train_label=P_recall_tok: 0.5919174961026502
train_label=P_f-score_tok: 0.7002908420231254
train_precision_macro_tok: 0.8339406164146221
train_recall_macro_tok: 0.7065486406177852
train_f-score_macro_tok: 0.7565538998633444
train_precision_micro_tok: 0.8754692295464828
train_recall_micro_tok: 0.8754692295464828
train_f-score_micro_tok: 0.8754692295464828
train_time: 96.08062601089478
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4818    0.0326    0.0611      1624
           N     0.6213    0.7870    0.6944      3310
           P     0.6791    0.7978    0.7337      3610

   micro avg     0.6482    0.6482    0.6482      8544
   macro avg     0.5941    0.5391    0.4964      8544
weighted avg     0.6192    0.6482    0.5906      8544

F1-macro sent:  0.4963945823087903
F1-micro sent:  0.6481741573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8869    0.9687    0.9260    124347
           N     0.7577    0.5591    0.6434     14202
           P     0.8572    0.5919    0.7003     25017

   micro avg     0.8755    0.8755    0.8755    163566
   macro avg     0.8339    0.7065    0.7566    163566
weighted avg     0.8711    0.8755    0.8669    163566

F1-macro tok:  0.7565538998633444
F1-micro tok:  0.8754692295464828
**************************************************
dev_cost_sum: 44313.01623535156
dev_cost_avg: 40.247971149274804
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 18905.0
dev_accuracy_tok: 0.8886434144965686
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6033057851239669
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7066795740561472
dev_label=P_precision_sent: 0.6836734693877551
dev_label=P_recall_sent: 0.7545045045045045
dev_label=P_f-score_sent: 0.7173447537473234
dev_precision_macro_sent: 0.7067708626150185
dev_recall_macro_sent: 0.5430474346525442
dev_f-score_macro_sent: 0.4888591730976108
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.8966791766177641
dev_label=O_recall_tok: 0.9730947238506634
dev_label=O_f-score_tok: 0.9333254416856559
dev_label=N_precision_tok: 0.7606896551724138
dev_label=N_recall_tok: 0.5939687668282175
dev_label=N_f-score_tok: 0.6670698518294526
dev_label=P_precision_tok: 0.9084003574620196
dev_label=P_recall_tok: 0.6329389788293898
dev_label=P_f-score_tok: 0.7460550458715596
dev_precision_macro_tok: 0.8552563964173991
dev_recall_macro_tok: 0.733334156502757
dev_f-score_macro_tok: 0.7821501131288894
dev_precision_micro_tok: 0.8886434144965686
dev_recall_micro_tok: 0.8886434144965686
dev_f-score_micro_tok: 0.8886434144965686
dev_time: 4.981073617935181
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6033    0.8528    0.7067       428
           P     0.6837    0.7545    0.7173       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.7068    0.5430    0.4889      1101
weighted avg     0.6836    0.6403    0.5728      1101

F1-macro sent:  0.4888591730976108
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8967    0.9731    0.9333     16205
           N     0.7607    0.5940    0.6671      1857
           P     0.9084    0.6329    0.7461      3212

   micro avg     0.8886    0.8886    0.8886     21274
   macro avg     0.8553    0.7333    0.7822     21274
weighted avg     0.8866    0.8886    0.8818     21274

F1-macro tok:  0.7821501131288894
F1-micro tok:  0.8886434144965686
**************************************************
Best epoch: 7
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330733.13568115234
train_cost_avg: 38.709402584404536
train_count_sent: 8544.0
train_total_correct_sent: 5444.0
train_accuracy_sent: 0.6371722846441947
train_count_tok: 163566.0
train_total_correct_tok: 143610.0
train_accuracy_tok: 0.8779942041744617
train_label=O_precision_sent: 0.4859154929577465
train_label=O_recall_sent: 0.042487684729064036
train_label=O_f-score_sent: 0.07814269535673839
train_label=N_precision_sent: 0.6069309280797531
train_label=N_recall_sent: 0.7725075528700907
train_label=N_f-score_sent: 0.6797820018609597
train_label=P_precision_sent: 0.6727142516113631
train_label=P_recall_sent: 0.7806094182825485
train_label=P_f-score_sent: 0.7226567508654956
train_precision_macro_sent: 0.5885202242162876
train_recall_macro_sent: 0.5318682186272344
train_f-score_macro_sent: 0.4935271493610645
train_precision_micro_sent: 0.6371722846441947
train_recall_micro_sent: 0.6371722846441947
train_f-score_micro_sent: 0.6371722846441947
train_label=O_precision_tok: 0.8887569775758961
train_label=O_recall_tok: 0.9692795161925901
train_label=O_f-score_tok: 0.9272734266810279
train_label=N_precision_tok: 0.7695975586496281
train_label=N_recall_tok: 0.5682298267849598
train_label=N_f-score_tok: 0.6537589112119248
train_label=P_precision_tok: 0.859506497967596
train_label=P_recall_tok: 0.6001119238917536
train_label=P_f-score_tok: 0.7067601920723097
train_precision_macro_tok: 0.8392870113977068
train_recall_macro_tok: 0.7125404222897679
train_f-score_macro_tok: 0.7625975099884208
train_precision_micro_tok: 0.8779942041744617
train_recall_micro_tok: 0.8779942041744617
train_f-score_micro_tok: 0.8779942041744618
train_time: 95.79910182952881
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4859    0.0425    0.0781      1624
           N     0.6069    0.7725    0.6798      3310
           P     0.6727    0.7806    0.7227      3610

   micro avg     0.6372    0.6372    0.6372      8544
   macro avg     0.5885    0.5319    0.4935      8544
weighted avg     0.6117    0.6372    0.5835      8544

F1-macro sent:  0.4935271493610645
F1-micro sent:  0.6371722846441947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8888    0.9693    0.9273    124347
           N     0.7696    0.5682    0.6538     14202
           P     0.8595    0.6001    0.7068     25017

   micro avg     0.8780    0.8780    0.8780    163566
   macro avg     0.8393    0.7125    0.7626    163566
weighted avg     0.8739    0.8780    0.8698    163566

F1-macro tok:  0.7625975099884208
F1-micro tok:  0.8779942041744618
**************************************************
dev_cost_sum: 44091.505859375
dev_cost_avg: 40.04678098035876
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 18936.0
dev_accuracy_tok: 0.8901005922722572
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6585858585858586
dev_label=N_recall_sent: 0.7616822429906542
dev_label=N_f-score_sent: 0.7063921993499459
dev_label=P_precision_sent: 0.6307947019867549
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7270992366412212
dev_precision_macro_sent: 0.7631268535242045
dev_recall_macro_sent: 0.5428413251843036
dev_f-score_macro_sent: 0.4836024844357281
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8925099735910547
dev_label=O_recall_tok: 0.9801912989817957
dev_label=O_f-score_tok: 0.9342979824716194
dev_label=N_precision_tok: 0.8009331259720062
dev_label=N_recall_tok: 0.5546580506192784
dev_label=N_f-score_tok: 0.655424753420299
dev_label=P_precision_tok: 0.9228662711090826
dev_label=P_recall_tok: 0.6295143212951432
dev_label=P_f-score_tok: 0.7484730705163797
dev_precision_macro_tok: 0.8721031235573812
dev_recall_macro_tok: 0.7214545569654058
dev_f-score_macro_tok: 0.7793986021360993
dev_precision_micro_tok: 0.8901005922722572
dev_recall_micro_tok: 0.8901005922722572
dev_f-score_micro_tok: 0.8901005922722572
dev_time: 5.059474229812622
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6586    0.7617    0.7064       428
           P     0.6308    0.8581    0.7271       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.7631    0.5428    0.4836      1101
weighted avg     0.7184    0.6440    0.5714      1101

F1-macro sent:  0.4836024844357281
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8925    0.9802    0.9343     16205
           N     0.8009    0.5547    0.6554      1857
           P     0.9229    0.6295    0.7485      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8721    0.7215    0.7794     21274
weighted avg     0.8891    0.8901    0.8819     21274

F1-macro tok:  0.7793986021360993
F1-micro tok:  0.8901005922722572
**************************************************
Best epoch: 7
**************************************************

EPOCH: 12
Learning rate: 0.900000
train_cost_sum: 328050.51873779297
train_cost_avg: 38.395425882232324
train_count_sent: 8544.0
train_total_correct_sent: 5531.0
train_accuracy_sent: 0.6473548689138576
train_count_tok: 163566.0
train_total_correct_tok: 143949.0
train_accuracy_tok: 0.880066762041011
train_label=O_precision_sent: 0.42857142857142855
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.06488332384746727
train_label=N_precision_sent: 0.6243691420331651
train_label=N_recall_sent: 0.7848942598187311
train_label=N_f-score_sent: 0.6954892250033462
train_label=P_precision_sent: 0.6767058823529412
train_label=P_recall_sent: 0.7966759002770083
train_label=P_f-score_sent: 0.7318066157760813
train_precision_macro_sent: 0.5765488176525116
train_recall_macro_sent: 0.538889560754409
train_f-score_macro_sent: 0.4973930548756316
train_precision_micro_sent: 0.6473548689138576
train_recall_micro_sent: 0.6473548689138576
train_f-score_micro_sent: 0.6473548689138576
train_label=O_precision_tok: 0.89087713338306
train_label=O_recall_tok: 0.9701158853852525
train_label=O_f-score_tok: 0.9288095659739599
train_label=N_precision_tok: 0.7672837174159426
train_label=N_recall_tok: 0.5720321081537811
train_label=N_f-score_tok: 0.6554255748285599
train_label=P_precision_tok: 0.8647202777303511
train_label=P_recall_tok: 0.6073470040372546
train_label=P_f-score_tok: 0.7135343289189442
train_precision_macro_tok: 0.8409603761764511
train_recall_macro_tok: 0.7164983325254294
train_f-score_macro_tok: 0.7659231565738214
train_precision_micro_tok: 0.880066762041011
train_recall_micro_tok: 0.880066762041011
train_f-score_micro_tok: 0.880066762041011
train_time: 96.71530032157898
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0351    0.0649      1624
           N     0.6244    0.7849    0.6955      3310
           P     0.6767    0.7967    0.7318      3610

   micro avg     0.6474    0.6474    0.6474      8544
   macro avg     0.5765    0.5389    0.4974      8544
weighted avg     0.6093    0.6474    0.5910      8544

F1-macro sent:  0.4973930548756316
F1-micro sent:  0.6473548689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8909    0.9701    0.9288    124347
           N     0.7673    0.5720    0.6554     14202
           P     0.8647    0.6073    0.7135     25017

   micro avg     0.8801    0.8801    0.8801    163566
   macro avg     0.8410    0.7165    0.7659    163566
weighted avg     0.8761    0.8801    0.8721    163566

F1-macro tok:  0.7659231565738214
F1-micro tok:  0.880066762041011
**************************************************
dev_cost_sum: 43824.305603027344
dev_cost_avg: 39.80409228249532
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 18986.0
dev_accuracy_tok: 0.8924508790072389
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6440677966101694
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7132429614181438
dev_label=P_precision_sent: 0.6584070796460177
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7373637264618434
dev_precision_macro_sent: 0.7008249587520624
dev_recall_macro_sent: 0.5514568357689608
dev_f-score_macro_sent: 0.4949315740226738
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.8947190631685621
dev_label=O_recall_tok: 0.9806849737735267
dev_label=O_f-score_tok: 0.9357317396296405
dev_label=N_precision_tok: 0.8295454545454546
dev_label=N_recall_tok: 0.5503500269251481
dev_label=N_f-score_tok: 0.6617028164454516
dev_label=P_precision_tok: 0.9087719298245615
dev_label=P_recall_tok: 0.6450809464508095
dev_label=P_f-score_tok: 0.7545520757465405
dev_precision_macro_tok: 0.8776788158461928
dev_recall_macro_tok: 0.7253719823831615
dev_f-score_macro_tok: 0.7839955439405442
dev_precision_micro_tok: 0.8924508790072389
dev_recall_micro_tok: 0.8924508790072389
dev_f-score_micro_tok: 0.8924508790072389
dev_time: 5.0674333572387695
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6441    0.7991    0.7132       428
           P     0.6584    0.8378    0.7374       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.7008    0.5515    0.4949      1101
weighted avg     0.6823    0.6521    0.5817      1101

F1-macro sent:  0.4949315740226738
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8947    0.9807    0.9357     16205
           N     0.8295    0.5504    0.6617      1857
           P     0.9088    0.6451    0.7546      3212

   micro avg     0.8925    0.8925    0.8925     21274
   macro avg     0.8777    0.7254    0.7840     21274
weighted avg     0.8912    0.8925    0.8845     21274

F1-macro tok:  0.7839955439405442
F1-micro tok:  0.8924508790072389
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 325679.47271728516
train_cost_avg: 38.11791581428899
train_count_sent: 8544.0
train_total_correct_sent: 5576.0
train_accuracy_sent: 0.6526217228464419
train_count_tok: 163566.0
train_total_correct_tok: 144325.0
train_accuracy_tok: 0.8823655282882751
train_label=O_precision_sent: 0.47783251231527096
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10618500273672689
train_label=N_precision_sent: 0.6156673558465426
train_label=N_recall_sent: 0.8096676737160121
train_label=N_f-score_sent: 0.6994649615033277
train_label=P_precision_sent: 0.7018555667001003
train_label=P_recall_sent: 0.7753462603878116
train_label=P_f-score_sent: 0.7367728349565675
train_precision_macro_sent: 0.598451811620638
train_recall_macro_sent: 0.5482476660477442
train_f-score_macro_sent: 0.5141409330655408
train_precision_micro_sent: 0.6526217228464419
train_recall_micro_sent: 0.6526217228464419
train_f-score_micro_sent: 0.6526217228464419
train_label=O_precision_tok: 0.8931747665558377
train_label=O_recall_tok: 0.9700032972247018
train_label=O_f-score_tok: 0.9300050117583561
train_label=N_precision_tok: 0.7712612696347244
train_label=N_recall_tok: 0.5842839036755386
train_label=N_f-score_tok: 0.6648772084451744
train_label=P_precision_tok: 0.8674848007205584
train_label=P_recall_tok: 0.6159811328296758
train_label=P_f-score_tok: 0.720413267572053
train_precision_macro_tok: 0.8439736123037068
train_recall_macro_tok: 0.7234227779099721
train_f-score_macro_tok: 0.7717651625918612
train_precision_micro_tok: 0.8823655282882751
train_recall_micro_tok: 0.8823655282882751
train_f-score_micro_tok: 0.8823655282882751
train_time: 96.45916295051575
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4778    0.0597    0.1062      1624
           N     0.6157    0.8097    0.6995      3310
           P     0.7019    0.7753    0.7368      3610

   micro avg     0.6526    0.6526    0.6526      8544
   macro avg     0.5985    0.5482    0.5141      8544
weighted avg     0.6259    0.6526    0.6025      8544

F1-macro sent:  0.5141409330655408
F1-micro sent:  0.6526217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8932    0.9700    0.9300    124347
           N     0.7713    0.5843    0.6649     14202
           P     0.8675    0.6160    0.7204     25017

   micro avg     0.8824    0.8824    0.8824    163566
   macro avg     0.8440    0.7234    0.7718    163566
weighted avg     0.8787    0.8824    0.8749    163566

F1-macro tok:  0.7717651625918612
F1-micro tok:  0.8823655282882751
**************************************************
dev_cost_sum: 43680.47424316406
dev_cost_avg: 39.673455261729394
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 18986.0
dev_accuracy_tok: 0.8924508790072389
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6419529837251357
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7237512742099897
dev_label=P_precision_sent: 0.671559633027523
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7401415571284127
dev_precision_macro_sent: 0.7711708722508862
dev_recall_macro_sent: 0.5556213377806652
dev_f-score_macro_sent: 0.4965849667679732
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9021191294387171
dev_label=O_recall_tok: 0.9719839555692688
dev_label=O_f-score_tok: 0.9357492945195306
dev_label=N_precision_tok: 0.7783216783216783
dev_label=N_recall_tok: 0.5993537964458805
dev_label=N_f-score_tok: 0.6772132643748099
dev_label=P_precision_tok: 0.8901006711409396
dev_label=P_recall_tok: 0.6606475716064757
dev_label=P_f-score_tok: 0.7583988563259472
dev_precision_macro_tok: 0.8568471596337783
dev_recall_macro_tok: 0.743995107873875
dev_f-score_macro_tok: 0.7904538050734292
dev_precision_micro_tok: 0.8924508790072389
dev_recall_micro_tok: 0.8924508790072389
dev_f-score_micro_tok: 0.8924508790072389
dev_time: 5.080087900161743
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6420    0.8294    0.7238       428
           P     0.6716    0.8243    0.7401       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7712    0.5556    0.4966      1101
weighted avg     0.7284    0.6576    0.5852      1101

F1-macro sent:  0.4965849667679732
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9021    0.9720    0.9357     16205
           N     0.7783    0.5994    0.6772      1857
           P     0.8901    0.6606    0.7584      3212

   micro avg     0.8925    0.8925    0.8925     21274
   macro avg     0.8568    0.7440    0.7905     21274
weighted avg     0.8895    0.8925    0.8864     21274

F1-macro tok:  0.7904538050734292
F1-micro tok:  0.8924508790072389
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 323644.3605957031
train_cost_avg: 37.87972385249334
train_count_sent: 8544.0
train_total_correct_sent: 5610.0
train_accuracy_sent: 0.6566011235955056
train_count_tok: 163566.0
train_total_correct_tok: 144672.0
train_accuracy_tok: 0.8844869960749789
train_label=O_precision_sent: 0.4897959183673469
train_label=O_recall_sent: 0.029556650246305417
train_label=O_f-score_sent: 0.05574912891986063
train_label=N_precision_sent: 0.6248556248556248
train_label=N_recall_sent: 0.8172205438066465
train_label=N_f-score_sent: 0.7082078806126456
train_label=P_precision_sent: 0.6939519067282002
train_label=P_recall_sent: 0.7914127423822714
train_label=P_f-score_sent: 0.7394849229972822
train_precision_macro_sent: 0.6028678166503907
train_recall_macro_sent: 0.5460633121450744
train_f-score_macro_sent: 0.5011473108432628
train_precision_micro_sent: 0.6566011235955056
train_recall_micro_sent: 0.6566011235955056
train_f-score_micro_sent: 0.6566011235955056
train_label=O_precision_tok: 0.8948956294846706
train_label=O_recall_tok: 0.970871834463236
train_label=O_f-score_tok: 0.9313368125870295
train_label=N_precision_tok: 0.7783653400129882
train_label=N_recall_tok: 0.5907618645261231
train_label=N_f-score_tok: 0.6717104999799849
train_label=P_precision_tok: 0.8699323379746128
train_label=P_recall_tok: 0.6218571371467402
train_label=P_f-score_tok: 0.7252680652680652
train_precision_macro_tok: 0.8477311024907572
train_recall_macro_tok: 0.7278302787120331
train_f-score_macro_tok: 0.7761051259450266
train_precision_micro_tok: 0.8844869960749789
train_recall_micro_tok: 0.8844869960749789
train_f-score_micro_tok: 0.8844869960749789
train_time: 96.01838183403015
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4898    0.0296    0.0557      1624
           N     0.6249    0.8172    0.7082      3310
           P     0.6940    0.7914    0.7395      3610

   micro avg     0.6566    0.6566    0.6566      8544
   macro avg     0.6029    0.5461    0.5011      8544
weighted avg     0.6284    0.6566    0.5974      8544

F1-macro sent:  0.5011473108432628
F1-micro sent:  0.6566011235955056
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9709    0.9313    124347
           N     0.7784    0.5908    0.6717     14202
           P     0.8699    0.6219    0.7253     25017

   micro avg     0.8845    0.8845    0.8845    163566
   macro avg     0.8477    0.7278    0.7761    163566
weighted avg     0.8810    0.8845    0.8773    163566

F1-macro tok:  0.7761051259450266
F1-micro tok:  0.8844869960749789
**************************************************
dev_cost_sum: 43456.36248779297
dev_cost_avg: 39.469902350402336
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 18992.0
dev_accuracy_tok: 0.8927329134154367
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6216666666666667
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7256809338521402
dev_label=P_precision_sent: 0.6904276985743381
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.725133689839572
dev_precision_macro_sent: 0.7040314550803349
dev_recall_macro_sent: 0.556647779477637
dev_f-score_macro_sent: 0.5059200767954243
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.8957311227654655
dev_label=O_recall_tok: 0.9801912989817957
dev_label=O_f-score_tok: 0.9360598738876775
dev_label=N_precision_tok: 0.7941176470588235
dev_label=N_recall_tok: 0.5815831987075929
dev_label=N_f-score_tok: 0.671433012123096
dev_label=P_precision_tok: 0.9298486932599724
dev_label=P_recall_tok: 0.6313823163138231
dev_label=P_f-score_tok: 0.7520860374559614
dev_precision_macro_tok: 0.8732324876947538
dev_recall_macro_tok: 0.7310522713344039
dev_f-score_macro_tok: 0.786526307822245
dev_precision_micro_tok: 0.8927329134154367
dev_recall_micro_tok: 0.8927329134154367
dev_f-score_micro_tok: 0.8927329134154367
dev_time: 4.983869314193726
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6217    0.8715    0.7257       428
           P     0.6904    0.7635    0.7251       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.7040    0.5566    0.5059      1101
weighted avg     0.6865    0.6540    0.5884      1101

F1-macro sent:  0.5059200767954243
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8957    0.9802    0.9361     16205
           N     0.7941    0.5816    0.6714      1857
           P     0.9298    0.6314    0.7521      3212

   micro avg     0.8927    0.8927    0.8927     21274
   macro avg     0.8732    0.7311    0.7865     21274
weighted avg     0.8920    0.8927    0.8852     21274

F1-macro tok:  0.786526307822245
F1-micro tok:  0.8927329134154367
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 321781.4465332031
train_cost_avg: 37.66168615791235
train_count_sent: 8544.0
train_total_correct_sent: 5612.0
train_accuracy_sent: 0.6568352059925093
train_count_tok: 163566.0
train_total_correct_tok: 144966.0
train_accuracy_tok: 0.8862844356406588
train_label=O_precision_sent: 0.4748201438848921
train_label=O_recall_sent: 0.04064039408866995
train_label=O_f-score_sent: 0.07487237663074305
train_label=N_precision_sent: 0.6259111215612508
train_label=N_recall_sent: 0.8042296072507553
train_label=N_f-score_sent: 0.7039534576226366
train_label=P_precision_sent: 0.6946050096339114
train_label=P_recall_sent: 0.7988919667590028
train_label=P_f-score_sent: 0.7431074465343983
train_precision_macro_sent: 0.5984454250266847
train_recall_macro_sent: 0.5479206560328094
train_f-score_macro_sent: 0.5073110935959261
train_precision_micro_sent: 0.6568352059925093
train_recall_micro_sent: 0.6568352059925093
train_f-score_micro_sent: 0.6568352059925093
train_label=O_precision_tok: 0.896839541377057
train_label=O_recall_tok: 0.9712498090022277
train_label=O_f-score_tok: 0.9325627096918665
train_label=N_precision_tok: 0.7787602468453533
train_label=N_recall_tok: 0.5953386846922969
train_label=N_f-score_tok: 0.6748074544075982
train_label=P_precision_tok: 0.8722083679689665
train_label=P_recall_tok: 0.6291321901107247
train_label=P_f-score_tok: 0.730992522409549
train_precision_macro_tok: 0.8492693853971257
train_recall_macro_tok: 0.7319068946017498
train_f-score_macro_tok: 0.7794542288363379
train_precision_micro_tok: 0.8862844356406588
train_recall_micro_tok: 0.8862844356406588
train_f-score_micro_tok: 0.8862844356406588
train_time: 95.99658131599426
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4748    0.0406    0.0749      1624
           N     0.6259    0.8042    0.7040      3310
           P     0.6946    0.7989    0.7431      3610

   micro avg     0.6568    0.6568    0.6568      8544
   macro avg     0.5984    0.5479    0.5073      8544
weighted avg     0.6262    0.6568    0.6009      8544

F1-macro sent:  0.5073110935959261
F1-micro sent:  0.6568352059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8968    0.9712    0.9326    124347
           N     0.7788    0.5953    0.6748     14202
           P     0.8722    0.6291    0.7310     25017

   micro avg     0.8863    0.8863    0.8863    163566
   macro avg     0.8493    0.7319    0.7795    163566
weighted avg     0.8828    0.8863    0.8794    163566

F1-macro tok:  0.7794542288363379
F1-micro tok:  0.8862844356406588
**************************************************
dev_cost_sum: 43351.1865234375
dev_cost_avg: 39.374374680688014
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 19007.0
dev_accuracy_tok: 0.8934379994359312
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.6455938697318008
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.7094736842105265
dev_label=P_precision_sent: 0.6462346760070052
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7270935960591133
dev_precision_macro_sent: 0.6806095152462687
dev_recall_macro_sent: 0.5482217106712066
dev_f-score_macro_sent: 0.49573339722068166
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.8974083295608872
dev_label=O_recall_tok: 0.9786485652576365
dev_label=O_f-score_tok: 0.9362694453464001
dev_label=N_precision_tok: 0.8069120961682945
dev_label=N_recall_tok: 0.5783521809369951
dev_label=N_f-score_tok: 0.6737766624843162
dev_label=P_precision_tok: 0.9132540730955526
dev_label=P_recall_tok: 0.6457036114570361
dev_label=P_f-score_tok: 0.7565201532008026
dev_precision_macro_tok: 0.8725248329415781
dev_recall_macro_tok: 0.7342347858838894
dev_f-score_macro_tok: 0.7888554203438396
dev_precision_micro_tok: 0.8934379994359312
dev_recall_micro_tok: 0.8934379994359312
dev_f-score_micro_tok: 0.8934379994359312
dev_time: 5.100069761276245
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.6456    0.7874    0.7095       428
           P     0.6462    0.8311    0.7271       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.6806    0.5482    0.4957      1101
weighted avg     0.6676    0.6467    0.5795      1101

F1-macro sent:  0.49573339722068166
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8974    0.9786    0.9363     16205
           N     0.8069    0.5784    0.6738      1857
           P     0.9133    0.6457    0.7565      3212

   micro avg     0.8934    0.8934    0.8934     21274
   macro avg     0.8725    0.7342    0.7889     21274
weighted avg     0.8919    0.8934    0.8862     21274

F1-macro tok:  0.7888554203438396
F1-micro tok:  0.8934379994359312
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 320146.0787963867
train_cost_avg: 37.470280758004066
train_count_sent: 8544.0
train_total_correct_sent: 5661.0
train_accuracy_sent: 0.6625702247191011
train_count_tok: 163566.0
train_total_correct_tok: 145114.0
train_accuracy_tok: 0.8871892691635181
train_label=O_precision_sent: 0.5384615384615384
train_label=O_recall_sent: 0.04741379310344827
train_label=O_f-score_sent: 0.08715336728919071
train_label=N_precision_sent: 0.629153018249883
train_label=N_recall_sent: 0.8123867069486405
train_label=N_f-score_sent: 0.7091244725738396
train_label=P_precision_sent: 0.7014780712381875
train_label=P_recall_sent: 0.8019390581717452
train_label=P_f-score_sent: 0.7483520744474602
train_precision_macro_sent: 0.623030875983203
train_recall_macro_sent: 0.5539131860746113
train_f-score_macro_sent: 0.5148766381034968
train_precision_micro_sent: 0.6625702247191011
train_recall_micro_sent: 0.6625702247191011
train_f-score_micro_sent: 0.6625702247191011
train_label=O_precision_tok: 0.8977496598841748
train_label=O_recall_tok: 0.9711452628531448
train_label=O_f-score_tok: 0.9330062582090706
train_label=N_precision_tok: 0.7814123006833713
train_label=N_recall_tok: 0.6038586114631742
train_label=N_f-score_tok: 0.6812567025459745
train_label=P_precision_tok: 0.872828852749198
train_label=P_recall_tok: 0.630731102850062
train_label=P_f-score_tok: 0.7322891286692192
train_precision_macro_tok: 0.8506636044389148
train_recall_macro_tok: 0.7352449923887937
train_f-score_macro_tok: 0.7821840298080881
train_precision_micro_tok: 0.8871892691635181
train_recall_micro_tok: 0.8871892691635181
train_f-score_micro_tok: 0.8871892691635181
train_time: 96.21038699150085
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0474    0.0872      1624
           N     0.6292    0.8124    0.7091      3310
           P     0.7015    0.8019    0.7484      3610

   micro avg     0.6626    0.6626    0.6626      8544
   macro avg     0.6230    0.5539    0.5149      8544
weighted avg     0.6425    0.6626    0.6075      8544

F1-macro sent:  0.5148766381034968
F1-micro sent:  0.6625702247191011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8977    0.9711    0.9330    124347
           N     0.7814    0.6039    0.6813     14202
           P     0.8728    0.6307    0.7323     25017

   micro avg     0.8872    0.8872    0.8872    163566
   macro avg     0.8507    0.7352    0.7822    163566
weighted avg     0.8838    0.8872    0.8804    163566

F1-macro tok:  0.7821840298080881
F1-micro tok:  0.8871892691635181
**************************************************
dev_cost_sum: 43089.226135253906
dev_cost_avg: 39.136445172801004
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19040.0
dev_accuracy_tok: 0.8949891886810191
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6373239436619719
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7269076305220883
dev_label=P_precision_sent: 0.6793168880455408
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.737384140061792
dev_precision_macro_sent: 0.6611024994580598
dev_recall_macro_sent: 0.5565226492459893
dev_f-score_macro_sent: 0.4994447745917899
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8989343611835393
dev_label=O_recall_tok: 0.9786485652576365
dev_label=O_f-score_tok: 0.9370992997902325
dev_label=N_precision_tok: 0.8051470588235294
dev_label=N_recall_tok: 0.5896607431340872
dev_label=N_f-score_tok: 0.6807584706248057
dev_label=P_precision_tok: 0.9181338028169014
dev_label=P_recall_tok: 0.6494396014943961
dev_label=P_f-score_tok: 0.7607585703865792
dev_precision_macro_tok: 0.8740717409413233
dev_recall_macro_tok: 0.7392496366287067
dev_f-score_macro_tok: 0.7928721136005392
dev_precision_micro_tok: 0.8949891886810191
dev_recall_micro_tok: 0.8949891886810191
dev_f-score_micro_tok: 0.8949891886810191
dev_time: 5.293179035186768
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6373    0.8458    0.7269       428
           P     0.6793    0.8063    0.7374       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6611    0.5565    0.4994      1101
weighted avg     0.6604    0.6576    0.5870      1101

F1-macro sent:  0.4994447745917899
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9786    0.9371     16205
           N     0.8051    0.5897    0.6808      1857
           P     0.9181    0.6494    0.7608      3212

   micro avg     0.8950    0.8950    0.8950     21274
   macro avg     0.8741    0.7392    0.7929     21274
weighted avg     0.8936    0.8950    0.8881     21274

F1-macro tok:  0.7928721136005392
F1-micro tok:  0.8949891886810191
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 0.900000
train_cost_sum: 318075.4866333008
train_cost_avg: 37.2279361696279
train_count_sent: 8544.0
train_total_correct_sent: 5689.0
train_accuracy_sent: 0.6658473782771536
train_count_tok: 163566.0
train_total_correct_tok: 145414.0
train_accuracy_tok: 0.889023391169314
train_label=O_precision_sent: 0.5546875
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.08105022831050228
train_label=N_precision_sent: 0.6386270244138265
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.7095474687793742
train_label=P_precision_sent: 0.6954896003739192
train_label=P_recall_sent: 0.824376731301939
train_label=P_f-score_sent: 0.7544682469260996
train_precision_macro_sent: 0.6296013749292486
train_recall_macro_sent: 0.5554277514342822
train_f-score_macro_sent: 0.5150219813386587
train_precision_micro_sent: 0.6658473782771536
train_recall_micro_sent: 0.6658473782771536
train_f-score_micro_sent: 0.6658473782771536
train_label=O_precision_tok: 0.9001245367159594
train_label=O_recall_tok: 0.9707029522224099
train_label=O_f-score_tok: 0.9340824317840616
train_label=N_precision_tok: 0.7807716408557873
train_label=N_recall_tok: 0.6141388536825799
train_label=N_f-score_tok: 0.6875024632483349
train_label=P_precision_tok: 0.8737566947207345
train_label=P_recall_tok: 0.6390854219130991
train_label=P_f-score_tok: 0.7382200161606833
train_precision_macro_tok: 0.8515509574308271
train_recall_macro_tok: 0.741309075939363
train_f-score_macro_tok: 0.7866016370643599
train_precision_micro_tok: 0.889023391169314
train_recall_micro_tok: 0.889023391169314
train_f-score_micro_tok: 0.889023391169314
train_time: 96.2452986240387
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5547    0.0437    0.0811      1624
           N     0.6386    0.7982    0.7095      3310
           P     0.6955    0.8244    0.7545      3610

   micro avg     0.6658    0.6658    0.6658      8544
   macro avg     0.6296    0.5554    0.5150      8544
weighted avg     0.6467    0.6658    0.6091      8544

F1-macro sent:  0.5150219813386587
F1-micro sent:  0.6658473782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9001    0.9707    0.9341    124347
           N     0.7808    0.6141    0.6875     14202
           P     0.8738    0.6391    0.7382     25017

   micro avg     0.8890    0.8890    0.8890    163566
   macro avg     0.8516    0.7413    0.7866    163566
weighted avg     0.8857    0.8890    0.8827    163566

F1-macro tok:  0.7866016370643599
F1-micro tok:  0.889023391169314
**************************************************
dev_cost_sum: 43103.508361816406
dev_cost_avg: 39.149417222358224
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 19015.0
dev_accuracy_tok: 0.8938140453135283
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.6554455445544555
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7095391211146839
dev_label=P_precision_sent: 0.6495726495726496
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7385811467444121
dev_precision_macro_sent: 0.6471272768302471
dev_recall_macro_sent: 0.5532626758088947
dev_f-score_macro_sent: 0.5021512003974764
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.8947605127051945
dev_label=O_recall_tok: 0.9821659981487195
dev_label=O_f-score_tok: 0.9364280881357927
dev_label=N_precision_tok: 0.8346972176759411
dev_label=N_recall_tok: 0.5492730210016155
dev_label=N_f-score_tok: 0.662552776875609
dev_label=P_precision_tok: 0.9182862190812721
dev_label=P_recall_tok: 0.6472602739726028
dev_label=P_f-score_tok: 0.7593133674214755
dev_precision_macro_tok: 0.8825813164874692
dev_recall_macro_tok: 0.7262330977076458
dev_f-score_macro_tok: 0.7860980774776257
dev_precision_micro_tok: 0.8938140453135283
dev_recall_micro_tok: 0.8938140453135283
dev_f-score_micro_tok: 0.8938140453135283
dev_time: 5.115814685821533
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.6554    0.7734    0.7095       428
           P     0.6496    0.8559    0.7386       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.6471    0.5533    0.5022      1101
weighted avg     0.6491    0.6521    0.5858      1101

F1-macro sent:  0.5021512003974764
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9822    0.9364     16205
           N     0.8347    0.5493    0.6626      1857
           P     0.9183    0.6473    0.7593      3212

   micro avg     0.8938    0.8938    0.8938     21274
   macro avg     0.8826    0.7262    0.7861     21274
weighted avg     0.8931    0.8938    0.8858     21274

F1-macro tok:  0.7860980774776257
F1-micro tok:  0.8938140453135283
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 0.900000
train_cost_sum: 316335.6390991211
train_cost_avg: 37.02430232901698
train_count_sent: 8544.0
train_total_correct_sent: 5707.0
train_accuracy_sent: 0.6679541198501873
train_count_tok: 163566.0
train_total_correct_tok: 145629.0
train_accuracy_tok: 0.8903378452734676
train_label=O_precision_sent: 0.5022222222222222
train_label=O_recall_sent: 0.06958128078817734
train_label=O_f-score_sent: 0.12222823147647376
train_label=N_precision_sent: 0.6469298245614035
train_label=N_recall_sent: 0.8021148036253777
train_label=N_f-score_sent: 0.7162125708119774
train_label=P_precision_sent: 0.6972716488730724
train_label=P_recall_sent: 0.8141274238227146
train_label=P_f-score_sent: 0.7511821086261979
train_precision_macro_sent: 0.6154745652188994
train_recall_macro_sent: 0.5619411694120898
train_f-score_macro_sent: 0.5298743036382164
train_precision_micro_sent: 0.6679541198501873
train_recall_micro_sent: 0.6679541198501873
train_f-score_micro_sent: 0.6679541198501873
train_label=O_precision_tok: 0.9010295434198746
train_label=O_recall_tok: 0.9712658930251634
train_label=O_f-score_tok: 0.934830312670529
train_label=N_precision_tok: 0.7861459366826012
train_label=N_recall_tok: 0.6137163779749331
train_label=N_f-score_tok: 0.6893115583850685
train_label=P_precision_tok: 0.8752643852703509
train_label=P_recall_tok: 0.6451213175040972
train_label=P_f-score_tok: 0.7427743004418262
train_precision_macro_tok: 0.8541466217909423
train_recall_macro_tok: 0.7433678628347312
train_f-score_macro_tok: 0.7889720571658079
train_precision_micro_tok: 0.8903378452734676
train_recall_micro_tok: 0.8903378452734676
train_f-score_micro_tok: 0.8903378452734676
train_time: 96.7243766784668
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5022    0.0696    0.1222      1624
           N     0.6469    0.8021    0.7162      3310
           P     0.6973    0.8141    0.7512      3610

   micro avg     0.6680    0.6680    0.6680      8544
   macro avg     0.6155    0.5619    0.5299      8544
weighted avg     0.6407    0.6680    0.6181      8544

F1-macro sent:  0.5298743036382164
F1-micro sent:  0.6679541198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9010    0.9713    0.9348    124347
           N     0.7861    0.6137    0.6893     14202
           P     0.8753    0.6451    0.7428     25017

   micro avg     0.8903    0.8903    0.8903    163566
   macro avg     0.8541    0.7434    0.7890    163566
weighted avg     0.8871    0.8903    0.8841    163566

F1-macro tok:  0.7889720571658079
F1-micro tok:  0.8903378452734676
**************************************************
dev_cost_sum: 42827.69079589844
dev_cost_avg: 38.898901721978596
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19046.0
dev_accuracy_tok: 0.8952712230892169
dev_label=O_precision_sent: 0.8235294117647058
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.1138211382113821
dev_label=N_precision_sent: 0.6147672552166934
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7288296860133207
dev_label=P_precision_sent: 0.7288503253796096
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7425414364640884
dev_precision_macro_sent: 0.7223823307870029
dev_recall_macro_sent: 0.5709173136733027
dev_f-score_macro_sent: 0.528397420229597
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.8997048473152458
dev_label=O_recall_tok: 0.9781548904659055
dev_label=O_f-score_tok: 0.9372911923838808
dev_label=N_precision_tok: 0.8147871545929798
dev_label=N_recall_tok: 0.5875067312870221
dev_label=N_f-score_tok: 0.6827284105131414
dev_label=P_precision_tok: 0.9080707811825637
dev_label=P_recall_tok: 0.6550435865504358
dev_label=P_f-score_tok: 0.7610779526134925
dev_precision_macro_tok: 0.8741875943635963
dev_recall_macro_tok: 0.7402350694344545
dev_f-score_macro_tok: 0.7936991851701715
dev_precision_micro_tok: 0.8952712230892169
dev_recall_micro_tok: 0.8952712230892169
dev_f-score_micro_tok: 0.8952712230892169
dev_time: 5.1607935428619385
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8235    0.0611    0.1138       229
           N     0.6148    0.8949    0.7288       428
           P     0.7289    0.7568    0.7425       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.7224    0.5709    0.5284      1101
weighted avg     0.7042    0.6658    0.6064      1101

F1-macro sent:  0.528397420229597
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8997    0.9782    0.9373     16205
           N     0.8148    0.5875    0.6827      1857
           P     0.9081    0.6550    0.7611      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8742    0.7402    0.7937     21274
weighted avg     0.8936    0.8953    0.8885     21274

F1-macro tok:  0.7936991851701715
F1-micro tok:  0.8952712230892169
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 315086.9298095703
train_cost_avg: 36.878151897187536
train_count_sent: 8544.0
train_total_correct_sent: 5704.0
train_accuracy_sent: 0.6676029962546817
train_count_tok: 163566.0
train_total_correct_tok: 145795.0
train_accuracy_tok: 0.8913527261166746
train_label=O_precision_sent: 0.532608695652174
train_label=O_recall_sent: 0.0603448275862069
train_label=O_f-score_sent: 0.10840707964601771
train_label=N_precision_sent: 0.6409090909090909
train_label=N_recall_sent: 0.8093655589123867
train_label=N_f-score_sent: 0.7153538050734313
train_label=P_precision_sent: 0.7002392344497608
train_label=P_recall_sent: 0.810803324099723
train_label=P_f-score_sent: 0.7514762516046213
train_precision_macro_sent: 0.6245856736703419
train_recall_macro_sent: 0.5601712368661055
train_f-score_macro_sent: 0.5250790454413568
train_precision_micro_sent: 0.6676029962546817
train_recall_micro_sent: 0.6676029962546817
train_f-score_micro_sent: 0.6676029962546817
train_label=O_precision_tok: 0.9018280348438817
train_label=O_recall_tok: 0.9716116995182835
train_label=O_f-score_tok: 0.9354201830316357
train_label=N_precision_tok: 0.7876527677929547
train_label=N_recall_tok: 0.6171665962540487
train_label=N_f-score_tok: 0.6920647453612316
train_label=P_precision_tok: 0.8778493692132763
train_label=P_recall_tok: 0.6480793060718711
train_label=P_f-score_tok: 0.7456652715816584
train_precision_macro_tok: 0.8557767239500377
train_recall_macro_tok: 0.7456192006147345
train_f-score_macro_tok: 0.7910500666581752
train_precision_micro_tok: 0.8913527261166746
train_recall_micro_tok: 0.8913527261166746
train_f-score_micro_tok: 0.8913527261166745
train_time: 96.11762714385986
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5326    0.0603    0.1084      1624
           N     0.6409    0.8094    0.7154      3310
           P     0.7002    0.8108    0.7515      3610

   micro avg     0.6676    0.6676    0.6676      8544
   macro avg     0.6246    0.5602    0.5251      8544
weighted avg     0.6454    0.6676    0.6153      8544

F1-macro sent:  0.5250790454413568
F1-micro sent:  0.6676029962546817
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9716    0.9354    124347
           N     0.7877    0.6172    0.6921     14202
           P     0.8778    0.6481    0.7457     25017

   micro avg     0.8914    0.8914    0.8914    163566
   macro avg     0.8558    0.7456    0.7911    163566
weighted avg     0.8882    0.8914    0.8853    163566

F1-macro tok:  0.7910500666581752
F1-micro tok:  0.8913527261166745
**************************************************
dev_cost_sum: 42740.34387207031
dev_cost_avg: 38.81956754956432
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19053.0
dev_accuracy_tok: 0.8956002632321143
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6659919028340081
dev_label=N_recall_sent: 0.7686915887850467
dev_label=N_f-score_sent: 0.7136659436008675
dev_label=P_precision_sent: 0.6423841059602649
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7404580152671755
dev_precision_macro_sent: 0.6583475584869799
dev_recall_macro_sent: 0.5504330290376896
dev_f-score_macro_sent: 0.49045511272612935
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.9033144427271166
dev_label=O_recall_tok: 0.9737735266892934
dev_label=O_f-score_tok: 0.9372215952960741
dev_label=N_precision_tok: 0.7960199004975125
dev_label=N_recall_tok: 0.6031233171782445
dev_label=N_f-score_tok: 0.6862745098039216
dev_label=P_precision_tok: 0.8978315262718932
dev_label=P_recall_tok: 0.6702988792029888
dev_label=P_f-score_tok: 0.7675579322638145
dev_precision_macro_tok: 0.8657219564988408
dev_recall_macro_tok: 0.7490652410235089
dev_f-score_macro_tok: 0.7970180124546035
dev_precision_micro_tok: 0.8956002632321143
dev_recall_micro_tok: 0.8956002632321143
dev_f-score_micro_tok: 0.8956002632321143
dev_time: 5.12099027633667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6660    0.7687    0.7137       428
           P     0.6424    0.8739    0.7405       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.6583    0.5504    0.4905      1101
weighted avg     0.6566    0.6530    0.5796      1101

F1-macro sent:  0.49045511272612935
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9033    0.9738    0.9372     16205
           N     0.7960    0.6031    0.6863      1857
           P     0.8978    0.6703    0.7676      3212

   micro avg     0.8956    0.8956    0.8956     21274
   macro avg     0.8657    0.7491    0.7970     21274
weighted avg     0.8931    0.8956    0.8897     21274

F1-macro tok:  0.7970180124546035
F1-micro tok:  0.8956002632321143
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 0.900000
train_cost_sum: 313226.21270751953
train_cost_avg: 36.66037133749058
train_count_sent: 8544.0
train_total_correct_sent: 5717.0
train_accuracy_sent: 0.669124531835206
train_count_tok: 163566.0
train_total_correct_tok: 146223.0
train_accuracy_tok: 0.8939694068449433
train_label=O_precision_sent: 0.47085201793721976
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.1136978884677856
train_label=N_precision_sent: 0.6440880804212542
train_label=N_recall_sent: 0.8129909365558913
train_label=N_f-score_sent: 0.71875
train_label=P_precision_sent: 0.7050446536326334
train_label=P_recall_sent: 0.8091412742382271
train_label=P_f-score_sent: 0.7535147684767187
train_precision_macro_sent: 0.6066615839970358
train_recall_macro_sent: 0.5622624610693038
train_f-score_macro_sent: 0.5286542189815014
train_precision_micro_sent: 0.669124531835206
train_recall_micro_sent: 0.669124531835206
train_f-score_micro_sent: 0.669124531835206
train_label=O_precision_tok: 0.9047430090218246
train_label=O_recall_tok: 0.9718127498049812
train_label=O_f-score_tok: 0.9370793138744998
train_label=N_precision_tok: 0.7942299156679983
train_label=N_recall_tok: 0.6299816927193354
train_label=N_f-score_tok: 0.702634782267248
train_label=P_precision_tok: 0.877134927412468
train_label=P_recall_tok: 0.6569132989567095
train_label=P_f-score_tok: 0.751217059401641
train_precision_macro_tok: 0.8587026173674303
train_recall_macro_tok: 0.7529025804936754
train_f-score_macro_tok: 0.7969770518477963
train_precision_micro_tok: 0.8939694068449433
train_recall_micro_tok: 0.8939694068449433
train_f-score_micro_tok: 0.8939694068449433
train_time: 96.56864905357361
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4709    0.0647    0.1137      1624
           N     0.6441    0.8130    0.7188      3310
           P     0.7050    0.8091    0.7535      3610

   micro avg     0.6691    0.6691    0.6691      8544
   macro avg     0.6067    0.5623    0.5287      8544
weighted avg     0.6369    0.6691    0.6184      8544

F1-macro sent:  0.5286542189815014
F1-micro sent:  0.669124531835206
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9047    0.9718    0.9371    124347
           N     0.7942    0.6300    0.7026     14202
           P     0.8771    0.6569    0.7512     25017

   micro avg     0.8940    0.8940    0.8940    163566
   macro avg     0.8587    0.7529    0.7970    163566
weighted avg     0.8909    0.8940    0.8883    163566

F1-macro tok:  0.7969770518477963
F1-micro tok:  0.8939694068449433
**************************************************
dev_cost_sum: 42648.00671386719
dev_cost_avg: 38.735700920860296
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19088.0
dev_accuracy_tok: 0.8972454639466015
dev_label=O_precision_sent: 0.7857142857142857
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09053497942386832
dev_label=N_precision_sent: 0.6892778993435449
dev_label=N_recall_sent: 0.735981308411215
dev_label=N_f-score_sent: 0.711864406779661
dev_label=P_precision_sent: 0.6253968253968254
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.7337057728119181
dev_precision_macro_sent: 0.700129670151552
dev_recall_macro_sent: 0.5571345434321396
dev_f-score_macro_sent: 0.5120350530051492
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.902519667084711
dev_label=O_recall_tok: 0.9769824128355445
dev_label=O_f-score_tok: 0.9382759949032506
dev_label=N_precision_tok: 0.8056562726613488
dev_label=N_recall_tok: 0.5982767905223478
dev_label=N_f-score_tok: 0.6866501854140914
dev_label=P_precision_tok: 0.9116022099447514
dev_label=P_recall_tok: 0.6678082191780822
dev_label=P_f-score_tok: 0.77088948787062
dev_precision_macro_tok: 0.8732593832302703
dev_recall_macro_tok: 0.7476891408453249
dev_f-score_macro_tok: 0.7986052227293207
dev_precision_micro_tok: 0.8972454639466015
dev_recall_micro_tok: 0.8972454639466015
dev_f-score_micro_tok: 0.8972454639466015
dev_time: 5.1596903800964355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7857    0.0480    0.0905       229
           N     0.6893    0.7360    0.7119       428
           P     0.6254    0.8874    0.7337       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.7001    0.5571    0.5120      1101
weighted avg     0.6836    0.6540    0.5914      1101

F1-macro sent:  0.5120350530051492
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9770    0.9383     16205
           N     0.8057    0.5983    0.6867      1857
           P     0.9116    0.6678    0.7709      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8733    0.7477    0.7986     21274
weighted avg     0.8954    0.8972    0.8910     21274

F1-macro tok:  0.7986052227293207
F1-micro tok:  0.8972454639466015
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 311519.7901611328
train_cost_avg: 36.460649597510866
train_count_sent: 8544.0
train_total_correct_sent: 5772.0
train_accuracy_sent: 0.675561797752809
train_count_tok: 163566.0
train_total_correct_tok: 146464.0
train_accuracy_tok: 0.8954428181895993
train_label=O_precision_sent: 0.4673913043478261
train_label=O_recall_sent: 0.07943349753694581
train_label=O_f-score_sent: 0.13578947368421054
train_label=N_precision_sent: 0.6559960600837232
train_label=N_recall_sent: 0.804833836858006
train_label=N_f-score_sent: 0.7228327228327229
train_label=P_precision_sent: 0.7081055383884003
train_label=P_recall_sent: 0.8252077562326869
train_label=P_f-score_sent: 0.7621849814506844
train_precision_macro_sent: 0.6104976342733165
train_recall_macro_sent: 0.5698250302092129
train_f-score_macro_sent: 0.5402690593225393
train_precision_micro_sent: 0.675561797752809
train_recall_micro_sent: 0.675561797752809
train_f-score_micro_sent: 0.675561797752809
train_label=O_precision_tok: 0.9066067260569035
train_label=O_recall_tok: 0.9714669433118611
train_label=O_f-score_tok: 0.9379168445980045
train_label=N_precision_tok: 0.7956556012963125
train_label=N_recall_tok: 0.6396282213772708
train_label=N_f-score_tok: 0.7091611694445529
train_label=P_precision_tok: 0.8770231672484925
train_label=P_recall_tok: 0.6627893032737738
train_label=P_f-score_tok: 0.7550030735605491
train_precision_macro_tok: 0.8597618315339028
train_recall_macro_tok: 0.7579614893209685
train_f-score_macro_tok: 0.8006936958677021
train_precision_micro_tok: 0.8954428181895993
train_recall_micro_tok: 0.8954428181895993
train_f-score_micro_tok: 0.8954428181895993
train_time: 96.94807410240173
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4674    0.0794    0.1358      1624
           N     0.6560    0.8048    0.7228      3310
           P     0.7081    0.8252    0.7622      3610

   micro avg     0.6756    0.6756    0.6756      8544
   macro avg     0.6105    0.5698    0.5403      8544
weighted avg     0.6422    0.6756    0.6279      8544

F1-macro sent:  0.5402690593225393
F1-micro sent:  0.675561797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9066    0.9715    0.9379    124347
           N     0.7957    0.6396    0.7092     14202
           P     0.8770    0.6628    0.7550     25017

   micro avg     0.8954    0.8954    0.8954    163566
   macro avg     0.8598    0.7580    0.8007    163566
weighted avg     0.8924    0.8954    0.8901    163566

F1-macro tok:  0.8006936958677021
F1-micro tok:  0.8954428181895993
**************************************************
dev_cost_sum: 42506.590576171875
dev_cost_avg: 38.607257562372276
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19115.0
dev_accuracy_tok: 0.8985146187834916
dev_label=O_precision_sent: 0.56
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11023622047244093
dev_label=N_precision_sent: 0.6324786324786325
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7305034550839092
dev_label=P_precision_sent: 0.7169042769857433
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7529411764705882
dev_precision_macro_sent: 0.6364609698214586
dev_recall_macro_sent: 0.5728047150934145
dev_f-score_macro_sent: 0.5312269506756461
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9044298370963132
dev_label=O_recall_tok: 0.9764270286948473
dev_label=O_f-score_tok: 0.9390504451038576
dev_label=N_precision_tok: 0.8151935719503287
dev_label=N_recall_tok: 0.6009693053311793
dev_label=N_f-score_tok: 0.6918784872907625
dev_label=P_precision_tok: 0.9029045643153527
dev_label=P_recall_tok: 0.6774595267745953
dev_label=P_f-score_tok: 0.7741017431519034
dev_precision_macro_tok: 0.8741759911206648
dev_recall_macro_tok: 0.751618620266874
dev_f-score_macro_tok: 0.8016768918488412
dev_precision_micro_tok: 0.8985146187834916
dev_recall_micro_tok: 0.8985146187834916
dev_f-score_micro_tok: 0.8985146187834916
dev_time: 5.135812282562256
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5600    0.0611    0.1102       229
           N     0.6325    0.8645    0.7305       428
           P     0.7169    0.7928    0.7529       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6365    0.5728    0.5312      1101
weighted avg     0.6514    0.6685    0.6105      1101

F1-macro sent:  0.5312269506756461
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9044    0.9764    0.9391     16205
           N     0.8152    0.6010    0.6919      1857
           P     0.9029    0.6775    0.7741      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8742    0.7516    0.8017     21274
weighted avg     0.8964    0.8985    0.8926     21274

F1-macro tok:  0.8016768918488412
F1-micro tok:  0.8985146187834916
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 310030.39111328125
train_cost_avg: 36.28632854790277
train_count_sent: 8544.0
train_total_correct_sent: 5805.0
train_accuracy_sent: 0.6794241573033708
train_count_tok: 163566.0
train_total_correct_tok: 146697.0
train_accuracy_tok: 0.8968673196141007
train_label=O_precision_sent: 0.5094339622641509
train_label=O_recall_sent: 0.08312807881773399
train_label=O_f-score_sent: 0.142932768660667
train_label=N_precision_sent: 0.6508393285371703
train_label=N_recall_sent: 0.8199395770392749
train_label=N_f-score_sent: 0.7256684491978611
train_label=P_precision_sent: 0.7193964468240448
train_label=P_recall_sent: 0.8188365650969529
train_label=P_f-score_sent: 0.7659023189532322
train_precision_macro_sent: 0.6265565792084554
train_recall_macro_sent: 0.5739680736513205
train_f-score_macro_sent: 0.5448345122705868
train_precision_micro_sent: 0.6794241573033708
train_recall_micro_sent: 0.6794241573033708
train_f-score_micro_sent: 0.6794241573033708
train_label=O_precision_tok: 0.9077753747259019
train_label=O_recall_tok: 0.9721424722751655
train_label=O_f-score_tok: 0.9388569808668367
train_label=N_precision_tok: 0.7956745443446411
train_label=N_recall_tok: 0.6424447260949162
train_label=N_f-score_tok: 0.710896412014492
train_label=P_precision_tok: 0.8814364932664378
train_label=P_recall_tok: 0.6671463404884679
train_label=P_f-score_tok: 0.7594648707681106
train_precision_macro_tok: 0.8616288041123269
train_recall_macro_tok: 0.7605778462861833
train_f-score_macro_tok: 0.8030727545498131
train_precision_micro_tok: 0.8968673196141007
train_recall_micro_tok: 0.8968673196141007
train_f-score_micro_tok: 0.8968673196141007
train_time: 96.34292984008789
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5094    0.0831    0.1429      1624
           N     0.6508    0.8199    0.7257      3310
           P     0.7194    0.8188    0.7659      3610

   micro avg     0.6794    0.6794    0.6794      8544
   macro avg     0.6266    0.5740    0.5448      8544
weighted avg     0.6529    0.6794    0.6319      8544

F1-macro sent:  0.5448345122705868
F1-micro sent:  0.6794241573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9078    0.9721    0.9389    124347
           N     0.7957    0.6424    0.7109     14202
           P     0.8814    0.6671    0.7595     25017

   micro avg     0.8969    0.8969    0.8969    163566
   macro avg     0.8616    0.7606    0.8031    163566
weighted avg     0.8940    0.8969    0.8916    163566

F1-macro tok:  0.8030727545498131
F1-micro tok:  0.8968673196141007
**************************************************
dev_cost_sum: 42357.421875
dev_cost_avg: 38.47177282016349
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19096.0
dev_accuracy_tok: 0.8976215098241985
dev_label=O_precision_sent: 0.34375
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.15017064846416384
dev_label=N_precision_sent: 0.6708074534161491
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.7113062568605928
dev_label=P_precision_sent: 0.6732851985559567
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.74749498997996
dev_precision_macro_sent: 0.5626142173240353
dev_recall_macro_sent: 0.564389768293372
dev_f-score_macro_sent: 0.5363239651015722
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.9045902014652014
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.9386227989428987
dev_label=N_precision_tok: 0.8195488721804511
dev_label=N_recall_tok: 0.5869682283252557
dev_label=N_f-score_tok: 0.6840288672732977
dev_label=P_precision_tok: 0.8903721682847896
dev_label=P_recall_tok: 0.6852428393524284
dev_label=P_f-score_tok: 0.7744546094299789
dev_precision_macro_tok: 0.8715037473101473
dev_recall_macro_tok: 0.7491757760303789
dev_f-score_macro_tok: 0.7990354252153917
dev_precision_micro_tok: 0.8976215098241985
dev_recall_micro_tok: 0.8976215098241985
dev_f-score_micro_tok: 0.8976215098241985
dev_time: 5.0624799728393555
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3438    0.0961    0.1502       229
           N     0.6708    0.7570    0.7113       428
           P     0.6733    0.8401    0.7475       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.5626    0.5644    0.5363      1101
weighted avg     0.6038    0.6530    0.6092      1101

F1-macro sent:  0.5363239651015722
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9753    0.9386     16205
           N     0.8195    0.5870    0.6840      1857
           P     0.8904    0.6852    0.7745      3212

   micro avg     0.8976    0.8976    0.8976     21274
   macro avg     0.8715    0.7492    0.7990     21274
weighted avg     0.8950    0.8976    0.8916     21274

F1-macro tok:  0.7990354252153917
F1-micro tok:  0.8976215098241985
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 308473.3937988281
train_cost_avg: 36.10409571615498
train_count_sent: 8544.0
train_total_correct_sent: 5858.0
train_accuracy_sent: 0.68562734082397
train_count_tok: 163566.0
train_total_correct_tok: 146875.0
train_accuracy_tok: 0.8979555653375396
train_label=O_precision_sent: 0.507537688442211
train_label=O_recall_sent: 0.062192118226600986
train_label=O_f-score_sent: 0.11080636313768515
train_label=N_precision_sent: 0.6527549824150058
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.735049504950495
train_label=P_precision_sent: 0.7286764705882353
train_label=P_recall_sent: 0.8235457063711912
train_label=P_f-score_sent: 0.7732119635890767
train_precision_macro_sent: 0.6296563804818174
train_recall_macro_sent: 0.5756084792969478
train_f-score_macro_sent: 0.5396892772257523
train_precision_micro_sent: 0.68562734082397
train_recall_micro_sent: 0.68562734082397
train_f-score_micro_sent: 0.68562734082397
train_label=O_precision_tok: 0.9088714771257557
train_label=O_recall_tok: 0.9720298841146148
train_label=O_f-score_tok: 0.9393902889229993
train_label=N_precision_tok: 0.8001917879870979
train_label=N_recall_tok: 0.6463174200816786
train_label=N_f-score_tok: 0.7150703073267635
train_label=P_precision_tok: 0.8806720050243366
train_label=P_recall_tok: 0.6726226166206979
train_label=P_f-score_tok: 0.762714169159641
train_precision_macro_tok: 0.86324509004573
train_recall_macro_tok: 0.7636566402723304
train_f-score_macro_tok: 0.8057249218031345
train_precision_micro_tok: 0.8979555653375396
train_recall_micro_tok: 0.8979555653375396
train_f-score_micro_tok: 0.8979555653375396
train_time: 96.78721952438354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5075    0.0622    0.1108      1624
           N     0.6528    0.8411    0.7350      3310
           P     0.7287    0.8235    0.7732      3610

   micro avg     0.6856    0.6856    0.6856      8544
   macro avg     0.6297    0.5756    0.5397      8544
weighted avg     0.6572    0.6856    0.6325      8544

F1-macro sent:  0.5396892772257523
F1-micro sent:  0.68562734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9089    0.9720    0.9394    124347
           N     0.8002    0.6463    0.7151     14202
           P     0.8807    0.6726    0.7627     25017

   micro avg     0.8980    0.8980    0.8980    163566
   macro avg     0.8632    0.7637    0.8057    163566
weighted avg     0.8951    0.8980    0.8929    163566

F1-macro tok:  0.8057249218031345
F1-micro tok:  0.8979555653375396
**************************************************
dev_cost_sum: 42394.22521972656
dev_cost_avg: 38.50520001791695
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06639004149377593
dev_label=N_precision_sent: 0.6902286902286903
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7304730473047304
dev_label=P_precision_sent: 0.6414473684210527
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7414448669201521
dev_precision_macro_sent: 0.6661142417721365
dev_recall_macro_sent: 0.5630046035914705
dev_f-score_macro_sent: 0.5127693185728862
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9105629715612304
dev_label=O_recall_tok: 0.968157975933354
dev_label=O_f-score_tok: 0.9384776431882756
dev_label=N_precision_tok: 0.782145236508994
dev_label=N_recall_tok: 0.6322024771136241
dev_label=N_f-score_tok: 0.699225729600953
dev_label=P_precision_tok: 0.8737711364530083
dev_label=P_recall_tok: 0.6917808219178082
dev_label=P_f-score_tok: 0.7721980886185925
dev_precision_macro_tok: 0.8554931148410776
dev_recall_macro_tok: 0.7640470916549287
dev_f-score_macro_tok: 0.8033004871359403
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 5.0264668464660645
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0349    0.0664       229
           N     0.6902    0.7757    0.7305       428
           P     0.6414    0.8784    0.7414       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6661    0.5630    0.5128      1101
weighted avg     0.6657    0.6630    0.5968      1101

F1-macro sent:  0.5127693185728862
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9106    0.9682    0.9385     16205
           N     0.7821    0.6322    0.6992      1857
           P     0.8738    0.6918    0.7722      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8555    0.7640    0.8033     21274
weighted avg     0.8938    0.8971    0.8925     21274

F1-macro tok:  0.8033004871359403
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 307052.75677490234
train_cost_avg: 35.93782265623857
train_count_sent: 8544.0
train_total_correct_sent: 5821.0
train_accuracy_sent: 0.6812968164794008
train_count_tok: 163566.0
train_total_correct_tok: 147120.0
train_accuracy_tok: 0.8994534316422729
train_label=O_precision_sent: 0.535
train_label=O_recall_sent: 0.06588669950738917
train_label=O_f-score_sent: 0.11732456140350879
train_label=N_precision_sent: 0.6482435597189695
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.7303430079155673
train_label=P_precision_sent: 0.7231222385861561
train_label=P_recall_sent: 0.8160664819944599
train_label=P_f-score_sent: 0.7667881311816763
train_precision_macro_sent: 0.6354552661017085
train_recall_macro_sent: 0.5727356526456314
train_f-score_macro_sent: 0.5381519001669175
train_precision_micro_sent: 0.6812968164794008
train_recall_micro_sent: 0.6812968164794008
train_f-score_micro_sent: 0.6812968164794008
train_label=O_precision_tok: 0.9114209616937157
train_label=O_recall_tok: 0.9714508592889254
train_label=O_f-score_tok: 0.9404789710530822
train_label=N_precision_tok: 0.7983864046004635
train_label=N_recall_tok: 0.6549781720884382
train_label=N_f-score_tok: 0.719607008857773
train_label=P_precision_tok: 0.8783672205593972
train_label=P_recall_tok: 0.6803773434064836
train_label=P_f-score_tok: 0.7667980628449149
train_precision_macro_tok: 0.8627248622845255
train_recall_macro_tok: 0.7689354582612825
train_f-score_macro_tok: 0.8089613475852566
train_precision_micro_tok: 0.8994534316422729
train_recall_micro_tok: 0.8994534316422729
train_f-score_micro_tok: 0.8994534316422729
train_time: 73.03937864303589
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5350    0.0659    0.1173      1624
           N     0.6482    0.8363    0.7303      3310
           P     0.7231    0.8161    0.7668      3610

   micro avg     0.6813    0.6813    0.6813      8544
   macro avg     0.6355    0.5727    0.5382      8544
weighted avg     0.6584    0.6813    0.6292      8544

F1-macro sent:  0.5381519001669175
F1-micro sent:  0.6812968164794008
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9715    0.9405    124347
           N     0.7984    0.6550    0.7196     14202
           P     0.8784    0.6804    0.7668     25017

   micro avg     0.8995    0.8995    0.8995    163566
   macro avg     0.8627    0.7689    0.8090    163566
weighted avg     0.8966    0.8995    0.8947    163566

F1-macro tok:  0.8089613475852566
F1-micro tok:  0.8994534316422729
**************************************************
dev_cost_sum: 42220.67565917969
dev_cost_avg: 38.34757098926402
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19139.0
dev_accuracy_tok: 0.8996427564162828
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.1171875
dev_label=N_precision_sent: 0.6012364760432767
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.7237209302325582
dev_label=P_precision_sent: 0.7494145199063232
dev_label=P_recall_sent: 0.7207207207207207
dev_label=P_f-score_sent: 0.7347876004592422
dev_precision_macro_sent: 0.6354021838350518
dev_recall_macro_sent: 0.5650338029332439
dev_f-score_macro_sent: 0.5252320102306002
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9110441883361325
dev_label=O_recall_tok: 0.9707497685899413
dev_label=O_f-score_tok: 0.939949808795411
dev_label=N_precision_tok: 0.786479250334672
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.7012831990450612
dev_label=P_precision_tok: 0.8885793871866295
dev_label=P_recall_tok: 0.6952054794520548
dev_label=P_f-score_tok: 0.7800873362445415
dev_precision_macro_tok: 0.8620342752858113
dev_recall_macro_tok: 0.7662320760391289
dev_f-score_macro_tok: 0.8071067813616711
dev_precision_micro_tok: 0.8996427564162828
dev_recall_micro_tok: 0.8996427564162828
dev_f-score_micro_tok: 0.8996427564162828
dev_time: 2.455779552459717
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0655    0.1172       229
           N     0.6012    0.9089    0.7237       428
           P     0.7494    0.7207    0.7348       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6354    0.5650    0.5252      1101
weighted avg     0.6515    0.6576    0.6020      1101

F1-macro sent:  0.5252320102306002
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9707    0.9399     16205
           N     0.7865    0.6327    0.7013      1857
           P     0.8886    0.6952    0.7801      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8620    0.7662    0.8071     21274
weighted avg     0.8968    0.8996    0.8950     21274

F1-macro tok:  0.8071067813616711
F1-micro tok:  0.8996427564162828
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.900000
train_cost_sum: 305692.3106689453
train_cost_avg: 35.77859441350015
train_count_sent: 8544.0
train_total_correct_sent: 5820.0
train_accuracy_sent: 0.6811797752808989
train_count_tok: 163566.0
train_total_correct_tok: 147294.0
train_accuracy_tok: 0.9005172224056345
train_label=O_precision_sent: 0.4797979797979798
train_label=O_recall_sent: 0.058497536945812806
train_label=O_f-score_sent: 0.10428100987925355
train_label=N_precision_sent: 0.651279598182253
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7270057402215993
train_label=P_precision_sent: 0.7207683073229292
train_label=P_recall_sent: 0.8315789473684211
train_label=P_f-score_sent: 0.7722186495176848
train_precision_macro_sent: 0.6172819617677207
train_recall_macro_sent: 0.5709116981953791
train_f-score_macro_sent: 0.5345017998728459
train_precision_micro_sent: 0.6811797752808989
train_recall_micro_sent: 0.6811797752808989
train_f-score_micro_sent: 0.6811797752808989
train_label=O_precision_tok: 0.9126233397301259
train_label=O_recall_tok: 0.9714186912430537
train_label=O_f-score_tok: 0.9411036014101789
train_label=N_precision_tok: 0.8027448640354616
train_label=N_recall_tok: 0.6630756231516688
train_label=N_f-score_tok: 0.7262561215439787
train_label=P_precision_tok: 0.877137136109257
train_label=P_recall_tok: 0.6828956309709397
train_label=P_f-score_tok: 0.7679237650020226
train_precision_macro_tok: 0.8641684466249483
train_recall_macro_tok: 0.7724633151218874
train_f-score_macro_tok: 0.8117611626520601
train_precision_micro_tok: 0.9005172224056345
train_recall_micro_tok: 0.9005172224056345
train_f-score_micro_tok: 0.9005172224056345
train_time: 51.42121982574463
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4798    0.0585    0.1043      1624
           N     0.6513    0.8227    0.7270      3310
           P     0.7208    0.8316    0.7722      3610

   micro avg     0.6812    0.6812    0.6812      8544
   macro avg     0.6173    0.5709    0.5345      8544
weighted avg     0.6480    0.6812    0.6277      8544

F1-macro sent:  0.5345017998728459
F1-micro sent:  0.6811797752808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9126    0.9714    0.9411    124347
           N     0.8027    0.6631    0.7263     14202
           P     0.8771    0.6829    0.7679     25017

   micro avg     0.9005    0.9005    0.9005    163566
   macro avg     0.8642    0.7725    0.8118    163566
weighted avg     0.8977    0.9005    0.8960    163566

F1-macro tok:  0.8117611626520601
F1-micro tok:  0.9005172224056345
**************************************************
dev_cost_sum: 42151.18212890625
dev_cost_avg: 38.284452433157355
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19146.0
dev_accuracy_tok: 0.8999717965591802
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0823045267489712
dev_label=N_precision_sent: 0.6764132553606238
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7375132837407014
dev_label=P_precision_sent: 0.6567944250871081
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7406679764243614
dev_precision_macro_sent: 0.6824977982444821
dev_recall_macro_sent: 0.5678382949737477
dev_f-score_macro_sent: 0.5201619289713446
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9041673792828231
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.939963254904285
dev_label=N_precision_tok: 0.8150036416605972
dev_label=N_recall_tok: 0.6025848142164781
dev_label=N_f-score_tok: 0.6928792569659442
dev_label=P_precision_tok: 0.9182203389830509
dev_label=P_recall_tok: 0.6746575342465754
dev_label=P_f-score_tok: 0.7778176597272075
dev_precision_macro_tok: 0.8791304533088238
dev_recall_macro_tok: 0.7519842076898855
dev_f-score_macro_tok: 0.8035533905324789
dev_precision_micro_tok: 0.8999717965591802
dev_recall_micro_tok: 0.8999717965591802
dev_f-score_micro_tok: 0.8999717965591802
dev_time: 2.513852834701538
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0437    0.0823       229
           N     0.6764    0.8107    0.7375       428
           P     0.6568    0.8491    0.7407       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6825    0.5678    0.5202      1101
weighted avg     0.6764    0.6667    0.6025      1101

F1-macro sent:  0.5201619289713446
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9787    0.9400     16205
           N     0.8150    0.6026    0.6929      1857
           P     0.9182    0.6747    0.7778      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8791    0.7520    0.8036     21274
weighted avg     0.8985    0.9000    0.8939     21274

F1-macro tok:  0.8035533905324789
F1-micro tok:  0.8999717965591802
**************************************************
Best epoch: 22
**************************************************

EPOCH: 26
Learning rate: 0.900000
train_cost_sum: 304346.94372558594
train_cost_avg: 35.62113105402457
train_count_sent: 8544.0
train_total_correct_sent: 5822.0
train_accuracy_sent: 0.6814138576779026
train_count_tok: 163566.0
train_total_correct_tok: 147615.0
train_accuracy_tok: 0.9024797329518359
train_label=O_precision_sent: 0.4505928853754941
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.121470431539691
train_label=N_precision_sent: 0.6615233896644624
train_label=N_recall_sent: 0.816012084592145
train_label=N_f-score_sent: 0.7306911943730557
train_label=P_precision_sent: 0.7145912547528517
train_label=P_recall_sent: 0.8329639889196676
train_label=P_f-score_sent: 0.7692504476848299
train_precision_macro_sent: 0.6089025099309361
train_recall_macro_sent: 0.5730577059489294
train_f-score_macro_sent: 0.5404706911991922
train_precision_micro_sent: 0.6814138576779026
train_recall_micro_sent: 0.6814138576779026
train_f-score_micro_sent: 0.6814138576779026
train_label=O_precision_tok: 0.9145974018108591
train_label=O_recall_tok: 0.9715634474494761
train_label=O_f-score_tok: 0.9422201771181451
train_label=N_precision_tok: 0.8057608972724956
train_label=N_recall_tok: 0.6677228559357837
train_label=N_f-score_tok: 0.7302760771629896
train_label=P_precision_tok: 0.8790154783049987
train_label=P_recall_tok: 0.692369188951513
train_label=P_f-score_tok: 0.7746075756898171
train_precision_macro_tok: 0.8664579257961177
train_recall_macro_tok: 0.7772184974455909
train_f-score_macro_tok: 0.8157012766569839
train_precision_micro_tok: 0.9024797329518359
train_recall_micro_tok: 0.9024797329518359
train_f-score_micro_tok: 0.9024797329518359
train_time: 51.406657218933105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4506    0.0702    0.1215      1624
           N     0.6615    0.8160    0.7307      3310
           P     0.7146    0.8330    0.7693      3610

   micro avg     0.6814    0.6814    0.6814      8544
   macro avg     0.6089    0.5731    0.5405      8544
weighted avg     0.6439    0.6814    0.6312      8544

F1-macro sent:  0.5404706911991922
F1-micro sent:  0.6814138576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9146    0.9716    0.9422    124347
           N     0.8058    0.6677    0.7303     14202
           P     0.8790    0.6924    0.7746     25017

   micro avg     0.9025    0.9025    0.9025    163566
   macro avg     0.8665    0.7772    0.8157    163566
weighted avg     0.8997    0.9025    0.8982    163566

F1-macro tok:  0.8157012766569839
F1-micro tok:  0.9024797329518359
**************************************************
dev_cost_sum: 42070.9658203125
dev_cost_avg: 38.2115947505109
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19126.0
dev_accuracy_tok: 0.8990316818651876
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6328257191201354
dev_label=N_recall_sent: 0.8738317757009346
dev_label=N_f-score_sent: 0.7340529931305201
dev_label=P_precision_sent: 0.7083333333333334
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7531645569620253
dev_precision_macro_sent: 0.7248307952622675
dev_recall_macro_sent: 0.5665732969634533
dev_f-score_macro_sent: 0.5099235805273024
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9088917079921578
dev_label=O_recall_tok: 0.9726627584078988
dev_label=O_f-score_tok: 0.9396965451456165
dev_label=N_precision_tok: 0.7780730897009966
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.6966091612135633
dev_label=P_precision_tok: 0.9035846724351051
dev_label=P_recall_tok: 0.6827521793275217
dev_label=P_f-score_tok: 0.7777974818230183
dev_precision_macro_tok: 0.8635164900427531
dev_recall_macro_tok: 0.7620006353212485
dev_f-score_macro_tok: 0.8047010627273994
dev_precision_micro_tok: 0.8990316818651876
dev_recall_micro_tok: 0.8990316818651876
dev_f-score_micro_tok: 0.8990316818651876
dev_time: 2.502695083618164
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6328    0.8738    0.7341       428
           P     0.7083    0.8041    0.7532       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.7248    0.5666    0.5099      1101
weighted avg     0.7050    0.6685    0.5979      1101

F1-macro sent:  0.5099235805273024
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9089    0.9727    0.9397     16205
           N     0.7781    0.6306    0.6966      1857
           P     0.9036    0.6828    0.7778      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8635    0.7620    0.8047     21274
weighted avg     0.8967    0.8990    0.8940     21274

F1-macro tok:  0.8047010627273994
F1-micro tok:  0.8990316818651876
**************************************************
Best epoch: 22
**************************************************

EPOCH: 27
Learning rate: 0.810000
train_cost_sum: 302769.89013671875
train_cost_avg: 35.43655081188188
train_count_sent: 8544.0
train_total_correct_sent: 5910.0
train_accuracy_sent: 0.6917134831460674
train_count_tok: 163566.0
train_total_correct_tok: 147856.0
train_accuracy_tok: 0.903953144296492
train_label=O_precision_sent: 0.49794238683127573
train_label=O_recall_sent: 0.07450738916256158
train_label=O_f-score_sent: 0.12961971076593468
train_label=N_precision_sent: 0.6607950487979053
train_label=N_recall_sent: 0.8386706948640483
train_label=N_f-score_sent: 0.7391825322859805
train_label=P_precision_sent: 0.7348780487804878
train_label=P_recall_sent: 0.8346260387811635
train_label=P_f-score_sent: 0.7815823605706874
train_precision_macro_sent: 0.6312051614698896
train_recall_macro_sent: 0.5826013742692578
train_f-score_macro_sent: 0.5501282012075343
train_precision_micro_sent: 0.6917134831460674
train_recall_micro_sent: 0.6917134831460674
train_f-score_micro_sent: 0.6917134831460674
train_label=O_precision_tok: 0.9161202289352992
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.9431753439838915
train_label=N_precision_tok: 0.807793085960612
train_label=N_recall_tok: 0.6729333896634276
train_label=N_f-score_tok: 0.7342219490646488
train_label=P_precision_tok: 0.8803733602421796
train_label=P_recall_tok: 0.6974857097173922
train_label=P_f-score_tok: 0.7783303967705243
train_precision_macro_tok: 0.8680955583793636
train_recall_macro_tok: 0.7807653950925149
train_f-score_macro_tok: 0.8185758966063549
train_precision_micro_tok: 0.903953144296492
train_recall_micro_tok: 0.903953144296492
train_f-score_micro_tok: 0.903953144296492
train_time: 51.3842568397522
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4979    0.0745    0.1296      1624
           N     0.6608    0.8387    0.7392      3310
           P     0.7349    0.8346    0.7816      3610

   micro avg     0.6917    0.6917    0.6917      8544
   macro avg     0.6312    0.5826    0.5501      8544
weighted avg     0.6611    0.6917    0.6412      8544

F1-macro sent:  0.5501282012075343
F1-micro sent:  0.6917134831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9161    0.9719    0.9432    124347
           N     0.8078    0.6729    0.7342     14202
           P     0.8804    0.6975    0.7783     25017

   micro avg     0.9040    0.9040    0.9040    163566
   macro avg     0.8681    0.7808    0.8186    163566
weighted avg     0.9012    0.9040    0.8998    163566

F1-macro tok:  0.8185758966063549
F1-micro tok:  0.903953144296492
**************************************************
dev_cost_sum: 42072.185607910156
dev_cost_avg: 38.21270264115364
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19159.0
dev_accuracy_tok: 0.9005828711102755
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.6245901639344262
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.7341040462427746
dev_label=P_precision_sent: 0.7265135699373695
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7540628385698808
dev_precision_macro_sent: 0.7281456890683763
dev_recall_macro_sent: 0.5725462739807922
dev_f-score_macro_sent: 0.5237181455599584
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9064682312535776
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9405196733481812
dev_label=N_precision_tok: 0.7997227997227997
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.6993939393939393
dev_label=P_precision_tok: 0.9186785260482846
dev_label=P_recall_tok: 0.675280199252802
dev_label=P_f-score_tok: 0.7783958370715953
dev_precision_macro_tok: 0.8749565190082206
dev_recall_macro_tok: 0.7579806224541702
dev_f-score_macro_tok: 0.8061031499379053
dev_precision_micro_tok: 0.9005828711102755
dev_recall_micro_tok: 0.9005828711102755
dev_f-score_micro_tok: 0.9005828711102755
dev_time: 2.47965145111084
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.6246    0.8902    0.7341       428
           P     0.7265    0.7838    0.7541       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.7281    0.5725    0.5237      1101
weighted avg     0.7091    0.6712    0.6067      1101

F1-macro sent:  0.5237181455599584
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9772    0.9405     16205
           N     0.7997    0.6214    0.6994      1857
           P     0.9187    0.6753    0.7784      3212

   micro avg     0.9006    0.9006    0.9006     21274
   macro avg     0.8750    0.7580    0.8061     21274
weighted avg     0.8990    0.9006    0.8950     21274

F1-macro tok:  0.8061031499379053
F1-micro tok:  0.9005828711102755
**************************************************
Best epoch: 22
**************************************************

EPOCH: 28
Learning rate: 0.729000
train_cost_sum: 300797.86602783203
train_cost_avg: 35.20574274670319
train_count_sent: 8544.0
train_total_correct_sent: 5893.0
train_accuracy_sent: 0.6897237827715356
train_count_tok: 163566.0
train_total_correct_tok: 148283.0
train_accuracy_tok: 0.9065637112847413
train_label=O_precision_sent: 0.5408163265306123
train_label=O_recall_sent: 0.06527093596059114
train_label=O_f-score_sent: 0.11648351648351647
train_label=N_precision_sent: 0.6584959543074727
train_label=N_recall_sent: 0.83595166163142
train_label=N_f-score_sent: 0.7366879659211928
train_label=P_precision_sent: 0.7284129281234926
train_label=P_recall_sent: 0.8365650969529086
train_label=P_f-score_sent: 0.778751933986591
train_precision_macro_sent: 0.6425750696538591
train_recall_macro_sent: 0.5792625648483066
train_f-score_macro_sent: 0.5439744721304335
train_precision_micro_sent: 0.6897237827715356
train_recall_micro_sent: 0.6897237827715356
train_f-score_micro_sent: 0.6897237827715356
train_label=O_precision_tok: 0.9184105980386944
train_label=O_recall_tok: 0.9723274385389273
train_label=O_f-score_tok: 0.9446002640686891
train_label=N_precision_tok: 0.812950847173293
train_label=N_recall_tok: 0.6824390930854809
train_label=N_f-score_tok: 0.7419996937681825
train_label=P_precision_tok: 0.8843826573986098
train_label=P_recall_tok: 0.7069192948794819
train_label=P_f-score_tok: 0.7857555427200427
train_precision_macro_tok: 0.8719147008701991
train_recall_macro_tok: 0.7872286088346301
train_f-score_macro_tok: 0.8241185001856381
train_precision_micro_tok: 0.9065637112847413
train_recall_micro_tok: 0.9065637112847413
train_f-score_micro_tok: 0.9065637112847413
train_time: 61.940818071365356
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5408    0.0653    0.1165      1624
           N     0.6585    0.8360    0.7367      3310
           P     0.7284    0.8366    0.7788      3610

   micro avg     0.6897    0.6897    0.6897      8544
   macro avg     0.6426    0.5793    0.5440      8544
weighted avg     0.6657    0.6897    0.6366      8544

F1-macro sent:  0.5439744721304335
F1-micro sent:  0.6897237827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9723    0.9446    124347
           N     0.8130    0.6824    0.7420     14202
           P     0.8844    0.7069    0.7858     25017

   micro avg     0.9066    0.9066    0.9066    163566
   macro avg     0.8719    0.7872    0.8241    163566
weighted avg     0.9040    0.9066    0.9027    163566

F1-macro tok:  0.8241185001856381
F1-micro tok:  0.9065637112847413
**************************************************
dev_cost_sum: 42092.254455566406
dev_cost_avg: 38.23093047735368
dev_count_sent: 1101.0
dev_total_correct_sent: 750.0
dev_accuracy_sent: 0.6811989100817438
dev_count_tok: 21274.0
dev_total_correct_tok: 19152.0
dev_accuracy_tok: 0.900253830967378
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11811023622047244
dev_label=N_precision_sent: 0.6530973451327433
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.743202416918429
dev_label=P_precision_sent: 0.7162426614481409
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7664921465968587
dev_precision_macro_sent: 0.6564466688602947
dev_recall_macro_sent: 0.5839920134802394
dev_f-score_macro_sent: 0.54260159991192
dev_precision_micro_sent: 0.6811989100817438
dev_recall_micro_sent: 0.6811989100817438
dev_f-score_micro_sent: 0.6811989100817438
dev_label=O_precision_tok: 0.9096361224842858
dev_label=O_recall_tok: 0.9734032705954953
dev_label=O_f-score_tok: 0.9404399928456448
dev_label=N_precision_tok: 0.7975120939875605
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.698547215496368
dev_label=P_precision_tok: 0.8946098149637972
dev_label=P_recall_tok: 0.6924034869240349
dev_label=P_f-score_tok: 0.7806247806247806
dev_precision_macro_tok: 0.8672526771452146
dev_recall_macro_tok: 0.7624130584659428
dev_f-score_macro_tok: 0.8065373296555979
dev_precision_micro_tok: 0.900253830967378
dev_recall_micro_tok: 0.900253830967378
dev_f-score_micro_tok: 0.900253830967378
dev_time: 5.179883003234863
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0655    0.1181       229
           N     0.6531    0.8621    0.7432       428
           P     0.7162    0.8243    0.7665       444

   micro avg     0.6812    0.6812    0.6812      1101
   macro avg     0.6564    0.5840    0.5426      1101
weighted avg     0.6675    0.6812    0.6226      1101

F1-macro sent:  0.54260159991192
F1-micro sent:  0.6811989100817438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9096    0.9734    0.9404     16205
           N     0.7975    0.6214    0.6985      1857
           P     0.8946    0.6924    0.7806      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8673    0.7624    0.8065     21274
weighted avg     0.8976    0.9003    0.8952     21274

F1-macro tok:  0.8065373296555979
F1-micro tok:  0.900253830967378
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.729000
train_cost_sum: 299774.2048339844
train_cost_avg: 35.0859322137154
train_count_sent: 8544.0
train_total_correct_sent: 5903.0
train_accuracy_sent: 0.6908941947565543
train_count_tok: 163566.0
train_total_correct_tok: 148366.0
train_accuracy_tok: 0.9070711517063449
train_label=O_precision_sent: 0.5073891625615764
train_label=O_recall_sent: 0.06342364532019705
train_label=O_f-score_sent: 0.11275314723590588
train_label=N_precision_sent: 0.6646792272835679
train_label=N_recall_sent: 0.8419939577039275
train_label=N_f-score_sent: 0.7429028388644542
train_label=P_precision_sent: 0.726374156219865
train_label=P_recall_sent: 0.8346260387811635
train_label=P_f-score_sent: 0.7767465841711781
train_precision_macro_sent: 0.6328141820216698
train_recall_macro_sent: 0.5800145472684294
train_f-score_macro_sent: 0.5441341900905128
train_precision_micro_sent: 0.6908941947565543
train_recall_micro_sent: 0.6908941947565543
train_f-score_micro_sent: 0.6908941947565543
train_label=O_precision_tok: 0.9197832060836271
train_label=O_recall_tok: 0.9717242876788342
train_label=O_f-score_tok: 0.9450405919066464
train_label=N_precision_tok: 0.8104135525660189
train_label=N_recall_tok: 0.687156738487537
train_label=N_f-score_tok: 0.7437128486511202
train_label=P_precision_tok: 0.8819647730091789
train_label=P_recall_tok: 0.7105568213614742
train_label=P_f-score_tok: 0.7870362171256531
train_precision_macro_tok: 0.8707205105529416
train_recall_macro_tok: 0.7898126158426152
train_f-score_macro_tok: 0.8252632192278065
train_precision_micro_tok: 0.9070711517063449
train_recall_micro_tok: 0.9070711517063449
train_f-score_micro_tok: 0.9070711517063449
train_time: 95.74164772033691
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5074    0.0634    0.1128      1624
           N     0.6647    0.8420    0.7429      3310
           P     0.7264    0.8346    0.7767      3610

   micro avg     0.6909    0.6909    0.6909      8544
   macro avg     0.6328    0.5800    0.5441      8544
weighted avg     0.6608    0.6909    0.6374      8544

F1-macro sent:  0.5441341900905128
F1-micro sent:  0.6908941947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9198    0.9717    0.9450    124347
           N     0.8104    0.6872    0.7437     14202
           P     0.8820    0.7106    0.7870     25017

   micro avg     0.9071    0.9071    0.9071    163566
   macro avg     0.8707    0.7898    0.8253    163566
weighted avg     0.9045    0.9071    0.9034    163566

F1-macro tok:  0.8252632192278065
F1-micro tok:  0.9070711517063449
**************************************************
dev_cost_sum: 42026.03143310547
dev_cost_avg: 38.17078240972341
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19077.0
dev_accuracy_tok: 0.8967284008649056
dev_label=O_precision_sent: 0.9230769230769231
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09917355371900825
dev_label=N_precision_sent: 0.7281323877068558
dev_label=N_recall_sent: 0.719626168224299
dev_label=N_f-score_sent: 0.7238542890716805
dev_label=P_precision_sent: 0.6150375939849624
dev_label=P_recall_sent: 0.9211711711711712
dev_label=P_f-score_sent: 0.7376014427412082
dev_precision_macro_sent: 0.7554156349229139
dev_recall_macro_sent: 0.5643996953734537
dev_f-score_macro_sent: 0.5202097618439656
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9160300857915149
dev_label=O_recall_tok: 0.9619870410367171
dev_label=O_f-score_tok: 0.9384462571110375
dev_label=N_precision_tok: 0.7408536585365854
dev_label=N_recall_tok: 0.654281098546042
dev_label=N_f-score_tok: 0.694881326851587
dev_label=P_precision_tok: 0.8688837920489296
dev_label=P_recall_tok: 0.7076587795765878
dev_label=P_f-score_tok: 0.7800274536719286
dev_precision_macro_tok: 0.8419225121256767
dev_recall_macro_tok: 0.774642306386449
dev_f-score_macro_tok: 0.8044516792115176
dev_precision_micro_tok: 0.8967284008649056
dev_recall_micro_tok: 0.8967284008649056
dev_f-score_micro_tok: 0.8967284008649056
dev_time: 4.917717456817627
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9231    0.0524    0.0992       229
           N     0.7281    0.7196    0.7239       428
           P     0.6150    0.9212    0.7376       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.7554    0.5644    0.5202      1101
weighted avg     0.7231    0.6621    0.5995      1101

F1-macro sent:  0.5202097618439656
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9160    0.9620    0.9384     16205
           N     0.7409    0.6543    0.6949      1857
           P     0.8689    0.7077    0.7800      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8419    0.7746    0.8045     21274
weighted avg     0.8936    0.8967    0.8933     21274

F1-macro tok:  0.8044516792115176
F1-micro tok:  0.8967284008649056
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.729000
train_cost_sum: 298838.22869873047
train_cost_avg: 34.97638444507613
train_count_sent: 8544.0
train_total_correct_sent: 5969.0
train_accuracy_sent: 0.6986189138576779
train_count_tok: 163566.0
train_total_correct_tok: 148515.0
train_accuracy_tok: 0.9079820989692234
train_label=O_precision_sent: 0.48562300319488816
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15694372741352605
train_label=N_precision_sent: 0.686417273412001
train_label=N_recall_sent: 0.8259818731117825
train_label=N_f-score_sent: 0.7497600438776909
train_label=P_precision_sent: 0.72575329566855
train_label=P_recall_sent: 0.8540166204986149
train_label=P_f-score_sent: 0.784678035123441
train_precision_macro_sent: 0.6325978574251464
train_recall_macro_sent: 0.5911981842412327
train_f-score_macro_sent: 0.5637939354715527
train_precision_micro_sent: 0.6986189138576779
train_recall_micro_sent: 0.6986189138576779
train_f-score_micro_sent: 0.6986189138576779
train_label=O_precision_tok: 0.9210355740267663
train_label=O_recall_tok: 0.9713141450939708
train_label=O_f-score_tok: 0.945506924166869
train_label=N_precision_tok: 0.8127065432914738
train_label=N_recall_tok: 0.6926489226869454
train_label=N_f-score_tok: 0.7478902151600395
train_label=P_precision_tok: 0.8805037634673095
train_label=P_recall_tok: 0.7154335052164528
train_label=P_f-score_tok: 0.7894318983768526
train_precision_macro_tok: 0.8714152935951832
train_recall_macro_tok: 0.793132190999123
train_f-score_macro_tok: 0.8276096792345871
train_precision_micro_tok: 0.9079820989692234
train_recall_micro_tok: 0.9079820989692234
train_f-score_micro_tok: 0.9079820989692234
train_time: 96.3419554233551
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4856    0.0936    0.1569      1624
           N     0.6864    0.8260    0.7498      3310
           P     0.7258    0.8540    0.7847      3610

   micro avg     0.6986    0.6986    0.6986      8544
   macro avg     0.6326    0.5912    0.5638      8544
weighted avg     0.6649    0.6986    0.6518      8544

F1-macro sent:  0.5637939354715527
F1-micro sent:  0.6986189138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9210    0.9713    0.9455    124347
           N     0.8127    0.6926    0.7479     14202
           P     0.8805    0.7154    0.7894     25017

   micro avg     0.9080    0.9080    0.9080    163566
   macro avg     0.8714    0.7931    0.8276    163566
weighted avg     0.9054    0.9080    0.9045    163566

F1-macro tok:  0.8276096792345871
F1-micro tok:  0.9079820989692234
**************************************************
dev_cost_sum: 41992.249084472656
dev_cost_avg: 38.14009907763184
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19125.0
dev_accuracy_tok: 0.8989846761304879
dev_label=O_precision_sent: 0.48484848484848486
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12213740458015268
dev_label=N_precision_sent: 0.6872509960159362
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7419354838709677
dev_label=P_precision_sent: 0.6696113074204947
dev_label=P_recall_sent: 0.8536036036036037
dev_label=P_f-score_sent: 0.7504950495049506
dev_precision_macro_sent: 0.6139035960949718
dev_recall_macro_sent: 0.5765157885306439
dev_f-score_macro_sent: 0.5381893126520237
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9112837759480459
dev_label=O_recall_tok: 0.9698241283554458
dev_label=O_f-score_tok: 0.9396430599982063
dev_label=N_precision_tok: 0.7981906750173974
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6964177292046144
dev_label=P_precision_tok: 0.8730219992280973
dev_label=P_recall_tok: 0.7042341220423413
dev_label=P_f-score_tok: 0.7795967602963984
dev_precision_macro_tok: 0.8608321500645135
dev_recall_macro_tok: 0.7639070491812404
dev_f-score_macro_tok: 0.8052191831664063
dev_precision_micro_tok: 0.8989846761304879
dev_recall_micro_tok: 0.8989846761304879
dev_f-score_micro_tok: 0.8989846761304879
dev_time: 5.039490699768066
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4848    0.0699    0.1221       229
           N     0.6873    0.8061    0.7419       428
           P     0.6696    0.8536    0.7505       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6139    0.5765    0.5382      1101
weighted avg     0.6380    0.6721    0.6165      1101

F1-macro sent:  0.5381893126520237
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9113    0.9698    0.9396     16205
           N     0.7982    0.6177    0.6964      1857
           P     0.8730    0.7042    0.7796      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8608    0.7639    0.8052     21274
weighted avg     0.8956    0.8990    0.8942     21274

F1-macro tok:  0.8052191831664063
F1-micro tok:  0.8989846761304879
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 297743.76373291016
train_cost_avg: 34.84828695375821
train_count_sent: 8544.0
train_total_correct_sent: 5956.0
train_accuracy_sent: 0.6970973782771536
train_count_tok: 163566.0
train_total_correct_tok: 148722.0
train_accuracy_tok: 0.9092476431532226
train_label=O_precision_sent: 0.4717607973421927
train_label=O_recall_sent: 0.0874384236453202
train_label=O_f-score_sent: 0.14753246753246754
train_label=N_precision_sent: 0.6713085234093638
train_label=N_recall_sent: 0.8447129909365559
train_label=N_f-score_sent: 0.7480936454849498
train_label=P_precision_sent: 0.7400686611083864
train_label=P_recall_sent: 0.83601108033241
train_label=P_f-score_sent: 0.7851196670135276
train_precision_macro_sent: 0.627712660619981
train_recall_macro_sent: 0.5893874983047621
train_f-score_macro_sent: 0.5602485933436484
train_precision_micro_sent: 0.6970973782771536
train_recall_micro_sent: 0.6970973782771536
train_f-score_micro_sent: 0.6970973782771536
train_label=O_precision_tok: 0.9220644373186746
train_label=O_recall_tok: 0.9712498090022277
train_label=O_f-score_tok: 0.9460182432723527
train_label=N_precision_tok: 0.8142184790686153
train_label=N_recall_tok: 0.6943388255175328
train_label=N_f-score_tok: 0.7495154486375557
train_label=P_precision_tok: 0.8834676434676435
train_label=P_recall_tok: 0.7230683135467881
train_label=P_f-score_tok: 0.7952607051789325
train_precision_macro_tok: 0.8732501866183111
train_recall_macro_tok: 0.7962189826888495
train_f-score_macro_tok: 0.8302647990296137
train_precision_micro_tok: 0.9092476431532226
train_recall_micro_tok: 0.9092476431532226
train_f-score_micro_tok: 0.9092476431532226
train_time: 95.55195474624634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4718    0.0874    0.1475      1624
           N     0.6713    0.8447    0.7481      3310
           P     0.7401    0.8360    0.7851      3610

   micro avg     0.6971    0.6971    0.6971      8544
   macro avg     0.6277    0.5894    0.5602      8544
weighted avg     0.6624    0.6971    0.6496      8544

F1-macro sent:  0.5602485933436484
F1-micro sent:  0.6970973782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9221    0.9712    0.9460    124347
           N     0.8142    0.6943    0.7495     14202
           P     0.8835    0.7231    0.7953     25017

   micro avg     0.9092    0.9092    0.9092    163566
   macro avg     0.8733    0.7962    0.8303    163566
weighted avg     0.9068    0.9092    0.9059    163566

F1-macro tok:  0.8302647990296137
F1-micro tok:  0.9092476431532226
**************************************************
dev_cost_sum: 41957.337158203125
dev_cost_avg: 38.10838978946696
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.6086956521739131
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11111111111111109
dev_label=N_precision_sent: 0.6429840142095915
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7305751765893037
dev_label=P_precision_sent: 0.6990291262135923
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7507820646506779
dev_precision_macro_sent: 0.6502362641990324
dev_recall_macro_sent: 0.572580191504405
dev_f-score_macro_sent: 0.5308227841170309
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9104925795461107
dev_label=O_recall_tok: 0.9729713051527307
dev_label=O_f-score_tok: 0.9406956625499672
dev_label=N_precision_tok: 0.8016997167138811
dev_label=N_recall_tok: 0.6095853527194399
dev_label=N_f-score_tok: 0.69256653410829
dev_label=P_precision_tok: 0.8844793713163065
dev_label=P_recall_tok: 0.7008094645080947
dev_label=P_f-score_tok: 0.7820045162410979
dev_precision_macro_tok: 0.8655572225254328
dev_recall_macro_tok: 0.7611220407934217
dev_f-score_macro_tok: 0.805088904299785
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 5.059872627258301
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6087    0.0611    0.1111       229
           N     0.6430    0.8458    0.7306       428
           P     0.6990    0.8108    0.7508       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6502    0.5726    0.5308      1101
weighted avg     0.6585    0.6685    0.6099      1101

F1-macro sent:  0.5308227841170309
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9730    0.9407     16205
           N     0.8017    0.6096    0.6926      1857
           P     0.8845    0.7008    0.7820      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8656    0.7611    0.8051     21274
weighted avg     0.8971    0.9002    0.8951     21274

F1-macro tok:  0.805088904299785
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.729000
train_cost_sum: 296642.9381713867
train_cost_avg: 34.71944501069601
train_count_sent: 8544.0
train_total_correct_sent: 5970.0
train_accuracy_sent: 0.6987359550561798
train_count_tok: 163566.0
train_total_correct_tok: 149146.0
train_accuracy_tok: 0.911839868921414
train_label=O_precision_sent: 0.47058823529411764
train_label=O_recall_sent: 0.10837438423645321
train_label=O_f-score_sent: 0.1761761761761762
train_label=N_precision_sent: 0.6755436110432446
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7469944617047144
train_label=P_precision_sent: 0.7429482462595045
train_label=P_recall_sent: 0.8390581717451524
train_label=P_f-score_sent: 0.7880837778066866
train_precision_macro_sent: 0.6296933641989556
train_recall_macro_sent: 0.5942599960019249
train_f-score_macro_sent: 0.5704181385625257
train_precision_micro_sent: 0.6987359550561798
train_recall_micro_sent: 0.6987359550561798
train_f-score_micro_sent: 0.6987359550561798
train_label=O_precision_tok: 0.9239440279401763
train_label=O_recall_tok: 0.972271144458652
train_label=O_f-score_tok: 0.9474917515027548
train_label=N_precision_tok: 0.8222822527832351
train_label=N_recall_tok: 0.7072947472187016
train_label=N_f-score_tok: 0.7604663487016429
train_label=P_precision_tok: 0.8879457534513878
train_label=P_recall_tok: 0.727585242035416
train_label=P_f-score_tok: 0.7998066613937956
train_precision_macro_tok: 0.878057344724933
train_recall_macro_tok: 0.8023837112375899
train_f-score_macro_tok: 0.8359215871993978
train_precision_micro_tok: 0.911839868921414
train_recall_micro_tok: 0.911839868921414
train_f-score_micro_tok: 0.911839868921414
train_time: 96.30303025245667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4706    0.1084    0.1762      1624
           N     0.6755    0.8353    0.7470      3310
           P     0.7429    0.8391    0.7881      3610

   micro avg     0.6987    0.6987    0.6987      8544
   macro avg     0.6297    0.5943    0.5704      8544
weighted avg     0.6651    0.6987    0.6559      8544

F1-macro sent:  0.5704181385625257
F1-micro sent:  0.6987359550561798
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9239    0.9723    0.9475    124347
           N     0.8223    0.7073    0.7605     14202
           P     0.8879    0.7276    0.7998     25017

   micro avg     0.9118    0.9118    0.9118    163566
   macro avg     0.8781    0.8024    0.8359    163566
weighted avg     0.9096    0.9118    0.9087    163566

F1-macro tok:  0.8359215871993978
F1-micro tok:  0.911839868921414
**************************************************
dev_cost_sum: 41991.874938964844
dev_cost_avg: 38.13975925428233
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19139.0
dev_accuracy_tok: 0.8996427564162828
dev_label=O_precision_sent: 0.5625
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13793103448275862
dev_label=N_precision_sent: 0.6673040152963671
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7339642481598317
dev_label=P_precision_sent: 0.6831501831501832
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7535353535353535
dev_precision_macro_sent: 0.6376513994821834
dev_recall_macro_sent: 0.5780377569750299
dev_f-score_macro_sent: 0.5418102120593146
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9112384922702796
dev_label=O_recall_tok: 0.9711817340327059
dev_label=O_f-score_tok: 0.9402557055801172
dev_label=N_precision_tok: 0.7937716262975778
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6947304663840097
dev_label=P_precision_tok: 0.8811571540265832
dev_label=P_recall_tok: 0.7017434620174346
dev_label=P_f-score_tok: 0.7812824956672444
dev_precision_macro_tok: 0.8620557575314803
dev_recall_macro_tok: 0.7635293643986917
dev_f-score_macro_tok: 0.805422889210457
dev_precision_micro_tok: 0.8996427564162828
dev_recall_micro_tok: 0.8996427564162828
dev_f-score_micro_tok: 0.8996427564162828
dev_time: 5.024974584579468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5625    0.0786    0.1379       229
           N     0.6673    0.8154    0.7340       428
           P     0.6832    0.8401    0.7535       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6377    0.5780    0.5418      1101
weighted avg     0.6519    0.6721    0.6179      1101

F1-macro sent:  0.5418102120593146
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9112    0.9712    0.9403     16205
           N     0.7938    0.6177    0.6947      1857
           P     0.8812    0.7017    0.7813      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8621    0.7635    0.8054     21274
weighted avg     0.8964    0.8996    0.8948     21274

F1-macro tok:  0.805422889210457
F1-micro tok:  0.8996427564162828
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.656100
train_cost_sum: 295244.25048828125
train_cost_avg: 34.55574092793554
train_count_sent: 8544.0
train_total_correct_sent: 5977.0
train_accuracy_sent: 0.6995552434456929
train_count_tok: 163566.0
train_total_correct_tok: 149366.0
train_accuracy_tok: 0.9131848917256643
train_label=O_precision_sent: 0.49575070821529743
train_label=O_recall_sent: 0.10775862068965517
train_label=O_f-score_sent: 0.17703591299949417
train_label=N_precision_sent: 0.6733958183129055
train_label=N_recall_sent: 0.8465256797583082
train_label=N_f-score_sent: 0.7501003881675814
train_label=P_precision_sent: 0.7444168734491315
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.7853403141361256
train_precision_macro_sent: 0.6378544666591114
train_recall_macro_sent: 0.5951030770652953
train_f-score_macro_sent: 0.5708255384344004
train_precision_micro_sent: 0.6995552434456929
train_recall_micro_sent: 0.6995552434456929
train_f-score_micro_sent: 0.6995552434456929
train_label=O_precision_tok: 0.92607260220457
train_label=O_recall_tok: 0.9722470184242483
train_label=O_f-score_tok: 0.9485982408373677
train_label=N_precision_tok: 0.8245771713375276
train_label=N_recall_tok: 0.710604140261935
train_label=N_f-score_tok: 0.7633599334367082
train_label=P_precision_tok: 0.8844080846968239
train_label=P_recall_tok: 0.7346204580884999
train_label=P_f-score_tok: 0.8025853221826758
train_precision_macro_tok: 0.8783526194129738
train_recall_macro_tok: 0.8058238722582276
train_f-score_macro_tok: 0.8381811654855839
train_precision_micro_tok: 0.9131848917256643
train_recall_micro_tok: 0.9131848917256643
train_f-score_micro_tok: 0.9131848917256643
train_time: 96.25469827651978
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4958    0.1078    0.1770      1624
           N     0.6734    0.8465    0.7501      3310
           P     0.7444    0.8310    0.7853      3610

   micro avg     0.6996    0.6996    0.6996      8544
   macro avg     0.6379    0.5951    0.5708      8544
weighted avg     0.6696    0.6996    0.6561      8544

F1-macro sent:  0.5708255384344004
F1-micro sent:  0.6995552434456929
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9261    0.9722    0.9486    124347
           N     0.8246    0.7106    0.7634     14202
           P     0.8844    0.7346    0.8026     25017

   micro avg     0.9132    0.9132    0.9132    163566
   macro avg     0.8784    0.8058    0.8382    163566
weighted avg     0.9109    0.9132    0.9102    163566

F1-macro tok:  0.8381811654855839
F1-micro tok:  0.9131848917256643
**************************************************
dev_cost_sum: 42000.24365234375
dev_cost_avg: 38.147360265525656
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19179.0
dev_accuracy_tok: 0.9015229858042682
dev_label=O_precision_sent: 0.6470588235294118
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08943089430894309
dev_label=N_precision_sent: 0.659963436928702
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7405128205128205
dev_label=P_precision_sent: 0.6927374301675978
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7584097859327217
dev_precision_macro_sent: 0.6665865635419038
dev_recall_macro_sent: 0.5764435720869626
dev_f-score_macro_sent: 0.5294511669181617
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9147733892578352
dev_label=O_recall_tok: 0.969021906818883
dev_label=O_f-score_tok: 0.9411165383117077
dev_label=N_precision_tok: 0.7896483078964831
dev_label=N_recall_tok: 0.6408185245018848
dev_label=N_f-score_tok: 0.7074910820451843
dev_label=P_precision_tok: 0.8788927335640139
dev_label=P_recall_tok: 0.711706102117061
dev_label=P_f-score_tok: 0.7865129881300533
dev_precision_macro_tok: 0.8611048102394441
dev_recall_macro_tok: 0.7738488444792763
dev_f-score_macro_tok: 0.8117068694956484
dev_precision_micro_tok: 0.9015229858042682
dev_recall_micro_tok: 0.9015229858042682
dev_f-score_micro_tok: 0.9015229858042682
dev_time: 5.128913164138794
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6471    0.0480    0.0894       229
           N     0.6600    0.8435    0.7405       428
           P     0.6927    0.8378    0.7584       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6666    0.5764    0.5295      1101
weighted avg     0.6705    0.6757    0.6123      1101

F1-macro sent:  0.5294511669181617
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9148    0.9690    0.9411     16205
           N     0.7896    0.6408    0.7075      1857
           P     0.8789    0.7117    0.7865      3212

   micro avg     0.9015    0.9015    0.9015     21274
   macro avg     0.8611    0.7738    0.8117     21274
weighted avg     0.8984    0.9015    0.8974     21274

F1-macro tok:  0.8117068694956484
F1-micro tok:  0.9015229858042682
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.590490
train_cost_sum: 294078.88610839844
train_cost_avg: 34.419345284222665
train_count_sent: 8544.0
train_total_correct_sent: 5992.0
train_accuracy_sent: 0.701310861423221
train_count_tok: 163566.0
train_total_correct_tok: 149753.0
train_accuracy_tok: 0.9155509091131409
train_label=O_precision_sent: 0.48923076923076925
train_label=O_recall_sent: 0.0979064039408867
train_label=O_f-score_sent: 0.16316059517701387
train_label=N_precision_sent: 0.6754662145798014
train_label=N_recall_sent: 0.8425981873111782
train_label=N_f-score_sent: 0.7498319666621858
train_label=P_precision_sent: 0.7442542787286064
train_label=P_recall_sent: 0.843213296398892
train_label=P_f-score_sent: 0.7906493506493507
train_precision_macro_sent: 0.6363170875130589
train_recall_macro_sent: 0.5945726292169856
train_f-score_macro_sent: 0.5678806374961834
train_precision_micro_sent: 0.701310861423221
train_recall_micro_sent: 0.701310861423221
train_f-score_micro_sent: 0.701310861423221
train_label=O_precision_tok: 0.9283817185317101
train_label=O_recall_tok: 0.9726330349747079
train_label=O_f-score_tok: 0.9499923415586303
train_label=N_precision_tok: 0.8308692120227458
train_label=N_recall_tok: 0.7201802563019293
train_label=N_f-score_tok: 0.771575135787568
train_label=P_precision_tok: 0.8855685825946049
train_label=P_recall_tok: 0.7427349402406364
train_label=P_f-score_tok: 0.8078871279810431
train_precision_macro_tok: 0.8816065043830204
train_recall_macro_tok: 0.8118494105057579
train_f-score_macro_tok: 0.8431515351090805
train_precision_micro_tok: 0.9155509091131409
train_recall_micro_tok: 0.9155509091131409
train_f-score_micro_tok: 0.9155509091131409
train_time: 95.87387132644653
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4892    0.0979    0.1632      1624
           N     0.6755    0.8426    0.7498      3310
           P     0.7443    0.8432    0.7906      3610

   micro avg     0.7013    0.7013    0.7013      8544
   macro avg     0.6363    0.5946    0.5679      8544
weighted avg     0.6691    0.7013    0.6556      8544

F1-macro sent:  0.5678806374961834
F1-micro sent:  0.701310861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9284    0.9726    0.9500    124347
           N     0.8309    0.7202    0.7716     14202
           P     0.8856    0.7427    0.8079     25017

   micro avg     0.9156    0.9156    0.9156    163566
   macro avg     0.8816    0.8118    0.8432    163566
weighted avg     0.9134    0.9156    0.9128    163566

F1-macro tok:  0.8431515351090805
F1-micro tok:  0.9155509091131409
**************************************************
dev_cost_sum: 41998.52850341797
dev_cost_avg: 38.1458024554205
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19057.0
dev_accuracy_tok: 0.8957882861709129
dev_label=O_precision_sent: 0.5483870967741935
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.13076923076923075
dev_label=N_precision_sent: 0.6927835051546392
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7360350492880614
dev_label=P_precision_sent: 0.6632478632478632
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7541302235179786
dev_precision_macro_sent: 0.6348061550588987
dev_recall_macro_sent: 0.5777188035686994
dev_f-score_macro_sent: 0.540311501191757
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9164114043355325
dev_label=O_recall_tok: 0.9600123418697932
dev_label=O_f-score_tok: 0.9377053132816973
dev_label=N_precision_tok: 0.760705289672544
dev_label=N_recall_tok: 0.650511577813678
dev_label=N_f-score_tok: 0.7013062409288825
dev_label=P_precision_tok: 0.8457564575645756
dev_label=P_recall_tok: 0.7135740971357409
dev_label=P_f-score_tok: 0.7740628166160081
dev_precision_macro_tok: 0.8409577171908841
dev_recall_macro_tok: 0.7746993389397373
dev_f-score_macro_tok: 0.8043581236088625
dev_precision_micro_tok: 0.8957882861709129
dev_recall_micro_tok: 0.8957882861709129
dev_f-score_micro_tok: 0.8957882861709129
dev_time: 5.062817096710205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5484    0.0742    0.1308       229
           N     0.6928    0.7850    0.7360       428
           P     0.6632    0.8739    0.7541       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6348    0.5777    0.5403      1101
weighted avg     0.6508    0.6730    0.6174      1101

F1-macro sent:  0.540311501191757
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9164    0.9600    0.9377     16205
           N     0.7607    0.6505    0.7013      1857
           P     0.8458    0.7136    0.7741      3212

   micro avg     0.8958    0.8958    0.8958     21274
   macro avg     0.8410    0.7747    0.8044     21274
weighted avg     0.8922    0.8958    0.8924     21274

F1-macro tok:  0.8043581236088625
F1-micro tok:  0.8957882861709129
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.531441
train_cost_sum: 292729.2788696289
train_cost_avg: 34.26138563549028
train_count_sent: 8544.0
train_total_correct_sent: 6015.0
train_accuracy_sent: 0.704002808988764
train_count_tok: 163566.0
train_total_correct_tok: 149869.0
train_accuracy_tok: 0.916260102955382
train_label=O_precision_sent: 0.453125
train_label=O_recall_sent: 0.125
train_label=O_f-score_sent: 0.19594594594594594
train_label=N_precision_sent: 0.6900424257549289
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7557742244089108
train_label=P_precision_sent: 0.7451699682073857
train_label=P_recall_sent: 0.8440443213296399
train_label=P_f-score_sent: 0.7915313677100921
train_precision_macro_sent: 0.6294457979874383
train_recall_macro_sent: 0.601463917784603
train_f-score_macro_sent: 0.5810838460216496
train_precision_micro_sent: 0.704002808988764
train_recall_micro_sent: 0.704002808988764
train_f-score_micro_sent: 0.704002808988764
train_label=O_precision_tok: 0.9297148439603382
train_label=O_recall_tok: 0.9719735900343394
train_label=O_f-score_tok: 0.9503746864507404
train_label=N_precision_tok: 0.8273427471116817
train_label=N_recall_tok: 0.7260949162089847
train_label=N_f-score_tok: 0.7734193354833871
train_label=P_precision_tok: 0.8858930009951191
train_label=P_recall_tok: 0.7472918415477475
train_label=P_f-score_tok: 0.8107111882046835
train_precision_macro_tok: 0.8809835306890464
train_recall_macro_tok: 0.8151201159303572
train_f-score_macro_tok: 0.8448350700462703
train_precision_micro_tok: 0.916260102955382
train_recall_micro_tok: 0.916260102955382
train_f-score_micro_tok: 0.916260102955382
train_time: 94.51713728904724
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4531    0.1250    0.1959      1624
           N     0.6900    0.8353    0.7558      3310
           P     0.7452    0.8440    0.7915      3610

   micro avg     0.7040    0.7040    0.7040      8544
   macro avg     0.6294    0.6015    0.5811      8544
weighted avg     0.6683    0.7040    0.6645      8544

F1-macro sent:  0.5810838460216496
F1-micro sent:  0.704002808988764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9297    0.9720    0.9504    124347
           N     0.8273    0.7261    0.7734     14202
           P     0.8859    0.7473    0.8107     25017

   micro avg     0.9163    0.9163    0.9163    163566
   macro avg     0.8810    0.8151    0.8448    163566
weighted avg     0.9141    0.9163    0.9136    163566

F1-macro tok:  0.8448350700462703
F1-micro tok:  0.916260102955382
**************************************************
dev_cost_sum: 41942.09130859375
dev_cost_avg: 38.094542514617395
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19140.0
dev_accuracy_tok: 0.8996897621509824
dev_label=O_precision_sent: 0.6428571428571429
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07407407407407408
dev_label=N_precision_sent: 0.65
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.7368421052631579
dev_label=P_precision_sent: 0.698292220113852
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7579814624098867
dev_precision_macro_sent: 0.663716454323665
dev_recall_macro_sent: 0.5728658095307076
dev_f-score_macro_sent: 0.5229658805823729
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.914794280711993
dev_label=O_recall_tok: 0.9672940450478248
dev_label=O_f-score_tok: 0.9403119376124776
dev_label=N_precision_tok: 0.7857142857142857
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7052537845057881
dev_label=P_precision_tok: 0.8667681766273315
dev_label=P_recall_tok: 0.708904109589041
dev_label=P_f-score_tok: 0.7799280698749785
dev_precision_macro_tok: 0.8557589143512034
dev_recall_macro_tok: 0.7719798910717394
dev_f-score_macro_tok: 0.8084979306644148
dev_precision_micro_tok: 0.8996897621509824
dev_recall_micro_tok: 0.8996897621509824
dev_f-score_micro_tok: 0.8996897621509824
dev_time: 5.091357946395874
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6429    0.0393    0.0741       229
           N     0.6500    0.8505    0.7368       428
           P     0.6983    0.8288    0.7580       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6637    0.5729    0.5230      1101
weighted avg     0.6680    0.6730    0.6075      1101

F1-macro sent:  0.5229658805823729
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9148    0.9673    0.9403     16205
           N     0.7857    0.6397    0.7053      1857
           P     0.8668    0.7089    0.7799      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8558    0.7720    0.8085     21274
weighted avg     0.8963    0.8997    0.8956     21274

F1-macro tok:  0.8084979306644148
F1-micro tok:  0.8996897621509824
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42092.254455566406
test0_cost_avg: 38.23093047735368
test0_count_sent: 1101.0
test0_total_correct_sent: 750.0
test0_accuracy_sent: 0.6811989100817438
test0_count_tok: 21274.0
test0_total_correct_tok: 19152.0
test0_accuracy_tok: 0.900253830967378
test0_label=O_precision_sent: 0.6
test0_label=O_recall_sent: 0.06550218340611354
test0_label=O_f-score_sent: 0.11811023622047244
test0_label=N_precision_sent: 0.6530973451327433
test0_label=N_recall_sent: 0.8621495327102804
test0_label=N_f-score_sent: 0.743202416918429
test0_label=P_precision_sent: 0.7162426614481409
test0_label=P_recall_sent: 0.8243243243243243
test0_label=P_f-score_sent: 0.7664921465968587
test0_precision_macro_sent: 0.6564466688602947
test0_recall_macro_sent: 0.5839920134802394
test0_f-score_macro_sent: 0.54260159991192
test0_precision_micro_sent: 0.6811989100817438
test0_recall_micro_sent: 0.6811989100817438
test0_f-score_micro_sent: 0.6811989100817438
test0_label=O_precision_tok: 0.9096361224842858
test0_label=O_recall_tok: 0.9734032705954953
test0_label=O_f-score_tok: 0.9404399928456448
test0_label=N_precision_tok: 0.7975120939875605
test0_label=N_recall_tok: 0.6214324178782983
test0_label=N_f-score_tok: 0.698547215496368
test0_label=P_precision_tok: 0.8946098149637972
test0_label=P_recall_tok: 0.6924034869240349
test0_label=P_f-score_tok: 0.7806247806247806
test0_precision_macro_tok: 0.8672526771452146
test0_recall_macro_tok: 0.7624130584659428
test0_f-score_macro_tok: 0.8065373296555979
test0_precision_micro_tok: 0.900253830967378
test0_recall_micro_tok: 0.900253830967378
test0_f-score_micro_tok: 0.900253830967378
test0_time: 5.201777935028076
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0655    0.1181       229
           N     0.6531    0.8621    0.7432       428
           P     0.7162    0.8243    0.7665       444

   micro avg     0.6812    0.6812    0.6812      1101
   macro avg     0.6564    0.5840    0.5426      1101
weighted avg     0.6675    0.6812    0.6226      1101

F1-macro sent:  0.54260159991192
F1-micro sent:  0.6811989100817438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9096    0.9734    0.9404     16205
           N     0.7975    0.6214    0.6985      1857
           P     0.8946    0.6924    0.7806      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8673    0.7624    0.8065     21274
weighted avg     0.8976    0.9003    0.8952     21274

F1-macro tok:  0.8065373296555979
F1-micro tok:  0.900253830967378
**************************************************
test1_cost_sum: 81525.2848815918
test1_cost_avg: 36.88926917719086
test1_count_sent: 2210.0
test1_total_correct_sent: 1543.0
test1_accuracy_sent: 0.6981900452488687
test1_count_tok: 42405.0
test1_total_correct_tok: 37896.0
test1_accuracy_tok: 0.8936681995047754
test1_label=O_precision_sent: 0.4067796610169492
test1_label=O_recall_sent: 0.061696658097686374
test1_label=O_f-score_sent: 0.10714285714285714
test1_label=N_precision_sent: 0.6845397676496873
test1_label=N_recall_sent: 0.8399122807017544
test1_label=N_f-score_sent: 0.7543082225504677
test1_label=P_precision_sent: 0.7296511627906976
test1_label=P_recall_sent: 0.8283828382838284
test1_label=P_f-score_sent: 0.7758887171561051
test1_precision_macro_sent: 0.6069901971524446
test1_recall_macro_sent: 0.5766639256944232
test1_f-score_macro_sent: 0.5457799322831433
test1_precision_micro_sent: 0.6981900452488687
test1_recall_micro_sent: 0.6981900452488687
test1_f-score_micro_sent: 0.6981900452488687
test1_label=O_precision_tok: 0.9012688227983467
test1_label=O_recall_tok: 0.9745296581036315
test1_label=O_f-score_tok: 0.9364686096971334
test1_label=N_precision_tok: 0.7983510821023703
test1_label=N_recall_tok: 0.6180851063829788
test1_label=N_f-score_tok: 0.6967471143756557
test1_label=P_precision_tok: 0.8966292134831461
test1_label=P_recall_tok: 0.6602978787422897
test1_label=P_f-score_tok: 0.7605267717899845
test1_precision_macro_tok: 0.865416372794621
test1_recall_macro_tok: 0.7509708810763
test1_f-score_macro_tok: 0.7979141652875912
test1_precision_micro_tok: 0.8936681995047754
test1_recall_micro_tok: 0.8936681995047754
test1_f-score_micro_tok: 0.8936681995047754
test1_time: 10.515295505523682
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4068    0.0617    0.1071       389
           N     0.6845    0.8399    0.7543       912
           P     0.7297    0.8284    0.7759       909

   micro avg     0.6982    0.6982    0.6982      2210
   macro avg     0.6070    0.5767    0.5458      2210
weighted avg     0.6542    0.6982    0.6493      2210

F1-macro sent:  0.5457799322831433
F1-micro sent:  0.6981900452488687
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9013    0.9745    0.9365     31998
           N     0.7984    0.6181    0.6967      3760
           P     0.8966    0.6603    0.7605      6647

   micro avg     0.8937    0.8937    0.8937     42405
   macro avg     0.8654    0.7510    0.7979     42405
weighted avg     0.8914    0.8937    0.8876     42405

F1-macro tok:  0.7979141652875912
F1-micro tok:  0.8936681995047754
**************************************************
