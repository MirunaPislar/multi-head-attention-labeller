debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'O': 0, 'P': 2, 'N': 1}
{'O': 0, 'P': 2, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 20:02:38.992789: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 20:02:39.078309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 9.98GiB
2019-03-14 20:02:39.078354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 20:02:39.466715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 20:02:39.466768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 20:02:39.466780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 20:02:39.467016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 429372.53674316406
train_cost_avg: 50.25427630420928
train_count_sent: 8544.0
train_total_correct_sent: 4329.0
train_accuracy_sent: 0.5066713483146067
train_count_tok: 163566.0
train_total_correct_tok: 126217.0
train_accuracy_tok: 0.771657924018439
train_label=O_precision_sent: 0.229607250755287
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.07774936061381076
train_label=N_precision_sent: 0.4935600206079341
train_label=N_recall_sent: 0.5788519637462236
train_label=N_f-score_sent: 0.5328142380422692
train_label=P_precision_sent: 0.5395982452089587
train_label=P_recall_sent: 0.6473684210526316
train_label=P_f-score_sent: 0.5885908575746128
train_precision_macro_sent: 0.42092183885739326
train_recall_macro_sent: 0.42433947145183515
train_f-score_macro_sent: 0.3997181520768976
train_precision_micro_sent: 0.5066713483146067
train_recall_micro_sent: 0.5066713483146067
train_f-score_micro_sent: 0.5066713483146067
train_label=O_precision_tok: 0.7977223537026923
train_label=O_recall_tok: 0.9514584187797052
train_label=O_f-score_tok: 0.867834429945206
train_label=N_precision_tok: 0.48687224669603524
train_label=N_recall_tok: 0.19455006337135614
train_label=N_f-score_tok: 0.2780097600241485
train_label=P_precision_tok: 0.536847599164927
train_label=P_recall_tok: 0.205580205460287
train_label=P_f-score_tok: 0.2973090152325346
train_precision_macro_tok: 0.6071473998545515
train_recall_macro_tok: 0.4505295625371161
train_f-score_macro_tok: 0.4810510684006297
train_precision_micro_tok: 0.771657924018439
train_recall_micro_tok: 0.771657924018439
train_f-score_micro_tok: 0.7716579240184389
train_time: 99.19151782989502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2296    0.0468    0.0777      1624
           N     0.4936    0.5789    0.5328      3310
           P     0.5396    0.6474    0.5886      3610

   micro avg     0.5067    0.5067    0.5067      8544
   macro avg     0.4209    0.4243    0.3997      8544
weighted avg     0.4628    0.5067    0.4699      8544

F1-macro sent:  0.3997181520768976
F1-micro sent:  0.5066713483146067
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7977    0.9515    0.8678    124347
           N     0.4869    0.1946    0.2780     14202
           P     0.5368    0.2056    0.2973     25017

   micro avg     0.7717    0.7717    0.7717    163566
   macro avg     0.6071    0.4505    0.4811    163566
weighted avg     0.7308    0.7717    0.7294    163566

F1-macro tok:  0.4810510684006297
F1-micro tok:  0.7716579240184389
**************************************************
dev_cost_sum: 50873.216735839844
dev_cost_avg: 46.20637305707525
dev_count_sent: 1101.0
dev_total_correct_sent: 659.0
dev_accuracy_sent: 0.5985467756584922
dev_count_tok: 21274.0
dev_total_correct_tok: 17553.0
dev_accuracy_tok: 0.8250916611826643
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5773381294964028
dev_label=N_recall_sent: 0.75
dev_label=N_f-score_sent: 0.6524390243902439
dev_label=P_precision_sent: 0.6201834862385321
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.6835187057633975
dev_precision_macro_sent: 0.39917387191164505
dev_recall_macro_sent: 0.5037537537537538
dev_f-score_macro_sent: 0.44531924338454715
dev_precision_micro_sent: 0.5985467756584922
dev_recall_micro_sent: 0.5985467756584922
dev_f-score_micro_sent: 0.5985467756584922
dev_label=O_precision_tok: 0.843949566071721
dev_label=O_recall_tok: 0.9541499537179883
dev_label=O_f-score_tok: 0.8956728262758501
dev_label=N_precision_tok: 0.67206132879046
dev_label=N_recall_tok: 0.42487883683360256
dev_label=N_f-score_tok: 0.5206202573408116
dev_label=P_precision_tok: 0.7318718381112985
dev_label=P_recall_tok: 0.4053549190535492
dev_label=P_f-score_tok: 0.5217391304347826
dev_precision_macro_tok: 0.7492942443244931
dev_recall_macro_tok: 0.59479456986838
dev_f-score_macro_tok: 0.6460107380171481
dev_precision_micro_tok: 0.8250916611826643
dev_recall_micro_tok: 0.8250916611826643
dev_f-score_micro_tok: 0.8250916611826643
dev_time: 5.648035049438477
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5773    0.7500    0.6524       428
           P     0.6202    0.7613    0.6835       444

   micro avg     0.5985    0.5985    0.5985      1101
   macro avg     0.3992    0.5038    0.4453      1101
weighted avg     0.4745    0.5985    0.5293      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.44531924338454715
F1-micro sent:  0.5985467756584922
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8439    0.9541    0.8957     16205
           N     0.6721    0.4249    0.5206      1857
           P     0.7319    0.4054    0.5217      3212

   micro avg     0.8251    0.8251    0.8251     21274
   macro avg     0.7493    0.5948    0.6460     21274
weighted avg     0.8120    0.8251    0.8065     21274

F1-macro tok:  0.6460107380171481
F1-micro tok:  0.8250916611826643
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379842.9619140625
train_cost_avg: 44.45727550492305
train_count_sent: 8544.0
train_total_correct_sent: 4914.0
train_accuracy_sent: 0.5751404494382022
train_count_tok: 163566.0
train_total_correct_tok: 132521.0
train_accuracy_tok: 0.8101989411002286
train_label=O_precision_sent: 0.2898550724637681
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.023626698168930895
train_label=N_precision_sent: 0.5393966681674921
train_label=N_recall_sent: 0.7238670694864048
train_label=N_f-score_sent: 0.6181630546955624
train_label=P_precision_sent: 0.619390032234069
train_label=P_recall_sent: 0.69196675900277
train_label=P_f-score_sent: 0.6536700248593483
train_precision_macro_sent: 0.48288059095510977
train_recall_macro_sent: 0.4760496998083785
train_f-score_macro_sent: 0.4318199259079472
train_precision_micro_sent: 0.5751404494382022
train_recall_micro_sent: 0.5751404494382022
train_f-score_micro_sent: 0.5751404494382022
train_label=O_precision_tok: 0.8327663800207061
train_label=O_recall_tok: 0.9509035199884195
train_label=O_f-score_tok: 0.8879226835477259
train_label=N_precision_tok: 0.6420196219191194
train_label=N_recall_tok: 0.3778341078721307
train_label=N_f-score_tok: 0.47570921985815606
train_label=P_precision_tok: 0.6741547538007715
train_label=P_recall_tok: 0.3562777311428229
train_label=P_f-score_tok: 0.46618546995135735
train_precision_macro_tok: 0.7163135852468656
train_recall_macro_tok: 0.5616717863344577
train_f-score_macro_tok: 0.609939124452413
train_precision_micro_tok: 0.8101989411002286
train_recall_micro_tok: 0.8101989411002286
train_f-score_micro_tok: 0.8101989411002286
train_time: 97.18259954452515
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2899    0.0123    0.0236      1624
           N     0.5394    0.7239    0.6182      3310
           P     0.6194    0.6920    0.6537      3610

   micro avg     0.5751    0.5751    0.5751      8544
   macro avg     0.4829    0.4760    0.4318      8544
weighted avg     0.5258    0.5751    0.5202      8544

F1-macro sent:  0.4318199259079472
F1-micro sent:  0.5751404494382022
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8328    0.9509    0.8879    124347
           N     0.6420    0.3778    0.4757     14202
           P     0.6742    0.3563    0.4662     25017

   micro avg     0.8102    0.8102    0.8102    163566
   macro avg     0.7163    0.5617    0.6099    163566
weighted avg     0.7919    0.8102    0.7876    163566

F1-macro tok:  0.609939124452413
F1-micro tok:  0.8101989411002286
**************************************************
dev_cost_sum: 49381.21057128906
dev_cost_avg: 44.85123575957226
dev_count_sent: 1101.0
dev_total_correct_sent: 539.0
dev_accuracy_sent: 0.4895549500454133
dev_count_tok: 21274.0
dev_total_correct_tok: 17714.0
dev_accuracy_tok: 0.8326595844693052
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4349593495934959
dev_label=N_recall_sent: 1.0
dev_label=N_f-score_sent: 0.6062322946175637
dev_label=P_precision_sent: 0.9487179487179487
dev_label=P_recall_sent: 0.25
dev_label=P_f-score_sent: 0.3957219251336898
dev_precision_macro_sent: 0.4612257661038148
dev_recall_macro_sent: 0.4166666666666667
dev_f-score_macro_sent: 0.3339847399170845
dev_precision_micro_sent: 0.4895549500454133
dev_recall_micro_sent: 0.4895549500454133
dev_f-score_micro_sent: 0.4895549500454133
dev_label=O_precision_tok: 0.8412451778825546
dev_label=O_recall_tok: 0.9688984881209504
dev_label=O_f-score_tok: 0.9005707075052339
dev_label=N_precision_tok: 0.6964980544747081
dev_label=N_recall_tok: 0.4819601507808293
dev_label=N_f-score_tok: 0.5697008274984087
dev_label=P_precision_tok: 0.8437735849056603
dev_label=P_recall_tok: 0.3480697384806974
dev_label=P_f-score_tok: 0.49283667621776506
dev_precision_macro_tok: 0.793838939087641
dev_recall_macro_tok: 0.5996427924608257
dev_f-score_macro_tok: 0.6543694037404691
dev_precision_micro_tok: 0.8326595844693052
dev_recall_micro_tok: 0.8326595844693052
dev_f-score_micro_tok: 0.8326595844693052
dev_time: 5.149199485778809
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4350    1.0000    0.6062       428
           P     0.9487    0.2500    0.3957       444

   micro avg     0.4896    0.4896    0.4896      1101
   macro avg     0.4612    0.4167    0.3340      1101
weighted avg     0.5517    0.4896    0.3952      1101

F1-macro sent:  0.3339847399170845
F1-micro sent:  0.4895549500454133
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8412    0.9689    0.9006     16205
           N     0.6965    0.4820    0.5697      1857
           P     0.8438    0.3481    0.4928      3212

   micro avg     0.8327    0.8327    0.8327     21274
   macro avg     0.7938    0.5996    0.6544     21274
weighted avg     0.8290    0.8327    0.8101     21274

F1-macro tok:  0.6543694037404691
F1-micro tok:  0.8326595844693052
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369732.75158691406
train_cost_avg: 43.27396437112758
train_count_sent: 8544.0
train_total_correct_sent: 5011.0
train_accuracy_sent: 0.5864934456928839
train_count_tok: 163566.0
train_total_correct_tok: 135705.0
train_accuracy_tok: 0.8296650893217417
train_label=O_precision_sent: 0.16129032258064516
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006042296072507553
train_label=N_precision_sent: 0.5498016747465844
train_label=N_recall_sent: 0.7537764350453172
train_label=N_f-score_sent: 0.6358307849133537
train_label=P_precision_sent: 0.6316981132075472
train_label=P_recall_sent: 0.695567867036011
train_label=P_f-score_sent: 0.6620962425840474
train_precision_macro_sent: 0.44759670351159225
train_recall_macro_sent: 0.48414103993843943
train_f-score_macro_sent: 0.43465644118996954
train_precision_micro_sent: 0.5864934456928839
train_recall_micro_sent: 0.5864934456928839
train_f-score_micro_sent: 0.5864934456928839
train_label=O_precision_tok: 0.8507473401582265
train_label=O_recall_tok: 0.9530105269930115
train_label=O_f-score_tok: 0.8989800524197679
train_label=N_precision_tok: 0.6709373631187034
train_label=N_recall_tok: 0.4314181101253345
train_label=N_f-score_tok: 0.5251564241021686
train_label=P_precision_tok: 0.7314398943196829
train_label=P_recall_tok: 0.4426589918855178
train_label=P_f-score_tok: 0.551535224244839
train_precision_macro_tok: 0.7510415325322043
train_recall_macro_tok: 0.6090292096679546
train_f-score_macro_tok: 0.6585572335889252
train_precision_micro_tok: 0.8296650893217417
train_recall_micro_tok: 0.8296650893217417
train_f-score_micro_tok: 0.8296650893217415
train_time: 96.37290358543396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1613    0.0031    0.0060      1624
           N     0.5498    0.7538    0.6358      3310
           P     0.6317    0.6956    0.6621      3610

   micro avg     0.5865    0.5865    0.5865      8544
   macro avg     0.4476    0.4841    0.4347      8544
weighted avg     0.5106    0.5865    0.5272      8544

F1-macro sent:  0.43465644118996954
F1-micro sent:  0.5864934456928839
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8507    0.9530    0.8990    124347
           N     0.6709    0.4314    0.5252     14202
           P     0.7314    0.4427    0.5515     25017

   micro avg     0.8297    0.8297    0.8297    163566
   macro avg     0.7510    0.6090    0.6586    163566
weighted avg     0.8169    0.8297    0.8134    163566

F1-macro tok:  0.6585572335889252
F1-micro tok:  0.8296650893217415
**************************************************
dev_cost_sum: 48205.752685546875
dev_cost_avg: 43.783608252086175
dev_count_sent: 1101.0
dev_total_correct_sent: 666.0
dev_accuracy_sent: 0.6049046321525886
dev_count_tok: 21274.0
dev_total_correct_tok: 18259.0
dev_accuracy_tok: 0.8582777098806055
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.551829268292683
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.6678966789667897
dev_label=P_precision_sent: 0.6831460674157304
dev_label=P_recall_sent: 0.6846846846846847
dev_label=P_f-score_sent: 0.6839145106861643
dev_precision_macro_sent: 0.4116584452361378
dev_recall_macro_sent: 0.5101596924026831
dev_f-score_macro_sent: 0.45060372988431796
dev_precision_micro_sent: 0.6049046321525886
dev_recall_micro_sent: 0.6049046321525886
dev_f-score_micro_sent: 0.6049046321525886
dev_label=O_precision_tok: 0.8678952902761636
dev_label=O_recall_tok: 0.9677260104905894
dev_label=O_f-score_tok: 0.9150959911303029
dev_label=N_precision_tok: 0.7477231329690346
dev_label=N_recall_tok: 0.4421109316101239
dev_label=N_f-score_tok: 0.5556683587140441
dev_label=P_precision_tok: 0.8334124347413384
dev_label=P_recall_tok: 0.5466998754669987
dev_label=P_f-score_tok: 0.6602744876856551
dev_precision_macro_tok: 0.8163436193288455
dev_recall_macro_tok: 0.6521789391892373
dev_f-score_macro_tok: 0.7103462791766674
dev_precision_micro_tok: 0.8582777098806055
dev_recall_micro_tok: 0.8582777098806055
dev_f-score_micro_tok: 0.8582777098806055
dev_time: 5.221959590911865
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5518    0.8458    0.6679       428
           P     0.6831    0.6847    0.6839       444

   micro avg     0.6049    0.6049    0.6049      1101
   macro avg     0.4117    0.5102    0.4506      1101
weighted avg     0.4900    0.6049    0.5354      1101

F1-macro sent:  0.45060372988431796
F1-micro sent:  0.6049046321525886
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8679    0.9677    0.9151     16205
           N     0.7477    0.4421    0.5557      1857
           P     0.8334    0.5467    0.6603      3212

   micro avg     0.8583    0.8583    0.8583     21274
   macro avg     0.8163    0.6522    0.7103     21274
weighted avg     0.8522    0.8583    0.8452     21274

F1-macro tok:  0.7103462791766674
F1-micro tok:  0.8582777098806055
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362862.2608642578
train_cost_avg: 42.4698339026519
train_count_sent: 8544.0
train_total_correct_sent: 5179.0
train_accuracy_sent: 0.6061563670411985
train_count_tok: 163566.0
train_total_correct_tok: 137814.0
train_accuracy_tok: 0.8425589670224863
train_label=O_precision_sent: 0.391304347826087
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.01092896174863388
train_label=N_precision_sent: 0.572940635066728
train_label=N_recall_sent: 0.7522658610271903
train_label=N_f-score_sent: 0.6504702194357366
train_label=P_precision_sent: 0.6419161676646706
train_label=P_recall_sent: 0.7423822714681441
train_label=P_f-score_sent: 0.6885035324341682
train_precision_macro_sent: 0.5353870501858286
train_recall_macro_sent: 0.5000633348055056
train_f-score_macro_sent: 0.44996757120617953
train_precision_micro_sent: 0.6061563670411985
train_recall_micro_sent: 0.6061563670411985
train_f-score_micro_sent: 0.6061563670411985
train_label=O_precision_tok: 0.8606977046904153
train_label=O_recall_tok: 0.9571521628989843
train_label=O_f-score_tok: 0.9063660144157728
train_label=N_precision_tok: 0.6929720392961244
train_label=N_recall_tok: 0.4519785945641459
train_label=N_f-score_tok: 0.5471127210739399
train_label=P_precision_tok: 0.7724861119780289
train_label=P_recall_tok: 0.49470360155094534
train_label=P_f-score_tok: 0.6031483015741508
train_precision_macro_tok: 0.7753852853215228
train_recall_macro_tok: 0.6346114530046919
train_f-score_macro_tok: 0.6855423456879546
train_precision_micro_tok: 0.8425589670224863
train_recall_micro_tok: 0.8425589670224863
train_f-score_micro_tok: 0.8425589670224863
train_time: 97.00355648994446
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3913    0.0055    0.0109      1624
           N     0.5729    0.7523    0.6505      3310
           P     0.6419    0.7424    0.6885      3610

   micro avg     0.6062    0.6062    0.6062      8544
   macro avg     0.5354    0.5001    0.4500      8544
weighted avg     0.5676    0.6062    0.5450      8544

F1-macro sent:  0.44996757120617953
F1-micro sent:  0.6061563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8607    0.9572    0.9064    124347
           N     0.6930    0.4520    0.5471     14202
           P     0.7725    0.4947    0.6031     25017

   micro avg     0.8426    0.8426    0.8426    163566
   macro avg     0.7754    0.6346    0.6855    163566
weighted avg     0.8326    0.8426    0.8288    163566

F1-macro tok:  0.6855423456879546
F1-micro tok:  0.8425589670224863
**************************************************
dev_cost_sum: 47584.066162109375
dev_cost_avg: 43.21895200918199
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18363.0
dev_accuracy_tok: 0.8631663062893673
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6516393442622951
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.6943231441048034
dev_label=P_precision_sent: 0.6133768352365416
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7114474929044465
dev_precision_macro_sent: 0.4216720598329456
dev_recall_macro_sent: 0.5299458336841515
dev_f-score_macro_sent: 0.4685902123364167
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8754761371274927
dev_label=O_recall_tok: 0.9644554149953718
dev_label=O_f-score_tok: 0.9178142525765629
dev_label=N_precision_tok: 0.7749766573295985
dev_label=N_recall_tok: 0.44695745826602046
dev_label=N_f-score_tok: 0.5669398907103825
dev_label=P_precision_tok: 0.8098681412165036
dev_label=P_recall_tok: 0.5927770859277709
dev_label=P_f-score_tok: 0.6845227395290311
dev_precision_macro_tok: 0.820106978557865
dev_recall_macro_tok: 0.668063319729721
dev_f-score_macro_tok: 0.7230922942719923
dev_precision_micro_tok: 0.8631663062893673
dev_recall_micro_tok: 0.8631663062893673
dev_f-score_micro_tok: 0.8631663062893674
dev_time: 5.1840081214904785
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6516    0.7430    0.6943       428
           P     0.6134    0.8468    0.7114       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4217    0.5299    0.4686      1101
weighted avg     0.5007    0.6303    0.5568      1101

F1-macro sent:  0.4685902123364167
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8755    0.9645    0.9178     16205
           N     0.7750    0.4470    0.5669      1857
           P     0.8099    0.5928    0.6845      3212

   micro avg     0.8632    0.8632    0.8632     21274
   macro avg     0.8201    0.6681    0.7231     21274
weighted avg     0.8568    0.8632    0.8520     21274

F1-macro tok:  0.7230922942719923
F1-micro tok:  0.8631663062893674
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 357019.4621582031
train_cost_avg: 41.785985739490066
train_count_sent: 8544.0
train_total_correct_sent: 5236.0
train_accuracy_sent: 0.6128277153558053
train_count_tok: 163566.0
train_total_correct_tok: 139206.0
train_accuracy_tok: 0.851069293129379
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004901960784313725
train_label=N_precision_sent: 0.570017559262511
train_label=N_recall_sent: 0.7845921450151058
train_label=N_f-score_sent: 0.6603101957793034
train_label=P_precision_sent: 0.6620603015075377
train_label=P_recall_sent: 0.7299168975069252
train_label=P_f-score_sent: 0.69433465085639
train_precision_macro_sent: 0.5773592869233496
train_recall_macro_sent: 0.5056573655697411
train_f-score_macro_sent: 0.4531822691400024
train_precision_micro_sent: 0.6128277153558053
train_recall_micro_sent: 0.6128277153558053
train_f-score_micro_sent: 0.6128277153558053
train_label=O_precision_tok: 0.8678999592620613
train_label=O_recall_tok: 0.9594521781788061
train_label=O_f-score_tok: 0.9113826386209899
train_label=N_precision_tok: 0.7100282338178396
train_label=N_recall_tok: 0.478101675820307
train_label=N_f-score_tok: 0.5714285714285715
train_label=P_precision_tok: 0.7927323296450813
train_label=P_recall_tok: 0.5240836231362673
train_label=P_f-score_tok: 0.6310039464818559
train_precision_macro_tok: 0.7902201742416608
train_recall_macro_tok: 0.6538791590451268
train_f-score_macro_tok: 0.7046050521771391
train_precision_micro_tok: 0.851069293129379
train_recall_micro_tok: 0.851069293129379
train_f-score_micro_tok: 0.851069293129379
train_time: 97.42550277709961
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0025    0.0049      1624
           N     0.5700    0.7846    0.6603      3310
           P     0.6621    0.7299    0.6943      3610

   micro avg     0.6128    0.6128    0.6128      8544
   macro avg     0.5774    0.5057    0.4532      8544
weighted avg     0.5956    0.6128    0.5501      8544

F1-macro sent:  0.4531822691400024
F1-micro sent:  0.6128277153558053
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8679    0.9595    0.9114    124347
           N     0.7100    0.4781    0.5714     14202
           P     0.7927    0.5241    0.6310     25017

   micro avg     0.8511    0.8511    0.8511    163566
   macro avg     0.7902    0.6539    0.7046    163566
weighted avg     0.8427    0.8511    0.8390    163566

F1-macro tok:  0.7046050521771391
F1-micro tok:  0.851069293129379
**************************************************
dev_cost_sum: 46935.579833984375
dev_cost_avg: 42.62995443595311
dev_count_sent: 1101.0
dev_total_correct_sent: 676.0
dev_accuracy_sent: 0.6139872842870118
dev_count_tok: 21274.0
dev_total_correct_tok: 18514.0
dev_accuracy_tok: 0.870264172229012
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6527472527472528
dev_label=N_recall_sent: 0.6939252336448598
dev_label=N_f-score_sent: 0.6727066817667043
dev_label=P_precision_sent: 0.586687306501548
dev_label=P_recall_sent: 0.8536036036036037
dev_label=P_f-score_sent: 0.6954128440366972
dev_precision_macro_sent: 0.4131448530829336
dev_recall_macro_sent: 0.5158429457494879
dev_f-score_macro_sent: 0.45603984193446717
dev_precision_micro_sent: 0.6139872842870118
dev_recall_micro_sent: 0.6139872842870118
dev_f-score_micro_sent: 0.6139872842870118
dev_label=O_precision_tok: 0.8826452815270797
dev_label=O_recall_tok: 0.9644554149953718
dev_label=O_f-score_tok: 0.9217386175984902
dev_label=N_precision_tok: 0.7209964412811388
dev_label=N_recall_tok: 0.5455035002692514
dev_label=N_f-score_tok: 0.6210913549969345
dev_label=P_precision_tok: 0.8658649398704903
dev_label=P_recall_tok: 0.5828144458281445
dev_label=P_f-score_tok: 0.6966877558615557
dev_precision_macro_tok: 0.8231688875595696
dev_recall_macro_tok: 0.697591120364256
dev_f-score_macro_tok: 0.7465059094856601
dev_precision_micro_tok: 0.870264172229012
dev_recall_micro_tok: 0.870264172229012
dev_f-score_micro_tok: 0.870264172229012
dev_time: 5.1436357498168945
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6527    0.6939    0.6727       428
           P     0.5867    0.8536    0.6954       444

   micro avg     0.6140    0.6140    0.6140      1101
   macro avg     0.4131    0.5158    0.4560      1101
weighted avg     0.4903    0.6140    0.5419      1101

F1-macro sent:  0.45603984193446717
F1-micro sent:  0.6139872842870118
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8826    0.9645    0.9217     16205
           N     0.7210    0.5455    0.6211      1857
           P     0.8659    0.5828    0.6967      3212

   micro avg     0.8703    0.8703    0.8703     21274
   macro avg     0.8232    0.6976    0.7465     21274
weighted avg     0.8660    0.8703    0.8615     21274

F1-macro tok:  0.7465059094856601
F1-micro tok:  0.870264172229012
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 352503.89196777344
train_cost_avg: 41.25747799248285
train_count_sent: 8544.0
train_total_correct_sent: 5280.0
train_accuracy_sent: 0.6179775280898876
train_count_tok: 163566.0
train_total_correct_tok: 140314.0
train_accuracy_tok: 0.8578433170707849
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007294832826747719
train_label=N_precision_sent: 0.573058358929355
train_label=N_recall_sent: 0.7891238670694865
train_label=N_f-score_sent: 0.6639552618200305
train_label=P_precision_sent: 0.671374527112232
train_label=P_recall_sent: 0.7373961218836566
train_label=P_f-score_sent: 0.7028382838283828
train_precision_macro_sent: 0.5100490572519575
train_recall_macro_sent: 0.5100715234113103
train_f-score_macro_sent: 0.4580294594917203
train_precision_micro_sent: 0.6179775280898876
train_recall_micro_sent: 0.6179775280898876
train_f-score_micro_sent: 0.6179775280898876
train_label=O_precision_tok: 0.8736989064966961
train_label=O_recall_tok: 0.9612535887476176
train_label=O_f-score_tok: 0.9153874136049474
train_label=N_precision_tok: 0.7171274099765378
train_label=N_recall_tok: 0.4950007041261794
train_label=N_f-score_tok: 0.58571131014372
train_label=P_precision_tok: 0.8112651135358301
train_label=P_recall_tok: 0.549826118239597
train_label=P_f-score_tok: 0.6554369579719812
train_precision_macro_tok: 0.8006971433363547
train_recall_macro_tok: 0.6686934703711312
train_f-score_macro_tok: 0.7188452272402163
train_precision_micro_tok: 0.8578433170707849
train_recall_micro_tok: 0.8578433170707849
train_f-score_micro_tok: 0.857843317070785
train_time: 96.8390679359436
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0037    0.0073      1624
           N     0.5731    0.7891    0.6640      3310
           P     0.6714    0.7374    0.7028      3610

   micro avg     0.6180    0.6180    0.6180      8544
   macro avg     0.5100    0.5101    0.4580      8544
weighted avg     0.5600    0.6180    0.5556      8544

F1-macro sent:  0.4580294594917203
F1-micro sent:  0.6179775280898876
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8737    0.9613    0.9154    124347
           N     0.7171    0.4950    0.5857     14202
           P     0.8113    0.5498    0.6554     25017

   micro avg     0.8578    0.8578    0.8578    163566
   macro avg     0.8007    0.6687    0.7188    163566
weighted avg     0.8506    0.8578    0.8470    163566

F1-macro tok:  0.7188452272402163
F1-micro tok:  0.857843317070785
**************************************************
dev_cost_sum: 46444.95251464844
dev_cost_avg: 42.18433470903582
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 18605.0
dev_accuracy_tok: 0.8745416940866786
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6238532110091743
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.6988694758478932
dev_label=P_precision_sent: 0.6510791366906474
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.7240000000000001
dev_precision_macro_sent: 0.4249774492332739
dev_recall_macro_sent: 0.5365692795599338
dev_f-score_macro_sent: 0.4742898252826311
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8790053404539386
dev_label=O_recall_tok: 0.9750694230175871
dev_label=O_f-score_tok: 0.924548725900354
dev_label=N_precision_tok: 0.7754777070063694
dev_label=N_recall_tok: 0.5245018847603662
dev_label=N_f-score_tok: 0.6257629296498555
dev_label=P_precision_tok: 0.8961802154750245
dev_label=P_recall_tok: 0.5697384806973848
dev_label=P_f-score_tok: 0.6966121050628091
dev_precision_macro_tok: 0.8502210876451107
dev_recall_macro_tok: 0.6897699294917793
dev_f-score_macro_tok: 0.7489745868710062
dev_precision_micro_tok: 0.8745416940866786
dev_recall_micro_tok: 0.8745416940866786
dev_f-score_micro_tok: 0.8745416940866786
dev_time: 5.248314142227173
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6239    0.7944    0.6989       428
           P     0.6511    0.8153    0.7240       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.4250    0.5366    0.4743      1101
weighted avg     0.5051    0.6376    0.5636      1101

F1-macro sent:  0.4742898252826311
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8790    0.9751    0.9245     16205
           N     0.7755    0.5245    0.6258      1857
           P     0.8962    0.5697    0.6966      3212

   micro avg     0.8745    0.8745    0.8745     21274
   macro avg     0.8502    0.6898    0.7490     21274
weighted avg     0.8726    0.8745    0.8641     21274

F1-macro tok:  0.7489745868710062
F1-micro tok:  0.8745416940866786
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 348423.9334716797
train_cost_avg: 40.779954760262136
train_count_sent: 8544.0
train_total_correct_sent: 5290.0
train_accuracy_sent: 0.6191479400749064
train_count_tok: 163566.0
train_total_correct_tok: 141172.0
train_accuracy_tok: 0.863088906007361
train_label=O_precision_sent: 0.3492063492063492
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026081802015411975
train_label=N_precision_sent: 0.5860078503809744
train_label=N_recall_sent: 0.7667673716012084
train_label=N_f-score_sent: 0.6643109540636043
train_label=P_precision_sent: 0.6578313253012048
train_label=P_recall_sent: 0.7562326869806094
train_label=P_f-score_sent: 0.7036082474226804
train_precision_macro_sent: 0.5310151749628428
train_recall_macro_sent: 0.5121822855371249
train_f-score_macro_sent: 0.4646670011672322
train_precision_micro_sent: 0.6191479400749064
train_recall_micro_sent: 0.6191479400749064
train_f-score_micro_sent: 0.6191479400749064
train_label=O_precision_tok: 0.8777732188388383
train_label=O_recall_tok: 0.9634490578783566
train_label=O_f-score_tok: 0.918617802331778
train_label=N_precision_tok: 0.7313074770091963
train_label=N_recall_tok: 0.515138712857344
train_label=N_f-score_tok: 0.6044782285383788
train_label=P_precision_tok: 0.8229300854901043
train_label=P_recall_tok: 0.561777990966143
train_label=P_f-score_tok: 0.6677277586411687
train_precision_macro_tok: 0.8106702604460464
train_recall_macro_tok: 0.6801219205672813
train_f-score_macro_tok: 0.7302745965037752
train_precision_micro_tok: 0.863088906007361
train_recall_micro_tok: 0.863088906007361
train_f-score_micro_tok: 0.863088906007361
train_time: 97.88347864151001
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3492    0.0135    0.0261      1624
           N     0.5860    0.7668    0.6643      3310
           P     0.6578    0.7562    0.7036      3610

   micro avg     0.6191    0.6191    0.6191      8544
   macro avg     0.5310    0.5122    0.4647      8544
weighted avg     0.5713    0.6191    0.5596      8544

F1-macro sent:  0.4646670011672322
F1-micro sent:  0.6191479400749064
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8778    0.9634    0.9186    124347
           N     0.7313    0.5151    0.6045     14202
           P     0.8229    0.5618    0.6677     25017

   micro avg     0.8631    0.8631    0.8631    163566
   macro avg     0.8107    0.6801    0.7303    163566
weighted avg     0.8567    0.8631    0.8530    163566

F1-macro tok:  0.7302745965037752
F1-micro tok:  0.863088906007361
**************************************************
dev_cost_sum: 46091.06872558594
dev_cost_avg: 41.86291437382919
dev_count_sent: 1101.0
dev_total_correct_sent: 695.0
dev_accuracy_sent: 0.631244323342416
dev_count_tok: 21274.0
dev_total_correct_tok: 18677.0
dev_accuracy_tok: 0.8779261069850521
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6385542168674698
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.6868250539956804
dev_label=P_precision_sent: 0.6239600665557404
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7177033492822966
dev_precision_macro_sent: 0.7541714278077367
dev_recall_macro_sent: 0.5321062910847836
dev_f-score_macro_sent: 0.47394814019799814
dev_precision_micro_sent: 0.631244323342416
dev_recall_micro_sent: 0.631244323342416
dev_f-score_micro_sent: 0.631244323342416
dev_label=O_precision_tok: 0.8814587973273942
dev_label=O_recall_tok: 0.9769207034865782
dev_label=O_f-score_tok: 0.9267378896531538
dev_label=N_precision_tok: 0.8218283582089553
dev_label=N_recall_tok: 0.47442110931610126
dev_label=N_f-score_tok: 0.601570501877774
dev_label=P_precision_tok: 0.876449598572703
dev_label=P_recall_tok: 0.6117683686176837
dev_label=P_f-score_tok: 0.7205720572057206
dev_precision_macro_tok: 0.8599122513696842
dev_recall_macro_tok: 0.6877033938067877
dev_f-score_macro_tok: 0.7496268162455495
dev_precision_micro_tok: 0.8779261069850521
dev_recall_micro_tok: 0.8779261069850521
dev_f-score_micro_tok: 0.8779261069850521
dev_time: 5.153010129928589
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6386    0.7430    0.6868       428
           P     0.6240    0.8446    0.7177       444

   micro avg     0.6312    0.6312    0.6312      1101
   macro avg     0.7542    0.5321    0.4739      1101
weighted avg     0.7078    0.6312    0.5600      1101

F1-macro sent:  0.47394814019799814
F1-micro sent:  0.631244323342416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8815    0.9769    0.9267     16205
           N     0.8218    0.4744    0.6016      1857
           P     0.8764    0.6118    0.7206      3212

   micro avg     0.8779    0.8779    0.8779     21274
   macro avg     0.8599    0.6877    0.7496     21274
weighted avg     0.8755    0.8779    0.8672     21274

F1-macro tok:  0.7496268162455495
F1-micro tok:  0.8779261069850521
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 344596.9567260742
train_cost_avg: 40.332040815317676
train_count_sent: 8544.0
train_total_correct_sent: 5387.0
train_accuracy_sent: 0.630500936329588
train_count_tok: 163566.0
train_total_correct_tok: 141720.0
train_accuracy_tok: 0.866439235537948
train_label=O_precision_sent: 0.3235294117647059
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026004728132387706
train_label=N_precision_sent: 0.5907678650687972
train_label=N_recall_sent: 0.8042296072507553
train_label=N_f-score_sent: 0.681166837256909
train_label=P_precision_sent: 0.6808564231738036
train_label=P_recall_sent: 0.7487534626038781
train_label=P_f-score_sent: 0.7131926121372033
train_precision_macro_sent: 0.5317179000024356
train_recall_macro_sent: 0.5221766226280633
train_f-score_macro_sent: 0.47345472584216663
train_precision_micro_sent: 0.630500936329588
train_recall_micro_sent: 0.630500936329588
train_f-score_micro_sent: 0.630500936329588
train_label=O_precision_tok: 0.8805761945317319
train_label=O_recall_tok: 0.964542771437992
train_label=O_f-score_tok: 0.9206489324546826
train_label=N_precision_tok: 0.7386521308225966
train_label=N_recall_tok: 0.5247852415152795
train_label=N_f-score_tok: 0.6136176519018606
train_label=P_precision_tok: 0.8296086150995832
train_label=P_recall_tok: 0.5727705160490866
train_label=P_f-score_tok: 0.6776703161578661
train_precision_macro_tok: 0.8162789801513038
train_recall_macro_tok: 0.6873661763341193
train_f-score_macro_tok: 0.7373123001714698
train_precision_micro_tok: 0.866439235537948
train_recall_micro_tok: 0.866439235537948
train_f-score_micro_tok: 0.866439235537948
train_time: 97.70744752883911
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3235    0.0135    0.0260      1624
           N     0.5908    0.8042    0.6812      3310
           P     0.6809    0.7488    0.7132      3610

   micro avg     0.6305    0.6305    0.6305      8544
   macro avg     0.5317    0.5222    0.4735      8544
weighted avg     0.5780    0.6305    0.5702      8544

F1-macro sent:  0.47345472584216663
F1-micro sent:  0.630500936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9645    0.9206    124347
           N     0.7387    0.5248    0.6136     14202
           P     0.8296    0.5728    0.6777     25017

   micro avg     0.8664    0.8664    0.8664    163566
   macro avg     0.8163    0.6874    0.7373    163566
weighted avg     0.8605    0.8664    0.8568    163566

F1-macro tok:  0.7373123001714698
F1-micro tok:  0.866439235537948
**************************************************
dev_cost_sum: 45663.285888671875
dev_cost_avg: 41.474374104152474
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18738.0
dev_accuracy_tok: 0.8807934568017298
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6047297297297297
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7019607843137254
dev_label=P_precision_sent: 0.6751968503937008
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7205882352941175
dev_precision_macro_sent: 0.42664219337447684
dev_recall_macro_sent: 0.5363237068844545
dev_f-score_macro_sent: 0.47418300653594764
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8853513876454789
dev_label=O_recall_tok: 0.9764270286948473
dev_label=O_f-score_tok: 0.9286615605833846
dev_label=N_precision_tok: 0.7564655172413793
dev_label=N_recall_tok: 0.567043618739903
dev_label=N_f-score_tok: 0.6481994459833795
dev_label=P_precision_tok: 0.9263681592039801
dev_label=P_recall_tok: 0.5797011207970112
dev_label=P_f-score_tok: 0.7131367292225199
dev_precision_macro_tok: 0.8560616880302794
dev_recall_macro_tok: 0.7077239227439205
dev_f-score_macro_tok: 0.7633325785964281
dev_precision_micro_tok: 0.8807934568017298
dev_recall_micro_tok: 0.8807934568017298
dev_f-score_micro_tok: 0.8807934568017298
dev_time: 5.254169225692749
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6047    0.8364    0.7020       428
           P     0.6752    0.7725    0.7206       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4266    0.5363    0.4742      1101
weighted avg     0.5074    0.6367    0.5635      1101

F1-macro sent:  0.47418300653594764
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8854    0.9764    0.9287     16205
           N     0.7565    0.5670    0.6482      1857
           P     0.9264    0.5797    0.7131      3212

   micro avg     0.8808    0.8808    0.8808     21274
   macro avg     0.8561    0.7077    0.7633     21274
weighted avg     0.8803    0.8808    0.8716     21274

F1-macro tok:  0.7633325785964281
F1-micro tok:  0.8807934568017298
**************************************************
Best epoch: 5
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 341018.025390625
train_cost_avg: 39.913158402460795
train_count_sent: 8544.0
train_total_correct_sent: 5408.0
train_accuracy_sent: 0.6329588014981273
train_count_tok: 163566.0
train_total_correct_tok: 142303.0
train_accuracy_tok: 0.8700035459692113
train_label=O_precision_sent: 0.3163265306122449
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03600464576074332
train_label=N_precision_sent: 0.6096397041278931
train_label=N_recall_sent: 0.7719033232628398
train_label=N_f-score_sent: 0.6812425009998667
train_label=P_precision_sent: 0.663219741480611
train_label=P_recall_sent: 0.7817174515235457
train_label=P_f-score_sent: 0.7176096630642085
train_precision_macro_sent: 0.5297286587402498
train_recall_macro_sent: 0.5242364815790415
train_f-score_macro_sent: 0.4782856032749396
train_precision_micro_sent: 0.6329588014981273
train_recall_micro_sent: 0.6329588014981273
train_f-score_micro_sent: 0.6329588014981273
train_label=O_precision_tok: 0.8826909229842325
train_label=O_recall_tok: 0.9661350897086379
train_label=O_f-score_tok: 0.9225299386828132
train_label=N_precision_tok: 0.7501472031403337
train_label=N_recall_tok: 0.5382340515420363
train_label=N_f-score_tok: 0.6267628730731386
train_label=P_precision_tok: 0.8407433136505731
train_label=P_recall_tok: 0.5805252428348723
train_label=P_f-score_tok: 0.6868127970490175
train_precision_macro_tok: 0.8245271465917131
train_recall_macro_tok: 0.6949647946951822
train_f-score_macro_tok: 0.7453685362683231
train_precision_micro_tok: 0.8700035459692113
train_recall_micro_tok: 0.8700035459692113
train_f-score_micro_tok: 0.8700035459692113
train_time: 97.43504738807678
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3163    0.0191    0.0360      1624
           N     0.6096    0.7719    0.6812      3310
           P     0.6632    0.7817    0.7176      3610

   micro avg     0.6330    0.6330    0.6330      8544
   macro avg     0.5297    0.5242    0.4783      8544
weighted avg     0.5765    0.6330    0.5740      8544

F1-macro sent:  0.4782856032749396
F1-micro sent:  0.6329588014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8827    0.9661    0.9225    124347
           N     0.7501    0.5382    0.6268     14202
           P     0.8407    0.5805    0.6868     25017

   micro avg     0.8700    0.8700    0.8700    163566
   macro avg     0.8245    0.6950    0.7454    163566
weighted avg     0.8648    0.8700    0.8608    163566

F1-macro tok:  0.7453685362683231
F1-micro tok:  0.8700035459692113
**************************************************
dev_cost_sum: 45248.948486328125
dev_cost_avg: 41.09804585497559
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 18807.0
dev_accuracy_tok: 0.8840368524960045
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.663135593220339
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.6955555555555556
dev_label=P_precision_sent: 0.6169871794871795
dev_label=P_recall_sent: 0.8671171171171171
dev_label=P_f-score_sent: 0.7209737827715357
dev_precision_macro_sent: 0.5600409242358395
dev_recall_macro_sent: 0.5357197175954064
dev_f-score_macro_sent: 0.47787445180703614
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.8897021564101121
dev_label=O_recall_tok: 0.9751311323665536
dev_label=O_f-score_tok: 0.9304598716363423
dev_label=N_precision_tok: 0.7814619442351168
dev_label=N_recall_tok: 0.5584275713516424
dev_label=N_f-score_tok: 0.6513819095477387
dev_label=P_precision_tok: 0.9002744739249772
dev_label=P_recall_tok: 0.6127023661270237
dev_label=P_f-score_tok: 0.729158947758429
dev_precision_macro_tok: 0.8571461915234021
dev_recall_macro_tok: 0.7154203566150731
dev_f-score_macro_tok: 0.77033357631417
dev_precision_micro_tok: 0.8840368524960045
dev_recall_micro_tok: 0.8840368524960045
dev_f-score_micro_tok: 0.8840368524960045
dev_time: 5.121627569198608
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.6631    0.7313    0.6956       428
           P     0.6170    0.8671    0.7210       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.5600    0.5357    0.4779      1101
weighted avg     0.5898    0.6358    0.5647      1101

F1-macro sent:  0.47787445180703614
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8897    0.9751    0.9305     16205
           N     0.7815    0.5584    0.6514      1857
           P     0.9003    0.6127    0.7292      3212

   micro avg     0.8840    0.8840    0.8840     21274
   macro avg     0.8571    0.7154    0.7703     21274
weighted avg     0.8819    0.8840    0.8757     21274

F1-macro tok:  0.77033357631417
F1-micro tok:  0.8840368524960045
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 337708.5805053711
train_cost_avg: 39.52581700671478
train_count_sent: 8544.0
train_total_correct_sent: 5470.0
train_accuracy_sent: 0.6402153558052435
train_count_tok: 163566.0
train_total_correct_tok: 142815.0
train_accuracy_tok: 0.8731337808591028
train_label=O_precision_sent: 0.3951612903225806
train_label=O_recall_sent: 0.03017241379310345
train_label=O_f-score_sent: 0.05606407322654463
train_label=N_precision_sent: 0.6052752293577982
train_label=N_recall_sent: 0.7972809667673716
train_label=N_f-score_sent: 0.688135593220339
train_label=P_precision_sent: 0.6852216748768473
train_label=P_recall_sent: 0.7706371191135734
train_label=P_f-score_sent: 0.7254237288135593
train_precision_macro_sent: 0.5618860648524087
train_recall_macro_sent: 0.5326968332246828
train_f-score_macro_sent: 0.4898744650868143
train_precision_micro_sent: 0.6402153558052435
train_recall_micro_sent: 0.6402153558052435
train_f-score_micro_sent: 0.6402153558052435
train_label=O_precision_tok: 0.8858334438598818
train_label=O_recall_tok: 0.9668106186719422
train_label=O_f-score_tok: 0.9245523165718813
train_label=N_precision_tok: 0.752356222350452
train_label=N_recall_tok: 0.5508379101534995
train_label=N_f-score_tok: 0.6360162601626016
train_label=P_precision_tok: 0.8463389480921278
train_label=P_recall_tok: 0.5904784746372467
train_label=P_f-score_tok: 0.6956276047185137
train_precision_macro_tok: 0.8281762047674871
train_recall_macro_tok: 0.7027090011542295
train_f-score_macro_tok: 0.7520653938176656
train_precision_micro_tok: 0.8731337808591028
train_recall_micro_tok: 0.8731337808591028
train_f-score_micro_tok: 0.8731337808591028
train_time: 97.37189769744873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3952    0.0302    0.0561      1624
           N     0.6053    0.7973    0.6881      3310
           P     0.6852    0.7706    0.7254      3610

   micro avg     0.6402    0.6402    0.6402      8544
   macro avg     0.5619    0.5327    0.4899      8544
weighted avg     0.5991    0.6402    0.5837      8544

F1-macro sent:  0.4898744650868143
F1-micro sent:  0.6402153558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8858    0.9668    0.9246    124347
           N     0.7524    0.5508    0.6360     14202
           P     0.8463    0.5905    0.6956     25017

   micro avg     0.8731    0.8731    0.8731    163566
   macro avg     0.8282    0.7027    0.7521    163566
weighted avg     0.8682    0.8731    0.8645    163566

F1-macro tok:  0.7520653938176656
F1-micro tok:  0.8731337808591028
**************************************************
dev_cost_sum: 45045.658447265625
dev_cost_avg: 40.91340458425579
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18766.0
dev_accuracy_tok: 0.8821096173733195
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6058158319870759
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7163323782234956
dev_label=P_precision_sent: 0.6887966804979253
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7170626349892009
dev_precision_macro_sent: 0.4315375041616671
dev_recall_macro_sent: 0.5413053240156044
dev_f-score_macro_sent: 0.47779833773756547
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.876792556102901
dev_label=O_recall_tok: 0.9885220610922555
dev_label=O_f-score_tok: 0.9293110949963742
dev_label=N_precision_tok: 0.8597560975609756
dev_label=N_recall_tok: 0.4555735056542811
dev_label=N_f-score_tok: 0.5955649419218586
dev_label=P_precision_tok: 0.941089108910891
dev_label=P_recall_tok: 0.5918430884184309
dev_label=P_f-score_tok: 0.7266819571865443
dev_precision_macro_tok: 0.8925459208582559
dev_recall_macro_tok: 0.6786462183883225
dev_f-score_macro_tok: 0.7505193313682591
dev_precision_micro_tok: 0.8821096173733195
dev_recall_micro_tok: 0.8821096173733195
dev_f-score_micro_tok: 0.8821096173733195
dev_time: 5.081115484237671
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6058    0.8762    0.7163       428
           P     0.6888    0.7477    0.7171       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.4315    0.5413    0.4778      1101
weighted avg     0.5133    0.6421    0.5676      1101

F1-macro sent:  0.47779833773756547
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8768    0.9885    0.9293     16205
           N     0.8598    0.4556    0.5956      1857
           P     0.9411    0.5918    0.7267      3212

   micro avg     0.8821    0.8821    0.8821     21274
   macro avg     0.8925    0.6786    0.7505     21274
weighted avg     0.8850    0.8821    0.8696     21274

F1-macro tok:  0.7505193313682591
F1-micro tok:  0.8821096173733195
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 334940.58752441406
train_cost_avg: 39.2018477907788
train_count_sent: 8544.0
train_total_correct_sent: 5488.0
train_accuracy_sent: 0.6423220973782772
train_count_tok: 163566.0
train_total_correct_tok: 143257.0
train_accuracy_tok: 0.875836053947642
train_label=O_precision_sent: 0.373015873015873
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.053714285714285714
train_label=N_precision_sent: 0.6082281439925199
train_label=N_recall_sent: 0.7861027190332326
train_label=N_f-score_sent: 0.6858197153400105
train_label=P_precision_sent: 0.6857487922705314
train_label=P_recall_sent: 0.7864265927977839
train_label=P_f-score_sent: 0.7326451612903225
train_precision_macro_sent: 0.5556642697596414
train_recall_macro_sent: 0.5338233995101747
train_f-score_macro_sent: 0.49072638744820624
train_precision_micro_sent: 0.6423220973782772
train_recall_micro_sent: 0.6423220973782772
train_f-score_micro_sent: 0.6423220973782772
train_label=O_precision_tok: 0.8880760087997756
train_label=O_recall_tok: 0.9674298535549711
train_label=O_f-score_tok: 0.9260560805219299
train_label=N_precision_tok: 0.7574049302503344
train_label=N_recall_tok: 0.5581608224193776
train_label=N_f-score_tok: 0.6426949894600292
train_label=P_precision_tok: 0.8521142727581906
train_label=P_recall_tok: 0.6009113802614222
train_label=P_f-score_tok: 0.70479851848379
train_precision_macro_tok: 0.8325317372694335
train_recall_macro_tok: 0.708834018745257
train_f-score_macro_tok: 0.7578498628219164
train_precision_micro_tok: 0.875836053947642
train_recall_micro_tok: 0.875836053947642
train_f-score_micro_tok: 0.875836053947642
train_time: 96.65350461006165
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3730    0.0289    0.0537      1624
           N     0.6082    0.7861    0.6858      3310
           P     0.6857    0.7864    0.7326      3610

   micro avg     0.6423    0.6423    0.6423      8544
   macro avg     0.5557    0.5338    0.4907      8544
weighted avg     0.5963    0.6423    0.5855      8544

F1-macro sent:  0.49072638744820624
F1-micro sent:  0.6423220973782772
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8881    0.9674    0.9261    124347
           N     0.7574    0.5582    0.6427     14202
           P     0.8521    0.6009    0.7048     25017

   micro avg     0.8758    0.8758    0.8758    163566
   macro avg     0.8325    0.7088    0.7578    163566
weighted avg     0.8712    0.8758    0.8676    163566

F1-macro tok:  0.7578498628219164
F1-micro tok:  0.875836053947642
**************************************************
dev_cost_sum: 44582.748474121094
dev_cost_avg: 40.492959558693094
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18930.0
dev_accuracy_tok: 0.8898185578640594
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5869565217391305
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.7052238805970149
dev_label=P_precision_sent: 0.701098901098901
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7096774193548387
dev_precision_macro_sent: 0.7626851409460104
dev_recall_macro_sent: 0.5367932210053583
dev_f-score_macro_sent: 0.47740577242262366
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8931568572233174
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.9339222614840988
dev_label=N_precision_tok: 0.7858719646799117
dev_label=N_recall_tok: 0.5751211631663974
dev_label=N_f-score_tok: 0.6641791044776119
dev_label=P_precision_tok: 0.9277777777777778
dev_label=P_recall_tok: 0.6239103362391034
dev_label=P_f-score_tok: 0.7460908413998512
dev_precision_macro_tok: 0.8689355332270022
dev_recall_macro_tok: 0.7258727851047236
dev_f-score_macro_tok: 0.7813974024538539
dev_precision_micro_tok: 0.8898185578640594
dev_recall_micro_tok: 0.8898185578640594
dev_f-score_micro_tok: 0.8898185578640594
dev_time: 5.163089275360107
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5870    0.8832    0.7052       428
           P     0.7011    0.7185    0.7097       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.7627    0.5368    0.4774      1101
weighted avg     0.7189    0.6349    0.5639      1101

F1-macro sent:  0.47740577242262366
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8932    0.9786    0.9339     16205
           N     0.7859    0.5751    0.6642      1857
           P     0.9278    0.6239    0.7461      3212

   micro avg     0.8898    0.8898    0.8898     21274
   macro avg     0.8689    0.7259    0.7814     21274
weighted avg     0.8890    0.8898    0.8820     21274

F1-macro tok:  0.7813974024538539
F1-micro tok:  0.8898185578640594
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 332473.8080444336
train_cost_avg: 38.91313296400206
train_count_sent: 8544.0
train_total_correct_sent: 5518.0
train_accuracy_sent: 0.6458333333333334
train_count_tok: 163566.0
train_total_correct_tok: 143444.0
train_accuracy_tok: 0.8769793233312546
train_label=O_precision_sent: 0.5283018867924528
train_label=O_recall_sent: 0.017241379310344827
train_label=O_f-score_sent: 0.033392963625521764
train_label=N_precision_sent: 0.6165254237288136
train_label=N_recall_sent: 0.7912386706948641
train_label=N_f-score_sent: 0.6930404869012967
train_label=P_precision_sent: 0.6766438840443083
train_label=P_recall_sent: 0.7952908587257618
train_label=P_f-score_sent: 0.7311855341907552
train_precision_macro_sent: 0.6071570648551915
train_recall_macro_sent: 0.5345903029103236
train_f-score_macro_sent: 0.48587299490585795
train_precision_micro_sent: 0.6458333333333334
train_recall_micro_sent: 0.6458333333333334
train_f-score_micro_sent: 0.6458333333333334
train_label=O_precision_tok: 0.8892140128423962
train_label=O_recall_tok: 0.9677756600480912
train_label=O_f-score_tok: 0.9268330252618608
train_label=N_precision_tok: 0.758551881413911
train_label=N_recall_tok: 0.5621039290240811
train_label=N_f-score_tok: 0.6457170589662703
train_label=P_precision_tok: 0.8538596194025637
train_label=P_recall_tok: 0.6044289882879642
train_label=P_f-score_tok: 0.7078125731404766
train_precision_macro_tok: 0.8338751712196237
train_recall_macro_tok: 0.7114361924533789
train_f-score_macro_tok: 0.760120885789536
train_precision_micro_tok: 0.8769793233312546
train_recall_micro_tok: 0.8769793233312546
train_f-score_micro_tok: 0.8769793233312546
train_time: 96.72553896903992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5283    0.0172    0.0334      1624
           N     0.6165    0.7912    0.6930      3310
           P     0.6766    0.7953    0.7312      3610

   micro avg     0.6458    0.6458    0.6458      8544
   macro avg     0.6072    0.5346    0.4859      8544
weighted avg     0.6252    0.6458    0.5838      8544

F1-macro sent:  0.48587299490585795
F1-micro sent:  0.6458333333333334
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8892    0.9678    0.9268    124347
           N     0.7586    0.5621    0.6457     14202
           P     0.8539    0.6044    0.7078     25017

   micro avg     0.8770    0.8770    0.8770    163566
   macro avg     0.8339    0.7114    0.7601    163566
weighted avg     0.8725    0.8770    0.8689    163566

F1-macro tok:  0.760120885789536
F1-micro tok:  0.8769793233312546
**************************************************
dev_cost_sum: 44325.586181640625
dev_cost_avg: 40.259387994224
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18959.0
dev_accuracy_tok: 0.8911817241703488
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.7102564102564103
dev_label=N_recall_sent: 0.647196261682243
dev_label=N_f-score_sent: 0.6772616136919315
dev_label=P_precision_sent: 0.5774647887323944
dev_label=P_recall_sent: 0.9234234234234234
dev_label=P_f-score_sent: 0.7105719237435009
dev_precision_macro_sent: 0.7625737329962683
dev_recall_macro_sent: 0.5249954991109136
dev_f-score_macro_sent: 0.46550972986978173
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8934841323430115
dev_label=O_recall_tok: 0.9798827522369639
dev_label=O_f-score_tok: 0.9346911145775083
dev_label=N_precision_tok: 0.8079315707620529
dev_label=N_recall_tok: 0.559504577275175
dev_label=N_f-score_tok: 0.661151765828826
dev_label=P_precision_tok: 0.921028880866426
dev_label=P_recall_tok: 0.6354296388542964
dev_label=P_f-score_tok: 0.7520265291083272
dev_precision_macro_tok: 0.8741481946571635
dev_recall_macro_tok: 0.7249389894554784
dev_f-score_macro_tok: 0.7826231365048871
dev_precision_micro_tok: 0.8911817241703488
dev_recall_micro_tok: 0.8911817241703488
dev_f-score_micro_tok: 0.8911817241703488
dev_time: 5.09865927696228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.7103    0.6472    0.6773       428
           P     0.5775    0.9234    0.7106       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.7626    0.5250    0.4655      1101
weighted avg     0.7170    0.6249    0.5516      1101

F1-macro sent:  0.46550972986978173
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9799    0.9347     16205
           N     0.8079    0.5595    0.6612      1857
           P     0.9210    0.6354    0.7520      3212

   micro avg     0.8912    0.8912    0.8912     21274
   macro avg     0.8741    0.7249    0.7826     21274
weighted avg     0.8902    0.8912    0.8832     21274

F1-macro tok:  0.7826231365048871
F1-micro tok:  0.8911817241703488
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 329684.00469970703
train_cost_avg: 38.58661103695073
train_count_sent: 8544.0
train_total_correct_sent: 5590.0
train_accuracy_sent: 0.6542602996254682
train_count_tok: 163566.0
train_total_correct_tok: 144067.0
train_accuracy_tok: 0.8807881833632907
train_label=O_precision_sent: 0.39325842696629215
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.040863981319322826
train_label=N_precision_sent: 0.6218097447795824
train_label=N_recall_sent: 0.8096676737160121
train_label=N_f-score_sent: 0.7034120734908137
train_label=P_precision_sent: 0.6936067551266586
train_label=P_recall_sent: 0.796398891966759
train_label=P_f-score_sent: 0.7414571244358478
train_precision_macro_sent: 0.569558308957511
train_recall_macro_sent: 0.5425394299402341
train_f-score_macro_sent: 0.49524439308199475
train_precision_micro_sent: 0.6542602996254682
train_recall_micro_sent: 0.6542602996254682
train_f-score_micro_sent: 0.6542602996254682
train_label=O_precision_tok: 0.8917767803666102
train_label=O_recall_tok: 0.9698907090641511
train_label=O_f-score_tok: 0.9291949488801398
train_label=N_precision_tok: 0.7708748931319465
train_label=N_recall_tok: 0.5713983945923109
train_label=N_f-score_tok: 0.6563144486230742
train_label=P_precision_tok: 0.8623033707865169
train_label=P_recall_tok: 0.6135427909021866
train_label=P_f-score_tok: 0.7169582175304201
train_precision_macro_tok: 0.8416516814283579
train_recall_macro_tok: 0.7182772981862162
train_f-score_macro_tok: 0.7674892050112113
train_precision_micro_tok: 0.8807881833632907
train_recall_micro_tok: 0.8807881833632907
train_f-score_micro_tok: 0.8807881833632907
train_time: 96.75216174125671
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3933    0.0216    0.0409      1624
           N     0.6218    0.8097    0.7034      3310
           P     0.6936    0.7964    0.7415      3610

   micro avg     0.6543    0.6543    0.6543      8544
   macro avg     0.5696    0.5425    0.4952      8544
weighted avg     0.6087    0.6543    0.5936      8544

F1-macro sent:  0.49524439308199475
F1-micro sent:  0.6542602996254682
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9699    0.9292    124347
           N     0.7709    0.5714    0.6563     14202
           P     0.8623    0.6135    0.7170     25017

   micro avg     0.8808    0.8808    0.8808    163566
   macro avg     0.8417    0.7183    0.7675    163566
weighted avg     0.8768    0.8808    0.8730    163566

F1-macro tok:  0.7674892050112113
F1-micro tok:  0.8807881833632907
**************************************************
dev_cost_sum: 44056.849365234375
dev_cost_avg: 40.015303692310965
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 18961.0
dev_accuracy_tok: 0.891275735639748
dev_label=O_precision_sent: 0.5333333333333333
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06557377049180328
dev_label=N_precision_sent: 0.5840840840840841
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.7111517367458866
dev_label=P_precision_sent: 0.7428571428571429
dev_label=P_recall_sent: 0.7027027027027027
dev_label=P_f-score_sent: 0.7222222222222223
dev_precision_macro_sent: 0.6200915200915201
dev_recall_macro_sent: 0.548838568397398
dev_f-score_macro_sent: 0.4996492431533041
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8938660664040518
dev_label=O_recall_tok: 0.9801912989817957
dev_label=O_f-score_tok: 0.9350404709345107
dev_label=N_precision_tok: 0.8259075907590759
dev_label=N_recall_tok: 0.539041464728056
dev_label=N_f-score_tok: 0.6523297491039426
dev_label=P_precision_tok: 0.9057591623036649
dev_label=P_recall_tok: 0.6463262764632628
dev_label=P_f-score_tok: 0.7543604651162791
dev_precision_macro_tok: 0.875177606488931
dev_recall_macro_tok: 0.7218530133910382
dev_f-score_macro_tok: 0.7805768950515773
dev_precision_micro_tok: 0.891275735639748
dev_recall_micro_tok: 0.891275735639748
dev_f-score_micro_tok: 0.891275735639748
dev_time: 5.121122121810913
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5333    0.0349    0.0656       229
           N     0.5841    0.9089    0.7112       428
           P     0.7429    0.7027    0.7222       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.6201    0.5488    0.4996      1101
weighted avg     0.6376    0.6440    0.5813      1101

F1-macro sent:  0.4996492431533041
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8939    0.9802    0.9350     16205
           N     0.8259    0.5390    0.6523      1857
           P     0.9058    0.6463    0.7544      3212

   micro avg     0.8913    0.8913    0.8913     21274
   macro avg     0.8752    0.7219    0.7806     21274
weighted avg     0.8897    0.8913    0.8831     21274

F1-macro tok:  0.7805768950515773
F1-micro tok:  0.891275735639748
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 327367.57165527344
train_cost_avg: 38.31549293718088
train_count_sent: 8544.0
train_total_correct_sent: 5589.0
train_accuracy_sent: 0.6541432584269663
train_count_tok: 163566.0
train_total_correct_tok: 144257.0
train_accuracy_tok: 0.8819497939669614
train_label=O_precision_sent: 0.41843971631205673
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.0668555240793201
train_label=N_precision_sent: 0.6252053508566064
train_label=N_recall_sent: 0.804833836858006
train_label=N_f-score_sent: 0.7037379474309866
train_label=P_precision_sent: 0.6919362626750362
train_label=P_recall_sent: 0.7939058171745152
train_label=P_f-score_sent: 0.7394220846233229
train_precision_macro_sent: 0.5785271099478998
train_recall_macro_sent: 0.5450232344312017
train_f-score_macro_sent: 0.5033385187112098
train_precision_micro_sent: 0.6541432584269663
train_recall_micro_sent: 0.6541432584269663
train_f-score_micro_sent: 0.6541432584269663
train_label=O_precision_tok: 0.8937778107386533
train_label=O_recall_tok: 0.969199096077911
train_label=O_f-score_tok: 0.929961765057661
train_label=N_precision_tok: 0.7687726807481158
train_label=N_recall_tok: 0.5817490494296578
train_label=N_f-score_tok: 0.6623111146739349
train_label=P_precision_tok: 0.8608932643639802
train_label=P_recall_tok: 0.6186992844865491
train_label=P_f-score_tok: 0.7199739510652153
train_precision_macro_tok: 0.8411479186169165
train_recall_macro_tok: 0.7232158099980394
train_f-score_macro_tok: 0.7707489435989371
train_precision_micro_tok: 0.8819497939669614
train_recall_micro_tok: 0.8819497939669614
train_f-score_micro_tok: 0.8819497939669614
train_time: 97.13957905769348
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4184    0.0363    0.0669      1624
           N     0.6252    0.8048    0.7037      3310
           P     0.6919    0.7939    0.7394      3610

   micro avg     0.6541    0.6541    0.6541      8544
   macro avg     0.5785    0.5450    0.5033      8544
weighted avg     0.6141    0.6541    0.5978      8544

F1-macro sent:  0.5033385187112098
F1-micro sent:  0.6541432584269663
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8938    0.9692    0.9300    124347
           N     0.7688    0.5817    0.6623     14202
           P     0.8609    0.6187    0.7200     25017

   micro avg     0.8819    0.8819    0.8819    163566
   macro avg     0.8411    0.7232    0.7707    163566
weighted avg     0.8779    0.8819    0.8746    163566

F1-macro tok:  0.7707489435989371
F1-micro tok:  0.8819497939669614
**************************************************
dev_cost_sum: 43865.29846191406
dev_cost_avg: 39.841324670221674
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19005.0
dev_accuracy_tok: 0.8933439879665319
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5770348837209303
dev_label=N_recall_sent: 0.927570093457944
dev_label=N_f-score_sent: 0.7114695340501792
dev_label=P_precision_sent: 0.7560975609756098
dev_label=P_recall_sent: 0.6981981981981982
dev_label=P_f-score_sent: 0.7259953161592506
dev_precision_macro_sent: 0.6665997037877356
dev_recall_macro_sent: 0.5448339720367635
dev_f-score_macro_sent: 0.4849020765065915
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8977787851314597
dev_label=O_recall_tok: 0.977722925023141
dev_label=O_f-score_tok: 0.9360470268513867
dev_label=N_precision_tok: 0.8174048174048174
dev_label=N_recall_tok: 0.5665051157781368
dev_label=N_f-score_tok: 0.6692111959287532
dev_label=P_precision_tok: 0.9016673792218897
dev_label=P_recall_tok: 0.6566002490660025
dev_label=P_f-score_tok: 0.7598630877319401
dev_precision_macro_tok: 0.8722836605860556
dev_recall_macro_tok: 0.7336094299557602
dev_f-score_macro_tok: 0.7883737701706934
dev_precision_micro_tok: 0.8933439879665319
dev_recall_micro_tok: 0.8933439879665319
dev_f-score_micro_tok: 0.8933439879665319
dev_time: 5.060902833938599
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5770    0.9276    0.7115       428
           P     0.7561    0.6982    0.7260       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.6666    0.5448    0.4849      1101
weighted avg     0.6679    0.6440    0.5729      1101

F1-macro sent:  0.4849020765065915
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8978    0.9777    0.9360     16205
           N     0.8174    0.5665    0.6692      1857
           P     0.9017    0.6566    0.7599      3212

   micro avg     0.8933    0.8933    0.8933     21274
   macro avg     0.8723    0.7336    0.7884     21274
weighted avg     0.8914    0.8933    0.8862     21274

F1-macro tok:  0.7883737701706934
F1-micro tok:  0.8933439879665319
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 325113.95556640625
train_cost_avg: 38.05172700917676
train_count_sent: 8544.0
train_total_correct_sent: 5635.0
train_accuracy_sent: 0.6595271535580525
train_count_tok: 163566.0
train_total_correct_tok: 144718.0
train_accuracy_tok: 0.8847682281158676
train_label=O_precision_sent: 0.47058823529411764
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.08103545301069219
train_label=N_precision_sent: 0.634088200238379
train_label=N_recall_sent: 0.8036253776435045
train_label=N_f-score_sent: 0.7088607594936708
train_label=P_precision_sent: 0.6918493803622497
train_label=P_recall_sent: 0.8041551246537396
train_label=P_f-score_sent: 0.7437868306430951
train_precision_macro_sent: 0.5988419386315821
train_recall_macro_sent: 0.5507051592222342
train_f-score_macro_sent: 0.5112276810491526
train_precision_micro_sent: 0.6595271535580525
train_recall_micro_sent: 0.6595271535580525
train_f-score_micro_sent: 0.6595271535580525
train_label=O_precision_tok: 0.8956417848423458
train_label=O_recall_tok: 0.9706225321077308
train_label=O_f-score_tok: 0.931625910831172
train_label=N_precision_tok: 0.7733320926770262
train_label=N_recall_tok: 0.5851992677087734
train_label=N_f-score_tok: 0.6662391278207543
train_label=P_precision_tok: 0.869947957036873
train_label=P_recall_tok: 0.6280928968301555
train_label=P_f-score_tok: 0.7294969706817708
train_precision_macro_tok: 0.8463072781854151
train_recall_macro_tok: 0.7279715655488865
train_f-score_macro_tok: 0.7757873364445657
train_precision_micro_tok: 0.8847682281158676
train_recall_micro_tok: 0.8847682281158676
train_f-score_micro_tok: 0.8847682281158676
train_time: 96.38918495178223
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4706    0.0443    0.0810      1624
           N     0.6341    0.8036    0.7089      3310
           P     0.6918    0.8042    0.7438      3610

   micro avg     0.6595    0.6595    0.6595      8544
   macro avg     0.5988    0.5507    0.5112      8544
weighted avg     0.6274    0.6595    0.6043      8544

F1-macro sent:  0.5112276810491526
F1-micro sent:  0.6595271535580525
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8956    0.9706    0.9316    124347
           N     0.7733    0.5852    0.6662     14202
           P     0.8699    0.6281    0.7295     25017

   micro avg     0.8848    0.8848    0.8848    163566
   macro avg     0.8463    0.7280    0.7758    163566
weighted avg     0.8811    0.8848    0.8777    163566

F1-macro tok:  0.7757873364445657
F1-micro tok:  0.8847682281158676
**************************************************
dev_cost_sum: 43570.424072265625
dev_cost_avg: 39.57350051976896
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19015.0
dev_accuracy_tok: 0.8938140453135283
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.6483126110124334
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7366296670030272
dev_label=P_precision_sent: 0.6940726577437859
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.750775594622544
dev_precision_macro_sent: 0.6919062006965175
dev_recall_macro_sent: 0.5728020801277137
dev_f-score_macro_sent: 0.5258563986839335
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.8996020466173963
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9364698919958575
dev_label=N_precision_tok: 0.7910339840925524
dev_label=N_recall_tok: 0.589122240172321
dev_label=N_f-score_tok: 0.6753086419753087
dev_label=P_precision_tok: 0.9113428943937418
dev_label=P_recall_tok: 0.6528642590286425
dev_label=P_f-score_tok: 0.7607473245057138
dev_precision_macro_tok: 0.8673263083678968
dev_recall_macro_tok: 0.7394917457482592
dev_f-score_macro_tok: 0.7908419528256266
dev_precision_micro_tok: 0.8938140453135283
dev_recall_micro_tok: 0.8938140453135283
dev_f-score_micro_tok: 0.8938140453135283
dev_time: 5.106153726577759
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.6483    0.8528    0.7366       428
           P     0.6941    0.8176    0.7508       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6919    0.5728    0.5259      1101
weighted avg     0.6844    0.6712    0.6079      1101

F1-macro sent:  0.5258563986839335
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8996    0.9765    0.9365     16205
           N     0.7910    0.5891    0.6753      1857
           P     0.9113    0.6529    0.7607      3212

   micro avg     0.8938    0.8938    0.8938     21274
   macro avg     0.8673    0.7395    0.7908     21274
weighted avg     0.8919    0.8938    0.8871     21274

F1-macro tok:  0.7908419528256266
F1-micro tok:  0.8938140453135283
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 323236.10638427734
train_cost_avg: 37.83194129029463
train_count_sent: 8544.0
train_total_correct_sent: 5636.0
train_accuracy_sent: 0.6596441947565543
train_count_tok: 163566.0
train_total_correct_tok: 144897.0
train_accuracy_tok: 0.8858625875793258
train_label=O_precision_sent: 0.43859649122807015
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08356545961002786
train_label=N_precision_sent: 0.62401300510915
train_label=N_recall_sent: 0.8117824773413898
train_label=N_f-score_sent: 0.7056197478991597
train_label=P_precision_sent: 0.706663388246865
train_label=P_recall_sent: 0.7961218836565097
train_label=P_f-score_sent: 0.7487299726455646
train_precision_macro_sent: 0.589757628194695
train_recall_macro_sent: 0.5513622090025839
train_f-score_macro_sent: 0.5126383933849173
train_precision_micro_sent: 0.6596441947565543
train_recall_micro_sent: 0.6596441947565543
train_f-score_micro_sent: 0.6596441947565543
train_label=O_precision_tok: 0.8971193109552463
train_label=O_recall_tok: 0.9699872132017661
train_label=O_f-score_tok: 0.9321313477128528
train_label=N_precision_tok: 0.779061239457279
train_label=N_recall_tok: 0.5983664272637657
train_label=N_f-score_tok: 0.6768618080446038
train_label=P_precision_tok: 0.8667289001153149
train_label=P_recall_tok: 0.6309309669424791
train_label=P_f-score_tok: 0.7302674192652909
train_precision_macro_tok: 0.8476364835092801
train_recall_macro_tok: 0.7330948691360036
train_f-score_macro_tok: 0.7797535250075825
train_precision_micro_tok: 0.8858625875793258
train_recall_micro_tok: 0.8858625875793258
train_f-score_micro_tok: 0.8858625875793258
train_time: 97.88321876525879
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4386    0.0462    0.0836      1624
           N     0.6240    0.8118    0.7056      3310
           P     0.7067    0.7961    0.7487      3610

   micro avg     0.6596    0.6596    0.6596      8544
   macro avg     0.5898    0.5514    0.5126      8544
weighted avg     0.6237    0.6596    0.6056      8544

F1-macro sent:  0.5126383933849173
F1-micro sent:  0.6596441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8971    0.9700    0.9321    124347
           N     0.7791    0.5984    0.6769     14202
           P     0.8667    0.6309    0.7303     25017

   micro avg     0.8859    0.8859    0.8859    163566
   macro avg     0.8476    0.7331    0.7798    163566
weighted avg     0.8822    0.8859    0.8791    163566

F1-macro tok:  0.7797535250075825
F1-micro tok:  0.8858625875793258
**************************************************
dev_cost_sum: 43494.85632324219
dev_cost_avg: 39.50486496207283
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19019.0
dev_accuracy_tok: 0.8940020682523268
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6666666666666666
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7190527448869751
dev_label=P_precision_sent: 0.6471571906354515
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.7428023032629559
dev_precision_macro_sent: 0.7712746191007059
dev_recall_macro_sent: 0.5535763592838236
dev_f-score_macro_sent: 0.49305702182198274
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.8989497587283565
dev_label=O_recall_tok: 0.9771675408824437
dev_label=O_f-score_tok: 0.9364281490242461
dev_label=N_precision_tok: 0.7852586817859674
dev_label=N_recall_tok: 0.596661281637049
dev_label=N_f-score_tok: 0.6780905752753978
dev_label=P_precision_tok: 0.9234875444839857
dev_label=P_recall_tok: 0.6463262764632628
dev_label=P_f-score_tok: 0.7604395604395604
dev_precision_macro_tok: 0.8692319949994366
dev_recall_macro_tok: 0.7400516996609184
dev_f-score_macro_tok: 0.7916527615797347
dev_precision_micro_tok: 0.8940020682523268
dev_recall_micro_tok: 0.8940020682523268
dev_f-score_micro_tok: 0.8940020682523268
dev_time: 5.079993009567261
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6667    0.7804    0.7191       428
           P     0.6472    0.8716    0.7428       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.7713    0.5536    0.4931      1101
weighted avg     0.7281    0.6567    0.5827      1101

F1-macro sent:  0.49305702182198274
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9772    0.9364     16205
           N     0.7853    0.5967    0.6781      1857
           P     0.9235    0.6463    0.7604      3212

   micro avg     0.8940    0.8940    0.8940     21274
   macro avg     0.8692    0.7401    0.7917     21274
weighted avg     0.8927    0.8940    0.8873     21274

F1-macro tok:  0.7916527615797347
F1-micro tok:  0.8940020682523268
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 321108.67248535156
train_cost_avg: 37.58294387703085
train_count_sent: 8544.0
train_total_correct_sent: 5689.0
train_accuracy_sent: 0.6658473782771536
train_count_tok: 163566.0
train_total_correct_tok: 145339.0
train_accuracy_tok: 0.888564860667865
train_label=O_precision_sent: 0.41081081081081083
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.08402432283029299
train_label=N_precision_sent: 0.6258845012554212
train_label=N_recall_sent: 0.8283987915407856
train_label=N_f-score_sent: 0.7130412170068914
train_label=P_precision_sent: 0.7217194570135747
train_label=P_recall_sent: 0.7952908587257618
train_label=P_f-score_sent: 0.7567211386399578
train_precision_macro_sent: 0.5861382563599355
train_recall_macro_sent: 0.5568292266077325
train_f-score_macro_sent: 0.5179288928257141
train_precision_micro_sent: 0.6658473782771536
train_recall_micro_sent: 0.6658473782771536
train_f-score_micro_sent: 0.6658473782771536
train_label=O_precision_tok: 0.8995419165021787
train_label=O_recall_tok: 0.971217640956356
train_label=O_f-score_tok: 0.9340066975506763
train_label=N_precision_tok: 0.7807193719189337
train_label=N_recall_tok: 0.602168708632587
train_label=N_f-score_tok: 0.6799173159484815
train_label=P_precision_tok: 0.8726371411450673
train_label=P_recall_tok: 0.6403245792860854
train_label=P_f-score_tok: 0.738645271360723
train_precision_macro_tok: 0.8509661431887267
train_recall_macro_tok: 0.7379036429583428
train_f-score_macro_tok: 0.7841897616199601
train_precision_micro_tok: 0.888564860667865
train_recall_micro_tok: 0.888564860667865
train_f-score_micro_tok: 0.888564860667865
train_time: 96.24422693252563
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4108    0.0468    0.0840      1624
           N     0.6259    0.8284    0.7130      3310
           P     0.7217    0.7953    0.7567      3610

   micro avg     0.6658    0.6658    0.6658      8544
   macro avg     0.5861    0.5568    0.5179      8544
weighted avg     0.6255    0.6658    0.6119      8544

F1-macro sent:  0.5179288928257141
F1-micro sent:  0.6658473782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8995    0.9712    0.9340    124347
           N     0.7807    0.6022    0.6799     14202
           P     0.8726    0.6403    0.7386     25017

   micro avg     0.8886    0.8886    0.8886    163566
   macro avg     0.8510    0.7379    0.7842    163566
weighted avg     0.8851    0.8886    0.8821    163566

F1-macro tok:  0.7841897616199601
F1-micro tok:  0.888564860667865
**************************************************
dev_cost_sum: 43273.372619628906
dev_cost_avg: 39.303699018736516
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 19061.0
dev_accuracy_tok: 0.8959763091097114
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06666666666666667
dev_label=N_precision_sent: 0.5775480059084195
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.7076923076923077
dev_label=P_precision_sent: 0.7457627118644068
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7187864644107352
dev_precision_macro_sent: 0.6835278150151846
dev_recall_macro_sent: 0.5473931977931489
dev_f-score_macro_sent: 0.4977151462565699
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8992357769600906
dev_label=O_recall_tok: 0.9802530083307621
dev_label=O_f-score_tok: 0.9379982285208149
dev_label=N_precision_tok: 0.7949275362318841
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6777880753784368
dev_label=P_precision_tok: 0.9327052489905787
dev_label=P_recall_tok: 0.6472602739726028
dev_label=P_f-score_tok: 0.7641977577651168
dev_precision_macro_tok: 0.8756228540608512
dev_recall_macro_tok: 0.7394170104536615
dev_f-score_macro_tok: 0.7933280205547896
dev_precision_micro_tok: 0.8959763091097114
dev_recall_micro_tok: 0.8959763091097114
dev_f-score_micro_tok: 0.8959763091097114
dev_time: 5.143616437911987
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0349    0.0667       229
           N     0.5775    0.9136    0.7077       428
           P     0.7458    0.6937    0.7188       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6835    0.5474    0.4977      1101
weighted avg     0.6765    0.6421    0.5788      1101

F1-macro sent:  0.4977151462565699
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9803    0.9380     16205
           N     0.7949    0.5907    0.6778      1857
           P     0.9327    0.6473    0.7642      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8756    0.7394    0.7933     21274
weighted avg     0.8952    0.8960    0.8890     21274

F1-macro tok:  0.7933280205547896
F1-micro tok:  0.8959763091097114
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 319305.5710449219
train_cost_avg: 37.371906723422505
train_count_sent: 8544.0
train_total_correct_sent: 5721.0
train_accuracy_sent: 0.6695926966292135
train_count_tok: 163566.0
train_total_correct_tok: 145570.0
train_accuracy_tok: 0.8899771346123277
train_label=O_precision_sent: 0.4398496240601504
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.12380952380952381
train_label=N_precision_sent: 0.6367650476411806
train_label=N_recall_sent: 0.8277945619335347
train_label=N_f-score_sent: 0.7198213582030737
train_label=P_precision_sent: 0.720503144654088
train_label=P_recall_sent: 0.7933518005540167
train_label=P_f-score_sent: 0.755174686882004
train_precision_macro_sent: 0.599039272118473
train_recall_macro_sent: 0.5643968991543069
train_f-score_macro_sent: 0.5329351896315339
train_precision_micro_sent: 0.6695926966292135
train_recall_micro_sent: 0.6695926966292135
train_f-score_micro_sent: 0.6695926966292135
train_label=O_precision_tok: 0.900507561246469
train_label=O_recall_tok: 0.9716519095756231
train_label=O_f-score_tok: 0.9347279493110731
train_label=N_precision_tok: 0.7860655737704918
train_label=N_recall_tok: 0.6077313054499366
train_label=N_f-score_tok: 0.6854896354538955
train_label=P_precision_tok: 0.8752104262829216
train_label=P_recall_tok: 0.6442419154974617
train_label=P_f-score_tok: 0.7421716706575796
train_precision_macro_tok: 0.8539278537666274
train_recall_macro_tok: 0.741208376841007
train_f-score_macro_tok: 0.7874630851408494
train_precision_micro_tok: 0.8899771346123277
train_recall_micro_tok: 0.8899771346123277
train_f-score_micro_tok: 0.8899771346123277
train_time: 97.47361063957214
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4398    0.0720    0.1238      1624
           N     0.6368    0.8278    0.7198      3310
           P     0.7205    0.7934    0.7552      3610

   micro avg     0.6696    0.6696    0.6696      8544
   macro avg     0.5990    0.5644    0.5329      8544
weighted avg     0.6347    0.6696    0.6215      8544

F1-macro sent:  0.5329351896315339
F1-micro sent:  0.6695926966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9005    0.9717    0.9347    124347
           N     0.7861    0.6077    0.6855     14202
           P     0.8752    0.6442    0.7422     25017

   micro avg     0.8900    0.8900    0.8900    163566
   macro avg     0.8539    0.7412    0.7875    163566
weighted avg     0.8867    0.8900    0.8836    163566

F1-macro tok:  0.7874630851408494
F1-micro tok:  0.8899771346123277
**************************************************
dev_cost_sum: 43211.62658691406
dev_cost_avg: 39.247617245153556
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19029.0
dev_accuracy_tok: 0.8944721255993231
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05042016806722689
dev_label=N_precision_sent: 0.6235489220563848
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7293889427740059
dev_label=P_precision_sent: 0.7116564417177914
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7459807073954985
dev_precision_macro_sent: 0.6672906768136143
dev_recall_macro_sent: 0.5628297766811418
dev_f-score_macro_sent: 0.5085966060789104
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.89316693715373
dev_label=O_recall_tok: 0.9848812095032398
dev_label=O_f-score_tok: 0.9367846451840113
dev_label=N_precision_tok: 0.8346905537459284
dev_label=N_recall_tok: 0.5519655358104469
dev_label=N_f-score_tok: 0.6645056726094004
dev_label=P_precision_tok: 0.9389067524115756
dev_label=P_recall_tok: 0.6363636363636364
dev_label=P_f-score_tok: 0.7585822972722213
dev_precision_macro_tok: 0.888921414437078
dev_recall_macro_tok: 0.7244034605591078
dev_f-score_macro_tok: 0.7866242050218776
dev_precision_micro_tok: 0.8944721255993231
dev_recall_micro_tok: 0.8944721255993231
dev_f-score_micro_tok: 0.8944721255993231
dev_time: 5.058055877685547
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0262    0.0504       229
           N     0.6235    0.8785    0.7294       428
           P     0.7117    0.7838    0.7460       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6673    0.5628    0.5086      1101
weighted avg     0.6680    0.6630    0.5949      1101

F1-macro sent:  0.5085966060789104
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8932    0.9849    0.9368     16205
           N     0.8347    0.5520    0.6645      1857
           P     0.9389    0.6364    0.7586      3212

   micro avg     0.8945    0.8945    0.8945     21274
   macro avg     0.8889    0.7244    0.7866     21274
weighted avg     0.8950    0.8945    0.8861     21274

F1-macro tok:  0.7866242050218776
F1-micro tok:  0.8944721255993231
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 317313.7682495117
train_cost_avg: 37.138783737068316
train_count_sent: 8544.0
train_total_correct_sent: 5739.0
train_accuracy_sent: 0.6716994382022472
train_count_tok: 163566.0
train_total_correct_tok: 145874.0
train_accuracy_tok: 0.8918357115782009
train_label=O_precision_sent: 0.44214876033057854
train_label=O_recall_sent: 0.06588669950738917
train_label=O_f-score_sent: 0.11468381564844587
train_label=N_precision_sent: 0.642840180479696
train_label=N_recall_sent: 0.8178247734138973
train_label=N_f-score_sent: 0.7198510836324957
train_label=P_precision_sent: 0.7149841114641897
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.7596416049863655
train_precision_macro_sent: 0.5999910174248214
train_recall_macro_sent: 0.564653593466837
train_f-score_macro_sent: 0.5313921680891024
train_precision_micro_sent: 0.6716994382022472
train_recall_micro_sent: 0.6716994382022472
train_f-score_micro_sent: 0.6716994382022472
train_label=O_precision_tok: 0.9022922422160831
train_label=O_recall_tok: 0.9718288338279171
train_label=O_f-score_tok: 0.9357705099563647
train_label=N_precision_tok: 0.7886942387574499
train_label=N_recall_tok: 0.6149838050978735
train_label=N_f-score_tok: 0.6910903623991138
train_label=P_precision_tok: 0.8779226376468053
train_label=P_recall_tok: 0.6513970500059959
train_label=P_f-score_tok: 0.7478831547304895
train_precision_macro_tok: 0.8563030395401129
train_recall_macro_tok: 0.7460698963105955
train_f-score_macro_tok: 0.7915813423619893
train_precision_micro_tok: 0.8918357115782009
train_recall_micro_tok: 0.8918357115782009
train_f-score_micro_tok: 0.8918357115782009
train_time: 97.66299676895142
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4421    0.0659    0.1147      1624
           N     0.6428    0.8178    0.7199      3310
           P     0.7150    0.8102    0.7596      3610

   micro avg     0.6717    0.6717    0.6717      8544
   macro avg     0.6000    0.5647    0.5314      8544
weighted avg     0.6352    0.6717    0.6216      8544

F1-macro sent:  0.5313921680891024
F1-micro sent:  0.6716994382022472
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9023    0.9718    0.9358    124347
           N     0.7887    0.6150    0.6911     14202
           P     0.8779    0.6514    0.7479     25017

   micro avg     0.8918    0.8918    0.8918    163566
   macro avg     0.8563    0.7461    0.7916    163566
weighted avg     0.8887    0.8918    0.8858    163566

F1-macro tok:  0.7915813423619893
F1-micro tok:  0.8918357115782009
**************************************************
dev_cost_sum: 42970.30810546875
dev_cost_avg: 39.02843606309605
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6331058020477816
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7317554240631164
dev_label=P_precision_sent: 0.6968503937007874
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.7436974789915967
dev_precision_macro_sent: 0.6814139700114278
dev_recall_macro_sent: 0.5619845961130702
dev_f-score_macro_sent: 0.5059419281368818
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.899847138085263
dev_label=O_recall_tok: 0.9808083924714595
dev_label=O_f-score_tok: 0.938585095074997
dev_label=N_precision_tok: 0.813849590469099
dev_label=N_recall_tok: 0.5885837372105547
dev_label=N_f-score_tok: 0.683125
dev_label=P_precision_tok: 0.9285714285714286
dev_label=P_recall_tok: 0.6556662515566625
dev_label=P_f-score_tok: 0.7686131386861313
dev_precision_macro_tok: 0.8807560523752634
dev_recall_macro_tok: 0.7416861270795589
dev_f-score_macro_tok: 0.7967744112537094
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 5.125820636749268
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6331    0.8668    0.7318       428
           P     0.6969    0.7973    0.7437       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6814    0.5620    0.5059      1101
weighted avg     0.6757    0.6630    0.5932      1101

F1-macro sent:  0.5059419281368818
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8998    0.9808    0.9386     16205
           N     0.8138    0.5886    0.6831      1857
           P     0.9286    0.6557    0.7686      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8808    0.7417    0.7968     21274
weighted avg     0.8967    0.8975    0.8906     21274

F1-macro tok:  0.7967744112537094
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 315634.9237060547
train_cost_avg: 36.94228975960378
train_count_sent: 8544.0
train_total_correct_sent: 5758.0
train_accuracy_sent: 0.6739232209737828
train_count_tok: 163566.0
train_total_correct_tok: 146026.0
train_accuracy_tok: 0.8927650000611373
train_label=O_precision_sent: 0.40268456375838924
train_label=O_recall_sent: 0.07389162561576355
train_label=O_f-score_sent: 0.12486992715920917
train_label=N_precision_sent: 0.6462153267512929
train_label=N_recall_sent: 0.8305135951661632
train_label=N_f-score_sent: 0.7268640930724485
train_label=P_precision_sent: 0.7236973947895792
train_label=P_recall_sent: 0.8002770083102493
train_label=P_f-score_sent: 0.7600631412786109
train_precision_macro_sent: 0.5908657617664205
train_recall_macro_sent: 0.5682274096973919
train_f-score_macro_sent: 0.5372657205034228
train_precision_micro_sent: 0.6739232209737828
train_recall_micro_sent: 0.6739232209737828
train_f-score_micro_sent: 0.6739232209737828
train_label=O_precision_tok: 0.9037858783222746
train_label=O_recall_tok: 0.9716277835412194
train_label=O_f-score_tok: 0.936479761886307
train_label=N_precision_tok: 0.7891717461455718
train_label=N_recall_tok: 0.619912688353753
train_label=N_f-score_tok: 0.6943765281173594
train_label=P_precision_tok: 0.8758075711463505
train_label=P_recall_tok: 0.6556741415837231
train_label=P_f-score_tok: 0.7499199926850456
train_precision_macro_tok: 0.8562550652047324
train_recall_macro_tok: 0.7490715378262318
train_f-score_macro_tok: 0.7935920942295707
train_precision_micro_tok: 0.8927650000611373
train_recall_micro_tok: 0.8927650000611373
train_f-score_micro_tok: 0.8927650000611373
train_time: 96.62091016769409
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4027    0.0739    0.1249      1624
           N     0.6462    0.8305    0.7269      3310
           P     0.7237    0.8003    0.7601      3610

   micro avg     0.6739    0.6739    0.6739      8544
   macro avg     0.5909    0.5682    0.5373      8544
weighted avg     0.6327    0.6739    0.6265      8544

F1-macro sent:  0.5372657205034228
F1-micro sent:  0.6739232209737828
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9038    0.9716    0.9365    124347
           N     0.7892    0.6199    0.6944     14202
           P     0.8758    0.6557    0.7499     25017

   micro avg     0.8928    0.8928    0.8928    163566
   macro avg     0.8563    0.7491    0.7936    163566
weighted avg     0.8896    0.8928    0.8869    163566

F1-macro tok:  0.7935920942295707
F1-micro tok:  0.8927650000611373
**************************************************
dev_cost_sum: 42836.849609375
dev_cost_avg: 38.90722035365577
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19077.0
dev_accuracy_tok: 0.8967284008649056
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06611570247933884
dev_label=N_precision_sent: 0.6673189823874756
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7263045793397231
dev_label=P_precision_sent: 0.658578856152513
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7443682664054849
dev_precision_macro_sent: 0.6470941513082014
dev_recall_macro_sent: 0.5625064418783555
dev_f-score_macro_sent: 0.5122628494081823
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9049011177987962
dev_label=O_recall_tok: 0.9741437827830917
dev_label=O_f-score_tok: 0.9382466567607727
dev_label=N_precision_tok: 0.7977044476327116
dev_label=N_recall_tok: 0.5988152934841141
dev_label=N_f-score_tok: 0.6840972008612733
dev_label=P_precision_tok: 0.8948665297741273
dev_label=P_recall_tok: 0.6783935242839353
dev_label=P_f-score_tok: 0.7717372055958915
dev_precision_macro_tok: 0.8658240317352117
dev_recall_macro_tok: 0.7504508668503803
dev_f-score_macro_tok: 0.7980270210726458
dev_precision_micro_tok: 0.8967284008649056
dev_recall_micro_tok: 0.8967284008649056
dev_f-score_micro_tok: 0.8967284008649056
dev_time: 5.175079345703125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0349    0.0661       229
           N     0.6673    0.7967    0.7263       428
           P     0.6586    0.8559    0.7444       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6471    0.5625    0.5123      1101
weighted avg     0.6530    0.6621    0.5963      1101

F1-macro sent:  0.5122628494081823
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9049    0.9741    0.9382     16205
           N     0.7977    0.5988    0.6841      1857
           P     0.8949    0.6784    0.7717      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8658    0.7505    0.7980     21274
weighted avg     0.8940    0.8967    0.8909     21274

F1-macro tok:  0.7980270210726458
F1-micro tok:  0.8967284008649056
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 313501.8961791992
train_cost_avg: 36.69263766142313
train_count_sent: 8544.0
train_total_correct_sent: 5768.0
train_accuracy_sent: 0.6750936329588015
train_count_tok: 163566.0
train_total_correct_tok: 146463.0
train_accuracy_tok: 0.89543670444958
train_label=O_precision_sent: 0.4712041884816754
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.09917355371900827
train_label=N_precision_sent: 0.638141246836899
train_label=N_recall_sent: 0.8380664652567976
train_label=N_f-score_sent: 0.7245657568238214
train_label=P_precision_sent: 0.7249126310534199
train_label=P_recall_sent: 0.804432132963989
train_label=P_f-score_sent: 0.7626050420168067
train_precision_macro_sent: 0.6114193554573314
train_recall_macro_sent: 0.565972439144203
train_f-score_macro_sent: 0.5287814508532122
train_precision_micro_sent: 0.6750936329588015
train_recall_micro_sent: 0.6750936329588015
train_f-score_micro_sent: 0.6750936329588015
train_label=O_precision_tok: 0.906602230260097
train_label=O_recall_tok: 0.971571489460944
train_label=O_f-score_tok: 0.9379631606529377
train_label=N_precision_tok: 0.7978374545776833
train_label=N_recall_tok: 0.6338543867060977
train_label=N_f-score_tok: 0.7064547773199921
train_label=P_precision_tok: 0.8751116951379764
train_label=P_recall_tok: 0.6655074549306471
train_label=P_f-score_tok: 0.7560510421870033
train_precision_macro_tok: 0.8598504599919189
train_recall_macro_tok: 0.7569777770325629
train_f-score_macro_tok: 0.8001563267199776
train_precision_micro_tok: 0.89543670444958
train_recall_micro_tok: 0.89543670444958
train_f-score_micro_tok: 0.89543670444958
train_time: 96.71754884719849
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4712    0.0554    0.0992      1624
           N     0.6381    0.8381    0.7246      3310
           P     0.7249    0.8044    0.7626      3610

   micro avg     0.6751    0.6751    0.6751      8544
   macro avg     0.6114    0.5660    0.5288      8544
weighted avg     0.6431    0.6751    0.6218      8544

F1-macro sent:  0.5287814508532122
F1-micro sent:  0.6750936329588015
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9066    0.9716    0.9380    124347
           N     0.7978    0.6339    0.7065     14202
           P     0.8751    0.6655    0.7561     25017

   micro avg     0.8954    0.8954    0.8954    163566
   macro avg     0.8599    0.7570    0.8002    163566
weighted avg     0.8923    0.8954    0.8900    163566

F1-macro tok:  0.8001563267199776
F1-micro tok:  0.89543670444958
**************************************************
dev_cost_sum: 42745.229064941406
dev_cost_avg: 38.82400460031009
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19099.0
dev_accuracy_tok: 0.8977625270282974
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.6357142857142857
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7206477732793523
dev_label=P_precision_sent: 0.6779026217228464
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.7402862985685071
dev_precision_macro_sent: 0.7235865881933298
dev_recall_macro_sent: 0.5577639632041134
dev_f-score_macro_sent: 0.5039271764916594
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9098958333333333
dev_label=O_recall_tok: 0.9702560937982104
dev_label=O_f-score_tok: 0.939107062863969
dev_label=N_precision_tok: 0.7665369649805448
dev_label=N_recall_tok: 0.6365105008077544
dev_label=N_f-score_tok: 0.6954986760812003
dev_label=P_precision_tok: 0.8947797716150081
dev_label=P_recall_tok: 0.6830635118306351
dev_label=P_f-score_tok: 0.7747175141242937
dev_precision_macro_tok: 0.8570708566429621
dev_recall_macro_tok: 0.7632767021455332
dev_f-score_macro_tok: 0.8031077510231542
dev_precision_micro_tok: 0.8977625270282974
dev_recall_micro_tok: 0.8977625270282974
dev_f-score_micro_tok: 0.8977625270282974
dev_time: 5.151316165924072
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.6357    0.8318    0.7206       428
           P     0.6779    0.8153    0.7403       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7236    0.5578    0.5039      1101
weighted avg     0.6988    0.6576    0.5893      1101

F1-macro sent:  0.5039271764916594
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9099    0.9703    0.9391     16205
           N     0.7665    0.6365    0.6955      1857
           P     0.8948    0.6831    0.7747      3212

   micro avg     0.8978    0.8978    0.8978     21274
   macro avg     0.8571    0.7633    0.8031     21274
weighted avg     0.8951    0.8978    0.8930     21274

F1-macro tok:  0.8031077510231542
F1-micro tok:  0.8977625270282974
**************************************************
Best epoch: 14
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 311843.55041503906
train_cost_avg: 36.49854288565532
train_count_sent: 8544.0
train_total_correct_sent: 5774.0
train_accuracy_sent: 0.6757958801498127
train_count_tok: 163566.0
train_total_correct_tok: 146788.0
train_accuracy_tok: 0.8974236699558588
train_label=O_precision_sent: 0.46153846153846156
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.12185996793158738
train_label=N_precision_sent: 0.6490257397161414
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.72264631043257
train_label=P_precision_sent: 0.7154589371980676
train_label=P_recall_sent: 0.8204986149584488
train_label=P_f-score_sent: 0.7643870967741936
train_precision_macro_sent: 0.6086743794842234
train_recall_macro_sent: 0.5686004664915644
train_f-score_macro_sent: 0.5362977917127837
train_precision_micro_sent: 0.6757958801498127
train_recall_micro_sent: 0.6757958801498127
train_f-score_micro_sent: 0.6757958801498127
train_label=O_precision_tok: 0.9086576767540101
train_label=O_recall_tok: 0.9721665983095692
train_label=O_f-score_tok: 0.9393398993725354
train_label=N_precision_tok: 0.7967515364354697
train_label=N_recall_tok: 0.6389945078158006
train_label=N_f-score_tok: 0.7092060018755862
train_label=P_precision_tok: 0.8792454801964678
train_label=P_recall_tok: 0.6726226166206979
train_label=P_f-score_tok: 0.7621786887102253
train_precision_macro_tok: 0.8615515644619824
train_recall_macro_tok: 0.761261240915356
train_f-score_macro_tok: 0.803574863319449
train_precision_micro_tok: 0.8974236699558588
train_recall_micro_tok: 0.8974236699558588
train_f-score_micro_tok: 0.8974236699558588
train_time: 97.80504655838013
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0702    0.1219      1624
           N     0.6490    0.8151    0.7226      3310
           P     0.7155    0.8205    0.7644      3610

   micro avg     0.6758    0.6758    0.6758      8544
   macro avg     0.6087    0.5686    0.5363      8544
weighted avg     0.6415    0.6758    0.6261      8544

F1-macro sent:  0.5362977917127837
F1-micro sent:  0.6757958801498127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9087    0.9722    0.9393    124347
           N     0.7968    0.6390    0.7092     14202
           P     0.8792    0.6726    0.7622     25017

   micro avg     0.8974    0.8974    0.8974    163566
   macro avg     0.8616    0.7613    0.8036    163566
weighted avg     0.8944    0.8974    0.8923    163566

F1-macro tok:  0.803574863319449
F1-micro tok:  0.8974236699558588
**************************************************
dev_cost_sum: 42681.193786621094
dev_cost_avg: 38.76584358457865
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19138.0
dev_accuracy_tok: 0.8995957506815832
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.656934306569343
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7377049180327869
dev_label=P_precision_sent: 0.6869244935543278
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7558257345491387
dev_precision_macro_sent: 0.7146196000412237
dev_recall_macro_sent: 0.5720486944112623
dev_f-score_macro_sent: 0.5201587530921621
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9070981809835313
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.9400570884871552
dev_label=N_precision_tok: 0.7940566689702834
dev_label=N_recall_tok: 0.6187399030694669
dev_label=N_f-score_tok: 0.6955205811138014
dev_label=P_precision_tok: 0.90875
dev_label=P_recall_tok: 0.6790161892901619
dev_label=P_f-score_tok: 0.7772630078403421
dev_precision_macro_tok: 0.8699682833179382
dev_recall_macro_tok: 0.7577524936066603
dev_f-score_macro_tok: 0.8042802258137662
dev_precision_micro_tok: 0.8995957506815832
dev_recall_micro_tok: 0.8995957506815832
dev_f-score_micro_tok: 0.8995957506815832
dev_time: 5.083397626876831
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6569    0.8411    0.7377       428
           P     0.6869    0.8401    0.7558       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.7146    0.5720    0.5202      1101
weighted avg     0.6988    0.6730    0.6055      1101

F1-macro sent:  0.5201587530921621
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9071    0.9755    0.9401     16205
           N     0.7941    0.6187    0.6955      1857
           P     0.9087    0.6790    0.7773      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8700    0.7578    0.8043     21274
weighted avg     0.8975    0.8996    0.8941     21274

F1-macro tok:  0.8042802258137662
F1-micro tok:  0.8995957506815832
**************************************************
Best epoch: 14
**************************************************

test0_cost_sum: 43570.424072265625
test0_cost_avg: 39.57350051976896
test0_count_sent: 1101.0
test0_total_correct_sent: 739.0
test0_accuracy_sent: 0.6712079927338783
test0_count_tok: 21274.0
test0_total_correct_tok: 19015.0
test0_accuracy_tok: 0.8938140453135283
test0_label=O_precision_sent: 0.7333333333333333
test0_label=O_recall_sent: 0.048034934497816595
test0_label=O_f-score_sent: 0.09016393442622951
test0_label=N_precision_sent: 0.6483126110124334
test0_label=N_recall_sent: 0.852803738317757
test0_label=N_f-score_sent: 0.7366296670030272
test0_label=P_precision_sent: 0.6940726577437859
test0_label=P_recall_sent: 0.8175675675675675
test0_label=P_f-score_sent: 0.750775594622544
test0_precision_macro_sent: 0.6919062006965175
test0_recall_macro_sent: 0.5728020801277137
test0_f-score_macro_sent: 0.5258563986839335
test0_precision_micro_sent: 0.6712079927338783
test0_recall_micro_sent: 0.6712079927338783
test0_f-score_micro_sent: 0.6712079927338783
test0_label=O_precision_tok: 0.8996020466173963
test0_label=O_recall_tok: 0.9764887380438136
test0_label=O_f-score_tok: 0.9364698919958575
test0_label=N_precision_tok: 0.7910339840925524
test0_label=N_recall_tok: 0.589122240172321
test0_label=N_f-score_tok: 0.6753086419753087
test0_label=P_precision_tok: 0.9113428943937418
test0_label=P_recall_tok: 0.6528642590286425
test0_label=P_f-score_tok: 0.7607473245057138
test0_precision_macro_tok: 0.8673263083678968
test0_recall_macro_tok: 0.7394917457482592
test0_f-score_macro_tok: 0.7908419528256266
test0_precision_micro_tok: 0.8938140453135283
test0_recall_micro_tok: 0.8938140453135283
test0_f-score_micro_tok: 0.8938140453135283
test0_time: 5.071150779724121
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.6483    0.8528    0.7366       428
           P     0.6941    0.8176    0.7508       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6919    0.5728    0.5259      1101
weighted avg     0.6844    0.6712    0.6079      1101

F1-macro sent:  0.5258563986839335
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8996    0.9765    0.9365     16205
           N     0.7910    0.5891    0.6753      1857
           P     0.9113    0.6529    0.7607      3212

   micro avg     0.8938    0.8938    0.8938     21274
   macro avg     0.8673    0.7395    0.7908     21274
weighted avg     0.8919    0.8938    0.8871     21274

F1-macro tok:  0.7908419528256266
F1-micro tok:  0.8938140453135283
**************************************************
test1_cost_sum: 84512.22306060791
test1_cost_avg: 38.24082491430222
test1_count_sent: 2210.0
test1_total_correct_sent: 1523.0
test1_accuracy_sent: 0.6891402714932127
test1_count_tok: 42405.0
test1_total_correct_tok: 37615.0
test1_accuracy_tok: 0.8870416224501828
test1_label=O_precision_sent: 0.5454545454545454
test1_label=O_recall_sent: 0.04627249357326478
test1_label=O_f-score_sent: 0.08530805687203791
test1_label=N_precision_sent: 0.6678260869565218
test1_label=N_recall_sent: 0.8421052631578947
test1_label=N_f-score_sent: 0.7449078564500485
test1_label=P_precision_sent: 0.7176241480038948
test1_label=P_recall_sent: 0.8107810781078107
test1_label=P_f-score_sent: 0.7613636363636365
test1_precision_macro_sent: 0.6436349268049874
test1_recall_macro_sent: 0.5663862782796567
test1_f-score_macro_sent: 0.5305265165619076
test1_precision_micro_sent: 0.6891402714932127
test1_recall_micro_sent: 0.6891402714932127
test1_f-score_micro_sent: 0.6891402714932127
test1_label=O_precision_tok: 0.8914797183660671
test1_label=O_recall_tok: 0.9773735858491156
test1_label=O_f-score_tok: 0.9324527795584312
test1_label=N_precision_tok: 0.7910714285714285
test1_label=N_recall_tok: 0.589095744680851
test1_label=N_f-score_tok: 0.6753048780487805
test1_label=P_precision_tok: 0.9120247568523431
test1_label=P_recall_tok: 0.620731156912893
test1_label=P_f-score_tok: 0.7386984155402381
test1_precision_macro_tok: 0.8648586345966129
test1_recall_macro_tok: 0.7290668291476199
test1_f-score_macro_tok: 0.7821520243824832
test1_precision_micro_tok: 0.8870416224501828
test1_recall_micro_tok: 0.8870416224501828
test1_f-score_micro_tok: 0.8870416224501828
test1_time: 10.443054437637329
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.0463    0.0853       389
           N     0.6678    0.8421    0.7449       912
           P     0.7176    0.8108    0.7614       909

   micro avg     0.6891    0.6891    0.6891      2210
   macro avg     0.6436    0.5664    0.5305      2210
weighted avg     0.6668    0.6891    0.6356      2210

F1-macro sent:  0.5305265165619076
F1-micro sent:  0.6891402714932127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8915    0.9774    0.9325     31998
           N     0.7911    0.5891    0.6753      3760
           P     0.9120    0.6207    0.7387      6647

   micro avg     0.8870    0.8870    0.8870     42405
   macro avg     0.8649    0.7291    0.7822     42405
weighted avg     0.8858    0.8870    0.8793     42405

F1-macro tok:  0.7821520243824832
F1-micro tok:  0.8870416224501828
**************************************************
