to_write_filename: runs/transformer_sentiment_sent+word+LM_loss_model_selector=dev_label=N_f-score_tok.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_label=N_f-score_tok:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'O': 0, 'N': 1, 'P': 2}
{'O': 0, 'N': 1, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428271.6481933594
train_cost_avg: 50.125426988923145
train_count_sent: 8544.0
train_total_correct_sent: 4183.0
train_accuracy_sent: 0.4895833333333333
train_count_tok: 163566.0
train_total_correct_tok: 126060.0
train_accuracy_tok: 0.7706980668354059
train_label=O_precision_sent: 0.2222222222222222
train_label=O_recall_sent: 0.03694581280788178
train_label=O_f-score_sent: 0.06335797254487857
train_label=N_precision_sent: 0.4765419082762256
train_label=N_recall_sent: 0.5462235649546828
train_label=N_f-score_sent: 0.509009009009009
train_label=P_precision_sent: 0.5167410714285714
train_label=P_recall_sent: 0.6412742382271468
train_label=P_f-score_sent: 0.5723114956736711
train_precision_macro_sent: 0.4051684006423397
train_recall_macro_sent: 0.4081478719965705
train_f-score_macro_sent: 0.38155949240918624
train_precision_micro_sent: 0.4895833333333333
train_recall_micro_sent: 0.4895833333333333
train_f-score_micro_sent: 0.4895833333333333
train_label=O_precision_tok: 0.7971669172526783
train_label=O_recall_tok: 0.9508472259081442
train_label=O_f-score_tok: 0.867251509172394
train_label=N_precision_tok: 0.5209759522555731
train_label=N_recall_tok: 0.20898465004928884
train_label=N_f-score_tok: 0.29830644756017893
train_label=P_precision_tok: 0.508586387434555
train_label=P_recall_tok: 0.19414797937402567
train_label=P_f-score_tok: 0.28101946943616746
train_precision_macro_tok: 0.6089097523142688
train_recall_macro_tok: 0.4513266184438196
train_f-score_macro_tok: 0.4821924753895801
train_precision_micro_tok: 0.7706980668354059
train_recall_micro_tok: 0.7706980668354059
train_f-score_micro_tok: 0.7706980668354059
train_time: 94.13538932800293
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2222    0.0369    0.0634      1624
           N     0.4765    0.5462    0.5090      3310
           P     0.5167    0.6413    0.5723      3610

   micro avg     0.4896    0.4896    0.4896      8544
   macro avg     0.4052    0.4081    0.3816      8544
weighted avg     0.4452    0.4896    0.4510      8544

F1-macro sent:  0.38155949240918624
F1-micro sent:  0.4895833333333333
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7972    0.9508    0.8673    124347
           N     0.5210    0.2090    0.2983     14202
           P     0.5086    0.1941    0.2810     25017

   micro avg     0.7707    0.7707    0.7707    163566
   macro avg     0.6089    0.4513    0.4822    163566
weighted avg     0.7290    0.7707    0.7282    163566

F1-macro tok:  0.4821924753895801
F1-micro tok:  0.7706980668354059
**************************************************
dev_cost_sum: 51669.52276611328
dev_cost_avg: 46.92963012362696
dev_count_sent: 1101.0
dev_total_correct_sent: 637.0
dev_accuracy_sent: 0.5785649409627611
dev_count_tok: 21274.0
dev_total_correct_tok: 17375.0
dev_accuracy_tok: 0.8167246404061296
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.648
dev_label=N_recall_sent: 0.5677570093457944
dev_label=N_f-score_sent: 0.605230386052304
dev_label=P_precision_sent: 0.5426997245179064
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.6735042735042736
dev_precision_macro_sent: 0.3968999081726355
dev_recall_macro_sent: 0.48504813224439397
dev_f-score_macro_sent: 0.4262448865188591
dev_precision_micro_sent: 0.5785649409627611
dev_recall_micro_sent: 0.5785649409627611
dev_f-score_micro_sent: 0.5785649409627611
dev_label=O_precision_tok: 0.8592464768478574
dev_label=O_recall_tok: 0.9218142548596112
dev_label=O_f-score_tok: 0.8894313783864246
dev_label=N_precision_tok: 0.575531303848363
dev_label=N_recall_tok: 0.5395799676898223
dev_label=N_f-score_tok: 0.5569760978321289
dev_label=P_precision_tok: 0.6680633147113594
dev_label=P_recall_tok: 0.44676214196762143
dev_label=P_f-score_tok: 0.5354477611940298
dev_precision_macro_tok: 0.7009470318025266
dev_recall_macro_tok: 0.6360521215056849
dev_f-score_macro_tok: 0.6606184124708611
dev_precision_micro_tok: 0.8167246404061296
dev_recall_micro_tok: 0.8167246404061296
dev_f-score_micro_tok: 0.8167246404061295
dev_time: 5.255374431610107
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6480    0.5678    0.6052       428
           P     0.5427    0.8874    0.6735       444

   micro avg     0.5786    0.5786    0.5786      1101
   macro avg     0.3969    0.4850    0.4262      1101
weighted avg     0.4708    0.5786    0.5069      1101

F1-macro sent:  0.4262448865188591
F1-micro sent:  0.5785649409627611
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8592    0.9218    0.8894     16205
           N     0.5755    0.5396    0.5570      1857
           P     0.6681    0.4468    0.5354      3212

   micro avg     0.8167    0.8167    0.8167     21274
   macro avg     0.7009    0.6361    0.6606     21274
weighted avg     0.8056    0.8167    0.8070     21274

F1-macro tok:  0.6606184124708611
F1-micro tok:  0.8167246404061295
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379040.5838623047
train_cost_avg: 44.363364216093714
train_count_sent: 8544.0
train_total_correct_sent: 4843.0
train_accuracy_sent: 0.5668305243445693
train_count_tok: 163566.0
train_total_correct_tok: 132228.0
train_accuracy_tok: 0.8084076152745681
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002452483139178418
train_label=N_precision_sent: 0.5376647834274952
train_label=N_recall_sent: 0.6900302114803626
train_label=N_f-score_sent: 0.6043926964805504
train_label=P_precision_sent: 0.5961762648636045
train_label=P_recall_sent: 0.7083102493074792
train_label=P_f-score_sent: 0.6474237245220914
train_precision_macro_sent: 0.47318511133512847
train_recall_macro_sent: 0.4665239959604793
train_f-score_macro_sent: 0.41808963471394006
train_precision_micro_sent: 0.5668305243445693
train_recall_micro_sent: 0.5668305243445693
train_f-score_micro_sent: 0.5668305243445693
train_label=O_precision_tok: 0.8314803608370744
train_label=O_recall_tok: 0.9502842851053905
train_label=O_f-score_tok: 0.8869215382363648
train_label=N_precision_tok: 0.6351479289940828
train_label=N_recall_tok: 0.37790452049007184
train_label=N_f-score_tok: 0.4738654423450468
train_label=P_precision_tok: 0.6688201815105368
train_label=P_recall_tok: 0.3476036295319183
train_label=P_f-score_tok: 0.4574554827849233
train_precision_macro_tok: 0.711816157113898
train_recall_macro_tok: 0.5585974783757935
train_f-score_macro_tok: 0.6060808211221117
train_precision_micro_tok: 0.8084076152745681
train_recall_micro_tok: 0.8084076152745681
train_f-score_micro_tok: 0.8084076152745681
train_time: 93.20474290847778
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0012    0.0025      1624
           N     0.5377    0.6900    0.6044      3310
           P     0.5962    0.7083    0.6474      3610

   micro avg     0.5668    0.5668    0.5668      8544
   macro avg     0.4732    0.4665    0.4181      8544
weighted avg     0.5145    0.5668    0.5082      8544

F1-macro sent:  0.41808963471394006
F1-micro sent:  0.5668305243445693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8315    0.9503    0.8869    124347
           N     0.6351    0.3779    0.4739     14202
           P     0.6688    0.3476    0.4575     25017

   micro avg     0.8084    0.8084    0.8084    163566
   macro avg     0.7118    0.5586    0.6061    163566
weighted avg     0.7896    0.8084    0.7854    163566

F1-macro tok:  0.6060808211221117
F1-micro tok:  0.8084076152745681
**************************************************
dev_cost_sum: 49165.96643066406
dev_cost_avg: 44.65573699424529
dev_count_sent: 1101.0
dev_total_correct_sent: 657.0
dev_accuracy_sent: 0.5967302452316077
dev_count_tok: 21274.0
dev_total_correct_tok: 17672.0
dev_accuracy_tok: 0.8306853436119207
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5230566534914362
dev_label=N_recall_sent: 0.927570093457944
dev_label=N_f-score_sent: 0.6689132266217355
dev_label=P_precision_sent: 0.7602339181286549
dev_label=P_recall_sent: 0.5855855855855856
dev_label=P_f-score_sent: 0.6615776081424937
dev_precision_macro_sent: 0.4277635238733637
dev_recall_macro_sent: 0.5043852263478432
dev_f-score_macro_sent: 0.4434969449214097
dev_precision_micro_sent: 0.5967302452316077
dev_recall_micro_sent: 0.5967302452316077
dev_f-score_micro_sent: 0.5967302452316077
dev_label=O_precision_tok: 0.8360716557133772
dev_label=O_recall_tok: 0.9734649799444616
dev_label=O_f-score_tok: 0.8995523622159496
dev_label=N_precision_tok: 0.7185374149659864
dev_label=N_recall_tok: 0.4550350026925148
dev_label=N_f-score_tok: 0.5572040883613585
dev_label=P_precision_tok: 0.8552845528455284
dev_label=P_recall_tok: 0.3275217932752179
dev_label=P_f-score_tok: 0.47366051328230524
dev_precision_macro_tok: 0.8032978745082974
dev_recall_macro_tok: 0.5853405919707314
dev_f-score_macro_tok: 0.6434723212865378
dev_precision_micro_tok: 0.8306853436119207
dev_recall_micro_tok: 0.8306853436119207
dev_f-score_micro_tok: 0.8306853436119207
dev_time: 4.452341318130493
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5231    0.9276    0.6689       428
           P     0.7602    0.5856    0.6616       444

   micro avg     0.5967    0.5967    0.5967      1101
   macro avg     0.4278    0.5044    0.4435      1101
weighted avg     0.5099    0.5967    0.5268      1101

F1-macro sent:  0.4434969449214097
F1-micro sent:  0.5967302452316077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8361    0.9735    0.8996     16205
           N     0.7185    0.4550    0.5572      1857
           P     0.8553    0.3275    0.4737      3212

   micro avg     0.8307    0.8307    0.8307     21274
   macro avg     0.8033    0.5853    0.6435     21274
weighted avg     0.8287    0.8307    0.8054     21274

F1-macro tok:  0.6434723212865378
F1-micro tok:  0.8306853436119207
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368961.26641845703
train_cost_avg: 43.18366882238495
train_count_sent: 8544.0
train_total_correct_sent: 5042.0
train_accuracy_sent: 0.5901217228464419
train_count_tok: 163566.0
train_total_correct_tok: 135422.0
train_accuracy_tok: 0.8279349008962743
train_label=O_precision_sent: 0.23529411764705882
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004875076173065204
train_label=N_precision_sent: 0.5598976506164224
train_label=N_recall_sent: 0.7271903323262839
train_label=N_f-score_sent: 0.6326718359837035
train_label=P_precision_sent: 0.6222800378429517
train_label=P_recall_sent: 0.728808864265928
train_label=P_f-score_sent: 0.6713447307986732
train_precision_macro_sent: 0.4724906020354777
train_recall_macro_sent: 0.48615408359313467
train_f-score_macro_sent: 0.4362972143184806
train_precision_micro_sent: 0.5901217228464419
train_recall_micro_sent: 0.5901217228464419
train_f-score_micro_sent: 0.5901217228464419
train_label=O_precision_tok: 0.8482897729711171
train_label=O_recall_tok: 0.9537503920480591
train_label=O_f-score_tok: 0.8979341517983896
train_label=N_precision_tok: 0.6780165289256198
train_label=N_recall_tok: 0.433248838191804
train_label=N_f-score_tok: 0.5286763758216265
train_label=P_precision_tok: 0.726796050391556
train_label=P_recall_tok: 0.4266298916736619
train_label=P_f-score_tok: 0.5376555337262606
train_precision_macro_tok: 0.7510341174294309
train_recall_macro_tok: 0.6045430406378417
train_f-score_macro_tok: 0.6547553537820923
train_precision_micro_tok: 0.8279349008962743
train_recall_micro_tok: 0.8279349008962743
train_f-score_micro_tok: 0.8279349008962743
train_time: 93.47347402572632
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2353    0.0025    0.0049      1624
           N     0.5599    0.7272    0.6327      3310
           P     0.6223    0.7288    0.6713      3610

   micro avg     0.5901    0.5901    0.5901      8544
   macro avg     0.4725    0.4862    0.4363      8544
weighted avg     0.5246    0.5901    0.5297      8544

F1-macro sent:  0.4362972143184806
F1-micro sent:  0.5901217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8483    0.9538    0.8979    124347
           N     0.6780    0.4332    0.5287     14202
           P     0.7268    0.4266    0.5377     25017

   micro avg     0.8279    0.8279    0.8279    163566
   macro avg     0.7510    0.6045    0.6548    163566
weighted avg     0.8149    0.8279    0.8108    163566

F1-macro tok:  0.6547553537820923
F1-micro tok:  0.8279349008962743
**************************************************
dev_cost_sum: 48270.651916503906
dev_cost_avg: 43.8425539659436
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18128.0
dev_accuracy_tok: 0.8521199586349535
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.6172161172161172
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.6919917864476386
dev_label=P_precision_sent: 0.6419529837251357
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7121364092276832
dev_precision_macro_sent: 0.5863897003137509
dev_recall_macro_sent: 0.5304331797822391
dev_f-score_macro_sent: 0.4709287347777768
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8718527718189003
dev_label=O_recall_tok: 0.9530391854365936
dev_label=O_f-score_tok: 0.9106400542468822
dev_label=N_precision_tok: 0.7682692307692308
dev_label=N_recall_tok: 0.43026386645126546
dev_label=N_f-score_tok: 0.5516051087331723
dev_label=P_precision_tok: 0.748015873015873
dev_label=P_recall_tok: 0.5868617683686177
dev_label=P_f-score_tok: 0.6577110956036288
dev_precision_macro_tok: 0.796045958534668
dev_recall_macro_tok: 0.656721606752159
dev_f-score_macro_tok: 0.7066520861945612
dev_precision_micro_tok: 0.8521199586349535
dev_recall_micro_tok: 0.8521199586349535
dev_f-score_micro_tok: 0.8521199586349535
dev_time: 4.127741098403931
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6172    0.7874    0.6920       428
           P     0.6420    0.7995    0.7121       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.5864    0.5304    0.4709      1101
weighted avg     0.6028    0.6294    0.5580      1101

F1-macro sent:  0.4709287347777768
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8719    0.9530    0.9106     16205
           N     0.7683    0.4303    0.5516      1857
           P     0.7480    0.5869    0.6577      3212

   micro avg     0.8521    0.8521    0.8521     21274
   macro avg     0.7960    0.6567    0.7067     21274
weighted avg     0.8441    0.8521    0.8411     21274

F1-macro tok:  0.7066520861945612
F1-micro tok:  0.8521199586349535
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361988.06774902344
train_cost_avg: 42.36751729272278
train_count_sent: 8544.0
train_total_correct_sent: 5098.0
train_accuracy_sent: 0.5966760299625468
train_count_tok: 163566.0
train_total_correct_tok: 137473.0
train_accuracy_tok: 0.8404741816758984
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.019138755980861247
train_label=N_precision_sent: 0.5562943262411347
train_label=N_recall_sent: 0.7583081570996979
train_label=N_f-score_sent: 0.6417795960112503
train_label=P_precision_sent: 0.6455823293172691
train_label=P_recall_sent: 0.7124653739612188
train_label=P_f-score_sent: 0.6773768764814327
train_precision_macro_sent: 0.5117366629639124
train_recall_macro_sent: 0.4935419159365617
train_f-score_macro_sent: 0.44609840949118146
train_precision_micro_sent: 0.5966760299625468
train_recall_micro_sent: 0.5966760299625468
train_f-score_micro_sent: 0.5966760299625468
train_label=O_precision_tok: 0.8596878254831617
train_label=O_recall_tok: 0.9558493570411831
train_label=O_f-score_tok: 0.905221951005891
train_label=N_precision_tok: 0.6900515685431886
train_label=N_recall_tok: 0.45226024503591045
train_label=N_f-score_tok: 0.5464057847724373
train_label=P_precision_tok: 0.7619672540932384
train_label=P_recall_tok: 0.48738857576847744
train_label=P_f-score_tok: 0.594504985494527
train_precision_macro_tok: 0.7705688827065296
train_recall_macro_tok: 0.6318327259485237
train_f-score_macro_tok: 0.6820442404242851
train_precision_micro_tok: 0.8404741816758984
train_recall_micro_tok: 0.8404741816758984
train_f-score_micro_tok: 0.8404741816758984
train_time: 93.85807228088379
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0099    0.0191      1624
           N     0.5563    0.7583    0.6418      3310
           P     0.6456    0.7125    0.6774      3610

   micro avg     0.5967    0.5967    0.5967      8544
   macro avg     0.5117    0.4935    0.4461      8544
weighted avg     0.5516    0.5967    0.5385      8544

F1-macro sent:  0.44609840949118146
F1-micro sent:  0.5966760299625468
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8597    0.9558    0.9052    124347
           N     0.6901    0.4523    0.5464     14202
           P     0.7620    0.4874    0.5945     25017

   micro avg     0.8405    0.8405    0.8405    163566
   macro avg     0.7706    0.6318    0.6820    163566
weighted avg     0.8300    0.8405    0.8265    163566

F1-macro tok:  0.6820442404242851
F1-micro tok:  0.8404741816758984
**************************************************
dev_cost_sum: 47400.94287109375
dev_cost_avg: 43.05262749418143
dev_count_sent: 1101.0
dev_total_correct_sent: 684.0
dev_accuracy_sent: 0.6212534059945504
dev_count_tok: 21274.0
dev_total_correct_tok: 18386.0
dev_accuracy_tok: 0.8642474381874589
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5792880258899676
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.6845124282982792
dev_label=P_precision_sent: 0.6763485477178424
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7041036717062635
dev_precision_macro_sent: 0.4185455245359367
dev_recall_macro_sent: 0.5235609441216919
dev_f-score_macro_sent: 0.46287203333484755
dev_precision_micro_sent: 0.6212534059945504
dev_recall_micro_sent: 0.6212534059945504
dev_f-score_micro_sent: 0.6212534059945504
dev_label=O_precision_tok: 0.8710516125463296
dev_label=O_recall_tok: 0.9716754088244369
dev_label=O_f-score_tok: 0.9186161834198705
dev_label=N_precision_tok: 0.7835538752362949
dev_label=N_recall_tok: 0.4464189553042542
dev_label=N_f-score_tok: 0.5687821612349915
dev_label=P_precision_tok: 0.8466573165030388
dev_label=P_recall_tok: 0.5638231631382317
dev_label=P_f-score_tok: 0.6768828256400673
dev_precision_macro_tok: 0.8337542680952211
dev_recall_macro_tok: 0.6606391757556409
dev_f-score_macro_tok: 0.7214270567649764
dev_precision_micro_tok: 0.8642474381874589
dev_recall_micro_tok: 0.8642474381874589
dev_f-score_micro_tok: 0.8642474381874589
dev_time: 4.173454761505127
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5793    0.8364    0.6845       428
           P     0.6763    0.7342    0.7041       444

   micro avg     0.6213    0.6213    0.6213      1101
   macro avg     0.4185    0.5236    0.4629      1101
weighted avg     0.4979    0.6213    0.5500      1101

F1-macro sent:  0.46287203333484755
F1-micro sent:  0.6212534059945504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8711    0.9717    0.9186     16205
           N     0.7836    0.4464    0.5688      1857
           P     0.8467    0.5638    0.6769      3212

   micro avg     0.8642    0.8642    0.8642     21274
   macro avg     0.8338    0.6606    0.7214     21274
weighted avg     0.8597    0.8642    0.8516     21274

F1-macro tok:  0.7214270567649764
F1-micro tok:  0.8642474381874589
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355664.36950683594
train_cost_avg: 41.62738407149297
train_count_sent: 8544.0
train_total_correct_sent: 5266.0
train_accuracy_sent: 0.6163389513108615
train_count_tok: 163566.0
train_total_correct_tok: 139265.0
train_accuracy_tok: 0.8514300037905188
train_label=O_precision_sent: 0.5714285714285714
train_label=O_recall_sent: 0.014778325123152709
train_label=O_f-score_sent: 0.028811524609843934
train_label=N_precision_sent: 0.5779795686719637
train_label=N_recall_sent: 0.7691842900302115
train_label=N_f-score_sent: 0.6600129617627997
train_label=P_precision_sent: 0.6580424701000732
train_label=P_recall_sent: 0.746814404432133
train_label=P_f-score_sent: 0.6996237186972881
train_precision_macro_sent: 0.602483536733536
train_recall_macro_sent: 0.5102590065284991
train_f-score_macro_sent: 0.46281606835664385
train_precision_micro_sent: 0.6163389513108615
train_recall_micro_sent: 0.6163389513108615
train_f-score_micro_sent: 0.6163389513108615
train_label=O_precision_tok: 0.8677765827568165
train_label=O_recall_tok: 0.9603207154173402
train_label=O_f-score_tok: 0.9117062090817125
train_label=N_precision_tok: 0.7093451066961001
train_label=N_recall_tok: 0.47514434586677934
train_label=N_f-score_tok: 0.5690912924309509
train_label=P_precision_tok: 0.7968379446640316
train_label=P_recall_tok: 0.5238038134068833
train_label=P_f-score_tok: 0.6320968597752158
train_precision_macro_tok: 0.7913198780389826
train_recall_macro_tok: 0.653089624897001
train_f-score_macro_tok: 0.704298120429293
train_precision_micro_tok: 0.8514300037905188
train_recall_micro_tok: 0.8514300037905188
train_f-score_micro_tok: 0.8514300037905188
train_time: 94.24758911132812
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0148    0.0288      1624
           N     0.5780    0.7692    0.6600      3310
           P     0.6580    0.7468    0.6996      3610

   micro avg     0.6163    0.6163    0.6163      8544
   macro avg     0.6025    0.5103    0.4628      8544
weighted avg     0.6106    0.6163    0.5568      8544

F1-macro sent:  0.46281606835664385
F1-micro sent:  0.6163389513108615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8678    0.9603    0.9117    124347
           N     0.7093    0.4751    0.5691     14202
           P     0.7968    0.5238    0.6321     25017

   micro avg     0.8514    0.8514    0.8514    163566
   macro avg     0.7913    0.6531    0.7043    163566
weighted avg     0.8432    0.8514    0.8392    163566

F1-macro tok:  0.704298120429293
F1-micro tok:  0.8514300037905188
**************************************************
dev_cost_sum: 46729.37805175781
dev_cost_avg: 42.442668530206916
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18505.0
dev_accuracy_tok: 0.8698411206167153
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5705705705705706
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.6946983546617915
dev_label=P_precision_sent: 0.703016241299304
dev_label=P_recall_sent: 0.6824324324324325
dev_label=P_f-score_sent: 0.6925714285714286
dev_precision_macro_sent: 0.6745289372899581
dev_recall_macro_sent: 0.5277944454677916
dev_f-score_macro_sent: 0.4710069520648645
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8771460423634336
dev_label=O_recall_tok: 0.9710583153347733
dev_label=O_f-score_tok: 0.9217162102796895
dev_label=N_precision_tok: 0.7513768686073957
dev_label=N_recall_tok: 0.5142703284868066
dev_label=N_f-score_tok: 0.610613810741688
dev_label=P_precision_tok: 0.8793019873969947
dev_label=P_recall_tok: 0.5647571606475716
dev_label=P_f-score_tok: 0.6877725118483413
dev_precision_macro_tok: 0.8359416327892747
dev_recall_macro_tok: 0.6833619348230506
dev_f-score_macro_tok: 0.7400341776232396
dev_precision_micro_tok: 0.8698411206167153
dev_recall_micro_tok: 0.8698411206167153
dev_f-score_micro_tok: 0.8698411206167153
dev_time: 3.895487070083618
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5706    0.8879    0.6947       428
           P     0.7030    0.6824    0.6926       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.6745    0.5278    0.4710      1101
weighted avg     0.6613    0.6231    0.5547      1101

F1-macro sent:  0.4710069520648645
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8771    0.9711    0.9217     16205
           N     0.7514    0.5143    0.6106      1857
           P     0.8793    0.5648    0.6878      3212

   micro avg     0.8698    0.8698    0.8698     21274
   macro avg     0.8359    0.6834    0.7400     21274
weighted avg     0.8665    0.8698    0.8592     21274

F1-macro tok:  0.7400341776232396
F1-micro tok:  0.8698411206167153
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351081.0545654297
train_cost_avg: 41.09094739763924
train_count_sent: 8544.0
train_total_correct_sent: 5239.0
train_accuracy_sent: 0.6131788389513109
train_count_tok: 163566.0
train_total_correct_tok: 140268.0
train_accuracy_tok: 0.8575620850298962
train_label=O_precision_sent: 0.4074074074074074
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026221692491060787
train_label=N_precision_sent: 0.5821453610656695
train_label=N_recall_sent: 0.7525679758308157
train_label=N_f-score_sent: 0.6564764791145078
train_label=P_precision_sent: 0.6473521728805509
train_label=P_recall_sent: 0.7551246537396122
train_label=P_f-score_sent: 0.6970975578570516
train_precision_macro_sent: 0.5456349804512093
train_recall_macro_sent: 0.5070798091999948
train_f-score_macro_sent: 0.4599319098208734
train_precision_micro_sent: 0.6131788389513109
train_recall_micro_sent: 0.6131788389513109
train_f-score_micro_sent: 0.6131788389513109
train_label=O_precision_tok: 0.8724534793034833
train_label=O_recall_tok: 0.962612688685694
train_label=O_f-score_tok: 0.9153182638485303
train_label=N_precision_tok: 0.7228530140379852
train_label=N_recall_tok: 0.49309956344176875
train_label=N_f-score_tok: 0.5862704060276267
train_label=P_precision_tok: 0.8133205443318746
train_label=P_recall_tok: 0.542311228364712
train_label=P_f-score_tok: 0.6507266535565256
train_precision_macro_tok: 0.8028756792244477
train_recall_macro_tok: 0.6660078268307249
train_f-score_macro_tok: 0.7174384411442275
train_precision_micro_tok: 0.8575620850298962
train_recall_micro_tok: 0.8575620850298962
train_f-score_micro_tok: 0.8575620850298962
train_time: 97.54685282707214
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4074    0.0135    0.0262      1624
           N     0.5821    0.7526    0.6565      3310
           P     0.6474    0.7551    0.6971      3610

   micro avg     0.6132    0.6132    0.6132      8544
   macro avg     0.5456    0.5071    0.4599      8544
weighted avg     0.5765    0.6132    0.5538      8544

F1-macro sent:  0.4599319098208734
F1-micro sent:  0.6131788389513109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8725    0.9626    0.9153    124347
           N     0.7229    0.4931    0.5863     14202
           P     0.8133    0.5423    0.6507     25017

   micro avg     0.8576    0.8576    0.8576    163566
   macro avg     0.8029    0.6660    0.7174    163566
weighted avg     0.8504    0.8576    0.8463    163566

F1-macro tok:  0.7174384411442275
F1-micro tok:  0.8575620850298962
**************************************************
dev_cost_sum: 46234.36975097656
dev_cost_avg: 41.99306971024211
dev_count_sent: 1101.0
dev_total_correct_sent: 683.0
dev_accuracy_sent: 0.620345140781108
dev_count_tok: 21274.0
dev_total_correct_tok: 18601.0
dev_accuracy_tok: 0.8743536711478801
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6376518218623481
dev_label=N_recall_sent: 0.735981308411215
dev_label=N_f-score_sent: 0.6832971800433839
dev_label=P_precision_sent: 0.6062602965403624
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7002854424357755
dev_precision_macro_sent: 0.41463737280090357
dev_recall_macro_sent: 0.5216033790800146
dev_f-score_macro_sent: 0.4611942074930531
dev_precision_micro_sent: 0.620345140781108
dev_recall_micro_sent: 0.620345140781108
dev_f-score_micro_sent: 0.620345140781108
dev_label=O_precision_tok: 0.8769784172661871
dev_label=O_recall_tok: 0.9779080530700401
dev_label=O_f-score_tok: 0.9246973012399707
dev_label=N_precision_tok: 0.8158379373848987
dev_label=N_recall_tok: 0.4771136241249327
dev_label=N_f-score_tok: 0.6021066938498131
dev_label=P_precision_tok: 0.8819641170915958
dev_label=P_recall_tok: 0.5815691158156912
dev_label=P_f-score_tok: 0.70093808630394
dev_precision_macro_tok: 0.8582601572475607
dev_recall_macro_tok: 0.6788635976702214
dev_f-score_macro_tok: 0.7425806937979079
dev_precision_micro_tok: 0.8743536711478801
dev_recall_micro_tok: 0.8743536711478801
dev_f-score_micro_tok: 0.8743536711478802
dev_time: 7.046566724777222
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6377    0.7360    0.6833       428
           P     0.6063    0.8288    0.7003       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.4146    0.5216    0.4612      1101
weighted avg     0.4924    0.6203    0.5480      1101

F1-macro sent:  0.4611942074930531
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8770    0.9779    0.9247     16205
           N     0.8158    0.4771    0.6021      1857
           P     0.8820    0.5816    0.7009      3212

   micro avg     0.8744    0.8744    0.8744     21274
   macro avg     0.8583    0.6789    0.7426     21274
weighted avg     0.8724    0.8744    0.8628     21274

F1-macro tok:  0.7425806937979079
F1-micro tok:  0.8743536711478802
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346543.6330566406
train_cost_avg: 40.55988214614239
train_count_sent: 8544.0
train_total_correct_sent: 5304.0
train_accuracy_sent: 0.6207865168539326
train_count_tok: 163566.0
train_total_correct_tok: 141039.0
train_accuracy_tok: 0.8622757785847914
train_label=O_precision_sent: 0.48484848484848486
train_label=O_recall_sent: 0.019704433497536946
train_label=O_f-score_sent: 0.03786982248520711
train_label=N_precision_sent: 0.5918079096045198
train_label=N_recall_sent: 0.7595166163141994
train_label=N_f-score_sent: 0.6652553585604658
train_label=P_precision_sent: 0.6520094562647755
train_label=P_recall_sent: 0.7639889196675901
train_label=P_f-score_sent: 0.7035714285714286
train_precision_macro_sent: 0.57622195023926
train_recall_macro_sent: 0.5144033231597754
train_f-score_macro_sent: 0.4688988698723671
train_precision_micro_sent: 0.6207865168539326
train_recall_micro_sent: 0.6207865168539326
train_f-score_micro_sent: 0.6207865168539326
train_label=O_precision_tok: 0.8758353235029908
train_label=O_recall_tok: 0.9644140992545055
train_label=O_f-score_tok: 0.917992880927776
train_label=N_precision_tok: 0.731675392670157
train_label=N_recall_tok: 0.5116884945782284
train_label=N_f-score_tok: 0.6022209331233943
train_label=P_precision_tok: 0.8287954042247622
train_label=P_recall_tok: 0.553623535995523
train_label=P_f-score_tok: 0.6638228527607363
train_precision_macro_tok: 0.8121020401326366
train_recall_macro_tok: 0.6765753766094189
train_f-score_macro_tok: 0.7280122222706354
train_precision_micro_tok: 0.8622757785847914
train_recall_micro_tok: 0.8622757785847914
train_f-score_micro_tok: 0.8622757785847913
train_time: 141.68063044548035
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4848    0.0197    0.0379      1624
           N     0.5918    0.7595    0.6653      3310
           P     0.6520    0.7640    0.7036      3610

   micro avg     0.6208    0.6208    0.6208      8544
   macro avg     0.5762    0.5144    0.4689      8544
weighted avg     0.5969    0.6208    0.5622      8544

F1-macro sent:  0.4688988698723671
F1-micro sent:  0.6207865168539326
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8758    0.9644    0.9180    124347
           N     0.7317    0.5117    0.6022     14202
           P     0.8288    0.5536    0.6638     25017

   micro avg     0.8623    0.8623    0.8623    163566
   macro avg     0.8121    0.6766    0.7280    163566
weighted avg     0.8561    0.8623    0.8517    163566

F1-macro tok:  0.7280122222706354
F1-micro tok:  0.8622757785847913
**************************************************
dev_cost_sum: 45887.69104003906
dev_cost_avg: 41.67819349685655
dev_count_sent: 1101.0
dev_total_correct_sent: 672.0
dev_accuracy_sent: 0.6103542234332425
dev_count_tok: 21274.0
dev_total_correct_tok: 18686.0
dev_accuracy_tok: 0.8783491585973489
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6857142857142857
dev_label=N_recall_sent: 0.616822429906542
dev_label=N_f-score_sent: 0.6494464944649445
dev_label=P_precision_sent: 0.569620253164557
dev_label=P_recall_sent: 0.9121621621621622
dev_label=P_f-score_sent: 0.7012987012987014
dev_precision_macro_sent: 0.6184448462929475
dev_recall_macro_sent: 0.5140283429166423
dev_f-score_macro_sent: 0.45879540713489053
dev_precision_micro_sent: 0.6103542234332425
dev_recall_micro_sent: 0.6103542234332425
dev_f-score_micro_sent: 0.6103542234332425
dev_label=O_precision_tok: 0.883857606627113
dev_label=O_recall_tok: 0.9744523295279235
dev_label=O_f-score_tok: 0.9269466701887237
dev_label=N_precision_tok: 0.8206958073148974
dev_label=N_recall_tok: 0.49542272482498656
dev_label=N_f-score_tok: 0.6178643384822028
dev_label=P_precision_tok: 0.8635767380848273
dev_label=P_recall_tok: 0.614881693648817
dev_label=P_f-score_tok: 0.71831242044008
dev_precision_macro_tok: 0.856043384008946
dev_recall_macro_tok: 0.6949189160005756
dev_f-score_macro_tok: 0.7543744763703355
dev_precision_micro_tok: 0.8783491585973489
dev_recall_micro_tok: 0.8783491585973489
dev_f-score_micro_tok: 0.8783491585973489
dev_time: 7.232311010360718
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6857    0.6168    0.6494       428
           P     0.5696    0.9122    0.7013       444

   micro avg     0.6104    0.6104    0.6104      1101
   macro avg     0.6184    0.5140    0.4588      1101
weighted avg     0.6211    0.6104    0.5406      1101

F1-macro sent:  0.45879540713489053
F1-micro sent:  0.6103542234332425
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8839    0.9745    0.9269     16205
           N     0.8207    0.4954    0.6179      1857
           P     0.8636    0.6149    0.7183      3212

   micro avg     0.8783    0.8783    0.8783     21274
   macro avg     0.8560    0.6949    0.7544     21274
weighted avg     0.8753    0.8783    0.8685     21274

F1-macro tok:  0.7543744763703355
F1-micro tok:  0.8783491585973489
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342751.28479003906
train_cost_avg: 40.11602115988285
train_count_sent: 8544.0
train_total_correct_sent: 5367.0
train_accuracy_sent: 0.6281601123595506
train_count_tok: 163566.0
train_total_correct_tok: 141714.0
train_accuracy_tok: 0.8664025530978321
train_label=O_precision_sent: 0.5352112676056338
train_label=O_recall_sent: 0.023399014778325122
train_label=O_f-score_sent: 0.04483775811209439
train_label=N_precision_sent: 0.5995737627279185
train_label=N_recall_sent: 0.7649546827794562
train_label=N_f-score_sent: 0.672242134607726
train_label=P_precision_sent: 0.6581176470588235
train_label=P_recall_sent: 0.774792243767313
train_label=P_f-score_sent: 0.711704834605598
train_precision_macro_sent: 0.5976342257974586
train_recall_macro_sent: 0.5210486471083647
train_f-score_macro_sent: 0.47626157577513945
train_precision_micro_sent: 0.6281601123595506
train_recall_micro_sent: 0.6281601123595506
train_f-score_micro_sent: 0.6281601123595506
train_label=O_precision_tok: 0.878582968426747
train_label=O_recall_tok: 0.9665211062590975
train_label=O_f-score_tok: 0.9204564601363253
train_label=N_precision_tok: 0.7416532582461786
train_label=N_recall_tok: 0.519293057315871
train_label=N_f-score_tok: 0.6108672243849914
train_label=P_precision_tok: 0.8411076118604789
train_label=P_recall_tok: 0.5658152456329696
train_label=P_f-score_tok: 0.6765282225302299
train_precision_macro_tok: 0.8204479461778015
train_recall_macro_tok: 0.6838764697359795
train_f-score_macro_tok: 0.7359506356838489
train_precision_micro_tok: 0.8664025530978321
train_recall_micro_tok: 0.8664025530978321
train_f-score_micro_tok: 0.8664025530978322
train_time: 142.1020679473877
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5352    0.0234    0.0448      1624
           N     0.5996    0.7650    0.6722      3310
           P     0.6581    0.7748    0.7117      3610

   micro avg     0.6282    0.6282    0.6282      8544
   macro avg     0.5976    0.5210    0.4763      8544
weighted avg     0.6121    0.6282    0.5697      8544

F1-macro sent:  0.47626157577513945
F1-micro sent:  0.6281601123595506
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8786    0.9665    0.9205    124347
           N     0.7417    0.5193    0.6109     14202
           P     0.8411    0.5658    0.6765     25017

   micro avg     0.8664    0.8664    0.8664    163566
   macro avg     0.8204    0.6839    0.7360    163566
weighted avg     0.8610    0.8664    0.8563    163566

F1-macro tok:  0.7359506356838489
F1-micro tok:  0.8664025530978322
**************************************************
dev_cost_sum: 45346.06268310547
dev_cost_avg: 41.18625130163984
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18792.0
dev_accuracy_tok: 0.88333176647551
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.5824508320726173
dev_label=N_recall_sent: 0.8995327102803738
dev_label=N_f-score_sent: 0.7070707070707071
dev_label=P_precision_sent: 0.7310344827586207
dev_label=P_recall_sent: 0.7162162162162162
dev_label=P_f-score_sent: 0.7235494880546075
dev_precision_macro_sent: 0.6378284382770794
dev_recall_macro_sent: 0.5429497877259376
dev_f-score_macro_sent: 0.48542040692211347
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8908331451794987
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.93051502019398
dev_label=N_precision_tok: 0.76
dev_label=N_recall_tok: 0.5627355950457728
dev_label=N_f-score_tok: 0.6466584158415841
dev_label=P_precision_tok: 0.9001374255611544
dev_label=P_recall_tok: 0.6117683686176837
dev_label=P_f-score_tok: 0.7284522706209454
dev_precision_macro_tok: 0.8503235235802177
dev_recall_macro_tok: 0.7161336363502274
dev_f-score_macro_tok: 0.7685419022188366
dev_precision_micro_tok: 0.88333176647551
dev_recall_micro_tok: 0.88333176647551
dev_f-score_micro_tok: 0.8833317664755099
dev_time: 7.362022399902344
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.5825    0.8995    0.7071       428
           P     0.7310    0.7162    0.7235       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.6378    0.5429    0.4854      1101
weighted avg     0.6460    0.6412    0.5720      1101

F1-macro sent:  0.48542040692211347
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9739    0.9305     16205
           N     0.7600    0.5627    0.6467      1857
           P     0.9001    0.6118    0.7285      3212

   micro avg     0.8833    0.8833    0.8833     21274
   macro avg     0.8503    0.7161    0.7685     21274
weighted avg     0.8808    0.8833    0.8752     21274

F1-macro tok:  0.7685419022188366
F1-micro tok:  0.8833317664755099
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339355.76599121094
train_cost_avg: 39.71860557013237
train_count_sent: 8544.0
train_total_correct_sent: 5367.0
train_accuracy_sent: 0.6281601123595506
train_count_tok: 163566.0
train_total_correct_tok: 142375.0
train_accuracy_tok: 0.8704437352506023
train_label=O_precision_sent: 0.40789473684210525
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.036470588235294116
train_label=N_precision_sent: 0.6014857416726576
train_label=N_recall_sent: 0.7583081570996979
train_label=N_f-score_sent: 0.6708539355873313
train_label=P_precision_sent: 0.6579743888242142
train_label=P_recall_sent: 0.782825484764543
train_label=P_f-score_sent: 0.7149905123339659
train_precision_macro_sent: 0.555784955779659
train_recall_macro_sent: 0.5200741039383265
train_f-score_macro_sent: 0.4741050120521971
train_precision_micro_sent: 0.6281601123595506
train_recall_micro_sent: 0.6281601123595506
train_f-score_micro_sent: 0.6281601123595506
train_label=O_precision_tok: 0.8820485380674197
train_label=O_recall_tok: 0.9677515340136875
train_label=O_f-score_tok: 0.922914685400497
train_label=N_precision_tok: 0.7486510350240361
train_label=N_recall_tok: 0.5373186875088016
train_label=N_f-score_tok: 0.6256200040992007
train_label=P_precision_tok: 0.8502714825306893
train_label=P_recall_tok: 0.5758883958907942
train_label=P_f-score_tok: 0.6866852553561641
train_precision_macro_tok: 0.8269903518740483
train_recall_macro_tok: 0.6936528724710945
train_f-score_macro_tok: 0.745073314951954
train_precision_micro_tok: 0.8704437352506023
train_recall_micro_tok: 0.8704437352506023
train_f-score_micro_tok: 0.8704437352506023
train_time: 141.57707285881042
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4079    0.0191    0.0365      1624
           N     0.6015    0.7583    0.6709      3310
           P     0.6580    0.7828    0.7150      3610

   micro avg     0.6282    0.6282    0.6282      8544
   macro avg     0.5558    0.5201    0.4741      8544
weighted avg     0.5886    0.6282    0.5689      8544

F1-macro sent:  0.4741050120521971
F1-micro sent:  0.6281601123595506
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8820    0.9678    0.9229    124347
           N     0.7487    0.5373    0.6256     14202
           P     0.8503    0.5759    0.6867     25017

   micro avg     0.8704    0.8704    0.8704    163566
   macro avg     0.8270    0.6937    0.7451    163566
weighted avg     0.8656    0.8704    0.8610    163566

F1-macro tok:  0.745073314951954
F1-micro tok:  0.8704437352506023
**************************************************
dev_cost_sum: 45045.03186035156
dev_cost_avg: 40.91283547715855
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18809.0
dev_accuracy_tok: 0.8841308639654037
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6143106457242583
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7032967032967034
dev_label=P_precision_sent: 0.6653992395437263
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7216494845360826
dev_precision_macro_sent: 0.7599032950893282
dev_recall_macro_sent: 0.539817273094831
dev_f-score_macro_sent: 0.4807540683829344
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8893325085756059
dev_label=O_recall_tok: 0.9759333539031163
dev_label=O_f-score_tok: 0.930622572672708
dev_label=N_precision_tok: 0.7664714494875549
dev_label=N_recall_tok: 0.5638126009693053
dev_label=N_f-score_tok: 0.6497052435618987
dev_label=P_precision_tok: 0.916235294117647
dev_label=P_recall_tok: 0.6061643835616438
dev_label=P_f-score_tok: 0.7296233839235524
dev_precision_macro_tok: 0.8573464173936026
dev_recall_macro_tok: 0.7153034461446884
dev_f-score_macro_tok: 0.7699837333860531
dev_precision_micro_tok: 0.8841308639654037
dev_recall_micro_tok: 0.8841308639654037
dev_f-score_micro_tok: 0.8841308639654037
dev_time: 7.279886722564697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6143    0.8224    0.7033       428
           P     0.6654    0.7883    0.7216       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7599    0.5398    0.4808      1101
weighted avg     0.7151    0.6394    0.5680      1101

F1-macro sent:  0.4807540683829344
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8893    0.9759    0.9306     16205
           N     0.7665    0.5638    0.6497      1857
           P     0.9162    0.6062    0.7296      3212

   micro avg     0.8841    0.8841    0.8841     21274
   macro avg     0.8573    0.7153    0.7700     21274
weighted avg     0.8827    0.8841    0.8758     21274

F1-macro tok:  0.7699837333860531
F1-micro tok:  0.8841308639654037
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336244.00103759766
train_cost_avg: 39.354400870505344
train_count_sent: 8544.0
train_total_correct_sent: 5476.0
train_accuracy_sent: 0.6409176029962547
train_count_tok: 163566.0
train_total_correct_tok: 142661.0
train_accuracy_tok: 0.8721922648961276
train_label=O_precision_sent: 0.4479166666666667
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.05
train_label=N_precision_sent: 0.6007664562669072
train_label=N_recall_sent: 0.8051359516616314
train_label=N_f-score_sent: 0.6880970823650917
train_label=P_precision_sent: 0.6899302093718843
train_label=P_recall_sent: 0.7667590027700831
train_label=P_f-score_sent: 0.72631855156127
train_precision_macro_sent: 0.5795377774351528
train_recall_macro_sent: 0.5327909289813433
train_f-score_macro_sent: 0.48813854464212064
train_precision_micro_sent: 0.6409176029962547
train_recall_micro_sent: 0.6409176029962547
train_f-score_micro_sent: 0.6409176029962547
train_label=O_precision_tok: 0.8844966255458676
train_label=O_recall_tok: 0.9675424417155218
train_label=O_f-score_tok: 0.9241576378140255
train_label=N_precision_tok: 0.7471574484486414
train_label=N_recall_tok: 0.5459794395155612
train_label=N_f-score_tok: 0.6309194467046378
train_label=P_precision_tok: 0.8502854479785623
train_label=P_recall_tok: 0.5834432585841628
train_label=P_f-score_tok: 0.6920323353009507
train_precision_macro_tok: 0.8273131739910237
train_recall_macro_tok: 0.6989883799384153
train_f-score_macro_tok: 0.7490364732732048
train_precision_micro_tok: 0.8721922648961276
train_recall_micro_tok: 0.8721922648961276
train_f-score_micro_tok: 0.8721922648961276
train_time: 141.97584009170532
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4479    0.0265    0.0500      1624
           N     0.6008    0.8051    0.6881      3310
           P     0.6899    0.7668    0.7263      3610

   micro avg     0.6409    0.6409    0.6409      8544
   macro avg     0.5795    0.5328    0.4881      8544
weighted avg     0.6094    0.6409    0.5830      8544

F1-macro sent:  0.48813854464212064
F1-micro sent:  0.6409176029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8845    0.9675    0.9242    124347
           N     0.7472    0.5460    0.6309     14202
           P     0.8503    0.5834    0.6920     25017

   micro avg     0.8722    0.8722    0.8722    163566
   macro avg     0.8273    0.6990    0.7490    163566
weighted avg     0.8673    0.8722    0.8632    163566

F1-macro tok:  0.7490364732732048
F1-micro tok:  0.8721922648961276
**************************************************
dev_cost_sum: 44778.97918701172
dev_cost_avg: 40.671189089020636
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18839.0
dev_accuracy_tok: 0.8855410360063928
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.5777439024390244
dev_label=N_recall_sent: 0.8855140186915887
dev_label=N_f-score_sent: 0.6992619926199263
dev_label=P_precision_sent: 0.708803611738149
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7080045095828637
dev_precision_macro_sent: 0.5955158380590578
dev_recall_macro_sent: 0.5323626793752901
dev_f-score_macro_sent: 0.4719748369535995
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8850172279648771
dev_label=O_recall_tok: 0.9827213822894169
dev_label=O_f-score_tok: 0.9313137811047106
dev_label=N_precision_tok: 0.815590947191953
dev_label=N_recall_tok: 0.5239633817985999
dev_label=N_f-score_tok: 0.6380327868852459
dev_label=P_precision_tok: 0.9300431241015812
dev_label=P_recall_tok: 0.6042963885429639
dev_label=P_f-score_tok: 0.7325910549160217
dev_precision_macro_tok: 0.8768837664194704
dev_recall_macro_tok: 0.7036603842103268
dev_f-score_macro_tok: 0.7673125409686593
dev_precision_micro_tok: 0.8855410360063928
dev_recall_micro_tok: 0.8855410360063928
dev_f-score_micro_tok: 0.8855410360063928
dev_time: 7.958021879196167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.5777    0.8855    0.6993       428
           P     0.7088    0.7072    0.7080       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.5955    0.5324    0.4720      1101
weighted avg     0.6144    0.6303    0.5591      1101

F1-macro sent:  0.4719748369535995
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8850    0.9827    0.9313     16205
           N     0.8156    0.5240    0.6380      1857
           P     0.9300    0.6043    0.7326      3212

   micro avg     0.8855    0.8855    0.8855     21274
   macro avg     0.8769    0.7037    0.7673     21274
weighted avg     0.8858    0.8855    0.8757     21274

F1-macro tok:  0.7673125409686593
F1-micro tok:  0.8855410360063928
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333305.7116699219
train_cost_avg: 39.01049996136726
train_count_sent: 8544.0
train_total_correct_sent: 5520.0
train_accuracy_sent: 0.6460674157303371
train_count_tok: 163566.0
train_total_correct_tok: 143253.0
train_accuracy_tok: 0.8758115989875647
train_label=O_precision_sent: 0.5529411764705883
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.05500292568753658
train_label=N_precision_sent: 0.6155856497980517
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.6891873919404176
train_label=P_precision_sent: 0.6781176470588235
train_label=P_recall_sent: 0.7983379501385042
train_label=P_f-score_sent: 0.7333333333333334
train_precision_macro_sent: 0.6155481577758212
train_recall_macro_sent: 0.5366860976771216
train_f-score_macro_sent: 0.4925078836537626
train_precision_micro_sent: 0.6460674157303371
train_recall_micro_sent: 0.6460674157303371
train_f-score_micro_sent: 0.6460674157303371
train_label=O_precision_tok: 0.8873192755555228
train_label=O_recall_tok: 0.968853289584791
train_label=O_f-score_tok: 0.9262955558972782
train_label=N_precision_tok: 0.7581667947732513
train_label=N_recall_tok: 0.5556259681734967
train_label=N_f-score_tok: 0.6412840308817555
train_label=P_precision_tok: 0.8563704342824274
train_label=P_recall_tok: 0.5951153215813247
train_label=P_f-score_tok: 0.7022310268383567
train_precision_macro_tok: 0.833952168203734
train_recall_macro_tok: 0.7065315264465375
train_f-score_macro_tok: 0.7566035378724635
train_precision_micro_tok: 0.8758115989875647
train_recall_micro_tok: 0.8758115989875647
train_f-score_micro_tok: 0.8758115989875647
train_time: 141.06681656837463
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5529    0.0289    0.0550      1624
           N     0.6156    0.7828    0.6892      3310
           P     0.6781    0.7983    0.7333      3610

   micro avg     0.6461    0.6461    0.6461      8544
   macro avg     0.6155    0.5367    0.4925      8544
weighted avg     0.6301    0.6461    0.5873      8544

F1-macro sent:  0.4925078836537626
F1-micro sent:  0.6460674157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8873    0.9689    0.9263    124347
           N     0.7582    0.5556    0.6413     14202
           P     0.8564    0.5951    0.7022     25017

   micro avg     0.8758    0.8758    0.8758    163566
   macro avg     0.8340    0.7065    0.7566    163566
weighted avg     0.8714    0.8758    0.8673    163566

F1-macro tok:  0.7566035378724635
F1-micro tok:  0.8758115989875647
**************************************************
dev_cost_sum: 44387.939697265625
dev_cost_avg: 40.31602152340202
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18896.0
dev_accuracy_tok: 0.8882203628842719
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6298342541436464
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7044284243048404
dev_label=P_precision_sent: 0.6514598540145985
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.719758064516129
dev_precision_macro_sent: 0.6937647027194149
dev_recall_macro_sent: 0.5460179908104652
dev_f-score_macro_sent: 0.49704403183851004
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8947696139476962
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9333648253668331
dev_label=N_precision_tok: 0.7700573065902578
dev_label=N_recall_tok: 0.5788906838987614
dev_label=N_f-score_tok: 0.6609283738087919
dev_label=P_precision_tok: 0.9104882459312839
dev_label=P_recall_tok: 0.6270236612702366
dev_label=P_f-score_tok: 0.7426253687315634
dev_precision_macro_tok: 0.8584383888230792
dev_recall_macro_tok: 0.727118008093461
dev_f-score_macro_tok: 0.7789728559690627
dev_precision_micro_tok: 0.8882203628842719
dev_recall_micro_tok: 0.8882203628842719
dev_f-score_micro_tok: 0.8882203628842719
dev_time: 7.525116205215454
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6298    0.7991    0.7044       428
           P     0.6515    0.8041    0.7198       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6938    0.5460    0.4970      1101
weighted avg     0.6739    0.6421    0.5780      1101

F1-macro sent:  0.49704403183851004
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9754    0.9334     16205
           N     0.7701    0.5789    0.6609      1857
           P     0.9105    0.6270    0.7426      3212

   micro avg     0.8882    0.8882    0.8882     21274
   macro avg     0.8584    0.7271    0.7790     21274
weighted avg     0.8863    0.8882    0.8808     21274

F1-macro tok:  0.7789728559690627
F1-micro tok:  0.8882203628842719
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330759.89141845703
train_cost_avg: 38.712534107965475
train_count_sent: 8544.0
train_total_correct_sent: 5564.0
train_accuracy_sent: 0.6512172284644194
train_count_tok: 163566.0
train_total_correct_tok: 143631.0
train_accuracy_tok: 0.8781225927148674
train_label=O_precision_sent: 0.5673076923076923
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06828703703703703
train_label=N_precision_sent: 0.6242250834525512
train_label=N_recall_sent: 0.7909365558912387
train_label=N_f-score_sent: 0.6977611940298507
train_label=P_precision_sent: 0.6799340555817239
train_label=P_recall_sent: 0.7997229916897507
train_label=P_f-score_sent: 0.7349796334012219
train_precision_macro_sent: 0.6238222771139892
train_recall_macro_sent: 0.5423298656140244
train_f-score_macro_sent: 0.5003426214893699
train_precision_micro_sent: 0.6512172284644194
train_recall_micro_sent: 0.6512172284644194
train_f-score_micro_sent: 0.6512172284644194
train_label=O_precision_tok: 0.8891848223046901
train_label=O_recall_tok: 0.9692312641237827
train_label=O_f-score_tok: 0.9274841470171765
train_label=N_precision_tok: 0.7615204129516658
train_label=N_recall_tok: 0.5713279819743698
train_label=N_f-score_tok: 0.6528543267490043
train_label=P_precision_tok: 0.8633275762809441
train_label=P_recall_tok: 0.5994323859775352
train_label=P_f-score_tok: 0.7075754358647699
train_precision_macro_tok: 0.8380109371791001
train_recall_macro_tok: 0.7133305440252293
train_f-score_macro_tok: 0.7626379698769835
train_precision_micro_tok: 0.8781225927148674
train_recall_micro_tok: 0.8781225927148674
train_f-score_micro_tok: 0.8781225927148674
train_time: 142.51028084754944
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5673    0.0363    0.0683      1624
           N     0.6242    0.7909    0.6978      3310
           P     0.6799    0.7997    0.7350      3610

   micro avg     0.6512    0.6512    0.6512      8544
   macro avg     0.6238    0.5423    0.5003      8544
weighted avg     0.6369    0.6512    0.5938      8544

F1-macro sent:  0.5003426214893699
F1-micro sent:  0.6512172284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8892    0.9692    0.9275    124347
           N     0.7615    0.5713    0.6529     14202
           P     0.8633    0.5994    0.7076     25017

   micro avg     0.8781    0.8781    0.8781    163566
   macro avg     0.8380    0.7133    0.7626    163566
weighted avg     0.8741    0.8781    0.8700    163566

F1-macro tok:  0.7626379698769835
F1-micro tok:  0.8781225927148674
**************************************************
dev_cost_sum: 44156.71923828125
dev_cost_avg: 40.10601202387034
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18939.0
dev_accuracy_tok: 0.8902416094763561
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5805970149253732
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.70856102003643
dev_label=P_precision_sent: 0.7306791569086651
dev_label=P_recall_sent: 0.7027027027027027
dev_label=P_f-score_sent: 0.7164179104477613
dev_precision_macro_sent: 0.6870920572780128
dev_recall_macro_sent: 0.5415605480189409
dev_f-score_macro_sent: 0.4835766678151882
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8926966292134831
dev_label=O_recall_tok: 0.980561555075594
dev_label=O_f-score_tok: 0.9345684458167917
dev_label=N_precision_tok: 0.7825128581925055
dev_label=N_recall_tok: 0.5735056542810986
dev_label=N_f-score_tok: 0.6619018023617153
dev_label=P_precision_tok: 0.938949361097965
dev_label=P_recall_tok: 0.6176836861768369
dev_label=P_f-score_tok: 0.7451643192488263
dev_precision_macro_tok: 0.8713862828346511
dev_recall_macro_tok: 0.7239169651778431
dev_f-score_macro_tok: 0.780544855809111
dev_precision_micro_tok: 0.8902416094763561
dev_recall_micro_tok: 0.8902416094763561
dev_f-score_micro_tok: 0.8902416094763561
dev_time: 7.8482346534729
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5806    0.9089    0.7086       428
           P     0.7307    0.7027    0.7164       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6871    0.5416    0.4836      1101
weighted avg     0.6764    0.6394    0.5697      1101

F1-macro sent:  0.4835766678151882
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8927    0.9806    0.9346     16205
           N     0.7825    0.5735    0.6619      1857
           P     0.9389    0.6177    0.7452      3212

   micro avg     0.8902    0.8902    0.8902     21274
   macro avg     0.8714    0.7239    0.7805     21274
weighted avg     0.8901    0.8902    0.8822     21274

F1-macro tok:  0.780544855809111
F1-micro tok:  0.8902416094763561
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328275.82806396484
train_cost_avg: 38.42179635580113
train_count_sent: 8544.0
train_total_correct_sent: 5574.0
train_accuracy_sent: 0.6523876404494382
train_count_tok: 163566.0
train_total_correct_tok: 144022.0
train_accuracy_tok: 0.8805130650624213
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.03694581280788178
train_label=O_f-score_sent: 0.06880733944954129
train_label=N_precision_sent: 0.6245589273112209
train_label=N_recall_sent: 0.8021148036253777
train_label=N_f-score_sent: 0.7022880571352996
train_label=P_precision_sent: 0.685118619698059
train_label=P_recall_sent: 0.7919667590027701
train_label=P_f-score_sent: 0.7346781446742902
train_precision_macro_sent: 0.6032258490030933
train_recall_macro_sent: 0.5436757918120099
train_f-score_macro_sent: 0.5019245137530437
train_precision_micro_sent: 0.6523876404494382
train_recall_micro_sent: 0.6523876404494382
train_f-score_micro_sent: 0.6523876404494382
train_label=O_precision_tok: 0.8915909410190245
train_label=O_recall_tok: 0.9697459528577288
train_label=O_f-score_tok: 0.9290276354615284
train_label=N_precision_tok: 0.7673073334577346
train_label=N_recall_tok: 0.5790733699478947
train_label=N_f-score_tok: 0.660032102728732
train_label=P_precision_tok: 0.8643258905743992
train_label=P_recall_tok: 0.6081064875884399
train_label=P_f-score_tok: 0.7139236942137124
train_precision_macro_tok: 0.8410747216837194
train_recall_macro_tok: 0.7189752701313544
train_f-score_macro_tok: 0.7676611441346576
train_precision_micro_tok: 0.8805130650624213
train_recall_micro_tok: 0.8805130650624213
train_f-score_micro_tok: 0.8805130650624213
train_time: 142.49398517608643
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0369    0.0688      1624
           N     0.6246    0.8021    0.7023      3310
           P     0.6851    0.7920    0.7347      3610

   micro avg     0.6524    0.6524    0.6524      8544
   macro avg     0.6032    0.5437    0.5019      8544
weighted avg     0.6265    0.6524    0.5956      8544

F1-macro sent:  0.5019245137530437
F1-micro sent:  0.6523876404494382
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8916    0.9697    0.9290    124347
           N     0.7673    0.5791    0.6600     14202
           P     0.8643    0.6081    0.7139     25017

   micro avg     0.8805    0.8805    0.8805    163566
   macro avg     0.8411    0.7190    0.7677    163566
weighted avg     0.8766    0.8805    0.8728    163566

F1-macro tok:  0.7676611441346576
F1-micro tok:  0.8805130650624213
**************************************************
dev_cost_sum: 43843.211486816406
dev_cost_avg: 39.821263839070305
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 18966.0
dev_accuracy_tok: 0.8915107643132462
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.1422924901185771
dev_label=N_precision_sent: 0.625
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7254901960784315
dev_label=P_precision_sent: 0.7072164948453609
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7384284176533907
dev_precision_macro_sent: 0.6940721649484537
dev_recall_macro_sent: 0.5718703746394233
dev_f-score_macro_sent: 0.5354037012834665
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.892805028622741
dev_label=O_recall_tok: 0.9816723233569886
dev_label=O_f-score_tok: 0.9351321165094201
dev_label=N_precision_tok: 0.821078431372549
dev_label=N_recall_tok: 0.5411954765751211
dev_label=N_f-score_tok: 0.6523855890944499
dev_label=P_precision_tok: 0.9198028673835126
dev_label=P_recall_tok: 0.6391656288916563
dev_label=P_f-score_tok: 0.754224834680382
dev_precision_macro_tok: 0.8778954424596007
dev_recall_macro_tok: 0.7206778096079219
dev_f-score_macro_tok: 0.7805808467614174
dev_precision_micro_tok: 0.8915107643132462
dev_recall_micro_tok: 0.8915107643132462
dev_f-score_micro_tok: 0.8915107643132462
dev_time: 8.068365097045898
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0786    0.1423       229
           N     0.6250    0.8645    0.7255       428
           P     0.7072    0.7725    0.7384       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6941    0.5719    0.5354      1101
weighted avg     0.6842    0.6639    0.6094      1101

F1-macro sent:  0.5354037012834665
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8928    0.9817    0.9351     16205
           N     0.8211    0.5412    0.6524      1857
           P     0.9198    0.6392    0.7542      3212

   micro avg     0.8915    0.8915    0.8915     21274
   macro avg     0.8779    0.7207    0.7806     21274
weighted avg     0.8906    0.8915    0.8831     21274

F1-macro tok:  0.7805808467614174
F1-micro tok:  0.8915107643132462
**************************************************
Best epoch: 11
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 326031.0999145508
train_cost_avg: 38.15907068288281
train_count_sent: 8544.0
train_total_correct_sent: 5582.0
train_accuracy_sent: 0.6533239700374532
train_count_tok: 163566.0
train_total_correct_tok: 144245.0
train_accuracy_tok: 0.8818764290867295
train_label=O_precision_sent: 0.5028571428571429
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.09783212896053363
train_label=N_precision_sent: 0.6164447558981546
train_label=N_recall_sent: 0.7972809667673716
train_label=N_f-score_sent: 0.6952970623106309
train_label=P_precision_sent: 0.6983855185909981
train_label=P_recall_sent: 0.7908587257617729
train_label=P_f-score_sent: 0.7417511041829047
train_precision_macro_sent: 0.6058958057820986
train_recall_macro_sent: 0.547442294882457
train_f-score_macro_sent: 0.5116267651513564
train_precision_micro_sent: 0.6533239700374532
train_recall_micro_sent: 0.6533239700374532
train_f-score_micro_sent: 0.6533239700374532
train_label=O_precision_tok: 0.8929969873944292
train_label=O_recall_tok: 0.9702123895228675
train_label=O_f-score_tok: 0.9300047023272665
train_label=N_precision_tok: 0.7661440836132886
train_label=N_recall_tok: 0.5780875932967188
train_label=N_f-score_tok: 0.6589613933702545
train_label=P_precision_tok: 0.867106078530787
train_label=P_recall_tok: 0.6152616220969741
train_label=P_f-score_tok: 0.7197904975682754
train_precision_macro_tok: 0.8420823831795016
train_recall_macro_tok: 0.7211872016388535
train_f-score_macro_tok: 0.7695855310885987
train_precision_micro_tok: 0.8818764290867295
train_recall_micro_tok: 0.8818764290867295
train_f-score_micro_tok: 0.8818764290867295
train_time: 141.15184926986694
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5029    0.0542    0.0978      1624
           N     0.6164    0.7973    0.6953      3310
           P     0.6984    0.7909    0.7418      3610

   micro avg     0.6533    0.6533    0.6533      8544
   macro avg     0.6059    0.5474    0.5116      8544
weighted avg     0.6295    0.6533    0.6014      8544

F1-macro sent:  0.5116267651513564
F1-micro sent:  0.6533239700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8930    0.9702    0.9300    124347
           N     0.7661    0.5781    0.6590     14202
           P     0.8671    0.6153    0.7198     25017

   micro avg     0.8819    0.8819    0.8819    163566
   macro avg     0.8421    0.7212    0.7696    163566
weighted avg     0.8780    0.8819    0.8743    163566

F1-macro tok:  0.7695855310885987
F1-micro tok:  0.8818764290867295
**************************************************
dev_cost_sum: 43723.992919921875
dev_cost_avg: 39.712981761963555
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 18973.0
dev_accuracy_tok: 0.8918398044561436
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6517509727626459
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7112526539278131
dev_label=P_precision_sent: 0.6494845360824743
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.736842105263158
dev_precision_macro_sent: 0.7004118362817068
dev_recall_macro_sent: 0.5505096268778267
dev_f-score_macro_sent: 0.4940942644596684
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9009606587374199
dev_label=O_recall_tok: 0.9722925023141006
dev_label=O_f-score_tok: 0.9352684533879441
dev_label=N_precision_tok: 0.783226723525231
dev_label=N_recall_tok: 0.5934302638664513
dev_label=N_f-score_tok: 0.6752450980392157
dev_label=P_precision_tok: 0.8890290037831021
dev_label=P_recall_tok: 0.6584682440846824
dev_label=P_f-score_tok: 0.7565730638526204
dev_precision_macro_tok: 0.8577387953485843
dev_recall_macro_tok: 0.7413970034217447
dev_f-score_macro_tok: 0.7890288717599266
dev_precision_micro_tok: 0.8918398044561436
dev_recall_micro_tok: 0.8918398044561436
dev_f-score_micro_tok: 0.8918398044561436
dev_time: 8.375242233276367
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6518    0.7827    0.7113       428
           P     0.6495    0.8514    0.7368       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.7004    0.5505    0.4941      1101
weighted avg     0.6817    0.6512    0.5807      1101

F1-macro sent:  0.4940942644596684
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9010    0.9723    0.9353     16205
           N     0.7832    0.5934    0.6752      1857
           P     0.8890    0.6585    0.7566      3212

   micro avg     0.8918    0.8918    0.8918     21274
   macro avg     0.8577    0.7414    0.7890     21274
weighted avg     0.8889    0.8918    0.8856     21274

F1-macro tok:  0.7890288717599266
F1-micro tok:  0.8918398044561436
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323999.15686035156
train_cost_avg: 37.92124963253178
train_count_sent: 8544.0
train_total_correct_sent: 5607.0
train_accuracy_sent: 0.65625
train_count_tok: 163566.0
train_total_correct_tok: 144645.0
train_accuracy_tok: 0.8843219250944573
train_label=O_precision_sent: 0.5294117647058824
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07228915662650602
train_label=N_precision_sent: 0.616519174041298
train_label=N_recall_sent: 0.820845921450151
train_label=N_f-score_sent: 0.7041596475314241
train_label=P_precision_sent: 0.7035838725734196
train_label=P_recall_sent: 0.7831024930747923
train_label=P_f-score_sent: 0.7412165705296277
train_precision_macro_sent: 0.6165049371068666
train_recall_macro_sent: 0.5475805059910731
train_f-score_macro_sent: 0.5058884582291859
train_precision_micro_sent: 0.65625
train_recall_micro_sent: 0.65625
train_f-score_micro_sent: 0.65625
train_label=O_precision_tok: 0.8949023330317547
train_label=O_recall_tok: 0.9704616918783726
train_label=O_f-score_tok: 0.931151690053358
train_label=N_precision_tok: 0.7723953036886383
train_label=N_recall_tok: 0.5882974228981833
train_label=N_f-score_tok: 0.6678924017746513
train_label=P_precision_tok: 0.8722560464726582
train_label=P_recall_tok: 0.6242155334372627
train_label=P_f-score_tok: 0.7276794035414724
train_precision_macro_tok: 0.8465178943976838
train_recall_macro_tok: 0.7276582160712729
train_f-score_macro_tok: 0.775574498456494
train_precision_micro_tok: 0.8843219250944573
train_recall_micro_tok: 0.8843219250944573
train_f-score_micro_tok: 0.8843219250944573
train_time: 141.0897672176361
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0388    0.0723      1624
           N     0.6165    0.8208    0.7042      3310
           P     0.7036    0.7831    0.7412      3610

   micro avg     0.6562    0.6562    0.6562      8544
   macro avg     0.6165    0.5476    0.5059      8544
weighted avg     0.6367    0.6562    0.5997      8544

F1-macro sent:  0.5058884582291859
F1-micro sent:  0.65625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9705    0.9312    124347
           N     0.7724    0.5883    0.6679     14202
           P     0.8723    0.6242    0.7277     25017

   micro avg     0.8843    0.8843    0.8843    163566
   macro avg     0.8465    0.7277    0.7756    163566
weighted avg     0.8808    0.8843    0.8772    163566

F1-macro tok:  0.775574498456494
F1-micro tok:  0.8843219250944573
**************************************************
dev_cost_sum: 43450.07843017578
dev_cost_avg: 39.46419475946937
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19000.0
dev_accuracy_tok: 0.8931089592930338
dev_label=O_precision_sent: 0.8461538461538461
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09090909090909091
dev_label=N_precision_sent: 0.5853293413173652
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.7135036496350364
dev_label=P_precision_sent: 0.7428571428571429
dev_label=P_recall_sent: 0.7027027027027027
dev_label=P_f-score_sent: 0.7222222222222223
dev_precision_macro_sent: 0.7247801101094514
dev_recall_macro_sent: 0.5547630130232261
dev_f-score_macro_sent: 0.5088783209221166
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8993177942012507
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.936173990235242
dev_label=N_precision_tok: 0.7767732962447844
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.6779969650986344
dev_label=P_precision_tok: 0.918967052537845
dev_label=P_recall_tok: 0.6425902864259029
dev_label=P_f-score_tok: 0.7563209967020889
dev_precision_macro_tok: 0.8650193809946267
dev_recall_macro_tok: 0.7400927620059434
dev_f-score_macro_tok: 0.7901639840119884
dev_precision_micro_tok: 0.8931089592930338
dev_recall_micro_tok: 0.8931089592930338
dev_f-score_micro_tok: 0.8931089592930339
dev_time: 8.01762080192566
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8462    0.0480    0.0909       229
           N     0.5853    0.9136    0.7135       428
           P     0.7429    0.7027    0.7222       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.7248    0.5548    0.5089      1101
weighted avg     0.7031    0.6485    0.5875      1101

F1-macro sent:  0.5088783209221166
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8993    0.9762    0.9362     16205
           N     0.7768    0.6015    0.6780      1857
           P     0.9190    0.6426    0.7563      3212

   micro avg     0.8931    0.8931    0.8931     21274
   macro avg     0.8650    0.7401    0.7902     21274
weighted avg     0.8916    0.8931    0.8865     21274

F1-macro tok:  0.7901639840119884
F1-micro tok:  0.8931089592930339
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321941.8635253906
train_cost_avg: 37.68046155493804
train_count_sent: 8544.0
train_total_correct_sent: 5619.0
train_accuracy_sent: 0.6576544943820225
train_count_tok: 163566.0
train_total_correct_tok: 144862.0
train_accuracy_tok: 0.8856486066786496
train_label=O_precision_sent: 0.48507462686567165
train_label=O_recall_sent: 0.04002463054187192
train_label=O_f-score_sent: 0.07394766780432309
train_label=N_precision_sent: 0.6209344938158498
train_label=N_recall_sent: 0.8190332326283988
train_label=N_f-score_sent: 0.7063574778530485
train_label=P_precision_sent: 0.7030168150346192
train_label=P_recall_sent: 0.7875346260387812
train_label=P_f-score_sent: 0.7428795401097466
train_precision_macro_sent: 0.6030086452387136
train_recall_macro_sent: 0.548864163069684
train_f-score_macro_sent: 0.5077282285890393
train_precision_micro_sent: 0.6576544943820225
train_recall_micro_sent: 0.6576544943820225
train_f-score_micro_sent: 0.6576544943820225
train_label=O_precision_tok: 0.8967759676556276
train_label=O_recall_tok: 0.9703732297522256
train_label=O_f-score_tok: 0.9321241101742379
train_label=N_precision_tok: 0.7747592222424132
train_label=N_recall_tok: 0.6004083931840586
train_label=N_f-score_tok: 0.6765312599174865
train_label=P_precision_tok: 0.8702798756108396
train_label=P_recall_tok: 0.6264540112723348
train_label=P_f-score_tok: 0.728506682161534
train_precision_macro_tok: 0.8472716885029602
train_recall_macro_tok: 0.7324118780695397
train_f-score_macro_tok: 0.7790540174177529
train_precision_micro_tok: 0.8856486066786496
train_recall_micro_tok: 0.8856486066786496
train_f-score_micro_tok: 0.8856486066786496
train_time: 141.06260633468628
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4851    0.0400    0.0739      1624
           N     0.6209    0.8190    0.7064      3310
           P     0.7030    0.7875    0.7429      3610

   micro avg     0.6577    0.6577    0.6577      8544
   macro avg     0.6030    0.5489    0.5077      8544
weighted avg     0.6298    0.6577    0.6016      8544

F1-macro sent:  0.5077282285890393
F1-micro sent:  0.6576544943820225
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8968    0.9704    0.9321    124347
           N     0.7748    0.6004    0.6765     14202
           P     0.8703    0.6265    0.7285     25017

   micro avg     0.8856    0.8856    0.8856    163566
   macro avg     0.8473    0.7324    0.7791    163566
weighted avg     0.8821    0.8856    0.8788    163566

F1-macro tok:  0.7790540174177529
F1-micro tok:  0.8856486066786496
**************************************************
dev_cost_sum: 43349.115966796875
dev_cost_avg: 39.37249406611887
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19030.0
dev_accuracy_tok: 0.8945191313340227
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.059322033898305086
dev_label=N_precision_sent: 0.6619433198380567
dev_label=N_recall_sent: 0.764018691588785
dev_label=N_f-score_sent: 0.7093275488069415
dev_label=P_precision_sent: 0.6333333333333333
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7279693486590036
dev_precision_macro_sent: 0.7650922177237968
dev_recall_macro_sent: 0.5501474110113868
dev_f-score_macro_sent: 0.4988729771214167
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8994378513429107
dev_label=O_recall_tok: 0.9774760876272756
dev_label=O_f-score_tok: 0.936834634492548
dev_label=N_precision_tok: 0.8114068441064639
dev_label=N_recall_tok: 0.5745826602046311
dev_label=N_f-score_tok: 0.6727616645649432
dev_label=P_precision_tok: 0.9041737649063032
dev_label=P_recall_tok: 0.660958904109589
dev_label=P_f-score_tok: 0.7636690647482014
dev_precision_macro_tok: 0.8716728201185592
dev_recall_macro_tok: 0.7376725506471652
dev_f-score_macro_tok: 0.7910884546018976
dev_precision_micro_tok: 0.8945191313340227
dev_recall_micro_tok: 0.8945191313340227
dev_f-score_micro_tok: 0.8945191313340227
dev_time: 8.13839340209961
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0306    0.0593       229
           N     0.6619    0.7640    0.7093       428
           P     0.6333    0.8559    0.7280       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.7651    0.5501    0.4989      1101
weighted avg     0.7207    0.6485    0.5816      1101

F1-macro sent:  0.4988729771214167
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8994    0.9775    0.9368     16205
           N     0.8114    0.5746    0.6728      1857
           P     0.9042    0.6610    0.7637      3212

   micro avg     0.8945    0.8945    0.8945     21274
   macro avg     0.8717    0.7377    0.7911     21274
weighted avg     0.8925    0.8945    0.8876     21274

F1-macro tok:  0.7910884546018976
F1-micro tok:  0.8945191313340227
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319883.50732421875
train_cost_avg: 37.439549078209126
train_count_sent: 8544.0
train_total_correct_sent: 5640.0
train_accuracy_sent: 0.6601123595505618
train_count_tok: 163566.0
train_total_correct_tok: 145151.0
train_accuracy_tok: 0.8874154775442329
train_label=O_precision_sent: 0.41037735849056606
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.09477124183006537
train_label=N_precision_sent: 0.6329113924050633
train_label=N_recall_sent: 0.8006042296072508
train_label=N_f-score_sent: 0.7069494464452448
train_label=P_precision_sent: 0.7003618817852835
train_label=P_recall_sent: 0.8041551246537396
train_label=P_f-score_sent: 0.7486782720825274
train_precision_macro_sent: 0.5812168775603043
train_recall_macro_sent: 0.5527769276108063
train_f-score_macro_sent: 0.5167996534526126
train_precision_micro_sent: 0.6601123595505618
train_recall_micro_sent: 0.6601123595505618
train_f-score_micro_sent: 0.6601123595505618
train_label=O_precision_tok: 0.8985892425088405
train_label=O_recall_tok: 0.970694910210942
train_label=O_f-score_tok: 0.9332513762602833
train_label=N_precision_tok: 0.7734950584007187
train_label=N_recall_tok: 0.6061822278552317
train_label=N_f-score_tok: 0.6796936680877941
train_label=P_precision_tok: 0.8745513776158136
train_label=P_recall_tok: 0.6331294719590679
train_label=P_f-score_tok: 0.7345112224077165
train_precision_macro_tok: 0.8488785595084577
train_recall_macro_tok: 0.736668870008414
train_f-score_macro_tok: 0.7824854222519314
train_precision_micro_tok: 0.8874154775442329
train_recall_micro_tok: 0.8874154775442329
train_f-score_micro_tok: 0.8874154775442329
train_time: 141.1363649368286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4104    0.0536    0.0948      1624
           N     0.6329    0.8006    0.7069      3310
           P     0.7004    0.8042    0.7487      3610

   micro avg     0.6601    0.6601    0.6601      8544
   macro avg     0.5812    0.5528    0.5168      8544
weighted avg     0.6191    0.6601    0.6082      8544

F1-macro sent:  0.5167996534526126
F1-micro sent:  0.6601123595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8986    0.9707    0.9333    124347
           N     0.7735    0.6062    0.6797     14202
           P     0.8746    0.6331    0.7345     25017

   micro avg     0.8874    0.8874    0.8874    163566
   macro avg     0.8489    0.7367    0.7825    163566
weighted avg     0.8841    0.8874    0.8808    163566

F1-macro tok:  0.7824854222519314
F1-micro tok:  0.8874154775442329
**************************************************
dev_cost_sum: 43101.85400390625
dev_cost_avg: 39.14791462661785
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19043.0
dev_accuracy_tok: 0.8951302058851179
dev_label=O_precision_sent: 0.9
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07531380753138077
dev_label=N_precision_sent: 0.6239600665557404
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.728862973760933
dev_label=P_precision_sent: 0.7081632653061225
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7430406852248393
dev_precision_macro_sent: 0.744041110620621
dev_recall_macro_sent: 0.5656670219580883
dev_f-score_macro_sent: 0.5157391555057177
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.8985162532563145
dev_label=O_recall_tok: 0.9790805307004011
dev_label=O_f-score_tok: 0.9370699583616336
dev_label=N_precision_tok: 0.7949640287769785
dev_label=N_recall_tok: 0.5950457727517501
dev_label=N_f-score_tok: 0.6806282722513088
dev_label=P_precision_tok: 0.9308176100628931
dev_label=P_recall_tok: 0.6450809464508095
dev_label=P_f-score_tok: 0.7620448694372931
dev_precision_macro_tok: 0.8747659640320619
dev_recall_macro_tok: 0.7397357499676535
dev_f-score_macro_tok: 0.7932477000167452
dev_precision_micro_tok: 0.8951302058851179
dev_recall_micro_tok: 0.8951302058851179
dev_f-score_micro_tok: 0.8951302058851179
dev_time: 8.188154458999634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9000    0.0393    0.0753       229
           N     0.6240    0.8762    0.7289       428
           P     0.7082    0.7815    0.7430       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.7440    0.5657    0.5157      1101
weighted avg     0.7153    0.6639    0.5986      1101

F1-macro sent:  0.5157391555057177
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9791    0.9371     16205
           N     0.7950    0.5950    0.6806      1857
           P     0.9308    0.6451    0.7620      3212

   micro avg     0.8951    0.8951    0.8951     21274
   macro avg     0.8748    0.7397    0.7932     21274
weighted avg     0.8944    0.8951    0.8883     21274

F1-macro tok:  0.7932477000167452
F1-micro tok:  0.8951302058851179
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317742.35357666016
train_cost_avg: 37.18894587741809
train_count_sent: 8544.0
train_total_correct_sent: 5692.0
train_accuracy_sent: 0.6661985018726592
train_count_tok: 163566.0
train_total_correct_tok: 145432.0
train_accuracy_tok: 0.8891334384896616
train_label=O_precision_sent: 0.4140127388535032
train_label=O_recall_sent: 0.04002463054187192
train_label=O_f-score_sent: 0.072992700729927
train_label=N_precision_sent: 0.6350023397285914
train_label=N_recall_sent: 0.8199395770392749
train_label=N_f-score_sent: 0.715717299578059
train_label=P_precision_sent: 0.7082421590080233
train_label=P_recall_sent: 0.8069252077562327
train_label=P_f-score_sent: 0.7543700634468471
train_precision_macro_sent: 0.5857524125300393
train_recall_macro_sent: 0.5556298051124599
train_f-score_macro_sent: 0.5143600212516111
train_precision_micro_sent: 0.6661985018726592
train_recall_micro_sent: 0.6661985018726592
train_f-score_micro_sent: 0.6661985018726592
train_label=O_precision_tok: 0.9002176960009542
train_label=O_recall_tok: 0.9710568007269978
train_label=O_f-score_tok: 0.9342964031894273
train_label=N_precision_tok: 0.778329123060267
train_label=N_recall_tok: 0.607449654978172
train_label=N_f-score_tok: 0.6823538717076642
train_label=P_precision_tok: 0.8750408719346049
train_label=P_recall_tok: 0.6418435463884559
train_label=P_f-score_tok: 0.740516982959393
train_precision_macro_tok: 0.8511958969986088
train_recall_macro_tok: 0.740116667364542
train_f-score_macro_tok: 0.7857224192854949
train_precision_micro_tok: 0.8891334384896616
train_recall_micro_tok: 0.8891334384896616
train_f-score_micro_tok: 0.8891334384896616
train_time: 143.1253035068512
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4140    0.0400    0.0730      1624
           N     0.6350    0.8199    0.7157      3310
           P     0.7082    0.8069    0.7544      3610

   micro avg     0.6662    0.6662    0.6662      8544
   macro avg     0.5858    0.5556    0.5144      8544
weighted avg     0.6239    0.6662    0.6099      8544

F1-macro sent:  0.5143600212516111
F1-micro sent:  0.6661985018726592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9002    0.9711    0.9343    124347
           N     0.7783    0.6074    0.6824     14202
           P     0.8750    0.6418    0.7405     25017

   micro avg     0.8891    0.8891    0.8891    163566
   macro avg     0.8512    0.7401    0.7857    163566
weighted avg     0.8858    0.8891    0.8828    163566

F1-macro tok:  0.7857224192854949
F1-micro tok:  0.8891334384896616
**************************************************
dev_cost_sum: 43098.308166503906
dev_cost_avg: 39.144694065852775
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19036.0
dev_accuracy_tok: 0.8948011657422206
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.6561922365988909
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7327141382868937
dev_label=P_precision_sent: 0.6721014492753623
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7449799196787149
dev_precision_macro_sent: 0.6927645619580844
dev_recall_macro_sent: 0.5637419037614931
dev_f-score_macro_sent: 0.5094423231193379
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.8957618055946418
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9369480748851996
dev_label=N_precision_tok: 0.8373048479868529
dev_label=N_recall_tok: 0.5487345180398492
dev_label=N_f-score_tok: 0.6629798308392973
dev_label=P_precision_tok: 0.9179039301310044
dev_label=P_recall_tok: 0.6544209215442092
dev_label=P_f-score_tok: 0.7640857869865503
dev_precision_macro_tok: 0.8836568612374996
dev_recall_macro_tok: 0.7284199094612704
dev_f-score_macro_tok: 0.7880045642370157
dev_precision_micro_tok: 0.8948011657422206
dev_recall_micro_tok: 0.8948011657422206
dev_f-score_micro_tok: 0.8948011657422205
dev_time: 8.023757219314575
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.6562    0.8294    0.7327       428
           P     0.6721    0.8356    0.7450       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6928    0.5637    0.5094      1101
weighted avg     0.6821    0.6649    0.5958      1101

F1-macro sent:  0.5094423231193379
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8958    0.9821    0.9369     16205
           N     0.8373    0.5487    0.6630      1857
           P     0.9179    0.6544    0.7641      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8837    0.7284    0.7880     21274
weighted avg     0.8940    0.8948    0.8869     21274

F1-macro tok:  0.7880045642370157
F1-micro tok:  0.8948011657422205
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315877.1142578125
train_cost_avg: 36.970636032047345
train_count_sent: 8544.0
train_total_correct_sent: 5723.0
train_accuracy_sent: 0.6698267790262172
train_count_tok: 163566.0
train_total_correct_tok: 145765.0
train_accuracy_tok: 0.891169313916095
train_label=O_precision_sent: 0.4842105263157895
train_label=O_recall_sent: 0.05665024630541872
train_label=O_f-score_sent: 0.10143329658213891
train_label=N_precision_sent: 0.6433532934131736
train_label=N_recall_sent: 0.8114803625377643
train_label=N_f-score_sent: 0.7177020708082832
train_label=P_precision_sent: 0.7047140464225892
train_label=P_recall_sent: 0.8157894736842105
train_label=P_f-score_sent: 0.7561946334574401
train_precision_macro_sent: 0.6107592887171841
train_recall_macro_sent: 0.5613066941757978
train_f-score_macro_sent: 0.5251100002826208
train_precision_micro_sent: 0.6698267790262172
train_recall_micro_sent: 0.6698267790262172
train_f-score_micro_sent: 0.6698267790262172
train_label=O_precision_tok: 0.9019290083119871
train_label=O_recall_tok: 0.9712417669907597
train_label=O_f-score_tok: 0.9353030009680542
train_label=N_precision_tok: 0.7893460294646065
train_label=N_recall_tok: 0.6187156738487537
train_label=N_f-score_tok: 0.6936922712560195
train_label=P_precision_tok: 0.8745885273325779
train_label=P_recall_tok: 0.6478394691609706
train_label=P_f-score_tok: 0.7443280977312391
train_precision_macro_tok: 0.8552878550363904
train_recall_macro_tok: 0.7459323033334947
train_f-score_macro_tok: 0.7911077899851042
train_precision_micro_tok: 0.891169313916095
train_recall_micro_tok: 0.891169313916095
train_f-score_micro_tok: 0.891169313916095
train_time: 140.74700951576233
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4842    0.0567    0.1014      1624
           N     0.6434    0.8115    0.7177      3310
           P     0.7047    0.8158    0.7562      3610

   micro avg     0.6698    0.6698    0.6698      8544
   macro avg     0.6108    0.5613    0.5251      8544
weighted avg     0.6390    0.6698    0.6168      8544

F1-macro sent:  0.5251100002826208
F1-micro sent:  0.6698267790262172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9019    0.9712    0.9353    124347
           N     0.7893    0.6187    0.6937     14202
           P     0.8746    0.6478    0.7443     25017

   micro avg     0.8912    0.8912    0.8912    163566
   macro avg     0.8553    0.7459    0.7911    163566
weighted avg     0.8880    0.8912    0.8851    163566

F1-macro tok:  0.7911077899851042
F1-micro tok:  0.891169313916095
**************************************************
dev_cost_sum: 42822.86486816406
dev_cost_avg: 38.89451849969488
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19107.0
dev_accuracy_tok: 0.8981385729058945
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.664783427495292
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7361835245046925
dev_label=P_precision_sent: 0.6720142602495544
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7502487562189054
dev_precision_macro_sent: 0.7048584885075413
dev_recall_macro_sent: 0.5681443799429352
dev_f-score_macro_sent: 0.5150852700451208
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9063092025948677
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.939031644063764
dev_label=N_precision_tok: 0.7903114186851211
dev_label=N_recall_tok: 0.6149703823371029
dev_label=N_f-score_tok: 0.6917019987886129
dev_label=P_precision_tok: 0.9037344398340249
dev_label=P_recall_tok: 0.678082191780822
dev_label=P_f-score_tok: 0.774813233724653
dev_precision_macro_tok: 0.866785020371338
dev_recall_macro_tok: 0.7557526887499942
dev_f-score_macro_tok: 0.80184895885901
dev_precision_micro_tok: 0.8981385729058945
dev_recall_micro_tok: 0.8981385729058945
dev_f-score_micro_tok: 0.8981385729058945
dev_time: 7.006201982498169
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6648    0.8248    0.7362       428
           P     0.6720    0.8491    0.7502       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.7049    0.5681    0.5151      1101
weighted avg     0.6912    0.6694    0.6010      1101

F1-macro sent:  0.5150852700451208
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9742    0.9390     16205
           N     0.7903    0.6150    0.6917      1857
           P     0.9037    0.6781    0.7748      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8668    0.7558    0.8018     21274
weighted avg     0.8958    0.8981    0.8926     21274

F1-macro tok:  0.80184895885901
F1-micro tok:  0.8981385729058945
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 314256.5219116211
train_cost_avg: 36.78095996156614
train_count_sent: 8544.0
train_total_correct_sent: 5727.0
train_accuracy_sent: 0.6702949438202247
train_count_tok: 163566.0
train_total_correct_tok: 145951.0
train_accuracy_tok: 0.8923064695596884
train_label=O_precision_sent: 0.42727272727272725
train_label=O_recall_sent: 0.05788177339901478
train_label=O_f-score_sent: 0.1019522776572668
train_label=N_precision_sent: 0.6442762535477767
train_label=N_recall_sent: 0.8229607250755288
train_label=N_f-score_sent: 0.7227381268240913
train_label=P_precision_sent: 0.710205078125
train_label=P_recall_sent: 0.8058171745152355
train_label=P_f-score_sent: 0.7549961069296652
train_precision_macro_sent: 0.5939180196485013
train_recall_macro_sent: 0.5622198909965931
train_f-score_macro_sent: 0.5265621704703412
train_precision_micro_sent: 0.6702949438202247
train_recall_micro_sent: 0.6702949438202247
train_f-score_micro_sent: 0.6702949438202247
train_label=O_precision_tok: 0.9035842562107154
train_label=O_recall_tok: 0.9711130948072731
train_label=O_f-score_tok: 0.9361324407818998
train_label=N_precision_tok: 0.787511071744907
train_label=N_recall_tok: 0.6260385861146317
train_label=N_f-score_tok: 0.6975521732308175
train_label=P_precision_tok: 0.8749195106245976
train_label=P_recall_tok: 0.6517568053723468
train_label=P_f-score_tok: 0.7470276956910178
train_precision_macro_tok: 0.85533827952674
train_recall_macro_tok: 0.7496361620980839
train_f-score_macro_tok: 0.793570769901245
train_precision_micro_tok: 0.8923064695596884
train_recall_micro_tok: 0.8923064695596884
train_f-score_micro_tok: 0.8923064695596884
train_time: 93.645831823349
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4273    0.0579    0.1020      1624
           N     0.6443    0.8230    0.7227      3310
           P     0.7102    0.8058    0.7550      3610

   micro avg     0.6703    0.6703    0.6703      8544
   macro avg     0.5939    0.5622    0.5266      8544
weighted avg     0.6309    0.6703    0.6184      8544

F1-macro sent:  0.5265621704703412
F1-micro sent:  0.6702949438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9036    0.9711    0.9361    124347
           N     0.7875    0.6260    0.6976     14202
           P     0.8749    0.6518    0.7470     25017

   micro avg     0.8923    0.8923    0.8923    163566
   macro avg     0.8553    0.7496    0.7936    163566
weighted avg     0.8891    0.8923    0.8865    163566

F1-macro tok:  0.793570769901245
F1-micro tok:  0.8923064695596884
**************************************************
dev_cost_sum: 42701.42028808594
dev_cost_avg: 38.78421461224881
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19063.0
dev_accuracy_tok: 0.8960703205791106
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6508226691042047
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7302564102564102
dev_label=P_precision_sent: 0.6715063520871143
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7437185929648241
dev_precision_macro_sent: 0.7741096737304396
dev_recall_macro_sent: 0.5594031569830452
dev_f-score_macro_sent: 0.4999456907289172
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9077891333217853
dev_label=O_recall_tok: 0.9701943844492441
dev_label=O_f-score_tok: 0.9379548979835342
dev_label=N_precision_tok: 0.78969654199012
dev_label=N_recall_tok: 0.6025848142164781
dev_label=N_f-score_tok: 0.6835675015271838
dev_label=P_precision_tok: 0.8754925137903862
dev_label=P_recall_tok: 0.6917808219178082
dev_label=P_f-score_tok: 0.7728695652173914
dev_precision_macro_tok: 0.8576593963674305
dev_recall_macro_tok: 0.7548533401945101
dev_f-score_macro_tok: 0.7981306549093699
dev_precision_micro_tok: 0.8960703205791106
dev_recall_micro_tok: 0.8960703205791106
dev_f-score_micro_tok: 0.8960703205791106
dev_time: 4.870625972747803
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6508    0.8318    0.7303       428
           P     0.6715    0.8333    0.7437       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.7741    0.5594    0.4999      1101
weighted avg     0.7318    0.6621    0.5892      1101

F1-macro sent:  0.4999456907289172
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9078    0.9702    0.9380     16205
           N     0.7897    0.6026    0.6836      1857
           P     0.8755    0.6918    0.7729      3212

   micro avg     0.8961    0.8961    0.8961     21274
   macro avg     0.8577    0.7549    0.7981     21274
weighted avg     0.8926    0.8961    0.8908     21274

F1-macro tok:  0.7981306549093699
F1-micro tok:  0.8960703205791106
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 312568.61267089844
train_cost_avg: 36.583405041069575
train_count_sent: 8544.0
train_total_correct_sent: 5738.0
train_accuracy_sent: 0.6715823970037453
train_count_tok: 163566.0
train_total_correct_tok: 146362.0
train_accuracy_tok: 0.8948192167076288
train_label=O_precision_sent: 0.4631578947368421
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.0970231532524807
train_label=N_precision_sent: 0.6432955618508026
train_label=N_recall_sent: 0.823262839879154
train_label=N_f-score_sent: 0.7222369467267427
train_label=P_precision_sent: 0.7102962603205439
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.7569875776397516
train_precision_macro_sent: 0.6055832389693961
train_recall_macro_sent: 0.5625664464922017
train_f-score_macro_sent: 0.5254158925396583
train_precision_micro_sent: 0.6715823970037453
train_recall_micro_sent: 0.6715823970037453
train_f-score_micro_sent: 0.6715823970037453
train_label=O_precision_tok: 0.9060011099278547
train_label=O_recall_tok: 0.9715393214150724
train_label=O_f-score_tok: 0.9376263635622786
train_label=N_precision_tok: 0.7954866008462623
train_label=N_recall_tok: 0.6354034643008027
train_label=N_f-score_tok: 0.7064902528771628
train_label=P_precision_tok: 0.8755296610169492
train_label=P_recall_tok: 0.6607506895311188
train_label=P_f-score_tok: 0.7531266373556279
train_precision_macro_tok: 0.859005790597022
train_recall_macro_tok: 0.7558978250823314
train_f-score_macro_tok: 0.7990810845983565
train_precision_micro_tok: 0.8948192167076288
train_recall_micro_tok: 0.8948192167076288
train_f-score_micro_tok: 0.8948192167076288
train_time: 92.83797597885132
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4632    0.0542    0.0970      1624
           N     0.6433    0.8233    0.7222      3310
           P     0.7103    0.8102    0.7570      3610

   micro avg     0.6716    0.6716    0.6716      8544
   macro avg     0.6056    0.5626    0.5254      8544
weighted avg     0.6374    0.6716    0.6181      8544

F1-macro sent:  0.5254158925396583
F1-micro sent:  0.6715823970037453
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9060    0.9715    0.9376    124347
           N     0.7955    0.6354    0.7065     14202
           P     0.8755    0.6608    0.7531     25017

   micro avg     0.8948    0.8948    0.8948    163566
   macro avg     0.8590    0.7559    0.7991    163566
weighted avg     0.8917    0.8948    0.8893    163566

F1-macro tok:  0.7990810845983565
F1-micro tok:  0.8948192167076288
**************************************************
dev_cost_sum: 42613.89685058594
dev_cost_avg: 38.704720118606666
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.7015250544662309
dev_label=N_recall_sent: 0.7523364485981309
dev_label=N_f-score_sent: 0.7260428410372041
dev_label=P_precision_sent: 0.621283255086072
dev_label=P_recall_sent: 0.8941441441441441
dev_label=P_f-score_sent: 0.7331486611265005
dev_precision_macro_sent: 0.7742694365174342
dev_recall_macro_sent: 0.5531936764744992
dev_f-score_macro_sent: 0.49501785704307394
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9048682703321879
dev_label=O_recall_tok: 0.9749460043196544
dev_label=O_f-score_tok: 0.9386009208376652
dev_label=N_precision_tok: 0.7867494824016563
dev_label=N_recall_tok: 0.6138933764135702
dev_label=N_f-score_tok: 0.6896551724137931
dev_label=P_precision_tok: 0.9112050739957717
dev_label=P_recall_tok: 0.6709215442092155
dev_label=P_f-score_tok: 0.7728169266630804
dev_precision_macro_tok: 0.8676076089098719
dev_recall_macro_tok: 0.75325364164748
dev_f-score_macro_tok: 0.8003576733048462
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 5.052168846130371
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.7015    0.7523    0.7260       428
           P     0.6213    0.8941    0.7331       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7743    0.5532    0.4950      1101
weighted avg     0.7312    0.6558    0.5833      1101

F1-macro sent:  0.49501785704307394
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9049    0.9749    0.9386     16205
           N     0.7867    0.6139    0.6897      1857
           P     0.9112    0.6709    0.7728      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8676    0.7533    0.8004     21274
weighted avg     0.8955    0.8975    0.8918     21274

F1-macro tok:  0.8003576733048462
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 310851.27893066406
train_cost_avg: 36.38240624188484
train_count_sent: 8544.0
train_total_correct_sent: 5788.0
train_accuracy_sent: 0.677434456928839
train_count_tok: 163566.0
train_total_correct_tok: 146511.0
train_accuracy_tok: 0.8957301639705073
train_label=O_precision_sent: 0.5204081632653061
train_label=O_recall_sent: 0.06280788177339902
train_label=O_f-score_sent: 0.1120879120879121
train_label=N_precision_sent: 0.6560910632114313
train_label=N_recall_sent: 0.8184290030211481
train_label=N_f-score_sent: 0.7283236994219653
train_label=P_precision_sent: 0.7056174448921545
train_label=P_recall_sent: 0.8246537396121884
train_label=P_f-score_sent: 0.7605058117256354
train_precision_macro_sent: 0.6273722237896306
train_recall_macro_sent: 0.5686302081355784
train_f-score_macro_sent: 0.5336391410785043
train_precision_micro_sent: 0.677434456928839
train_recall_micro_sent: 0.677434456928839
train_f-score_micro_sent: 0.677434456928839
train_label=O_precision_tok: 0.9072050351877304
train_label=O_recall_tok: 0.9713784811857141
train_label=O_f-score_tok: 0.938195658083809
train_label=N_precision_tok: 0.7908336970755129
train_label=N_recall_tok: 0.6378679059287424
train_label=N_f-score_tok: 0.7061620610359746
train_label=P_precision_tok: 0.8785322648671446
train_label=P_recall_tok: 0.6661070472078986
train_label=P_f-score_tok: 0.757712856655678
train_precision_macro_tok: 0.8588569990434626
train_recall_macro_tok: 0.7584511447741185
train_f-score_macro_tok: 0.8006901919251539
train_precision_micro_tok: 0.8957301639705073
train_recall_micro_tok: 0.8957301639705073
train_f-score_micro_tok: 0.8957301639705073
train_time: 92.52022624015808
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5204    0.0628    0.1121      1624
           N     0.6561    0.8184    0.7283      3310
           P     0.7056    0.8247    0.7605      3610

   micro avg     0.6774    0.6774    0.6774      8544
   macro avg     0.6274    0.5686    0.5336      8544
weighted avg     0.6512    0.6774    0.6248      8544

F1-macro sent:  0.5336391410785043
F1-micro sent:  0.677434456928839
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9072    0.9714    0.9382    124347
           N     0.7908    0.6379    0.7062     14202
           P     0.8785    0.6661    0.7577     25017

   micro avg     0.8957    0.8957    0.8957    163566
   macro avg     0.8589    0.7585    0.8007    163566
weighted avg     0.8927    0.8957    0.8904    163566

F1-macro tok:  0.8006901919251539
F1-micro tok:  0.8957301639705073
**************************************************
dev_cost_sum: 42480.6240234375
dev_cost_avg: 38.58367304581063
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19132.0
dev_accuracy_tok: 0.8993137162733853
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6114649681528662
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7272727272727273
dev_label=P_precision_sent: 0.7278617710583153
dev_label=P_recall_sent: 0.759009009009009
dev_label=P_f-score_sent: 0.743109151047409
dev_precision_macro_sent: 0.6797755797370605
dev_recall_macro_sent: 0.5622576520935906
dev_f-score_macro_sent: 0.509653094725959
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9066674310611706
dev_label=O_recall_tok: 0.9759333539031163
dev_label=O_f-score_tok: 0.9400261531145981
dev_label=N_precision_tok: 0.7813134732566012
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.6922615476904618
dev_label=P_precision_tok: 0.9188615123194562
dev_label=P_recall_tok: 0.6734122042341221
dev_label=P_f-score_tok: 0.7772188286022278
dev_precision_macro_tok: 0.8689474722124094
dev_recall_macro_tok: 0.7569259920051788
dev_f-score_macro_tok: 0.8031688431357625
dev_precision_micro_tok: 0.8993137162733853
dev_recall_micro_tok: 0.8993137162733853
dev_f-score_micro_tok: 0.8993137162733853
dev_time: 4.973293781280518
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6115    0.8972    0.7273       428
           P     0.7279    0.7590    0.7431       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6798    0.5623    0.5097      1101
weighted avg     0.6768    0.6612    0.5946      1101

F1-macro sent:  0.509653094725959
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9067    0.9759    0.9400     16205
           N     0.7813    0.6214    0.6923      1857
           P     0.9189    0.6734    0.7772      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8689    0.7569    0.8032     21274
weighted avg     0.8976    0.8993    0.8938     21274

F1-macro tok:  0.8031688431357625
F1-micro tok:  0.8993137162733853
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 309086.39111328125
train_cost_avg: 36.175841656517
train_count_sent: 8544.0
train_total_correct_sent: 5792.0
train_accuracy_sent: 0.6779026217228464
train_count_tok: 163566.0
train_total_correct_tok: 146855.0
train_accuracy_tok: 0.8978332905371532
train_label=O_precision_sent: 0.45132743362831856
train_label=O_recall_sent: 0.06280788177339902
train_label=O_f-score_sent: 0.11027027027027027
train_label=N_precision_sent: 0.6528410453128746
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.72797754310921
train_label=P_precision_sent: 0.7154569568362672
train_label=P_recall_sent: 0.8218836565096953
train_label=P_f-score_sent: 0.7649864638391132
train_precision_macro_sent: 0.6065418119258201
train_recall_macro_sent: 0.5691167161849991
train_f-score_macro_sent: 0.5344114257395312
train_precision_micro_sent: 0.6779026217228464
train_recall_micro_sent: 0.6779026217228464
train_f-score_micro_sent: 0.6779026217228464
train_label=O_precision_tok: 0.9090430413262927
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.939410546117401
train_label=N_precision_tok: 0.7979419202930147
train_label=N_recall_tok: 0.6442754541613858
train_label=N_f-score_tok: 0.7129222018777513
train_label=P_precision_tok: 0.8798350472412173
train_label=P_recall_tok: 0.673741855538234
train_label=P_f-score_tok: 0.7631185765382351
train_precision_macro_tok: 0.8622733362868416
train_recall_macro_tok: 0.7632981318654481
train_f-score_macro_tok: 0.8051504415111292
train_precision_micro_tok: 0.8978332905371532
train_recall_micro_tok: 0.8978332905371532
train_f-score_micro_tok: 0.8978332905371532
train_time: 93.21936225891113
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4513    0.0628    0.1103      1624
           N     0.6528    0.8227    0.7280      3310
           P     0.7155    0.8219    0.7650      3610

   micro avg     0.6779    0.6779    0.6779      8544
   macro avg     0.6065    0.5691    0.5344      8544
weighted avg     0.6410    0.6779    0.6262      8544

F1-macro sent:  0.5344114257395312
F1-micro sent:  0.6779026217228464
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9090    0.9719    0.9394    124347
           N     0.7979    0.6443    0.7129     14202
           P     0.8798    0.6737    0.7631     25017

   micro avg     0.8978    0.8978    0.8978    163566
   macro avg     0.8623    0.7633    0.8052    163566
weighted avg     0.8949    0.8978    0.8928    163566

F1-macro tok:  0.8051504415111292
F1-micro tok:  0.8978332905371532
**************************************************
dev_cost_sum: 42374.86926269531
dev_cost_avg: 38.48761967547258
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19133.0
dev_accuracy_tok: 0.899360722008085
dev_label=O_precision_sent: 0.7647058823529411
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10569105691056911
dev_label=N_precision_sent: 0.6960167714884696
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7337016574585635
dev_label=P_precision_sent: 0.6523887973640856
dev_label=P_recall_sent: 0.8918918918918919
dev_label=P_f-score_sent: 0.7535680304471932
dev_precision_macro_sent: 0.7043704837351655
dev_recall_macro_sent: 0.574787128474432
dev_f-score_macro_sent: 0.5309869149387753
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9047102483585499
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9398576512455515
dev_label=N_precision_tok: 0.8284839203675345
dev_label=N_recall_tok: 0.5826602046311254
dev_label=N_f-score_tok: 0.6841606070186531
dev_label=P_precision_tok: 0.8988993069710558
dev_label=P_recall_tok: 0.6864881693648817
dev_label=P_f-score_tok: 0.7784642541924095
dev_precision_macro_tok: 0.8773644918990468
dev_recall_macro_tok: 0.748998239239027
dev_f-score_macro_tok: 0.8008275041522047
dev_precision_micro_tok: 0.899360722008085
dev_recall_micro_tok: 0.899360722008085
dev_f-score_micro_tok: 0.899360722008085
dev_time: 4.916181564331055
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7647    0.0568    0.1057       229
           N     0.6960    0.7757    0.7337       428
           P     0.6524    0.8919    0.7536       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.7044    0.5748    0.5310      1101
weighted avg     0.6927    0.6730    0.6111      1101

F1-macro sent:  0.5309869149387753
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9047    0.9778    0.9399     16205
           N     0.8285    0.5827    0.6842      1857
           P     0.8989    0.6865    0.7785      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8774    0.7490    0.8008     21274
weighted avg     0.8972    0.8994    0.8932     21274

F1-macro tok:  0.8008275041522047
F1-micro tok:  0.899360722008085
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 307553.73095703125
train_cost_avg: 35.996457274933434
train_count_sent: 8544.0
train_total_correct_sent: 5840.0
train_accuracy_sent: 0.6835205992509363
train_count_tok: 163566.0
train_total_correct_tok: 147011.0
train_accuracy_tok: 0.898787033980167
train_label=O_precision_sent: 0.5070422535211268
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11758301578660862
train_label=N_precision_sent: 0.65662362505978
train_label=N_recall_sent: 0.829607250755287
train_label=N_f-score_sent: 0.7330485851575012
train_label=P_precision_sent: 0.7196914919257652
train_label=P_recall_sent: 0.8271468144044322
train_label=P_f-score_sent: 0.7696868153112515
train_precision_macro_sent: 0.6277857901688906
train_recall_macro_sent: 0.5744188427379687
train_f-score_macro_sent: 0.540106138751787
train_precision_micro_sent: 0.6835205992509363
train_recall_micro_sent: 0.6835205992509363
train_f-score_micro_sent: 0.6835205992509363
train_label=O_precision_tok: 0.9107185935709547
train_label=O_recall_tok: 0.9715151953806687
train_label=O_f-score_tok: 0.9401350220821417
train_label=N_precision_tok: 0.7978741790528863
train_label=N_recall_tok: 0.6501197014504999
train_label=N_f-score_tok: 0.7164584464964693
train_label=P_precision_tok: 0.87733898480306
train_label=P_recall_tok: 0.6784586481192789
train_label=P_f-score_tok: 0.765187205554178
train_precision_macro_tok: 0.8619772524756337
train_recall_macro_tok: 0.766697848316816
train_f-score_macro_tok: 0.8072602247109296
train_precision_micro_tok: 0.898787033980167
train_recall_micro_tok: 0.898787033980167
train_f-score_micro_tok: 0.898787033980167
train_time: 93.33277988433838
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5070    0.0665    0.1176      1624
           N     0.6566    0.8296    0.7330      3310
           P     0.7197    0.8271    0.7697      3610

   micro avg     0.6835    0.6835    0.6835      8544
   macro avg     0.6278    0.5744    0.5401      8544
weighted avg     0.6548    0.6835    0.6315      8544

F1-macro sent:  0.540106138751787
F1-micro sent:  0.6835205992509363
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9107    0.9715    0.9401    124347
           N     0.7979    0.6501    0.7165     14202
           P     0.8773    0.6785    0.7652     25017

   micro avg     0.8988    0.8988    0.8988    163566
   macro avg     0.8620    0.7667    0.8073    163566
weighted avg     0.8958    0.8988    0.8940    163566

F1-macro tok:  0.8072602247109296
F1-micro tok:  0.898787033980167
**************************************************
dev_cost_sum: 42325.73742675781
dev_cost_avg: 38.442994938017996
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08196721311475409
dev_label=N_precision_sent: 0.7081447963800905
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.7195402298850575
dev_label=P_precision_sent: 0.6304347826086957
dev_label=P_recall_sent: 0.9144144144144144
dev_label=P_f-score_sent: 0.7463235294117648
dev_precision_macro_sent: 0.6684154152184844
dev_recall_macro_sent: 0.5631303159667033
dev_f-score_macro_sent: 0.5159436574705255
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9085446877347045
dev_label=O_recall_tok: 0.9704412218451095
dev_label=O_f-score_tok: 0.9384734737721548
dev_label=N_precision_tok: 0.7717319177173192
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.6914387633769322
dev_label=P_precision_tok: 0.8921887713588283
dev_label=P_recall_tok: 0.6827521793275217
dev_label=P_f-score_tok: 0.7735449735449734
dev_precision_macro_tok: 0.8574884589369507
dev_recall_macro_tok: 0.7598241152356087
dev_f-score_macro_tok: 0.8011524035646868
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 4.910299777984619
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0437    0.0820       229
           N     0.7081    0.7313    0.7195       428
           P     0.6304    0.9144    0.7463       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6684    0.5631    0.5159      1101
weighted avg     0.6682    0.6621    0.5977      1101

F1-macro sent:  0.5159436574705255
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9085    0.9704    0.9385     16205
           N     0.7717    0.6263    0.6914      1857
           P     0.8922    0.6828    0.7735      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8575    0.7598    0.8012     21274
weighted avg     0.8941    0.8970    0.8920     21274

F1-macro tok:  0.8011524035646868
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 21
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 305817.8381347656
train_cost_avg: 35.793286298544665
train_count_sent: 8544.0
train_total_correct_sent: 5875.0
train_accuracy_sent: 0.6876170411985019
train_count_tok: 163566.0
train_total_correct_tok: 147393.0
train_accuracy_tok: 0.901122482667547
train_label=O_precision_sent: 0.4921259842519685
train_label=O_recall_sent: 0.0769704433497537
train_label=O_f-score_sent: 0.13312034078807242
train_label=N_precision_sent: 0.6582612872238233
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7334760503077334
train_label=P_precision_sent: 0.7292777508482792
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7779214064115823
train_precision_macro_sent: 0.6265550074413571
train_recall_macro_sent: 0.5795283752090267
train_f-score_macro_sent: 0.5481725991691294
train_precision_micro_sent: 0.6876170411985019
train_recall_micro_sent: 0.6876170411985019
train_f-score_micro_sent: 0.6876170411985019
train_label=O_precision_tok: 0.9126593366761312
train_label=O_recall_tok: 0.9719414219884678
train_label=O_f-score_tok: 0.9413679893757472
train_label=N_precision_tok: 0.8038861662797696
train_label=N_recall_tok: 0.6583579777496127
train_label=N_f-score_tok: 0.7238803081330082
train_label=P_precision_tok: 0.8807851980933832
train_label=P_recall_tok: 0.6869328856377663
train_label=P_f-score_tok: 0.7718738771110313
train_precision_macro_tok: 0.8657769003497613
train_recall_macro_tok: 0.7724107617919489
train_f-score_macro_tok: 0.8123740582065956
train_precision_micro_tok: 0.901122482667547
train_recall_micro_tok: 0.901122482667547
train_f-score_micro_tok: 0.901122482667547
train_time: 92.98787045478821
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4921    0.0770    0.1331      1624
           N     0.6583    0.8281    0.7335      3310
           P     0.7293    0.8335    0.7779      3610

   micro avg     0.6876    0.6876    0.6876      8544
   macro avg     0.6266    0.5795    0.5482      8544
weighted avg     0.6567    0.6876    0.6381      8544

F1-macro sent:  0.5481725991691294
F1-micro sent:  0.6876170411985019
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9127    0.9719    0.9414    124347
           N     0.8039    0.6584    0.7239     14202
           P     0.8808    0.6869    0.7719     25017

   micro avg     0.9011    0.9011    0.9011    163566
   macro avg     0.8658    0.7724    0.8124    163566
weighted avg     0.8983    0.9011    0.8966    163566

F1-macro tok:  0.8123740582065956
F1-micro tok:  0.901122482667547
**************************************************
dev_cost_sum: 42200.50939941406
dev_cost_avg: 38.32925467703366
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19151.0
dev_accuracy_tok: 0.9002068252326784
dev_label=O_precision_sent: 0.7368421052631579
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11290322580645161
dev_label=N_precision_sent: 0.6485507246376812
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7306122448979593
dev_label=P_precision_sent: 0.690566037735849
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7515400410677618
dev_precision_macro_sent: 0.6919862892122294
dev_recall_macro_sent: 0.5739694312114016
dev_f-score_macro_sent: 0.5316851705907243
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9132584792599918
dev_label=O_recall_tok: 0.9687133600740512
dev_label=O_f-score_tok: 0.9401688926154398
dev_label=N_precision_tok: 0.7833553500660502
dev_label=N_recall_tok: 0.6386645126548196
dev_label=N_f-score_tok: 0.7036487689113022
dev_label=P_precision_tok: 0.881758070789576
dev_label=P_recall_tok: 0.7057907845579079
dev_label=P_f-score_tok: 0.7840221338405672
dev_precision_macro_tok: 0.8594573000385394
dev_recall_macro_tok: 0.771056219095593
dev_f-score_macro_tok: 0.8092799317891032
dev_precision_micro_tok: 0.9002068252326784
dev_recall_micro_tok: 0.9002068252326784
dev_f-score_micro_tok: 0.9002068252326785
dev_time: 4.949289321899414
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7368    0.0611    0.1129       229
           N     0.6486    0.8364    0.7306       428
           P     0.6906    0.8243    0.7515       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6920    0.5740    0.5317      1101
weighted avg     0.6839    0.6703    0.6106      1101

F1-macro sent:  0.5316851705907243
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9133    0.9687    0.9402     16205
           N     0.7834    0.6387    0.7036      1857
           P     0.8818    0.7058    0.7840      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8595    0.7711    0.8093     21274
weighted avg     0.8972    0.9002    0.8959     21274

F1-macro tok:  0.8092799317891032
F1-micro tok:  0.9002068252326785
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 304575.1248779297
train_cost_avg: 35.64783764957042
train_count_sent: 8544.0
train_total_correct_sent: 5907.0
train_accuracy_sent: 0.6913623595505618
train_count_tok: 163566.0
train_total_correct_tok: 147531.0
train_accuracy_tok: 0.9019661787902131
train_label=O_precision_sent: 0.5294117647058824
train_label=O_recall_sent: 0.08312807881773399
train_label=O_f-score_sent: 0.14369345396487493
train_label=N_precision_sent: 0.6733333333333333
train_label=N_recall_sent: 0.8238670694864049
train_label=N_f-score_sent: 0.7410326086956521
train_label=P_precision_sent: 0.7183297947629158
train_label=P_recall_sent: 0.8434903047091413
train_label=P_f-score_sent: 0.7758950184736909
train_precision_macro_sent: 0.6403582976007104
train_recall_macro_sent: 0.5834951510044267
train_f-score_macro_sent: 0.5535403603780726
train_precision_micro_sent: 0.6913623595505618
train_recall_micro_sent: 0.6913623595505618
train_f-score_micro_sent: 0.6913623595505618
train_label=O_precision_tok: 0.9137728898940314
train_label=O_recall_tok: 0.9715473634265402
train_label=O_f-score_tok: 0.9417748951495969
train_label=N_precision_tok: 0.8063329054343175
train_label=N_recall_tok: 0.6634276862413745
train_label=N_f-score_tok: 0.7279329393131688
train_label=P_precision_tok: 0.8794225294835298
train_label=P_recall_tok: 0.691529759763361
train_label=P_f-score_tok: 0.7742397457987423
train_precision_macro_tok: 0.8665094416039595
train_recall_macro_tok: 0.7755016031437586
train_f-score_macro_tok: 0.8146491934205028
train_precision_micro_tok: 0.9019661787902131
train_recall_micro_tok: 0.9019661787902131
train_f-score_micro_tok: 0.9019661787902131
train_time: 92.14886260032654
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0831    0.1437      1624
           N     0.6733    0.8239    0.7410      3310
           P     0.7183    0.8435    0.7759      3610

   micro avg     0.6914    0.6914    0.6914      8544
   macro avg     0.6404    0.5835    0.5535      8544
weighted avg     0.6650    0.6914    0.6422      8544

F1-macro sent:  0.5535403603780726
F1-micro sent:  0.6913623595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9138    0.9715    0.9418    124347
           N     0.8063    0.6634    0.7279     14202
           P     0.8794    0.6915    0.7742     25017

   micro avg     0.9020    0.9020    0.9020    163566
   macro avg     0.8665    0.7755    0.8146    163566
weighted avg     0.8992    0.9020    0.8976    163566

F1-macro tok:  0.8146491934205028
F1-micro tok:  0.9019661787902131
**************************************************
dev_cost_sum: 42135.71923828125
dev_cost_avg: 38.27040802750341
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.6923076923076923
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.14117647058823532
dev_label=N_precision_sent: 0.7199074074074074
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.7232558139534885
dev_label=P_precision_sent: 0.6267496111975117
dev_label=P_recall_sent: 0.9076576576576577
dev_label=P_f-score_sent: 0.7414903403863845
dev_precision_macro_sent: 0.6796549036375371
dev_recall_macro_sent: 0.5709652639212285
dev_f-score_macro_sent: 0.5353075416427028
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9054524693120183
dev_label=O_recall_tok: 0.9786485652576365
dev_label=O_f-score_tok: 0.9406287069988137
dev_label=N_precision_tok: 0.813362381989833
dev_label=N_recall_tok: 0.6031233171782445
dev_label=N_f-score_tok: 0.6926406926406927
dev_label=P_precision_tok: 0.9198152812762385
dev_label=P_recall_tok: 0.6821295143212951
dev_label=P_f-score_tok: 0.783339292098677
dev_precision_macro_tok: 0.87954337752603
dev_recall_macro_tok: 0.7546337989190587
dev_f-score_macro_tok: 0.8055362305793944
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 4.955441236495972
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6923    0.0786    0.1412       229
           N     0.7199    0.7266    0.7233       428
           P     0.6267    0.9077    0.7415       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6797    0.5710    0.5353      1101
weighted avg     0.6766    0.6649    0.6095      1101

F1-macro sent:  0.5353075416427028
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9055    0.9786    0.9406     16205
           N     0.8134    0.6031    0.6926      1857
           P     0.9198    0.6821    0.7833      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8795    0.7546    0.8055     21274
weighted avg     0.8996    0.9011    0.8952     21274

F1-macro tok:  0.8055362305793944
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 24
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 302828.22259521484
train_cost_avg: 35.44337811273582
train_count_sent: 8544.0
train_total_correct_sent: 5896.0
train_accuracy_sent: 0.6900749063670412
train_count_tok: 163566.0
train_total_correct_tok: 147754.0
train_accuracy_tok: 0.9033295428145214
train_label=O_precision_sent: 0.46496815286624205
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.15067079463364294
train_label=N_precision_sent: 0.6689320388349514
train_label=N_recall_sent: 0.8326283987915408
train_label=N_f-score_sent: 0.74185733512786
train_label=P_precision_sent: 0.7284671532846715
train_label=P_recall_sent: 0.8293628808864266
train_label=P_f-score_sent: 0.7756476683937824
train_precision_macro_sent: 0.6207891149952883
train_recall_macro_sent: 0.5839642525034933
train_f-score_macro_sent: 0.5560585993850952
train_precision_micro_sent: 0.6900749063670412
train_recall_micro_sent: 0.6900749063670412
train_f-score_micro_sent: 0.6900749063670412
train_label=O_precision_tok: 0.9156970794897256
train_label=O_recall_tok: 0.9715312794036044
train_label=O_f-score_tok: 0.9427882439245189
train_label=N_precision_tok: 0.8063591127603947
train_label=N_recall_tok: 0.6732150401351922
train_label=N_f-score_tok: 0.7337963851260602
train_label=P_precision_tok: 0.8789686552072801
train_label=P_recall_tok: 0.694967422152936
train_label=P_f-score_tok: 0.7762126928142509
train_precision_macro_tok: 0.8670082824858002
train_recall_macro_tok: 0.7799045805639109
train_f-score_macro_tok: 0.8175991072882766
train_precision_micro_tok: 0.9033295428145214
train_recall_micro_tok: 0.9033295428145214
train_f-score_micro_tok: 0.9033295428145214
train_time: 93.30973935127258
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4650    0.0899    0.1507      1624
           N     0.6689    0.8326    0.7419      3310
           P     0.7285    0.8294    0.7756      3610

   micro avg     0.6901    0.6901    0.6901      8544
   macro avg     0.6208    0.5840    0.5561      8544
weighted avg     0.6553    0.6901    0.6438      8544

F1-macro sent:  0.5560585993850952
F1-micro sent:  0.6900749063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9715    0.9428    124347
           N     0.8064    0.6732    0.7338     14202
           P     0.8790    0.6950    0.7762     25017

   micro avg     0.9033    0.9033    0.9033    163566
   macro avg     0.8670    0.7799    0.8176    163566
weighted avg     0.9006    0.9033    0.8992    163566

F1-macro tok:  0.8175991072882766
F1-micro tok:  0.9033295428145214
**************************************************
dev_cost_sum: 42060.393127441406
dev_cost_avg: 38.20199194136367
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.7692307692307693
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08264462809917354
dev_label=N_precision_sent: 0.60062893081761
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.7180451127819549
dev_label=P_precision_sent: 0.7323008849557522
dev_label=P_recall_sent: 0.7454954954954955
dev_label=P_f-score_sent: 0.7388392857142857
dev_precision_macro_sent: 0.7007201950013772
dev_recall_macro_sent: 0.5605623274174064
dev_f-score_macro_sent: 0.5131763421984714
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.911274453061697
dev_label=O_recall_tok: 0.9716136994754705
dev_label=O_f-score_tok: 0.9404772571155511
dev_label=N_precision_tok: 0.7681438664097624
dev_label=N_recall_tok: 0.6440495422724825
dev_label=N_f-score_tok: 0.7006444053895724
dev_label=P_precision_tok: 0.9052890528905289
dev_label=P_recall_tok: 0.6874221668742216
dev_label=P_f-score_tok: 0.7814546098035746
dev_precision_macro_tok: 0.8615691241206628
dev_recall_macro_tok: 0.7676951362073915
dev_f-score_macro_tok: 0.8075254241028994
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 4.847494125366211
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7692    0.0437    0.0826       229
           N     0.6006    0.8925    0.7180       428
           P     0.7323    0.7455    0.7388       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.7007    0.5606    0.5132      1101
weighted avg     0.6888    0.6567    0.5943      1101

F1-macro sent:  0.5131763421984714
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9113    0.9716    0.9405     16205
           N     0.7681    0.6440    0.7006      1857
           P     0.9053    0.6874    0.7815      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8616    0.7677    0.8075     21274
weighted avg     0.8979    0.9001    0.8955     21274

F1-macro tok:  0.8075254241028994
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 24
**************************************************

EPOCH: 27
Learning rate: 1.000000
train_cost_sum: 301457.22857666016
train_cost_avg: 35.28291532966528
train_count_sent: 8544.0
train_total_correct_sent: 5921.0
train_accuracy_sent: 0.693000936329588
train_count_tok: 163566.0
train_total_correct_tok: 148014.0
train_accuracy_tok: 0.9049191152195444
train_label=O_precision_sent: 0.4963768115942029
train_label=O_recall_sent: 0.08435960591133004
train_label=O_f-score_sent: 0.14421052631578946
train_label=N_precision_sent: 0.6652329749103942
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.742895263509006
train_label=P_precision_sent: 0.7347538574577517
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.7799298063174315
train_precision_macro_sent: 0.6321212146541163
train_recall_macro_sent: 0.585490716650768
train_f-score_macro_sent: 0.555678532047409
train_precision_micro_sent: 0.693000936329588
train_recall_micro_sent: 0.693000936329588
train_f-score_micro_sent: 0.693000936329588
train_label=O_precision_tok: 0.9170890878737289
train_label=O_recall_tok: 0.9719092539425961
train_label=O_f-score_tok: 0.9437037094878712
train_label=N_precision_tok: 0.8088495575221238
train_label=N_recall_tok: 0.6757498943810731
train_label=N_f-score_tok: 0.7363332949706526
train_label=P_precision_tok: 0.8816324481702725
train_label=P_recall_tok: 0.7020426110245034
train_label=P_f-score_tok: 0.7816547242867952
train_precision_macro_tok: 0.8691903645220417
train_recall_macro_tok: 0.7832339197827243
train_f-score_macro_tok: 0.8205639095817729
train_precision_micro_tok: 0.9049191152195444
train_recall_micro_tok: 0.9049191152195444
train_f-score_micro_tok: 0.9049191152195444
train_time: 93.33306908607483
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4964    0.0844    0.1442      1624
           N     0.6652    0.8411    0.7429      3310
           P     0.7348    0.8310    0.7799      3610

   micro avg     0.6930    0.6930    0.6930      8544
   macro avg     0.6321    0.5855    0.5557      8544
weighted avg     0.6625    0.6930    0.6447      8544

F1-macro sent:  0.555678532047409
F1-micro sent:  0.693000936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9171    0.9719    0.9437    124347
           N     0.8088    0.6757    0.7363     14202
           P     0.8816    0.7020    0.7817     25017

   micro avg     0.9049    0.9049    0.9049    163566
   macro avg     0.8692    0.7832    0.8206    163566
weighted avg     0.9023    0.9049    0.9009    163566

F1-macro tok:  0.8205639095817729
F1-micro tok:  0.9049191152195444
**************************************************
dev_cost_sum: 42037.03869628906
dev_cost_avg: 38.18077992396827
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19165.0
dev_accuracy_tok: 0.9008649055184732
dev_label=O_precision_sent: 0.6060606060606061
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.15267175572519084
dev_label=N_precision_sent: 0.6252072968490879
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7313288069835112
dev_label=P_precision_sent: 0.7376344086021506
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7546754675467546
dev_precision_macro_sent: 0.6563007705039482
dev_recall_macro_sent: 0.5802332961864448
dev_f-score_macro_sent: 0.5462253434184855
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9113770378078391
dev_label=O_recall_tok: 0.9728478864547979
dev_label=O_f-score_tok: 0.9411097513655494
dev_label=N_precision_tok: 0.7532628962088254
dev_label=N_recall_tok: 0.6526655896607432
dev_label=N_f-score_tok: 0.6993652625504906
dev_label=P_precision_tok: 0.9243768483312209
dev_label=P_recall_tok: 0.6811955168119551
dev_label=P_f-score_tok: 0.7843699587739738
dev_precision_macro_tok: 0.8630055941159617
dev_recall_macro_tok: 0.7689029976424987
dev_f-score_macro_tok: 0.8082816575633379
dev_precision_micro_tok: 0.9008649055184732
dev_recall_micro_tok: 0.9008649055184732
dev_f-score_micro_tok: 0.9008649055184732
dev_time: 5.010015964508057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6061    0.0873    0.1527       229
           N     0.6252    0.8808    0.7313       428
           P     0.7376    0.7725    0.7547       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6563    0.5802    0.5462      1101
weighted avg     0.6666    0.6721    0.6204      1101

F1-macro sent:  0.5462253434184855
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9728    0.9411     16205
           N     0.7533    0.6527    0.6994      1857
           P     0.9244    0.6812    0.7844      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8630    0.7689    0.8083     21274
weighted avg     0.8995    0.9009    0.8963     21274

F1-macro tok:  0.8082816575633379
F1-micro tok:  0.9008649055184732
**************************************************
Best epoch: 24
**************************************************

EPOCH: 28
Learning rate: 1.000000
train_cost_sum: 299868.95373535156
train_cost_avg: 35.09702173868815
train_count_sent: 8544.0
train_total_correct_sent: 5867.0
train_accuracy_sent: 0.6866807116104869
train_count_tok: 163566.0
train_total_correct_tok: 148367.0
train_accuracy_tok: 0.9070772654463641
train_label=O_precision_sent: 0.4219948849104859
train_label=O_recall_sent: 0.10160098522167488
train_label=O_f-score_sent: 0.16377171215880892
train_label=N_precision_sent: 0.6618897255282973
train_label=N_recall_sent: 0.823262839879154
train_label=N_f-score_sent: 0.7338090749966338
train_label=P_precision_sent: 0.737611496531219
train_label=P_recall_sent: 0.8246537396121884
train_label=P_f-score_sent: 0.7787078210829191
train_precision_macro_sent: 0.6071653689900007
train_recall_macro_sent: 0.5831725215710057
train_f-score_macro_sent: 0.5587628694127873
train_precision_micro_sent: 0.6866807116104869
train_recall_micro_sent: 0.6866807116104869
train_f-score_micro_sent: 0.6866807116104869
train_label=O_precision_tok: 0.9196641316676943
train_label=O_recall_tok: 0.9715393214150724
train_label=O_f-score_tok: 0.9448902654590392
train_label=N_precision_tok: 0.8134663341645886
train_label=N_recall_tok: 0.6890578791719476
train_label=N_f-score_tok: 0.7461116193961573
train_label=P_precision_tok: 0.8809417596034697
train_label=P_recall_tok: 0.7104369029060239
train_label=P_f-score_tok: 0.7865551425030979
train_precision_macro_tok: 0.8713574084785843
train_recall_macro_tok: 0.790344701164348
train_f-score_macro_tok: 0.8258523424527647
train_precision_micro_tok: 0.9070772654463641
train_recall_micro_tok: 0.9070772654463641
train_f-score_micro_tok: 0.9070772654463641
train_time: 92.8049008846283
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4220    0.1016    0.1638      1624
           N     0.6619    0.8233    0.7338      3310
           P     0.7376    0.8247    0.7787      3610

   micro avg     0.6867    0.6867    0.6867      8544
   macro avg     0.6072    0.5832    0.5588      8544
weighted avg     0.6483    0.6867    0.6444      8544

F1-macro sent:  0.5587628694127873
F1-micro sent:  0.6866807116104869
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9715    0.9449    124347
           N     0.8135    0.6891    0.7461     14202
           P     0.8809    0.7104    0.7866     25017

   micro avg     0.9071    0.9071    0.9071    163566
   macro avg     0.8714    0.7903    0.8259    163566
weighted avg     0.9045    0.9071    0.9034    163566

F1-macro tok:  0.8258523424527647
F1-micro tok:  0.9070772654463641
**************************************************
dev_cost_sum: 42030.38806152344
dev_cost_avg: 38.17473938376334
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19169.0
dev_accuracy_tok: 0.9010529284572718
dev_label=O_precision_sent: 0.425
dev_label=O_recall_sent: 0.14847161572052403
dev_label=O_f-score_sent: 0.2200647249190939
dev_label=N_precision_sent: 0.6460176991150443
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7351460221550856
dev_label=P_precision_sent: 0.7456140350877193
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7555555555555554
dev_precision_macro_sent: 0.6055439114009212
dev_recall_macro_sent: 0.5890137066013489
dev_f-score_macro_sent: 0.5702554342099116
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9087826186918037
dev_label=O_recall_tok: 0.9756865165072508
dev_label=O_f-score_tok: 0.9410469303336012
dev_label=N_precision_tok: 0.7952973720608575
dev_label=N_recall_tok: 0.6192784060312332
dev_label=N_f-score_tok: 0.696336663639116
dev_label=P_precision_tok: 0.908641975308642
dev_label=P_recall_tok: 0.6874221668742216
dev_label=P_f-score_tok: 0.782701169797944
dev_precision_macro_tok: 0.8709073220204343
dev_recall_macro_tok: 0.7607956964709018
dev_f-score_macro_tok: 0.806694921256887
dev_precision_micro_tok: 0.9010529284572718
dev_recall_micro_tok: 0.9010529284572718
dev_f-score_micro_tok: 0.9010529284572718
dev_time: 5.00862193107605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4250    0.1485    0.2201       229
           N     0.6460    0.8528    0.7351       428
           P     0.7456    0.7658    0.7556       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6055    0.5890    0.5703      1101
weighted avg     0.6402    0.6712    0.6362      1101

F1-macro sent:  0.5702554342099116
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9757    0.9410     16205
           N     0.7953    0.6193    0.6963      1857
           P     0.9086    0.6874    0.7827      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8709    0.7608    0.8067     21274
weighted avg     0.8989    0.9011    0.8958     21274

F1-macro tok:  0.806694921256887
F1-micro tok:  0.9010529284572718
**************************************************
Best epoch: 24
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 298298.7000732422
train_cost_avg: 34.913237368122914
train_count_sent: 8544.0
train_total_correct_sent: 5917.0
train_accuracy_sent: 0.6925327715355806
train_count_tok: 163566.0
train_total_correct_tok: 148653.0
train_accuracy_tok: 0.9088257950918895
train_label=O_precision_sent: 0.43452380952380953
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.14897959183673468
train_label=N_precision_sent: 0.6635647816750179
train_label=N_recall_sent: 0.8401812688821753
train_label=N_f-score_sent: 0.7415011331822424
train_label=P_precision_sent: 0.7443365695792881
train_label=P_recall_sent: 0.8282548476454293
train_label=P_f-score_sent: 0.7840566408810804
train_precision_macro_sent: 0.6141417202593719
train_recall_macro_sent: 0.5861125314533723
train_f-score_macro_sent: 0.5581791219666858
train_precision_micro_sent: 0.6925327715355806
train_recall_micro_sent: 0.6925327715355806
train_f-score_micro_sent: 0.6925327715355806
train_label=O_precision_tok: 0.9214735156160623
train_label=O_recall_tok: 0.9716277835412194
train_label=O_f-score_tok: 0.9458862766282266
train_label=N_precision_tok: 0.813418055784783
train_label=N_recall_tok: 0.6940571750457682
train_label=N_f-score_tok: 0.7490121580547112
train_label=P_precision_tok: 0.8841292480204593
train_label=P_recall_tok: 0.7185913578766439
train_label=P_f-score_tok: 0.7928114663726571
train_precision_macro_tok: 0.8730069398071015
train_recall_macro_tok: 0.7947587721545438
train_f-score_macro_tok: 0.8292366336851984
train_precision_micro_tok: 0.9088257950918895
train_recall_micro_tok: 0.9088257950918895
train_f-score_micro_tok: 0.9088257950918895
train_time: 93.09339833259583
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4345    0.0899    0.1490      1624
           N     0.6636    0.8402    0.7415      3310
           P     0.7443    0.8283    0.7841      3610

   micro avg     0.6925    0.6925    0.6925      8544
   macro avg     0.6141    0.5861    0.5582      8544
weighted avg     0.6542    0.6925    0.6469      8544

F1-macro sent:  0.5581791219666858
F1-micro sent:  0.6925327715355806
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9215    0.9716    0.9459    124347
           N     0.8134    0.6941    0.7490     14202
           P     0.8841    0.7186    0.7928     25017

   micro avg     0.9088    0.9088    0.9088    163566
   macro avg     0.8730    0.7948    0.8292    163566
weighted avg     0.9064    0.9088    0.9054    163566

F1-macro tok:  0.8292366336851984
F1-micro tok:  0.9088257950918895
**************************************************
dev_cost_sum: 41906.79217529297
dev_cost_avg: 38.06248153977563
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19142.0
dev_accuracy_tok: 0.8997837736203816
dev_label=O_precision_sent: 0.6818181818181818
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.1195219123505976
dev_label=N_precision_sent: 0.6893004115226338
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7330415754923413
dev_label=P_precision_sent: 0.6559865092748736
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.7502410800385729
dev_precision_macro_sent: 0.6757017008718963
dev_recall_macro_sent: 0.5747795299686905
dev_f-score_macro_sent: 0.5342681892938373
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.914357388717111
dev_label=O_recall_tok: 0.967170626349892
dev_label=O_f-score_tok: 0.940022791339291
dev_label=N_precision_tok: 0.781578947368421
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7035830618892507
dev_label=P_precision_tok: 0.8729429774205893
dev_label=P_recall_tok: 0.7101494396014943
dev_label=P_f-score_tok: 0.7831759656652361
dev_precision_macro_tok: 0.8562931045020404
dev_recall_macro_tok: 0.7723538615099129
dev_f-score_macro_tok: 0.8089272729645925
dev_precision_micro_tok: 0.8997837736203816
dev_recall_micro_tok: 0.8997837736203816
dev_f-score_micro_tok: 0.8997837736203816
dev_time: 5.018702268600464
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6818    0.0655    0.1195       229
           N     0.6893    0.7827    0.7330       428
           P     0.6560    0.8761    0.7502       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6757    0.5748    0.5343      1101
weighted avg     0.6743    0.6712    0.6124      1101

F1-macro sent:  0.5342681892938373
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9144    0.9672    0.9400     16205
           N     0.7816    0.6397    0.7036      1857
           P     0.8729    0.7101    0.7832      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8563    0.7724    0.8089     21274
weighted avg     0.8965    0.8998    0.8957     21274

F1-macro tok:  0.8089272729645925
F1-micro tok:  0.8997837736203816
**************************************************
Best epoch: 24
**************************************************

EPOCH: 30
Learning rate: 0.810000
train_cost_sum: 296555.60290527344
train_cost_avg: 34.70922318647863
train_count_sent: 8544.0
train_total_correct_sent: 5954.0
train_accuracy_sent: 0.6968632958801498
train_count_tok: 163566.0
train_total_correct_tok: 148895.0
train_accuracy_tok: 0.9103053201765648
train_label=O_precision_sent: 0.46726190476190477
train_label=O_recall_sent: 0.09667487684729065
train_label=O_f-score_sent: 0.1602040816326531
train_label=N_precision_sent: 0.6809145129224652
train_label=N_recall_sent: 0.8277945619335347
train_label=N_f-score_sent: 0.7472047995636761
train_label=P_precision_sent: 0.7306405353728489
train_label=P_recall_sent: 0.846814404432133
train_label=P_f-score_sent: 0.7844495765973826
train_precision_macro_sent: 0.6262723176857397
train_recall_macro_sent: 0.5904279477376528
train_f-score_macro_sent: 0.5639528192645705
train_precision_micro_sent: 0.6968632958801498
train_recall_micro_sent: 0.6968632958801498
train_f-score_micro_sent: 0.6968632958801498
train_label=O_precision_tok: 0.9237896315338475
train_label=O_recall_tok: 0.9710165906696583
train_label=O_f-score_tok: 0.9468145586568961
train_label=N_precision_tok: 0.8136549468520032
train_label=N_recall_tok: 0.7006759611322348
train_label=N_f-score_tok: 0.7529509685230023
train_label=P_precision_tok: 0.8821733229934083
train_label=P_recall_tok: 0.7275452692169325
train_label=P_f-score_tok: 0.7974325834081799
train_precision_macro_tok: 0.8732059671264197
train_recall_macro_tok: 0.7997459403396086
train_f-score_macro_tok: 0.8323993701960261
train_precision_micro_tok: 0.9103053201765648
train_recall_micro_tok: 0.9103053201765648
train_f-score_micro_tok: 0.9103053201765648
train_time: 93.1081063747406
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4673    0.0967    0.1602      1624
           N     0.6809    0.8278    0.7472      3310
           P     0.7306    0.8468    0.7844      3610

   micro avg     0.6969    0.6969    0.6969      8544
   macro avg     0.6263    0.5904    0.5640      8544
weighted avg     0.6613    0.6969    0.6514      8544

F1-macro sent:  0.5639528192645705
F1-micro sent:  0.6968632958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9238    0.9710    0.9468    124347
           N     0.8137    0.7007    0.7530     14202
           P     0.8822    0.7275    0.7974     25017

   micro avg     0.9103    0.9103    0.9103    163566
   macro avg     0.8732    0.7997    0.8324    163566
weighted avg     0.9079    0.9103    0.9071    163566

F1-macro tok:  0.8323993701960261
F1-micro tok:  0.9103053201765648
**************************************************
dev_cost_sum: 41964.670166015625
dev_cost_avg: 38.11505010537296
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19186.0
dev_accuracy_tok: 0.9018520259471655
dev_label=O_precision_sent: 0.4166666666666667
dev_label=O_recall_sent: 0.1091703056768559
dev_label=O_f-score_sent: 0.17301038062283738
dev_label=N_precision_sent: 0.6549165120593692
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7300930713547054
dev_label=P_precision_sent: 0.7151394422310757
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.758985200845666
dev_precision_macro_sent: 0.5955742069857038
dev_recall_macro_sent: 0.5808317397918671
dev_f-score_macro_sent: 0.5540295509410695
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9108739544274589
dev_label=O_recall_tok: 0.9743906201789572
dev_label=O_f-score_tok: 0.9415623136553369
dev_label=N_precision_tok: 0.798465829846583
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.6958371315709511
dev_label=P_precision_tok: 0.8986027944111776
dev_label=P_recall_tok: 0.7008094645080947
dev_label=P_f-score_tok: 0.787475948924261
dev_precision_macro_tok: 0.8693141928950731
dev_recall_macro_tok: 0.7639286586364845
dev_f-score_macro_tok: 0.808291798050183
dev_precision_micro_tok: 0.9018520259471655
dev_recall_micro_tok: 0.9018520259471655
dev_f-score_micro_tok: 0.9018520259471655
dev_time: 4.487607717514038
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.1092    0.1730       229
           N     0.6549    0.8248    0.7301       428
           P     0.7151    0.8086    0.7590       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.5956    0.5808    0.5540      1101
weighted avg     0.6296    0.6694    0.6259      1101

F1-macro sent:  0.5540295509410695
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9744    0.9416     16205
           N     0.7985    0.6166    0.6958      1857
           P     0.8986    0.7008    0.7875      3212

   micro avg     0.9019    0.9019    0.9019     21274
   macro avg     0.8693    0.7639    0.8083     21274
weighted avg     0.8992    0.9019    0.8968     21274

F1-macro tok:  0.808291798050183
F1-micro tok:  0.9018520259471655
**************************************************
Best epoch: 24
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 295387.52868652344
train_cost_avg: 34.572510379977
train_count_sent: 8544.0
train_total_correct_sent: 5993.0
train_accuracy_sent: 0.7014279026217228
train_count_tok: 163566.0
train_total_correct_tok: 149204.0
train_accuracy_tok: 0.9121944658425345
train_label=O_precision_sent: 0.4763231197771588
train_label=O_recall_sent: 0.10529556650246305
train_label=O_f-score_sent: 0.17246596066565809
train_label=N_precision_sent: 0.6805049769361495
train_label=N_recall_sent: 0.8468277945619336
train_label=N_f-score_sent: 0.7546103109435993
train_label=P_precision_sent: 0.7424987702902115
train_label=P_recall_sent: 0.8362880886426592
train_label=P_f-score_sent: 0.786607608129234
train_precision_macro_sent: 0.63310895566784
train_recall_macro_sent: 0.596137149902352
train_f-score_macro_sent: 0.5712279599128305
train_precision_micro_sent: 0.7014279026217228
train_recall_micro_sent: 0.7014279026217228
train_f-score_micro_sent: 0.7014279026217228
train_label=O_precision_tok: 0.9248737566947207
train_label=O_recall_tok: 0.9721263882522296
train_label=O_f-score_tok: 0.9479115613984873
train_label=N_precision_tok: 0.8210941350418925
train_label=N_recall_tok: 0.7038445289395859
train_label=N_f-score_tok: 0.7579617834394905
train_label=P_precision_tok: 0.8857046201430504
train_label=P_recall_tok: 0.7325818443458448
train_label=P_f-score_tok: 0.8018989695683563
train_precision_macro_tok: 0.8772241706265546
train_recall_macro_tok: 0.8028509205125535
train_f-score_macro_tok: 0.8359241048021113
train_precision_micro_tok: 0.9121944658425345
train_recall_micro_tok: 0.9121944658425345
train_f-score_micro_tok: 0.9121944658425345
train_time: 94.0630316734314
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4763    0.1053    0.1725      1624
           N     0.6805    0.8468    0.7546      3310
           P     0.7425    0.8363    0.7866      3610

   micro avg     0.7014    0.7014    0.7014      8544
   macro avg     0.6331    0.5961    0.5712      8544
weighted avg     0.6679    0.7014    0.6575      8544

F1-macro sent:  0.5712279599128305
F1-micro sent:  0.7014279026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9249    0.9721    0.9479    124347
           N     0.8211    0.7038    0.7580     14202
           P     0.8857    0.7326    0.8019     25017

   micro avg     0.9122    0.9122    0.9122    163566
   macro avg     0.8772    0.8029    0.8359    163566
weighted avg     0.9099    0.9122    0.9091    163566

F1-macro tok:  0.8359241048021113
F1-micro tok:  0.9121944658425345
**************************************************
dev_cost_sum: 41932.56494140625
dev_cost_avg: 38.08589004669051
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19138.0
dev_accuracy_tok: 0.8995957506815832
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12549019607843137
dev_label=N_precision_sent: 0.6462093862815884
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7291242362525459
dev_label=P_precision_sent: 0.6986564299424184
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7544041450777201
dev_precision_macro_sent: 0.6534168105362074
dev_recall_macro_sent: 0.5753791378612828
dev_f-score_macro_sent: 0.5363395258028991
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9124854819976771
dev_label=O_recall_tok: 0.9696390003085468
dev_label=O_f-score_tok: 0.9401944652206432
dev_label=N_precision_tok: 0.8085409252669039
dev_label=N_recall_tok: 0.6117393645665051
dev_label=N_f-score_tok: 0.6965052115266708
dev_label=P_precision_tok: 0.8640996602491506
dev_label=P_recall_tok: 0.712640099626401
dev_label=P_f-score_tok: 0.7810953762156628
dev_precision_macro_tok: 0.8617086891712438
dev_recall_macro_tok: 0.7646728215004842
dev_f-score_macro_tok: 0.8059316843209922
dev_precision_micro_tok: 0.8995957506815832
dev_recall_micro_tok: 0.8995957506815832
dev_f-score_micro_tok: 0.8995957506815832
dev_time: 4.7904767990112305
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0699    0.1255       229
           N     0.6462    0.8364    0.7291       428
           P     0.6987    0.8198    0.7544       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6534    0.5754    0.5363      1101
weighted avg     0.6609    0.6703    0.6138      1101

F1-macro sent:  0.5363395258028991
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9696    0.9402     16205
           N     0.8085    0.6117    0.6965      1857
           P     0.8641    0.7126    0.7811      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8617    0.7647    0.8059     21274
weighted avg     0.8961    0.8996    0.8949     21274

F1-macro tok:  0.8059316843209922
F1-micro tok:  0.8995957506815832
**************************************************
Best epoch: 24
**************************************************

test0_cost_sum: 42200.50939941406
test0_cost_avg: 38.32925467703366
test0_count_sent: 1101.0
test0_total_correct_sent: 738.0
test0_accuracy_sent: 0.670299727520436
test0_count_tok: 21274.0
test0_total_correct_tok: 19151.0
test0_accuracy_tok: 0.9002068252326784
test0_label=O_precision_sent: 0.7368421052631579
test0_label=O_recall_sent: 0.0611353711790393
test0_label=O_f-score_sent: 0.11290322580645161
test0_label=N_precision_sent: 0.6485507246376812
test0_label=N_recall_sent: 0.8364485981308412
test0_label=N_f-score_sent: 0.7306122448979593
test0_label=P_precision_sent: 0.690566037735849
test0_label=P_recall_sent: 0.8243243243243243
test0_label=P_f-score_sent: 0.7515400410677618
test0_precision_macro_sent: 0.6919862892122294
test0_recall_macro_sent: 0.5739694312114016
test0_f-score_macro_sent: 0.5316851705907243
test0_precision_micro_sent: 0.670299727520436
test0_recall_micro_sent: 0.670299727520436
test0_f-score_micro_sent: 0.670299727520436
test0_label=O_precision_tok: 0.9132584792599918
test0_label=O_recall_tok: 0.9687133600740512
test0_label=O_f-score_tok: 0.9401688926154398
test0_label=N_precision_tok: 0.7833553500660502
test0_label=N_recall_tok: 0.6386645126548196
test0_label=N_f-score_tok: 0.7036487689113022
test0_label=P_precision_tok: 0.881758070789576
test0_label=P_recall_tok: 0.7057907845579079
test0_label=P_f-score_tok: 0.7840221338405672
test0_precision_macro_tok: 0.8594573000385394
test0_recall_macro_tok: 0.771056219095593
test0_f-score_macro_tok: 0.8092799317891032
test0_precision_micro_tok: 0.9002068252326784
test0_recall_micro_tok: 0.9002068252326784
test0_f-score_micro_tok: 0.9002068252326785
test0_time: 4.965256452560425
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7368    0.0611    0.1129       229
           N     0.6486    0.8364    0.7306       428
           P     0.6906    0.8243    0.7515       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6920    0.5740    0.5317      1101
weighted avg     0.6839    0.6703    0.6106      1101

F1-macro sent:  0.5316851705907243
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9133    0.9687    0.9402     16205
           N     0.7834    0.6387    0.7036      1857
           P     0.8818    0.7058    0.7840      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8595    0.7711    0.8093     21274
weighted avg     0.8972    0.9002    0.8959     21274

F1-macro tok:  0.8092799317891032
F1-micro tok:  0.9002068252326785
**************************************************
test1_cost_sum: 81559.87169265747
test1_cost_avg: 36.904919317944554
test1_count_sent: 2210.0
test1_total_correct_sent: 1545.0
test1_accuracy_sent: 0.6990950226244343
test1_count_tok: 42405.0
test1_total_correct_tok: 37925.0
test1_accuracy_tok: 0.8943520811225092
test1_label=O_precision_sent: 0.5526315789473685
test1_label=O_recall_sent: 0.05398457583547558
test1_label=O_f-score_sent: 0.09836065573770493
test1_label=N_precision_sent: 0.684257602862254
test1_label=N_recall_sent: 0.8388157894736842
test1_label=N_f-score_sent: 0.7536945812807881
test1_label=P_precision_sent: 0.7201138519924098
test1_label=P_recall_sent: 0.834983498349835
test1_label=P_f-score_sent: 0.7733061640346408
test1_precision_macro_sent: 0.6523343446006775
test1_recall_macro_sent: 0.5759279545529982
test1_f-score_macro_sent: 0.5417871336843779
test1_precision_micro_sent: 0.6990950226244343
test1_recall_micro_sent: 0.6990950226244343
test1_f-score_micro_sent: 0.6990950226244343
test1_label=O_precision_tok: 0.9046510274171954
test1_label=O_recall_tok: 0.9713732108256766
test1_label=O_f-score_tok: 0.9368256073301585
test1_label=N_precision_tok: 0.7885883905013192
test1_label=N_recall_tok: 0.635904255319149
test1_label=N_f-score_tok: 0.7040636042402827
test1_label=P_precision_tok: 0.8877367896311067
test1_label=P_recall_tok: 0.6697758387242365
test1_label=P_f-score_tok: 0.7635054021608644
test1_precision_macro_tok: 0.8603254025165404
test1_recall_macro_tok: 0.7590177682896874
test1_f-score_macro_tok: 0.8014648712437685
test1_precision_micro_tok: 0.8943520811225092
test1_recall_micro_tok: 0.8943520811225092
test1_f-score_micro_tok: 0.8943520811225092
test1_time: 9.990410566329956
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5526    0.0540    0.0984       389
           N     0.6843    0.8388    0.7537       912
           P     0.7201    0.8350    0.7733       909

   micro avg     0.6991    0.6991    0.6991      2210
   macro avg     0.6523    0.5759    0.5418      2210
weighted avg     0.6758    0.6991    0.6464      2210

F1-macro sent:  0.5417871336843779
F1-micro sent:  0.6990950226244343
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9047    0.9714    0.9368     31998
           N     0.7886    0.6359    0.7041      3760
           P     0.8877    0.6698    0.7635      6647

   micro avg     0.8944    0.8944    0.8944     42405
   macro avg     0.8603    0.7590    0.8015     42405
weighted avg     0.8917    0.8944    0.8890     42405

F1-macro tok:  0.8014648712437685
F1-micro tok:  0.8943520811225092
**************************************************
