to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.5_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.5
sentence_composition: attention
random_seed: 100
{'P': 2, 'O': 0, 'N': 1}
{'P': 2, 'O': 0, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428474.267578125
train_cost_avg: 50.14914180455583
train_count_sent: 8544.0
train_total_correct_sent: 4369.0
train_accuracy_sent: 0.5113529962546817
train_count_tok: 163566.0
train_total_correct_tok: 126024.0
train_accuracy_tok: 0.7704779721947104
train_label=O_precision_sent: 0.22784810126582278
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.07422680412371134
train_label=N_precision_sent: 0.5067801116724275
train_label=N_recall_sent: 0.5758308157099697
train_label=N_f-score_sent: 0.5391033800028283
train_label=P_precision_sent: 0.5352585627938213
train_label=P_recall_sent: 0.6623268698060942
train_label=P_f-score_sent: 0.5920515042713879
train_precision_macro_sent: 0.4232955919106905
train_recall_macro_sent: 0.42749755362850733
train_f-score_macro_sent: 0.40179389613264255
train_precision_micro_sent: 0.5113529962546817
train_recall_micro_sent: 0.5113529962546817
train_f-score_micro_sent: 0.5113529962546817
train_label=O_precision_tok: 0.7946766022462273
train_label=O_recall_tok: 0.9536860559563158
train_label=O_f-score_tok: 0.866950562003107
train_label=N_precision_tok: 0.5016568483063328
train_label=N_recall_tok: 0.19187438388959302
train_label=N_f-score_tok: 0.27757970866863607
train_label=P_precision_tok: 0.5289692342241186
train_label=P_recall_tok: 0.1883119478754447
train_label=P_f-score_tok: 0.2777466615570557
train_precision_macro_tok: 0.6084342282588929
train_recall_macro_tok: 0.4446241292404512
train_f-score_macro_tok: 0.4740923107429329
train_precision_micro_tok: 0.7704779721947104
train_recall_micro_tok: 0.7704779721947104
train_f-score_micro_tok: 0.7704779721947104
train_time: 201.1458282470703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2278    0.0443    0.0742      1624
           N     0.5068    0.5758    0.5391      3310
           P     0.5353    0.6623    0.5921      3610

   micro avg     0.5114    0.5114    0.5114      8544
   macro avg     0.4233    0.4275    0.4018      8544
weighted avg     0.4658    0.5114    0.4731      8544

F1-macro sent:  0.40179389613264255
F1-micro sent:  0.5113529962546817
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7947    0.9537    0.8670    124347
           N     0.5017    0.1919    0.2776     14202
           P     0.5290    0.1883    0.2777     25017

   micro avg     0.7705    0.7705    0.7705    163566
   macro avg     0.6084    0.4446    0.4741    163566
weighted avg     0.7286    0.7705    0.7257    163566

F1-macro tok:  0.4740923107429329
F1-micro tok:  0.7704779721947104
**************************************************
dev_cost_sum: 50799.59423828125
dev_cost_avg: 46.13950430361603
dev_count_sent: 1101.0
dev_total_correct_sent: 598.0
dev_accuracy_sent: 0.5431425976385105
dev_count_tok: 21274.0
dev_total_correct_tok: 17408.0
dev_accuracy_tok: 0.8182758296512175
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6891385767790262
dev_label=N_recall_sent: 0.42990654205607476
dev_label=N_f-score_sent: 0.5294964028776978
dev_label=P_precision_sent: 0.49640287769784175
dev_label=P_recall_sent: 0.9324324324324325
dev_label=P_f-score_sent: 0.647887323943662
dev_precision_macro_sent: 0.3951804848256226
dev_recall_macro_sent: 0.45411299149616907
dev_f-score_macro_sent: 0.3924612422737866
dev_precision_micro_sent: 0.5431425976385105
dev_recall_micro_sent: 0.5431425976385105
dev_f-score_micro_sent: 0.5431425976385105
dev_label=O_precision_tok: 0.838180138065989
dev_label=O_recall_tok: 0.9515581610614008
dev_label=O_f-score_tok: 0.8912779608115138
dev_label=N_precision_tok: 0.7168742921857305
dev_label=N_recall_tok: 0.3408723747980614
dev_label=N_f-score_tok: 0.462043795620438
dev_label=P_precision_tok: 0.6795386158475426
dev_label=P_recall_tok: 0.42185554171855544
dev_label=P_f-score_tok: 0.5205532078371111
dev_precision_macro_tok: 0.744864348699754
dev_recall_macro_tok: 0.5714286925260058
dev_f-score_macro_tok: 0.6246249880896876
dev_precision_micro_tok: 0.8182758296512175
dev_recall_micro_tok: 0.8182758296512175
dev_f-score_micro_tok: 0.8182758296512175
dev_time: 12.341932773590088
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6891    0.4299    0.5295       428
           P     0.4964    0.9324    0.6479       444

   micro avg     0.5431    0.5431    0.5431      1101
   macro avg     0.3952    0.4541    0.3925      1101
weighted avg     0.4681    0.5431    0.4671      1101

F1-macro sent:  0.3924612422737866
F1-micro sent:  0.5431425976385105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8382    0.9516    0.8913     16205
           N     0.7169    0.3409    0.4620      1857
           P     0.6795    0.4219    0.5206      3212

   micro avg     0.8183    0.8183    0.8183     21274
   macro avg     0.7449    0.5714    0.6246     21274
weighted avg     0.8036    0.8183    0.7978     21274

F1-macro tok:  0.6246249880896876
F1-micro tok:  0.8182758296512175
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379974.6403808594
train_cost_avg: 44.47268731049384
train_count_sent: 8544.0
train_total_correct_sent: 4884.0
train_accuracy_sent: 0.5716292134831461
train_count_tok: 163566.0
train_total_correct_tok: 131906.0
train_accuracy_tok: 0.8064389909883473
train_label=O_precision_sent: 0.25806451612903225
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.018979833926453145
train_label=N_precision_sent: 0.545024816828173
train_label=N_recall_sent: 0.6966767371601208
train_label=N_f-score_sent: 0.6115899748044026
train_label=P_precision_sent: 0.602681721947777
train_label=P_recall_sent: 0.7096952908587257
train_label=P_f-score_sent: 0.6518254674977739
train_precision_macro_sent: 0.46859035163499413
train_recall_macro_sent: 0.47207474825587165
train_f-score_macro_sent: 0.4274650920762099
train_precision_micro_sent: 0.5716292134831461
train_recall_micro_sent: 0.5716292134831461
train_f-score_micro_sent: 0.5716292134831461
train_label=O_precision_tok: 0.8267782893041461
train_label=O_recall_tok: 0.9546510973324648
train_label=O_f-score_tok: 0.8861252733963856
train_label=N_precision_tok: 0.6370464672183322
train_label=N_recall_tok: 0.3523447401774398
train_label=N_f-score_tok: 0.45373350863671397
train_label=P_precision_tok: 0.6754038905374217
train_label=P_recall_tok: 0.3275372746532358
train_label=P_f-score_tok: 0.4411424264448572
train_precision_macro_tok: 0.7130762156866334
train_recall_macro_tok: 0.5448443707210467
train_f-score_macro_tok: 0.5936670694926522
train_precision_micro_tok: 0.8064389909883473
train_recall_micro_tok: 0.8064389909883473
train_f-score_micro_tok: 0.8064389909883471
train_time: 198.86868476867676
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2581    0.0099    0.0190      1624
           N     0.5450    0.6967    0.6116      3310
           P     0.6027    0.7097    0.6518      3610

   micro avg     0.5716    0.5716    0.5716      8544
   macro avg     0.4686    0.4721    0.4275      8544
weighted avg     0.5148    0.5716    0.5159      8544

F1-macro sent:  0.4274650920762099
F1-micro sent:  0.5716292134831461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8268    0.9547    0.8861    124347
           N     0.6370    0.3523    0.4537     14202
           P     0.6754    0.3275    0.4411     25017

   micro avg     0.8064    0.8064    0.8064    163566
   macro avg     0.7131    0.5448    0.5937    163566
weighted avg     0.7872    0.8064    0.7805    163566

F1-macro tok:  0.5936670694926522
F1-micro tok:  0.8064389909883471
**************************************************
dev_cost_sum: 49265.63409423828
dev_cost_avg: 44.74626166597482
dev_count_sent: 1101.0
dev_total_correct_sent: 588.0
dev_accuracy_sent: 0.5340599455040872
dev_count_tok: 21274.0
dev_total_correct_tok: 17716.0
dev_accuracy_tok: 0.8327535959387046
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.46420581655480986
dev_label=N_recall_sent: 0.969626168224299
dev_label=N_f-score_sent: 0.6278366111951588
dev_label=P_precision_sent: 0.8357487922705314
dev_label=P_recall_sent: 0.38963963963963966
dev_label=P_f-score_sent: 0.5314900153609831
dev_precision_macro_sent: 0.4333182029417804
dev_recall_macro_sent: 0.45308860262131284
dev_f-score_macro_sent: 0.3864422088520472
dev_precision_micro_sent: 0.5340599455040872
dev_recall_micro_sent: 0.5340599455040872
dev_f-score_micro_sent: 0.5340599455040872
dev_label=O_precision_tok: 0.8395858903890282
dev_label=O_recall_tok: 0.9708731872878741
dev_label=O_f-score_tok: 0.9004693223443223
dev_label=N_precision_tok: 0.7072181670721817
dev_label=N_recall_tok: 0.46957458266020463
dev_label=N_f-score_tok: 0.564401294498382
dev_label=P_precision_tok: 0.8533026113671275
dev_label=P_recall_tok: 0.3458904109589041
dev_label=P_f-score_tok: 0.4922463447053611
dev_precision_macro_tok: 0.8000355562761124
dev_recall_macro_tok: 0.5954460603023276
dev_f-score_macro_tok: 0.6523723205160218
dev_precision_micro_tok: 0.8327535959387046
dev_recall_micro_tok: 0.8327535959387046
dev_f-score_micro_tok: 0.8327535959387045
dev_time: 12.114711284637451
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4642    0.9696    0.6278       428
           P     0.8357    0.3896    0.5315       444

   micro avg     0.5341    0.5341    0.5341      1101
   macro avg     0.4333    0.4531    0.3864      1101
weighted avg     0.5175    0.5341    0.4584      1101

F1-macro sent:  0.3864422088520472
F1-micro sent:  0.5340599455040872
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8396    0.9709    0.9005     16205
           N     0.7072    0.4696    0.5644      1857
           P     0.8533    0.3459    0.4922      3212

   micro avg     0.8328    0.8328    0.8328     21274
   macro avg     0.8000    0.5954    0.6524     21274
weighted avg     0.8301    0.8328    0.8095     21274

F1-macro tok:  0.6523723205160218
F1-micro tok:  0.8327535959387045
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 370069.4428100586
train_cost_avg: 43.31337111540948
train_count_sent: 8544.0
train_total_correct_sent: 5046.0
train_accuracy_sent: 0.5905898876404494
train_count_tok: 163566.0
train_total_correct_tok: 135114.0
train_accuracy_tok: 0.8260518689703239
train_label=O_precision_sent: 0.14285714285714285
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002442002442002442
train_label=N_precision_sent: 0.5528964437486021
train_label=N_recall_sent: 0.7468277945619335
train_label=N_f-score_sent: 0.6353939082380157
train_label=P_precision_sent: 0.6336536092633653
train_label=P_recall_sent: 0.7124653739612188
train_label=P_f-score_sent: 0.6707523797105228
train_precision_macro_sent: 0.44313573195637007
train_recall_macro_sent: 0.4868415652055828
train_f-score_macro_sent: 0.43619609679684695
train_precision_micro_sent: 0.5905898876404494
train_recall_micro_sent: 0.5905898876404494
train_f-score_micro_sent: 0.5905898876404494
train_label=O_precision_tok: 0.8445990110264863
train_label=O_recall_tok: 0.9560262812934771
train_label=O_f-score_tok: 0.8968649447942089
train_label=N_precision_tok: 0.6769302002546591
train_label=N_recall_tok: 0.4117729897197578
train_label=N_f-score_tok: 0.5120616435357471
train_label=P_precision_tok: 0.7327689594356261
train_label=P_recall_tok: 0.41519766558740057
train_label=P_f-score_tok: 0.5300571545213308
train_precision_macro_tok: 0.7514327235722572
train_recall_macro_tok: 0.5943323122002119
train_f-score_macro_tok: 0.6463279142837622
train_precision_micro_tok: 0.8260518689703239
train_recall_micro_tok: 0.8260518689703239
train_f-score_micro_tok: 0.826051868970324
train_time: 198.66314673423767
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1429    0.0012    0.0024      1624
           N     0.5529    0.7468    0.6354      3310
           P     0.6337    0.7125    0.6708      3610

   micro avg     0.5906    0.5906    0.5906      8544
   macro avg     0.4431    0.4868    0.4362      8544
weighted avg     0.5091    0.5906    0.5300      8544

F1-macro sent:  0.43619609679684695
F1-micro sent:  0.5905898876404494
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8446    0.9560    0.8969    124347
           N     0.6769    0.4118    0.5121     14202
           P     0.7328    0.4152    0.5301     25017

   micro avg     0.8261    0.8261    0.8261    163566
   macro avg     0.7514    0.5943    0.6463    163566
weighted avg     0.8129    0.8261    0.8074    163566

F1-macro tok:  0.6463279142837622
F1-micro tok:  0.826051868970324
**************************************************
dev_cost_sum: 48346.53894042969
dev_cost_avg: 43.911479509927055
dev_count_sent: 1101.0
dev_total_correct_sent: 651.0
dev_accuracy_sent: 0.5912806539509536
dev_count_tok: 21274.0
dev_total_correct_tok: 18232.0
dev_accuracy_tok: 0.8570085550437153
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6862745098039216
dev_label=N_recall_sent: 0.572429906542056
dev_label=N_f-score_sent: 0.624203821656051
dev_label=P_precision_sent: 0.5440976933514247
dev_label=P_recall_sent: 0.9031531531531531
dev_label=P_f-score_sent: 0.6790855207451312
dev_precision_macro_sent: 0.6482193058136868
dev_recall_macro_sent: 0.4991390402768601
dev_f-score_macro_sent: 0.44855407458570484
dev_precision_micro_sent: 0.5912806539509536
dev_recall_micro_sent: 0.5912806539509536
dev_f-score_micro_sent: 0.5912806539509536
dev_label=O_precision_tok: 0.8699191524951213
dev_label=O_recall_tok: 0.9627892625732799
dev_label=O_f-score_tok: 0.9140011716461629
dev_label=N_precision_tok: 0.7532833020637899
dev_label=N_recall_tok: 0.4324178782983306
dev_label=N_f-score_tok: 0.5494355114608279
dev_label=P_precision_tok: 0.8037835459744831
dev_label=P_recall_tok: 0.5688044831880449
dev_label=P_f-score_tok: 0.6661804922515954
dev_precision_macro_tok: 0.8089953335111314
dev_recall_macro_tok: 0.6546705413532184
dev_f-score_macro_tok: 0.7098723917861953
dev_precision_micro_tok: 0.8570085550437153
dev_recall_micro_tok: 0.8570085550437153
dev_f-score_micro_tok: 0.8570085550437153
dev_time: 11.963670015335083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6863    0.5724    0.6242       428
           P     0.5441    0.9032    0.6791       444

   micro avg     0.5913    0.5913    0.5913      1101
   macro avg     0.6482    0.4991    0.4486      1101
weighted avg     0.6348    0.5913    0.5253      1101

F1-macro sent:  0.44855407458570484
F1-micro sent:  0.5912806539509536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8699    0.9628    0.9140     16205
           N     0.7533    0.4324    0.5494      1857
           P     0.8038    0.5688    0.6662      3212

   micro avg     0.8570    0.8570    0.8570     21274
   macro avg     0.8090    0.6547    0.7099     21274
weighted avg     0.8498    0.8570    0.8448     21274

F1-macro tok:  0.7098723917861953
F1-micro tok:  0.8570085550437153
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 363140.638671875
train_cost_avg: 42.502415574891735
train_count_sent: 8544.0
train_total_correct_sent: 5172.0
train_accuracy_sent: 0.6053370786516854
train_count_tok: 163566.0
train_total_correct_tok: 137433.0
train_accuracy_tok: 0.8402296320751257
train_label=O_precision_sent: 0.41935483870967744
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.01570996978851964
train_label=N_precision_sent: 0.5724907063197026
train_label=N_recall_sent: 0.7444108761329306
train_label=N_f-score_sent: 0.6472287890727607
train_label=P_precision_sent: 0.6402946067949632
train_label=P_recall_sent: 0.7465373961218836
train_label=P_f-score_sent: 0.6893464637421666
train_precision_macro_sent: 0.544046717274781
train_recall_macro_sent: 0.49965106612106286
train_f-score_macro_sent: 0.4507617408678157
train_precision_micro_sent: 0.6053370786516854
train_recall_micro_sent: 0.6053370786516854
train_f-score_micro_sent: 0.6053370786516854
train_label=O_precision_tok: 0.8572415381072991
train_label=O_recall_tok: 0.9580930782407295
train_label=O_f-score_tok: 0.9048658871424068
train_label=N_precision_tok: 0.6939636040834443
train_label=N_recall_tok: 0.4403605126038586
train_label=N_f-score_tok: 0.5388127853881279
train_label=P_precision_tok: 0.7730774168699448
train_label=P_recall_tok: 0.48139265299596273
train_label=P_f-score_tok: 0.5933243010222934
train_precision_macro_tok: 0.7747608530202293
train_recall_macro_tok: 0.6266154146135169
train_f-score_macro_tok: 0.6790009911842759
train_precision_micro_tok: 0.8402296320751257
train_recall_micro_tok: 0.8402296320751257
train_f-score_micro_tok: 0.8402296320751257
train_time: 160.12415599822998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4194    0.0080    0.0157      1624
           N     0.5725    0.7444    0.6472      3310
           P     0.6403    0.7465    0.6893      3610

   micro avg     0.6053    0.6053    0.6053      8544
   macro avg     0.5440    0.4997    0.4508      8544
weighted avg     0.5720    0.6053    0.5450      8544

F1-macro sent:  0.4507617408678157
F1-micro sent:  0.6053370786516854
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8572    0.9581    0.9049    124347
           N     0.6940    0.4404    0.5388     14202
           P     0.7731    0.4814    0.5933     25017

   micro avg     0.8402    0.8402    0.8402    163566
   macro avg     0.7748    0.6266    0.6790    163566
weighted avg     0.8302    0.8402    0.8254    163566

F1-macro tok:  0.6790009911842759
F1-micro tok:  0.8402296320751257
**************************************************
dev_cost_sum: 47744.705322265625
dev_cost_avg: 43.3648549702685
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18303.0
dev_accuracy_tok: 0.8603459622073893
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6342975206611571
dev_label=N_recall_sent: 0.7172897196261683
dev_label=N_f-score_sent: 0.6732456140350878
dev_label=P_precision_sent: 0.5996758508914101
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.6974552309142319
dev_precision_macro_sent: 0.41132445718418903
dev_recall_macro_sent: 0.5168743509865005
dev_f-score_macro_sent: 0.4569002816497732
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8628017217893532
dev_label=O_recall_tok: 0.9771675408824437
dev_label=O_f-score_tok: 0.9164303489785289
dev_label=N_precision_tok: 0.7929240374609782
dev_label=N_recall_tok: 0.41033925686591277
dev_label=N_f-score_tok: 0.5408090844570618
dev_label=P_precision_tok: 0.8704081632653061
dev_label=P_recall_tok: 0.5311332503113325
dev_label=P_f-score_tok: 0.6597061098221192
dev_precision_macro_tok: 0.8420446408385458
dev_recall_macro_tok: 0.639546682686563
dev_f-score_macro_tok: 0.7056485144192366
dev_precision_micro_tok: 0.8603459622073893
dev_recall_micro_tok: 0.8603459622073893
dev_f-score_micro_tok: 0.8603459622073893
dev_time: 8.193608283996582
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6343    0.7173    0.6732       428
           P     0.5997    0.8333    0.6975       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4113    0.5169    0.4569      1101
weighted avg     0.4884    0.6149    0.5430      1101

F1-macro sent:  0.4569002816497732
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8628    0.9772    0.9164     16205
           N     0.7929    0.4103    0.5408      1857
           P     0.8704    0.5311    0.6597      3212

   micro avg     0.8603    0.8603    0.8603     21274
   macro avg     0.8420    0.6395    0.7056     21274
weighted avg     0.8579    0.8603    0.8449     21274

F1-macro tok:  0.7056485144192366
F1-micro tok:  0.8603459622073893
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 357348.78076171875
train_cost_avg: 41.8245295835345
train_count_sent: 8544.0
train_total_correct_sent: 5265.0
train_accuracy_sent: 0.6162219101123596
train_count_tok: 163566.0
train_total_correct_tok: 139029.0
train_accuracy_tok: 0.8499871611459594
train_label=O_precision_sent: 0.45614035087719296
train_label=O_recall_sent: 0.01600985221674877
train_label=O_f-score_sent: 0.03093396787626413
train_label=N_precision_sent: 0.5795890720252879
train_label=N_recall_sent: 0.7755287009063444
train_label=N_f-score_sent: 0.6633932032562346
train_label=P_precision_sent: 0.6584524396254312
train_label=P_recall_sent: 0.7401662049861496
train_label=P_f-score_sent: 0.696922274387063
train_precision_macro_sent: 0.564727287509304
train_recall_macro_sent: 0.5105682527030809
train_f-score_macro_sent: 0.4637498151731873
train_precision_micro_sent: 0.6162219101123596
train_recall_micro_sent: 0.6162219101123596
train_f-score_micro_sent: 0.6162219101123596
train_label=O_precision_tok: 0.8655193144860456
train_label=O_recall_tok: 0.960947992311837
train_label=O_f-score_tok: 0.9107406899285071
train_label=N_precision_tok: 0.7128087931222113
train_label=N_recall_tok: 0.46120264751443457
train_label=N_f-score_tok: 0.5600444615450387
train_label=P_precision_tok: 0.7958333333333333
train_label=P_recall_tok: 0.5191669664628052
train_label=P_f-score_tok: 0.6283958681084741
train_precision_macro_tok: 0.7913871469805301
train_recall_macro_tok: 0.6471058687630257
train_f-score_macro_tok: 0.6997270065273401
train_precision_micro_tok: 0.8499871611459594
train_recall_micro_tok: 0.8499871611459594
train_f-score_micro_tok: 0.8499871611459593
train_time: 146.1514892578125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4561    0.0160    0.0309      1624
           N     0.5796    0.7755    0.6634      3310
           P     0.6585    0.7402    0.6969      3610

   micro avg     0.6162    0.6162    0.6162      8544
   macro avg     0.5647    0.5106    0.4637      8544
weighted avg     0.5894    0.6162    0.5573      8544

F1-macro sent:  0.4637498151731873
F1-micro sent:  0.6162219101123596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8655    0.9609    0.9107    124347
           N     0.7128    0.4612    0.5600     14202
           P     0.7958    0.5192    0.6284     25017

   micro avg     0.8500    0.8500    0.8500    163566
   macro avg     0.7914    0.6471    0.6997    163566
weighted avg     0.8416    0.8500    0.8371    163566

F1-macro tok:  0.6997270065273401
F1-micro tok:  0.8499871611459593
**************************************************
dev_cost_sum: 46969.327392578125
dev_cost_avg: 42.66060616946242
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18488.0
dev_accuracy_tok: 0.8690420231268214
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.623352165725047
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.6903023983315953
dev_label=P_precision_sent: 0.6298245614035087
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7080867850098619
dev_precision_macro_sent: 0.4177255757095186
dev_recall_macro_sent: 0.527307681513289
dev_f-score_macro_sent: 0.4661297277804857
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8803822372119168
dev_label=O_recall_tok: 0.966491823511262
dev_label=O_f-score_tok: 0.9214296220032359
dev_label=N_precision_tok: 0.7474825716498839
dev_label=N_recall_tok: 0.5196553581044696
dev_label=N_f-score_tok: 0.6130876747141042
dev_label=P_precision_tok: 0.8486092111263109
dev_label=P_recall_tok: 0.5793897882938979
dev_label=P_f-score_tok: 0.6886216466234967
dev_precision_macro_tok: 0.8254913399960372
dev_recall_macro_tok: 0.6885123233032099
dev_f-score_macro_tok: 0.7410463144469457
dev_precision_micro_tok: 0.8690420231268214
dev_recall_micro_tok: 0.8690420231268214
dev_f-score_micro_tok: 0.8690420231268214
dev_time: 8.531163454055786
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6234    0.7734    0.6903       428
           P     0.6298    0.8086    0.7081       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4177    0.5273    0.4661      1101
weighted avg     0.4963    0.6267    0.5539      1101

F1-macro sent:  0.4661297277804857
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9665    0.9214     16205
           N     0.7475    0.5197    0.6131      1857
           P     0.8486    0.5794    0.6886      3212

   micro avg     0.8690    0.8690    0.8690     21274
   macro avg     0.8255    0.6885    0.7410     21274
weighted avg     0.8640    0.8690    0.8594     21274

F1-macro tok:  0.7410463144469457
F1-micro tok:  0.8690420231268214
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 352755.66357421875
train_cost_avg: 41.28694564304995
train_count_sent: 8544.0
train_total_correct_sent: 5281.0
train_accuracy_sent: 0.6180945692883895
train_count_tok: 163566.0
train_total_correct_tok: 140129.0
train_accuracy_tok: 0.8567122751672108
train_label=O_precision_sent: 0.42857142857142855
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.02510460251046025
train_label=N_precision_sent: 0.581901489117984
train_label=N_recall_sent: 0.7673716012084593
train_label=N_f-score_sent: 0.6618892508143323
train_label=P_precision_sent: 0.6585956416464891
train_label=P_recall_sent: 0.7534626038781164
train_label=P_f-score_sent: 0.7028423772609819
train_precision_macro_sent: 0.5563561864453005
train_recall_macro_sent: 0.5112550798564448
train_f-score_macro_sent: 0.46327874352859144
train_precision_micro_sent: 0.6180945692883895
train_recall_micro_sent: 0.6180945692883895
train_f-score_micro_sent: 0.6180945692883895
train_label=O_precision_tok: 0.8708610475048159
train_label=O_recall_tok: 0.9634329738554207
train_label=O_f-score_tok: 0.9148110815846544
train_label=N_precision_tok: 0.7182198952879582
train_label=N_recall_tok: 0.4829601464582453
train_label=N_f-score_tok: 0.5775513640956551
train_label=P_precision_tok: 0.8187952100176281
train_label=P_recall_tok: 0.5384338649718191
train_label=P_f-score_tok: 0.6496575672807947
train_precision_macro_tok: 0.8026253842701342
train_recall_macro_tok: 0.6616089950951617
train_f-score_macro_tok: 0.7140066709870347
train_precision_micro_tok: 0.8567122751672108
train_recall_micro_tok: 0.8567122751672108
train_f-score_micro_tok: 0.8567122751672108
train_time: 145.90994501113892
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0129    0.0251      1624
           N     0.5819    0.7674    0.6619      3310
           P     0.6586    0.7535    0.7028      3610

   micro avg     0.6181    0.6181    0.6181      8544
   macro avg     0.5564    0.5113    0.4633      8544
weighted avg     0.5852    0.6181    0.5582      8544

F1-macro sent:  0.46327874352859144
F1-micro sent:  0.6180945692883895
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8709    0.9634    0.9148    124347
           N     0.7182    0.4830    0.5776     14202
           P     0.8188    0.5384    0.6497     25017

   micro avg     0.8567    0.8567    0.8567    163566
   macro avg     0.8026    0.6616    0.7140    163566
weighted avg     0.8496    0.8567    0.8450    163566

F1-macro tok:  0.7140066709870347
F1-micro tok:  0.8567122751672108
**************************************************
dev_cost_sum: 46499.13952636719
dev_cost_avg: 42.23355088680035
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18581.0
dev_accuracy_tok: 0.8734135564538874
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5753424657534246
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.6967741935483871
dev_label=P_precision_sent: 0.704954954954955
dev_label=P_recall_sent: 0.704954954954955
dev_label=P_f-score_sent: 0.704954954954955
dev_precision_macro_sent: 0.42676580690279325
dev_recall_macro_sent: 0.5293775083494711
dev_f-score_macro_sent: 0.467243049501114
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.878476084538376
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.9240895129442738
dev_label=N_precision_tok: 0.7973684210526316
dev_label=N_recall_tok: 0.4894991922455573
dev_label=N_f-score_tok: 0.6066066066066066
dev_label=P_precision_tok: 0.8714020427112349
dev_label=P_recall_tok: 0.5843711083437111
dev_label=P_f-score_tok: 0.6995900111815131
dev_precision_macro_tok: 0.8490821827674142
dev_recall_macro_tok: 0.682856489171019
dev_f-score_macro_tok: 0.7434287102441312
dev_precision_micro_tok: 0.8734135564538874
dev_recall_micro_tok: 0.8734135564538874
dev_f-score_micro_tok: 0.8734135564538874
dev_time: 8.271013021469116
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5753    0.8832    0.6968       428
           P     0.7050    0.7050    0.7050       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.4268    0.5294    0.4672      1101
weighted avg     0.5079    0.6276    0.5551      1101

F1-macro sent:  0.467243049501114
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8785    0.9747    0.9241     16205
           N     0.7974    0.4895    0.6066      1857
           P     0.8714    0.5844    0.6996      3212

   micro avg     0.8734    0.8734    0.8734     21274
   macro avg     0.8491    0.6829    0.7434     21274
weighted avg     0.8703    0.8734    0.8625     21274

F1-macro tok:  0.7434287102441312
F1-micro tok:  0.8734135564538874
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 348608.79943847656
train_cost_avg: 40.80159169457825
train_count_sent: 8544.0
train_total_correct_sent: 5302.0
train_accuracy_sent: 0.6205524344569289
train_count_tok: 163566.0
train_total_correct_tok: 140953.0
train_accuracy_tok: 0.86174999694313
train_label=O_precision_sent: 0.41237113402061853
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.046484601975595584
train_label=N_precision_sent: 0.6025609455799065
train_label=N_recall_sent: 0.739274924471299
train_label=N_f-score_sent: 0.6639533306199974
train_label=P_precision_sent: 0.6418148654810761
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7041020510255127
train_precision_macro_sent: 0.552248981693867
train_recall_macro_sent: 0.5145612865650069
train_f-score_macro_sent: 0.47151332787370187
train_precision_micro_sent: 0.6205524344569289
train_recall_micro_sent: 0.6205524344569289
train_f-score_micro_sent: 0.6205524344569289
train_label=O_precision_tok: 0.8751778327387336
train_label=O_recall_tok: 0.9647036116673502
train_label=O_f-score_tok: 0.9177626293924579
train_label=N_precision_tok: 0.7331091409354937
train_label=N_recall_tok: 0.5065483734685255
train_label=N_f-score_tok: 0.5991255465334167
train_label=P_precision_tok: 0.827100563346518
train_label=P_recall_tok: 0.5516648678898349
train_label=P_f-score_tok: 0.6618708486200034
train_precision_macro_tok: 0.8117958456735819
train_recall_macro_tok: 0.6743056176752368
train_f-score_macro_tok: 0.7262530081819594
train_precision_micro_tok: 0.86174999694313
train_recall_micro_tok: 0.86174999694313
train_f-score_micro_tok: 0.86174999694313
train_time: 146.01872324943542
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4124    0.0246    0.0465      1624
           N     0.6026    0.7393    0.6640      3310
           P     0.6418    0.7798    0.7041      3610

   micro avg     0.6206    0.6206    0.6206      8544
   macro avg     0.5522    0.5146    0.4715      8544
weighted avg     0.5830    0.6206    0.5636      8544

F1-macro sent:  0.47151332787370187
F1-micro sent:  0.6205524344569289
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8752    0.9647    0.9178    124347
           N     0.7331    0.5065    0.5991     14202
           P     0.8271    0.5517    0.6619     25017

   micro avg     0.8617    0.8617    0.8617    163566
   macro avg     0.8118    0.6743    0.7263    163566
weighted avg     0.8555    0.8617    0.8510    163566

F1-macro tok:  0.7262530081819594
F1-micro tok:  0.86174999694313
**************************************************
dev_cost_sum: 46193.098388671875
dev_cost_avg: 41.955584367549385
dev_count_sent: 1101.0
dev_total_correct_sent: 675.0
dev_accuracy_sent: 0.6130790190735694
dev_count_tok: 21274.0
dev_total_correct_tok: 18673.0
dev_accuracy_tok: 0.8777380840462536
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6917098445595855
dev_label=N_recall_sent: 0.6238317757009346
dev_label=N_f-score_sent: 0.6560196560196561
dev_label=P_precision_sent: 0.5706293706293706
dev_label=P_recall_sent: 0.918918918918919
dev_label=P_f-score_sent: 0.7040552200172563
dev_precision_macro_sent: 0.4207797383963187
dev_recall_macro_sent: 0.5142502315399512
dev_f-score_macro_sent: 0.4533582920123041
dev_precision_micro_sent: 0.6130790190735694
dev_recall_micro_sent: 0.6130790190735694
dev_f-score_micro_sent: 0.6130790190735694
dev_label=O_precision_tok: 0.8800221975582686
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.9266910153396639
dev_label=N_precision_tok: 0.8311195445920304
dev_label=N_recall_tok: 0.4717285945072698
dev_label=N_f-score_tok: 0.6018550326348334
dev_label=P_precision_tok: 0.8813636363636363
dev_label=P_recall_tok: 0.6036737235367372
dev_label=P_f-score_tok: 0.7165558019216555
dev_precision_macro_tok: 0.8641684595046452
dev_recall_macro_tok: 0.6846630579842258
dev_f-score_macro_tok: 0.7483672832987175
dev_precision_micro_tok: 0.8777380840462536
dev_recall_micro_tok: 0.8777380840462536
dev_f-score_micro_tok: 0.8777380840462536
dev_time: 8.230200290679932
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6917    0.6238    0.6560       428
           P     0.5706    0.9189    0.7041       444

   micro avg     0.6131    0.6131    0.6131      1101
   macro avg     0.4208    0.5143    0.4534      1101
weighted avg     0.4990    0.6131    0.5389      1101

F1-macro sent:  0.4533582920123041
F1-micro sent:  0.6130790190735694
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8800    0.9786    0.9267     16205
           N     0.8311    0.4717    0.6019      1857
           P     0.8814    0.6037    0.7166      3212

   micro avg     0.8777    0.8777    0.8777     21274
   macro avg     0.8642    0.6847    0.7484     21274
weighted avg     0.8760    0.8777    0.8666     21274

F1-macro tok:  0.7483672832987175
F1-micro tok:  0.8777380840462536
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 344687.6715698242
train_cost_avg: 40.342658189352086
train_count_sent: 8544.0
train_total_correct_sent: 5459.0
train_accuracy_sent: 0.6389279026217228
train_count_tok: 163566.0
train_total_correct_tok: 141641.0
train_accuracy_tok: 0.8659562500764217
train_label=O_precision_sent: 0.5223880597014925
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.04139562389118865
train_label=N_precision_sent: 0.6037391700866394
train_label=N_recall_sent: 0.8
train_label=N_f-score_sent: 0.6881496881496882
train_label=P_precision_sent: 0.6785626986066976
train_label=P_recall_sent: 0.7689750692520776
train_label=P_f-score_sent: 0.720945331775094
train_precision_macro_sent: 0.6015633094649432
train_recall_macro_sent: 0.5301755977966696
train_f-score_macro_sent: 0.48349688127199036
train_precision_micro_sent: 0.6389279026217228
train_recall_micro_sent: 0.6389279026217228
train_f-score_micro_sent: 0.6389279026217228
train_label=O_precision_tok: 0.878473516832986
train_label=O_recall_tok: 0.9663441820068035
train_label=O_f-score_tok: 0.9203161619410872
train_label=N_precision_tok: 0.7392821535393819
train_label=N_recall_tok: 0.5221095620335164
train_label=N_f-score_tok: 0.612000660283922
train_label=P_precision_tok: 0.8395916661691839
train_label=P_recall_tok: 0.5621777191509774
train_label=P_f-score_tok: 0.6734342080061291
train_precision_macro_tok: 0.819115778847184
train_recall_macro_tok: 0.6835438210637657
train_f-score_macro_tok: 0.7352503434103794
train_precision_micro_tok: 0.8659562500764217
train_recall_micro_tok: 0.8659562500764217
train_f-score_micro_tok: 0.8659562500764216
train_time: 145.898291349411
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5224    0.0216    0.0414      1624
           N     0.6037    0.8000    0.6881      3310
           P     0.6786    0.7690    0.7209      3610

   micro avg     0.6389    0.6389    0.6389      8544
   macro avg     0.6016    0.5302    0.4835      8544
weighted avg     0.6199    0.6389    0.5791      8544

F1-macro sent:  0.48349688127199036
F1-micro sent:  0.6389279026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8785    0.9663    0.9203    124347
           N     0.7393    0.5221    0.6120     14202
           P     0.8396    0.5622    0.6734     25017

   micro avg     0.8660    0.8660    0.8660    163566
   macro avg     0.8191    0.6835    0.7353    163566
weighted avg     0.8604    0.8660    0.8558    163566

F1-macro tok:  0.7352503434103794
F1-micro tok:  0.8659562500764216
**************************************************
dev_cost_sum: 45622.36096191406
dev_cost_avg: 41.43720341681568
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18776.0
dev_accuracy_tok: 0.8825796747203158
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5634807417974322
dev_label=N_recall_sent: 0.9228971962616822
dev_label=N_f-score_sent: 0.6997342781222321
dev_label=P_precision_sent: 0.7455919395465995
dev_label=P_recall_sent: 0.6666666666666666
dev_label=P_f-score_sent: 0.703923900118906
dev_precision_macro_sent: 0.6585797826702328
dev_recall_macro_sent: 0.5327658291274991
dev_f-score_macro_sent: 0.47363318585049435
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8922030053870145
dev_label=O_recall_tok: 0.9709348966368405
dev_label=O_f-score_tok: 0.9299054373522458
dev_label=N_precision_tok: 0.7557142857142857
dev_label=N_recall_tok: 0.5697361335487345
dev_label=N_f-score_tok: 0.6496776174393614
dev_label=P_precision_tok: 0.8861098704778919
dev_label=P_recall_tok: 0.6176836861768369
dev_label=P_f-score_tok: 0.7279398275545771
dev_precision_macro_tok: 0.8446757205263973
dev_recall_macro_tok: 0.719451572120804
dev_f-score_macro_tok: 0.7691742941153947
dev_precision_micro_tok: 0.8825796747203158
dev_recall_micro_tok: 0.8825796747203158
dev_f-score_micro_tok: 0.8825796747203158
dev_time: 8.361819744110107
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5635    0.9229    0.6997       428
           P     0.7456    0.6667    0.7039       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.6586    0.5328    0.4736      1101
weighted avg     0.6584    0.6294    0.5595      1101

F1-macro sent:  0.47363318585049435
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8922    0.9709    0.9299     16205
           N     0.7557    0.5697    0.6497      1857
           P     0.8861    0.6177    0.7279      3212

   micro avg     0.8826    0.8826    0.8826     21274
   macro avg     0.8447    0.7195    0.7692     21274
weighted avg     0.8794    0.8826    0.8750     21274

F1-macro tok:  0.7691742941153947
F1-micro tok:  0.8825796747203158
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 341181.2409057617
train_cost_avg: 39.932261341966495
train_count_sent: 8544.0
train_total_correct_sent: 5428.0
train_accuracy_sent: 0.6352996254681648
train_count_tok: 163566.0
train_total_correct_tok: 142211.0
train_accuracy_tok: 0.8694410818874339
train_label=O_precision_sent: 0.4594594594594595
train_label=O_recall_sent: 0.020935960591133004
train_label=O_f-score_sent: 0.04004711425206125
train_label=N_precision_sent: 0.5967078189300411
train_label=N_recall_sent: 0.7885196374622356
train_label=N_f-score_sent: 0.6793336803748047
train_label=P_precision_sent: 0.6796875
train_label=P_recall_sent: 0.771191135734072
train_label=P_f-score_sent: 0.7225538541396315
train_precision_macro_sent: 0.5786182594631669
train_recall_macro_sent: 0.5268822445958136
train_f-score_macro_sent: 0.48064488292216573
train_precision_micro_sent: 0.6352996254681648
train_recall_micro_sent: 0.6352996254681648
train_f-score_micro_sent: 0.6352996254681648
train_label=O_precision_tok: 0.8812772005920021
train_label=O_recall_tok: 0.9673092233829526
train_label=O_f-score_tok: 0.9222912744936415
train_label=N_precision_tok: 0.7471783295711061
train_label=N_recall_tok: 0.5360512603858612
train_label=N_f-score_tok: 0.624246648353901
train_label=P_precision_tok: 0.8475519507429993
train_label=P_recall_tok: 0.572250869408802
train_label=P_f-score_tok: 0.683210842798511
train_precision_macro_tok: 0.8253358269687024
train_recall_macro_tok: 0.6918704510592052
train_f-score_macro_tok: 0.7432495885486845
train_precision_micro_tok: 0.8694410818874339
train_recall_micro_tok: 0.8694410818874339
train_f-score_micro_tok: 0.8694410818874337
train_time: 146.7581045627594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4595    0.0209    0.0400      1624
           N     0.5967    0.7885    0.6793      3310
           P     0.6797    0.7712    0.7226      3610

   micro avg     0.6353    0.6353    0.6353      8544
   macro avg     0.5786    0.5269    0.4806      8544
weighted avg     0.6057    0.6353    0.5761      8544

F1-macro sent:  0.48064488292216573
F1-micro sent:  0.6352996254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8813    0.9673    0.9223    124347
           N     0.7472    0.5361    0.6242     14202
           P     0.8476    0.5723    0.6832     25017

   micro avg     0.8694    0.8694    0.8694    163566
   macro avg     0.8253    0.6919    0.7432    163566
weighted avg     0.8645    0.8694    0.8598    163566

F1-macro tok:  0.7432495885486845
F1-micro tok:  0.8694410818874337
**************************************************
dev_cost_sum: 45306.76525878906
dev_cost_avg: 41.15055881815537
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18802.0
dev_accuracy_tok: 0.8838018238225064
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6374045801526718
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7016806722689076
dev_label=P_precision_sent: 0.6404886561954625
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7217305801376598
dev_precision_macro_sent: 0.6759644121160447
dev_recall_macro_sent: 0.5400169483445001
dev_f-score_macro_sent: 0.4830541084559803
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8873341915262775
dev_label=O_recall_tok: 0.9783400185128047
dev_label=O_f-score_tok: 0.9306175158487907
dev_label=N_precision_tok: 0.7865519937451134
dev_label=N_recall_tok: 0.5417339795368874
dev_label=N_f-score_tok: 0.6415816326530612
dev_label=P_precision_tok: 0.9125939849624061
dev_label=P_recall_tok: 0.6046077210460772
dev_label=P_f-score_tok: 0.7273408239700374
dev_precision_macro_tok: 0.862160056744599
dev_recall_macro_tok: 0.7082272396985898
dev_f-score_macro_tok: 0.7665133241572964
dev_precision_micro_tok: 0.8838018238225064
dev_recall_micro_tok: 0.8838018238225064
dev_f-score_micro_tok: 0.8838018238225064
dev_time: 7.991017818450928
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6374    0.7804    0.7017       428
           P     0.6405    0.8266    0.7217       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6760    0.5400    0.4831      1101
weighted avg     0.6621    0.6394    0.5692      1101

F1-macro sent:  0.4830541084559803
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8873    0.9783    0.9306     16205
           N     0.7866    0.5417    0.6416      1857
           P     0.9126    0.6046    0.7273      3212

   micro avg     0.8838    0.8838    0.8838     21274
   macro avg     0.8622    0.7082    0.7665     21274
weighted avg     0.8824    0.8838    0.8747     21274

F1-macro tok:  0.7665133241572964
F1-micro tok:  0.8838018238225064
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 337968.79803466797
train_cost_avg: 39.55627317821489
train_count_sent: 8544.0
train_total_correct_sent: 5448.0
train_accuracy_sent: 0.6376404494382022
train_count_tok: 163566.0
train_total_correct_tok: 142673.0
train_accuracy_tok: 0.8722656297763594
train_label=O_precision_sent: 0.3987341772151899
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07070707070707072
train_label=N_precision_sent: 0.6064880112834978
train_label=N_recall_sent: 0.7794561933534743
train_label=N_f-score_sent: 0.6821787414066631
train_label=P_precision_sent: 0.6788480154888674
train_label=P_recall_sent: 0.7770083102493075
train_label=P_f-score_sent: 0.7246189615086541
train_precision_macro_sent: 0.5613567346625183
train_recall_macro_sent: 0.5317525356836859
train_f-score_macro_sent: 0.4925015912074627
train_precision_micro_sent: 0.6376404494382022
train_recall_micro_sent: 0.6376404494382022
train_f-score_micro_sent: 0.6376404494382022
train_label=O_precision_tok: 0.8835229357798166
train_label=O_recall_tok: 0.9680973405068075
train_label=O_f-score_tok: 0.9238786325245494
train_label=N_precision_tok: 0.7530947775628627
train_label=N_recall_tok: 0.5483030559076186
train_label=N_f-score_tok: 0.6345856083448782
train_label=P_precision_tok: 0.8545004712535345
train_label=P_recall_tok: 0.5798457049206539
train_label=P_f-score_tok: 0.690877050937061
train_precision_macro_tok: 0.830372728198738
train_recall_macro_tok: 0.6987487004450267
train_f-score_macro_tok: 0.7497804306021628
train_precision_micro_tok: 0.8722656297763594
train_recall_micro_tok: 0.8722656297763594
train_f-score_micro_tok: 0.8722656297763592
train_time: 146.52933073043823
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3987    0.0388    0.0707      1624
           N     0.6065    0.7795    0.6822      3310
           P     0.6788    0.7770    0.7246      3610

   micro avg     0.6376    0.6376    0.6376      8544
   macro avg     0.5614    0.5318    0.4925      8544
weighted avg     0.5976    0.6376    0.5839      8544

F1-macro sent:  0.4925015912074627
F1-micro sent:  0.6376404494382022
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8835    0.9681    0.9239    124347
           N     0.7531    0.5483    0.6346     14202
           P     0.8545    0.5798    0.6909     25017

   micro avg     0.8723    0.8723    0.8723    163566
   macro avg     0.8304    0.6987    0.7498    163566
weighted avg     0.8678    0.8723    0.8631    163566

F1-macro tok:  0.7497804306021628
F1-micro tok:  0.8722656297763592
**************************************************
dev_cost_sum: 45098.34405517578
dev_cost_avg: 40.96125708916965
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18746.0
dev_accuracy_tok: 0.8811695026793269
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6329588014981273
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7027027027027027
dev_label=P_precision_sent: 0.6494661921708185
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7256461232604374
dev_precision_macro_sent: 0.6274749978896487
dev_recall_macro_sent: 0.5416307116405065
dev_f-score_macro_sent: 0.4846632838680553
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8785242290748899
dev_label=O_recall_tok: 0.9845109534094415
dev_label=O_f-score_tok: 0.9285028371890004
dev_label=N_precision_tok: 0.8161634103019538
dev_label=N_recall_tok: 0.49488422186322023
dev_label=N_f-score_tok: 0.616158229969829
dev_label=P_precision_tok: 0.9421529175050302
dev_label=P_recall_tok: 0.5831257783312578
dev_label=P_f-score_tok: 0.7203846153846154
dev_precision_macro_tok: 0.878946852293958
dev_recall_macro_tok: 0.6875069845346399
dev_f-score_macro_tok: 0.7550152275144816
dev_precision_micro_tok: 0.8811695026793269
dev_recall_micro_tok: 0.8811695026793269
dev_f-score_micro_tok: 0.8811695026793269
dev_time: 7.8411595821380615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6330    0.7897    0.7027       428
           P     0.6495    0.8221    0.7256       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.6275    0.5416    0.4847      1101
weighted avg     0.6328    0.6412    0.5711      1101

F1-macro sent:  0.4846632838680553
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8785    0.9845    0.9285     16205
           N     0.8162    0.4949    0.6162      1857
           P     0.9422    0.5831    0.7204      3212

   micro avg     0.8812    0.8812    0.8812     21274
   macro avg     0.8789    0.6875    0.7550     21274
weighted avg     0.8827    0.8812    0.8698     21274

F1-macro tok:  0.7550152275144816
F1-micro tok:  0.8811695026793269
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 335223.03857421875
train_cost_avg: 39.23490620016605
train_count_sent: 8544.0
train_total_correct_sent: 5491.0
train_accuracy_sent: 0.6426732209737828
train_count_tok: 163566.0
train_total_correct_tok: 143212.0
train_accuracy_tok: 0.8755609356467725
train_label=O_precision_sent: 0.47368421052631576
train_label=O_recall_sent: 0.0332512315270936
train_label=O_f-score_sent: 0.0621403912543153
train_label=N_precision_sent: 0.6151471984805318
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.688912523265089
train_label=P_precision_sent: 0.6747273589378853
train_label=P_recall_sent: 0.788365650969529
train_label=P_f-score_sent: 0.7271333673990803
train_precision_macro_sent: 0.5878529226482443
train_recall_macro_sent: 0.5347987795633253
train_f-score_macro_sent: 0.49272876063949483
train_precision_micro_sent: 0.6426732209737828
train_recall_micro_sent: 0.6426732209737828
train_f-score_micro_sent: 0.6426732209737828
train_label=O_precision_tok: 0.886441550798205
train_label=O_recall_tok: 0.9690141298141491
train_label=O_f-score_tok: 0.9258904935895219
train_label=N_precision_tok: 0.7588876146788991
train_label=N_recall_tok: 0.5591465990705534
train_label=N_f-score_tok: 0.6438822670882997
train_label=P_precision_tok: 0.8605287677614721
train_label=P_recall_tok: 0.5906783387296638
train_label=P_f-score_tok: 0.7005143520822963
train_precision_macro_tok: 0.835285977746192
train_recall_macro_tok: 0.7062796892047888
train_f-score_macro_tok: 0.7567623709200393
train_precision_micro_tok: 0.8755609356467725
train_recall_micro_tok: 0.8755609356467725
train_f-score_micro_tok: 0.8755609356467724
train_time: 147.20014095306396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4737    0.0333    0.0621      1624
           N     0.6151    0.7828    0.6889      3310
           P     0.6747    0.7884    0.7271      3610

   micro avg     0.6427    0.6427    0.6427      8544
   macro avg     0.5879    0.5348    0.4927      8544
weighted avg     0.6134    0.6427    0.5859      8544

F1-macro sent:  0.49272876063949483
F1-micro sent:  0.6426732209737828
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8864    0.9690    0.9259    124347
           N     0.7589    0.5591    0.6439     14202
           P     0.8605    0.5907    0.7005     25017

   micro avg     0.8756    0.8756    0.8756    163566
   macro avg     0.8353    0.7063    0.7568    163566
weighted avg     0.8714    0.8756    0.8669    163566

F1-macro tok:  0.7567623709200393
F1-micro tok:  0.8755609356467724
**************************************************
dev_cost_sum: 44597.004150390625
dev_cost_avg: 40.5059074935428
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 18910.0
dev_accuracy_tok: 0.8888784431700667
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07468879668049792
dev_label=N_precision_sent: 0.6093489148580968
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7108081791626095
dev_label=P_precision_sent: 0.6877551020408164
dev_label=P_recall_sent: 0.759009009009009
dev_label=P_f-score_sent: 0.7216274089935761
dev_precision_macro_sent: 0.6823680056329712
dev_recall_macro_sent: 0.5503713524568113
dev_f-score_macro_sent: 0.5023747949455611
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.8959006633781256
dev_label=O_recall_tok: 0.9750694230175871
dev_label=O_f-score_tok: 0.9338100585071805
dev_label=N_precision_tok: 0.779145546705286
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6646077825818405
dev_label=P_precision_tok: 0.9011524822695035
dev_label=P_recall_tok: 0.6329389788293898
dev_label=P_f-score_tok: 0.7435991221653254
dev_precision_macro_tok: 0.8587328974509717
dev_recall_macro_tok: 0.7291458629025015
dev_f-score_macro_tok: 0.7806723210847822
dev_precision_micro_tok: 0.8888784431700667
dev_recall_micro_tok: 0.8888784431700667
dev_f-score_micro_tok: 0.8888784431700667
dev_time: 7.537001848220825
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0393    0.0747       229
           N     0.6093    0.8528    0.7108       428
           P     0.6878    0.7590    0.7216       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.6824    0.5504    0.5024      1101
weighted avg     0.6702    0.6458    0.5829      1101

F1-macro sent:  0.5023747949455611
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9751    0.9338     16205
           N     0.7791    0.5794    0.6646      1857
           P     0.9012    0.6329    0.7436      3212

   micro avg     0.8889    0.8889    0.8889     21274
   macro avg     0.8587    0.7291    0.7807     21274
weighted avg     0.8865    0.8889    0.8816     21274

F1-macro tok:  0.7806723210847822
F1-micro tok:  0.8888784431700667
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 332468.0207519531
train_cost_avg: 38.912455612354066
train_count_sent: 8544.0
train_total_correct_sent: 5489.0
train_accuracy_sent: 0.642439138576779
train_count_tok: 163566.0
train_total_correct_tok: 143562.0
train_accuracy_tok: 0.8777007446535343
train_label=O_precision_sent: 0.4397163120567376
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.07025495750708216
train_label=N_precision_sent: 0.6110588235294118
train_label=N_recall_sent: 0.7845921450151058
train_label=N_f-score_sent: 0.6870370370370371
train_label=P_precision_sent: 0.6814351071514568
train_label=P_recall_sent: 0.7839335180055401
train_label=P_f-score_sent: 0.7290995749066083
train_precision_macro_sent: 0.5774034142458687
train_recall_macro_sent: 0.535567667640708
train_f-score_macro_sent: 0.4954638564835758
train_precision_micro_sent: 0.642439138576779
train_recall_micro_sent: 0.642439138576779
train_f-score_micro_sent: 0.642439138576779
train_label=O_precision_tok: 0.8886849070653897
train_label=O_recall_tok: 0.9693438522843334
train_label=O_f-score_tok: 0.9272636356642819
train_label=N_precision_tok: 0.7646722015459491
train_label=N_recall_tok: 0.5642163075623151
train_label=N_f-score_tok: 0.6493253920019448
train_label=P_precision_tok: 0.8602039647072305
train_label=P_recall_tok: 0.600151896710237
train_label=P_f-score_tok: 0.7070236161145254
train_precision_macro_tok: 0.8378536911061897
train_recall_macro_tok: 0.7112373521856284
train_f-score_macro_tok: 0.761204214593584
train_precision_micro_tok: 0.8777007446535343
train_recall_micro_tok: 0.8777007446535343
train_f-score_micro_tok: 0.8777007446535344
train_time: 147.55671954154968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4397    0.0382    0.0703      1624
           N     0.6111    0.7846    0.6870      3310
           P     0.6814    0.7839    0.7291      3610

   micro avg     0.6424    0.6424    0.6424      8544
   macro avg     0.5774    0.5356    0.4955      8544
weighted avg     0.6082    0.6424    0.5876      8544

F1-macro sent:  0.4954638564835758
F1-micro sent:  0.642439138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8887    0.9693    0.9273    124347
           N     0.7647    0.5642    0.6493     14202
           P     0.8602    0.6002    0.7070     25017

   micro avg     0.8777    0.8777    0.8777    163566
   macro avg     0.8379    0.7112    0.7612    163566
weighted avg     0.8736    0.8777    0.8694    163566

F1-macro tok:  0.761204214593584
F1-micro tok:  0.8777007446535344
**************************************************
dev_cost_sum: 44354.11486816406
dev_cost_avg: 40.28529960777844
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18939.0
dev_accuracy_tok: 0.8902416094763561
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5965189873417721
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7113207547169811
dev_label=P_precision_sent: 0.702355460385439
dev_label=P_recall_sent: 0.7387387387387387
dev_label=P_f-score_sent: 0.7200878155872668
dev_precision_macro_sent: 0.766291482575737
dev_recall_macro_sent: 0.5427711615627381
dev_f-score_macro_sent: 0.48290819587342176
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8934278640558181
dev_label=O_recall_tok: 0.9798210428879975
dev_label=O_f-score_tok: 0.9346322512287724
dev_label=N_precision_tok: 0.7815845824411135
dev_label=N_recall_tok: 0.5896607431340872
dev_label=N_f-score_tok: 0.6721915285451198
dev_label=P_precision_tok: 0.9357448833888624
dev_label=P_recall_tok: 0.612079701120797
dev_label=P_f-score_tok: 0.7400715226802183
dev_precision_macro_tok: 0.8702524432952646
dev_recall_macro_tok: 0.7271871623809606
dev_f-score_macro_tok: 0.78229843415137
dev_precision_micro_tok: 0.8902416094763561
dev_recall_micro_tok: 0.8902416094763561
dev_f-score_micro_tok: 0.8902416094763561
dev_time: 7.374830007553101
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5965    0.8808    0.7113       428
           P     0.7024    0.7387    0.7201       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7663    0.5428    0.4829      1101
weighted avg     0.7231    0.6421    0.5705      1101

F1-macro sent:  0.48290819587342176
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9798    0.9346     16205
           N     0.7816    0.5897    0.6722      1857
           P     0.9357    0.6121    0.7401      3212

   micro avg     0.8902    0.8902    0.8902     21274
   macro avg     0.8703    0.7272    0.7823     21274
weighted avg     0.8901    0.8902    0.8823     21274

F1-macro tok:  0.78229843415137
F1-micro tok:  0.8902416094763561
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 330177.2814941406
train_cost_avg: 38.6443447441644
train_count_sent: 8544.0
train_total_correct_sent: 5566.0
train_accuracy_sent: 0.6514513108614233
train_count_tok: 163566.0
train_total_correct_tok: 143845.0
train_accuracy_tok: 0.8794309330790018
train_label=O_precision_sent: 0.4954128440366973
train_label=O_recall_sent: 0.0332512315270936
train_label=O_f-score_sent: 0.0623196768609348
train_label=N_precision_sent: 0.6234817813765182
train_label=N_recall_sent: 0.7909365558912387
train_label=N_f-score_sent: 0.6972965774404049
train_label=P_precision_sent: 0.6831916902738433
train_label=P_recall_sent: 0.8016620498614958
train_label=P_f-score_sent: 0.737700739230181
train_precision_macro_sent: 0.600695438562353
train_recall_macro_sent: 0.5419499457599427
train_f-score_macro_sent: 0.4991056645105069
train_precision_micro_sent: 0.6514513108614233
train_recall_micro_sent: 0.6514513108614233
train_f-score_micro_sent: 0.6514513108614233
train_label=O_precision_tok: 0.8901972654519682
train_label=O_recall_tok: 0.9696977007889214
train_label=O_f-score_tok: 0.9282483766296252
train_label=N_precision_tok: 0.7669539153240914
train_label=N_recall_tok: 0.5765385157020138
train_label=N_f-score_tok: 0.6582522710828844
train_label=P_precision_tok: 0.8646633788278473
train_label=P_recall_tok: 0.6027101570931767
train_label=P_f-score_tok: 0.7103050288540809
train_precision_macro_tok: 0.8406048532013024
train_recall_macro_tok: 0.7163154578613705
train_f-score_macro_tok: 0.7656018921888634
train_precision_micro_tok: 0.8794309330790018
train_recall_micro_tok: 0.8794309330790018
train_f-score_micro_tok: 0.8794309330790018
train_time: 147.6791477203369
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4954    0.0333    0.0623      1624
           N     0.6235    0.7909    0.6973      3310
           P     0.6832    0.8017    0.7377      3610

   micro avg     0.6515    0.6515    0.6515      8544
   macro avg     0.6007    0.5419    0.4991      8544
weighted avg     0.6244    0.6515    0.5937      8544

F1-macro sent:  0.4991056645105069
F1-micro sent:  0.6514513108614233
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8902    0.9697    0.9282    124347
           N     0.7670    0.5765    0.6583     14202
           P     0.8647    0.6027    0.7103     25017

   micro avg     0.8794    0.8794    0.8794    163566
   macro avg     0.8406    0.7163    0.7656    163566
weighted avg     0.8756    0.8794    0.8715    163566

F1-macro tok:  0.7656018921888634
F1-micro tok:  0.8794309330790018
**************************************************
dev_cost_sum: 44143.23547363281
dev_cost_avg: 40.09376518949393
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18952.0
dev_accuracy_tok: 0.8908526840274513
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.5917065390749602
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7033175355450237
dev_label=P_precision_sent: 0.7002141327623126
dev_label=P_recall_sent: 0.7364864864864865
dev_label=P_f-score_sent: 0.7178924259055983
dev_precision_macro_sent: 0.7163545096600433
dev_recall_macro_sent: 0.5431699299184913
dev_f-score_macro_sent: 0.4906858063592469
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8969721025175776
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.9349014509027511
dev_label=N_precision_tok: 0.8079315707620529
dev_label=N_recall_tok: 0.559504577275175
dev_label=N_f-score_tok: 0.661151765828826
dev_label=P_precision_tok: 0.8903061224489796
dev_label=P_recall_tok: 0.6519302615193027
dev_label=P_f-score_tok: 0.7526959022286125
dev_precision_macro_tok: 0.8650699319095367
dev_recall_macro_tok: 0.7292050100311531
dev_f-score_macro_tok: 0.7829163729867298
dev_precision_micro_tok: 0.8908526840274513
dev_recall_micro_tok: 0.8908526840274513
dev_f-score_micro_tok: 0.8908526840274513
dev_time: 7.44277286529541
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.5917    0.8668    0.7033       428
           P     0.7002    0.7365    0.7179       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7164    0.5432    0.4907      1101
weighted avg     0.6907    0.6394    0.5735      1101

F1-macro sent:  0.4906858063592469
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9762    0.9349     16205
           N     0.8079    0.5595    0.6612      1857
           P     0.8903    0.6519    0.7527      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8651    0.7292    0.7829     21274
weighted avg     0.8882    0.8909    0.8835     21274

F1-macro tok:  0.7829163729867298
F1-micro tok:  0.8908526840274513
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 327464.14111328125
train_cost_avg: 38.32679554228479
train_count_sent: 8544.0
train_total_correct_sent: 5599.0
train_accuracy_sent: 0.6553136704119851
train_count_tok: 163566.0
train_total_correct_tok: 144464.0
train_accuracy_tok: 0.8832153381509604
train_label=O_precision_sent: 0.4722222222222222
train_label=O_recall_sent: 0.04187192118226601
train_label=O_f-score_sent: 0.07692307692307691
train_label=N_precision_sent: 0.6196177757310615
train_label=N_recall_sent: 0.8129909365558913
train_label=N_f-score_sent: 0.7032536260290083
train_label=P_precision_sent: 0.7000246487552378
train_label=P_recall_sent: 0.7867036011080333
train_label=P_f-score_sent: 0.740837354897613
train_precision_macro_sent: 0.5972882155695073
train_recall_macro_sent: 0.5471888196153968
train_f-score_macro_sent: 0.5070046859498994
train_precision_micro_sent: 0.6553136704119851
train_recall_micro_sent: 0.6553136704119851
train_f-score_micro_sent: 0.6553136704119851
train_label=O_precision_tok: 0.8934007147560876
train_label=O_recall_tok: 0.9710246326811262
train_label=O_f-score_tok: 0.9305967676051452
train_label=N_precision_tok: 0.7740091820481589
train_label=N_recall_tok: 0.5816786368117166
train_label=N_f-score_tok: 0.6642010050251256
train_label=P_precision_tok: 0.8713222861007778
train_label=P_recall_tok: 0.6179398009353639
train_label=P_f-score_tok: 0.7230758436820318
train_precision_macro_tok: 0.8462440609683415
train_recall_macro_tok: 0.7235476901427357
train_f-score_macro_tok: 0.7726245387707675
train_precision_micro_tok: 0.8832153381509604
train_recall_micro_tok: 0.8832153381509604
train_f-score_micro_tok: 0.8832153381509605
train_time: 146.80946397781372
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4722    0.0419    0.0769      1624
           N     0.6196    0.8130    0.7033      3310
           P     0.7000    0.7867    0.7408      3610

   micro avg     0.6553    0.6553    0.6553      8544
   macro avg     0.5973    0.5472    0.5070      8544
weighted avg     0.6256    0.6553    0.6001      8544

F1-macro sent:  0.5070046859498994
F1-micro sent:  0.6553136704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9710    0.9306    124347
           N     0.7740    0.5817    0.6642     14202
           P     0.8713    0.6179    0.7231     25017

   micro avg     0.8832    0.8832    0.8832    163566
   macro avg     0.8462    0.7235    0.7726    163566
weighted avg     0.8797    0.8832    0.8757    163566

F1-macro tok:  0.7726245387707675
F1-micro tok:  0.8832153381509605
**************************************************
dev_cost_sum: 43993.971618652344
dev_cost_avg: 39.95819402239086
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.655893536121673
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7232704402515724
dev_label=P_precision_sent: 0.6468531468531469
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7283464566929135
dev_precision_macro_sent: 0.7675822276582732
dev_recall_macro_sent: 0.5508361787898988
dev_f-score_macro_sent: 0.49249298863666774
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.9017826534110387
dev_label=O_recall_tok: 0.9739586547361926
dev_label=O_f-score_tok: 0.9364820363722668
dev_label=N_precision_tok: 0.7986870897155361
dev_label=N_recall_tok: 0.5896607431340872
dev_label=N_f-score_tok: 0.6784386617100371
dev_label=P_precision_tok: 0.8904623073719283
dev_label=P_recall_tok: 0.6656288916562889
dev_label=P_f-score_tok: 0.7618029574202744
dev_precision_macro_tok: 0.8636440168328344
dev_recall_macro_tok: 0.743082763175523
dev_f-score_macro_tok: 0.7922412185008594
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 7.7889134883880615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6559    0.8061    0.7233       428
           P     0.6469    0.8333    0.7283       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.7676    0.5508    0.4925      1101
weighted avg     0.7238    0.6521    0.5803      1101

F1-macro sent:  0.49249298863666774
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9740    0.9365     16205
           N     0.7987    0.5897    0.6784      1857
           P     0.8905    0.6656    0.7618      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8636    0.7431    0.7922     21274
weighted avg     0.8911    0.8939    0.8876     21274

F1-macro tok:  0.7922412185008594
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 10
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 325524.5315551758
train_cost_avg: 38.099781314978436
train_count_sent: 8544.0
train_total_correct_sent: 5588.0
train_accuracy_sent: 0.6540262172284644
train_count_tok: 163566.0
train_total_correct_tok: 144608.0
train_accuracy_tok: 0.8840957167137424
train_label=O_precision_sent: 0.437125748502994
train_label=O_recall_sent: 0.04495073891625616
train_label=O_f-score_sent: 0.08151870463428253
train_label=N_precision_sent: 0.6157714285714285
train_label=N_recall_sent: 0.8138972809667674
train_label=N_f-score_sent: 0.7011060507482108
train_label=P_precision_sent: 0.7048975512243878
train_label=P_recall_sent: 0.7814404432132964
train_label=P_f-score_sent: 0.7411981082501314
train_precision_macro_sent: 0.5859315760996034
train_recall_macro_sent: 0.5467628210321066
train_f-score_macro_sent: 0.5079409545442083
train_precision_micro_sent: 0.6540262172284644
train_recall_micro_sent: 0.6540262172284644
train_f-score_micro_sent: 0.6540262172284644
train_label=O_precision_tok: 0.8940421373684133
train_label=O_recall_tok: 0.971225682967824
train_label=O_f-score_tok: 0.931037008198775
train_label=N_precision_tok: 0.7784721574479992
train_label=N_recall_tok: 0.5876637093367132
train_label=N_f-score_tok: 0.6697428078481724
train_label=P_precision_tok: 0.8722062714631538
train_label=P_recall_tok: 0.6192988767638006
train_label=P_f-score_tok: 0.7243104254324451
train_precision_macro_tok: 0.8482401887598554
train_recall_macro_tok: 0.7260627563561126
train_f-score_macro_tok: 0.7750300804931308
train_precision_micro_tok: 0.8840957167137424
train_recall_micro_tok: 0.8840957167137424
train_f-score_micro_tok: 0.8840957167137424
train_time: 147.07415890693665
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4371    0.0450    0.0815      1624
           N     0.6158    0.8139    0.7011      3310
           P     0.7049    0.7814    0.7412      3610

   micro avg     0.6540    0.6540    0.6540      8544
   macro avg     0.5859    0.5468    0.5079      8544
weighted avg     0.6195    0.6540    0.6003      8544

F1-macro sent:  0.5079409545442083
F1-micro sent:  0.6540262172284644
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8940    0.9712    0.9310    124347
           N     0.7785    0.5877    0.6697     14202
           P     0.8722    0.6193    0.7243     25017

   micro avg     0.8841    0.8841    0.8841    163566
   macro avg     0.8482    0.7261    0.7750    163566
weighted avg     0.8807    0.8841    0.8767    163566

F1-macro tok:  0.7750300804931308
F1-micro tok:  0.8840957167137424
**************************************************
dev_cost_sum: 43713.71936035156
dev_cost_avg: 39.703650645187615
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 18993.0
dev_accuracy_tok: 0.8927799191501363
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.5611111111111111
dev_label=N_recall_sent: 0.9439252336448598
dev_label=N_f-score_sent: 0.7038327526132405
dev_label=P_precision_sent: 0.782258064516129
dev_label=P_recall_sent: 0.6554054054054054
dev_label=P_f-score_sent: 0.7132352941176471
dev_precision_macro_sent: 0.7070489844683393
dev_recall_macro_sent: 0.5432994415465949
dev_f-score_macro_sent: 0.49196385871421744
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.899664410443092
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.9363049783934173
dev_label=N_precision_tok: 0.7557908669755129
dev_label=N_recall_tok: 0.6149703823371029
dev_label=N_f-score_tok: 0.678147268408551
dev_label=P_precision_tok: 0.9321723189734189
dev_label=P_recall_tok: 0.6332503113325031
dev_label=P_f-score_tok: 0.7541713014460512
dev_precision_macro_tok: 0.8625425321306746
dev_recall_macro_tok: 0.7414258220902185
dev_f-score_macro_tok: 0.7895411827493398
dev_precision_micro_tok: 0.8927799191501363
dev_recall_micro_tok: 0.8927799191501363
dev_f-score_micro_tok: 0.8927799191501363
dev_time: 7.643080234527588
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.5611    0.9439    0.7038       428
           P     0.7823    0.6554    0.7132       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.7070    0.5433    0.4920      1101
weighted avg     0.6954    0.6376    0.5735      1101

F1-macro sent:  0.49196385871421744
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8997    0.9761    0.9363     16205
           N     0.7558    0.6150    0.6781      1857
           P     0.9322    0.6333    0.7542      3212

   micro avg     0.8928    0.8928    0.8928     21274
   macro avg     0.8625    0.7414    0.7895     21274
weighted avg     0.8920    0.8928    0.8863     21274

F1-macro tok:  0.7895411827493398
F1-micro tok:  0.8927799191501363
**************************************************
Best epoch: 10
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 323412.1770019531
train_cost_avg: 37.85254880640837
train_count_sent: 8544.0
train_total_correct_sent: 5644.0
train_accuracy_sent: 0.6605805243445693
train_count_tok: 163566.0
train_total_correct_tok: 144782.0
train_accuracy_tok: 0.885159507477104
train_label=O_precision_sent: 0.4772727272727273
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07175398633257403
train_label=N_precision_sent: 0.622206864777701
train_label=N_recall_sent: 0.816012084592145
train_label=N_f-score_sent: 0.7060514965364004
train_label=P_precision_sent: 0.707442888725129
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.7499023564640022
train_precision_macro_sent: 0.6023074935918524
train_recall_macro_sent: 0.5508630405194755
train_f-score_macro_sent: 0.5092359464443256
train_precision_micro_sent: 0.6605805243445693
train_recall_micro_sent: 0.6605805243445693
train_f-score_micro_sent: 0.6605805243445693
train_label=O_precision_tok: 0.895946547884187
train_label=O_recall_tok: 0.9705421119930517
train_label=O_f-score_tok: 0.9317536972055265
train_label=N_precision_tok: 0.7734928670041418
train_label=N_recall_tok: 0.5917476411772989
train_label=N_f-score_tok: 0.6705229983643834
train_label=P_precision_tok: 0.8718404533081495
train_label=P_recall_tok: 0.6273334132789703
train_label=P_f-score_tok: 0.7296480543028501
train_precision_macro_tok: 0.847093289398826
train_recall_macro_tok: 0.7298743888164404
train_f-score_macro_tok: 0.7773082499575867
train_precision_micro_tok: 0.885159507477104
train_recall_micro_tok: 0.885159507477104
train_f-score_micro_tok: 0.885159507477104
train_time: 147.70802521705627
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4773    0.0388    0.0718      1624
           N     0.6222    0.8160    0.7061      3310
           P     0.7074    0.7978    0.7499      3610

   micro avg     0.6606    0.6606    0.6606      8544
   macro avg     0.6023    0.5509    0.5092      8544
weighted avg     0.6307    0.6606    0.6040      8544

F1-macro sent:  0.5092359464443256
F1-micro sent:  0.6605805243445693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9705    0.9318    124347
           N     0.7735    0.5917    0.6705     14202
           P     0.8718    0.6273    0.7296     25017

   micro avg     0.8852    0.8852    0.8852    163566
   macro avg     0.8471    0.7299    0.7773    163566
weighted avg     0.8816    0.8852    0.8782    163566

F1-macro tok:  0.7773082499575867
F1-micro tok:  0.885159507477104
**************************************************
dev_cost_sum: 43560.79187011719
dev_cost_avg: 39.56475192562869
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19022.0
dev_accuracy_tok: 0.8941430854564257
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.649155722326454
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7200832466181062
dev_label=P_precision_sent: 0.6595744680851063
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7380952380952381
dev_precision_macro_sent: 0.6862433968038535
dev_recall_macro_sent: 0.5531164964907772
dev_f-score_macro_sent: 0.4946431858915726
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9021881963092041
dev_label=O_recall_tok: 0.9744523295279235
dev_label=O_f-score_tok: 0.9369289189509908
dev_label=N_precision_tok: 0.7798611111111111
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.681225356384592
dev_label=P_precision_tok: 0.9043329043329044
dev_label=P_recall_tok: 0.6562889165628891
dev_label=P_f-score_tok: 0.7605989536352157
dev_precision_macro_tok: 0.8621274039177398
dev_recall_macro_tok: 0.7451600240514521
dev_f-score_macro_tok: 0.7929177429902662
dev_precision_micro_tok: 0.8941430854564257
dev_recall_micro_tok: 0.8941430854564257
dev_f-score_micro_tok: 0.8941430854564257
dev_time: 7.403102159500122
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6492    0.8084    0.7201       428
           P     0.6596    0.8378    0.7381       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6862    0.5531    0.4946      1101
weighted avg     0.6743    0.6549    0.5829      1101

F1-macro sent:  0.4946431858915726
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9022    0.9745    0.9369     16205
           N     0.7799    0.6047    0.6812      1857
           P     0.9043    0.6563    0.7606      3212

   micro avg     0.8941    0.8941    0.8941     21274
   macro avg     0.8621    0.7452    0.7929     21274
weighted avg     0.8918    0.8941    0.8880     21274

F1-macro tok:  0.7929177429902662
F1-micro tok:  0.8941430854564257
**************************************************
Best epoch: 10
**************************************************

EPOCH: 16
Learning rate: 0.810000
train_cost_sum: 321256.0402832031
train_cost_avg: 37.600191980711976
train_count_sent: 8544.0
train_total_correct_sent: 5697.0
train_accuracy_sent: 0.6667837078651685
train_count_tok: 163566.0
train_total_correct_tok: 145237.0
train_accuracy_tok: 0.8879412591858944
train_label=O_precision_sent: 0.528169014084507
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08493771234428087
train_label=N_precision_sent: 0.6310883243999068
train_label=N_recall_sent: 0.8181268882175227
train_label=N_f-score_sent: 0.7125378239705301
train_label=P_precision_sent: 0.7088299683775238
train_label=P_recall_sent: 0.807202216066482
train_label=P_f-score_sent: 0.75482450459785
train_precision_macro_sent: 0.6226957689539793
train_recall_macro_sent: 0.557170456764619
train_f-score_macro_sent: 0.517433346970887
train_precision_micro_sent: 0.6667837078651685
train_recall_micro_sent: 0.6667837078651685
train_f-score_micro_sent: 0.6667837078651685
train_label=O_precision_tok: 0.8981591625527865
train_label=O_recall_tok: 0.9715232373921365
train_label=O_f-score_tok: 0.9334018412136712
train_label=N_precision_tok: 0.7852850118375524
train_label=N_recall_tok: 0.6072384171243487
train_label=N_f-score_tok: 0.6848792884371029
train_label=P_precision_tok: 0.8742809734513274
train_label=P_recall_tok: 0.631850341767598
train_label=P_f-score_tok: 0.733554539759148
train_precision_macro_tok: 0.8525750492805554
train_recall_macro_tok: 0.7368706654280276
train_f-score_macro_tok: 0.7839452231366407
train_precision_micro_tok: 0.8879412591858944
train_recall_micro_tok: 0.8879412591858944
train_f-score_micro_tok: 0.8879412591858944
train_time: 146.5488703250885
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5282    0.0462    0.0849      1624
           N     0.6311    0.8181    0.7125      3310
           P     0.7088    0.8072    0.7548      3610

   micro avg     0.6668    0.6668    0.6668      8544
   macro avg     0.6227    0.5572    0.5174      8544
weighted avg     0.6444    0.6668    0.6111      8544

F1-macro sent:  0.517433346970887
F1-micro sent:  0.6667837078651685
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8982    0.9715    0.9334    124347
           N     0.7853    0.6072    0.6849     14202
           P     0.8743    0.6319    0.7336     25017

   micro avg     0.8879    0.8879    0.8879    163566
   macro avg     0.8526    0.7369    0.7839    163566
weighted avg     0.8847    0.8879    0.8813    163566

F1-macro tok:  0.7839452231366407
F1-micro tok:  0.8879412591858944
**************************************************
dev_cost_sum: 43389.225158691406
dev_cost_avg: 39.40892384985595
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 19026.0
dev_accuracy_tok: 0.8943311083952242
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.5635593220338984
dev_label=N_recall_sent: 0.9322429906542056
dev_label=N_f-score_sent: 0.7024647887323944
dev_label=P_precision_sent: 0.7760416666666666
dev_label=P_recall_sent: 0.6711711711711712
dev_label=P_f-score_sent: 0.7198067632850242
dev_precision_macro_sent: 0.7057929221594476
dev_recall_macro_sent: 0.5446606158049655
dev_f-score_macro_sent: 0.4936983604763944
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.9007746639325587
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9368205918071146
dev_label=N_precision_tok: 0.7673634524612273
dev_label=N_recall_tok: 0.6128163704900377
dev_label=N_f-score_tok: 0.681437125748503
dev_label=P_precision_tok: 0.9279642058165548
dev_label=P_recall_tok: 0.6457036114570361
dev_label=P_f-score_tok: 0.7615201028088856
dev_precision_macro_tok: 0.8653674407367803
dev_recall_macro_tok: 0.7447972088337412
dev_f-score_macro_tok: 0.7932592734548344
dev_precision_micro_tok: 0.8943311083952242
dev_recall_micro_tok: 0.8943311083952242
dev_f-score_micro_tok: 0.8943311083952242
dev_time: 7.639442205429077
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.5636    0.9322    0.7025       428
           P     0.7760    0.6712    0.7198       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7058    0.5447    0.4937      1101
weighted avg     0.6938    0.6394    0.5756      1101

F1-macro sent:  0.4936983604763944
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9008    0.9759    0.9368     16205
           N     0.7674    0.6128    0.6814      1857
           P     0.9280    0.6457    0.7615      3212

   micro avg     0.8943    0.8943    0.8943     21274
   macro avg     0.8654    0.7448    0.7933     21274
weighted avg     0.8932    0.8943    0.8881     21274

F1-macro tok:  0.7932592734548344
F1-micro tok:  0.8943311083952242
**************************************************
Best epoch: 10
**************************************************

EPOCH: 17
Learning rate: 0.729000
train_cost_sum: 319397.7370605469
train_cost_avg: 37.3826939443524
train_count_sent: 8544.0
train_total_correct_sent: 5693.0
train_accuracy_sent: 0.666315543071161
train_count_tok: 163566.0
train_total_correct_tok: 145597.0
train_accuracy_tok: 0.8901422055928494
train_label=O_precision_sent: 0.5269461077844312
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.09826912339475154
train_label=N_precision_sent: 0.6309689383402874
train_label=N_recall_sent: 0.8223564954682779
train_label=N_f-score_sent: 0.7140608604407135
train_label=P_precision_sent: 0.7095742062515382
train_label=P_recall_sent: 0.7986149584487534
train_label=P_f-score_sent: 0.7514661801120813
train_precision_macro_sent: 0.6224964174587523
train_recall_macro_sent: 0.5583862153450859
train_f-score_macro_sent: 0.5212653879825154
train_precision_micro_sent: 0.666315543071161
train_recall_micro_sent: 0.666315543071161
train_f-score_micro_sent: 0.666315543071161
train_label=O_precision_tok: 0.900175000930856
train_label=O_recall_tok: 0.9721183462407618
train_label=O_f-score_tok: 0.9347644529679235
train_label=N_precision_tok: 0.790341578327444
train_label=N_recall_tok: 0.6142092663005211
train_label=N_f-score_tok: 0.6912318237648084
train_label=P_precision_tok: 0.8766717825038369
train_label=P_recall_tok: 0.6393252588239997
train_label=P_f-score_tok: 0.7394188761239916
train_precision_macro_tok: 0.8557294539207123
train_recall_macro_tok: 0.7418842904550941
train_f-score_macro_tok: 0.7884717176189079
train_precision_micro_tok: 0.8901422055928494
train_recall_micro_tok: 0.8901422055928494
train_f-score_micro_tok: 0.8901422055928494
train_time: 147.02203226089478
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5269    0.0542    0.0983      1624
           N     0.6310    0.8224    0.7141      3310
           P     0.7096    0.7986    0.7515      3610

   micro avg     0.6663    0.6663    0.6663      8544
   macro avg     0.6225    0.5584    0.5213      8544
weighted avg     0.6444    0.6663    0.6128      8544

F1-macro sent:  0.5212653879825154
F1-micro sent:  0.666315543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9002    0.9721    0.9348    124347
           N     0.7903    0.6142    0.6912     14202
           P     0.8767    0.6393    0.7394     25017

   micro avg     0.8901    0.8901    0.8901    163566
   macro avg     0.8557    0.7419    0.7885    163566
weighted avg     0.8870    0.8901    0.8837    163566

F1-macro tok:  0.7884717176189079
F1-micro tok:  0.8901422055928494
**************************************************
dev_cost_sum: 43326.124755859375
dev_cost_avg: 39.351611949009424
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19029.0
dev_accuracy_tok: 0.8944721255993231
dev_label=O_precision_sent: 0.7857142857142857
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09053497942386832
dev_label=N_precision_sent: 0.6634050880626223
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7220447284345046
dev_label=P_precision_sent: 0.6614583333333334
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7470588235294118
dev_precision_macro_sent: 0.7035259023700805
dev_recall_macro_sent: 0.5660663724574265
dev_f-score_macro_sent: 0.519879510462595
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.8954090244176888
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9367550545925425
dev_label=N_precision_tok: 0.8281622911694511
dev_label=N_recall_tok: 0.5605815831987075
dev_label=N_f-score_tok: 0.6685934489402697
dev_label=P_precision_tok: 0.9242086491306286
dev_label=P_recall_tok: 0.6453922789539228
dev_label=P_f-score_tok: 0.7600366636113658
dev_precision_macro_tok: 0.8825933215725894
dev_recall_macro_tok: 0.7293593836507944
dev_f-score_macro_tok: 0.7884617223813927
dev_precision_micro_tok: 0.8944721255993231
dev_recall_micro_tok: 0.8944721255993231
dev_f-score_micro_tok: 0.8944721255993231
dev_time: 7.549890041351318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7857    0.0480    0.0905       229
           N     0.6634    0.7921    0.7220       428
           P     0.6615    0.8581    0.7471       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.7035    0.5661    0.5199      1101
weighted avg     0.6881    0.6639    0.6008      1101

F1-macro sent:  0.519879510462595
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8954    0.9821    0.9368     16205
           N     0.8282    0.5606    0.6686      1857
           P     0.9242    0.6454    0.7600      3212

   micro avg     0.8945    0.8945    0.8945     21274
   macro avg     0.8826    0.7294    0.7885     21274
weighted avg     0.8939    0.8945    0.8867     21274

F1-macro tok:  0.7884617223813927
F1-micro tok:  0.8944721255993231
**************************************************
Best epoch: 17
**************************************************

EPOCH: 18
Learning rate: 0.729000
train_cost_sum: 317903.28021240234
train_cost_avg: 37.20778092373623
train_count_sent: 8544.0
train_total_correct_sent: 5761.0
train_accuracy_sent: 0.6742743445692884
train_count_tok: 163566.0
train_total_correct_tok: 145729.0
train_accuracy_tok: 0.8909492192753995
train_label=O_precision_sent: 0.48026315789473684
train_label=O_recall_sent: 0.04495073891625616
train_label=O_f-score_sent: 0.08220720720720721
train_label=N_precision_sent: 0.6488095238095238
train_label=N_recall_sent: 0.823262839879154
train_label=N_f-score_sent: 0.7256990679094542
train_label=P_precision_sent: 0.7068225190839694
train_label=P_recall_sent: 0.820775623268698
train_label=P_f-score_sent: 0.7595488336324019
train_precision_macro_sent: 0.61196506692941
train_recall_macro_sent: 0.562996400688036
train_f-score_macro_sent: 0.5224850362496878
train_precision_micro_sent: 0.6742743445692884
train_recall_micro_sent: 0.6742743445692884
train_f-score_micro_sent: 0.6742743445692884
train_label=O_precision_tok: 0.9012970932877846
train_label=O_recall_tok: 0.9717644977361738
train_label=O_f-score_tok: 0.9352052504488886
train_label=N_precision_tok: 0.7884165015312556
train_label=N_recall_tok: 0.6163216448387551
train_label=N_f-score_tok: 0.6918273790705026
train_label=P_precision_tok: 0.8774123403098668
train_label=P_recall_tok: 0.6451612903225806
train_label=P_f-score_tok: 0.7435732055652815
train_precision_macro_tok: 0.8557086450429691
train_recall_macro_tok: 0.7444158109658364
train_f-score_macro_tok: 0.7902019450282243
train_precision_micro_tok: 0.8909492192753995
train_recall_micro_tok: 0.8909492192753995
train_f-score_micro_tok: 0.8909492192753995
train_time: 147.9973602294922
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4803    0.0450    0.0822      1624
           N     0.6488    0.8233    0.7257      3310
           P     0.7068    0.8208    0.7595      3610

   micro avg     0.6743    0.6743    0.6743      8544
   macro avg     0.6120    0.5630    0.5225      8544
weighted avg     0.6413    0.6743    0.6177      8544

F1-macro sent:  0.5224850362496878
F1-micro sent:  0.6742743445692884
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9013    0.9718    0.9352    124347
           N     0.7884    0.6163    0.6918     14202
           P     0.8774    0.6452    0.7436     25017

   micro avg     0.8909    0.8909    0.8909    163566
   macro avg     0.8557    0.7444    0.7902    163566
weighted avg     0.8878    0.8909    0.8848    163566

F1-macro tok:  0.7902019450282243
F1-micro tok:  0.8909492192753995
**************************************************
dev_cost_sum: 43123.04309082031
dev_cost_avg: 39.167159937166495
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19086.0
dev_accuracy_tok: 0.8971514524772022
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.5812220566318927
dev_label=N_recall_sent: 0.9112149532710281
dev_label=N_f-score_sent: 0.7097361237488626
dev_label=P_precision_sent: 0.7494089834515366
dev_label=P_recall_sent: 0.713963963963964
dev_label=P_f-score_sent: 0.7312572087658593
dev_precision_macro_sent: 0.7292579657420956
dev_recall_macro_sent: 0.5504599301991459
dev_f-score_macro_sent: 0.49728026338061354
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.9037451472939028
dev_label=O_recall_tok: 0.9768589941376119
dev_label=O_f-score_tok: 0.9388808161086564
dev_label=N_precision_tok: 0.7881297446514838
dev_label=N_recall_tok: 0.6149703823371029
dev_label=N_f-score_tok: 0.6908650937689051
dev_label=P_precision_tok: 0.9155478562148116
dev_label=P_recall_tok: 0.6581569115815691
dev_label=P_f-score_tok: 0.7658032965042565
dev_precision_macro_tok: 0.8691409160533995
dev_recall_macro_tok: 0.7499954293520945
dev_f-score_macro_tok: 0.7985164021272727
dev_precision_micro_tok: 0.8971514524772022
dev_recall_micro_tok: 0.8971514524772022
dev_f-score_micro_tok: 0.8971514524772022
dev_time: 6.972455978393555
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.5812    0.9112    0.7097       428
           P     0.7494    0.7140    0.7313       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7293    0.5505    0.4973      1101
weighted avg     0.7064    0.6476    0.5814      1101

F1-macro sent:  0.49728026338061354
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9037    0.9769    0.9389     16205
           N     0.7881    0.6150    0.6909      1857
           P     0.9155    0.6582    0.7658      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8691    0.7500    0.7985     21274
weighted avg     0.8954    0.8972    0.8911     21274

F1-macro tok:  0.7985164021272727
F1-micro tok:  0.8971514524772022
**************************************************
Best epoch: 17
**************************************************

EPOCH: 19
Learning rate: 0.729000
train_cost_sum: 316351.3609008789
train_cost_avg: 37.02614242753732
train_count_sent: 8544.0
train_total_correct_sent: 5718.0
train_accuracy_sent: 0.6692415730337079
train_count_tok: 163566.0
train_total_correct_tok: 146042.0
train_accuracy_tok: 0.8928628199014466
train_label=O_precision_sent: 0.5220588235294118
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.08068181818181817
train_label=N_precision_sent: 0.6346109175377468
train_label=N_recall_sent: 0.8253776435045317
train_label=N_f-score_sent: 0.7175311884438608
train_label=P_precision_sent: 0.710455764075067
train_label=P_recall_sent: 0.8074792243767313
train_label=P_f-score_sent: 0.7558667185271619
train_precision_macro_sent: 0.6223751683807419
train_recall_macro_sent: 0.558858693234641
train_f-score_macro_sent: 0.518026575050947
train_precision_micro_sent: 0.6692415730337079
train_recall_micro_sent: 0.6692415730337079
train_f-score_micro_sent: 0.6692415730337079
train_label=O_precision_tok: 0.9030494090929465
train_label=O_recall_tok: 0.9721505142866333
train_label=O_f-score_tok: 0.9363267740473803
train_label=N_precision_tok: 0.7913035746043038
train_label=N_recall_tok: 0.6266018870581608
train_label=N_f-score_tok: 0.6993869852247722
train_label=P_precision_tok: 0.8808646657275978
train_label=P_recall_tok: 0.6499180557221089
train_label=P_f-score_tok: 0.7479700977573317
train_precision_macro_tok: 0.858405883141616
train_recall_macro_tok: 0.7495568190223011
train_f-score_macro_tok: 0.7945612856764948
train_precision_micro_tok: 0.8928628199014466
train_recall_micro_tok: 0.8928628199014466
train_f-score_micro_tok: 0.8928628199014466
train_time: 146.71859431266785
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5221    0.0437    0.0807      1624
           N     0.6346    0.8254    0.7175      3310
           P     0.7105    0.8075    0.7559      3610

   micro avg     0.6692    0.6692    0.6692      8544
   macro avg     0.6224    0.5589    0.5180      8544
weighted avg     0.6453    0.6692    0.6127      8544

F1-macro sent:  0.518026575050947
F1-micro sent:  0.6692415730337079
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9030    0.9722    0.9363    124347
           N     0.7913    0.6266    0.6994     14202
           P     0.8809    0.6499    0.7480     25017

   micro avg     0.8929    0.8929    0.8929    163566
   macro avg     0.8584    0.7496    0.7946    163566
weighted avg     0.8900    0.8929    0.8869    163566

F1-macro tok:  0.7945612856764948
F1-micro tok:  0.8928628199014466
**************************************************
dev_cost_sum: 43091.98486328125
dev_cost_avg: 39.13895082950159
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19054.0
dev_accuracy_tok: 0.8956472689668139
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6307420494699647
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7183098591549296
dev_label=P_precision_sent: 0.6862003780718336
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7461459403905446
dev_precision_macro_sent: 0.6612030314028217
dev_recall_macro_sent: 0.5563823220028583
dev_f-score_macro_sent: 0.4994994509123212
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9079715590496561
dev_label=O_recall_tok: 0.9692687442147485
dev_label=O_f-score_tok: 0.937619388729704
dev_label=N_precision_tok: 0.782312925170068
dev_label=N_recall_tok: 0.6192784060312332
dev_label=N_f-score_tok: 0.6913134956417192
dev_label=P_precision_tok: 0.8770459081836327
dev_label=P_recall_tok: 0.683997509339975
dev_label=P_f-score_tok: 0.7685849221619729
dev_precision_macro_tok: 0.8557767974677856
dev_recall_macro_tok: 0.7575148865286522
dev_f-score_macro_tok: 0.7991726021777987
dev_precision_micro_tok: 0.8956472689668139
dev_recall_micro_tok: 0.8956472689668139
dev_f-score_micro_tok: 0.8956472689668139
dev_time: 7.50188684463501
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6307    0.8341    0.7183       428
           P     0.6862    0.8176    0.7461       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6612    0.5564    0.4995      1101
weighted avg     0.6606    0.6576    0.5872      1101

F1-macro sent:  0.4994994509123212
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9693    0.9376     16205
           N     0.7823    0.6193    0.6913      1857
           P     0.8770    0.6840    0.7686      3212

   micro avg     0.8956    0.8956    0.8956     21274
   macro avg     0.8558    0.7575    0.7992     21274
weighted avg     0.8923    0.8956    0.8906     21274

F1-macro tok:  0.7991726021777987
F1-micro tok:  0.8956472689668139
**************************************************
Best epoch: 17
**************************************************

EPOCH: 20
Learning rate: 0.729000
train_cost_sum: 315204.8209838867
train_cost_avg: 36.89195002152232
train_count_sent: 8544.0
train_total_correct_sent: 5743.0
train_accuracy_sent: 0.6721676029962547
train_count_tok: 163566.0
train_total_correct_tok: 146210.0
train_accuracy_tok: 0.8938899282246922
train_label=O_precision_sent: 0.5209580838323353
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.09715242881072025
train_label=N_precision_sent: 0.6256708407871199
train_label=N_recall_sent: 0.8453172205438066
train_label=N_f-score_sent: 0.7190953482395271
train_label=P_precision_sent: 0.7318822023047376
train_label=P_recall_sent: 0.7916897506925208
train_label=P_f-score_sent: 0.7606121091151031
train_precision_macro_sent: 0.6261703756413975
train_recall_macro_sent: 0.563526133269252
train_f-score_macro_sent: 0.5256199620551169
train_precision_micro_sent: 0.6721676029962547
train_recall_micro_sent: 0.6721676029962547
train_f-score_micro_sent: 0.6721676029962547
train_label=O_precision_tok: 0.9043375459232156
train_label=O_recall_tok: 0.9719735900343394
train_label=O_f-score_tok: 0.9369365179035172
train_label=N_precision_tok: 0.7916887709991158
train_label=N_recall_tok: 0.6304745810449233
train_label=N_f-score_tok: 0.7019441831295077
train_label=P_precision_tok: 0.8809715728948359
train_label=P_recall_tok: 0.6553143862173721
train_label=P_f-score_tok: 0.7515701645807545
train_precision_macro_tok: 0.8589992966057224
train_recall_macro_tok: 0.7525875190988782
train_f-score_macro_tok: 0.7968169552045931
train_precision_micro_tok: 0.8938899282246922
train_recall_micro_tok: 0.8938899282246922
train_f-score_micro_tok: 0.8938899282246922
train_time: 146.90054154396057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5210    0.0536    0.0972      1624
           N     0.6257    0.8453    0.7191      3310
           P     0.7319    0.7917    0.7606      3610

   micro avg     0.6722    0.6722    0.6722      8544
   macro avg     0.6262    0.5635    0.5256      8544
weighted avg     0.6506    0.6722    0.6184      8544

F1-macro sent:  0.5256199620551169
F1-micro sent:  0.6721676029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9043    0.9720    0.9369    124347
           N     0.7917    0.6305    0.7019     14202
           P     0.8810    0.6553    0.7516     25017

   micro avg     0.8939    0.8939    0.8939    163566
   macro avg     0.8590    0.7526    0.7968    163566
weighted avg     0.8910    0.8939    0.8882    163566

F1-macro tok:  0.7968169552045931
F1-micro tok:  0.8938899282246922
**************************************************
dev_cost_sum: 42956.1728515625
dev_cost_avg: 39.015597503689825
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07468879668049792
dev_label=N_precision_sent: 0.6616541353383458
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7333333333333333
dev_label=P_precision_sent: 0.6786355475763016
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.7552447552447553
dev_precision_macro_sent: 0.6967632276382157
dev_recall_macro_sent: 0.5710275226456919
dev_f-score_macro_sent: 0.5210889617528621
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9075451034641766
dev_label=O_recall_tok: 0.9716136994754705
dev_label=O_f-score_tok: 0.9384872146390891
dev_label=N_precision_tok: 0.776158940397351
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6961686961686961
dev_label=P_precision_tok: 0.8964803312629399
dev_label=P_recall_tok: 0.6740348692403487
dev_label=P_f-score_tok: 0.7695041762928737
dev_precision_macro_tok: 0.8600614583748225
dev_recall_macro_tok: 0.7589246799686369
dev_f-score_macro_tok: 0.8013866957002196
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 7.52886962890625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0393    0.0747       229
           N     0.6617    0.8224    0.7333       428
           P     0.6786    0.8514    0.7552       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6968    0.5710    0.5211      1101
weighted avg     0.6869    0.6712    0.6052      1101

F1-macro sent:  0.5210889617528621
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9075    0.9716    0.9385     16205
           N     0.7762    0.6311    0.6962      1857
           P     0.8965    0.6740    0.7695      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8601    0.7589    0.8014     21274
weighted avg     0.8944    0.8970    0.8918     21274

F1-macro tok:  0.8013866957002196
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 313793.68518066406
train_cost_avg: 36.72678899586424
train_count_sent: 8544.0
train_total_correct_sent: 5776.0
train_accuracy_sent: 0.6760299625468165
train_count_tok: 163566.0
train_total_correct_tok: 146333.0
train_accuracy_tok: 0.8946419182470685
train_label=O_precision_sent: 0.5315315315315315
train_label=O_recall_sent: 0.07266009852216748
train_label=O_f-score_sent: 0.12784398699891658
train_label=N_precision_sent: 0.6449067431850789
train_label=N_recall_sent: 0.8148036253776435
train_label=N_f-score_sent: 0.7199679658302189
train_label=P_precision_sent: 0.7152173913043478
train_label=P_recall_sent: 0.8202216066481994
train_label=P_f-score_sent: 0.7641290322580644
train_precision_macro_sent: 0.6305518886736527
train_recall_macro_sent: 0.5692284435160034
train_f-score_macro_sent: 0.5373136616957334
train_precision_micro_sent: 0.6760299625468165
train_recall_micro_sent: 0.6760299625468165
train_f-score_micro_sent: 0.6760299625468165
train_label=O_precision_tok: 0.9057476607485605
train_label=O_recall_tok: 0.9715151953806687
train_label=O_f-score_tok: 0.9374793867834846
train_label=N_precision_tok: 0.792401269393512
train_label=N_recall_tok: 0.632939022672863
train_label=N_f-score_tok: 0.7037500978626791
train_label=P_precision_tok: 0.8775867558102515
train_label=P_recall_tok: 0.6611104448974697
train_label=P_f-score_tok: 0.7541207851720129
train_precision_macro_tok: 0.8585785619841081
train_recall_macro_tok: 0.7551882209836672
train_f-score_macro_tok: 0.7984500899393921
train_precision_micro_tok: 0.8946419182470685
train_recall_micro_tok: 0.8946419182470685
train_f-score_micro_tok: 0.8946419182470685
train_time: 147.44610476493835
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5315    0.0727    0.1278      1624
           N     0.6449    0.8148    0.7200      3310
           P     0.7152    0.8202    0.7641      3610

   micro avg     0.6760    0.6760    0.6760      8544
   macro avg     0.6306    0.5692    0.5373      8544
weighted avg     0.6531    0.6760    0.6261      8544

F1-macro sent:  0.5373136616957334
F1-micro sent:  0.6760299625468165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9057    0.9715    0.9375    124347
           N     0.7924    0.6329    0.7038     14202
           P     0.8776    0.6611    0.7541     25017

   micro avg     0.8946    0.8946    0.8946    163566
   macro avg     0.8586    0.7552    0.7985    163566
weighted avg     0.8916    0.8946    0.8891    163566

F1-macro tok:  0.7984500899393921
F1-micro tok:  0.8946419182470685
**************************************************
dev_cost_sum: 42914.15447998047
dev_cost_avg: 38.97743367845637
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19095.0
dev_accuracy_tok: 0.8975745040894989
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.6747967479674797
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7217391304347825
dev_label=P_precision_sent: 0.6445182724252492
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7418738049713193
dev_precision_macro_sent: 0.7254859591785286
dev_recall_macro_sent: 0.5585918939385861
dev_f-score_macro_sent: 0.5048201310110735
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9033896370691623
dev_label=O_recall_tok: 0.9769207034865782
dev_label=O_f-score_tok: 0.9387174241750421
dev_label=N_precision_tok: 0.8111273792093704
dev_label=N_recall_tok: 0.596661281637049
dev_label=N_f-score_tok: 0.6875581756127832
dev_label=P_precision_tok: 0.9043624161073825
dev_label=P_recall_tok: 0.6712328767123288
dev_label=P_f-score_tok: 0.7705503931379557
dev_precision_macro_tok: 0.872959810795305
dev_recall_macro_tok: 0.7482716206119854
dev_f-score_macro_tok: 0.798941997641927
dev_precision_micro_tok: 0.8975745040894989
dev_recall_micro_tok: 0.8975745040894989
dev_f-score_micro_tok: 0.8975745040894989
dev_time: 7.37559962272644
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.6748    0.7757    0.7217       428
           P     0.6445    0.8739    0.7419       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.7255    0.5586    0.5048      1101
weighted avg     0.7005    0.6594    0.5903      1101

F1-macro sent:  0.5048201310110735
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9034    0.9769    0.9387     16205
           N     0.8111    0.5967    0.6876      1857
           P     0.9044    0.6712    0.7706      3212

   micro avg     0.8976    0.8976    0.8976     21274
   macro avg     0.8730    0.7483    0.7989     21274
weighted avg     0.8955    0.8976    0.8914     21274

F1-macro tok:  0.798941997641927
F1-micro tok:  0.8975745040894989
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 0.729000
train_cost_sum: 312313.9716796875
train_cost_avg: 36.55360155427054
train_count_sent: 8544.0
train_total_correct_sent: 5813.0
train_accuracy_sent: 0.6803604868913857
train_count_tok: 163566.0
train_total_correct_tok: 146706.0
train_accuracy_tok: 0.8969223432742746
train_label=O_precision_sent: 0.5586592178770949
train_label=O_recall_sent: 0.06157635467980296
train_label=O_f-score_sent: 0.11092623405435387
train_label=N_precision_sent: 0.6550144648023144
train_label=N_recall_sent: 0.820845921450151
train_label=N_f-score_sent: 0.7286135693215339
train_label=P_precision_sent: 0.7104576713303297
train_label=P_recall_sent: 0.8299168975069252
train_label=P_f-score_sent: 0.7655551296793152
train_precision_macro_sent: 0.6413771180032464
train_recall_macro_sent: 0.5707797245456264
train_f-score_macro_sent: 0.5350316443517343
train_precision_micro_sent: 0.6803604868913857
train_recall_micro_sent: 0.6803604868913857
train_f-score_micro_sent: 0.6803604868913857
train_label=O_precision_tok: 0.9076198771568877
train_label=O_recall_tok: 0.9720781361834222
train_label=O_f-score_tok: 0.9387438112804581
train_label=N_precision_tok: 0.7966488288446355
train_label=N_recall_tok: 0.6394169835234474
train_label=N_f-score_tok: 0.709425413069802
train_label=P_precision_tok: 0.8820896308389068
train_label=P_recall_tok: 0.6695447095974737
train_label=P_f-score_tok: 0.7612598282052447
train_precision_macro_tok: 0.8621194456134766
train_recall_macro_tok: 0.7603466097681144
train_f-score_macro_tok: 0.8031430175185017
train_precision_micro_tok: 0.8969223432742746
train_recall_micro_tok: 0.8969223432742746
train_f-score_micro_tok: 0.8969223432742746
train_time: 146.36208486557007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5587    0.0616    0.1109      1624
           N     0.6550    0.8208    0.7286      3310
           P     0.7105    0.8299    0.7656      3610

   micro avg     0.6804    0.6804    0.6804      8544
   macro avg     0.6414    0.5708    0.5350      8544
weighted avg     0.6601    0.6804    0.6268      8544

F1-macro sent:  0.5350316443517343
F1-micro sent:  0.6803604868913857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9076    0.9721    0.9387    124347
           N     0.7966    0.6394    0.7094     14202
           P     0.8821    0.6695    0.7613     25017

   micro avg     0.8969    0.8969    0.8969    163566
   macro avg     0.8621    0.7603    0.8031    163566
weighted avg     0.8941    0.8969    0.8917    163566

F1-macro tok:  0.8031430175185017
F1-micro tok:  0.8969223432742746
**************************************************
dev_cost_sum: 42809.77880859375
dev_cost_avg: 38.88263288700613
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19101.0
dev_accuracy_tok: 0.8978565384976968
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09795918367346937
dev_label=N_precision_sent: 0.6849894291754757
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.7192008879023307
dev_label=P_precision_sent: 0.6421568627450981
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.744318181818182
dev_precision_macro_sent: 0.692382097306858
dev_recall_macro_sent: 0.5648487425514728
dev_f-score_macro_sent: 0.5204927511313273
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9031650983746792
dev_label=O_recall_tok: 0.9772909595803764
dev_label=O_f-score_tok: 0.938767042086544
dev_label=N_precision_tok: 0.8214553638409603
dev_label=N_recall_tok: 0.5896607431340872
dev_label=N_f-score_tok: 0.6865203761755486
dev_label=P_precision_tok: 0.9014962593516209
dev_label=P_recall_tok: 0.675280199252802
dev_label=P_f-score_tok: 0.7721609113563546
dev_precision_macro_tok: 0.8753722405224201
dev_recall_macro_tok: 0.7474106339890886
dev_f-score_macro_tok: 0.799149443206149
dev_precision_micro_tok: 0.8978565384976968
dev_recall_micro_tok: 0.8978565384976968
dev_f-score_micro_tok: 0.8978565384976968
dev_time: 7.616509437561035
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0524    0.0980       229
           N     0.6850    0.7570    0.7192       428
           P     0.6422    0.8851    0.7443       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6924    0.5648    0.5205      1101
weighted avg     0.6812    0.6621    0.6001      1101

F1-macro sent:  0.5204927511313273
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9032    0.9773    0.9388     16205
           N     0.8215    0.5897    0.6865      1857
           P     0.9015    0.6753    0.7722      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8754    0.7474    0.7991     21274
weighted avg     0.8958    0.8979    0.8916     21274

F1-macro tok:  0.799149443206149
F1-micro tok:  0.8978565384976968
**************************************************
Best epoch: 20
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 311179.5098876953
train_cost_avg: 36.420822786481196
train_count_sent: 8544.0
train_total_correct_sent: 5831.0
train_accuracy_sent: 0.6824672284644194
train_count_tok: 163566.0
train_total_correct_tok: 146730.0
train_accuracy_tok: 0.8970690730347383
train_label=O_precision_sent: 0.43564356435643564
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.0963855421686747
train_label=N_precision_sent: 0.6567877629063098
train_label=N_recall_sent: 0.8302114803625378
train_label=N_f-score_sent: 0.733386709367494
train_label=P_precision_sent: 0.7202982202982203
train_label=P_recall_sent: 0.8296398891966759
train_label=P_f-score_sent: 0.7711122554067971
train_precision_macro_sent: 0.6042431825203219
train_recall_macro_sent: 0.5713461872258134
train_f-score_macro_sent: 0.5336281689809885
train_precision_micro_sent: 0.6824672284644194
train_recall_micro_sent: 0.6824672284644194
train_f-score_micro_sent: 0.6824672284644194
train_label=O_precision_tok: 0.9080412278197635
train_label=O_recall_tok: 0.9720620521604864
train_label=O_f-score_tok: 0.9389616291399474
train_label=N_precision_tok: 0.8013668623499518
train_label=N_recall_tok: 0.6439938036896212
train_label=N_f-score_tok: 0.7141128245168847
train_label=P_precision_tok: 0.877724670413362
train_label=P_recall_tok: 0.6679857696766199
train_label=P_f-score_tok: 0.7586253858725259
train_precision_macro_tok: 0.8623775868610258
train_recall_macro_tok: 0.7613472085089091
train_f-score_macro_tok: 0.803899946509786
train_precision_micro_tok: 0.8970690730347383
train_recall_micro_tok: 0.8970690730347383
train_f-score_micro_tok: 0.8970690730347383
train_time: 194.93660378456116
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4356    0.0542    0.0964      1624
           N     0.6568    0.8302    0.7334      3310
           P     0.7203    0.8296    0.7711      3610

   micro avg     0.6825    0.6825    0.6825      8544
   macro avg     0.6042    0.5713    0.5336      8544
weighted avg     0.6416    0.6825    0.6282      8544

F1-macro sent:  0.5336281689809885
F1-micro sent:  0.6824672284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9721    0.9390    124347
           N     0.8014    0.6440    0.7141     14202
           P     0.8777    0.6680    0.7586     25017

   micro avg     0.8971    0.8971    0.8971    163566
   macro avg     0.8624    0.7613    0.8039    163566
weighted avg     0.8941    0.8971    0.8919    163566

F1-macro tok:  0.803899946509786
F1-micro tok:  0.8970690730347383
**************************************************
dev_cost_sum: 42712.82275390625
dev_cost_avg: 38.794571075300865
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19096.0
dev_accuracy_tok: 0.8976215098241985
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0823045267489712
dev_label=N_precision_sent: 0.6713709677419355
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7207792207792209
dev_label=P_precision_sent: 0.6480541455160744
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.740096618357488
dev_precision_macro_sent: 0.6779036091812415
dev_recall_macro_sent: 0.561439372686975
dev_f-score_macro_sent: 0.5143934552952266
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9079167387418555
dev_label=O_recall_tok: 0.9716754088244369
dev_label=O_f-score_tok: 0.9387146774770478
dev_label=N_precision_tok: 0.7730870712401056
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6949303290839016
dev_label=P_precision_tok: 0.901863354037267
dev_label=P_recall_tok: 0.678082191780822
dev_label=P_f-score_tok: 0.7741247556424383
dev_precision_macro_tok: 0.8609557213397427
dev_recall_macro_tok: 0.7602943572651167
dev_f-score_macro_tok: 0.8025899207344627
dev_precision_micro_tok: 0.8976215098241985
dev_recall_micro_tok: 0.8976215098241985
dev_f-score_micro_tok: 0.8976215098241985
dev_time: 10.992582321166992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0437    0.0823       229
           N     0.6714    0.7780    0.7208       428
           P     0.6481    0.8626    0.7401       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.6779    0.5614    0.5144      1101
weighted avg     0.6709    0.6594    0.5958      1101

F1-macro sent:  0.5143934552952266
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9079    0.9717    0.9387     16205
           N     0.7731    0.6311    0.6949      1857
           P     0.9019    0.6781    0.7741      3212

   micro avg     0.8976    0.8976    0.8976     21274
   macro avg     0.8610    0.7603    0.8026     21274
weighted avg     0.8952    0.8976    0.8926     21274

F1-macro tok:  0.8025899207344627
F1-micro tok:  0.8976215098241985
**************************************************
Best epoch: 20
**************************************************

EPOCH: 24
Learning rate: 0.729000
train_cost_sum: 309836.0705566406
train_cost_avg: 36.26358503706
train_count_sent: 8544.0
train_total_correct_sent: 5822.0
train_accuracy_sent: 0.6814138576779026
train_count_tok: 163566.0
train_total_correct_tok: 147117.0
train_accuracy_tok: 0.8994350904222149
train_label=O_precision_sent: 0.4577922077922078
train_label=O_recall_sent: 0.08682266009852217
train_label=O_f-score_sent: 0.14596273291925466
train_label=N_precision_sent: 0.6526974951830443
train_label=N_recall_sent: 0.8187311178247734
train_label=N_f-score_sent: 0.7263468239077994
train_label=P_precision_sent: 0.7274730656219393
train_label=P_recall_sent: 0.8229916897506925
train_label=P_f-score_sent: 0.7722900961788405
train_precision_macro_sent: 0.6126542561990638
train_recall_macro_sent: 0.576181822557996
train_f-score_macro_sent: 0.5481998843352982
train_precision_micro_sent: 0.6814138576779026
train_recall_micro_sent: 0.6814138576779026
train_f-score_micro_sent: 0.6814138576779026
train_label=O_precision_tok: 0.9100729443470013
train_label=O_recall_tok: 0.9722389764127803
train_label=O_f-score_tok: 0.9401293995054202
train_label=N_precision_tok: 0.8018119068162208
train_label=N_recall_tok: 0.654344458526968
train_label=N_f-score_tok: 0.7206110421836228
train_label=P_precision_tok: 0.8847138750979879
train_label=P_recall_tok: 0.6766998441060079
train_label=P_f-score_tok: 0.7668508787823881
train_precision_macro_tok: 0.8655329087537367
train_recall_macro_tok: 0.7677610930152521
train_f-score_macro_tok: 0.8091971068238104
train_precision_micro_tok: 0.8994350904222149
train_recall_micro_tok: 0.8994350904222149
train_f-score_micro_tok: 0.8994350904222148
train_time: 199.4348373413086
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4578    0.0868    0.1460      1624
           N     0.6527    0.8187    0.7263      3310
           P     0.7275    0.8230    0.7723      3610

   micro avg     0.6814    0.6814    0.6814      8544
   macro avg     0.6127    0.5762    0.5482      8544
weighted avg     0.6472    0.6814    0.6354      8544

F1-macro sent:  0.5481998843352982
F1-micro sent:  0.6814138576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9101    0.9722    0.9401    124347
           N     0.8018    0.6543    0.7206     14202
           P     0.8847    0.6767    0.7669     25017

   micro avg     0.8994    0.8994    0.8994    163566
   macro avg     0.8655    0.7678    0.8092    163566
weighted avg     0.8968    0.8994    0.8946    163566

F1-macro tok:  0.8091971068238104
F1-micro tok:  0.8994350904222148
**************************************************
dev_cost_sum: 42630.960876464844
dev_cost_avg: 38.720218779713754
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19131.0
dev_accuracy_tok: 0.8992667105386857
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.6365217391304347
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7298105682951147
dev_label=P_precision_sent: 0.6980392156862745
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7463312368972747
dev_precision_macro_sent: 0.653186984938903
dev_recall_macro_sent: 0.566870036996144
dev_f-score_macro_sent: 0.5192581527512047
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9113997448683753
dev_label=O_recall_tok: 0.9699475470533786
dev_label=O_f-score_tok: 0.9397626378882545
dev_label=N_precision_tok: 0.7794601711652402
dev_label=N_recall_tok: 0.6375875067312871
dev_label=N_f-score_tok: 0.7014218009478673
dev_label=P_precision_tok: 0.8884017536867278
dev_label=P_recall_tok: 0.6939601494396015
dev_label=P_f-score_tok: 0.7792343995804928
dev_precision_macro_tok: 0.8597538899067811
dev_recall_macro_tok: 0.7671650677414222
dev_f-score_macro_tok: 0.8068062794722048
dev_precision_micro_tok: 0.8992667105386857
dev_recall_micro_tok: 0.8992667105386857
dev_f-score_micro_tok: 0.8992667105386858
dev_time: 10.992729902267456
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6365    0.8551    0.7298       428
           P     0.6980    0.8018    0.7463       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6532    0.5669    0.5193      1101
weighted avg     0.6589    0.6649    0.6017      1101

F1-macro sent:  0.5192581527512047
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9699    0.9398     16205
           N     0.7795    0.6376    0.7014      1857
           P     0.8884    0.6940    0.7792      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8598    0.7672    0.8068     21274
weighted avg     0.8964    0.8993    0.8947     21274

F1-macro tok:  0.8068062794722048
F1-micro tok:  0.8992667105386858
**************************************************
Best epoch: 20
**************************************************

EPOCH: 25
Learning rate: 0.656100
train_cost_sum: 308656.0417480469
train_cost_avg: 36.12547305103545
train_count_sent: 8544.0
train_total_correct_sent: 5866.0
train_accuracy_sent: 0.6865636704119851
train_count_tok: 163566.0
train_total_correct_tok: 147287.0
train_accuracy_tok: 0.9004744262254992
train_label=O_precision_sent: 0.5229357798165137
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.12377850162866451
train_label=N_precision_sent: 0.6570817490494296
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7355679702048417
train_label=P_precision_sent: 0.7253521126760564
train_label=P_recall_sent: 0.8274238227146814
train_label=P_f-score_sent: 0.7730331262939959
train_precision_macro_sent: 0.6351232138473333
train_recall_macro_sent: 0.5776560996912753
train_f-score_macro_sent: 0.5441265327091673
train_precision_micro_sent: 0.6865636704119851
train_recall_micro_sent: 0.6865636704119851
train_f-score_micro_sent: 0.6865636704119851
train_label=O_precision_tok: 0.9111532899493854
train_label=O_recall_tok: 0.9728582112958093
train_label=O_f-score_tok: 0.9409952744880694
train_label=N_precision_tok: 0.803798571179648
train_label=N_recall_tok: 0.649626813124912
train_label=N_f-score_tok: 0.7185358255451714
train_label=P_precision_tok: 0.8845238095238095
train_label=P_recall_tok: 0.6830954950633569
train_label=P_f-score_tok: 0.7708685747795295
train_precision_macro_tok: 0.8664918902176143
train_recall_macro_tok: 0.7685268398280259
train_f-score_macro_tok: 0.81013322493759
train_precision_micro_tok: 0.9004744262254992
train_recall_micro_tok: 0.9004744262254992
train_f-score_micro_tok: 0.9004744262254992
train_time: 198.77933597564697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5229    0.0702    0.1238      1624
           N     0.6571    0.8353    0.7356      3310
           P     0.7254    0.8274    0.7730      3610

   micro avg     0.6866    0.6866    0.6866      8544
   macro avg     0.6351    0.5777    0.5441      8544
weighted avg     0.6604    0.6866    0.6351      8544

F1-macro sent:  0.5441265327091673
F1-micro sent:  0.6865636704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9112    0.9729    0.9410    124347
           N     0.8038    0.6496    0.7185     14202
           P     0.8845    0.6831    0.7709     25017

   micro avg     0.9005    0.9005    0.9005    163566
   macro avg     0.8665    0.7685    0.8101    163566
weighted avg     0.8978    0.9005    0.8957    163566

F1-macro tok:  0.81013322493759
F1-micro tok:  0.9004744262254992
**************************************************
dev_cost_sum: 42504.482177734375
dev_cost_avg: 38.60534257741542
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19174.0
dev_accuracy_tok: 0.9012879571307699
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12749003984063745
dev_label=N_precision_sent: 0.682
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7349137931034483
dev_label=P_precision_sent: 0.6528497409326425
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.7390029325513195
dev_precision_macro_sent: 0.6873741560684566
dev_recall_macro_sent: 0.5726497729823853
dev_f-score_macro_sent: 0.533802255165135
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9072046770218376
dev_label=O_recall_tok: 0.9767355754396791
dev_label=O_f-score_tok: 0.9406870319743255
dev_label=N_precision_tok: 0.8152866242038217
dev_label=N_recall_tok: 0.6203554119547657
dev_label=N_f-score_tok: 0.7045871559633028
dev_label=P_precision_tok: 0.9088649544324772
dev_label=P_recall_tok: 0.6830635118306351
dev_label=P_f-score_tok: 0.7799502310700319
dev_precision_macro_tok: 0.8771187518860456
dev_recall_macro_tok: 0.7600514997416933
dev_f-score_macro_tok: 0.8084081396692201
dev_precision_micro_tok: 0.9012879571307699
dev_recall_micro_tok: 0.9012879571307699
dev_f-score_micro_tok: 0.9012879571307699
dev_time: 11.128450632095337
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0699    0.1275       229
           N     0.6820    0.7967    0.7349       428
           P     0.6528    0.8514    0.7390       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6874    0.5726    0.5338      1101
weighted avg     0.6797    0.6676    0.6102      1101

F1-macro sent:  0.533802255165135
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9072    0.9767    0.9407     16205
           N     0.8153    0.6204    0.7046      1857
           P     0.9089    0.6831    0.7800      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8771    0.7601    0.8084     21274
weighted avg     0.8994    0.9013    0.8958     21274

F1-macro tok:  0.8084081396692201
F1-micro tok:  0.9012879571307699
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 0.656100
train_cost_sum: 307477.5910644531
train_cost_avg: 35.98754577065228
train_count_sent: 8544.0
train_total_correct_sent: 5887.0
train_accuracy_sent: 0.6890215355805244
train_count_tok: 163566.0
train_total_correct_tok: 147403.0
train_accuracy_tok: 0.9011836200677402
train_label=O_precision_sent: 0.4715447154471545
train_label=O_recall_sent: 0.07142857142857142
train_label=O_f-score_sent: 0.12406417112299466
train_label=N_precision_sent: 0.6531184302733006
train_label=N_recall_sent: 0.8447129909365559
train_label=N_f-score_sent: 0.736661836385193
train_label=P_precision_sent: 0.7406024396315658
train_label=P_recall_sent: 0.8240997229916898
train_label=P_f-score_sent: 0.78012324636161
train_precision_macro_sent: 0.6217551951173403
train_recall_macro_sent: 0.5800804284522724
train_f-score_macro_sent: 0.5469497512899325
train_precision_micro_sent: 0.6890215355805244
train_recall_micro_sent: 0.6890215355805244
train_f-score_micro_sent: 0.6890215355805244
train_label=O_precision_tok: 0.9123315374051101
train_label=O_recall_tok: 0.9723113545159915
train_label=O_f-score_tok: 0.9413670002997636
train_label=N_precision_tok: 0.8059778852798894
train_label=N_recall_tok: 0.65694972539079
train_label=N_f-score_tok: 0.7238730700597409
train_label=P_precision_tok: 0.8819087733716868
train_label=P_recall_tok: 0.6862933205420314
train_label=P_f-score_tok: 0.7719006406653929
train_precision_macro_tok: 0.8667393986855622
train_recall_macro_tok: 0.7718514668162709
train_f-score_macro_tok: 0.8123802370082992
train_precision_micro_tok: 0.9011836200677402
train_recall_micro_tok: 0.9011836200677402
train_f-score_micro_tok: 0.9011836200677402
train_time: 200.14233493804932
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4715    0.0714    0.1241      1624
           N     0.6531    0.8447    0.7367      3310
           P     0.7406    0.8241    0.7801      3610

   micro avg     0.6890    0.6890    0.6890      8544
   macro avg     0.6218    0.5801    0.5469      8544
weighted avg     0.6556    0.6890    0.6386      8544

F1-macro sent:  0.5469497512899325
F1-micro sent:  0.6890215355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9723    0.9414    124347
           N     0.8060    0.6569    0.7239     14202
           P     0.8819    0.6863    0.7719     25017

   micro avg     0.9012    0.9012    0.9012    163566
   macro avg     0.8667    0.7719    0.8124    163566
weighted avg     0.8984    0.9012    0.8966    163566

F1-macro tok:  0.8123802370082992
F1-micro tok:  0.9011836200677402
**************************************************
dev_cost_sum: 42494.784423828125
dev_cost_avg: 38.59653444489385
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19102.0
dev_accuracy_tok: 0.8979035442323964
dev_label=O_precision_sent: 0.6470588235294118
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08943089430894309
dev_label=N_precision_sent: 0.5993788819875776
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.7201492537313432
dev_label=P_precision_sent: 0.7386363636363636
dev_label=P_recall_sent: 0.7319819819819819
dev_label=P_f-score_sent: 0.7352941176470589
dev_precision_macro_sent: 0.6616913563844511
dev_recall_macro_sent: 0.5606286917861011
dev_f-score_macro_sent: 0.5149580885624484
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9087127339958401
dev_label=O_recall_tok: 0.9705646405430423
dev_label=O_f-score_tok: 0.938620833706323
dev_label=N_precision_tok: 0.776673293571902
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6963755199049317
dev_label=P_precision_tok: 0.8962148962148963
dev_label=P_recall_tok: 0.6855541718555417
dev_label=P_f-score_tok: 0.7768565884635737
dev_precision_macro_tok: 0.8605336412608794
dev_recall_macro_tok: 0.7624147611962252
dev_f-score_macro_tok: 0.8039509806916095
dev_precision_micro_tok: 0.8979035442323964
dev_recall_micro_tok: 0.8979035442323964
dev_f-score_micro_tok: 0.8979035442323964
dev_time: 10.833539247512817
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6471    0.0480    0.0894       229
           N     0.5994    0.9019    0.7201       428
           P     0.7386    0.7320    0.7353       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6617    0.5606    0.5150      1101
weighted avg     0.6655    0.6558    0.5951      1101

F1-macro sent:  0.5149580885624484
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9087    0.9706    0.9386     16205
           N     0.7767    0.6311    0.6964      1857
           P     0.8962    0.6856    0.7769      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8605    0.7624    0.8040     21274
weighted avg     0.8953    0.8979    0.8931     21274

F1-macro tok:  0.8039509806916095
F1-micro tok:  0.8979035442323964
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 0.656100
train_cost_sum: 306380.7087402344
train_cost_avg: 35.8591653488102
train_count_sent: 8544.0
train_total_correct_sent: 5881.0
train_accuracy_sent: 0.6883192883895131
train_count_tok: 163566.0
train_total_correct_tok: 147741.0
train_accuracy_tok: 0.9032500641942702
train_label=O_precision_sent: 0.45323741007194246
train_label=O_recall_sent: 0.07758620689655173
train_label=O_f-score_sent: 0.13249211356466875
train_label=N_precision_sent: 0.667156862745098
train_label=N_recall_sent: 0.8223564954682779
train_label=N_f-score_sent: 0.7366711772665765
train_label=P_precision_sent: 0.7245580506450071
train_label=P_recall_sent: 0.8401662049861496
train_label=P_f-score_sent: 0.7780913288866085
train_precision_macro_sent: 0.6149841078206825
train_recall_macro_sent: 0.5800363024503264
train_f-score_macro_sent: 0.5490848732392846
train_precision_micro_sent: 0.6883192883895131
train_recall_micro_sent: 0.6883192883895131
train_f-score_micro_sent: 0.6883192883895131
train_label=O_precision_tok: 0.9138003957644144
train_label=O_recall_tok: 0.9729949254907637
train_label=O_f-score_tok: 0.9424691040666175
train_label=N_precision_tok: 0.8096171881660841
train_label=N_recall_tok: 0.6686382199690184
train_label=N_f-score_tok: 0.7324052292622729
train_label=P_precision_tok: 0.887882685875997
train_label=P_recall_tok: 0.68977095575009
train_label=P_f-score_tok: 0.7763880140376136
train_precision_macro_tok: 0.8704334232688318
train_recall_macro_tok: 0.7771347004032907
train_f-score_macro_tok: 0.8170874491221681
train_precision_micro_tok: 0.9032500641942702
train_recall_micro_tok: 0.9032500641942702
train_f-score_micro_tok: 0.9032500641942702
train_time: 199.95487332344055
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4532    0.0776    0.1325      1624
           N     0.6672    0.8224    0.7367      3310
           P     0.7246    0.8402    0.7781      3610

   micro avg     0.6883    0.6883    0.6883      8544
   macro avg     0.6150    0.5800    0.5491      8544
weighted avg     0.6507    0.6883    0.6393      8544

F1-macro sent:  0.5490848732392846
F1-micro sent:  0.6883192883895131
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9138    0.9730    0.9425    124347
           N     0.8096    0.6686    0.7324     14202
           P     0.8879    0.6898    0.7764     25017

   micro avg     0.9033    0.9033    0.9033    163566
   macro avg     0.8704    0.7771    0.8171    163566
weighted avg     0.9008    0.9033    0.8988    163566

F1-macro tok:  0.8170874491221681
F1-micro tok:  0.9032500641942702
**************************************************
dev_cost_sum: 42508.61553955078
dev_cost_avg: 38.60909676616783
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19124.0
dev_accuracy_tok: 0.8989376703957883
dev_label=O_precision_sent: 0.6521739130434783
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11904761904761904
dev_label=N_precision_sent: 0.6086261980830671
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.7229601518026565
dev_label=P_precision_sent: 0.7389380530973452
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7455357142857143
dev_precision_macro_sent: 0.6665793880746302
dev_recall_macro_sent: 0.5693137838487388
dev_f-score_macro_sent: 0.5291811617119966
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9103424340583064
dev_label=O_recall_tok: 0.9711817340327059
dev_label=O_f-score_tok: 0.939778461170991
dev_label=N_precision_tok: 0.7650411652944902
dev_label=N_recall_tok: 0.650511577813678
dev_label=N_f-score_tok: 0.7031431897555296
dev_label=P_precision_tok: 0.9048608226007478
dev_label=P_recall_tok: 0.678082191780822
dev_label=P_f-score_tok: 0.7752269087026161
dev_precision_macro_tok: 0.8600814739845148
dev_recall_macro_tok: 0.766591834542402
dev_f-score_macro_tok: 0.806049519876379
dev_precision_micro_tok: 0.8989376703957883
dev_recall_micro_tok: 0.8989376703957883
dev_f-score_micro_tok: 0.8989376703957883
dev_time: 11.063430547714233
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6522    0.0655    0.1190       229
           N     0.6086    0.8902    0.7230       428
           P     0.7389    0.7523    0.7455       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6666    0.5693    0.5292      1101
weighted avg     0.6702    0.6630    0.6065      1101

F1-macro sent:  0.5291811617119966
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9103    0.9712    0.9398     16205
           N     0.7650    0.6505    0.7031      1857
           P     0.9049    0.6781    0.7752      3212

   micro avg     0.8989    0.8989    0.8989     21274
   macro avg     0.8601    0.7666    0.8060     21274
weighted avg     0.8968    0.8989    0.8943     21274

F1-macro tok:  0.806049519876379
F1-micro tok:  0.8989376703957883
**************************************************
Best epoch: 25
**************************************************

EPOCH: 28
Learning rate: 0.656100
train_cost_sum: 305100.8674926758
train_cost_avg: 35.70937119530382
train_count_sent: 8544.0
train_total_correct_sent: 5907.0
train_accuracy_sent: 0.6913623595505618
train_count_tok: 163566.0
train_total_correct_tok: 147848.0
train_accuracy_tok: 0.9039042343763374
train_label=O_precision_sent: 0.509090909090909
train_label=O_recall_sent: 0.08620689655172414
train_label=O_f-score_sent: 0.1474460242232754
train_label=N_precision_sent: 0.6700804681784931
train_label=N_recall_sent: 0.8302114803625378
train_label=N_f-score_sent: 0.7416003238429362
train_label=P_precision_sent: 0.7243282149712092
train_label=P_recall_sent: 0.8362880886426592
train_label=P_f-score_sent: 0.7762921059398302
train_precision_macro_sent: 0.6344998640802038
train_recall_macro_sent: 0.5842354885189738
train_f-score_macro_sent: 0.555112818002014
train_precision_micro_sent: 0.6913623595505618
train_recall_micro_sent: 0.6913623595505618
train_f-score_micro_sent: 0.6913623595505618
train_label=O_precision_tok: 0.9153801306853028
train_label=O_recall_tok: 0.9722550604357162
train_label=O_f-score_tok: 0.9429607674908353
train_label=N_precision_tok: 0.8091914893617022
train_label=N_recall_tok: 0.669483171384312
train_label=N_f-score_tok: 0.7327373612823674
train_label=P_precision_tok: 0.8835030137263841
train_label=P_recall_tok: 0.6972458728064916
train_label=P_f-score_tok: 0.7794012511170688
train_precision_macro_tok: 0.8693582112577963
train_recall_macro_tok: 0.7796613682088399
train_f-score_macro_tok: 0.8183664599634239
train_precision_micro_tok: 0.9039042343763374
train_recall_micro_tok: 0.9039042343763374
train_f-score_micro_tok: 0.9039042343763374
train_time: 199.4314124584198
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5091    0.0862    0.1474      1624
           N     0.6701    0.8302    0.7416      3310
           P     0.7243    0.8363    0.7763      3610

   micro avg     0.6914    0.6914    0.6914      8544
   macro avg     0.6345    0.5842    0.5551      8544
weighted avg     0.6624    0.6914    0.6433      8544

F1-macro sent:  0.555112818002014
F1-micro sent:  0.6913623595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9154    0.9723    0.9430    124347
           N     0.8092    0.6695    0.7327     14202
           P     0.8835    0.6972    0.7794     25017

   micro avg     0.9039    0.9039    0.9039    163566
   macro avg     0.8694    0.7797    0.8184    163566
weighted avg     0.9013    0.9039    0.8997    163566

F1-macro tok:  0.8183664599634239
F1-micro tok:  0.9039042343763374
**************************************************
dev_cost_sum: 42453.355712890625
dev_cost_avg: 38.55890618791156
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19158.0
dev_accuracy_tok: 0.9005358653755758
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.140625
dev_label=N_precision_sent: 0.6433566433566433
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7359999999999999
dev_label=P_precision_sent: 0.703187250996016
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7463002114164905
dev_precision_macro_sent: 0.671070187006442
dev_recall_macro_sent: 0.5778202497481769
dev_f-score_macro_sent: 0.5409750704721635
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9029528676888132
dev_label=O_recall_tok: 0.981240357914224
dev_label=O_f-score_tok: 0.9404702055300902
dev_label=N_precision_tok: 0.8356269113149847
dev_label=N_recall_tok: 0.5885837372105547
dev_label=N_f-score_tok: 0.6906793048973143
dev_label=P_precision_tok: 0.9185059422750425
dev_label=P_recall_tok: 0.6737235367372354
dev_label=P_f-score_tok: 0.7772988505747126
dev_precision_macro_tok: 0.8856952404262802
dev_recall_macro_tok: 0.7478492106206714
dev_f-score_macro_tok: 0.802816120334039
dev_precision_micro_tok: 0.9005358653755758
dev_recall_micro_tok: 0.9005358653755758
dev_f-score_micro_tok: 0.9005358653755758
dev_time: 10.950265169143677
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0786    0.1406       229
           N     0.6434    0.8598    0.7360       428
           P     0.7032    0.7950    0.7463       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6711    0.5778    0.5410      1101
weighted avg     0.6723    0.6712    0.6163      1101

F1-macro sent:  0.5409750704721635
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9030    0.9812    0.9405     16205
           N     0.8356    0.5886    0.6907      1857
           P     0.9185    0.6737    0.7773      3212

   micro avg     0.9005    0.9005    0.9005     21274
   macro avg     0.8857    0.7478    0.8028     21274
weighted avg     0.8994    0.9005    0.8940     21274

F1-macro tok:  0.802816120334039
F1-micro tok:  0.9005358653755758
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.656100
train_cost_sum: 303848.1831665039
train_cost_avg: 35.56275552042415
train_count_sent: 8544.0
train_total_correct_sent: 5935.0
train_accuracy_sent: 0.6946395131086143
train_count_tok: 163566.0
train_total_correct_tok: 148130.0
train_accuracy_tok: 0.9056283090617855
train_label=O_precision_sent: 0.5092592592592593
train_label=O_recall_sent: 0.06773399014778325
train_label=O_f-score_sent: 0.11956521739130435
train_label=N_precision_sent: 0.6661089866156787
train_label=N_recall_sent: 0.8419939577039275
train_label=N_f-score_sent: 0.7437950360288231
train_label=P_precision_sent: 0.7331081081081081
train_label=P_recall_sent: 0.8415512465373961
train_label=P_f-score_sent: 0.7835955635800878
train_precision_macro_sent: 0.6361587846610154
train_recall_macro_sent: 0.5837597314630356
train_f-score_macro_sent: 0.5489852723334051
train_precision_micro_sent: 0.6946395131086143
train_recall_micro_sent: 0.6946395131086143
train_f-score_micro_sent: 0.6946395131086143
train_label=O_precision_tok: 0.9170950279761634
train_label=O_recall_tok: 0.9727858331925981
train_label=O_f-score_tok: 0.9441198852660541
train_label=N_precision_tok: 0.8117211182216234
train_label=N_recall_tok: 0.6787776369525419
train_label=N_f-score_tok: 0.7393205000383465
train_label=P_precision_tok: 0.8855598221503638
train_label=P_recall_tok: 0.7006035895590998
train_label=P_f-score_tok: 0.7822981990225178
train_precision_macro_tok: 0.8714586561160503
train_recall_macro_tok: 0.78405568656808
train_f-score_macro_tok: 0.8219128614423061
train_precision_micro_tok: 0.9056283090617855
train_recall_micro_tok: 0.9056283090617855
train_f-score_micro_tok: 0.9056283090617855
train_time: 200.46455550193787
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5093    0.0677    0.1196      1624
           N     0.6661    0.8420    0.7438      3310
           P     0.7331    0.8416    0.7836      3610

   micro avg     0.6946    0.6946    0.6946      8544
   macro avg     0.6362    0.5838    0.5490      8544
weighted avg     0.6646    0.6946    0.6420      8544

F1-macro sent:  0.5489852723334051
F1-micro sent:  0.6946395131086143
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9171    0.9728    0.9441    124347
           N     0.8117    0.6788    0.7393     14202
           P     0.8856    0.7006    0.7823     25017

   micro avg     0.9056    0.9056    0.9056    163566
   macro avg     0.8715    0.7841    0.8219    163566
weighted avg     0.9031    0.9056    0.9016    163566

F1-macro tok:  0.8219128614423061
F1-micro tok:  0.9056283090617855
**************************************************
dev_cost_sum: 42384.80261230469
dev_cost_avg: 38.49664179137574
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.7158836689038032
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.7314285714285714
dev_label=P_precision_sent: 0.6291079812206573
dev_label=P_recall_sent: 0.9054054054054054
dev_label=P_f-score_sent: 0.7423822714681441
dev_precision_macro_sent: 0.6927749944859313
dev_recall_macro_sent: 0.5670346304350303
dev_f-score_macro_sent: 0.521324925774315
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9129929720624964
dev_label=O_recall_tok: 0.9700092564023449
dev_label=O_f-score_tok: 0.9406379031775477
dev_label=N_precision_tok: 0.7871352785145889
dev_label=N_recall_tok: 0.6392030156165859
dev_label=N_f-score_tok: 0.7054977711738484
dev_label=P_precision_tok: 0.8854452726559435
dev_label=P_recall_tok: 0.7026774595267746
dev_label=P_f-score_tok: 0.7835445235202222
dev_precision_macro_tok: 0.8618578410776762
dev_recall_macro_tok: 0.7706299105152352
dev_f-score_macro_tok: 0.8098933992905395
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 10.817337989807129
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.7159    0.7477    0.7314       428
           P     0.6291    0.9054    0.7424       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6928    0.5670    0.5213      1101
weighted avg     0.6845    0.6658    0.6025      1101

F1-macro sent:  0.521324925774315
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9130    0.9700    0.9406     16205
           N     0.7871    0.6392    0.7055      1857
           P     0.8854    0.7027    0.7835      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8619    0.7706    0.8099     21274
weighted avg     0.8978    0.9008    0.8964     21274

F1-macro tok:  0.8098933992905395
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.656100
train_cost_sum: 303157.76971435547
train_cost_avg: 35.48194870252288
train_count_sent: 8544.0
train_total_correct_sent: 5919.0
train_accuracy_sent: 0.6927668539325843
train_count_tok: 163566.0
train_total_correct_tok: 148191.0
train_accuracy_tok: 0.9060012472029639
train_label=O_precision_sent: 0.4883720930232558
train_label=O_recall_sent: 0.09051724137931035
train_label=O_f-score_sent: 0.1527272727272727
train_label=N_precision_sent: 0.6753913894324853
train_label=N_recall_sent: 0.8341389728096676
train_label=N_f-score_sent: 0.7464179507975128
train_label=P_precision_sent: 0.7246690734055355
train_label=P_recall_sent: 0.8340720221606648
train_label=P_f-score_sent: 0.7755312298776563
train_precision_macro_sent: 0.6294775186204254
train_recall_macro_sent: 0.586242745449881
train_f-score_macro_sent: 0.5582254844674807
train_precision_micro_sent: 0.6927668539325843
train_recall_micro_sent: 0.6927668539325843
train_f-score_micro_sent: 0.6927668539325843
train_label=O_precision_tok: 0.9178709476545948
train_label=O_recall_tok: 0.9720218421031468
train_label=O_f-score_tok: 0.9441706050072257
train_label=N_precision_tok: 0.8118628359592215
train_label=N_recall_tok: 0.6784959864807774
train_label=N_f-score_tok: 0.7392121514326263
train_label=P_precision_tok: 0.8837313880283801
train_label=P_recall_tok: 0.7069992405164488
train_label=P_f-score_tok: 0.7855477337833937
train_precision_macro_tok: 0.8711550572140654
train_recall_macro_tok: 0.7858390230334577
train_f-score_macro_tok: 0.8229768300744152
train_precision_micro_tok: 0.9060012472029639
train_recall_micro_tok: 0.9060012472029639
train_f-score_micro_tok: 0.9060012472029639
train_time: 184.46351146697998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4884    0.0905    0.1527      1624
           N     0.6754    0.8341    0.7464      3310
           P     0.7247    0.8341    0.7755      3610

   micro avg     0.6928    0.6928    0.6928      8544
   macro avg     0.6295    0.5862    0.5582      8544
weighted avg     0.6607    0.6928    0.6459      8544

F1-macro sent:  0.5582254844674807
F1-micro sent:  0.6927668539325843
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9179    0.9720    0.9442    124347
           N     0.8119    0.6785    0.7392     14202
           P     0.8837    0.7070    0.7855     25017

   micro avg     0.9060    0.9060    0.9060    163566
   macro avg     0.8712    0.7858    0.8230    163566
weighted avg     0.9034    0.9060    0.9021    163566

F1-macro tok:  0.8229768300744152
F1-micro tok:  0.9060012472029639
**************************************************
dev_cost_sum: 42374.74353027344
dev_cost_avg: 38.48750547708759
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19159.0
dev_accuracy_tok: 0.9005828711102755
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.16793893129770993
dev_label=N_precision_sent: 0.643979057591623
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7372627372627374
dev_label=P_precision_sent: 0.7171717171717171
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7561235356762512
dev_precision_macro_sent: 0.6759391471433357
dev_recall_macro_sent: 0.5859229837518211
dev_f-score_macro_sent: 0.5537750680788995
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9109787135585378
dev_label=O_recall_tok: 0.971860536871336
dev_label=O_f-score_tok: 0.9404353148419072
dev_label=N_precision_tok: 0.8051675977653632
dev_label=N_recall_tok: 0.620893914916532
dev_label=N_f-score_tok: 0.7011249619945272
dev_label=P_precision_tok: 0.8837118245888802
dev_label=P_recall_tok: 0.7026774595267746
dev_label=P_f-score_tok: 0.7828650711064863
dev_precision_macro_tok: 0.8666193786375938
dev_recall_macro_tok: 0.7651439704382142
dev_f-score_macro_tok: 0.8081417826476401
dev_precision_micro_tok: 0.9005828711102755
dev_recall_micro_tok: 0.9005828711102755
dev_f-score_micro_tok: 0.9005828711102755
dev_time: 7.26748251914978
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0961    0.1679       229
           N     0.6440    0.8621    0.7373       428
           P     0.7172    0.7995    0.7561       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6759    0.5859    0.5538      1101
weighted avg     0.6782    0.6776    0.6265      1101

F1-macro sent:  0.5537750680788995
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9719    0.9404     16205
           N     0.8052    0.6209    0.7011      1857
           P     0.8837    0.7027    0.7829      3212

   micro avg     0.9006    0.9006    0.9006     21274
   macro avg     0.8666    0.7651    0.8081     21274
weighted avg     0.8976    0.9006    0.8958     21274

F1-macro tok:  0.8081417826476401
F1-micro tok:  0.9005828711102755
**************************************************
Best epoch: 30
**************************************************

EPOCH: 31
Learning rate: 0.656100
train_cost_sum: 301584.52380371094
train_cost_avg: 35.29781411560287
train_count_sent: 8544.0
train_total_correct_sent: 5937.0
train_accuracy_sent: 0.694873595505618
train_count_tok: 163566.0
train_total_correct_tok: 148537.0
train_accuracy_tok: 0.9081166012496484
train_label=O_precision_sent: 0.48398576512455516
train_label=O_recall_sent: 0.08374384236453201
train_label=O_f-score_sent: 0.1427821522309711
train_label=N_precision_sent: 0.6690838772057046
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.743386598630321
train_label=P_precision_sent: 0.7350945225399903
train_label=P_recall_sent: 0.8401662049861496
train_label=P_f-score_sent: 0.7841261633919338
train_precision_macro_sent: 0.62938805495675
train_recall_macro_sent: 0.5867212745952423
train_f-score_macro_sent: 0.556764971417742
train_precision_micro_sent: 0.694873595505618
train_recall_micro_sent: 0.694873595505618
train_f-score_micro_sent: 0.694873595505618
train_label=O_precision_tok: 0.9200009133184666
train_label=O_recall_tok: 0.9721022622178259
train_label=O_f-score_tok: 0.9453342509462883
train_label=N_precision_tok: 0.8173862310385064
train_label=N_recall_tok: 0.6905365441487115
train_label=N_f-score_tok: 0.7486259541984733
train_label=P_precision_tok: 0.8846820952475346
train_label=P_recall_tok: 0.713594755566215
train_label=P_f-score_tok: 0.7899814142844501
train_precision_macro_tok: 0.8740230798681692
train_recall_macro_tok: 0.7920778539775841
train_f-score_macro_tok: 0.8279805398097372
train_precision_micro_tok: 0.9081166012496484
train_recall_micro_tok: 0.9081166012496484
train_f-score_micro_tok: 0.9081166012496484
train_time: 147.53953218460083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4840    0.0837    0.1428      1624
           N     0.6691    0.8363    0.7434      3310
           P     0.7351    0.8402    0.7841      3610

   micro avg     0.6949    0.6949    0.6949      8544
   macro avg     0.6294    0.5867    0.5568      8544
weighted avg     0.6618    0.6949    0.6464      8544

F1-macro sent:  0.556764971417742
F1-micro sent:  0.694873595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9200    0.9721    0.9453    124347
           N     0.8174    0.6905    0.7486     14202
           P     0.8847    0.7136    0.7900     25017

   micro avg     0.9081    0.9081    0.9081    163566
   macro avg     0.8740    0.7921    0.8280    163566
weighted avg     0.9057    0.9081    0.9045    163566

F1-macro tok:  0.8279805398097372
F1-micro tok:  0.9081166012496484
**************************************************
dev_cost_sum: 42318.877014160156
dev_cost_avg: 38.43676386390568
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19171.0
dev_accuracy_tok: 0.901146939926671
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08196721311475409
dev_label=N_precision_sent: 0.6617375231053605
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.73890608875129
dev_label=P_precision_sent: 0.6825688073394496
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7522750252780586
dev_precision_macro_sent: 0.6703243323704923
dev_recall_macro_sent: 0.5726515194131404
dev_f-score_macro_sent: 0.5243827757147009
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.9097614382851216
dev_label=O_recall_tok: 0.9742672014810244
dev_label=O_f-score_tok: 0.940910039035728
dev_label=N_precision_tok: 0.8082001389854065
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.7057038834951456
dev_label=P_precision_tok: 0.8948004836759371
dev_label=P_recall_tok: 0.6911581569115816
dev_label=P_f-score_tok: 0.7799051466713508
dev_precision_macro_tok: 0.8709206869821551
dev_recall_macro_tok: 0.7639014343089338
dev_f-score_macro_tok: 0.8088396897340747
dev_precision_micro_tok: 0.901146939926671
dev_recall_micro_tok: 0.901146939926671
dev_f-score_micro_tok: 0.901146939926671
dev_time: 7.036251544952393
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0437    0.0820       229
           N     0.6617    0.8364    0.7389       428
           P     0.6826    0.8378    0.7523       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6703    0.5727    0.5244      1101
weighted avg     0.6712    0.6721    0.6077      1101

F1-macro sent:  0.5243827757147009
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9098    0.9743    0.9409     16205
           N     0.8082    0.6263    0.7057      1857
           P     0.8948    0.6912    0.7799      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8709    0.7639    0.8088     21274
weighted avg     0.8986    0.9011    0.8961     21274

F1-macro tok:  0.8088396897340747
F1-micro tok:  0.901146939926671
**************************************************
Best epoch: 30
**************************************************

EPOCH: 32
Learning rate: 0.656100
train_cost_sum: 300917.87774658203
train_cost_avg: 35.219789062099956
train_count_sent: 8544.0
train_total_correct_sent: 5946.0
train_accuracy_sent: 0.6959269662921348
train_count_tok: 163566.0
train_total_correct_tok: 148684.0
train_accuracy_tok: 0.9090153210324884
train_label=O_precision_sent: 0.4921875
train_label=O_recall_sent: 0.07758620689655173
train_label=O_f-score_sent: 0.13404255319148936
train_label=N_precision_sent: 0.6689754000477669
train_label=N_recall_sent: 0.8462235649546828
train_label=N_f-score_sent: 0.7472322262238228
train_label=P_precision_sent: 0.7361619117288466
train_label=P_recall_sent: 0.8362880886426592
train_label=P_f-score_sent: 0.7830372195564776
train_precision_macro_sent: 0.6324416039255379
train_recall_macro_sent: 0.5866992868312979
train_f-score_macro_sent: 0.5547706663239299
train_precision_micro_sent: 0.6959269662921348
train_recall_micro_sent: 0.6959269662921348
train_f-score_micro_sent: 0.6959269662921348
train_label=O_precision_tok: 0.9208211813619853
train_label=O_recall_tok: 0.9724802367568176
train_label=O_f-score_tok: 0.9459459459459459
train_label=N_precision_tok: 0.8195889157027544
train_label=N_recall_tok: 0.6934938741022392
train_label=N_f-score_tok: 0.7512872344483008
train_label=P_precision_tok: 0.8854939187184812
train_label=P_recall_tok: 0.715913179038254
train_label=P_f-score_tok: 0.7917246866918639
train_precision_macro_tok: 0.875301338594407
train_recall_macro_tok: 0.7939624299657703
train_f-score_macro_tok: 0.8296526223620369
train_precision_micro_tok: 0.9090153210324884
train_recall_micro_tok: 0.9090153210324884
train_f-score_micro_tok: 0.9090153210324885
train_time: 101.1747772693634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4922    0.0776    0.1340      1624
           N     0.6690    0.8462    0.7472      3310
           P     0.7362    0.8363    0.7830      3610

   micro avg     0.6959    0.6959    0.6959      8544
   macro avg     0.6324    0.5867    0.5548      8544
weighted avg     0.6638    0.6959    0.6458      8544

F1-macro sent:  0.5547706663239299
F1-micro sent:  0.6959269662921348
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9208    0.9725    0.9459    124347
           N     0.8196    0.6935    0.7513     14202
           P     0.8855    0.7159    0.7917     25017

   micro avg     0.9090    0.9090    0.9090    163566
   macro avg     0.8753    0.7940    0.8297    163566
weighted avg     0.9066    0.9090    0.9055    163566

F1-macro tok:  0.8296526223620369
F1-micro tok:  0.9090153210324885
**************************************************
dev_cost_sum: 42392.281005859375
dev_cost_avg: 38.50343415609389
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11857707509881421
dev_label=N_precision_sent: 0.6833667334669339
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7357065803667745
dev_label=P_precision_sent: 0.6678200692041523
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7553816046966733
dev_precision_macro_sent: 0.6587289342236954
dev_recall_macro_sent: 0.5772001749126999
dev_f-score_macro_sent: 0.536555086720754
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9116335630320227
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.9406106231702217
dev_label=N_precision_tok: 0.800548320767649
dev_label=N_recall_tok: 0.6289714593430263
dev_label=N_f-score_tok: 0.7044632086851629
dev_label=P_precision_tok: 0.8845247446975648
dev_label=P_recall_tok: 0.701120797011208
dev_label=P_f-score_tok: 0.7822160472386245
dev_precision_macro_tok: 0.8655688761657455
dev_recall_macro_tok: 0.7671941790439241
dev_f-score_macro_tok: 0.8090966263646697
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 5.101886034011841
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0655    0.1186       229
           N     0.6834    0.7967    0.7357       428
           P     0.6678    0.8694    0.7554       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6587    0.5772    0.5366      1101
weighted avg     0.6650    0.6739    0.6153      1101

F1-macro sent:  0.536555086720754
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9116    0.9715    0.9406     16205
           N     0.8005    0.6290    0.7045      1857
           P     0.8845    0.7011    0.7822      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8656    0.7672    0.8091     21274
weighted avg     0.8978    0.9008    0.8961     21274

F1-macro tok:  0.8090966263646697
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 30
**************************************************

EPOCH: 33
Learning rate: 0.656100
train_cost_sum: 299911.5354003906
train_cost_avg: 35.10200554779853
train_count_sent: 8544.0
train_total_correct_sent: 6022.0
train_accuracy_sent: 0.7048220973782772
train_count_tok: 163566.0
train_total_correct_tok: 148847.0
train_accuracy_tok: 0.9100118606556374
train_label=O_precision_sent: 0.5284280936454849
train_label=O_recall_sent: 0.09729064039408868
train_label=O_f-score_sent: 0.16432657306292253
train_label=N_precision_sent: 0.6789676796912687
train_label=N_recall_sent: 0.850453172205438
train_label=N_f-score_sent: 0.7550965665236051
train_label=P_precision_sent: 0.7438399609660893
train_label=P_recall_sent: 0.8445983379501385
train_label=P_f-score_sent: 0.7910234790504606
train_precision_macro_sent: 0.650411911434281
train_recall_macro_sent: 0.5974473835165551
train_f-score_macro_sent: 0.5701488728789961
train_precision_micro_sent: 0.7048220973782772
train_recall_micro_sent: 0.7048220973782772
train_f-score_micro_sent: 0.7048220973782772
train_label=O_precision_tok: 0.9221059700695223
train_label=O_recall_tok: 0.9717162456673664
train_label=O_f-score_tok: 0.9462613162923283
train_label=N_precision_tok: 0.8199966865473823
train_label=N_recall_tok: 0.6970145049992958
train_label=N_f-score_tok: 0.7535205906980285
train_label=P_precision_tok: 0.8856626093757638
train_label=P_recall_tok: 0.7242275252828076
train_label=P_f-score_tok: 0.796850947794344
train_precision_macro_tok: 0.8759217553308895
train_recall_macro_tok: 0.7976527586498232
train_f-score_macro_tok: 0.8322109515949002
train_precision_micro_tok: 0.9100118606556374
train_recall_micro_tok: 0.9100118606556374
train_f-score_micro_tok: 0.9100118606556374
train_time: 96.04463601112366
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5284    0.0973    0.1643      1624
           N     0.6790    0.8505    0.7551      3310
           P     0.7438    0.8446    0.7910      3610

   micro avg     0.7048    0.7048    0.7048      8544
   macro avg     0.6504    0.5974    0.5701      8544
weighted avg     0.6778    0.7048    0.6580      8544

F1-macro sent:  0.5701488728789961
F1-micro sent:  0.7048220973782772
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9221    0.9717    0.9463    124347
           N     0.8200    0.6970    0.7535     14202
           P     0.8857    0.7242    0.7969     25017

   micro avg     0.9100    0.9100    0.9100    163566
   macro avg     0.8759    0.7977    0.8322    163566
weighted avg     0.9077    0.9100    0.9067    163566

F1-macro tok:  0.8322109515949002
F1-micro tok:  0.9100118606556374
**************************************************
dev_cost_sum: 42310.92053222656
dev_cost_avg: 38.42953726814402
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19183.0
dev_accuracy_tok: 0.9017110087430666
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08196721311475409
dev_label=N_precision_sent: 0.6792079207920793
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7352625937834941
dev_label=P_precision_sent: 0.6643717728055077
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7531707317073171
dev_precision_macro_sent: 0.6700821200880845
dev_recall_macro_sent: 0.5714797869329967
dev_f-score_macro_sent: 0.5234668462018551
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9137530491346265
dev_label=O_recall_tok: 0.9708731872878741
dev_label=O_f-score_tok: 0.9414475062082996
dev_label=N_precision_tok: 0.7859947643979057
dev_label=N_recall_tok: 0.6467420570813139
dev_label=N_f-score_tok: 0.7096011816838996
dev_label=P_precision_tok: 0.8896360759493671
dev_label=P_recall_tok: 0.700186799501868
dev_label=P_f-score_tok: 0.783623693379791
dev_precision_macro_tok: 0.8631279631606331
dev_recall_macro_tok: 0.772600681290352
dev_f-score_macro_tok: 0.8115574604239968
dev_precision_micro_tok: 0.9017110087430666
dev_recall_micro_tok: 0.9017110087430666
dev_f-score_micro_tok: 0.9017110087430666
dev_time: 4.979629993438721
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0437    0.0820       229
           N     0.6792    0.8014    0.7353       428
           P     0.6644    0.8694    0.7532       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6701    0.5715    0.5235      1101
weighted avg     0.6706    0.6712    0.6066      1101

F1-macro sent:  0.5234668462018551
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9138    0.9709    0.9414     16205
           N     0.7860    0.6467    0.7096      1857
           P     0.8896    0.7002    0.7836      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8631    0.7726    0.8116     21274
weighted avg     0.8990    0.9017    0.8974     21274

F1-macro tok:  0.8115574604239968
F1-micro tok:  0.9017110087430666
**************************************************
Best epoch: 30
**************************************************

EPOCH: 34
Learning rate: 0.656100
train_cost_sum: 298835.3411254883
train_cost_avg: 34.9760464800431
train_count_sent: 8544.0
train_total_correct_sent: 6025.0
train_accuracy_sent: 0.7051732209737828
train_count_tok: 163566.0
train_total_correct_tok: 149008.0
train_accuracy_tok: 0.9109961727987479
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15767634854771784
train_label=N_precision_sent: 0.6808252427184466
train_label=N_recall_sent: 0.8474320241691843
train_label=N_f-score_sent: 0.7550471063257065
train_label=P_precision_sent: 0.7446601941747573
train_label=P_recall_sent: 0.8498614958448754
train_label=P_f-score_sent: 0.79379042690815
train_precision_macro_sent: 0.6418284789644013
train_recall_macro_sent: 0.5969631930424534
train_f-score_macro_sent: 0.5688379605938582
train_precision_micro_sent: 0.7051732209737828
train_recall_micro_sent: 0.7051732209737828
train_f-score_micro_sent: 0.7051732209737828
train_label=O_precision_tok: 0.9236689058547508
train_label=O_recall_tok: 0.9719816320458073
train_label=O_f-score_tok: 0.9472096176302323
train_label=N_precision_tok: 0.8178246992388902
train_label=N_recall_tok: 0.7036332910857626
train_label=N_f-score_tok: 0.7564437379357329
train_label=P_precision_tok: 0.8856362217017955
train_label=P_recall_tok: 0.7255866011112444
train_label=P_f-score_tok: 0.7976622064025664
train_precision_macro_tok: 0.8757099422651455
train_recall_macro_tok: 0.800400508080938
train_f-score_macro_tok: 0.8337718539895106
train_precision_micro_tok: 0.9109961727987479
train_recall_micro_tok: 0.9109961727987479
train_f-score_micro_tok: 0.9109961727987479
train_time: 95.40731835365295
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0936    0.1577      1624
           N     0.6808    0.8474    0.7550      3310
           P     0.7447    0.8499    0.7938      3610

   micro avg     0.7052    0.7052    0.7052      8544
   macro avg     0.6418    0.5970    0.5688      8544
weighted avg     0.6734    0.7052    0.6579      8544

F1-macro sent:  0.5688379605938582
F1-micro sent:  0.7051732209737828
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9237    0.9720    0.9472    124347
           N     0.8178    0.7036    0.7564     14202
           P     0.8856    0.7256    0.7977     25017

   micro avg     0.9110    0.9110    0.9110    163566
   macro avg     0.8757    0.8004    0.8338    163566
weighted avg     0.9087    0.9110    0.9078    163566

F1-macro tok:  0.8337718539895106
F1-micro tok:  0.9109961727987479
**************************************************
dev_cost_sum: 42348.32067871094
dev_cost_avg: 38.463506520173425
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19121.0
dev_accuracy_tok: 0.8987966531916893
dev_label=O_precision_sent: 0.65625
dev_label=O_recall_sent: 0.09170305676855896
dev_label=O_f-score_sent: 0.16091954022988508
dev_label=N_precision_sent: 0.6557377049180327
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7369498464687819
dev_label=P_precision_sent: 0.7019230769230769
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7572614107883818
dev_precision_macro_sent: 0.6713035939470364
dev_recall_macro_sent: 0.5849655413892446
dev_f-score_macro_sent: 0.5517102658290163
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9127094972067039
dev_label=O_recall_tok: 0.967849429188522
dev_label=O_f-score_tok: 0.9394710832909041
dev_label=N_precision_tok: 0.7972789115646258
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.7045386233844305
dev_label=P_precision_tok: 0.8645038167938931
dev_label=P_recall_tok: 0.7051681195516812
dev_label=P_f-score_tok: 0.7767489711934156
dev_precision_macro_tok: 0.8581640751884075
dev_recall_macro_tok: 0.7680476733100982
dev_f-score_macro_tok: 0.8069195592895834
dev_precision_micro_tok: 0.8987966531916893
dev_recall_micro_tok: 0.8987966531916893
dev_f-score_micro_tok: 0.8987966531916893
dev_time: 5.201015472412109
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6562    0.0917    0.1609       229
           N     0.6557    0.8411    0.7369       428
           P     0.7019    0.8221    0.7573       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6713    0.5850    0.5517      1101
weighted avg     0.6745    0.6776    0.6253      1101

F1-macro sent:  0.5517102658290163
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9127    0.9678    0.9395     16205
           N     0.7973    0.6311    0.7045      1857
           P     0.8645    0.7052    0.7767      3212

   micro avg     0.8988    0.8988    0.8988     21274
   macro avg     0.8582    0.7680    0.8069     21274
weighted avg     0.8954    0.8988    0.8944     21274

F1-macro tok:  0.8069195592895834
F1-micro tok:  0.8987966531916893
**************************************************
Best epoch: 30
**************************************************

EPOCH: 35
Learning rate: 0.590490
train_cost_sum: 297634.9793701172
train_cost_avg: 34.83555470155866
train_count_sent: 8544.0
train_total_correct_sent: 5992.0
train_accuracy_sent: 0.701310861423221
train_count_tok: 163566.0
train_total_correct_tok: 149389.0
train_accuracy_tok: 0.9133255077461087
train_label=O_precision_sent: 0.4782608695652174
train_label=O_recall_sent: 0.09482758620689655
train_label=O_f-score_sent: 0.15827338129496402
train_label=N_precision_sent: 0.6823442501846836
train_label=N_recall_sent: 0.8371601208459214
train_label=N_f-score_sent: 0.7518654185320852
train_label=P_precision_sent: 0.7370824321076664
train_label=P_recall_sent: 0.849584487534626
train_label=P_f-score_sent: 0.7893450006434178
train_precision_macro_sent: 0.6325625172858559
train_recall_macro_sent: 0.5938573981958147
train_f-score_macro_sent: 0.5664946001568224
train_precision_micro_sent: 0.701310861423221
train_recall_micro_sent: 0.701310861423221
train_f-score_micro_sent: 0.701310861423221
train_label=O_precision_tok: 0.9257407549192251
train_label=O_recall_tok: 0.9723676485962669
train_label=O_f-score_tok: 0.9484815086465561
train_label=N_precision_tok: 0.8259803921568627
train_label=N_recall_tok: 0.7118715673848753
train_label=N_f-score_tok: 0.764692534604039
train_label=P_precision_tok: 0.886657655918131
train_label=P_recall_tok: 0.7342207299036655
train_label=P_f-score_tok: 0.8032711608685194
train_precision_macro_tok: 0.879459600998073
train_recall_macro_tok: 0.806153315294936
train_f-score_macro_tok: 0.8388150680397048
train_precision_micro_tok: 0.9133255077461087
train_recall_micro_tok: 0.9133255077461087
train_f-score_micro_tok: 0.9133255077461085
train_time: 95.01890325546265
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4783    0.0948    0.1583      1624
           N     0.6823    0.8372    0.7519      3310
           P     0.7371    0.8496    0.7893      3610

   micro avg     0.7013    0.7013    0.7013      8544
   macro avg     0.6326    0.5939    0.5665      8544
weighted avg     0.6667    0.7013    0.6549      8544

F1-macro sent:  0.5664946001568224
F1-micro sent:  0.701310861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9257    0.9724    0.9485    124347
           N     0.8260    0.7119    0.7647     14202
           P     0.8867    0.7342    0.8033     25017

   micro avg     0.9133    0.9133    0.9133    163566
   macro avg     0.8795    0.8062    0.8388    163566
weighted avg     0.9111    0.9133    0.9103    163566

F1-macro tok:  0.8388150680397048
F1-micro tok:  0.9133255077461085
**************************************************
dev_cost_sum: 42270.36364746094
dev_cost_avg: 38.39270086054581
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19134.0
dev_accuracy_tok: 0.8994077277427847
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6346153846153846
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7259999999999999
dev_label=P_precision_sent: 0.6994219653179191
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7538940809968847
dev_precision_macro_sent: 0.6780124499777679
dev_recall_macro_sent: 0.5654220314261941
dev_f-score_macro_sent: 0.5128238289515418
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9135752140236445
dev_label=O_recall_tok: 0.9680345572354212
dev_label=O_f-score_tok: 0.94001677852349
dev_label=N_precision_tok: 0.7702265372168284
dev_label=N_recall_tok: 0.6408185245018848
dev_label=N_f-score_tok: 0.6995884773662551
dev_label=P_precision_tok: 0.882329945269742
dev_label=P_recall_tok: 0.7026774595267746
dev_label=P_f-score_tok: 0.7823223570190642
dev_precision_macro_tok: 0.8553772321700716
dev_recall_macro_tok: 0.7705101804213603
dev_f-score_macro_tok: 0.8073092043029364
dev_precision_micro_tok: 0.8994077277427847
dev_recall_micro_tok: 0.8994077277427847
dev_f-score_micro_tok: 0.8994077277427848
dev_time: 5.153904676437378
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6346    0.8481    0.7260       428
           P     0.6994    0.8176    0.7539       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6780    0.5654    0.5128      1101
weighted avg     0.6743    0.6658    0.5984      1101

F1-macro sent:  0.5128238289515418
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9680    0.9400     16205
           N     0.7702    0.6408    0.6996      1857
           P     0.8823    0.7027    0.7823      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8554    0.7705    0.8073     21274
weighted avg     0.8963    0.8994    0.8952     21274

F1-macro tok:  0.8073092043029364
F1-micro tok:  0.8994077277427848
**************************************************
Best epoch: 30
**************************************************

EPOCH: 36
Learning rate: 0.531441
train_cost_sum: 296357.3977050781
train_cost_avg: 34.68602501229847
train_count_sent: 8544.0
train_total_correct_sent: 6023.0
train_accuracy_sent: 0.704939138576779
train_count_tok: 163566.0
train_total_correct_tok: 149568.0
train_accuracy_tok: 0.9144198672095668
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.0979064039408867
train_label=O_f-score_sent: 0.16374871266735325
train_label=N_precision_sent: 0.683566005388195
train_label=N_recall_sent: 0.843202416918429
train_label=N_f-score_sent: 0.7550385499797105
train_label=P_precision_sent: 0.7417330436881486
train_label=P_recall_sent: 0.8512465373961219
train_label=P_f-score_sent: 0.7927253966206629
train_precision_macro_sent: 0.6417663496921145
train_recall_macro_sent: 0.5974517860851458
train_f-score_macro_sent: 0.5705042197559088
train_precision_micro_sent: 0.704939138576779
train_recall_micro_sent: 0.704939138576779
train_f-score_micro_sent: 0.704939138576779
train_label=O_precision_tok: 0.9271971596616746
train_label=O_recall_tok: 0.9723837326192027
train_label=O_f-score_tok: 0.94925300485959
train_label=N_precision_tok: 0.8236581806388844
train_label=N_recall_tok: 0.715321785663991
train_label=N_f-score_tok: 0.7656768164003617
train_label=P_precision_tok: 0.8881632653061224
train_label=P_recall_tok: 0.7393372506695447
train_label=P_f-score_tok: 0.8069455957418962
train_precision_macro_tok: 0.8796728685355605
train_recall_macro_tok: 0.8090142563175795
train_f-score_macro_tok: 0.840625139000616
train_precision_micro_tok: 0.9144198672095668
train_recall_micro_tok: 0.9144198672095668
train_f-score_micro_tok: 0.9144198672095668
train_time: 95.41633987426758
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0979    0.1637      1624
           N     0.6836    0.8432    0.7550      3310
           P     0.7417    0.8512    0.7927      3610

   micro avg     0.7049    0.7049    0.7049      8544
   macro avg     0.6418    0.5975    0.5705      8544
weighted avg     0.6733    0.7049    0.6586      8544

F1-macro sent:  0.5705042197559088
F1-micro sent:  0.704939138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9272    0.9724    0.9493    124347
           N     0.8237    0.7153    0.7657     14202
           P     0.8882    0.7393    0.8069     25017

   micro avg     0.9144    0.9144    0.9144    163566
   macro avg     0.8797    0.8090    0.8406    163566
weighted avg     0.9122    0.9144    0.9115    163566

F1-macro tok:  0.840625139000616
F1-micro tok:  0.9144198672095668
**************************************************
dev_cost_sum: 42356.7314453125
dev_cost_avg: 38.471145726896005
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19166.0
dev_accuracy_tok: 0.9009119112531729
dev_label=O_precision_sent: 0.5294117647058824
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07317073170731707
dev_label=N_precision_sent: 0.6610486891385767
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7338877338877339
dev_label=P_precision_sent: 0.6836363636363636
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7565392354124749
dev_precision_macro_sent: 0.6246989391602743
dev_recall_macro_sent: 0.5703048373435673
dev_f-score_macro_sent: 0.5211992336691753
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9105442373174814
dev_label=O_recall_tok: 0.9735883986423943
dev_label=O_f-score_tok: 0.9410115710366218
dev_label=N_precision_tok: 0.8037841625788367
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6985383678440924
dev_label=P_precision_tok: 0.8896825396825396
dev_label=P_recall_tok: 0.6980074719800747
dev_label=P_f-score_tok: 0.7822749476622471
dev_precision_macro_tok: 0.8680036465262858
dev_recall_macro_tok: 0.7630862559228011
dev_f-score_macro_tok: 0.807274962180987
dev_precision_micro_tok: 0.9009119112531729
dev_recall_micro_tok: 0.9009119112531729
dev_f-score_micro_tok: 0.9009119112531729
dev_time: 5.1295270919799805
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0393    0.0732       229
           N     0.6610    0.8248    0.7339       428
           P     0.6836    0.8468    0.7565       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6247    0.5703    0.5212      1101
weighted avg     0.6428    0.6703    0.6056      1101

F1-macro sent:  0.5211992336691753
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9736    0.9410     16205
           N     0.8038    0.6177    0.6985      1857
           P     0.8897    0.6980    0.7823      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8680    0.7631    0.8073     21274
weighted avg     0.8981    0.9009    0.8959     21274

F1-macro tok:  0.807274962180987
F1-micro tok:  0.9009119112531729
**************************************************
Best epoch: 30
**************************************************

EPOCH: 37
Learning rate: 0.478297
train_cost_sum: 295601.1778564453
train_cost_avg: 34.597516134883584
train_count_sent: 8544.0
train_total_correct_sent: 6034.0
train_accuracy_sent: 0.7062265917602997
train_count_tok: 163566.0
train_total_correct_tok: 149796.0
train_accuracy_tok: 0.9158137999339716
train_label=O_precision_sent: 0.46766169154228854
train_label=O_recall_sent: 0.11576354679802955
train_label=O_f-score_sent: 0.1855873642645607
train_label=N_precision_sent: 0.6892795246348106
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.757654102598993
train_label=P_precision_sent: 0.7462832074092127
train_label=P_recall_sent: 0.8481994459833795
train_label=P_f-score_sent: 0.7939841825489432
train_precision_macro_sent: 0.6344081411954373
train_recall_macro_sent: 0.6016835353581534
train_f-score_macro_sent: 0.5790752164708323
train_precision_micro_sent: 0.7062265917602997
train_recall_micro_sent: 0.7062265917602997
train_f-score_micro_sent: 0.7062265917602997
train_label=O_precision_tok: 0.928050324114917
train_label=O_recall_tok: 0.972890379341681
train_label=O_f-score_tok: 0.9499415002630526
train_label=N_precision_tok: 0.8304768093574851
train_label=N_recall_tok: 0.7198986058301647
train_label=N_f-score_tok: 0.771244295251386
train_label=P_precision_tok: 0.8897607655502392
train_label=P_recall_tok: 0.7433345325178878
train_label=P_f-score_tok: 0.809983230611756
train_precision_macro_tok: 0.882762633007547
train_recall_macro_tok: 0.8120411725632445
train_f-score_macro_tok: 0.8437230087087316
train_precision_micro_tok: 0.9158137999339716
train_recall_micro_tok: 0.9158137999339716
train_f-score_micro_tok: 0.9158137999339716
train_time: 112.06246209144592
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4677    0.1158    0.1856      1624
           N     0.6893    0.8411    0.7577      3310
           P     0.7463    0.8482    0.7940      3610

   micro avg     0.7062    0.7062    0.7062      8544
   macro avg     0.6344    0.6017    0.5791      8544
weighted avg     0.6712    0.7062    0.6643      8544

F1-macro sent:  0.5790752164708323
F1-micro sent:  0.7062265917602997
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9281    0.9729    0.9499    124347
           N     0.8305    0.7199    0.7712     14202
           P     0.8898    0.7433    0.8100     25017

   micro avg     0.9158    0.9158    0.9158    163566
   macro avg     0.8828    0.8120    0.8437    163566
weighted avg     0.9137    0.9158    0.9130    163566

F1-macro tok:  0.8437230087087316
F1-micro tok:  0.9158137999339716
**************************************************
dev_cost_sum: 42317.52795410156
dev_cost_avg: 38.43553855958362
dev_count_sent: 1101.0
dev_total_correct_sent: 740.0
dev_accuracy_sent: 0.6721162579473207
dev_count_tok: 21274.0
dev_total_correct_tok: 19067.0
dev_accuracy_tok: 0.8962583435179092
dev_label=O_precision_sent: 0.5263157894736842
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08064516129032258
dev_label=N_precision_sent: 0.6587155963302752
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7379239465570401
dev_label=P_precision_sent: 0.6908752327746741
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7563710499490317
dev_precision_macro_sent: 0.6253022061928778
dev_recall_macro_sent: 0.5726795848617666
dev_f-score_macro_sent: 0.5249800525987981
dev_precision_micro_sent: 0.6721162579473207
dev_recall_micro_sent: 0.6721162579473207
dev_f-score_micro_sent: 0.6721162579473207
dev_label=O_precision_tok: 0.916058394160584
dev_label=O_recall_tok: 0.9603208886146252
dev_label=O_f-score_tok: 0.9376675805139639
dev_label=N_precision_tok: 0.7553058676654182
dev_label=N_recall_tok: 0.6515885837372105
dev_label=N_f-score_tok: 0.6996241688349233
dev_label=P_precision_tok: 0.8550670640834576
dev_label=P_recall_tok: 0.7145080946450809
dev_label=P_f-score_tok: 0.7784938941655359
dev_precision_macro_tok: 0.8421437753031533
dev_recall_macro_tok: 0.7754725223323056
dev_f-score_macro_tok: 0.8052618811714743
dev_precision_micro_tok: 0.8962583435179092
dev_recall_micro_tok: 0.8962583435179092
dev_f-score_micro_tok: 0.8962583435179092
dev_time: 8.2456955909729
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5263    0.0437    0.0806       229
           N     0.6587    0.8388    0.7379       428
           P     0.6909    0.8356    0.7564       444

   micro avg     0.6721    0.6721    0.6721      1101
   macro avg     0.6253    0.5727    0.5250      1101
weighted avg     0.6441    0.6721    0.6087      1101

F1-macro sent:  0.5249800525987981
F1-micro sent:  0.6721162579473207
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9161    0.9603    0.9377     16205
           N     0.7553    0.6516    0.6996      1857
           P     0.8551    0.7145    0.7785      3212

   micro avg     0.8963    0.8963    0.8963     21274
   macro avg     0.8421    0.7755    0.8053     21274
weighted avg     0.8928    0.8963    0.8929     21274

F1-macro tok:  0.8052618811714743
F1-micro tok:  0.8962583435179092
**************************************************
Best epoch: 30
**************************************************

test0_cost_sum: 42374.7431640625
test0_cost_avg: 38.48750514447094
test0_count_sent: 1101.0
test0_total_correct_sent: 746.0
test0_accuracy_sent: 0.6775658492279746
test0_count_tok: 21274.0
test0_total_correct_tok: 19159.0
test0_accuracy_tok: 0.9005828711102755
test0_label=O_precision_sent: 0.6666666666666666
test0_label=O_recall_sent: 0.09606986899563319
test0_label=O_f-score_sent: 0.16793893129770993
test0_label=N_precision_sent: 0.643979057591623
test0_label=N_recall_sent: 0.8621495327102804
test0_label=N_f-score_sent: 0.7372627372627374
test0_label=P_precision_sent: 0.7171717171717171
test0_label=P_recall_sent: 0.7995495495495496
test0_label=P_f-score_sent: 0.7561235356762512
test0_precision_macro_sent: 0.6759391471433357
test0_recall_macro_sent: 0.5859229837518211
test0_f-score_macro_sent: 0.5537750680788995
test0_precision_micro_sent: 0.6775658492279746
test0_recall_micro_sent: 0.6775658492279746
test0_f-score_micro_sent: 0.6775658492279746
test0_label=O_precision_tok: 0.9109787135585378
test0_label=O_recall_tok: 0.971860536871336
test0_label=O_f-score_tok: 0.9404353148419072
test0_label=N_precision_tok: 0.8051675977653632
test0_label=N_recall_tok: 0.620893914916532
test0_label=N_f-score_tok: 0.7011249619945272
test0_label=P_precision_tok: 0.8837118245888802
test0_label=P_recall_tok: 0.7026774595267746
test0_label=P_f-score_tok: 0.7828650711064863
test0_precision_macro_tok: 0.8666193786375938
test0_recall_macro_tok: 0.7651439704382142
test0_f-score_macro_tok: 0.8081417826476401
test0_precision_micro_tok: 0.9005828711102755
test0_recall_micro_tok: 0.9005828711102755
test0_f-score_micro_tok: 0.9005828711102755
test0_time: 8.385039329528809
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0961    0.1679       229
           N     0.6440    0.8621    0.7373       428
           P     0.7172    0.7995    0.7561       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6759    0.5859    0.5538      1101
weighted avg     0.6782    0.6776    0.6265      1101

F1-macro sent:  0.5537750680788995
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9719    0.9404     16205
           N     0.8052    0.6209    0.7011      1857
           P     0.8837    0.7027    0.7829      3212

   micro avg     0.9006    0.9006    0.9006     21274
   macro avg     0.8666    0.7651    0.8081     21274
weighted avg     0.8976    0.9006    0.8958     21274

F1-macro tok:  0.8081417826476401
F1-micro tok:  0.9005828711102755
**************************************************
test1_cost_sum: 81883.98083877563
test1_cost_avg: 37.05157504016997
test1_count_sent: 2210.0
test1_total_correct_sent: 1556.0
test1_accuracy_sent: 0.7040723981900453
test1_count_tok: 42405.0
test1_total_correct_tok: 37951.0
test1_accuracy_tok: 0.8949652163659946
test1_label=O_precision_sent: 0.45652173913043476
test1_label=O_recall_sent: 0.05398457583547558
test1_label=O_f-score_sent: 0.09655172413793102
test1_label=N_precision_sent: 0.6734006734006734
test1_label=N_recall_sent: 0.8771929824561403
test1_label=N_f-score_sent: 0.7619047619047619
test1_label=P_precision_sent: 0.7530737704918032
test1_label=P_recall_sent: 0.8085808580858086
test1_label=P_f-score_sent: 0.7798408488063661
test1_precision_macro_sent: 0.6276653943409705
test1_recall_macro_sent: 0.5799194721258082
test1_f-score_macro_sent: 0.5460991116163529
test1_precision_micro_sent: 0.7040723981900453
test1_recall_micro_sent: 0.7040723981900453
test1_f-score_micro_sent: 0.7040723981900453
test1_label=O_precision_tok: 0.903057527894508
test1_label=O_recall_tok: 0.9738108631789487
test1_label=O_f-score_tok: 0.9371005819286348
test1_label=N_precision_tok: 0.8061827023271969
test1_label=N_recall_tok: 0.6172872340425531
test1_label=N_f-score_tok: 0.6992016870010543
test1_label=P_precision_tok: 0.8902609042023502
test1_label=P_recall_tok: 0.672483827290507
test1_label=P_f-score_tok: 0.7661981487829962
test1_precision_macro_tok: 0.8665003781413517
test1_recall_macro_tok: 0.7545273081706697
test1_f-score_macro_tok: 0.8008334725708951
test1_precision_micro_tok: 0.8949652163659946
test1_recall_micro_tok: 0.8949652163659946
test1_f-score_micro_tok: 0.8949652163659946
test1_time: 15.990208148956299
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4565    0.0540    0.0966       389
           N     0.6734    0.8772    0.7619       912
           P     0.7531    0.8086    0.7798       909

   micro avg     0.7041    0.7041    0.7041      2210
   macro avg     0.6277    0.5799    0.5461      2210
weighted avg     0.6680    0.7041    0.6522      2210

F1-macro sent:  0.5460991116163529
F1-micro sent:  0.7040723981900453
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9738    0.9371     31998
           N     0.8062    0.6173    0.6992      3760
           P     0.8903    0.6725    0.7662      6647

   micro avg     0.8950    0.8950    0.8950     42405
   macro avg     0.8665    0.7545    0.8008     42405
weighted avg     0.8925    0.8950    0.8892     42405

F1-macro tok:  0.8008334725708951
F1-micro tok:  0.8949652163659946
**************************************************
