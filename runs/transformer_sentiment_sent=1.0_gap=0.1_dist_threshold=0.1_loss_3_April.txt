to_write_filename: runs/transformer_sentiment_sent=1.0_gap=0.1_dist_threshold=0.1_loss_3_April.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 0.0
gap_objective_weight: 0.1
maximum_gap_threshold: 0.1
sentence_composition: attention
random_seed: 100
{'O': 0, 'P': 2, 'N': 1}
{'O': 0, 'P': 2, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-04-03 17:58:29.906897: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-03 17:58:29.983663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 35b6:00:00.0
totalMemory: 11.17GiB freeMemory: 10.48GiB
2019-04-03 17:58:29.983709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-04-03 17:58:30.355809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-03 17:58:30.355859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-04-03 17:58:30.355872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-04-03 17:58:30.356109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 35b6:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7835707.
Parameter count without word embeddings: 2035207.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 8724.586866378784
train_cost_avg: 1.0211361032746704
train_count_sent: 8544.0
train_total_correct_sent: 4293.0
train_accuracy_sent: 0.5024578651685393
train_count_tok: 163566.0
train_total_correct_tok: 123128.0
train_accuracy_tok: 0.7527725810987613
train_label=O_precision_sent: 0.3167701863354037
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05714285714285715
train_label=N_precision_sent: 0.48120660761311945
train_label=N_recall_sent: 0.6072507552870091
train_label=N_f-score_sent: 0.5369306798450648
train_label=P_precision_sent: 0.5306704707560628
train_label=P_recall_sent: 0.6182825484764543
train_label=P_f-score_sent: 0.5711361310133061
train_precision_macro_sent: 0.4428824215681953
train_recall_macro_sent: 0.4189790815500543
train_f-score_macro_sent: 0.388403222667076
train_precision_micro_sent: 0.5024578651685393
train_recall_micro_sent: 0.5024578651685393
train_f-score_micro_sent: 0.5024578651685393
train_label=O_precision_tok: 0.7605304356973571
train_label=O_recall_tok: 0.9883953774518083
train_label=O_f-score_tok: 0.8596188144780557
train_label=N_precision_tok: 0.08384819064430715
train_label=N_recall_tok: 0.00668919870440783
train_label=N_f-score_tok: 0.012389957613302902
train_label=P_precision_tok: 0.15542168674698795
train_label=P_recall_tok: 0.005156493584362634
train_label=P_f-score_tok: 0.00998181607149766
train_precision_macro_tok: 0.33326677102955077
train_recall_macro_tok: 0.33341368991352627
train_f-score_macro_tok: 0.29399686272095205
train_precision_micro_tok: 0.7527725810987613
train_recall_micro_tok: 0.7527725810987613
train_f-score_micro_tok: 0.7527725810987613
train_time: 83.39007997512817
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3168    0.0314    0.0571      1624
           N     0.4812    0.6073    0.5369      3310
           P     0.5307    0.6183    0.5711      3610

   micro avg     0.5025    0.5025    0.5025      8544
   macro avg     0.4429    0.4190    0.3884      8544
weighted avg     0.4709    0.5025    0.4602      8544

F1-macro sent:  0.388403222667076
F1-micro sent:  0.5024578651685393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7605    0.9884    0.8596    124347
           N     0.0838    0.0067    0.0124     14202
           P     0.1554    0.0052    0.0100     25017

   micro avg     0.7528    0.7528    0.7528    163566
   macro avg     0.3333    0.3334    0.2940    163566
weighted avg     0.6092    0.7528    0.6561    163566

F1-macro tok:  0.29399686272095205
F1-micro tok:  0.7527725810987613
**************************************************
dev_cost_sum: 994.174750328064
dev_cost_avg: 0.9029743418056894
dev_count_sent: 1101.0
dev_total_correct_sent: 667.0
dev_accuracy_sent: 0.6058128973660308
dev_count_tok: 21274.0
dev_total_correct_tok: 16205.0
dev_accuracy_tok: 0.7617279308075585
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5751748251748252
dev_label=N_recall_sent: 0.7686915887850467
dev_label=N_f-score_sent: 0.658
dev_label=P_precision_sent: 0.6387832699619772
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.6927835051546393
dev_precision_macro_sent: 0.6268749206011565
dev_recall_macro_sent: 0.5113939899986507
dev_f-score_macro_sent: 0.45600829482166133
dev_precision_micro_sent: 0.6058128973660308
dev_recall_micro_sent: 0.6058128973660308
dev_f-score_micro_sent: 0.6058128973660308
dev_label=O_precision_tok: 0.7617279308075585
dev_label=O_recall_tok: 1.0
dev_label=O_f-score_tok: 0.8647509271858907
dev_label=N_precision_tok: 0.0
dev_label=N_recall_tok: 0.0
dev_label=N_f-score_tok: 0.0
dev_label=P_precision_tok: 0.0
dev_label=P_recall_tok: 0.0
dev_label=P_f-score_tok: 0.0
dev_precision_macro_tok: 0.2539093102691862
dev_recall_macro_tok: 0.3333333333333333
dev_f-score_macro_tok: 0.2882503090619636
dev_precision_micro_tok: 0.7617279308075585
dev_recall_micro_tok: 0.7617279308075585
dev_f-score_micro_tok: 0.7617279308075585
dev_time: 4.6346588134765625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5752    0.7687    0.6580       428
           P     0.6388    0.7568    0.6928       444

   micro avg     0.6058    0.6058    0.6058      1101
   macro avg     0.6269    0.5114    0.4560      1101
weighted avg     0.6199    0.6058    0.5388      1101

F1-macro sent:  0.45600829482166133
F1-micro sent:  0.6058128973660308
**************************************************
Token pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.7617    1.0000    0.8648     16205
           N     0.0000    0.0000    0.0000      1857
           P     0.0000    0.0000    0.0000      3212

   micro avg     0.7617    0.7617    0.7617     21274
   macro avg     0.2539    0.3333    0.2883     21274
weighted avg     0.5802    0.7617    0.6587     21274

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro tok:  0.2882503090619636
F1-micro tok:  0.7617279308075585
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 7991.340532302856
train_cost_avg: 0.9353160735373194
train_count_sent: 8544.0
train_total_correct_sent: 4887.0
train_accuracy_sent: 0.5719803370786517
train_count_tok: 163566.0
train_total_correct_tok: 27139.0
train_accuracy_tok: 0.1659207903843097
train_label=O_precision_sent: 0.5833333333333334
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.04156769596199525
train_label=N_precision_sent: 0.5612543183630082
train_label=N_recall_sent: 0.6380664652567976
train_label=N_f-score_sent: 0.5972006220839814
train_label=P_precision_sent: 0.5803855115441644
train_label=P_recall_sent: 0.7590027700831025
train_label=P_f-score_sent: 0.6577841795702797
train_precision_macro_sent: 0.574991054413502
train_recall_macro_sent: 0.47287365315927704
train_f-score_macro_sent: 0.43218416587208547
train_precision_micro_sent: 0.5719803370786517
train_recall_micro_sent: 0.5719803370786517
train_f-score_micro_sent: 0.5719803370786517
train_label=O_precision_tok: 0.7518251875887244
train_label=O_recall_tok: 0.11925498805761298
train_label=O_f-score_tok: 0.20585683447744518
train_label=N_precision_tok: 0.08497657165169856
train_label=N_recall_tok: 0.8581185748486129
train_label=N_f-score_tok: 0.15463969851159132
train_label=P_precision_tok: 0.2887323943661972
train_label=P_recall_tok: 0.004916656673462046
train_label=P_f-score_tok: 0.00966867114727037
train_precision_macro_tok: 0.3751780512022067
train_recall_macro_tok: 0.3274300731932293
train_f-score_macro_tok: 0.12338840137876896
train_precision_micro_tok: 0.1659207903843097
train_recall_micro_tok: 0.1659207903843097
train_f-score_micro_tok: 0.1659207903843097
train_time: 112.61984372138977
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0216    0.0416      1624
           N     0.5613    0.6381    0.5972      3310
           P     0.5804    0.7590    0.6578      3610

   micro avg     0.5720    0.5720    0.5720      8544
   macro avg     0.5750    0.4729    0.4322      8544
weighted avg     0.5735    0.5720    0.5172      8544

F1-macro sent:  0.43218416587208547
F1-micro sent:  0.5719803370786517
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7518    0.1193    0.2059    124347
           N     0.0850    0.8581    0.1546     14202
           P     0.2887    0.0049    0.0097     25017

   micro avg     0.1659    0.1659    0.1659    163566
   macro avg     0.3752    0.3274    0.1234    163566
weighted avg     0.6231    0.1659    0.1714    163566

F1-macro tok:  0.12338840137876896
F1-micro tok:  0.1659207903843097
**************************************************
dev_cost_sum: 988.7290267944336
dev_cost_avg: 0.8980281805580687
dev_count_sent: 1101.0
dev_total_correct_sent: 680.0
dev_accuracy_sent: 0.6176203451407811
dev_count_tok: 21274.0
dev_total_correct_tok: 1856.0
dev_accuracy_tok: 0.0872426436025195
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5537313432835821
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.6757741347905282
dev_label=P_precision_sent: 0.7172897196261683
dev_label=P_recall_sent: 0.6914414414414415
dev_label=P_f-score_sent: 0.7041284403669725
dev_precision_macro_sent: 0.6458959098588056
dev_recall_macro_sent: 0.5223324986007106
dev_f-score_macro_sent: 0.4657146514892818
dev_precision_micro_sent: 0.6176203451407811
dev_recall_micro_sent: 0.6176203451407811
dev_f-score_micro_sent: 0.6176203451407811
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.08721203573107664
dev_label=N_recall_tok: 0.9989229940764675
dev_label=N_f-score_tok: 0.16041855839494965
dev_label=P_precision_tok: 0.25
dev_label=P_recall_tok: 0.00031133250311332503
dev_label=P_f-score_tok: 0.0006218905472636816
dev_precision_macro_tok: 0.11240401191035887
dev_recall_macro_tok: 0.3330781088598603
dev_f-score_macro_tok: 0.053680149647404446
dev_precision_micro_tok: 0.0872426436025195
dev_recall_micro_tok: 0.0872426436025195
dev_f-score_micro_tok: 0.0872426436025195
dev_time: 7.157137393951416
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5537    0.8668    0.6758       428
           P     0.7173    0.6914    0.7041       444

   micro avg     0.6176    0.6176    0.6176      1101
   macro avg     0.6459    0.5223    0.4657      1101
weighted avg     0.6432    0.6176    0.5502      1101

F1-macro sent:  0.4657146514892818
F1-micro sent:  0.6176203451407811
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.0872    0.9989    0.1604      1857
           P     0.2500    0.0003    0.0006      3212

   micro avg     0.0872    0.0872    0.0872     21274
   macro avg     0.1124    0.3331    0.0537     21274
weighted avg     0.0454    0.0872    0.0141     21274

F1-macro tok:  0.053680149647404446
F1-micro tok:  0.0872426436025195
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 7661.23775100708
train_cost_avg: 0.8966804483856601
train_count_sent: 8544.0
train_total_correct_sent: 5145.0
train_accuracy_sent: 0.6021769662921348
train_count_tok: 163566.0
train_total_correct_tok: 14504.0
train_accuracy_tok: 0.08867368524020884
train_label=O_precision_sent: 0.4875
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.04577464788732394
train_label=N_precision_sent: 0.5661063153112221
train_label=N_recall_sent: 0.7528700906344411
train_label=N_f-score_sent: 0.646265560165975
train_label=P_precision_sent: 0.6435253569670113
train_label=P_recall_sent: 0.7240997229916898
train_label=P_f-score_sent: 0.6814389989572471
train_precision_macro_sent: 0.5657105574260778
train_recall_macro_sent: 0.5003281973170847
train_f-score_macro_sent: 0.45782640233684874
train_precision_micro_sent: 0.6021769662921348
train_recall_micro_sent: 0.6021769662921348
train_f-score_micro_sent: 0.6021769662921348
train_label=O_precision_tok: 0.6196078431372549
train_label=O_recall_tok: 0.0012706378119295197
train_label=O_f-score_tok: 0.00253607486236176
train_label=N_precision_tok: 0.08641708589241073
train_label=N_recall_tok: 0.9857766511758908
train_label=N_f-score_tok: 0.15890401629901196
train_label=P_precision_tok: 0.2649310872894334
train_label=P_recall_tok: 0.013830595195267218
train_label=P_f-score_tok: 0.026288796869657717
train_precision_macro_tok: 0.3236520054396997
train_recall_macro_tok: 0.33362596139436246
train_f-score_macro_tok: 0.06257629601034381
train_precision_micro_tok: 0.08867368524020884
train_recall_micro_tok: 0.08867368524020884
train_f-score_micro_tok: 0.08867368524020883
train_time: 126.13641738891602
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4875    0.0240    0.0458      1624
           N     0.5661    0.7529    0.6463      3310
           P     0.6435    0.7241    0.6814      3610

   micro avg     0.6022    0.6022    0.6022      8544
   macro avg     0.5657    0.5003    0.4578      8544
weighted avg     0.5839    0.6022    0.5470      8544

F1-macro sent:  0.45782640233684874
F1-micro sent:  0.6021769662921348
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.6196    0.0013    0.0025    124347
           N     0.0864    0.9858    0.1589     14202
           P     0.2649    0.0138    0.0263     25017

   micro avg     0.0887    0.0887    0.0887    163566
   macro avg     0.3237    0.3336    0.0626    163566
weighted avg     0.5191    0.0887    0.0197    163566

F1-macro tok:  0.06257629601034381
F1-micro tok:  0.08867368524020883
**************************************************
dev_cost_sum: 1037.906084060669
dev_cost_avg: 0.9426939909724513
dev_count_sent: 1101.0
dev_total_correct_sent: 663.0
dev_accuracy_sent: 0.6021798365122616
dev_count_tok: 21274.0
dev_total_correct_tok: 1858.0
dev_accuracy_tok: 0.08733665507191878
dev_label=O_precision_sent: 0.5454545454545454
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05
dev_label=N_precision_sent: 0.7109826589595376
dev_label=N_recall_sent: 0.5747663551401869
dev_label=N_f-score_sent: 0.6356589147286822
dev_label=P_precision_sent: 0.5524193548387096
dev_label=P_recall_sent: 0.9256756756756757
dev_label=P_f-score_sent: 0.6919191919191919
dev_precision_macro_sent: 0.6029521864175975
dev_recall_macro_sent: 0.5088809680594361
dev_f-score_macro_sent: 0.4591927022159581
dev_precision_micro_sent: 0.6021798365122616
dev_recall_micro_sent: 0.6021798365122616
dev_f-score_micro_sent: 0.6021798365122616
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.08729785633696878
dev_label=N_recall_tok: 1.0
dev_label=N_f-score_tok: 0.16057762981538326
dev_label=P_precision_tok: 0.5
dev_label=P_recall_tok: 0.00031133250311332503
dev_label=P_f-score_tok: 0.0006222775357809583
dev_precision_macro_tok: 0.19576595211232292
dev_recall_macro_tok: 0.33343711083437105
dev_f-score_macro_tok: 0.05373330245038807
dev_precision_micro_tok: 0.08733665507191878
dev_recall_micro_tok: 0.08733665507191878
dev_f-score_micro_tok: 0.08733665507191878
dev_time: 7.140214443206787
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.0262    0.0500       229
           N     0.7110    0.5748    0.6357       428
           P     0.5524    0.9257    0.6919       444

   micro avg     0.6022    0.6022    0.6022      1101
   macro avg     0.6030    0.5089    0.4592      1101
weighted avg     0.6126    0.6022    0.5365      1101

F1-macro sent:  0.4591927022159581
F1-micro sent:  0.6021798365122616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.0873    1.0000    0.1606      1857
           P     0.5000    0.0003    0.0006      3212

   micro avg     0.0873    0.0873    0.0873     21274
   macro avg     0.1958    0.3334    0.0537     21274
weighted avg     0.0831    0.0873    0.0141     21274

F1-macro tok:  0.05373330245038807
F1-micro tok:  0.08733665507191878
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 7461.247602462769
train_cost_avg: 0.8732733617114664
train_count_sent: 8544.0
train_total_correct_sent: 5250.0
train_accuracy_sent: 0.6144662921348315
train_count_tok: 163566.0
train_total_correct_tok: 14527.0
train_accuracy_tok: 0.08881430126065319
train_label=O_precision_sent: 0.41916167664670656
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07816862088218872
train_label=N_precision_sent: 0.5860934930702373
train_label=N_recall_sent: 0.7537764350453172
train_label=N_f-score_sent: 0.6594423153165059
train_label=P_precision_sent: 0.6516990291262136
train_label=P_recall_sent: 0.7437673130193906
train_label=P_f-score_sent: 0.6946959896507116
train_precision_macro_sent: 0.5523180662810524
train_recall_macro_sent: 0.5135490654468566
train_f-score_macro_sent: 0.47743564194980204
train_precision_micro_sent: 0.6144662921348315
train_recall_micro_sent: 0.6144662921348315
train_f-score_micro_sent: 0.6144662921348315
train_label=O_precision_tok: 0.5765765765765766
train_label=O_recall_tok: 0.0005146887339461346
train_label=O_f-score_tok: 0.001028459399958219
train_label=N_precision_tok: 0.0869602704883201
train_label=N_recall_tok: 0.9942261653288269
train_label=N_f-score_tok: 0.1599320402095427
train_label=P_precision_tok: 0.3170055452865065
train_label=P_recall_tok: 0.013710676739816925
train_label=P_f-score_tok: 0.02628453197440515
train_precision_macro_tok: 0.3268474641171344
train_recall_macro_tok: 0.33615051026752996
train_f-score_macro_tok: 0.06241501052796868
train_precision_micro_tok: 0.08881430126065319
train_recall_micro_tok: 0.08881430126065319
train_f-score_micro_tok: 0.0888143012606532
train_time: 126.65164351463318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4192    0.0431    0.0782      1624
           N     0.5861    0.7538    0.6594      3310
           P     0.6517    0.7438    0.6947      3610

   micro avg     0.6145    0.6145    0.6145      8544
   macro avg     0.5523    0.5135    0.4774      8544
weighted avg     0.5821    0.6145    0.5639      8544

F1-macro sent:  0.47743564194980204
F1-micro sent:  0.6144662921348315
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.5766    0.0005    0.0010    124347
           N     0.0870    0.9942    0.1599     14202
           P     0.3170    0.0137    0.0263     25017

   micro avg     0.0888    0.0888    0.0888    163566
   macro avg     0.3268    0.3362    0.0624    163566
weighted avg     0.4944    0.0888    0.0187    163566

F1-macro tok:  0.06241501052796868
F1-micro tok:  0.0888143012606532
**************************************************
dev_cost_sum: 936.8091259002686
dev_cost_avg: 0.8508711406905255
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 1858.0
dev_accuracy_tok: 0.08733665507191878
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02553191489361702
dev_label=N_precision_sent: 0.6493506493506493
dev_label=N_recall_sent: 0.7009345794392523
dev_label=N_f-score_sent: 0.6741573033707865
dev_label=P_precision_sent: 0.6066350710900474
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7130919220055711
dev_precision_macro_sent: 0.5853285734802323
dev_recall_macro_sent: 0.5262999603284467
dev_f-score_macro_sent: 0.4709270467566582
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.08729785633696878
dev_label=N_recall_tok: 1.0
dev_label=N_f-score_tok: 0.16057762981538326
dev_label=P_precision_tok: 0.5
dev_label=P_recall_tok: 0.00031133250311332503
dev_label=P_f-score_tok: 0.0006222775357809583
dev_precision_macro_tok: 0.19576595211232292
dev_recall_macro_tok: 0.33343711083437105
dev_f-score_macro_tok: 0.05373330245038807
dev_precision_micro_tok: 0.08733665507191878
dev_recall_micro_tok: 0.08733665507191878
dev_f-score_micro_tok: 0.08733665507191878
dev_time: 7.0956175327301025
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0131    0.0255       229
           N     0.6494    0.7009    0.6742       428
           P     0.6066    0.8649    0.7131       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.5853    0.5263    0.4709      1101
weighted avg     0.6011    0.6240    0.5549      1101

F1-macro sent:  0.4709270467566582
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.0873    1.0000    0.1606      1857
           P     0.5000    0.0003    0.0006      3212

   micro avg     0.0873    0.0873    0.0873     21274
   macro avg     0.1958    0.3334    0.0537     21274
weighted avg     0.0831    0.0873    0.0141     21274

F1-macro tok:  0.05373330245038807
F1-micro tok:  0.08733665507191878
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 7383.806489944458
train_cost_avg: 0.8642095610890049
train_count_sent: 8544.0
train_total_correct_sent: 5328.0
train_accuracy_sent: 0.6235955056179775
train_count_tok: 163566.0
train_total_correct_tok: 18600.0
train_accuracy_tok: 0.11371556435934119
train_label=O_precision_sent: 0.5205479452054794
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.08587570621468926
train_label=N_precision_sent: 0.6112531969309463
train_label=N_recall_sent: 0.7220543806646526
train_label=N_f-score_sent: 0.6620498614958448
train_label=P_precision_sent: 0.6377005347593583
train_label=P_recall_sent: 0.792797783933518
train_label=P_f-score_sent: 0.7068411953568783
train_precision_macro_sent: 0.5898338922985946
train_recall_macro_sent: 0.5205500647182736
train_f-score_macro_sent: 0.4849222543558041
train_precision_micro_sent: 0.6235955056179775
train_recall_micro_sent: 0.6235955056179775
train_f-score_micro_sent: 0.6235955056179775
train_label=O_precision_tok: 0.6190476190476191
train_label=O_recall_tok: 0.0001045461490828086
train_label=O_f-score_tok: 0.00020905699215232213
train_label=N_precision_tok: 0.09446616627186849
train_label=N_recall_tok: 0.9322630615406281
train_label=N_f-score_tok: 0.17154925562653053
train_label=P_precision_tok: 0.22861174056180256
train_label=P_recall_tok: 0.21373466043090697
train_label=P_f-score_tok: 0.22092302607114822
train_precision_macro_tok: 0.31404184196043
train_recall_macro_tok: 0.3820340893735393
train_f-score_macro_tok: 0.13089377956327702
train_precision_micro_tok: 0.11371556435934119
train_recall_micro_tok: 0.11371556435934119
train_f-score_micro_tok: 0.11371556435934119
train_time: 126.54128408432007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5205    0.0468    0.0859      1624
           N     0.6113    0.7221    0.6620      3310
           P     0.6377    0.7928    0.7068      3610

   micro avg     0.6236    0.6236    0.6236      8544
   macro avg     0.5898    0.5206    0.4849      8544
weighted avg     0.6052    0.6236    0.5715      8544

F1-macro sent:  0.4849222543558041
F1-micro sent:  0.6235955056179775
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.6190    0.0001    0.0002    124347
           N     0.0945    0.9323    0.1715     14202
           P     0.2286    0.2137    0.2209     25017

   micro avg     0.1137    0.1137    0.1137    163566
   macro avg     0.3140    0.3820    0.1309    163566
weighted avg     0.5138    0.1137    0.0488    163566

F1-macro tok:  0.13089377956327702
F1-micro tok:  0.11371556435934119
**************************************************
dev_cost_sum: 1032.9932479858398
dev_cost_avg: 0.9382318328663396
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 3201.0
dev_accuracy_tok: 0.15046535677352638
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7112299465240641
dev_label=N_recall_sent: 0.6214953271028038
dev_label=N_f-score_sent: 0.6633416458852868
dev_label=P_precision_sent: 0.5653370013755158
dev_label=P_recall_sent: 0.9256756756756757
dev_label=P_f-score_sent: 0.7019641332194705
dev_precision_macro_sent: 0.4255223159665267
dev_recall_macro_sent: 0.5157236675928264
dev_f-score_macro_sent: 0.4551019263682525
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.11568322981366459
dev_label=N_recall_tok: 0.8023694130317717
dev_label=N_f-score_tok: 0.20221211915586615
dev_label=P_precision_tok: 0.20383607338575171
dev_label=P_recall_tok: 0.5326899128268991
dev_label=P_f-score_tok: 0.2948474926762019
dev_precision_macro_tok: 0.10650643439980544
dev_recall_macro_tok: 0.44501977528622366
dev_f-score_macro_tok: 0.16568653727735602
dev_precision_micro_tok: 0.15046535677352638
dev_recall_micro_tok: 0.15046535677352638
dev_f-score_micro_tok: 0.15046535677352638
dev_time: 7.2957868576049805
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7112    0.6215    0.6633       428
           P     0.5653    0.9257    0.7020       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4255    0.5157    0.4551      1101
weighted avg     0.5045    0.6149    0.5409      1101

F1-macro sent:  0.4551019263682525
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.1157    0.8024    0.2022      1857
           P     0.2038    0.5327    0.2948      3212

   micro avg     0.1505    0.1505    0.1505     21274
   macro avg     0.1065    0.4450    0.1657     21274
weighted avg     0.0409    0.1505    0.0622     21274

F1-macro tok:  0.16568653727735602
F1-micro tok:  0.15046535677352638
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 7256.983892440796
train_cost_avg: 0.8493660922800557
train_count_sent: 8544.0
train_total_correct_sent: 5399.0
train_accuracy_sent: 0.6319054307116105
train_count_tok: 163566.0
train_total_correct_tok: 18613.0
train_accuracy_tok: 0.11379504297959234
train_label=O_precision_sent: 0.45588235294117646
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03664302600472813
train_label=N_precision_sent: 0.6000464792005578
train_label=N_recall_sent: 0.7800604229607251
train_label=N_f-score_sent: 0.6783134112701957
train_label=P_precision_sent: 0.6676252096812845
train_label=P_recall_sent: 0.7717451523545706
train_label=P_f-score_sent: 0.7159193113195426
train_precision_macro_sent: 0.5745180139410062
train_recall_macro_sent: 0.5236314150886782
train_f-score_macro_sent: 0.4769585828648221
train_precision_micro_sent: 0.6319054307116105
train_recall_micro_sent: 0.6319054307116105
train_f-score_micro_sent: 0.6319054307116105
train_label=O_precision_tok: 0.6440677966101694
train_label=O_recall_tok: 0.0003055964357805174
train_label=O_f-score_tok: 0.0006109030111087889
train_label=N_precision_tok: 0.09498430101445177
train_label=N_recall_tok: 0.9223348824109281
train_label=N_f-score_tok: 0.17223175486000172
train_label=P_precision_tok: 0.21390625
train_label=P_recall_tok: 0.21889115401526962
train_label=P_f-score_tok: 0.21636999427069956
train_precision_macro_tok: 0.3176527825415404
train_recall_macro_tok: 0.38051054428732606
train_f-score_macro_tok: 0.1297375507139367
train_precision_micro_tok: 0.11379504297959234
train_recall_micro_tok: 0.11379504297959234
train_f-score_micro_tok: 0.11379504297959232
train_time: 126.1781702041626
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4559    0.0191    0.0366      1624
           N     0.6000    0.7801    0.6783      3310
           P     0.6676    0.7717    0.7159      3610

   micro avg     0.6319    0.6319    0.6319      8544
   macro avg     0.5745    0.5236    0.4770      8544
weighted avg     0.6012    0.6319    0.5722      8544

F1-macro sent:  0.4769585828648221
F1-micro sent:  0.6319054307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.6441    0.0003    0.0006    124347
           N     0.0950    0.9223    0.1722     14202
           P     0.2139    0.2189    0.2164     25017

   micro avg     0.1138    0.1138    0.1138    163566
   macro avg     0.3177    0.3805    0.1297    163566
weighted avg     0.5306    0.1138    0.0485    163566

F1-macro tok:  0.1297375507139367
F1-micro tok:  0.11379504297959232
**************************************************
dev_cost_sum: 932.696780204773
dev_cost_avg: 0.8471360401496575
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 1947.0
dev_accuracy_tok: 0.09152016546018614
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6336633663366337
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.6859592711682744
dev_label=P_precision_sent: 0.6323777403035413
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7232401157184186
dev_precision_macro_sent: 0.6442359244356138
dev_recall_macro_sent: 0.5336639234835374
dev_f-score_macro_sent: 0.47548025539901256
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.08894462666409415
dev_label=N_recall_tok: 0.9929994614970382
dev_label=N_f-score_tok: 0.16326530612244897
dev_label=P_precision_tok: 0.1900369003690037
dev_label=P_recall_tok: 0.03206724782067248
dev_label=P_f-score_tok: 0.054874800213106034
dev_precision_macro_tok: 0.09299384234436596
dev_recall_macro_tok: 0.34168890310590355
dev_f-score_macro_tok: 0.07271336877851833
dev_precision_micro_tok: 0.09152016546018614
dev_recall_micro_tok: 0.09152016546018614
dev_f-score_micro_tok: 0.09152016546018614
dev_time: 7.074832916259766
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6337    0.7477    0.6860       428
           P     0.6324    0.8446    0.7232       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.6442    0.5337    0.4755      1101
weighted avg     0.6400    0.6331    0.5619      1101

F1-macro sent:  0.47548025539901256
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.0889    0.9930    0.1633      1857
           P     0.1900    0.0321    0.0549      3212

   micro avg     0.0915    0.0915    0.0915     21274
   macro avg     0.0930    0.3417    0.0727     21274
weighted avg     0.0365    0.0915    0.0225     21274

F1-macro tok:  0.07271336877851833
F1-micro tok:  0.09152016546018614
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 7093.813011169434
train_cost_avg: 0.8302683767754487
train_count_sent: 8544.0
train_total_correct_sent: 5536.0
train_accuracy_sent: 0.6479400749063671
train_count_tok: 163566.0
train_total_correct_tok: 14265.0
train_accuracy_tok: 0.0872125013755915
train_label=O_precision_sent: 0.5728155339805825
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06832657788071801
train_label=N_precision_sent: 0.6117182050685886
train_label=N_recall_sent: 0.7948640483383685
train_label=N_f-score_sent: 0.6913677571935356
train_label=P_precision_sent: 0.68743961352657
train_label=P_recall_sent: 0.788365650969529
train_label=P_f-score_sent: 0.7344516129032258
train_precision_macro_sent: 0.623991117525247
train_recall_macro_sent: 0.5398532495229937
train_f-score_macro_sent: 0.4980486493258265
train_precision_micro_sent: 0.6479400749063671
train_recall_micro_sent: 0.6479400749063671
train_f-score_micro_sent: 0.6479400749063671
train_label=O_precision_tok: 0.8461538461538461
train_label=O_recall_tok: 0.00026538637844097566
train_label=O_f-score_tok: 0.000530606338333896
train_label=N_precision_tok: 0.08686720019624077
train_label=N_recall_tok: 0.997394733136178
train_label=N_f-score_tok: 0.15981541967766139
train_label=P_precision_tok: 0.14502164502164502
train_label=P_recall_tok: 0.002678178838389895
train_label=P_f-score_tok: 0.0052592330939204845
train_precision_macro_tok: 0.35934756379057725
train_recall_macro_tok: 0.33344609945100295
train_f-score_macro_tok: 0.055201753036638594
train_precision_micro_tok: 0.0872125013755915
train_recall_micro_tok: 0.0872125013755915
train_f-score_micro_tok: 0.0872125013755915
train_time: 126.01843190193176
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5728    0.0363    0.0683      1624
           N     0.6117    0.7949    0.6914      3310
           P     0.6874    0.7884    0.7345      3610

   micro avg     0.6479    0.6479    0.6479      8544
   macro avg     0.6240    0.5399    0.4980      8544
weighted avg     0.6363    0.6479    0.5911      8544

F1-macro sent:  0.4980486493258265
F1-micro sent:  0.6479400749063671
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8462    0.0003    0.0005    124347
           N     0.0869    0.9974    0.1598     14202
           P     0.1450    0.0027    0.0053     25017

   micro avg     0.0872    0.0872    0.0872    163566
   macro avg     0.3593    0.3334    0.0552    163566
weighted avg     0.6730    0.0872    0.0151    163566

F1-macro tok:  0.055201753036638594
F1-micro tok:  0.0872125013755915
**************************************************
dev_cost_sum: 912.4922752380371
dev_cost_avg: 0.8287849911335486
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 1873.0
dev_accuracy_tok: 0.08804174109241328
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.6408730158730159
dev_label=N_recall_sent: 0.7546728971962616
dev_label=N_f-score_sent: 0.6931330472103004
dev_label=P_precision_sent: 0.6331058020477816
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7203883495145631
dev_precision_macro_sent: 0.6973868787008719
dev_recall_macro_sent: 0.5431865976085052
dev_f-score_macro_sent: 0.4961737989082879
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.0
dev_label=O_recall_tok: 0.0
dev_label=O_f-score_tok: 0.0
dev_label=N_precision_tok: 0.08743633276740238
dev_label=N_recall_tok: 0.9983844911147012
dev_label=N_f-score_tok: 0.16079094575256928
dev_label=P_precision_tok: 0.2714285714285714
dev_label=P_recall_tok: 0.005915317559153176
dev_label=P_f-score_tok: 0.01157830591102986
dev_precision_macro_tok: 0.11962163473199126
dev_recall_macro_tok: 0.3347666028912848
dev_f-score_macro_tok: 0.05745641722119971
dev_precision_micro_tok: 0.08804174109241328
dev_recall_micro_tok: 0.08804174109241328
dev_f-score_micro_tok: 0.08804174109241328
dev_time: 6.988862991333008
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.6409    0.7547    0.6931       428
           P     0.6331    0.8356    0.7204       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.6974    0.5432    0.4962      1101
weighted avg     0.6746    0.6385    0.5756      1101

F1-macro sent:  0.4961737989082879
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000     16205
           N     0.0874    0.9984    0.1608      1857
           P     0.2714    0.0059    0.0116      3212

   micro avg     0.0880    0.0880    0.0880     21274
   macro avg     0.1196    0.3348    0.0575     21274
weighted avg     0.0486    0.0880    0.0158     21274

F1-macro tok:  0.05745641722119971
F1-micro tok:  0.08804174109241328
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 7082.815967559814
train_cost_avg: 0.8289812696114015
train_count_sent: 8544.0
train_total_correct_sent: 5542.0
train_accuracy_sent: 0.6486423220973783
train_count_tok: 163566.0
train_total_correct_tok: 18403.0
train_accuracy_tok: 0.11251115757553526
train_label=O_precision_sent: 0.5032258064516129
train_label=O_recall_sent: 0.0480295566502463
train_label=O_f-score_sent: 0.08768971332209105
train_label=N_precision_sent: 0.6115437471369675
train_label=N_recall_sent: 0.8066465256797583
train_label=N_f-score_sent: 0.6956748306409588
train_label=P_precision_sent: 0.6945065871240368
train_label=P_recall_sent: 0.7739612188365651
train_label=P_f-score_sent: 0.7320843704965282
train_precision_macro_sent: 0.6030920469042057
train_recall_macro_sent: 0.5428791003888566
train_f-score_macro_sent: 0.5051496381531927
train_precision_micro_sent: 0.6486423220973783
train_recall_micro_sent: 0.6486423220973783
train_f-score_micro_sent: 0.6486423220973783
train_label=O_precision_tok: 0.898876404494382
train_label=O_recall_tok: 0.0006433609174326683
train_label=O_f-score_tok: 0.0012858015365328362
train_label=N_precision_tok: 0.09004008143529711
train_label=N_recall_tok: 0.7972116603295311
train_label=N_f-score_tok: 0.16180526774613066
train_label=P_precision_tok: 0.1855405083083773
train_label=P_recall_tok: 0.27984970220250227
train_label=P_f-score_tok: 0.22313944223107568
train_precision_macro_tok: 0.39148566474601876
train_recall_macro_tok: 0.35923490781648865
train_f-score_macro_tok: 0.12874350383791308
train_precision_micro_tok: 0.11251115757553526
train_recall_micro_tok: 0.11251115757553526
train_f-score_micro_tok: 0.11251115757553527
train_time: 126.02132987976074
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5032    0.0480    0.0877      1624
           N     0.6115    0.8066    0.6957      3310
           P     0.6945    0.7740    0.7321      3610

   micro avg     0.6486    0.6486    0.6486      8544
   macro avg     0.6031    0.5429    0.5051      8544
weighted avg     0.6260    0.6486    0.5955      8544

F1-macro sent:  0.5051496381531927
F1-micro sent:  0.6486423220973783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.0006    0.0013    124347
           N     0.0900    0.7972    0.1618     14202
           P     0.1855    0.2798    0.2231     25017

   micro avg     0.1125    0.1125    0.1125    163566
   macro avg     0.3915    0.3592    0.1287    163566
weighted avg     0.7195    0.1125    0.0492    163566

F1-macro tok:  0.12874350383791308
F1-micro tok:  0.11251115757553527
**************************************************
dev_cost_sum: 943.0567102432251
dev_cost_avg: 0.8565456042172799
dev_count_sent: 1101.0
dev_total_correct_sent: 681.0
dev_accuracy_sent: 0.6185286103542235
dev_count_tok: 21274.0
dev_total_correct_tok: 2636.0
dev_accuracy_tok: 0.12390711666823352
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5562218890554723
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.6776255707762557
dev_label=P_precision_sent: 0.7146171693735499
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7040000000000001
dev_precision_macro_sent: 0.645835241698563
dev_recall_macro_sent: 0.5230832493514614
dev_f-score_macro_sent: 0.4662889833622002
dev_precision_micro_sent: 0.6185286103542235
dev_recall_micro_sent: 0.6185286103542235
dev_f-score_micro_sent: 0.6185286103542235
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 6.17093489663684e-05
dev_label=O_f-score_tok: 0.0001234110823151919
dev_label=N_precision_tok: 0.07750205809714218
dev_label=N_recall_tok: 0.35487345180398494
dev_label=N_f-score_tok: 0.12722007722007722
dev_label=P_precision_tok: 0.1547376664056382
dev_label=P_recall_tok: 0.6151930261519303
dev_label=P_f-score_tok: 0.24727818796145665
dev_precision_macro_tok: 0.4107465748342601
dev_recall_macro_tok: 0.32337606243496053
dev_f-score_macro_tok: 0.12487389208794969
dev_precision_micro_tok: 0.12390711666823352
dev_recall_micro_tok: 0.12390711666823352
dev_f-score_micro_tok: 0.12390711666823352
dev_time: 7.050866365432739
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5562    0.8668    0.6776       428
           P     0.7146    0.6937    0.7040       444

   micro avg     0.6185    0.6185    0.6185      1101
   macro avg     0.6458    0.5231    0.4663      1101
weighted avg     0.6431    0.6185    0.5509      1101

F1-macro sent:  0.4662889833622002
F1-micro sent:  0.6185286103542235
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0001    0.0001     16205
           N     0.0775    0.3549    0.1272      1857
           P     0.1547    0.6152    0.2473      3212

   micro avg     0.1239    0.1239    0.1239     21274
   macro avg     0.4107    0.3234    0.1249     21274
weighted avg     0.7919    0.1239    0.0485     21274

F1-macro tok:  0.12487389208794969
F1-micro tok:  0.12390711666823352
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 7107.812246322632
train_cost_avg: 0.8319068640358885
train_count_sent: 8544.0
train_total_correct_sent: 5535.0
train_accuracy_sent: 0.6478230337078652
train_count_tok: 163566.0
train_total_correct_tok: 19615.0
train_accuracy_tok: 0.11992101047895039
train_label=O_precision_sent: 0.47802197802197804
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.09634551495016612
train_label=N_precision_sent: 0.6093892433910666
train_label=N_recall_sent: 0.8078549848942598
train_label=N_f-score_sent: 0.6947259028319045
train_label=P_precision_sent: 0.6980372420734776
train_label=P_recall_sent: 0.7684210526315789
train_label=P_f-score_sent: 0.7315400843881855
train_precision_macro_sent: 0.5951494878288407
train_recall_macro_sent: 0.5432824886990891
train_f-score_macro_sent: 0.5075371673900854
train_precision_micro_sent: 0.6478230337078652
train_recall_micro_sent: 0.6478230337078652
train_f-score_micro_sent: 0.6478230337078652
train_label=O_precision_tok: 0.7780429594272077
train_label=O_recall_tok: 0.0026216957385381233
train_label=O_f-score_tok: 0.00522578266514916
train_label=N_precision_tok: 0.08371801192130149
train_label=N_recall_tok: 0.5261230812561611
train_label=N_f-score_tok: 0.14445067372938697
train_label=P_precision_tok: 0.15991609716489613
train_label=P_recall_tok: 0.4723587960187073
train_label=P_f-score_tok: 0.23893966353930768
train_precision_macro_tok: 0.34055902283780176
train_recall_macro_tok: 0.3337011910044689
train_f-score_macro_tok: 0.12953870664461462
train_precision_micro_tok: 0.11992101047895039
train_recall_micro_tok: 0.11992101047895039
train_f-score_micro_tok: 0.11992101047895039
train_time: 126.13811135292053
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4780    0.0536    0.0963      1624
           N     0.6094    0.8079    0.6947      3310
           P     0.6980    0.7684    0.7315      3610

   micro avg     0.6478    0.6478    0.6478      8544
   macro avg     0.5951    0.5433    0.5075      8544
weighted avg     0.6219    0.6478    0.5965      8544

F1-macro sent:  0.5075371673900854
F1-micro sent:  0.6478230337078652
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7780    0.0026    0.0052    124347
           N     0.0837    0.5261    0.1445     14202
           P     0.1599    0.4724    0.2389     25017

   micro avg     0.1199    0.1199    0.1199    163566
   macro avg     0.3406    0.3337    0.1295    163566
weighted avg     0.6232    0.1199    0.0531    163566

F1-macro tok:  0.12953870664461462
F1-micro tok:  0.11992101047895039
**************************************************
dev_cost_sum: 933.8452911376953
dev_cost_avg: 0.8481791926772891
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 2270.0
dev_accuracy_tok: 0.10670301776816772
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.6427104722792608
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.6841530054644809
dev_label=P_precision_sent: 0.6237458193979933
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7159309021113244
dev_precision_macro_sent: 0.6304854305590847
dev_recall_macro_sent: 0.5383555411919286
dev_f-score_macro_sent: 0.49390552021234324
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.7727272727272727
dev_label=O_recall_tok: 0.001049058932428263
dev_label=O_f-score_tok: 0.002095273309915573
dev_label=N_precision_tok: 0.08564617742210114
dev_label=N_recall_tok: 0.8126009693053312
dev_label=N_f-score_tok: 0.1549599507085644
dev_label=P_precision_tok: 0.20478943022295623
dev_label=P_recall_tok: 0.23163138231631383
dev_label=P_f-score_tok: 0.21738495252008763
dev_precision_macro_tok: 0.3543876267907767
dev_recall_macro_tok: 0.3484271368513578
dev_f-score_macro_tok: 0.12481339217952253
dev_precision_micro_tok: 0.10670301776816772
dev_recall_micro_tok: 0.10670301776816772
dev_f-score_micro_tok: 0.10670301776816773
dev_time: 7.336267471313477
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6427    0.7313    0.6842       428
           P     0.6237    0.8401    0.7159       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.6305    0.5384    0.4939      1101
weighted avg     0.6314    0.6322    0.5716      1101

F1-macro sent:  0.49390552021234324
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7727    0.0010    0.0021     16205
           N     0.0856    0.8126    0.1550      1857
           P     0.2048    0.2316    0.2174      3212

   micro avg     0.1067    0.1067    0.1067     21274
   macro avg     0.3544    0.3484    0.1248     21274
weighted avg     0.6270    0.1067    0.0479     21274

F1-macro tok:  0.12481339217952253
F1-micro tok:  0.10670301776816773
**************************************************
Best epoch: 6
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 6978.277067184448
train_cost_avg: 0.8167459114214007
train_count_sent: 8544.0
train_total_correct_sent: 5581.0
train_accuracy_sent: 0.6532069288389513
train_count_tok: 163566.0
train_total_correct_tok: 19711.0
train_accuracy_tok: 0.12050792952080505
train_label=O_precision_sent: 0.4909090909090909
train_label=O_recall_sent: 0.049876847290640396
train_label=O_f-score_sent: 0.09055338177752935
train_label=N_precision_sent: 0.6172148355493352
train_label=N_recall_sent: 0.7993957703927492
train_label=N_f-score_sent: 0.696590759510333
train_label=P_precision_sent: 0.6974584555229717
train_label=P_recall_sent: 0.7905817174515235
train_label=P_f-score_sent: 0.741106206180213
train_precision_macro_sent: 0.6018607939937993
train_recall_macro_sent: 0.5466181117116377
train_f-score_macro_sent: 0.5094167824893584
train_precision_micro_sent: 0.6532069288389513
train_recall_micro_sent: 0.6532069288389513
train_f-score_micro_sent: 0.6532069288389513
train_label=O_precision_tok: 0.7735849056603774
train_label=O_recall_tok: 0.0016486123509212125
train_label=O_f-score_tok: 0.0032902128205951273
train_label=N_precision_tok: 0.09197243373335633
train_label=N_recall_tok: 0.7884100830868892
train_label=N_f-score_tok: 0.1647283828018684
train_label=P_precision_tok: 0.19993743683526638
train_label=P_recall_tok: 0.3321341487788304
train_label=P_f-score_tok: 0.24961321817499063
train_precision_macro_tok: 0.3551649254096667
train_recall_macro_tok: 0.3740642814055469
train_f-score_macro_tok: 0.13921060459915138
train_precision_micro_tok: 0.12050792952080505
train_recall_micro_tok: 0.12050792952080505
train_f-score_micro_tok: 0.12050792952080505
train_time: 126.43449783325195
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4909    0.0499    0.0906      1624
           N     0.6172    0.7994    0.6966      3310
           P     0.6975    0.7906    0.7411      3610

   micro avg     0.6532    0.6532    0.6532      8544
   macro avg     0.6019    0.5466    0.5094      8544
weighted avg     0.6271    0.6532    0.6002      8544

F1-macro sent:  0.5094167824893584
F1-micro sent:  0.6532069288389513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7736    0.0016    0.0033    124347
           N     0.0920    0.7884    0.1647     14202
           P     0.1999    0.3321    0.2496     25017

   micro avg     0.1205    0.1205    0.1205    163566
   macro avg     0.3552    0.3741    0.1392    163566
weighted avg     0.6267    0.1205    0.0550    163566

F1-macro tok:  0.13921060459915138
F1-micro tok:  0.12050792952080505
**************************************************
dev_cost_sum: 926.0541563034058
dev_cost_avg: 0.8411027759340651
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 2675.0
dev_accuracy_tok: 0.12574034032151923
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6080843585237259
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.6940822467402208
dev_label=P_precision_sent: 0.6704980842911877
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7246376811594203
dev_precision_macro_sent: 0.6928608142716378
dev_recall_macro_sent: 0.5438780003527177
dev_f-score_macro_sent: 0.4952218448647339
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8095238095238095
dev_label=O_recall_tok: 0.001049058932428263
dev_label=O_f-score_tok: 0.0020954024405275486
dev_label=N_precision_tok: 0.09492939666238767
dev_label=N_recall_tok: 0.7964458804523424
dev_label=N_f-score_tok: 0.1696392728106899
dev_label=P_precision_tok: 0.2078265468006346
dev_label=P_recall_tok: 0.36706102117061024
dev_label=P_f-score_tok: 0.26539110861001686
dev_precision_macro_tok: 0.3707599176622773
dev_recall_macro_tok: 0.388185320185127
dev_f-score_macro_tok: 0.14570859462041144
dev_precision_micro_tok: 0.12574034032151923
dev_recall_micro_tok: 0.12574034032151923
dev_f-score_micro_tok: 0.12574034032151923
dev_time: 7.354709625244141
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6081    0.8084    0.6941       428
           P     0.6705    0.7883    0.7246       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6929    0.5439    0.4952      1101
weighted avg     0.6732    0.6394    0.5760      1101

F1-macro sent:  0.4952218448647339
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8095    0.0010    0.0021     16205
           N     0.0949    0.7964    0.1696      1857
           P     0.2078    0.3671    0.2654      3212

   micro avg     0.1257    0.1257    0.1257     21274
   macro avg     0.3708    0.3882    0.1457     21274
weighted avg     0.6563    0.1257    0.0565     21274

F1-macro tok:  0.14570859462041144
F1-micro tok:  0.12574034032151923
**************************************************
Best epoch: 6
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 6922.255229949951
train_cost_avg: 0.8101890484491984
train_count_sent: 8544.0
train_total_correct_sent: 5648.0
train_accuracy_sent: 0.6610486891385767
train_count_tok: 163566.0
train_total_correct_tok: 20342.0
train_accuracy_tok: 0.12436569947299561
train_label=O_precision_sent: 0.5186915887850467
train_label=O_recall_sent: 0.06834975369458128
train_label=O_f-score_sent: 0.1207834602829162
train_label=N_precision_sent: 0.6203746002740977
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.7065556711758586
train_label=P_precision_sent: 0.7138157894736842
train_label=P_recall_sent: 0.7814404432132964
train_label=P_f-score_sent: 0.7460989156307855
train_precision_macro_sent: 0.6176273261776095
train_recall_macro_sent: 0.5567780011848011
train_f-score_macro_sent: 0.5244793490298534
train_precision_micro_sent: 0.6610486891385767
train_recall_micro_sent: 0.6610486891385767
train_f-score_micro_sent: 0.6610486891385767
train_label=O_precision_tok: 0.7634069400630915
train_label=O_recall_tok: 0.003892333550467643
train_label=O_f-score_tok: 0.007745177266944575
train_label=N_precision_tok: 0.09387946067798052
train_label=N_recall_tok: 0.7770736515983664
train_label=N_f-score_tok: 0.16752051124418438
train_label=P_precision_tok: 0.19441567313837407
train_label=P_recall_tok: 0.3526402046608306
train_label=P_f-score_tok: 0.2506463619058442
train_precision_macro_tok: 0.35056735795981536
train_recall_macro_tok: 0.3778687299365549
train_f-score_macro_tok: 0.1419706834723244
train_precision_micro_tok: 0.12436569947299561
train_recall_micro_tok: 0.12436569947299561
train_f-score_micro_tok: 0.12436569947299561
train_time: 125.72890520095825
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5187    0.0683    0.1208      1624
           N     0.6204    0.8205    0.7066      3310
           P     0.7138    0.7814    0.7461      3610

   micro avg     0.6610    0.6610    0.6610      8544
   macro avg     0.6176    0.5568    0.5245      8544
weighted avg     0.6405    0.6610    0.6119      8544

F1-macro sent:  0.5244793490298534
F1-micro sent:  0.6610486891385767
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7634    0.0039    0.0077    124347
           N     0.0939    0.7771    0.1675     14202
           P     0.1944    0.3526    0.2506     25017

   micro avg     0.1244    0.1244    0.1244    163566
   macro avg     0.3506    0.3779    0.1420    163566
weighted avg     0.6182    0.1244    0.0588    163566

F1-macro tok:  0.1419706834723244
F1-micro tok:  0.12436569947299561
**************************************************
dev_cost_sum: 919.3848667144775
dev_cost_avg: 0.8350452922020686
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 2723.0
dev_accuracy_tok: 0.12799661558710163
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6492985971943888
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.6990291262135923
dev_label=P_precision_sent: 0.6402027027027027
dev_label=P_recall_sent: 0.8536036036036037
dev_label=P_f-score_sent: 0.7316602316602318
dev_precision_macro_sent: 0.6631670999656971
dev_recall_macro_sent: 0.5470602116625053
dev_f-score_macro_sent: 0.4964222545771882
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.88
dev_label=O_recall_tok: 0.001357605677260105
dev_label=O_f-score_tok: 0.002711028958718423
dev_label=N_precision_tok: 0.09437652811735942
dev_label=N_recall_tok: 0.7275175013462574
dev_label=N_f-score_tok: 0.1670789018055899
dev_label=P_precision_tok: 0.1946928179982694
dev_label=P_recall_tok: 0.4202988792029888
dev_label=P_f-score_tok: 0.26611472501478417
dev_precision_macro_tok: 0.38968978203854293
dev_recall_macro_tok: 0.3830579954088354
dev_f-score_macro_tok: 0.14530155192636415
dev_precision_micro_tok: 0.12799661558710163
dev_recall_micro_tok: 0.12799661558710163
dev_f-score_micro_tok: 0.12799661558710163
dev_time: 7.123821258544922
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6493    0.7570    0.6990       428
           P     0.6402    0.8536    0.7317       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.6632    0.5471    0.4964      1101
weighted avg     0.6562    0.6449    0.5790      1101

F1-macro sent:  0.4964222545771882
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8800    0.0014    0.0027     16205
           N     0.0944    0.7275    0.1671      1857
           P     0.1947    0.4203    0.2661      3212

   micro avg     0.1280    0.1280    0.1280     21274
   macro avg     0.3897    0.3831    0.1453     21274
weighted avg     0.7080    0.1280    0.0568     21274

F1-macro tok:  0.14530155192636415
F1-micro tok:  0.12799661558710163
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 6846.780649185181
train_cost_avg: 0.8013554130600633
train_count_sent: 8544.0
train_total_correct_sent: 5665.0
train_accuracy_sent: 0.6630383895131086
train_count_tok: 163566.0
train_total_correct_tok: 18036.0
train_accuracy_tok: 0.11026741498844503
train_label=O_precision_sent: 0.5592105263157895
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.09572072072072071
train_label=N_precision_sent: 0.6384015594541911
train_label=N_recall_sent: 0.7915407854984894
train_label=N_f-score_sent: 0.7067709738332885
train_label=P_precision_sent: 0.6902985074626866
train_label=P_recall_sent: 0.8199445983379502
train_label=P_f-score_sent: 0.7495568498354014
train_precision_macro_sent: 0.6293035310775558
train_recall_macro_sent: 0.5546084284380907
train_f-score_macro_sent: 0.5173495147964702
train_precision_micro_sent: 0.6630383895131086
train_recall_micro_sent: 0.6630383895131086
train_f-score_micro_sent: 0.6630383895131086
train_label=O_precision_tok: 0.7974683544303798
train_label=O_recall_tok: 0.0010132934449564525
train_label=O_f-score_tok: 0.0020240150997951887
train_label=N_precision_tok: 0.08806130364264615
train_label=N_recall_tok: 0.7913674130404168
train_label=N_f-score_tok: 0.15848662826361323
train_label=P_precision_tok: 0.18643973058327046
train_label=P_recall_tok: 0.26665867210297
train_label=P_f-score_tok: 0.2194480081581631
train_precision_macro_tok: 0.35732312955209883
train_recall_macro_tok: 0.3530131261961144
train_f-score_macro_tok: 0.12665288384052384
train_precision_micro_tok: 0.11026741498844503
train_recall_micro_tok: 0.11026741498844503
train_f-score_micro_tok: 0.11026741498844503
train_time: 127.16295099258423
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5592    0.0523    0.0957      1624
           N     0.6384    0.7915    0.7068      3310
           P     0.6903    0.8199    0.7496      3610

   micro avg     0.6630    0.6630    0.6630      8544
   macro avg     0.6293    0.5546    0.5173      8544
weighted avg     0.6453    0.6630    0.6087      8544

F1-macro sent:  0.5173495147964702
F1-micro sent:  0.6630383895131086
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7975    0.0010    0.0020    124347
           N     0.0881    0.7914    0.1585     14202
           P     0.1864    0.2667    0.2194     25017

   micro avg     0.1103    0.1103    0.1103    163566
   macro avg     0.3573    0.3530    0.1267    163566
weighted avg     0.6424    0.1103    0.0489    163566

F1-macro tok:  0.12665288384052384
F1-micro tok:  0.11026741498844503
**************************************************
dev_cost_sum: 893.893476486206
dev_cost_avg: 0.8118923492154461
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 2377.0
dev_accuracy_tok: 0.11173263138102849
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6062717770034843
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.6946107784431138
dev_label=P_precision_sent: 0.6819923371647509
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7370600414078674
dev_precision_macro_sent: 0.6294213713894118
dev_recall_macro_sent: 0.5426621168775191
dev_f-score_macro_sent: 0.4857706151640023
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8571428571428571
dev_label=O_recall_tok: 0.0003702560937982104
dev_label=O_f-score_tok: 0.0007401924500370096
dev_label=N_precision_tok: 0.08870165584225616
dev_label=N_recall_tok: 0.8163704900376952
dev_label=N_f-score_tok: 0.16001688832594468
dev_label=P_precision_tok: 0.20474137931034483
dev_label=P_recall_tok: 0.2661892901618929
dev_label=P_f-score_tok: 0.2314564158094207
dev_precision_macro_tok: 0.3835286307651527
dev_recall_macro_tok: 0.36097667876446216
dev_f-score_macro_tok: 0.13073783219513413
dev_precision_micro_tok: 0.11173263138102849
dev_recall_micro_tok: 0.11173263138102849
dev_f-score_micro_tok: 0.11173263138102849
dev_time: 7.054640769958496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6063    0.8131    0.6946       428
           P     0.6820    0.8018    0.7371       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6294    0.5427    0.4858      1101
weighted avg     0.6355    0.6421    0.5726      1101

F1-macro sent:  0.4857706151640023
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0004    0.0007     16205
           N     0.0887    0.8164    0.1600      1857
           P     0.2047    0.2662    0.2315      3212

   micro avg     0.1117    0.1117    0.1117     21274
   macro avg     0.3835    0.3610    0.1307     21274
weighted avg     0.6916    0.1117    0.0495     21274

F1-macro tok:  0.13073783219513413
F1-micro tok:  0.11173263138102849
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 6701.565123558044
train_cost_avg: 0.7843592138995839
train_count_sent: 8544.0
train_total_correct_sent: 5656.0
train_accuracy_sent: 0.6619850187265918
train_count_tok: 163566.0
train_total_correct_tok: 16379.0
train_accuracy_tok: 0.10013694777643276
train_label=O_precision_sent: 0.4527363184079602
train_label=O_recall_sent: 0.05603448275862069
train_label=O_f-score_sent: 0.09972602739726028
train_label=N_precision_sent: 0.6493046776232617
train_label=N_recall_sent: 0.7758308157099698
train_label=N_f-score_sent: 0.7069511355815554
train_label=P_precision_sent: 0.6829990884229717
train_label=P_recall_sent: 0.8301939058171746
train_label=P_f-score_sent: 0.7494373593398349
train_precision_macro_sent: 0.5950133614847312
train_recall_macro_sent: 0.5540197347619217
train_f-score_macro_sent: 0.5187048407728835
train_precision_micro_sent: 0.6619850187265918
train_recall_micro_sent: 0.6619850187265918
train_f-score_micro_sent: 0.6619850187265918
train_label=O_precision_tok: 0.8813559322033898
train_label=O_recall_tok: 0.0004181845963312344
train_label=O_f-score_tok: 0.0008359725415172902
train_label=N_precision_tok: 0.08524151884099859
train_label=N_recall_tok: 0.8306576538515702
train_label=N_f-score_tok: 0.15461640792414005
train_label=P_precision_tok: 0.18039184453647658
train_label=P_recall_tok: 0.18107686772994364
train_label=P_f-score_tok: 0.1807337070358475
train_precision_macro_tok: 0.38232976519362166
train_recall_macro_tok: 0.33738423539261503
train_f-score_macro_tok: 0.11206202916716829
train_precision_micro_tok: 0.10013694777643276
train_recall_micro_tok: 0.10013694777643276
train_f-score_micro_tok: 0.10013694777643276
train_time: 126.45147490501404
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4527    0.0560    0.0997      1624
           N     0.6493    0.7758    0.7070      3310
           P     0.6830    0.8302    0.7494      3610

   micro avg     0.6620    0.6620    0.6620      8544
   macro avg     0.5950    0.5540    0.5187      8544
weighted avg     0.6262    0.6620    0.6095      8544

F1-macro sent:  0.5187048407728835
F1-micro sent:  0.6619850187265918
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8814    0.0004    0.0008    124347
           N     0.0852    0.8307    0.1546     14202
           P     0.1804    0.1811    0.1807     25017

   micro avg     0.1001    0.1001    0.1001    163566
   macro avg     0.3823    0.3374    0.1121    163566
weighted avg     0.7050    0.1001    0.0417    163566

F1-macro tok:  0.11206202916716829
F1-micro tok:  0.10013694777643276
**************************************************
dev_cost_sum: 899.6728363037109
dev_cost_avg: 0.8171415406936521
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 1945.0
dev_accuracy_tok: 0.09142615399078688
dev_label=O_precision_sent: 0.7692307692307693
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08264462809917354
dev_label=N_precision_sent: 0.6149732620320856
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.6976744186046512
dev_label=P_precision_sent: 0.6698292220113852
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7270854788877446
dev_precision_macro_sent: 0.6846777510914134
dev_recall_macro_sent: 0.5482626445569759
dev_f-score_macro_sent: 0.5024681751971897
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.000308546744831842
dev_label=O_f-score_tok: 0.0006169031462060457
dev_label=N_precision_tok: 0.08424574209245742
dev_label=N_recall_tok: 0.8949919224555735
dev_label=N_f-score_tok: 0.15399583043780402
dev_label=P_precision_tok: 0.18040233614536016
dev_label=P_recall_tok: 0.08655043586550436
dev_label=P_f-score_tok: 0.11697875026299179
dev_precision_macro_tok: 0.42154935941260585
dev_recall_macro_tok: 0.3272836350219699
dev_f-score_macro_tok: 0.09053049461566727
dev_precision_micro_tok: 0.09142615399078688
dev_recall_micro_tok: 0.09142615399078688
dev_f-score_micro_tok: 0.09142615399078688
dev_time: 7.553788900375366
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7692    0.0437    0.0826       229
           N     0.6150    0.8061    0.6977       428
           P     0.6698    0.7950    0.7271       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6847    0.5483    0.5025      1101
weighted avg     0.6692    0.6431    0.5816      1101

F1-macro sent:  0.5024681751971897
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0003    0.0006     16205
           N     0.0842    0.8950    0.1540      1857
           P     0.1804    0.0866    0.1170      3212

   micro avg     0.0914    0.0914    0.0914     21274
   macro avg     0.4215    0.3273    0.0905     21274
weighted avg     0.7963    0.0914    0.0316     21274

F1-macro tok:  0.09053049461566727
F1-micro tok:  0.09142615399078688
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 6765.7150802612305
train_cost_avg: 0.791867401715968
train_count_sent: 8544.0
train_total_correct_sent: 5653.0
train_accuracy_sent: 0.6616338951310862
train_count_tok: 163566.0
train_total_correct_tok: 14016.0
train_accuracy_tok: 0.08569018011078097
train_label=O_precision_sent: 0.5329341317365269
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.0993858179787828
train_label=N_precision_sent: 0.626129256428075
train_label=N_recall_sent: 0.8166163141993957
train_label=N_f-score_sent: 0.7087976924085486
train_label=P_precision_sent: 0.704679802955665
train_label=P_recall_sent: 0.7925207756232687
train_label=P_f-score_sent: 0.7460234680573663
train_precision_macro_sent: 0.6212477303734224
train_recall_macro_sent: 0.5546466818292296
train_f-score_macro_sent: 0.5180689928148993
train_precision_micro_sent: 0.6616338951310862
train_recall_micro_sent: 0.6616338951310862
train_f-score_micro_sent: 0.6616338951310862
train_label=O_precision_tok: 0.8266666666666667
train_label=O_recall_tok: 0.0004986047110103179
train_label=O_f-score_tok: 0.0009966083168571475
train_label=N_precision_tok: 0.0758730303583379
train_label=N_recall_tok: 0.7025066891987044
train_label=N_f-score_tok: 0.13695452236818625
train_label=P_precision_tok: 0.12430067197999688
train_label=P_recall_tok: 0.15897189910860615
train_label=P_f-score_tok: 0.13951448817792744
train_precision_macro_tok: 0.34228012300166716
train_recall_macro_tok: 0.287325731006107
train_f-score_macro_tok: 0.09248853962099028
train_precision_micro_tok: 0.08569018011078097
train_recall_micro_tok: 0.08569018011078097
train_f-score_micro_tok: 0.08569018011078097
train_time: 127.02252674102783
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5329    0.0548    0.0994      1624
           N     0.6261    0.8166    0.7088      3310
           P     0.7047    0.7925    0.7460      3610

   micro avg     0.6616    0.6616    0.6616      8544
   macro avg     0.6212    0.5546    0.5181      8544
weighted avg     0.6416    0.6616    0.6087      8544

F1-macro sent:  0.5180689928148993
F1-micro sent:  0.6616338951310862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8267    0.0005    0.0010    124347
           N     0.0759    0.7025    0.1370     14202
           P     0.1243    0.1590    0.1395     25017

   micro avg     0.0857    0.0857    0.0857    163566
   macro avg     0.3423    0.2873    0.0925    163566
weighted avg     0.6541    0.0857    0.0340    163566

F1-macro tok:  0.09248853962099028
F1-micro tok:  0.08569018011078097
**************************************************
dev_cost_sum: 921.1567897796631
dev_cost_avg: 0.8366546682830728
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 1768.0
dev_accuracy_tok: 0.08310613894895177
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6241007194244604
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7052845528455284
dev_label=P_precision_sent: 0.6697416974169742
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7363083164300204
dev_precision_macro_sent: 0.7646141389471448
dev_recall_macro_sent: 0.5471385559333973
dev_f-score_macro_sent: 0.48915164608035533
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.0002468373958654736
dev_label=O_f-score_tok: 0.0004935529644024924
dev_label=N_precision_tok: 0.08235525217305897
dev_label=N_recall_tok: 0.9030694668820679
dev_label=N_f-score_tok: 0.15094509450945093
dev_label=P_precision_tok: 0.09592061742006615
dev_label=P_recall_tok: 0.02708592777085928
dev_label=P_f-score_tok: 0.042243262927895125
dev_precision_macro_tok: 0.39275862319770843
dev_recall_macro_tok: 0.3101340773495976
dev_f-score_macro_tok: 0.06456063680058284
dev_precision_micro_tok: 0.08310613894895177
dev_recall_micro_tok: 0.08310613894895177
dev_f-score_micro_tok: 0.08310613894895177
dev_time: 7.276059627532959
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6241    0.8107    0.7053       428
           P     0.6697    0.8176    0.7363       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7646    0.5471    0.4892      1101
weighted avg     0.7207    0.6476    0.5765      1101

F1-macro sent:  0.48915164608035533
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0002    0.0005     16205
           N     0.0824    0.9031    0.1509      1857
           P     0.0959    0.0271    0.0422      3212

   micro avg     0.0831    0.0831    0.0831     21274
   macro avg     0.3928    0.3101    0.0646     21274
weighted avg     0.7834    0.0831    0.0199     21274

F1-macro tok:  0.06456063680058284
F1-micro tok:  0.08310613894895177
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 6588.028929710388
train_cost_avg: 0.7710708016983132
train_count_sent: 8544.0
train_total_correct_sent: 5726.0
train_accuracy_sent: 0.6701779026217228
train_count_tok: 163566.0
train_total_correct_tok: 13529.0
train_accuracy_tok: 0.08271278872137242
train_label=O_precision_sent: 0.580952380952381
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.13304252998909485
train_label=N_precision_sent: 0.6387310606060606
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.7162198035572073
train_label=P_precision_sent: 0.7070559610705596
train_label=P_recall_sent: 0.8049861495844876
train_label=P_f-score_sent: 0.7528497409326426
train_precision_macro_sent: 0.6422464675430004
train_recall_macro_sent: 0.5650716808250387
train_f-score_macro_sent: 0.5340373581596483
train_precision_micro_sent: 0.6701779026217228
train_recall_micro_sent: 0.6701779026217228
train_f-score_micro_sent: 0.6701779026217228
train_label=O_precision_tok: 0.8938053097345132
train_label=O_recall_tok: 0.0008122431582587437
train_label=O_f-score_tok: 0.0016230114092881248
train_label=N_precision_tok: 0.07393462654650985
train_label=N_recall_tok: 0.6816645542881284
train_label=N_f-score_tok: 0.13340039409681553
train_label=P_precision_tok: 0.11524620920862425
train_label=P_recall_tok: 0.14977815085741697
train_label=P_f-score_tok: 0.13026247175386754
train_precision_macro_tok: 0.3609953818298824
train_recall_macro_tok: 0.27741831610126805
train_f-score_macro_tok: 0.08842862575332373
train_precision_micro_tok: 0.08271278872137242
train_recall_micro_tok: 0.08271278872137242
train_f-score_micro_tok: 0.08271278872137242
train_time: 127.16894435882568
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5810    0.0751    0.1330      1624
           N     0.6387    0.8151    0.7162      3310
           P     0.7071    0.8050    0.7528      3610

   micro avg     0.6702    0.6702    0.6702      8544
   macro avg     0.6422    0.5651    0.5340      8544
weighted avg     0.6566    0.6702    0.6208      8544

F1-macro sent:  0.5340373581596483
F1-micro sent:  0.6701779026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8938    0.0008    0.0016    124347
           N     0.0739    0.6817    0.1334     14202
           P     0.1152    0.1498    0.1303     25017

   micro avg     0.0827    0.0827    0.0827    163566
   macro avg     0.3610    0.2774    0.0884    163566
weighted avg     0.7035    0.0827    0.0327    163566

F1-macro tok:  0.08842862575332373
F1-micro tok:  0.08271278872137242
**************************************************
dev_cost_sum: 893.9929552078247
dev_cost_avg: 0.8119827022777699
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 1905.0
dev_accuracy_tok: 0.08954592460280154
dev_label=O_precision_sent: 0.5454545454545454
dev_label=O_recall_sent: 0.10480349344978165
dev_label=O_f-score_sent: 0.1758241758241758
dev_label=N_precision_sent: 0.6304347826086957
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.710204081632653
dev_label=P_precision_sent: 0.7029702970297029
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7481559536354057
dev_precision_macro_sent: 0.6262865416976481
dev_recall_macro_sent: 0.572479051716288
dev_f-score_macro_sent: 0.5447280703640781
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9166666666666666
dev_label=O_recall_tok: 0.0006788028386300525
dev_label=O_f-score_tok: 0.0013566010976136154
dev_label=N_precision_tok: 0.07579151280343846
dev_label=N_recall_tok: 0.6742057081313947
dev_label=N_f-score_tok: 0.13626469307792774
dev_label=P_precision_tok: 0.13535736875395318
dev_label=P_recall_tok: 0.19987546699875466
dev_label=P_f-score_tok: 0.16140791954745443
dev_precision_macro_tok: 0.37593851607468604
dev_recall_macro_tok: 0.2915866593229265
dev_f-score_macro_tok: 0.09967640457433193
dev_precision_micro_tok: 0.08954592460280154
dev_recall_micro_tok: 0.08954592460280154
dev_f-score_micro_tok: 0.08954592460280154
dev_time: 7.096678972244263
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.1048    0.1758       229
           N     0.6304    0.8131    0.7102       428
           P     0.7030    0.7995    0.7482       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.6263    0.5725    0.5447      1101
weighted avg     0.6420    0.6603    0.6144      1101

F1-macro sent:  0.5447280703640781
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9167    0.0007    0.0014     16205
           N     0.0758    0.6742    0.1363      1857
           P     0.1354    0.1999    0.1614      3212

   micro avg     0.0895    0.0895    0.0895     21274
   macro avg     0.3759    0.2916    0.0997     21274
weighted avg     0.7253    0.0895    0.0373     21274

F1-macro tok:  0.09967640457433193
F1-micro tok:  0.08954592460280154
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 6526.390348434448
train_cost_avg: 0.7638565482718221
train_count_sent: 8544.0
train_total_correct_sent: 5750.0
train_accuracy_sent: 0.6729868913857678
train_count_tok: 163566.0
train_total_correct_tok: 14937.0
train_accuracy_tok: 0.09132093466857415
train_label=O_precision_sent: 0.5185185185185185
train_label=O_recall_sent: 0.09482758620689655
train_label=O_f-score_sent: 0.16033315981259758
train_label=N_precision_sent: 0.6527604296777417
train_label=N_recall_sent: 0.7894259818731117
train_label=N_f-score_sent: 0.7146178039108438
train_label=P_precision_sent: 0.7028746465598492
train_label=P_recall_sent: 0.8263157894736842
train_label=P_f-score_sent: 0.7596129360835243
train_precision_macro_sent: 0.6247178649187032
train_recall_macro_sent: 0.5701897858512308
train_f-score_macro_sent: 0.5448546332689886
train_precision_micro_sent: 0.6729868913857678
train_recall_micro_sent: 0.6729868913857678
train_f-score_micro_sent: 0.6729868913857678
train_label=O_precision_tok: 0.9142857142857143
train_label=O_recall_tok: 0.0010293774678922691
train_label=O_f-score_tok: 0.0020564396282342734
train_label=N_precision_tok: 0.06817162657969833
train_label=N_recall_tok: 0.47099000140825237
train_label=N_f-score_tok: 0.11910400455832339
train_label=P_precision_tok: 0.12433773313324963
train_label=P_recall_tok: 0.3245792860854619
train_label=P_f-score_tok: 0.1797991652181615
train_precision_macro_tok: 0.36893169133288745
train_recall_macro_tok: 0.2655328883205355
train_f-score_macro_tok: 0.10031986980157305
train_precision_micro_tok: 0.09132093466857415
train_recall_micro_tok: 0.09132093466857415
train_f-score_micro_tok: 0.09132093466857415
train_time: 127.27348732948303
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5185    0.0948    0.1603      1624
           N     0.6528    0.7894    0.7146      3310
           P     0.7029    0.8263    0.7596      3610

   micro avg     0.6730    0.6730    0.6730      8544
   macro avg     0.6247    0.5702    0.5449      8544
weighted avg     0.6484    0.6730    0.6283      8544

F1-macro sent:  0.5448546332689886
F1-micro sent:  0.6729868913857678
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9143    0.0010    0.0021    124347
           N     0.0682    0.4710    0.1191     14202
           P     0.1243    0.3246    0.1798     25017

   micro avg     0.0913    0.0913    0.0913    163566
   macro avg     0.3689    0.2655    0.1003    163566
weighted avg     0.7200    0.0913    0.0394    163566

F1-macro tok:  0.10031986980157305
F1-micro tok:  0.09132093466857415
**************************************************
dev_cost_sum: 925.8512487411499
dev_cost_avg: 0.8409184820537238
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 1776.0
dev_accuracy_tok: 0.08348218482654884
dev_label=O_precision_sent: 0.43333333333333335
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10038610038610038
dev_label=N_precision_sent: 0.7095959595959596
dev_label=N_recall_sent: 0.6565420560747663
dev_label=N_f-score_sent: 0.6820388349514562
dev_label=P_precision_sent: 0.6074074074074074
dev_label=P_recall_sent: 0.9234234234234234
dev_label=P_f-score_sent: 0.7327971403038428
dev_precision_macro_sent: 0.5834455667789001
dev_recall_macro_sent: 0.5455780128167182
dev_f-score_macro_sent: 0.5050740252137998
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.0003702560937982104
dev_label=O_f-score_tok: 0.0007402381099253593
dev_label=N_precision_tok: 0.07608695652173914
dev_label=N_recall_tok: 0.7312870220786214
dev_label=N_f-score_tok: 0.13783303730017762
dev_label=P_precision_tok: 0.12046783625730995
dev_label=P_recall_tok: 0.12826899128268993
dev_label=P_f-score_tok: 0.12424607961399278
dev_precision_macro_tok: 0.3988515975930164
dev_recall_macro_tok: 0.28664208981836986
dev_f-score_macro_tok: 0.08760645167469859
dev_precision_micro_tok: 0.08348218482654884
dev_recall_micro_tok: 0.08348218482654884
dev_f-score_micro_tok: 0.08348218482654884
dev_time: 7.137654542922974
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4333    0.0568    0.1004       229
           N     0.7096    0.6565    0.6820       428
           P     0.6074    0.9234    0.7328       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.5834    0.5456    0.5051      1101
weighted avg     0.6109    0.6394    0.5815      1101

F1-macro sent:  0.5050740252137998
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0004    0.0007     16205
           N     0.0761    0.7313    0.1378      1857
           P     0.1205    0.1283    0.1242      3212

   micro avg     0.0835    0.0835    0.0835     21274
   macro avg     0.3989    0.2866    0.0876     21274
weighted avg     0.7866    0.0835    0.0314     21274

F1-macro tok:  0.08760645167469859
F1-micro tok:  0.08348218482654884
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 6508.288636207581
train_cost_avg: 0.7617379021778535
train_count_sent: 8544.0
train_total_correct_sent: 5791.0
train_accuracy_sent: 0.6777855805243446
train_count_tok: 163566.0
train_total_correct_tok: 18946.0
train_accuracy_tok: 0.1158309184060257
train_label=O_precision_sent: 0.5521235521235521
train_label=O_recall_sent: 0.08805418719211823
train_label=O_f-score_sent: 0.15188528943175783
train_label=N_precision_sent: 0.6418918918918919
train_label=N_recall_sent: 0.8323262839879154
train_label=N_f-score_sent: 0.724809260720863
train_label=P_precision_sent: 0.7245179063360881
train_label=P_recall_sent: 0.8013850415512466
train_label=P_f-score_sent: 0.7610153886623702
train_precision_macro_sent: 0.6395111167838441
train_recall_macro_sent: 0.5739218375770934
train_f-score_macro_sent: 0.5459033129383304
train_precision_micro_sent: 0.6777855805243446
train_recall_micro_sent: 0.6777855805243446
train_f-score_micro_sent: 0.6777855805243446
train_label=O_precision_tok: 0.8994708994708994
train_label=O_recall_tok: 0.00136714194954442
train_label=O_f-score_tok: 0.002730134258367058
train_label=N_precision_tok: 0.06847005488844346
train_label=N_recall_tok: 0.25735811857484864
train_label=N_f-score_tok: 0.10816329550330707
train_label=P_precision_tok: 0.13746863522309902
train_label=P_recall_tok: 0.6044289882879642
train_label=P_f-score_tok: 0.22399324509491678
train_precision_macro_tok: 0.36846986319414726
train_recall_macro_tok: 0.28771808293745244
train_f-score_macro_tok: 0.11162889161886363
train_precision_micro_tok: 0.1158309184060257
train_recall_micro_tok: 0.1158309184060257
train_f-score_micro_tok: 0.1158309184060257
train_time: 126.52998161315918
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5521    0.0881    0.1519      1624
           N     0.6419    0.8323    0.7248      3310
           P     0.7245    0.8014    0.7610      3610

   micro avg     0.6778    0.6778    0.6778      8544
   macro avg     0.6395    0.5739    0.5459      8544
weighted avg     0.6597    0.6778    0.6312      8544

F1-macro sent:  0.5459033129383304
F1-micro sent:  0.6777855805243446
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8995    0.0014    0.0027    124347
           N     0.0685    0.2574    0.1082     14202
           P     0.1375    0.6044    0.2240     25017

   micro avg     0.1158    0.1158    0.1158    163566
   macro avg     0.3685    0.2877    0.1116    163566
weighted avg     0.7108    0.1158    0.0457    163566

F1-macro tok:  0.11162889161886363
F1-micro tok:  0.1158309184060257
**************************************************
dev_cost_sum: 920.1725015640259
dev_cost_avg: 0.8357606735368083
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 2238.0
dev_accuracy_tok: 0.10519883425777946
dev_label=O_precision_sent: 0.5384615384615384
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10980392156862745
dev_label=N_precision_sent: 0.662
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7133620689655172
dev_label=P_precision_sent: 0.6608695652173913
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.745829244357213
dev_precision_macro_sent: 0.6204437012263099
dev_recall_macro_sent: 0.5634519043387346
dev_f-score_macro_sent: 0.5229984116304526
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.000617093489663684
dev_label=O_f-score_tok: 0.0012334258402713536
dev_label=N_precision_tok: 0.05265109380793474
dev_label=N_recall_tok: 0.15293484114162628
dev_label=N_f-score_tok: 0.07833402289339401
dev_label=P_precision_tok: 0.1224952741020794
dev_label=P_recall_tok: 0.6052303860523038
dev_label=P_f-score_tok: 0.20375222722985012
dev_precision_macro_tok: 0.39171545597000473
dev_recall_macro_tok: 0.25292744022786456
dev_f-score_macro_tok: 0.09443989198783849
dev_precision_micro_tok: 0.10519883425777946
dev_recall_micro_tok: 0.10519883425777946
dev_f-score_micro_tok: 0.10519883425777946
dev_time: 7.0583531856536865
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0611    0.1098       229
           N     0.6620    0.7734    0.7134       428
           P     0.6609    0.8559    0.7458       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6204    0.5635    0.5230      1101
weighted avg     0.6358    0.6585    0.6009      1101

F1-macro sent:  0.5229984116304526
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0006    0.0012     16205
           N     0.0527    0.1529    0.0783      1857
           P     0.1225    0.6052    0.2038      3212

   micro avg     0.1052    0.1052    0.1052     21274
   macro avg     0.3917    0.2529    0.0944     21274
weighted avg     0.7848    0.1052    0.0385     21274

F1-macro tok:  0.09443989198783849
F1-micro tok:  0.10519883425777946
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 6538.537806510925
train_cost_avg: 0.7652783013238442
train_count_sent: 8544.0
train_total_correct_sent: 5786.0
train_accuracy_sent: 0.6772003745318352
train_count_tok: 163566.0
train_total_correct_tok: 19231.0
train_accuracy_tok: 0.11757333431153173
train_label=O_precision_sent: 0.4369230769230769
train_label=O_recall_sent: 0.0874384236453202
train_label=O_f-score_sent: 0.1457157516675218
train_label=N_precision_sent: 0.6498667312818027
train_label=N_recall_sent: 0.8102719033232628
train_label=N_f-score_sent: 0.7212585720048407
train_label=P_precision_sent: 0.7238514173998045
train_label=P_recall_sent: 0.8204986149584488
train_label=P_f-score_sent: 0.769150869903921
train_precision_macro_sent: 0.6035470752015614
train_recall_macro_sent: 0.5727363139756773
train_f-score_macro_sent: 0.5453750645254278
train_precision_micro_sent: 0.6772003745318352
train_recall_micro_sent: 0.6772003745318352
train_f-score_micro_sent: 0.6772003745318352
train_label=O_precision_tok: 0.7993421052631579
train_label=O_recall_tok: 0.00390841757340346
train_label=O_f-score_tok: 0.0077788003681325294
train_label=N_precision_tok: 0.06741181391457916
train_label=N_recall_tok: 0.2042670046472328
train_label=N_f-score_tok: 0.10136976727933468
train_label=P_precision_tok: 0.13211700743804408
train_label=P_recall_tok: 0.633329336051485
train_label=P_f-score_tok: 0.21862688956195966
train_precision_macro_tok: 0.3329569755385937
train_recall_macro_tok: 0.2805015860907071
train_f-score_macro_tok: 0.10925848573647562
train_precision_micro_tok: 0.11757333431153173
train_recall_micro_tok: 0.11757333431153173
train_f-score_micro_tok: 0.11757333431153173
train_time: 127.59197330474854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4369    0.0874    0.1457      1624
           N     0.6499    0.8103    0.7213      3310
           P     0.7239    0.8205    0.7692      3610

   micro avg     0.6772    0.6772    0.6772      8544
   macro avg     0.6035    0.5727    0.5454      8544
weighted avg     0.6407    0.6772    0.6321      8544

F1-macro sent:  0.5453750645254278
F1-micro sent:  0.6772003745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7993    0.0039    0.0078    124347
           N     0.0674    0.2043    0.1014     14202
           P     0.1321    0.6333    0.2186     25017

   micro avg     0.1176    0.1176    0.1176    163566
   macro avg     0.3330    0.2805    0.1093    163566
weighted avg     0.6337    0.1176    0.0482    163566

F1-macro tok:  0.10925848573647562
F1-micro tok:  0.11757333431153173
**************************************************
dev_cost_sum: 913.1432495117188
dev_cost_avg: 0.8293762484211796
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 2226.0
dev_accuracy_tok: 0.10463476544138385
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.7078384798099763
dev_label=N_recall_sent: 0.6962616822429907
dev_label=N_f-score_sent: 0.702002355712603
dev_label=P_precision_sent: 0.6148148148148148
dev_label=P_recall_sent: 0.9346846846846847
dev_label=P_f-score_sent: 0.741733690795353
dev_precision_macro_sent: 0.640884431541597
dev_recall_macro_sent: 0.548015601202966
dev_f-score_macro_sent: 0.48979235738299387
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.0004936747917309472
dev_label=O_f-score_tok: 0.0009868623943748843
dev_label=N_precision_tok: 0.04757929883138564
dev_label=N_recall_tok: 0.12277867528271405
dev_label=N_f-score_tok: 0.0685817416152805
dev_label=P_precision_tok: 0.12079640645866213
dev_label=P_recall_tok: 0.6195516811955168
dev_label=P_f-score_tok: 0.20217413390226555
dev_precision_macro_tok: 0.389458568430016
dev_recall_macro_tok: 0.24760801042332062
dev_f-score_macro_tok: 0.09058091263730698
dev_precision_micro_tok: 0.10463476544138385
dev_recall_micro_tok: 0.10463476544138385
dev_f-score_micro_tok: 0.10463476544138385
dev_time: 7.024130821228027
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.7078    0.6963    0.7020       428
           P     0.6148    0.9347    0.7417       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6409    0.5480    0.4898      1101
weighted avg     0.6479    0.6503    0.5773      1101

F1-macro sent:  0.48979235738299387
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0005    0.0010     16205
           N     0.0476    0.1228    0.0686      1857
           P     0.1208    0.6196    0.2022      3212

   micro avg     0.1046    0.1046    0.1046     21274
   macro avg     0.3895    0.2476    0.0906     21274
weighted avg     0.7841    0.1046    0.0373     21274

F1-macro tok:  0.09058091263730698
F1-micro tok:  0.10463476544138385
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 6457.933186531067
train_cost_avg: 0.7558442399966137
train_count_sent: 8544.0
train_total_correct_sent: 5805.0
train_accuracy_sent: 0.6794241573033708
train_count_tok: 163566.0
train_total_correct_tok: 15683.0
train_accuracy_tok: 0.09588178472298645
train_label=O_precision_sent: 0.44168734491315137
train_label=O_recall_sent: 0.10960591133004927
train_label=O_f-score_sent: 0.1756290083867785
train_label=N_precision_sent: 0.6540238268903477
train_label=N_recall_sent: 0.8126888217522659
train_label=N_f-score_sent: 0.7247743499932641
train_label=P_precision_sent: 0.7291459781529295
train_label=P_recall_sent: 0.813573407202216
train_label=P_f-score_sent: 0.7690494893951296
train_precision_macro_sent: 0.6082857166521428
train_recall_macro_sent: 0.5786227134281771
train_f-score_macro_sent: 0.5564842825917241
train_precision_micro_sent: 0.6794241573033708
train_recall_micro_sent: 0.6794241573033708
train_f-score_micro_sent: 0.6794241573033708
train_label=O_precision_tok: 0.935
train_label=O_recall_tok: 0.0015038561444988621
train_label=O_f-score_tok: 0.003002882445984247
train_label=N_precision_tok: 0.05164007479509987
train_label=N_recall_tok: 0.20806928601605407
train_label=N_f-score_tok: 0.08274413720686034
train_label=P_precision_tok: 0.11815192711719096
train_label=P_recall_tok: 0.5012991166007115
train_label=P_f-score_tok: 0.19123208295211955
train_precision_macro_tok: 0.3682640006374303
train_recall_macro_tok: 0.23695741958708813
train_f-score_macro_tok: 0.09232636753498806
train_precision_micro_tok: 0.09588178472298645
train_recall_micro_tok: 0.09588178472298645
train_f-score_micro_tok: 0.09588178472298645
train_time: 127.24217915534973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4417    0.1096    0.1756      1624
           N     0.6540    0.8127    0.7248      3310
           P     0.7291    0.8136    0.7690      3610

   micro avg     0.6794    0.6794    0.6794      8544
   macro avg     0.6083    0.5786    0.5565      8544
weighted avg     0.6454    0.6794    0.6391      8544

F1-macro sent:  0.5564842825917241
F1-micro sent:  0.6794241573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9350    0.0015    0.0030    124347
           N     0.0516    0.2081    0.0827     14202
           P     0.1182    0.5013    0.1912     25017

   micro avg     0.0959    0.0959    0.0959    163566
   macro avg     0.3683    0.2370    0.0923    163566
weighted avg     0.7334    0.0959    0.0387    163566

F1-macro tok:  0.09232636753498806
F1-micro tok:  0.09588178472298645
**************************************************
dev_cost_sum: 900.6768741607666
dev_cost_avg: 0.8180534733521949
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 1683.0
dev_accuracy_tok: 0.07911065149948293
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6053067993366501
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7080504364694471
dev_label=P_precision_sent: 0.7067209775967414
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7422459893048128
dev_precision_macro_sent: 0.6754378304063685
dev_recall_macro_sent: 0.5520564436615533
dev_f-score_macro_sent: 0.4975564357100641
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.0003702560937982104
dev_label=O_f-score_tok: 0.0007402381099253593
dev_label=N_precision_tok: 0.052197515398267044
dev_label=N_recall_tok: 0.2692514808831449
dev_label=N_f-score_tok: 0.08744316194473592
dev_label=P_precision_tok: 0.10069295919240312
dev_label=P_recall_tok: 0.3664383561643836
dev_label=P_f-score_tok: 0.1579759747667942
dev_precision_macro_tok: 0.3842968248635567
dev_recall_macro_tok: 0.2120200310471089
dev_f-score_macro_tok: 0.08205312494048517
dev_precision_micro_tok: 0.07911065149948293
dev_recall_micro_tok: 0.07911065149948293
dev_f-score_micro_tok: 0.07911065149948293
dev_time: 7.411771774291992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6053    0.8528    0.7081       428
           P     0.7067    0.7815    0.7422       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6754    0.5521    0.4976      1101
weighted avg     0.6689    0.6512    0.5834      1101

F1-macro sent:  0.4975564357100641
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0004    0.0007     16205
           N     0.0522    0.2693    0.0874      1857
           P     0.1007    0.3664    0.1580      3212

   micro avg     0.0791    0.0791    0.0791     21274
   macro avg     0.3843    0.2120    0.0821     21274
weighted avg     0.7815    0.0791    0.0320     21274

F1-macro tok:  0.08205312494048517
F1-micro tok:  0.07911065149948293
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 6407.120220184326
train_cost_avg: 0.7498970295159558
train_count_sent: 8544.0
train_total_correct_sent: 5826.0
train_accuracy_sent: 0.6818820224719101
train_count_tok: 163566.0
train_total_correct_tok: 13747.0
train_accuracy_tok: 0.08404558404558404
train_label=O_precision_sent: 0.4483695652173913
train_label=O_recall_sent: 0.10160098522167488
train_label=O_f-score_sent: 0.16566265060240964
train_label=N_precision_sent: 0.6477569427961073
train_label=N_recall_sent: 0.8244712990936556
train_label=N_f-score_sent: 0.7255084407816031
train_label=P_precision_sent: 0.739843552863992
train_label=P_recall_sent: 0.8121883656509695
train_label=P_f-score_sent: 0.7743298560676087
train_precision_macro_sent: 0.6119900202924968
train_recall_macro_sent: 0.5794202166554333
train_f-score_macro_sent: 0.5551669824838737
train_precision_micro_sent: 0.6818820224719101
train_recall_micro_sent: 0.6818820224719101
train_f-score_micro_sent: 0.6818820224719101
train_label=O_precision_tok: 0.9174311926605505
train_label=O_recall_tok: 0.0008042011467908353
train_label=O_f-score_tok: 0.0016069936363052003
train_label=N_precision_tok: 0.061061622661384506
train_label=N_recall_tok: 0.3755104914800732
train_label=N_f-score_tok: 0.10504234784321449
train_label=P_precision_tok: 0.10922371549810166
train_label=P_recall_tok: 0.33233401287124753
train_label=P_f-score_tok: 0.1644122765385224
train_precision_macro_tok: 0.36257217694001226
train_recall_macro_tok: 0.2362162351660372
train_f-score_macro_tok: 0.09035387267268069
train_precision_micro_tok: 0.08404558404558404
train_recall_micro_tok: 0.08404558404558404
train_f-score_micro_tok: 0.08404558404558404
train_time: 127.79707741737366
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4484    0.1016    0.1657      1624
           N     0.6478    0.8245    0.7255      3310
           P     0.7398    0.8122    0.7743      3610

   micro avg     0.6819    0.6819    0.6819      8544
   macro avg     0.6120    0.5794    0.5552      8544
weighted avg     0.6488    0.6819    0.6397      8544

F1-macro sent:  0.5551669824838737
F1-micro sent:  0.6818820224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9174    0.0008    0.0016    124347
           N     0.0611    0.3755    0.1050     14202
           P     0.1092    0.3323    0.1644     25017

   micro avg     0.0840    0.0840    0.0840    163566
   macro avg     0.3626    0.2362    0.0904    163566
weighted avg     0.7195    0.0840    0.0355    163566

F1-macro tok:  0.09035387267268069
F1-micro tok:  0.08404558404558404
**************************************************
dev_cost_sum: 885.6623363494873
dev_cost_avg: 0.8044162909622955
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 1527.0
dev_accuracy_tok: 0.07177775688634014
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.049792531120331954
dev_label=N_precision_sent: 0.6125827814569537
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7170542635658915
dev_label=P_precision_sent: 0.7051546391752578
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.736275565123789
dev_precision_macro_sent: 0.6059124735440705
dev_recall_macro_sent: 0.5536523749803757
dev_f-score_macro_sent: 0.5010407866033375
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 1.0
dev_label=O_recall_tok: 0.0003702560937982104
dev_label=O_f-score_tok: 0.0007402381099253593
dev_label=N_precision_tok: 0.06891827495830355
dev_label=N_recall_tok: 0.6230479267635972
dev_label=N_f-score_tok: 0.12410834003754356
dev_label=P_precision_tok: 0.08125
dev_label=P_recall_tok: 0.1133250311332503
dev_label=P_f-score_tok: 0.09464378575143007
dev_precision_macro_tok: 0.3833894249861012
dev_recall_macro_tok: 0.24558107133021526
dev_f-score_macro_tok: 0.073164121299633
dev_precision_micro_tok: 0.07177775688634014
dev_recall_micro_tok: 0.07177775688634014
dev_f-score_micro_tok: 0.07177775688634014
dev_time: 7.302232027053833
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0262    0.0498       229
           N     0.6126    0.8645    0.7171       428
           P     0.7052    0.7703    0.7363       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.6059    0.5537    0.5010      1101
weighted avg     0.6265    0.6521    0.5860      1101

F1-macro sent:  0.5010407866033375
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0004    0.0007     16205
           N     0.0689    0.6230    0.1241      1857
           P     0.0813    0.1133    0.0946      3212

   micro avg     0.0718    0.0718    0.0718     21274
   macro avg     0.3834    0.2456    0.0732     21274
weighted avg     0.7800    0.0718    0.0257     21274

F1-macro tok:  0.073164121299633
F1-micro tok:  0.07177775688634014
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 6254.552953720093
train_cost_avg: 0.7320403737968273
train_count_sent: 8544.0
train_total_correct_sent: 5916.0
train_accuracy_sent: 0.6924157303370787
train_count_tok: 163566.0
train_total_correct_tok: 13126.0
train_accuracy_tok: 0.08024895149358668
train_label=O_precision_sent: 0.5361111111111111
train_label=O_recall_sent: 0.1188423645320197
train_label=O_f-score_sent: 0.19455645161290322
train_label=N_precision_sent: 0.6538372362624624
train_label=N_recall_sent: 0.851963746223565
train_label=N_f-score_sent: 0.7398661944116489
train_label=P_precision_sent: 0.7499354172048567
train_label=P_recall_sent: 0.8041551246537396
train_label=P_f-score_sent: 0.7760994519449272
train_precision_macro_sent: 0.6466279215261433
train_recall_macro_sent: 0.5916537451364414
train_f-score_macro_sent: 0.5701740326564931
train_precision_micro_sent: 0.6924157303370787
train_recall_micro_sent: 0.6924157303370787
train_f-score_micro_sent: 0.6924157303370787
train_label=O_precision_tok: 0.8918918918918919
train_label=O_recall_tok: 0.001592318270645854
train_label=O_f-score_tok: 0.003178961057727043
train_label=N_precision_tok: 0.07581081478432179
train_label=N_recall_tok: 0.7261653288269257
train_label=N_f-score_tok: 0.13728883504838987
train_label=P_precision_tok: 0.09575948440017577
train_label=P_recall_tok: 0.10452892033417276
train_label=P_f-score_tok: 0.09995222169135212
train_precision_macro_tok: 0.35448739702546317
train_recall_macro_tok: 0.27742885581058147
train_f-score_macro_tok: 0.08014000593248968
train_precision_micro_tok: 0.08024895149358668
train_recall_micro_tok: 0.08024895149358668
train_f-score_micro_tok: 0.08024895149358668
train_time: 102.2882559299469
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5361    0.1188    0.1946      1624
           N     0.6538    0.8520    0.7399      3310
           P     0.7499    0.8042    0.7761      3610

   micro avg     0.6924    0.6924    0.6924      8544
   macro avg     0.6466    0.5917    0.5702      8544
weighted avg     0.6721    0.6924    0.6515      8544

F1-macro sent:  0.5701740326564931
F1-micro sent:  0.6924157303370787
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8919    0.0016    0.0032    124347
           N     0.0758    0.7262    0.1373     14202
           P     0.0958    0.1045    0.1000     25017

   micro avg     0.0802    0.0802    0.0802    163566
   macro avg     0.3545    0.2774    0.0801    163566
weighted avg     0.6993    0.0802    0.0296    163566

F1-macro tok:  0.08014000593248968
F1-micro tok:  0.08024895149358668
**************************************************
dev_cost_sum: 900.1667423248291
dev_cost_avg: 0.8175901383513434
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 1715.0
dev_accuracy_tok: 0.08061483500987121
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.6708595387840671
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.707182320441989
dev_label=P_precision_sent: 0.6378466557911908
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.7398297067171239
dev_precision_macro_sent: 0.6483566103129648
dev_recall_macro_sent: 0.5529539558740065
dev_f-score_macro_sent: 0.5017817868308154
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.7894736842105263
dev_label=O_recall_tok: 0.0009256402344955261
dev_label=O_f-score_tok: 0.001849112426035503
dev_label=N_precision_tok: 0.08031720211468077
dev_label=N_recall_tok: 0.8508346795907378
dev_label=N_f-score_tok: 0.14677876352826422
dev_label=P_precision_tok: 0.07580543272267846
dev_label=P_recall_tok: 0.037359900373599
dev_label=P_f-score_tok: 0.05005213764337852
dev_precision_macro_tok: 0.31519877301596183
dev_recall_macro_tok: 0.2963734067329441
dev_f-score_macro_tok: 0.06622667119922608
dev_precision_micro_tok: 0.08061483500987121
dev_recall_micro_tok: 0.08061483500987121
dev_f-score_micro_tok: 0.08061483500987121
dev_time: 4.185078382492065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.6709    0.7477    0.7072       428
           P     0.6378    0.8806    0.7398       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.6484    0.5530    0.5018      1101
weighted avg     0.6504    0.6521    0.5854      1101

F1-macro sent:  0.5017817868308154
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7895    0.0009    0.0018     16205
           N     0.0803    0.8508    0.1468      1857
           P     0.0758    0.0374    0.0501      3212

   micro avg     0.0806    0.0806    0.0806     21274
   macro avg     0.3152    0.2964    0.0662     21274
weighted avg     0.6198    0.0806    0.0218     21274

F1-macro tok:  0.06622667119922608
F1-micro tok:  0.08061483500987121
**************************************************
Best epoch: 14
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 6207.1098165512085
train_cost_avg: 0.7264875721618924
train_count_sent: 8544.0
train_total_correct_sent: 5881.0
train_accuracy_sent: 0.6883192883895131
train_count_tok: 163566.0
train_total_correct_tok: 13748.0
train_accuracy_tok: 0.08405169778560337
train_label=O_precision_sent: 0.45454545454545453
train_label=O_recall_sent: 0.11391625615763547
train_label=O_f-score_sent: 0.18217626784835056
train_label=N_precision_sent: 0.6715637450199203
train_label=N_recall_sent: 0.8148036253776435
train_label=N_f-score_sent: 0.7362817362817363
train_label=P_precision_sent: 0.7277359864110653
train_label=P_recall_sent: 0.8307479224376731
train_label=P_f-score_sent: 0.7758375371879447
train_precision_macro_sent: 0.6179483953254801
train_recall_macro_sent: 0.586489267990984
train_f-score_macro_sent: 0.5647651804393439
train_precision_micro_sent: 0.6883192883895131
train_recall_micro_sent: 0.6883192883895131
train_f-score_micro_sent: 0.6883192883895131
train_label=O_precision_tok: 0.8832997987927566
train_label=O_recall_tok: 0.003530443034411767
train_label=O_f-score_tok: 0.007032776905578162
train_label=N_precision_tok: 0.08046023688663283
train_label=N_recall_tok: 0.8370652020842135
train_label=N_f-score_tok: 0.14680893104129616
train_label=P_precision_tok: 0.09276062406162282
train_label=P_recall_tok: 0.05680137506495583
train_label=P_f-score_tok: 0.07045815152717176
train_precision_macro_tok: 0.35217355324700406
train_recall_macro_tok: 0.2991323400611937
train_f-score_macro_tok: 0.07476661982468202
train_precision_micro_tok: 0.08405169778560337
train_recall_micro_tok: 0.08405169778560337
train_f-score_micro_tok: 0.08405169778560337
train_time: 84.51477670669556
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.1139    0.1822      1624
           N     0.6716    0.8148    0.7363      3310
           P     0.7277    0.8307    0.7758      3610

   micro avg     0.6883    0.6883    0.6883      8544
   macro avg     0.6179    0.5865    0.5648      8544
weighted avg     0.6540    0.6883    0.6477      8544

F1-macro sent:  0.5647651804393439
F1-micro sent:  0.6883192883895131
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8833    0.0035    0.0070    124347
           N     0.0805    0.8371    0.1468     14202
           P     0.0928    0.0568    0.0705     25017

   micro avg     0.0841    0.0841    0.0841    163566
   macro avg     0.3522    0.2991    0.0748    163566
weighted avg     0.6927    0.0841    0.0289    163566

F1-macro tok:  0.07476661982468202
F1-micro tok:  0.08405169778560337
**************************************************
dev_cost_sum: 881.0329608917236
dev_cost_avg: 0.8002115902740451
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 1850.0
dev_accuracy_tok: 0.0869606091943217
dev_label=O_precision_sent: 0.45454545454545453
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0796812749003984
dev_label=N_precision_sent: 0.6633266533066132
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7141316073354909
dev_label=P_precision_sent: 0.6603448275862069
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7480468749999999
dev_precision_macro_sent: 0.5927389784794249
dev_recall_macro_sent: 0.5598817402882211
dev_f-score_macro_sent: 0.5139532524119631
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8666666666666667
dev_label=O_recall_tok: 0.0016044430731255786
dev_label=O_f-score_tok: 0.0032029565753002778
dev_label=N_precision_tok: 0.08596937551000816
dev_label=N_recall_tok: 0.9644588045234249
dev_label=N_f-score_tok: 0.15786690171881887
dev_label=P_precision_tok: 0.08029197080291971
dev_label=P_recall_tok: 0.010273972602739725
dev_label=P_f-score_tok: 0.018216947281258625
dev_precision_macro_tok: 0.3443093376598649
dev_recall_macro_tok: 0.32544574006643007
dev_f-score_macro_tok: 0.05976226852512593
dev_precision_micro_tok: 0.0869606091943217
dev_recall_micro_tok: 0.0869606091943217
dev_f-score_micro_tok: 0.0869606091943217
dev_time: 4.379151821136475
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.0437    0.0797       229
           N     0.6633    0.7734    0.7141       428
           P     0.6603    0.8626    0.7480       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.5927    0.5599    0.5140      1101
weighted avg     0.6187    0.6576    0.5958      1101

F1-macro sent:  0.5139532524119631
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8667    0.0016    0.0032     16205
           N     0.0860    0.9645    0.1579      1857
           P     0.0803    0.0103    0.0182      3212

   micro avg     0.0870    0.0870    0.0870     21274
   macro avg     0.3443    0.3254    0.0598     21274
weighted avg     0.6798    0.0870    0.0190     21274

F1-macro tok:  0.05976226852512593
F1-micro tok:  0.0869606091943217
**************************************************
Best epoch: 14
**************************************************

test0_cost_sum: 893.9929552078247
test0_cost_avg: 0.8119827022777699
test0_count_sent: 1101.0
test0_total_correct_sent: 727.0
test0_accuracy_sent: 0.6603088101725704
test0_count_tok: 21274.0
test0_total_correct_tok: 1905.0
test0_accuracy_tok: 0.08954592460280154
test0_label=O_precision_sent: 0.5454545454545454
test0_label=O_recall_sent: 0.10480349344978165
test0_label=O_f-score_sent: 0.1758241758241758
test0_label=N_precision_sent: 0.6304347826086957
test0_label=N_recall_sent: 0.8130841121495327
test0_label=N_f-score_sent: 0.710204081632653
test0_label=P_precision_sent: 0.7029702970297029
test0_label=P_recall_sent: 0.7995495495495496
test0_label=P_f-score_sent: 0.7481559536354057
test0_precision_macro_sent: 0.6262865416976481
test0_recall_macro_sent: 0.572479051716288
test0_f-score_macro_sent: 0.5447280703640781
test0_precision_micro_sent: 0.6603088101725704
test0_recall_micro_sent: 0.6603088101725704
test0_f-score_micro_sent: 0.6603088101725704
test0_label=O_precision_tok: 0.9166666666666666
test0_label=O_recall_tok: 0.0006788028386300525
test0_label=O_f-score_tok: 0.0013566010976136154
test0_label=N_precision_tok: 0.07579151280343846
test0_label=N_recall_tok: 0.6742057081313947
test0_label=N_f-score_tok: 0.13626469307792774
test0_label=P_precision_tok: 0.13535736875395318
test0_label=P_recall_tok: 0.19987546699875466
test0_label=P_f-score_tok: 0.16140791954745443
test0_precision_macro_tok: 0.37593851607468604
test0_recall_macro_tok: 0.2915866593229265
test0_f-score_macro_tok: 0.09967640457433193
test0_precision_micro_tok: 0.08954592460280154
test0_recall_micro_tok: 0.08954592460280154
test0_f-score_micro_tok: 0.08954592460280154
test0_time: 4.4075610637664795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.1048    0.1758       229
           N     0.6304    0.8131    0.7102       428
           P     0.7030    0.7995    0.7482       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.6263    0.5725    0.5447      1101
weighted avg     0.6420    0.6603    0.6144      1101

F1-macro sent:  0.5447280703640781
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9167    0.0007    0.0014     16205
           N     0.0758    0.6742    0.1363      1857
           P     0.1354    0.1999    0.1614      3212

   micro avg     0.0895    0.0895    0.0895     21274
   macro avg     0.3759    0.2916    0.0997     21274
weighted avg     0.7253    0.0895    0.0373     21274

F1-macro tok:  0.09967640457433193
F1-micro tok:  0.08954592460280154
**************************************************
test1_cost_sum: 1700.4116959571838
test1_cost_avg: 0.7694170569942008
test1_count_sent: 2210.0
test1_total_correct_sent: 1510.0
test1_accuracy_sent: 0.6832579185520362
test1_count_tok: 42405.0
test1_total_correct_tok: 3851.0
test1_accuracy_tok: 0.09081476241009315
test1_label=O_precision_sent: 0.39285714285714285
test1_label=O_recall_sent: 0.08483290488431877
test1_label=O_f-score_sent: 0.13953488372093023
test1_label=N_precision_sent: 0.6506849315068494
test1_label=N_recall_sent: 0.8333333333333334
test1_label=N_f-score_sent: 0.7307692307692308
test1_label=P_precision_sent: 0.7484342379958246
test1_label=P_recall_sent: 0.7887788778877888
test1_label=P_f-score_sent: 0.7680771290840922
test1_precision_macro_sent: 0.5973254374532723
test1_recall_macro_sent: 0.5689817053684804
test1_f-score_macro_sent: 0.5461270811914177
test1_precision_micro_sent: 0.6832579185520362
test1_recall_micro_sent: 0.6832579185520362
test1_f-score_micro_sent: 0.6832579185520362
test1_label=O_precision_tok: 0.9032258064516129
test1_label=O_recall_tok: 0.0008750546909181824
test1_label=O_f-score_tok: 0.0017484154984545254
test1_label=N_precision_tok: 0.0787305833358665
test1_label=N_recall_tok: 0.6888297872340425
test1_label=N_f-score_tok: 0.1413099817224541
test1_label=P_precision_tok: 0.13010446343779677
test1_label=P_recall_tok: 0.1854972167895291
test1_label=P_f-score_tok: 0.15293971719176383
test1_precision_macro_tok: 0.37068695107509203
test1_recall_macro_tok: 0.29173401957149664
test1_f-score_macro_tok: 0.09866603813755748
test1_precision_micro_tok: 0.09081476241009315
test1_recall_micro_tok: 0.09081476241009315
test1_f-score_micro_tok: 0.09081476241009315
test1_time: 8.238894939422607
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3929    0.0848    0.1395       389
           N     0.6507    0.8333    0.7308       912
           P     0.7484    0.7888    0.7681       909

   micro avg     0.6833    0.6833    0.6833      2210
   macro avg     0.5973    0.5690    0.5461      2210
weighted avg     0.6455    0.6833    0.6420      2210

F1-macro sent:  0.5461270811914177
F1-micro sent:  0.6832579185520362
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9032    0.0009    0.0017     31998
           N     0.0787    0.6888    0.1413      3760
           P     0.1301    0.1855    0.1529      6647

   micro avg     0.0908    0.0908    0.0908     42405
   macro avg     0.3707    0.2917    0.0987     42405
weighted avg     0.7089    0.0908    0.0378     42405

F1-macro tok:  0.09866603813755748
F1-micro tok:  0.09081476241009315
**************************************************
