to_write_filename: runs/transformer_conll03_0.1_attention_loss_between_all=TRUE_model_selector=macro_sent_29_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'O': 0, 'MISC': 2, 'PER': 4, 'ORG': 3, 'LOC': 1}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-29 09:12:26.127674: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-29 09:12:26.214000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 81fa:00:00.0
totalMemory: 11.17GiB freeMemory: 9.98GiB
2019-03-29 09:12:26.214044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-29 09:12:26.588618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-29 09:12:26.588669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-29 09:12:26.588683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-29 09:12:26.588916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 81fa:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 9797652.
Parameter count without word embeddings: 3230652.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 453572.8170776367
train_cost_avg: 32.30345538620018
train_count_sent: 14041.0
train_total_correct_sent: 11891.0
train_accuracy_sent: 0.8468770030624599
train_count_tok: 203621.0
train_total_correct_tok: 186115.0
train_accuracy_tok: 0.9140265493244802
train_label=0_precision_sent: 0.7015400955921403
train_label=0_recall_sent: 0.45410794087315226
train_label=0_f-score_sent: 0.5513355592654424
train_label=1_precision_sent: 0.869386412238855
train_label=1_recall_sent: 0.9495149119655049
train_label=1_f-score_sent: 0.9076857020180334
train_precision_macro_sent: 0.7854632539154977
train_recall_macro_sent: 0.7018114264193286
train_f-score_macro_sent: 0.7295106306417379
train_precision_micro_sent: 0.8468770030624599
train_recall_micro_sent: 0.8468770030624599
train_f-score_micro_sent: 0.84687700306246
train_label=O_precision_tok: 0.9443707332562201
train_label=O_recall_tok: 0.9821616011510927
train_label=O_f-score_tok: 0.9628955142769599
train_label=LOC_precision_tok: 0.7119297163995068
train_label=LOC_recall_tok: 0.5567072435820176
train_label=LOC_f-score_tok: 0.624822455191072
train_label=MISC_precision_tok: 0.5818789454140364
train_label=MISC_recall_tok: 0.3411713477030263
train_label=MISC_f-score_tok: 0.43013999451001916
train_label=ORG_precision_tok: 0.6673161860223434
train_label=ORG_recall_tok: 0.5124189526184538
train_label=ORG_f-score_tok: 0.5796986966089263
train_label=PER_precision_tok: 0.7938909231065716
train_label=PER_recall_tok: 0.7403846153846154
train_label=PER_f-score_tok: 0.7662047800613783
train_precision_macro_tok: 0.7398773008397356
train_recall_macro_tok: 0.6265687520878412
train_f-score_macro_tok: 0.672752288129671
train_precision_micro_tok: 0.9140265493244802
train_recall_micro_tok: 0.9140265493244802
train_f-score_micro_tok: 0.9140265493244802
train_time: 160.2945215702057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7015    0.4541    0.5513      2909
           1     0.8694    0.9495    0.9077     11132

   micro avg     0.8469    0.8469    0.8469     14041
   macro avg     0.7855    0.7018    0.7295     14041
weighted avg     0.8346    0.8469    0.8339     14041

F1-macro sent:  0.7295106306417379
F1-micro sent:  0.84687700306246
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9444    0.9822    0.9629    169578
         LOC     0.7119    0.5567    0.6248      8297
        MISC     0.5819    0.3412    0.4301      4593
         ORG     0.6673    0.5124    0.5797     10025
         PER     0.7939    0.7404    0.7662     11128

   micro avg     0.9140    0.9140    0.9140    203621
   macro avg     0.7399    0.6266    0.6728    203621
weighted avg     0.9049    0.9140    0.9075    203621

F1-macro tok:  0.672752288129671
F1-micro tok:  0.9140265493244802
**************************************************
dev_cost_sum: 101940.62216186523
dev_cost_avg: 31.366345280573917
dev_count_sent: 3250.0
dev_total_correct_sent: 2933.0
dev_accuracy_sent: 0.9024615384615384
dev_count_tok: 51362.0
dev_total_correct_tok: 49869.0
dev_accuracy_tok: 0.9709318172968342
dev_label=0_precision_sent: 0.9712643678160919
dev_label=0_recall_sent: 0.524031007751938
dev_label=0_f-score_sent: 0.6807653575025175
dev_label=1_precision_sent: 0.8942108890420399
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9424368984928272
dev_precision_macro_sent: 0.9327376284290659
dev_recall_macro_sent: 0.7600961180794239
dev_f-score_macro_sent: 0.8116011279976724
dev_precision_micro_sent: 0.9024615384615384
dev_recall_micro_sent: 0.9024615384615384
dev_f-score_micro_sent: 0.9024615384615384
dev_label=O_precision_tok: 0.9855394368478286
dev_label=O_recall_tok: 0.996187937042494
dev_label=O_f-score_tok: 0.990835077925099
dev_label=LOC_precision_tok: 0.8836538461538461
dev_label=LOC_recall_tok: 0.87774594078319
dev_label=LOC_f-score_tok: 0.8806899856252994
dev_label=MISC_precision_tok: 0.8863636363636364
dev_label=MISC_recall_tok: 0.6766561514195584
dev_label=MISC_f-score_tok: 0.7674418604651163
dev_label=ORG_precision_tok: 0.8540389972144847
dev_label=ORG_recall_tok: 0.732791586998088
dev_label=ORG_f-score_tok: 0.7887831232312837
dev_label=PER_precision_tok: 0.9229836264402669
dev_label=PER_recall_tok: 0.9666560812956494
dev_label=PER_f-score_tok: 0.9443151853575306
dev_precision_macro_tok: 0.9065159086040125
dev_recall_macro_tok: 0.8500075395077961
dev_f-score_macro_tok: 0.8744130465208657
dev_precision_micro_tok: 0.9709318172968342
dev_recall_micro_tok: 0.9709318172968342
dev_f-score_micro_tok: 0.9709318172968342
dev_time: 15.442598342895508
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9713    0.5240    0.6808       645
           1     0.8942    0.9962    0.9424      2605

   micro avg     0.9025    0.9025    0.9025      3250
   macro avg     0.9327    0.7601    0.8116      3250
weighted avg     0.9095    0.9025    0.8905      3250

F1-macro sent:  0.8116011279976724
F1-micro sent:  0.9024615384615384
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9855    0.9962    0.9908     42759
         LOC     0.8837    0.8777    0.8807      2094
        MISC     0.8864    0.6767    0.7674      1268
         ORG     0.8540    0.7328    0.7888      2092
         PER     0.9230    0.9667    0.9443      3149

   micro avg     0.9709    0.9709    0.9709     51362
   macro avg     0.9065    0.8500    0.8744     51362
weighted avg     0.9697    0.9709    0.9697     51362

F1-macro tok:  0.8744130465208657
F1-micro tok:  0.9709318172968342
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 383630.0237426758
train_cost_avg: 27.322129744510775
train_count_sent: 14041.0
train_total_correct_sent: 12605.0
train_accuracy_sent: 0.8977280820454384
train_count_tok: 203621.0
train_total_correct_tok: 196046.0
train_accuracy_tok: 0.962798532567859
train_label=0_precision_sent: 0.7893909626719057
train_label=0_recall_sent: 0.6906153317291165
train_label=0_f-score_sent: 0.7367070040337367
train_label=1_precision_sent: 0.9217118997912317
train_label=1_recall_sent: 0.9518505210204815
train_label=1_f-score_sent: 0.936538801484886
train_precision_macro_sent: 0.8555514312315686
train_recall_macro_sent: 0.821232926374799
train_f-score_macro_sent: 0.8366229027593113
train_precision_micro_sent: 0.8977280820454384
train_recall_micro_sent: 0.8977280820454384
train_f-score_micro_sent: 0.8977280820454384
train_label=O_precision_tok: 0.987356557978458
train_label=O_recall_tok: 0.9919388128177004
train_label=O_f-score_tok: 0.9896423812227344
train_label=LOC_precision_tok: 0.8334128309086573
train_label=LOC_recall_tok: 0.8423526575870797
train_label=LOC_f-score_tok: 0.8378588982796858
train_label=MISC_precision_tok: 0.7531499100025714
train_label=MISC_recall_tok: 0.6377095580230786
train_label=MISC_f-score_tok: 0.6906390002357934
train_label=ORG_precision_tok: 0.7887338608912953
train_label=ORG_recall_tok: 0.7556109725685786
train_label=ORG_f-score_tok: 0.7718172092312396
train_label=PER_precision_tok: 0.9090269842665026
train_label=PER_recall_tok: 0.9293673616103523
train_label=PER_f-score_tok: 0.919084647856032
train_precision_macro_tok: 0.8543360288094968
train_recall_macro_tok: 0.8313958725213577
train_f-score_macro_tok: 0.8418084273650971
train_precision_micro_tok: 0.962798532567859
train_recall_micro_tok: 0.962798532567859
train_f-score_micro_tok: 0.962798532567859
train_time: 160.35201358795166
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7894    0.6906    0.7367      2909
           1     0.9217    0.9519    0.9365     11132

   micro avg     0.8977    0.8977    0.8977     14041
   macro avg     0.8556    0.8212    0.8366     14041
weighted avg     0.8943    0.8977    0.8951     14041

F1-macro sent:  0.8366229027593113
F1-micro sent:  0.8977280820454384
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9874    0.9919    0.9896    169578
         LOC     0.8334    0.8424    0.8379      8297
        MISC     0.7531    0.6377    0.6906      4593
         ORG     0.7887    0.7556    0.7718     10025
         PER     0.9090    0.9294    0.9191     11128

   micro avg     0.9628    0.9628    0.9628    203621
   macro avg     0.8543    0.8314    0.8418    203621
weighted avg     0.9617    0.9628    0.9621    203621

F1-macro tok:  0.8418084273650971
F1-micro tok:  0.962798532567859
**************************************************
dev_cost_sum: 99299.3405456543
dev_cost_avg: 30.55364324481671
dev_count_sent: 3250.0
dev_total_correct_sent: 3027.0
dev_accuracy_sent: 0.9313846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50040.0
dev_accuracy_tok: 0.974261126903158
dev_label=0_precision_sent: 0.7874659400544959
dev_label=0_recall_sent: 0.896124031007752
dev_label=0_f-score_sent: 0.8382886149383612
dev_label=1_precision_sent: 0.9733704292527822
dev_label=1_recall_sent: 0.9401151631477928
dev_label=1_f-score_sent: 0.9564538176137473
dev_precision_macro_sent: 0.880418184653639
dev_recall_macro_sent: 0.9181195970777724
dev_f-score_macro_sent: 0.8973712162760542
dev_precision_micro_sent: 0.9313846153846154
dev_recall_micro_sent: 0.9313846153846154
dev_f-score_micro_sent: 0.9313846153846154
dev_label=O_precision_tok: 0.9924166413888046
dev_label=O_recall_tok: 0.9946911761266634
dev_label=O_f-score_tok: 0.9935526069893478
dev_label=LOC_precision_tok: 0.9557321225879682
dev_label=LOC_recall_tok: 0.8042024832855779
dev_label=LOC_f-score_tok: 0.8734439834024896
dev_label=MISC_precision_tok: 0.9225941422594143
dev_label=MISC_recall_tok: 0.695583596214511
dev_label=MISC_f-score_tok: 0.7931654676258993
dev_label=ORG_precision_tok: 0.7434367541766109
dev_label=ORG_recall_tok: 0.8934034416826003
dev_label=ORG_f-score_tok: 0.8115501519756838
dev_label=PER_precision_tok: 0.9388939810571342
dev_label=PER_recall_tok: 0.9758653540806606
dev_label=PER_f-score_tok: 0.9570227343506696
dev_precision_macro_tok: 0.9106147282939864
dev_recall_macro_tok: 0.8727492102780026
dev_f-score_macro_tok: 0.8857469888688181
dev_precision_micro_tok: 0.974261126903158
dev_recall_micro_tok: 0.974261126903158
dev_f-score_micro_tok: 0.974261126903158
dev_time: 14.875104427337646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7875    0.8961    0.8383       645
           1     0.9734    0.9401    0.9565      2605

   micro avg     0.9314    0.9314    0.9314      3250
   macro avg     0.8804    0.9181    0.8974      3250
weighted avg     0.9365    0.9314    0.9330      3250

F1-macro sent:  0.8973712162760542
F1-micro sent:  0.9313846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9924    0.9947    0.9936     42759
         LOC     0.9557    0.8042    0.8734      2094
        MISC     0.9226    0.6956    0.7932      1268
         ORG     0.7434    0.8934    0.8116      2092
         PER     0.9389    0.9759    0.9570      3149

   micro avg     0.9743    0.9743    0.9743     51362
   macro avg     0.9106    0.8727    0.8857     51362
weighted avg     0.9758    0.9743    0.9741     51362

F1-macro tok:  0.8857469888688181
F1-micro tok:  0.974261126903158
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 372382.11041259766
train_cost_avg: 26.521053373164136
train_count_sent: 14041.0
train_total_correct_sent: 12873.0
train_accuracy_sent: 0.9168150416636992
train_count_tok: 203621.0
train_total_correct_tok: 197310.0
train_accuracy_tok: 0.9690061437670967
train_label=0_precision_sent: 0.8157417482771128
train_label=0_recall_sent: 0.7731179099346854
train_label=0_f-score_sent: 0.7938581009530532
train_label=1_precision_sent: 0.9415101028004254
train_label=1_recall_sent: 0.9543657923104564
train_label=1_f-score_sent: 0.9478943611705924
train_precision_macro_sent: 0.8786259255387691
train_recall_macro_sent: 0.863741851122571
train_f-score_macro_sent: 0.8708762310618228
train_precision_micro_sent: 0.9168150416636992
train_recall_micro_sent: 0.9168150416636992
train_f-score_micro_sent: 0.9168150416636992
train_label=O_precision_tok: 0.9898136718979604
train_label=O_recall_tok: 0.9930356532097324
train_label=O_f-score_tok: 0.9914220448149588
train_label=LOC_precision_tok: 0.8679199807182454
train_label=LOC_recall_tok: 0.8680245872001928
train_label=LOC_f-score_tok: 0.8679722808074721
train_label=MISC_precision_tok: 0.788818359375
train_label=MISC_recall_tok: 0.7034617896799478
train_label=MISC_f-score_tok: 0.7436989296812062
train_label=ORG_precision_tok: 0.8182844243792325
train_label=ORG_recall_tok: 0.7955112219451371
train_label=ORG_f-score_tok: 0.8067371402559304
train_label=PER_precision_tok: 0.9254691216632895
train_label=PER_recall_tok: 0.9440150970524802
train_label=PER_f-score_tok: 0.9346501178878064
train_precision_macro_tok: 0.8780611116067456
train_recall_macro_tok: 0.8608096698174981
train_f-score_macro_tok: 0.8688961026894748
train_precision_micro_tok: 0.9690061437670967
train_recall_micro_tok: 0.9690061437670967
train_f-score_micro_tok: 0.9690061437670967
train_time: 182.6585249900818
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8157    0.7731    0.7939      2909
           1     0.9415    0.9544    0.9479     11132

   micro avg     0.9168    0.9168    0.9168     14041
   macro avg     0.8786    0.8637    0.8709     14041
weighted avg     0.9155    0.9168    0.9160     14041

F1-macro sent:  0.8708762310618228
F1-micro sent:  0.9168150416636992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9898    0.9930    0.9914    169578
         LOC     0.8679    0.8680    0.8680      8297
        MISC     0.7888    0.7035    0.7437      4593
         ORG     0.8183    0.7955    0.8067     10025
         PER     0.9255    0.9440    0.9347     11128

   micro avg     0.9690    0.9690    0.9690    203621
   macro avg     0.8781    0.8608    0.8689    203621
weighted avg     0.9684    0.9690    0.9686    203621

F1-macro tok:  0.8688961026894748
F1-micro tok:  0.9690061437670967
**************************************************
dev_cost_sum: 96792.05773925781
dev_cost_avg: 29.782171612079328
dev_count_sent: 3250.0
dev_total_correct_sent: 3104.0
dev_accuracy_sent: 0.955076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50338.0
dev_accuracy_tok: 0.9800630816556988
dev_label=0_precision_sent: 0.9354275741710296
dev_label=0_recall_sent: 0.8310077519379845
dev_label=0_f-score_sent: 0.8801313628899836
dev_label=1_precision_sent: 0.9592827792304819
dev_label=1_recall_sent: 0.9857965451055662
dev_label=1_f-score_sent: 0.9723589549413102
dev_precision_macro_sent: 0.9473551767007558
dev_recall_macro_sent: 0.9084021485217754
dev_f-score_macro_sent: 0.9262451589156468
dev_precision_micro_sent: 0.955076923076923
dev_recall_micro_sent: 0.955076923076923
dev_f-score_micro_sent: 0.9550769230769229
dev_label=O_precision_tok: 0.9923834812382084
dev_label=O_recall_tok: 0.9964218059355925
dev_label=O_f-score_tok: 0.9943985436213415
dev_label=LOC_precision_tok: 0.8840194776449757
dev_label=LOC_recall_tok: 0.9536771728748806
dev_label=LOC_f-score_tok: 0.9175281415116011
dev_label=MISC_precision_tok: 0.8999055712936733
dev_label=MISC_recall_tok: 0.751577287066246
dev_label=MISC_f-score_tok: 0.8190803609798023
dev_label=ORG_precision_tok: 0.8979591836734694
dev_label=ORG_recall_tok: 0.8202676864244742
dev_label=ORG_f-score_tok: 0.8573569822633027
dev_label=PER_precision_tok: 0.958125
dev_label=PER_recall_tok: 0.9736424261670371
dev_label=PER_f-score_tok: 0.9658213891951489
dev_precision_macro_tok: 0.9264785427700654
dev_recall_macro_tok: 0.8991172756936461
dev_f-score_macro_tok: 0.9108370835142393
dev_precision_micro_tok: 0.9800630816556988
dev_recall_micro_tok: 0.9800630816556988
dev_f-score_micro_tok: 0.9800630816556988
dev_time: 24.104853630065918
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9354    0.8310    0.8801       645
           1     0.9593    0.9858    0.9724      2605

   micro avg     0.9551    0.9551    0.9551      3250
   macro avg     0.9474    0.9084    0.9262      3250
weighted avg     0.9545    0.9551    0.9541      3250

F1-macro sent:  0.9262451589156468
F1-micro sent:  0.9550769230769229
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9924    0.9964    0.9944     42759
         LOC     0.8840    0.9537    0.9175      2094
        MISC     0.8999    0.7516    0.8191      1268
         ORG     0.8980    0.8203    0.8574      2092
         PER     0.9581    0.9736    0.9658      3149

   micro avg     0.9801    0.9801    0.9801     51362
   macro avg     0.9265    0.8991    0.9108     51362
weighted avg     0.9797    0.9801    0.9796     51362

F1-macro tok:  0.9108370835142393
F1-micro tok:  0.9800630816556988
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 363436.6407470703
train_cost_avg: 25.883957036327207
train_count_sent: 14041.0
train_total_correct_sent: 13115.0
train_accuracy_sent: 0.9340502813189944
train_count_tok: 203621.0
train_total_correct_tok: 198181.0
train_accuracy_tok: 0.9732836986361918
train_label=0_precision_sent: 0.8517204682511529
train_label=0_recall_sent: 0.8253695427982124
train_label=0_f-score_sent: 0.8383379888268156
train_label=1_precision_sent: 0.9547317768668686
train_label=1_recall_sent: 0.9624505928853755
train_label=1_f-score_sent: 0.9585756464167486
train_precision_macro_sent: 0.9032261225590108
train_recall_macro_sent: 0.8939100678417939
train_f-score_macro_sent: 0.8984568176217822
train_precision_micro_sent: 0.9340502813189944
train_recall_micro_sent: 0.9340502813189944
train_f-score_micro_sent: 0.9340502813189944
train_label=O_precision_tok: 0.9913068028091143
train_label=O_recall_tok: 0.9938789229734989
train_label=O_f-score_tok: 0.992591196598311
train_label=LOC_precision_tok: 0.8860820401780344
train_label=LOC_recall_tok: 0.8877907677473785
train_label=LOC_f-score_tok: 0.886935580975316
train_label=MISC_precision_tok: 0.8147434353167912
train_label=MISC_recall_tok: 0.7363379055083823
train_label=MISC_f-score_tok: 0.7735590118938702
train_label=ORG_precision_tok: 0.8426339285714286
train_label=ORG_recall_tok: 0.828428927680798
train_label=ORG_f-score_tok: 0.8354710527639455
train_label=PER_precision_tok: 0.9384029070282727
train_label=PER_recall_tok: 0.9514737598849748
train_label=PER_f-score_tok: 0.9448931328365535
train_precision_macro_tok: 0.8946338227807283
train_recall_macro_tok: 0.8795820567590065
train_f-score_macro_tok: 0.8866899950135994
train_precision_micro_tok: 0.9732836986361918
train_recall_micro_tok: 0.9732836986361918
train_f-score_micro_tok: 0.9732836986361918
train_time: 260.94023633003235
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8517    0.8254    0.8383      2909
           1     0.9547    0.9625    0.9586     11132

   micro avg     0.9341    0.9341    0.9341     14041
   macro avg     0.9032    0.8939    0.8985     14041
weighted avg     0.9334    0.9341    0.9337     14041

F1-macro sent:  0.8984568176217822
F1-micro sent:  0.9340502813189944
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9913    0.9939    0.9926    169578
         LOC     0.8861    0.8878    0.8869      8297
        MISC     0.8147    0.7363    0.7736      4593
         ORG     0.8426    0.8284    0.8355     10025
         PER     0.9384    0.9515    0.9449     11128

   micro avg     0.9733    0.9733    0.9733    203621
   macro avg     0.8946    0.8796    0.8867    203621
weighted avg     0.9728    0.9733    0.9730    203621

F1-macro tok:  0.8866899950135994
F1-micro tok:  0.9732836986361918
**************************************************
dev_cost_sum: 94791.29286193848
dev_cost_avg: 29.166551649827223
dev_count_sent: 3250.0
dev_total_correct_sent: 3146.0
dev_accuracy_sent: 0.968
dev_count_tok: 51362.0
dev_total_correct_tok: 50435.0
dev_accuracy_tok: 0.9819516373972976
dev_label=0_precision_sent: 0.9273301737756714
dev_label=0_recall_sent: 0.9100775193798449
dev_label=0_f-score_sent: 0.918622848200313
dev_label=1_precision_sent: 0.9778372181887658
dev_label=1_recall_sent: 0.982341650671785
dev_label=1_f-score_sent: 0.9800842589046342
dev_precision_macro_sent: 0.9525836959822186
dev_recall_macro_sent: 0.946209585025815
dev_f-score_macro_sent: 0.9493535535524736
dev_precision_micro_sent: 0.968
dev_recall_micro_sent: 0.968
dev_f-score_micro_sent: 0.968
dev_label=O_precision_tok: 0.9931478114948958
dev_label=O_recall_tok: 0.9965621272714517
dev_label=O_f-score_tok: 0.9948520399229557
dev_label=LOC_precision_tok: 0.9375605033881897
dev_label=LOC_recall_tok: 0.9250238777459407
dev_label=LOC_f-score_tok: 0.93125
dev_label=MISC_precision_tok: 0.8628099173553719
dev_label=MISC_recall_tok: 0.8233438485804416
dev_label=MISC_f-score_tok: 0.8426150121065377
dev_label=ORG_precision_tok: 0.9125455491931286
dev_label=ORG_recall_tok: 0.8379541108986616
dev_label=ORG_f-score_tok: 0.8736606030401196
dev_label=PER_precision_tok: 0.9478367597422522
dev_label=PER_recall_tok: 0.9809463321689426
dev_label=PER_f-score_tok: 0.9641073657927591
dev_precision_macro_tok: 0.9307801082347676
dev_recall_macro_tok: 0.9127660593330876
dev_f-score_macro_tok: 0.9212970041724745
dev_precision_micro_tok: 0.9819516373972976
dev_recall_micro_tok: 0.9819516373972976
dev_f-score_micro_tok: 0.9819516373972976
dev_time: 34.489861249923706
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9273    0.9101    0.9186       645
           1     0.9778    0.9823    0.9801      2605

   micro avg     0.9680    0.9680    0.9680      3250
   macro avg     0.9526    0.9462    0.9494      3250
weighted avg     0.9678    0.9680    0.9679      3250

F1-macro sent:  0.9493535535524736
F1-micro sent:  0.968
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9931    0.9966    0.9949     42759
         LOC     0.9376    0.9250    0.9313      2094
        MISC     0.8628    0.8233    0.8426      1268
         ORG     0.9125    0.8380    0.8737      2092
         PER     0.9478    0.9809    0.9641      3149

   micro avg     0.9820    0.9820    0.9820     51362
   macro avg     0.9308    0.9128    0.9213     51362
weighted avg     0.9816    0.9820    0.9817     51362

F1-macro tok:  0.9212970041724745
F1-micro tok:  0.9819516373972976
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355990.79626464844
train_cost_avg: 25.35366400289498
train_count_sent: 14041.0
train_total_correct_sent: 13213.0
train_accuracy_sent: 0.9410298411794031
train_count_tok: 203621.0
train_total_correct_tok: 198687.0
train_accuracy_tok: 0.9757687075498107
train_label=0_precision_sent: 0.8649596632760435
train_label=0_recall_sent: 0.8477139910622207
train_label=0_f-score_sent: 0.8562500000000001
train_label=1_precision_sent: 0.9604110813226094
train_label=1_recall_sent: 0.9654150197628458
train_label=1_f-score_sent: 0.9629065495923304
train_precision_macro_sent: 0.9126853722993264
train_recall_macro_sent: 0.9065645054125333
train_f-score_macro_sent: 0.9095782747961652
train_precision_micro_sent: 0.9410298411794031
train_recall_micro_sent: 0.9410298411794031
train_f-score_micro_sent: 0.9410298411794031
train_label=O_precision_tok: 0.9920870250744231
train_label=O_recall_tok: 0.9944037552040949
train_label=O_f-score_tok: 0.9932440392045989
train_label=LOC_precision_tok: 0.8978805394990366
train_label=LOC_recall_tok: 0.8986380619501024
train_label=LOC_f-score_tok: 0.8982591410156014
train_label=MISC_precision_tok: 0.8248003757632691
train_label=MISC_recall_tok: 0.7646418462878293
train_label=MISC_f-score_tok: 0.7935826460286973
train_label=ORG_precision_tok: 0.8593797661413319
train_label=ORG_recall_tok: 0.8430922693266832
train_label=ORG_f-score_tok: 0.8511581067472306
train_label=PER_precision_tok: 0.9456
train_label=PER_recall_tok: 0.9559669302659957
train_label=PER_f-score_tok: 0.9507552060058986
train_precision_macro_tok: 0.9039495412956121
train_recall_macro_tok: 0.891348572606941
train_f-score_macro_tok: 0.8973998278004054
train_precision_micro_tok: 0.9757687075498107
train_recall_micro_tok: 0.9757687075498107
train_f-score_micro_tok: 0.9757687075498107
train_time: 325.58509039878845
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8650    0.8477    0.8563      2909
           1     0.9604    0.9654    0.9629     11132

   micro avg     0.9410    0.9410    0.9410     14041
   macro avg     0.9127    0.9066    0.9096     14041
weighted avg     0.9406    0.9410    0.9408     14041

F1-macro sent:  0.9095782747961652
F1-micro sent:  0.9410298411794031
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9921    0.9944    0.9932    169578
         LOC     0.8979    0.8986    0.8983      8297
        MISC     0.8248    0.7646    0.7936      4593
         ORG     0.8594    0.8431    0.8512     10025
         PER     0.9456    0.9560    0.9508     11128

   micro avg     0.9758    0.9758    0.9758    203621
   macro avg     0.9039    0.8913    0.8974    203621
weighted avg     0.9754    0.9758    0.9756    203621

F1-macro tok:  0.8973998278004054
F1-micro tok:  0.9757687075498107
**************************************************
dev_cost_sum: 93361.55194091797
dev_cost_avg: 28.726631366436298
dev_count_sent: 3250.0
dev_total_correct_sent: 3087.0
dev_accuracy_sent: 0.9498461538461539
dev_count_tok: 51362.0
dev_total_correct_tok: 50455.0
dev_accuracy_tok: 0.9823410303337098
dev_label=0_precision_sent: 0.8113695090439277
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.8851303735024666
dev_label=1_precision_sent: 0.9931340872374798
dev_label=1_recall_sent: 0.943953934740883
dev_label=1_f-score_sent: 0.9679197008462901
dev_precision_macro_sent: 0.9022517981407037
dev_recall_macro_sent: 0.9587986727967981
dev_f-score_macro_sent: 0.9265250371743783
dev_precision_micro_sent: 0.9498461538461539
dev_recall_micro_sent: 0.9498461538461539
dev_f-score_micro_sent: 0.9498461538461539
dev_label=O_precision_tok: 0.9938427092079485
dev_label=O_recall_tok: 0.9965621272714517
dev_label=O_f-score_tok: 0.9952005605184795
dev_label=LOC_precision_tok: 0.9394230769230769
dev_label=LOC_recall_tok: 0.933142311365807
dev_label=LOC_f-score_tok: 0.9362721609966459
dev_label=MISC_precision_tok: 0.8152580403889305
dev_label=MISC_recall_tok: 0.8596214511041009
dev_label=MISC_f-score_tok: 0.836852207293666
dev_label=ORG_precision_tok: 0.9325720500271887
dev_label=ORG_recall_tok: 0.8197896749521989
dev_label=ORG_f-score_tok: 0.8725515136097685
dev_label=PER_precision_tok: 0.9547987616099072
dev_label=PER_recall_tok: 0.9793585265163544
dev_label=PER_f-score_tok: 0.9669227151591159
dev_precision_macro_tok: 0.9271789276314104
dev_recall_macro_tok: 0.9176948182419826
dev_f-score_macro_tok: 0.9215598315155352
dev_precision_micro_tok: 0.9823410303337098
dev_recall_micro_tok: 0.9823410303337098
dev_f-score_micro_tok: 0.9823410303337098
dev_time: 34.63302707672119
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8114    0.9736    0.8851       645
           1     0.9931    0.9440    0.9679      2605

   micro avg     0.9498    0.9498    0.9498      3250
   macro avg     0.9023    0.9588    0.9265      3250
weighted avg     0.9571    0.9498    0.9515      3250

F1-macro sent:  0.9265250371743783
F1-micro sent:  0.9498461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9938    0.9966    0.9952     42759
         LOC     0.9394    0.9331    0.9363      2094
        MISC     0.8153    0.8596    0.8369      1268
         ORG     0.9326    0.8198    0.8726      2092
         PER     0.9548    0.9794    0.9669      3149

   micro avg     0.9823    0.9823    0.9823     51362
   macro avg     0.9272    0.9177    0.9216     51362
weighted avg     0.9823    0.9823    0.9822     51362

F1-macro tok:  0.9215598315155352
F1-micro tok:  0.9823410303337098
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 349339.17404174805
train_cost_avg: 24.879935477654588
train_count_sent: 14041.0
train_total_correct_sent: 13391.0
train_accuracy_sent: 0.95370700092586
train_count_tok: 203621.0
train_total_correct_tok: 199307.0
train_accuracy_tok: 0.9788135801317153
train_label=0_precision_sent: 0.8923237235151095
train_label=0_recall_sent: 0.8831213475421107
train_label=0_f-score_sent: 0.8876986869384935
train_label=1_precision_sent: 0.9695395090485576
train_label=1_recall_sent: 0.9721523535752785
train_label=1_f-score_sent: 0.9708441733201759
train_precision_macro_sent: 0.9309316162818335
train_recall_macro_sent: 0.9276368505586946
train_f-score_macro_sent: 0.9292714301293348
train_precision_micro_sent: 0.95370700092586
train_recall_micro_sent: 0.95370700092586
train_f-score_micro_sent: 0.95370700092586
train_label=O_precision_tok: 0.9930134551319026
train_label=O_recall_tok: 0.9948873084952058
train_label=O_f-score_tok: 0.993949498639079
train_label=LOC_precision_tok: 0.9144855867808467
train_label=LOC_recall_tok: 0.9138242738339158
train_label=LOC_f-score_tok: 0.9141548107065348
train_label=MISC_precision_tok: 0.8454756380510441
train_label=MISC_recall_tok: 0.793381232310037
train_label=MISC_f-score_tok: 0.8186004717510951
train_label=ORG_precision_tok: 0.877602844083291
train_label=ORG_recall_tok: 0.8618453865336658
train_label=ORG_f-score_tok: 0.8696527428283846
train_label=PER_precision_tok: 0.9514941917176554
train_label=PER_recall_tok: 0.964234363767074
train_label=PER_f-score_tok: 0.9578219147511716
train_precision_macro_tok: 0.916414343152948
train_recall_macro_tok: 0.9056345129879798
train_f-score_macro_tok: 0.9108358877352529
train_precision_micro_tok: 0.9788135801317153
train_recall_micro_tok: 0.9788135801317153
train_f-score_micro_tok: 0.9788135801317153
train_time: 326.59702610969543
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8923    0.8831    0.8877      2909
           1     0.9695    0.9722    0.9708     11132

   micro avg     0.9537    0.9537    0.9537     14041
   macro avg     0.9309    0.9276    0.9293     14041
weighted avg     0.9535    0.9537    0.9536     14041

F1-macro sent:  0.9292714301293348
F1-micro sent:  0.95370700092586
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9930    0.9949    0.9939    169578
         LOC     0.9145    0.9138    0.9142      8297
        MISC     0.8455    0.7934    0.8186      4593
         ORG     0.8776    0.8618    0.8697     10025
         PER     0.9515    0.9642    0.9578     11128

   micro avg     0.9788    0.9788    0.9788    203621
   macro avg     0.9164    0.9056    0.9108    203621
weighted avg     0.9785    0.9788    0.9786    203621

F1-macro tok:  0.9108358877352529
F1-micro tok:  0.9788135801317153
**************************************************
dev_cost_sum: 92007.69443511963
dev_cost_avg: 28.310059826190656
dev_count_sent: 3250.0
dev_total_correct_sent: 3167.0
dev_accuracy_sent: 0.9744615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50567.0
dev_accuracy_tok: 0.9845216307776177
dev_label=0_precision_sent: 0.9561688311688312
dev_label=0_recall_sent: 0.9131782945736434
dev_label=0_f-score_sent: 0.9341792228390168
dev_label=1_precision_sent: 0.9787395596051632
dev_label=1_recall_sent: 0.9896353166986565
dev_label=1_f-score_sent: 0.9841572819240314
dev_precision_macro_sent: 0.9674541953869973
dev_recall_macro_sent: 0.95140680563615
dev_f-score_macro_sent: 0.9591682523815241
dev_precision_micro_sent: 0.9744615384615385
dev_recall_micro_sent: 0.9744615384615385
dev_f-score_micro_sent: 0.9744615384615385
dev_label=O_precision_tok: 0.9936378466557912
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9953892306435234
dev_label=LOC_precision_tok: 0.9565217391304348
dev_label=LOC_recall_tok: 0.9350525310410697
dev_label=LOC_f-score_tok: 0.9456652982371407
dev_label=MISC_precision_tok: 0.9177718832891246
dev_label=MISC_recall_tok: 0.8186119873817035
dev_label=MISC_f-score_tok: 0.8653605669028762
dev_label=ORG_precision_tok: 0.905911330049261
dev_label=ORG_recall_tok: 0.8790630975143403
dev_label=ORG_f-score_tok: 0.8922852983988354
dev_label=PER_precision_tok: 0.9540690505548706
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9682465196308462
dev_precision_macro_tok: 0.9455823699358964
dev_recall_macro_tok: 0.922545222878672
dev_f-score_macro_tok: 0.9333893827626444
dev_precision_micro_tok: 0.9845216307776177
dev_recall_micro_tok: 0.9845216307776177
dev_f-score_micro_tok: 0.9845216307776177
dev_time: 34.11188101768494
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9562    0.9132    0.9342       645
           1     0.9787    0.9896    0.9842      2605

   micro avg     0.9745    0.9745    0.9745      3250
   macro avg     0.9675    0.9514    0.9592      3250
weighted avg     0.9743    0.9745    0.9742      3250

F1-macro sent:  0.9591682523815241
F1-micro sent:  0.9744615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9971    0.9954     42759
         LOC     0.9565    0.9351    0.9457      2094
        MISC     0.9178    0.8186    0.8654      1268
         ORG     0.9059    0.8791    0.8923      2092
         PER     0.9541    0.9829    0.9682      3149

   micro avg     0.9845    0.9845    0.9845     51362
   macro avg     0.9456    0.9225    0.9334     51362
weighted avg     0.9843    0.9845    0.9843     51362

F1-macro tok:  0.9333893827626444
F1-micro tok:  0.9845216307776177
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 344356.5448913574
train_cost_avg: 24.525072636661022
train_count_sent: 14041.0
train_total_correct_sent: 13446.0
train_accuracy_sent: 0.957624100847518
train_count_tok: 203621.0
train_total_correct_tok: 199579.0
train_accuracy_tok: 0.9801493951999057
train_label=0_precision_sent: 0.900623268698061
train_label=0_recall_sent: 0.8941216913028532
train_label=0_f-score_sent: 0.8973607038123167
train_label=1_precision_sent: 0.972384111898144
train_label=1_recall_sent: 0.9742184692777578
train_label=1_f-score_sent: 0.9733004262957147
train_precision_macro_sent: 0.9365036902981025
train_recall_macro_sent: 0.9341700802903055
train_f-score_macro_sent: 0.9353305650540157
train_precision_micro_sent: 0.957624100847518
train_recall_micro_sent: 0.957624100847518
train_f-score_micro_sent: 0.957624100847518
train_label=O_precision_tok: 0.9935769122079879
train_label=O_recall_tok: 0.9952057460283763
train_label=O_f-score_tok: 0.9943906621022055
train_label=LOC_precision_tok: 0.9167068466730954
train_label=LOC_recall_tok: 0.9165963601301675
train_label=LOC_f-score_tok: 0.9166516000723197
train_label=MISC_precision_tok: 0.8604008293020041
train_label=MISC_recall_tok: 0.8131939908556499
train_label=MISC_f-score_tok: 0.8361316319677635
train_label=ORG_precision_tok: 0.8823529411764706
train_label=ORG_recall_tok: 0.8708229426433916
train_label=ORG_f-score_tok: 0.8765500276118279
train_label=PER_precision_tok: 0.9563824105394338
train_label=PER_recall_tok: 0.9654924514737598
train_label=PER_f-score_tok: 0.9609158393703604
train_precision_macro_tok: 0.9218839879797984
train_recall_macro_tok: 0.912262298226269
train_f-score_macro_tok: 0.9169279522248954
train_precision_micro_tok: 0.9801493951999057
train_recall_micro_tok: 0.9801493951999057
train_f-score_micro_tok: 0.9801493951999057
train_time: 327.3539204597473
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9006    0.8941    0.8974      2909
           1     0.9724    0.9742    0.9733     11132

   micro avg     0.9576    0.9576    0.9576     14041
   macro avg     0.9365    0.9342    0.9353     14041
weighted avg     0.9575    0.9576    0.9576     14041

F1-macro sent:  0.9353305650540157
F1-micro sent:  0.957624100847518
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9952    0.9944    169578
         LOC     0.9167    0.9166    0.9167      8297
        MISC     0.8604    0.8132    0.8361      4593
         ORG     0.8824    0.8708    0.8766     10025
         PER     0.9564    0.9655    0.9609     11128

   micro avg     0.9801    0.9801    0.9801    203621
   macro avg     0.9219    0.9123    0.9169    203621
weighted avg     0.9799    0.9801    0.9800    203621

F1-macro tok:  0.9169279522248954
F1-micro tok:  0.9801493951999057
**************************************************
dev_cost_sum: 91142.56596374512
dev_cost_avg: 28.043866450383113
dev_count_sent: 3250.0
dev_total_correct_sent: 3188.0
dev_accuracy_sent: 0.9809230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50565.0
dev_accuracy_tok: 0.9844826914839765
dev_label=0_precision_sent: 0.9477726574500768
dev_label=0_recall_sent: 0.9565891472868217
dev_label=0_f-score_sent: 0.9521604938271605
dev_label=1_precision_sent: 0.9892266256252404
dev_label=1_recall_sent: 0.9869481765834933
dev_label=1_f-score_sent: 0.988086087624904
dev_precision_macro_sent: 0.9684996415376586
dev_recall_macro_sent: 0.9717686619351575
dev_f-score_macro_sent: 0.9701232907260322
dev_precision_micro_sent: 0.9809230769230769
dev_recall_micro_sent: 0.9809230769230769
dev_f-score_micro_sent: 0.9809230769230769
dev_label=O_precision_tok: 0.9954212026351446
dev_label=O_recall_tok: 0.9965153534928319
dev_label=O_f-score_tok: 0.9959679775609186
dev_label=LOC_precision_tok: 0.9731404958677686
dev_label=LOC_recall_tok: 0.8997134670487106
dev_label=LOC_f-score_tok: 0.9349875930521092
dev_label=MISC_precision_tok: 0.8814390842191333
dev_label=MISC_recall_tok: 0.8501577287066246
dev_label=MISC_f-score_tok: 0.8655158570855078
dev_label=ORG_precision_tok: 0.8630013519603424
dev_label=ORG_recall_tok: 0.9153919694072657
dev_label=ORG_f-score_tok: 0.8884249594061703
dev_label=PER_precision_tok: 0.9685336689741976
dev_label=PER_recall_tok: 0.9774531597332486
dev_label=PER_f-score_tok: 0.9729729729729729
dev_precision_macro_tok: 0.9363071607313171
dev_recall_macro_tok: 0.9278463356777363
dev_f-score_macro_tok: 0.9315738720155358
dev_precision_micro_tok: 0.9844826914839765
dev_recall_micro_tok: 0.9844826914839765
dev_f-score_micro_tok: 0.9844826914839765
dev_time: 34.48895740509033
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9478    0.9566    0.9522       645
           1     0.9892    0.9869    0.9881      2605

   micro avg     0.9809    0.9809    0.9809      3250
   macro avg     0.9685    0.9718    0.9701      3250
weighted avg     0.9810    0.9809    0.9810      3250

F1-macro sent:  0.9701232907260322
F1-micro sent:  0.9809230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9965    0.9960     42759
         LOC     0.9731    0.8997    0.9350      2094
        MISC     0.8814    0.8502    0.8655      1268
         ORG     0.8630    0.9154    0.8884      2092
         PER     0.9685    0.9775    0.9730      3149

   micro avg     0.9845    0.9845    0.9845     51362
   macro avg     0.9363    0.9278    0.9316     51362
weighted avg     0.9847    0.9845    0.9845     51362

F1-macro tok:  0.9315738720155358
F1-micro tok:  0.9844826914839765
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 339998.16760253906
train_cost_avg: 24.21466901235945
train_count_sent: 14041.0
train_total_correct_sent: 13516.0
train_accuracy_sent: 0.9626095007478099
train_count_tok: 203621.0
train_total_correct_tok: 199973.0
train_accuracy_tok: 0.982084362614858
train_label=0_precision_sent: 0.9068259385665529
train_label=0_recall_sent: 0.9133722928841527
train_label=0_f-score_sent: 0.9100873437232402
train_label=1_precision_sent: 0.977319773197732
train_label=1_recall_sent: 0.9754761049227453
train_label=1_f-score_sent: 0.9763970687407274
train_precision_macro_sent: 0.9420728558821425
train_recall_macro_sent: 0.944424198903449
train_f-score_macro_sent: 0.9432422062319838
train_precision_micro_sent: 0.9626095007478099
train_recall_micro_sent: 0.9626095007478099
train_f-score_micro_sent: 0.9626095007478099
train_label=O_precision_tok: 0.9943697805627864
train_label=O_recall_tok: 0.9956598143627121
train_label=O_f-score_tok: 0.995014379331479
train_label=LOC_precision_tok: 0.9254037117377681
train_label=LOC_recall_tok: 0.9255152464746293
train_label=LOC_f-score_tok: 0.9254594757457065
train_label=MISC_precision_tok: 0.8673050615595075
train_label=MISC_recall_tok: 0.8282168517308949
train_label=MISC_f-score_tok: 0.8473103909121283
train_label=ORG_precision_tok: 0.8948692152917505
train_label=ORG_recall_tok: 0.887281795511222
train_label=ORG_f-score_tok: 0.8910593538692712
train_label=PER_precision_tok: 0.9601750156263952
train_label=PER_recall_tok: 0.9663012221423436
train_label=PER_f-score_tok: 0.9632283781968021
train_precision_macro_tok: 0.9284245569556415
train_recall_macro_tok: 0.9205949860443603
train_f-score_macro_tok: 0.9244143956110774
train_precision_micro_tok: 0.982084362614858
train_recall_micro_tok: 0.982084362614858
train_f-score_micro_tok: 0.982084362614858
train_time: 326.67781138420105
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9068    0.9134    0.9101      2909
           1     0.9773    0.9755    0.9764     11132

   micro avg     0.9626    0.9626    0.9626     14041
   macro avg     0.9421    0.9444    0.9432     14041
weighted avg     0.9627    0.9626    0.9627     14041

F1-macro sent:  0.9432422062319838
F1-micro sent:  0.9626095007478099
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9944    0.9957    0.9950    169578
         LOC     0.9254    0.9255    0.9255      8297
        MISC     0.8673    0.8282    0.8473      4593
         ORG     0.8949    0.8873    0.8911     10025
         PER     0.9602    0.9663    0.9632     11128

   micro avg     0.9821    0.9821    0.9821    203621
   macro avg     0.9284    0.9206    0.9244    203621
weighted avg     0.9819    0.9821    0.9820    203621

F1-macro tok:  0.9244143956110774
F1-micro tok:  0.982084362614858
**************************************************
dev_cost_sum: 90324.26737213135
dev_cost_avg: 27.792082268348107
dev_count_sent: 3250.0
dev_total_correct_sent: 3085.0
dev_accuracy_sent: 0.9492307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50626.0
dev_accuracy_tok: 0.9856703399400335
dev_label=0_precision_sent: 0.9958677685950413
dev_label=0_recall_sent: 0.7472868217054264
dev_label=0_f-score_sent: 0.8538529672276352
dev_label=1_precision_sent: 0.9410701373825018
dev_label=1_recall_sent: 0.9992322456813819
dev_label=1_f-score_sent: 0.9692794637870042
dev_precision_macro_sent: 0.9684689529887716
dev_recall_macro_sent: 0.8732595336934041
dev_f-score_macro_sent: 0.9115662155073196
dev_precision_micro_sent: 0.9492307692307692
dev_recall_micro_sent: 0.9492307692307692
dev_f-score_micro_sent: 0.9492307692307692
dev_label=O_precision_tok: 0.996070267362167
dev_label=O_recall_tok: 0.9958839074814659
dev_label=O_f-score_tok: 0.9959770787042452
dev_label=LOC_precision_tok: 0.9546550892426435
dev_label=LOC_recall_tok: 0.9450811843361987
dev_label=LOC_f-score_tok: 0.9498440124790017
dev_label=MISC_precision_tok: 0.884709730171709
dev_label=MISC_recall_tok: 0.8533123028391167
dev_label=MISC_f-score_tok: 0.8687274187073465
dev_label=ORG_precision_tok: 0.902158273381295
dev_label=ORG_recall_tok: 0.8991395793499044
dev_label=ORG_f-score_tok: 0.9006463969355998
dev_label=PER_precision_tok: 0.9600619195046439
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9722527041856089
dev_precision_macro_tok: 0.9395310559324915
dev_recall_macro_tok: 0.9356348079483678
dev_f-score_macro_tok: 0.9374895222023604
dev_precision_micro_tok: 0.9856703399400335
dev_recall_micro_tok: 0.9856703399400335
dev_f-score_micro_tok: 0.9856703399400335
dev_time: 34.27564764022827
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9959    0.7473    0.8539       645
           1     0.9411    0.9992    0.9693      2605

   micro avg     0.9492    0.9492    0.9492      3250
   macro avg     0.9685    0.8733    0.9116      3250
weighted avg     0.9519    0.9492    0.9464      3250

F1-macro sent:  0.9115662155073196
F1-micro sent:  0.9492307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9959    0.9960     42759
         LOC     0.9547    0.9451    0.9498      2094
        MISC     0.8847    0.8533    0.8687      1268
         ORG     0.9022    0.8991    0.9006      2092
         PER     0.9601    0.9848    0.9723      3149

   micro avg     0.9857    0.9857    0.9857     51362
   macro avg     0.9395    0.9356    0.9375     51362
weighted avg     0.9856    0.9857    0.9856     51362

F1-macro tok:  0.9374895222023604
F1-micro tok:  0.9856703399400335
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 335600.29403686523
train_cost_avg: 23.90145246327649
train_count_sent: 14041.0
train_total_correct_sent: 13558.0
train_accuracy_sent: 0.9656007406879852
train_count_tok: 203621.0
train_total_correct_tok: 200330.0
train_accuracy_tok: 0.9838376198918579
train_label=0_precision_sent: 0.9191430545957153
train_label=0_recall_sent: 0.9144035751117222
train_label=0_f-score_sent: 0.916767189384801
train_label=1_precision_sent: 0.9776621512514578
train_label=1_recall_sent: 0.9789795185052103
train_label=1_f-score_sent: 0.9783203913999731
train_precision_macro_sent: 0.9484026029235866
train_recall_macro_sent: 0.9466915468084662
train_f-score_macro_sent: 0.947543790392387
train_precision_micro_sent: 0.9656007406879852
train_recall_micro_sent: 0.9656007406879852
train_f-score_micro_sent: 0.9656007406879852
train_label=O_precision_tok: 0.9948811894018826
train_label=O_recall_tok: 0.9959841488872377
train_label=O_f-score_tok: 0.9954323636192183
train_label=LOC_precision_tok: 0.9310635226179018
train_label=LOC_recall_tok: 0.932746775943112
train_label=LOC_f-score_tok: 0.9319043891865857
train_label=MISC_precision_tok: 0.8790413746326023
train_label=MISC_recall_tok: 0.8465055519268452
train_label=MISC_f-score_tok: 0.8624667258207632
train_label=ORG_precision_tok: 0.9064233135020672
train_label=ORG_recall_tok: 0.8966583541147132
train_label=ORG_f-score_tok: 0.9015143917360346
train_label=PER_precision_tok: 0.965544943318754
train_label=PER_recall_tok: 0.9720524802300503
train_label=PER_f-score_tok: 0.9687877837983073
train_precision_macro_tok: 0.9353908686946415
train_recall_macro_tok: 0.9287894622203916
train_f-score_macro_tok: 0.9320211308321816
train_precision_micro_tok: 0.9838376198918579
train_recall_micro_tok: 0.9838376198918579
train_f-score_micro_tok: 0.9838376198918579
train_time: 328.2217402458191
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9191    0.9144    0.9168      2909
           1     0.9777    0.9790    0.9783     11132

   micro avg     0.9656    0.9656    0.9656     14041
   macro avg     0.9484    0.9467    0.9475     14041
weighted avg     0.9655    0.9656    0.9656     14041

F1-macro sent:  0.947543790392387
F1-micro sent:  0.9656007406879852
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9949    0.9960    0.9954    169578
         LOC     0.9311    0.9327    0.9319      8297
        MISC     0.8790    0.8465    0.8625      4593
         ORG     0.9064    0.8967    0.9015     10025
         PER     0.9655    0.9721    0.9688     11128

   micro avg     0.9838    0.9838    0.9838    203621
   macro avg     0.9354    0.9288    0.9320    203621
weighted avg     0.9837    0.9838    0.9838    203621

F1-macro tok:  0.9320211308321816
F1-micro tok:  0.9838376198918579
**************************************************
dev_cost_sum: 89454.42585754395
dev_cost_avg: 27.524438725398138
dev_count_sent: 3250.0
dev_total_correct_sent: 3193.0
dev_accuracy_sent: 0.9824615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50655.0
dev_accuracy_tok: 0.986234959697831
dev_label=0_precision_sent: 0.9579439252336449
dev_label=0_recall_sent: 0.9534883720930233
dev_label=0_f-score_sent: 0.9557109557109558
dev_label=1_precision_sent: 0.9884969325153374
dev_label=1_recall_sent: 0.9896353166986565
dev_label=1_f-score_sent: 0.989065797045847
dev_precision_macro_sent: 0.9732204288744912
dev_recall_macro_sent: 0.9715618443958398
dev_f-score_macro_sent: 0.9723883763784014
dev_precision_micro_sent: 0.9824615384615385
dev_recall_micro_sent: 0.9824615384615385
dev_f-score_micro_sent: 0.9824615384615385
dev_label=O_precision_tok: 0.9938034337363431
dev_label=O_recall_tok: 0.9977080848476344
dev_label=O_f-score_tok: 0.9957519314707186
dev_label=LOC_precision_tok: 0.9569424286405418
dev_label=LOC_recall_tok: 0.944603629417383
dev_label=LOC_f-score_tok: 0.950732996875751
dev_label=MISC_precision_tok: 0.8854166666666666
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8783783783783784
dev_label=ORG_precision_tok: 0.9419989642672191
dev_label=ORG_recall_tok: 0.8695028680688337
dev_label=ORG_f-score_tok: 0.9043002734277902
dev_label=PER_precision_tok: 0.9695829413609282
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9757021142316187
dev_precision_macro_tok: 0.9495488869343397
dev_recall_macro_tok: 0.9330329403990586
dev_f-score_macro_tok: 0.9409731388768513
dev_precision_micro_tok: 0.986234959697831
dev_recall_micro_tok: 0.986234959697831
dev_f-score_micro_tok: 0.986234959697831
dev_time: 34.75074553489685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9579    0.9535    0.9557       645
           1     0.9885    0.9896    0.9891      2605

   micro avg     0.9825    0.9825    0.9825      3250
   macro avg     0.9732    0.9716    0.9724      3250
weighted avg     0.9824    0.9825    0.9824      3250

F1-macro sent:  0.9723883763784014
F1-micro sent:  0.9824615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9938    0.9977    0.9958     42759
         LOC     0.9569    0.9446    0.9507      2094
        MISC     0.8854    0.8715    0.8784      1268
         ORG     0.9420    0.8695    0.9043      2092
         PER     0.9696    0.9819    0.9757      3149

   micro avg     0.9862    0.9862    0.9862     51362
   macro avg     0.9495    0.9330    0.9410     51362
weighted avg     0.9860    0.9862    0.9861     51362

F1-macro tok:  0.9409731388768513
F1-micro tok:  0.986234959697831
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 332225.5828857422
train_cost_avg: 23.661105539900447
train_count_sent: 14041.0
train_total_correct_sent: 13618.0
train_accuracy_sent: 0.9698739406025212
train_count_tok: 203621.0
train_total_correct_tok: 200506.0
train_accuracy_tok: 0.9847019708183341
train_label=0_precision_sent: 0.924812030075188
train_label=0_recall_sent: 0.9302165692677896
train_label=0_f-score_sent: 0.9275064267352184
train_label=1_precision_sent: 0.981736392262708
train_label=1_recall_sent: 0.9802371541501976
train_label=1_f-score_sent: 0.980986200386569
train_precision_macro_sent: 0.9532742111689481
train_recall_macro_sent: 0.9552268617089936
train_f-score_macro_sent: 0.9542463135608937
train_precision_micro_sent: 0.9698739406025212
train_recall_micro_sent: 0.9698739406025212
train_f-score_micro_sent: 0.9698739406025212
train_label=O_precision_tok: 0.9951226983023691
train_label=O_recall_tok: 0.9962259255327932
train_label=O_f-score_tok: 0.9956740063180725
train_label=LOC_precision_tok: 0.9363471971066908
train_label=LOC_recall_tok: 0.9361214896950705
train_label=LOC_f-score_tok: 0.9362343297974928
train_label=MISC_precision_tok: 0.8860845839017736
train_label=MISC_recall_tok: 0.8484650555192684
train_label=MISC_f-score_tok: 0.8668668668668669
train_label=ORG_precision_tok: 0.911175938034403
train_label=ORG_recall_tok: 0.9035411471321696
train_label=ORG_f-score_tok: 0.9073424822197736
train_label=PER_precision_tok: 0.9665805186703502
train_label=PER_recall_tok: 0.9746585190510424
train_label=PER_f-score_tok: 0.9706027115307172
train_precision_macro_tok: 0.9390621872031174
train_recall_macro_tok: 0.9318024273860688
train_f-score_macro_tok: 0.9353440793465845
train_precision_micro_tok: 0.9847019708183341
train_recall_micro_tok: 0.9847019708183341
train_f-score_micro_tok: 0.9847019708183341
train_time: 328.7033278942108
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9248    0.9302    0.9275      2909
           1     0.9817    0.9802    0.9810     11132

   micro avg     0.9699    0.9699    0.9699     14041
   macro avg     0.9533    0.9552    0.9542     14041
weighted avg     0.9699    0.9699    0.9699     14041

F1-macro sent:  0.9542463135608937
F1-micro sent:  0.9698739406025212
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9951    0.9962    0.9957    169578
         LOC     0.9363    0.9361    0.9362      8297
        MISC     0.8861    0.8485    0.8669      4593
         ORG     0.9112    0.9035    0.9073     10025
         PER     0.9666    0.9747    0.9706     11128

   micro avg     0.9847    0.9847    0.9847    203621
   macro avg     0.9391    0.9318    0.9353    203621
weighted avg     0.9846    0.9847    0.9846    203621

F1-macro tok:  0.9353440793465845
F1-micro tok:  0.9847019708183341
**************************************************
dev_cost_sum: 88551.68857574463
dev_cost_avg: 27.246673407921424
dev_count_sent: 3250.0
dev_total_correct_sent: 3200.0
dev_accuracy_sent: 0.9846153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50735.0
dev_accuracy_tok: 0.9877925314434796
dev_label=0_precision_sent: 0.968503937007874
dev_label=0_recall_sent: 0.9534883720930233
dev_label=0_f-score_sent: 0.9609375
dev_label=1_precision_sent: 0.988527724665392
dev_label=1_recall_sent: 0.9923224568138196
dev_label=1_f-score_sent: 0.9904214559386973
dev_precision_macro_sent: 0.978515830836633
dev_recall_macro_sent: 0.9729054144534215
dev_f-score_macro_sent: 0.9756794779693487
dev_precision_micro_sent: 0.9846153846153847
dev_recall_micro_sent: 0.9846153846153847
dev_f-score_micro_sent: 0.9846153846153847
dev_label=O_precision_tok: 0.9953789063411674
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9964021213466346
dev_label=LOC_precision_tok: 0.9613899613899614
dev_label=LOC_recall_tok: 0.9512893982808023
dev_label=LOC_f-score_tok: 0.9563130100816131
dev_label=MISC_precision_tok: 0.9101497504159733
dev_label=MISC_recall_tok: 0.862776025236593
dev_label=MISC_f-score_tok: 0.88582995951417
dev_label=ORG_precision_tok: 0.9186489058039962
dev_label=ORG_recall_tok: 0.9230401529636711
dev_label=ORG_f-score_tok: 0.9208392942298521
dev_label=PER_precision_tok: 0.9776999044281618
dev_label=PER_recall_tok: 0.9745951095585901
dev_label=PER_f-score_tok: 0.976145038167939
dev_precision_macro_tok: 0.952653485675852
dev_recall_macro_tok: 0.9418256256431146
dev_f-score_macro_tok: 0.9471058846680418
dev_precision_micro_tok: 0.9877925314434796
dev_recall_micro_tok: 0.9877925314434796
dev_f-score_micro_tok: 0.9877925314434796
dev_time: 34.655797243118286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9685    0.9535    0.9609       645
           1     0.9885    0.9923    0.9904      2605

   micro avg     0.9846    0.9846    0.9846      3250
   macro avg     0.9785    0.9729    0.9757      3250
weighted avg     0.9846    0.9846    0.9846      3250

F1-macro sent:  0.9756794779693487
F1-micro sent:  0.9846153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9974    0.9964     42759
         LOC     0.9614    0.9513    0.9563      2094
        MISC     0.9101    0.8628    0.8858      1268
         ORG     0.9186    0.9230    0.9208      2092
         PER     0.9777    0.9746    0.9761      3149

   micro avg     0.9878    0.9878    0.9878     51362
   macro avg     0.9527    0.9418    0.9471     51362
weighted avg     0.9877    0.9878    0.9877     51362

F1-macro tok:  0.9471058846680418
F1-micro tok:  0.9877925314434796
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 329046.88189697266
train_cost_avg: 23.434718460008025
train_count_sent: 14041.0
train_total_correct_sent: 13623.0
train_accuracy_sent: 0.9702300405953992
train_count_tok: 203621.0
train_total_correct_tok: 200656.0
train_accuracy_tok: 0.9854386335397626
train_label=0_precision_sent: 0.926979773740144
train_label=0_recall_sent: 0.9295290477827433
train_label=0_f-score_sent: 0.92825266048747
train_label=1_precision_sent: 0.9815713772024451
train_label=1_recall_sent: 0.9808659719726913
train_label=1_f-score_sent: 0.9812185478073329
train_precision_macro_sent: 0.9542755754712946
train_recall_macro_sent: 0.9551975098777172
train_f-score_macro_sent: 0.9547356041474014
train_precision_micro_sent: 0.9702300405953992
train_recall_micro_sent: 0.9702300405953992
train_f-score_micro_sent: 0.9702300405953992
train_label=O_precision_tok: 0.9954937177123402
train_label=O_recall_tok: 0.9965797450140939
train_label=O_f-score_tok: 0.9960364353261174
train_label=LOC_precision_tok: 0.9372822299651568
train_label=LOC_recall_tok: 0.9402193563938773
train_label=LOC_f-score_tok: 0.938748495788207
train_label=MISC_precision_tok: 0.8908845981140547
train_label=MISC_recall_tok: 0.8639233616372741
train_label=MISC_f-score_tok: 0.8771968608378468
train_label=ORG_precision_tok: 0.9157099697885196
train_label=ORG_recall_tok: 0.9070324189526184
train_label=ORG_f-score_tok: 0.9113505387121021
train_label=PER_precision_tok: 0.9681642901981885
train_label=PER_recall_tok: 0.9701653486700216
train_label=PER_f-score_tok: 0.9691637865254276
train_precision_macro_tok: 0.941506961155652
train_recall_macro_tok: 0.935584046133577
train_f-score_macro_tok: 0.9384992234379401
train_precision_micro_tok: 0.9854386335397626
train_recall_micro_tok: 0.9854386335397626
train_f-score_micro_tok: 0.9854386335397626
train_time: 327.53195810317993
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9270    0.9295    0.9283      2909
           1     0.9816    0.9809    0.9812     11132

   micro avg     0.9702    0.9702    0.9702     14041
   macro avg     0.9543    0.9552    0.9547     14041
weighted avg     0.9703    0.9702    0.9702     14041

F1-macro sent:  0.9547356041474014
F1-micro sent:  0.9702300405953992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9966    0.9960    169578
         LOC     0.9373    0.9402    0.9387      8297
        MISC     0.8909    0.8639    0.8772      4593
         ORG     0.9157    0.9070    0.9114     10025
         PER     0.9682    0.9702    0.9692     11128

   micro avg     0.9854    0.9854    0.9854    203621
   macro avg     0.9415    0.9356    0.9385    203621
weighted avg     0.9853    0.9854    0.9854    203621

F1-macro tok:  0.9384992234379401
F1-micro tok:  0.9854386335397626
**************************************************
dev_cost_sum: 88024.51223754883
dev_cost_avg: 27.08446530386118
dev_count_sent: 3250.0
dev_total_correct_sent: 3194.0
dev_accuracy_sent: 0.9827692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50729.0
dev_accuracy_tok: 0.987675713562556
dev_label=0_precision_sent: 0.955177743431221
dev_label=0_recall_sent: 0.958139534883721
dev_label=0_f-score_sent: 0.9566563467492261
dev_label=1_precision_sent: 0.9896273530541683
dev_label=1_recall_sent: 0.9888675623800384
dev_label=1_f-score_sent: 0.989247311827957
dev_precision_macro_sent: 0.9724025482426946
dev_recall_macro_sent: 0.9735035486318797
dev_f-score_macro_sent: 0.9729518292885915
dev_precision_micro_sent: 0.9827692307692307
dev_recall_micro_sent: 0.9827692307692307
dev_f-score_micro_sent: 0.9827692307692307
dev_label=O_precision_tok: 0.9957499474581416
dev_label=O_recall_tok: 0.9972403470614374
dev_label=O_f-score_tok: 0.9964945899838752
dev_label=LOC_precision_tok: 0.9636275460717749
dev_label=LOC_recall_tok: 0.9489016236867239
dev_label=LOC_f-score_tok: 0.9562078922040422
dev_label=MISC_precision_tok: 0.8971291866028708
dev_label=MISC_recall_tok: 0.887223974763407
dev_label=MISC_f-score_tok: 0.8921490880253766
dev_label=ORG_precision_tok: 0.93389662027833
dev_label=ORG_recall_tok: 0.8981835564053537
dev_label=ORG_f-score_tok: 0.915692007797271
dev_label=PER_precision_tok: 0.9644970414201184
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9738993710691823
dev_precision_macro_tok: 0.950980068366247
dev_recall_macro_tok: 0.9430072646260012
dev_f-score_macro_tok: 0.9468885898159496
dev_precision_micro_tok: 0.987675713562556
dev_recall_micro_tok: 0.987675713562556
dev_f-score_micro_tok: 0.987675713562556
dev_time: 34.93550133705139
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9552    0.9581    0.9567       645
           1     0.9896    0.9889    0.9892      2605

   micro avg     0.9828    0.9828    0.9828      3250
   macro avg     0.9724    0.9735    0.9730      3250
weighted avg     0.9828    0.9828    0.9828      3250

F1-macro sent:  0.9729518292885915
F1-micro sent:  0.9827692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9972    0.9965     42759
         LOC     0.9636    0.9489    0.9562      2094
        MISC     0.8971    0.8872    0.8921      1268
         ORG     0.9339    0.8982    0.9157      2092
         PER     0.9645    0.9835    0.9739      3149

   micro avg     0.9877    0.9877    0.9877     51362
   macro avg     0.9510    0.9430    0.9469     51362
weighted avg     0.9876    0.9877    0.9876     51362

F1-macro tok:  0.9468885898159496
F1-micro tok:  0.987675713562556
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 325905.14321899414
train_cost_avg: 23.210963835837486
train_count_sent: 14041.0
train_total_correct_sent: 13693.0
train_accuracy_sent: 0.9752154404956912
train_count_tok: 203621.0
train_total_correct_tok: 200888.0
train_accuracy_tok: 0.986578005215572
train_label=0_precision_sent: 0.9348047538200339
train_label=0_recall_sent: 0.9463733241663802
train_label=0_f-score_sent: 0.9405534677143834
train_label=1_precision_sent: 0.9859408795962509
train_label=1_recall_sent: 0.9827524254401725
train_label=1_f-score_sent: 0.9843440705416592
train_precision_macro_sent: 0.9603728167081425
train_recall_macro_sent: 0.9645628748032764
train_f-score_macro_sent: 0.9624487691280212
train_precision_micro_sent: 0.9752154404956912
train_recall_micro_sent: 0.9752154404956912
train_f-score_micro_sent: 0.9752154404956912
train_label=O_precision_tok: 0.9957401428201079
train_label=O_recall_tok: 0.9965974359881589
train_label=O_f-score_tok: 0.9961686049595936
train_label=LOC_precision_tok: 0.9435687642882926
train_label=LOC_recall_tok: 0.9451609015306738
train_label=LOC_f-score_tok: 0.9443641618497111
train_label=MISC_precision_tok: 0.8987256874580818
train_label=MISC_recall_tok: 0.8752449379490529
train_label=MISC_f-score_tok: 0.886829913964262
train_label=ORG_precision_tok: 0.9226741844542892
train_label=ORG_recall_tok: 0.9141147132169576
train_label=ORG_f-score_tok: 0.9183745051861502
train_label=PER_precision_tok: 0.9713800196762364
train_label=PER_recall_tok: 0.9760064701653487
train_label=PER_f-score_tok: 0.9736877493388318
train_precision_macro_tok: 0.9464177597394017
train_recall_macro_tok: 0.9414248917700384
train_f-score_macro_tok: 0.9438849870597098
train_precision_micro_tok: 0.986578005215572
train_recall_micro_tok: 0.986578005215572
train_f-score_micro_tok: 0.986578005215572
train_time: 326.5985550880432
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9348    0.9464    0.9406      2909
           1     0.9859    0.9828    0.9843     11132

   micro avg     0.9752    0.9752    0.9752     14041
   macro avg     0.9604    0.9646    0.9624     14041
weighted avg     0.9753    0.9752    0.9753     14041

F1-macro sent:  0.9624487691280212
F1-micro sent:  0.9752154404956912
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9966    0.9962    169578
         LOC     0.9436    0.9452    0.9444      8297
        MISC     0.8987    0.8752    0.8868      4593
         ORG     0.9227    0.9141    0.9184     10025
         PER     0.9714    0.9760    0.9737     11128

   micro avg     0.9866    0.9866    0.9866    203621
   macro avg     0.9464    0.9414    0.9439    203621
weighted avg     0.9865    0.9866    0.9865    203621

F1-macro tok:  0.9438849870597098
F1-micro tok:  0.986578005215572
**************************************************
dev_cost_sum: 87506.68242645264
dev_cost_avg: 26.92513305429312
dev_count_sent: 3250.0
dev_total_correct_sent: 3190.0
dev_accuracy_sent: 0.9815384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50735.0
dev_accuracy_tok: 0.9877925314434796
dev_label=0_precision_sent: 0.9372197309417041
dev_label=0_recall_sent: 0.9720930232558139
dev_label=0_f-score_sent: 0.9543378995433789
dev_label=1_precision_sent: 0.993025958930647
dev_label=1_recall_sent: 0.9838771593090211
dev_label=1_f-score_sent: 0.9884303895102198
dev_precision_macro_sent: 0.9651228449361755
dev_recall_macro_sent: 0.9779850912824175
dev_f-score_macro_sent: 0.9713841445267993
dev_precision_micro_sent: 0.9815384615384616
dev_recall_micro_sent: 0.9815384615384616
dev_f-score_micro_sent: 0.9815384615384616
dev_label=O_precision_tok: 0.995634003408746
dev_label=O_recall_tok: 0.9973105077293669
dev_label=O_f-score_tok: 0.9964715504147681
dev_label=LOC_precision_tok: 0.9556085918854416
dev_label=LOC_recall_tok: 0.956064947468959
dev_label=LOC_f-score_tok: 0.9558367152064932
dev_label=MISC_precision_tok: 0.9143576826196473
dev_label=MISC_recall_tok: 0.8588328075709779
dev_label=MISC_f-score_tok: 0.8857259048393655
dev_label=ORG_precision_tok: 0.929126213592233
dev_label=ORG_recall_tok: 0.9149139579349904
dev_label=ORG_f-score_tok: 0.9219653179190752
dev_label=PER_precision_tok: 0.968916797488226
dev_label=PER_recall_tok: 0.9799936487773896
dev_label=PER_f-score_tok: 0.974423744868961
dev_precision_macro_tok: 0.9527286577988587
dev_recall_macro_tok: 0.9414231738963368
dev_f-score_macro_tok: 0.9468846466497325
dev_precision_micro_tok: 0.9877925314434796
dev_recall_micro_tok: 0.9877925314434796
dev_f-score_micro_tok: 0.9877925314434796
dev_time: 34.29463243484497
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9372    0.9721    0.9543       645
           1     0.9930    0.9839    0.9884      2605

   micro avg     0.9815    0.9815    0.9815      3250
   macro avg     0.9651    0.9780    0.9714      3250
weighted avg     0.9820    0.9815    0.9817      3250

F1-macro sent:  0.9713841445267993
F1-micro sent:  0.9815384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9973    0.9965     42759
         LOC     0.9556    0.9561    0.9558      2094
        MISC     0.9144    0.8588    0.8857      1268
         ORG     0.9291    0.9149    0.9220      2092
         PER     0.9689    0.9800    0.9744      3149

   micro avg     0.9878    0.9878    0.9878     51362
   macro avg     0.9527    0.9414    0.9469     51362
weighted avg     0.9876    0.9878    0.9877     51362

F1-macro tok:  0.9468846466497325
F1-micro tok:  0.9877925314434796
**************************************************
Best epoch: 9
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 323128.998046875
train_cost_avg: 23.0132467806335
train_count_sent: 14041.0
train_total_correct_sent: 13705.0
train_accuracy_sent: 0.9760700804785984
train_count_tok: 203621.0
train_total_correct_tok: 201041.0
train_accuracy_tok: 0.9873294011914292
train_label=0_precision_sent: 0.9410353102502571
train_label=0_recall_sent: 0.9436232382261945
train_label=0_f-score_sent: 0.9423274974253346
train_label=1_precision_sent: 0.9852571017619561
train_label=1_recall_sent: 0.9845490477901545
train_label=1_f-score_sent: 0.9849029475197699
train_precision_macro_sent: 0.9631462060061067
train_recall_macro_sent: 0.9640861430081745
train_f-score_macro_sent: 0.9636152224725523
train_precision_micro_sent: 0.9760700804785984
train_recall_micro_sent: 0.9760700804785984
train_f-score_micro_sent: 0.9760700804785984
train_label=O_precision_tok: 0.9958403544536488
train_label=O_recall_tok: 0.996709478823904
train_label=O_f-score_tok: 0.9962747270883927
train_label=LOC_precision_tok: 0.9499698613622665
train_label=LOC_recall_tok: 0.9497408701940461
train_label=LOC_f-score_tok: 0.9498553519768563
train_label=MISC_precision_tok: 0.90498546836575
train_label=MISC_recall_tok: 0.8813411713477031
train_label=MISC_f-score_tok: 0.8930068387381425
train_label=ORG_precision_tok: 0.9254913758523867
train_label=ORG_recall_tok: 0.9205985037406483
train_label=ORG_f-score_tok: 0.9230384557683654
train_label=PER_precision_tok: 0.9739130434782609
train_label=PER_recall_tok: 0.9762760603882099
train_label=PER_f-score_tok: 0.9750931203159359
train_precision_macro_tok: 0.9500400207024626
train_recall_macro_tok: 0.9449332168989024
train_f-score_macro_tok: 0.9474536987775386
train_precision_micro_tok: 0.9873294011914292
train_recall_micro_tok: 0.9873294011914292
train_f-score_micro_tok: 0.9873294011914292
train_time: 327.2997410297394
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9410    0.9436    0.9423      2909
           1     0.9853    0.9845    0.9849     11132

   micro avg     0.9761    0.9761    0.9761     14041
   macro avg     0.9631    0.9641    0.9636     14041
weighted avg     0.9761    0.9761    0.9761     14041

F1-macro sent:  0.9636152224725523
F1-micro sent:  0.9760700804785984
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9967    0.9963    169578
         LOC     0.9500    0.9497    0.9499      8297
        MISC     0.9050    0.8813    0.8930      4593
         ORG     0.9255    0.9206    0.9230     10025
         PER     0.9739    0.9763    0.9751     11128

   micro avg     0.9873    0.9873    0.9873    203621
   macro avg     0.9500    0.9449    0.9475    203621
weighted avg     0.9873    0.9873    0.9873    203621

F1-macro tok:  0.9474536987775386
F1-micro tok:  0.9873294011914292
**************************************************
dev_cost_sum: 86962.87267303467
dev_cost_avg: 26.75780697631836
dev_count_sent: 3250.0
dev_total_correct_sent: 3179.0
dev_accuracy_sent: 0.9781538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50728.0
dev_accuracy_tok: 0.9876562439157354
dev_label=0_precision_sent: 0.993127147766323
dev_label=0_recall_sent: 0.896124031007752
dev_label=0_f-score_sent: 0.9421352893235535
dev_label=1_precision_sent: 0.974887556221889
dev_label=1_recall_sent: 0.9984644913627639
dev_label=1_f-score_sent: 0.9865351792148682
dev_precision_macro_sent: 0.984007351994106
dev_recall_macro_sent: 0.947294261185258
dev_f-score_macro_sent: 0.9643352342692109
dev_precision_micro_sent: 0.9781538461538462
dev_recall_micro_sent: 0.9781538461538462
dev_f-score_micro_sent: 0.9781538461538462
dev_label=O_precision_tok: 0.9961913218216231
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9966337837206042
dev_label=LOC_precision_tok: 0.931891394385642
dev_label=LOC_recall_tok: 0.9670487106017192
dev_label=LOC_f-score_tok: 0.9491445980782751
dev_label=MISC_precision_tok: 0.9225531914893617
dev_label=MISC_recall_tok: 0.8548895899053628
dev_label=MISC_f-score_tok: 0.8874334834220221
dev_label=ORG_precision_tok: 0.9320531757754801
dev_label=ORG_recall_tok: 0.9048757170172084
dev_label=ORG_f-score_tok: 0.9182634004365753
dev_label=PER_precision_tok: 0.970495919648462
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9761641673243884
dev_precision_macro_tok: 0.9506370006241138
dev_recall_macro_tok: 0.9411579343842108
dev_f-score_macro_tok: 0.9455278865963731
dev_precision_micro_tok: 0.9876562439157354
dev_recall_micro_tok: 0.9876562439157354
dev_f-score_micro_tok: 0.9876562439157354
dev_time: 34.35569715499878
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9931    0.8961    0.9421       645
           1     0.9749    0.9985    0.9865      2605

   micro avg     0.9782    0.9782    0.9782      3250
   macro avg     0.9840    0.9473    0.9643      3250
weighted avg     0.9785    0.9782    0.9777      3250

F1-macro sent:  0.9643352342692109
F1-micro sent:  0.9781538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9971    0.9966     42759
         LOC     0.9319    0.9670    0.9491      2094
        MISC     0.9226    0.8549    0.8874      1268
         ORG     0.9321    0.9049    0.9183      2092
         PER     0.9705    0.9819    0.9762      3149

   micro avg     0.9877    0.9877    0.9877     51362
   macro avg     0.9506    0.9412    0.9455     51362
weighted avg     0.9876    0.9877    0.9876     51362

F1-macro tok:  0.9455278865963731
F1-micro tok:  0.9876562439157354
**************************************************
Best epoch: 9
**************************************************

EPOCH: 13
Learning rate: 1.000000
2019-03-29 10:23:01.819491: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.00G (2147483648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-03-29 10:23:01.829634: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.80G (1932735232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
train_cost_sum: 320656.26385498047
train_cost_avg: 22.837138655008935
train_count_sent: 14041.0
train_total_correct_sent: 13721.0
train_accuracy_sent: 0.977209600455808
train_count_tok: 203621.0
train_total_correct_tok: 201205.0
train_accuracy_tok: 0.9881348191001911
train_label=0_precision_sent: 0.9419597132127006
train_label=0_recall_sent: 0.9484358886215194
train_label=0_f-score_sent: 0.9451867077766357
train_label=1_precision_sent: 0.9865010799136069
train_label=1_recall_sent: 0.9847287100251527
train_label=1_f-score_sent: 0.9856140981837799
train_precision_macro_sent: 0.9642303965631538
train_recall_macro_sent: 0.9665822993233361
train_f-score_macro_sent: 0.9654004029802078
train_precision_micro_sent: 0.977209600455808
train_recall_micro_sent: 0.977209600455808
train_f-score_micro_sent: 0.977209600455808
train_label=O_precision_tok: 0.9961585143113018
train_label=O_recall_tok: 0.9970279163570747
train_label=O_f-score_tok: 0.9965930257232453
train_label=LOC_precision_tok: 0.9508255996143185
train_label=LOC_recall_tok: 0.9508255996143185
train_label=LOC_f-score_tok: 0.9508255996143185
train_label=MISC_precision_tok: 0.913412184780183
train_label=MISC_recall_tok: 0.8911386893098193
train_label=MISC_f-score_tok: 0.9021379766365439
train_label=ORG_precision_tok: 0.9319666365189428
train_label=ORG_recall_tok: 0.9250872817955113
train_label=ORG_f-score_tok: 0.9285142170604727
train_label=PER_precision_tok: 0.9739387426114992
train_label=PER_recall_tok: 0.9772645578720345
train_label=PER_f-score_tok: 0.9755988158248856
train_precision_macro_tok: 0.9532603355672491
train_recall_macro_tok: 0.9482688089897516
train_f-score_macro_tok: 0.9507339269718932
train_precision_micro_tok: 0.9881348191001911
train_recall_micro_tok: 0.9881348191001911
train_f-score_micro_tok: 0.9881348191001911
train_time: 328.1729545593262
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9420    0.9484    0.9452      2909
           1     0.9865    0.9847    0.9856     11132

   micro avg     0.9772    0.9772    0.9772     14041
   macro avg     0.9642    0.9666    0.9654     14041
weighted avg     0.9773    0.9772    0.9772     14041

F1-macro sent:  0.9654004029802078
F1-micro sent:  0.977209600455808
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9970    0.9966    169578
         LOC     0.9508    0.9508    0.9508      8297
        MISC     0.9134    0.8911    0.9021      4593
         ORG     0.9320    0.9251    0.9285     10025
         PER     0.9739    0.9773    0.9756     11128

   micro avg     0.9881    0.9881    0.9881    203621
   macro avg     0.9533    0.9483    0.9507    203621
weighted avg     0.9881    0.9881    0.9881    203621

F1-macro tok:  0.9507339269718932
F1-micro tok:  0.9881348191001911
**************************************************
dev_cost_sum: 86462.11400604248
dev_cost_avg: 26.60372738647461
dev_count_sent: 3250.0
dev_total_correct_sent: 3198.0
dev_accuracy_sent: 0.984
dev_count_tok: 51362.0
dev_total_correct_tok: 50776.0
dev_accuracy_tok: 0.9885907869631245
dev_label=0_precision_sent: 0.9917081260364843
dev_label=0_recall_sent: 0.9271317829457364
dev_label=0_f-score_sent: 0.9583333333333333
dev_label=1_precision_sent: 0.9822440498677748
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9900990099009901
dev_precision_macro_sent: 0.9869760879521295
dev_recall_macro_sent: 0.9626061985745956
dev_f-score_macro_sent: 0.9742161716171617
dev_precision_micro_sent: 0.984
dev_recall_micro_sent: 0.984
dev_f-score_micro_sent: 0.984
dev_label=O_precision_tok: 0.9963540327669619
dev_label=O_recall_tok: 0.9970064781683389
dev_label=O_f-score_tok: 0.9966801486919319
dev_label=LOC_precision_tok: 0.9554291133238502
dev_label=LOC_recall_tok: 0.9622731614135626
dev_label=LOC_f-score_tok: 0.9588389245776826
dev_label=MISC_precision_tok: 0.8860465116279069
dev_label=MISC_recall_tok: 0.9014195583596214
dev_label=MISC_f-score_tok: 0.8936669272869429
dev_label=ORG_precision_tok: 0.9468937875751503
dev_label=ORG_recall_tok: 0.9034416826003824
dev_label=ORG_f-score_tok: 0.9246575342465754
dev_label=PER_precision_tok: 0.9738993710691823
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9786696160530889
dev_precision_macro_tok: 0.9517245632726103
dev_recall_macro_tok: 0.9495255403509978
dev_f-score_macro_tok: 0.9505026301712443
dev_precision_micro_tok: 0.9885907869631245
dev_recall_micro_tok: 0.9885907869631245
dev_f-score_micro_tok: 0.9885907869631245
dev_time: 34.46915149688721
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9917    0.9271    0.9583       645
           1     0.9822    0.9981    0.9901      2605

   micro avg     0.9840    0.9840    0.9840      3250
   macro avg     0.9870    0.9626    0.9742      3250
weighted avg     0.9841    0.9840    0.9838      3250

F1-macro sent:  0.9742161716171617
F1-micro sent:  0.984
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9970    0.9967     42759
         LOC     0.9554    0.9623    0.9588      2094
        MISC     0.8860    0.9014    0.8937      1268
         ORG     0.9469    0.9034    0.9247      2092
         PER     0.9739    0.9835    0.9787      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9517    0.9495    0.9505     51362
weighted avg     0.9886    0.9886    0.9886     51362

F1-macro tok:  0.9505026301712443
F1-micro tok:  0.9885907869631245
**************************************************
Best epoch: 9
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 318062.9135131836
train_cost_avg: 22.65244024736013
train_count_sent: 14041.0
train_total_correct_sent: 13736.0
train_accuracy_sent: 0.978277900434442
train_count_tok: 203621.0
train_total_correct_tok: 201402.0
train_accuracy_tok: 0.9891023028076672
train_label=0_precision_sent: 0.9477303988995873
train_label=0_recall_sent: 0.9474046063939499
train_label=0_f-score_sent: 0.9475674746432869
train_label=1_precision_sent: 0.9862570735650767
train_label=1_recall_sent: 0.9863456701401365
train_label=1_f-score_sent: 0.9863013698630138
train_precision_macro_sent: 0.966993736232332
train_recall_macro_sent: 0.9668751382670432
train_f-score_macro_sent: 0.9669344222531504
train_precision_micro_sent: 0.978277900434442
train_recall_micro_sent: 0.978277900434442
train_f-score_micro_sent: 0.978277900434442
train_label=O_precision_tok: 0.9965289850375093
train_label=O_recall_tok: 0.9971930321150149
train_label=O_f-score_tok: 0.9968608979895008
train_label=LOC_precision_tok: 0.9546933365465718
train_label=LOC_recall_tok: 0.9549234663131252
train_label=LOC_f-score_tok: 0.9548083875632681
train_label=MISC_precision_tok: 0.9208361129641983
train_label=MISC_recall_tok: 0.9015893751360766
train_label=MISC_f-score_tok: 0.9111111111111112
train_label=ORG_precision_tok: 0.9365922067514775
train_label=ORG_recall_tok: 0.9326683291770573
train_label=ORG_f-score_tok: 0.9346261495401839
train_label=PER_precision_tok: 0.976235315218366
train_label=PER_recall_tok: 0.978253055355859
train_label=PER_f-score_tok: 0.9772431437676735
train_precision_macro_tok: 0.9569771913036245
train_recall_macro_tok: 0.9529254516194265
train_f-score_macro_tok: 0.9549299379943476
train_precision_micro_tok: 0.9891023028076672
train_recall_micro_tok: 0.9891023028076672
train_f-score_micro_tok: 0.9891023028076672
train_time: 322.51802468299866
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9477    0.9474    0.9476      2909
           1     0.9863    0.9863    0.9863     11132

   micro avg     0.9783    0.9783    0.9783     14041
   macro avg     0.9670    0.9669    0.9669     14041
weighted avg     0.9783    0.9783    0.9783     14041

F1-macro sent:  0.9669344222531504
F1-micro sent:  0.978277900434442
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9972    0.9969    169578
         LOC     0.9547    0.9549    0.9548      8297
        MISC     0.9208    0.9016    0.9111      4593
         ORG     0.9366    0.9327    0.9346     10025
         PER     0.9762    0.9783    0.9772     11128

   micro avg     0.9891    0.9891    0.9891    203621
   macro avg     0.9570    0.9529    0.9549    203621
weighted avg     0.9891    0.9891    0.9891    203621

F1-macro tok:  0.9549299379943476
F1-micro tok:  0.9891023028076672
**************************************************
dev_cost_sum: 86082.02983093262
dev_cost_avg: 26.48677840951773
dev_count_sent: 3250.0
dev_total_correct_sent: 3215.0
dev_accuracy_sent: 0.9892307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50774.0
dev_accuracy_tok: 0.9885518476694832
dev_label=0_precision_sent: 0.9750778816199377
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9728049728049727
dev_label=1_precision_sent: 0.9927147239263804
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9932860157299059
dev_precision_macro_sent: 0.9838963027731591
dev_recall_macro_sent: 0.9822003005549852
dev_f-score_macro_sent: 0.9830454942674394
dev_precision_micro_sent: 0.9892307692307692
dev_recall_micro_sent: 0.9892307692307692
dev_f-score_micro_sent: 0.9892307692307692
dev_label=O_precision_tok: 0.9968650570840352
dev_label=O_recall_tok: 0.9965153534928319
dev_label=O_f-score_tok: 0.9966901746137562
dev_label=LOC_precision_tok: 0.9641993226898887
dev_label=LOC_recall_tok: 0.9517669531996179
dev_label=LOC_f-score_tok: 0.957942802211007
dev_label=MISC_precision_tok: 0.9135399673735726
dev_label=MISC_recall_tok: 0.8832807570977917
dev_label=MISC_f-score_tok: 0.8981555733761025
dev_label=ORG_precision_tok: 0.9187529522909778
dev_label=ORG_recall_tok: 0.9297323135755258
dev_label=ORG_f-score_tok: 0.9242100261344736
dev_label=PER_precision_tok: 0.9682044887780549
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9771904986628913
dev_precision_macro_tok: 0.9523123576433058
dev_recall_macro_tok: 0.9495280497507019
dev_f-score_macro_tok: 0.9508378149996461
dev_precision_micro_tok: 0.9885518476694832
dev_recall_micro_tok: 0.9885518476694832
dev_f-score_micro_tok: 0.9885518476694831
dev_time: 24.55189037322998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9751    0.9705    0.9728       645
           1     0.9927    0.9939    0.9933      2605

   micro avg     0.9892    0.9892    0.9892      3250
   macro avg     0.9839    0.9822    0.9830      3250
weighted avg     0.9892    0.9892    0.9892      3250

F1-macro sent:  0.9830454942674394
F1-micro sent:  0.9892307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9965    0.9967     42759
         LOC     0.9642    0.9518    0.9579      2094
        MISC     0.9135    0.8833    0.8982      1268
         ORG     0.9188    0.9297    0.9242      2092
         PER     0.9682    0.9863    0.9772      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9523    0.9495    0.9508     51362
weighted avg     0.9885    0.9886    0.9885     51362

F1-macro tok:  0.9508378149996461
F1-micro tok:  0.9885518476694831
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 315976.124420166
train_cost_avg: 22.50381913112784
train_count_sent: 14041.0
train_total_correct_sent: 13795.0
train_accuracy_sent: 0.9824798803504023
train_count_tok: 203621.0
train_total_correct_tok: 201505.0
train_accuracy_tok: 0.9896081445430481
train_label=0_precision_sent: 0.9570889117748026
train_label=0_recall_sent: 0.9584049501546923
train_label=0_f-score_sent: 0.9577464788732394
train_label=1_precision_sent: 0.9891265276779295
train_label=1_recall_sent: 0.9887711103126123
train_label=1_f-score_sent: 0.9889487870619946
train_precision_macro_sent: 0.973107719726366
train_recall_macro_sent: 0.9735880302336524
train_f-score_macro_sent: 0.973347632967617
train_precision_micro_sent: 0.9824798803504023
train_recall_micro_sent: 0.9824798803504023
train_f-score_micro_sent: 0.9824798803504023
train_label=O_precision_tok: 0.9966223584544195
train_label=O_recall_tok: 0.9970161223743645
train_label=O_f-score_tok: 0.9968192015281981
train_label=LOC_precision_tok: 0.9567209162145871
train_label=LOC_recall_tok: 0.9564902976979631
train_label=LOC_f-score_tok: 0.9566055930568949
train_label=MISC_precision_tok: 0.9197435330532833
train_label=MISC_recall_tok: 0.9057261049423035
train_label=MISC_f-score_tok: 0.912681000438789
train_label=ORG_precision_tok: 0.943137451196316
train_label=ORG_recall_tok: 0.9397506234413965
train_label=ORG_f-score_tok: 0.9414409913060857
train_label=PER_precision_tok: 0.9773480168323037
train_label=PER_recall_tok: 0.9809489575844716
train_label=PER_f-score_tok: 0.979145176481141
train_precision_macro_tok: 0.9587144551501818
train_recall_macro_tok: 0.9559864212081
train_f-score_macro_tok: 0.9573383925622216
train_precision_micro_tok: 0.9896081445430481
train_recall_micro_tok: 0.9896081445430481
train_f-score_micro_tok: 0.9896081445430481
train_time: 241.92034339904785
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9571    0.9584    0.9577      2909
           1     0.9891    0.9888    0.9889     11132

   micro avg     0.9825    0.9825    0.9825     14041
   macro avg     0.9731    0.9736    0.9733     14041
weighted avg     0.9825    0.9825    0.9825     14041

F1-macro sent:  0.973347632967617
F1-micro sent:  0.9824798803504023
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9966    0.9970    0.9968    169578
         LOC     0.9567    0.9565    0.9566      8297
        MISC     0.9197    0.9057    0.9127      4593
         ORG     0.9431    0.9398    0.9414     10025
         PER     0.9773    0.9809    0.9791     11128

   micro avg     0.9896    0.9896    0.9896    203621
   macro avg     0.9587    0.9560    0.9573    203621
weighted avg     0.9896    0.9896    0.9896    203621

F1-macro tok:  0.9573383925622216
F1-micro tok:  0.9896081445430481
**************************************************
dev_cost_sum: 85888.81746673584
dev_cost_avg: 26.427328451303335
dev_count_sent: 3250.0
dev_total_correct_sent: 3169.0
dev_accuracy_sent: 0.9750769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50766.0
dev_accuracy_tok: 0.9883960904949184
dev_label=0_precision_sent: 0.8949579831932774
dev_label=0_recall_sent: 0.9906976744186047
dev_label=0_f-score_sent: 0.9403973509933775
dev_label=1_precision_sent: 0.9976340694006309
dev_label=1_recall_sent: 0.9712092130518234
dev_label=1_f-score_sent: 0.9842443104454386
dev_precision_macro_sent: 0.9462960262969542
dev_recall_macro_sent: 0.9809534437352141
dev_f-score_macro_sent: 0.962320830719408
dev_precision_micro_sent: 0.9750769230769231
dev_recall_micro_sent: 0.9750769230769231
dev_f-score_micro_sent: 0.9750769230769231
dev_label=O_precision_tok: 0.9957981231616789
dev_label=O_recall_tok: 0.9976379241797049
dev_label=O_f-score_tok: 0.9967171746673366
dev_label=LOC_precision_tok: 0.9541154210028382
dev_label=LOC_recall_tok: 0.9632282712511939
dev_label=LOC_f-score_tok: 0.9586501901140685
dev_label=MISC_precision_tok: 0.9117889530090684
dev_label=MISC_recall_tok: 0.8722397476340694
dev_label=MISC_f-score_tok: 0.8915759774284562
dev_label=ORG_precision_tok: 0.9532520325203252
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.9241379310344828
dev_label=PER_precision_tok: 0.9628367915763394
dev_label=PER_recall_tok: 0.987297554779295
dev_label=PER_f-score_tok: 0.9749137660708685
dev_precision_macro_tok: 0.95555826425405
dev_recall_macro_tok: 0.9434306039665582
dev_f-score_macro_tok: 0.9491990078630425
dev_precision_micro_tok: 0.9883960904949184
dev_recall_micro_tok: 0.9883960904949184
dev_f-score_micro_tok: 0.9883960904949184
dev_time: 24.220227003097534
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8950    0.9907    0.9404       645
           1     0.9976    0.9712    0.9842      2605

   micro avg     0.9751    0.9751    0.9751      3250
   macro avg     0.9463    0.9810    0.9623      3250
weighted avg     0.9773    0.9751    0.9755      3250

F1-macro sent:  0.962320830719408
F1-micro sent:  0.9750769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9976    0.9967     42759
         LOC     0.9541    0.9632    0.9587      2094
        MISC     0.9118    0.8722    0.8916      1268
         ORG     0.9533    0.8967    0.9241      2092
         PER     0.9628    0.9873    0.9749      3149

   micro avg     0.9884    0.9884    0.9884     51362
   macro avg     0.9556    0.9434    0.9492     51362
weighted avg     0.9883    0.9884    0.9883     51362

F1-macro tok:  0.9491990078630425
F1-micro tok:  0.9883960904949184
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 314163.44287109375
train_cost_avg: 22.374719953784897
train_count_sent: 14041.0
train_total_correct_sent: 13757.0
train_accuracy_sent: 0.9797735204045296
train_count_tok: 203621.0
train_total_correct_tok: 201635.0
train_accuracy_tok: 0.9902465855682862
train_label=0_precision_sent: 0.9499485773054508
train_label=0_recall_sent: 0.9525610175317979
train_label=0_f-score_sent: 0.9512530037761758
train_label=1_precision_sent: 0.9875943905070119
train_label=1_recall_sent: 0.9868846568451312
train_label=1_f-score_sent: 0.9872393961179008
train_precision_macro_sent: 0.9687714839062314
train_recall_macro_sent: 0.9697228371884645
train_f-score_macro_sent: 0.9692461999470383
train_precision_micro_sent: 0.9797735204045296
train_recall_micro_sent: 0.9797735204045296
train_f-score_micro_sent: 0.9797735204045296
train_label=O_precision_tok: 0.9967760377680986
train_label=O_recall_tok: 0.9972991779594051
train_label=O_f-score_tok: 0.997037539241551
train_label=LOC_precision_tok: 0.9600481347773766
train_label=LOC_recall_tok: 0.961552368325901
train_label=LOC_f-score_tok: 0.9607996627927983
train_label=MISC_precision_tok: 0.9280177187153932
train_label=MISC_recall_tok: 0.9122577835837143
train_label=MISC_f-score_tok: 0.9200702678963549
train_label=ORG_precision_tok: 0.9458889669711876
train_label=ORG_recall_tok: 0.939850374064838
train_label=ORG_f-score_tok: 0.942860002001401
train_label=PER_precision_tok: 0.9782414040114613
train_label=PER_recall_tok: 0.9817577282530554
train_label=PER_f-score_tok: 0.9799964119124507
train_precision_macro_tok: 0.9617944524487034
train_recall_macro_tok: 0.9585434864373827
train_f-score_macro_tok: 0.9601527767689111
train_precision_micro_tok: 0.9902465855682862
train_recall_micro_tok: 0.9902465855682862
train_f-score_micro_tok: 0.9902465855682862
train_time: 241.81293559074402
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9499    0.9526    0.9513      2909
           1     0.9876    0.9869    0.9872     11132

   micro avg     0.9798    0.9798    0.9798     14041
   macro avg     0.9688    0.9697    0.9692     14041
weighted avg     0.9798    0.9798    0.9798     14041

F1-macro sent:  0.9692461999470383
F1-micro sent:  0.9797735204045296
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9973    0.9970    169578
         LOC     0.9600    0.9616    0.9608      8297
        MISC     0.9280    0.9123    0.9201      4593
         ORG     0.9459    0.9399    0.9429     10025
         PER     0.9782    0.9818    0.9800     11128

   micro avg     0.9902    0.9902    0.9902    203621
   macro avg     0.9618    0.9585    0.9602    203621
weighted avg     0.9902    0.9902    0.9902    203621

F1-macro tok:  0.9601527767689111
F1-micro tok:  0.9902465855682862
**************************************************
dev_cost_sum: 85320.36710357666
dev_cost_avg: 26.252420647254358
dev_count_sent: 3250.0
dev_total_correct_sent: 3209.0
dev_accuracy_sent: 0.9873846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50799.0
dev_accuracy_tok: 0.9890385888399984
dev_label=0_precision_sent: 0.9548192771084337
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9686783804430863
dev_label=1_precision_sent: 0.9957463263727765
dev_label=1_recall_sent: 0.9884836852207294
dev_label=1_f-score_sent: 0.9921017145058756
dev_precision_macro_sent: 0.9752828017406051
dev_recall_macro_sent: 0.9857147108274189
dev_f-score_macro_sent: 0.9803900474744809
dev_precision_micro_sent: 0.9873846153846154
dev_recall_micro_sent: 0.9873846153846154
dev_f-score_micro_sent: 0.9873846153846154
dev_label=O_precision_tok: 0.9955901910917193
dev_label=O_recall_tok: 0.9979185668514231
dev_label=O_f-score_tok: 0.9967530192249293
dev_label=LOC_precision_tok: 0.9717211116528522
dev_label=LOC_recall_tok: 0.9517669531996179
dev_label=LOC_f-score_tok: 0.9616405307599518
dev_label=MISC_precision_tok: 0.9067315490673155
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.8940423830467812
dev_label=ORG_precision_tok: 0.9426470588235294
dev_label=ORG_recall_tok: 0.9192160611854685
dev_label=ORG_f-score_tok: 0.930784123910939
dev_label=PER_precision_tok: 0.9735765964139667
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9781921618204803
dev_precision_macro_tok: 0.9580533014098765
dev_recall_macro_tok: 0.9466913500440206
dev_f-score_macro_tok: 0.9522824437526163
dev_precision_micro_tok: 0.9890385888399984
dev_recall_micro_tok: 0.9890385888399984
dev_f-score_micro_tok: 0.9890385888399984
dev_time: 24.62872552871704
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9548    0.9829    0.9687       645
           1     0.9957    0.9885    0.9921      2605

   micro avg     0.9874    0.9874    0.9874      3250
   macro avg     0.9753    0.9857    0.9804      3250
weighted avg     0.9876    0.9874    0.9875      3250

F1-macro sent:  0.9803900474744809
F1-micro sent:  0.9873846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9979    0.9968     42759
         LOC     0.9717    0.9518    0.9616      2094
        MISC     0.9067    0.8817    0.8940      1268
         ORG     0.9426    0.9192    0.9308      2092
         PER     0.9736    0.9829    0.9782      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9581    0.9467    0.9523     51362
weighted avg     0.9889    0.9890    0.9890     51362

F1-macro tok:  0.9522824437526163
F1-micro tok:  0.9890385888399984
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 0.900000
train_cost_sum: 312273.38442993164
train_cost_avg: 22.24010999429753
train_count_sent: 14041.0
train_total_correct_sent: 13829.0
train_accuracy_sent: 0.9849013603019728
train_count_tok: 203621.0
train_total_correct_tok: 201756.0
train_accuracy_tok: 0.9908408268302386
train_label=0_precision_sent: 0.961025641025641
train_label=0_recall_sent: 0.966311447232726
train_label=0_f-score_sent: 0.9636612958519027
train_label=1_precision_sent: 0.9911838790931989
train_label=1_recall_sent: 0.9897592526051024
train_label=1_f-score_sent: 0.9904710535778496
train_precision_macro_sent: 0.9761047600594199
train_recall_macro_sent: 0.9780353499189143
train_f-score_macro_sent: 0.9770661747148761
train_precision_micro_sent: 0.9849013603019728
train_recall_micro_sent: 0.9849013603019728
train_f-score_micro_sent: 0.9849013603019728
train_label=O_precision_tok: 0.9968883702839362
train_label=O_recall_tok: 0.9975232636308955
train_label=O_f-score_tok: 0.9972057159026598
train_label=LOC_precision_tok: 0.9616402116402116
train_label=LOC_recall_tok: 0.9638423526575871
train_label=LOC_f-score_tok: 0.9627400228736531
train_label=MISC_precision_tok: 0.9339246119733925
train_label=MISC_recall_tok: 0.9170476812540823
train_label=MISC_f-score_tok: 0.9254092057563441
train_label=ORG_precision_tok: 0.9507949285570537
train_label=ORG_recall_tok: 0.9425436408977557
train_label=ORG_f-score_tok: 0.946651304914091
train_label=PER_precision_tok: 0.9793214573449109
train_label=PER_recall_tok: 0.9831056793673616
train_label=PER_f-score_tok: 0.981209919727342
train_precision_macro_tok: 0.964513915959901
train_recall_macro_tok: 0.9608125235615365
train_f-score_macro_tok: 0.9626432338348179
train_precision_micro_tok: 0.9908408268302386
train_recall_micro_tok: 0.9908408268302386
train_f-score_micro_tok: 0.9908408268302386
train_time: 242.47689509391785
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9610    0.9663    0.9637      2909
           1     0.9912    0.9898    0.9905     11132

   micro avg     0.9849    0.9849    0.9849     14041
   macro avg     0.9761    0.9780    0.9771     14041
weighted avg     0.9849    0.9849    0.9849     14041

F1-macro sent:  0.9770661747148761
F1-micro sent:  0.9849013603019728
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9975    0.9972    169578
         LOC     0.9616    0.9638    0.9627      8297
        MISC     0.9339    0.9170    0.9254      4593
         ORG     0.9508    0.9425    0.9467     10025
         PER     0.9793    0.9831    0.9812     11128

   micro avg     0.9908    0.9908    0.9908    203621
   macro avg     0.9645    0.9608    0.9626    203621
weighted avg     0.9908    0.9908    0.9908    203621

F1-macro tok:  0.9626432338348179
F1-micro tok:  0.9908408268302386
**************************************************
dev_cost_sum: 85179.71794891357
dev_cost_avg: 26.2091439842811
dev_count_sent: 3250.0
dev_total_correct_sent: 3172.0
dev_accuracy_sent: 0.976
dev_count_tok: 51362.0
dev_total_correct_tok: 50786.0
dev_accuracy_tok: 0.9887854834313305
dev_label=0_precision_sent: 0.8998589562764457
dev_label=0_recall_sent: 0.9891472868217054
dev_label=0_f-score_sent: 0.9423929098966026
dev_label=1_precision_sent: 0.9972451790633609
dev_label=1_recall_sent: 0.9727447216890595
dev_label=1_f-score_sent: 0.9848425961912165
dev_precision_macro_sent: 0.9485520676699033
dev_recall_macro_sent: 0.9809460042553824
dev_f-score_macro_sent: 0.9636177530439096
dev_precision_micro_sent: 0.976
dev_recall_micro_sent: 0.976
dev_f-score_micro_sent: 0.976
dev_label=O_precision_tok: 0.9956350225251511
dev_label=O_recall_tok: 0.9975443766224654
dev_label=O_f-score_tok: 0.996588785046729
dev_label=LOC_precision_tok: 0.9684619116933527
dev_label=LOC_recall_tok: 0.9531996179560649
dev_label=LOC_f-score_tok: 0.9607701564380265
dev_label=MISC_precision_tok: 0.9192751235584844
dev_label=MISC_recall_tok: 0.8801261829652997
dev_label=MISC_f-score_tok: 0.8992747784045124
dev_label=ORG_precision_tok: 0.9359099804305284
dev_label=ORG_recall_tok: 0.9144359464627151
dev_label=ORG_f-score_tok: 0.9250483558994198
dev_label=PER_precision_tok: 0.9703310430980637
dev_label=PER_recall_tok: 0.9866624325182598
dev_label=PER_f-score_tok: 0.9784285939222171
dev_precision_macro_tok: 0.9579226162611161
dev_recall_macro_tok: 0.946393711304961
dev_f-score_macro_tok: 0.952022133942181
dev_precision_micro_tok: 0.9887854834313305
dev_recall_micro_tok: 0.9887854834313305
dev_f-score_micro_tok: 0.9887854834313305
dev_time: 24.612885236740112
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8999    0.9891    0.9424       645
           1     0.9972    0.9727    0.9848      2605

   micro avg     0.9760    0.9760    0.9760      3250
   macro avg     0.9486    0.9809    0.9636      3250
weighted avg     0.9779    0.9760    0.9764      3250

F1-macro sent:  0.9636177530439096
F1-micro sent:  0.976
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9975    0.9966     42759
         LOC     0.9685    0.9532    0.9608      2094
        MISC     0.9193    0.8801    0.8993      1268
         ORG     0.9359    0.9144    0.9250      2092
         PER     0.9703    0.9867    0.9784      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9579    0.9464    0.9520     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.952022133942181
F1-micro tok:  0.9887854834313305
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 0.900000
train_cost_sum: 310795.457611084
train_cost_avg: 22.134852048364362
train_count_sent: 14041.0
train_total_correct_sent: 13808.0
train_accuracy_sent: 0.9834057403318852
train_count_tok: 203621.0
train_total_correct_tok: 201745.0
train_accuracy_tok: 0.9907868048973337
train_label=0_precision_sent: 0.9572795625427204
train_label=0_recall_sent: 0.962873839807494
train_label=0_f-score_sent: 0.9600685518423308
train_label=1_precision_sent: 0.9902834008097166
train_label=1_recall_sent: 0.9887711103126123
train_label=1_f-score_sent: 0.9895266777543039
train_precision_macro_sent: 0.9737814816762185
train_recall_macro_sent: 0.9758224750600532
train_f-score_macro_sent: 0.9747976147983173
train_precision_micro_sent: 0.9834057403318852
train_recall_micro_sent: 0.9834057403318852
train_f-score_micro_sent: 0.9834057403318852
train_label=O_precision_tok: 0.997099193434272
train_label=O_recall_tok: 0.997275589993985
train_label=O_f-score_tok: 0.9971873839132511
train_label=LOC_precision_tok: 0.963798720888138
train_label=LOC_recall_tok: 0.9626370977461733
train_label=LOC_f-score_tok: 0.9632175590931018
train_label=MISC_precision_tok: 0.9346390845070423
train_label=MISC_recall_tok: 0.9246679730023949
train_label=MISC_f-score_tok: 0.92962679216373
train_label=ORG_precision_tok: 0.9441446842525979
train_label=ORG_recall_tok: 0.9425436408977557
train_label=ORG_f-score_tok: 0.9433434832526332
train_label=PER_precision_tok: 0.9795954895292643
train_label=PER_recall_tok: 0.9836448598130841
train_label=PER_f-score_tok: 0.9816159985651511
train_precision_macro_tok: 0.9638554345222629
train_recall_macro_tok: 0.9621538322906785
train_f-score_macro_tok: 0.9629982433975733
train_precision_micro_tok: 0.9907868048973337
train_recall_micro_tok: 0.9907868048973337
train_f-score_micro_tok: 0.9907868048973337
train_time: 240.83194065093994
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9573    0.9629    0.9601      2909
           1     0.9903    0.9888    0.9895     11132

   micro avg     0.9834    0.9834    0.9834     14041
   macro avg     0.9738    0.9758    0.9748     14041
weighted avg     0.9834    0.9834    0.9834     14041

F1-macro sent:  0.9747976147983173
F1-micro sent:  0.9834057403318852
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9973    0.9972    169578
         LOC     0.9638    0.9626    0.9632      8297
        MISC     0.9346    0.9247    0.9296      4593
         ORG     0.9441    0.9425    0.9433     10025
         PER     0.9796    0.9836    0.9816     11128

   micro avg     0.9908    0.9908    0.9908    203621
   macro avg     0.9639    0.9622    0.9630    203621
weighted avg     0.9908    0.9908    0.9908    203621

F1-macro tok:  0.9629982433975733
F1-micro tok:  0.9907868048973337
**************************************************
dev_cost_sum: 84791.89951324463
dev_cost_avg: 26.0898152348445
dev_count_sent: 3250.0
dev_total_correct_sent: 3200.0
dev_accuracy_sent: 0.9846153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50792.0
dev_accuracy_tok: 0.9889023013122542
dev_label=0_precision_sent: 0.956989247311828
dev_label=0_recall_sent: 0.9658914728682171
dev_label=0_f-score_sent: 0.9614197530864198
dev_label=1_precision_sent: 0.9915352058484033
dev_label=1_recall_sent: 0.9892514395393474
dev_label=1_f-score_sent: 0.990392006149116
dev_precision_macro_sent: 0.9742622265801156
dev_recall_macro_sent: 0.9775714562037823
dev_f-score_macro_sent: 0.975905879617768
dev_precision_micro_sent: 0.9846153846153847
dev_recall_micro_sent: 0.9846153846153847
dev_f-score_micro_sent: 0.9846153846153847
dev_label=O_precision_tok: 0.9968435081484253
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9969600598634366
dev_label=LOC_precision_tok: 0.9702873843156357
dev_label=LOC_recall_tok: 0.9512893982808023
dev_label=LOC_f-score_tok: 0.9606944779358573
dev_label=MISC_precision_tok: 0.921552436003303
dev_label=MISC_recall_tok: 0.8801261829652997
dev_label=MISC_f-score_tok: 0.9003630496167809
dev_label=ORG_precision_tok: 0.9071164510166358
dev_label=ORG_recall_tok: 0.9383365200764818
dev_label=ORG_f-score_tok: 0.9224624060150375
dev_label=PER_precision_tok: 0.9753554502369668
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9778270509977827
dev_precision_macro_tok: 0.9542310459441932
dev_recall_macro_tok: 0.9494279900133519
dev_f-score_macro_tok: 0.9516614088857789
dev_precision_micro_tok: 0.9889023013122542
dev_recall_micro_tok: 0.9889023013122542
dev_f-score_micro_tok: 0.9889023013122542
dev_time: 24.6027512550354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9570    0.9659    0.9614       645
           1     0.9915    0.9893    0.9904      2605

   micro avg     0.9846    0.9846    0.9846      3250
   macro avg     0.9743    0.9776    0.9759      3250
weighted avg     0.9847    0.9846    0.9846      3250

F1-macro sent:  0.975905879617768
F1-micro sent:  0.9846153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9971    0.9970     42759
         LOC     0.9703    0.9513    0.9607      2094
        MISC     0.9216    0.8801    0.9004      1268
         ORG     0.9071    0.9383    0.9225      2092
         PER     0.9754    0.9803    0.9778      3149

   micro avg     0.9889    0.9889    0.9889     51362
   macro avg     0.9542    0.9494    0.9517     51362
weighted avg     0.9889    0.9889    0.9889     51362

F1-macro tok:  0.9516614088857789
F1-micro tok:  0.9889023013122542
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.810000
train_cost_sum: 309136.89654541016
train_cost_avg: 22.016729331629524
train_count_sent: 14041.0
train_total_correct_sent: 13850.0
train_accuracy_sent: 0.9863969802720604
train_count_tok: 203621.0
train_total_correct_tok: 201861.0
train_accuracy_tok: 0.9913564907352385
train_label=0_precision_sent: 0.9663692518874399
train_label=0_recall_sent: 0.968030250945342
train_label=0_f-score_sent: 0.9671990382964106
train_label=1_precision_sent: 0.9916419520086277
train_label=1_recall_sent: 0.991196550485088
train_label=1_f-score_sent: 0.9914192012219777
train_precision_macro_sent: 0.9790056019480338
train_recall_macro_sent: 0.9796134007152151
train_f-score_macro_sent: 0.9793091197591941
train_precision_micro_sent: 0.9863969802720604
train_recall_micro_sent: 0.9863969802720604
train_f-score_micro_sent: 0.9863969802720604
train_label=O_precision_tok: 0.9971823679898141
train_label=O_recall_tok: 0.9975822335444456
train_label=O_f-score_tok: 0.9973822606891022
train_label=LOC_precision_tok: 0.9644278307005909
train_label=LOC_recall_tok: 0.9639628781487285
train_label=LOC_f-score_tok: 0.9641952983725135
train_label=MISC_precision_tok: 0.9388115749944775
train_label=MISC_recall_tok: 0.925321140866536
train_label=MISC_f-score_tok: 0.932017543859649
train_label=ORG_precision_tok: 0.9512512512512512
train_label=ORG_recall_tok: 0.9479301745635911
train_label=ORG_f-score_tok: 0.9495878091431427
train_label=PER_precision_tok: 0.9800268696820421
train_label=PER_recall_tok: 0.9832854061826024
train_label=PER_f-score_tok: 0.9816534338133046
train_precision_macro_tok: 0.9663399789236353
train_recall_macro_tok: 0.9636163666611808
train_f-score_macro_tok: 0.9649672691755425
train_precision_micro_tok: 0.9913564907352385
train_recall_micro_tok: 0.9913564907352385
train_f-score_micro_tok: 0.9913564907352385
train_time: 242.15587663650513
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9664    0.9680    0.9672      2909
           1     0.9916    0.9912    0.9914     11132

   micro avg     0.9864    0.9864    0.9864     14041
   macro avg     0.9790    0.9796    0.9793     14041
weighted avg     0.9864    0.9864    0.9864     14041

F1-macro sent:  0.9793091197591941
F1-micro sent:  0.9863969802720604
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9976    0.9974    169578
         LOC     0.9644    0.9640    0.9642      8297
        MISC     0.9388    0.9253    0.9320      4593
         ORG     0.9513    0.9479    0.9496     10025
         PER     0.9800    0.9833    0.9817     11128

   micro avg     0.9914    0.9914    0.9914    203621
   macro avg     0.9663    0.9636    0.9650    203621
weighted avg     0.9913    0.9914    0.9913    203621

F1-macro tok:  0.9649672691755425
F1-micro tok:  0.9913564907352385
**************************************************
dev_cost_sum: 84644.5736694336
dev_cost_avg: 26.04448420597957
dev_count_sent: 3250.0
dev_total_correct_sent: 3196.0
dev_accuracy_sent: 0.9833846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50800.0
dev_accuracy_tok: 0.989058058486819
dev_label=0_precision_sent: 0.93519882179676
dev_label=0_recall_sent: 0.9844961240310077
dev_label=0_f-score_sent: 0.959214501510574
dev_label=1_precision_sent: 0.9961104628549202
dev_label=1_recall_sent: 0.9831094049904031
dev_label=1_f-score_sent: 0.9895672333848532
dev_precision_macro_sent: 0.9656546423258401
dev_recall_macro_sent: 0.9838027645107055
dev_f-score_macro_sent: 0.9743908674477135
dev_precision_micro_sent: 0.9833846153846154
dev_recall_micro_sent: 0.9833846153846154
dev_f-score_micro_sent: 0.9833846153846154
dev_label=O_precision_tok: 0.9960077510330819
dev_label=O_recall_tok: 0.9977314717369443
dev_label=O_f-score_tok: 0.9968688662491823
dev_label=LOC_precision_tok: 0.945479962721342
dev_label=LOC_recall_tok: 0.9689589302769819
dev_label=LOC_f-score_tok: 0.9570754716981134
dev_label=MISC_precision_tok: 0.9351535836177475
dev_label=MISC_recall_tok: 0.8643533123028391
dev_label=MISC_f-score_tok: 0.8983606557377048
dev_label=ORG_precision_tok: 0.9488833746898263
dev_label=ORG_recall_tok: 0.9139579349904398
dev_label=ORG_f-score_tok: 0.9310932554175797
dev_label=PER_precision_tok: 0.9702753441802253
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9774625689519307
dev_precision_macro_tok: 0.9591600032484446
dev_recall_macro_tok: 0.9459517430084718
dev_f-score_macro_tok: 0.9521721636109021
dev_precision_micro_tok: 0.989058058486819
dev_recall_micro_tok: 0.989058058486819
dev_f-score_micro_tok: 0.989058058486819
dev_time: 24.477020263671875
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9352    0.9845    0.9592       645
           1     0.9961    0.9831    0.9896      2605

   micro avg     0.9834    0.9834    0.9834      3250
   macro avg     0.9657    0.9838    0.9744      3250
weighted avg     0.9840    0.9834    0.9835      3250

F1-macro sent:  0.9743908674477135
F1-micro sent:  0.9833846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9977    0.9969     42759
         LOC     0.9455    0.9690    0.9571      2094
        MISC     0.9352    0.8644    0.8984      1268
         ORG     0.9489    0.9140    0.9311      2092
         PER     0.9703    0.9848    0.9775      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9592    0.9460    0.9522     51362
weighted avg     0.9889    0.9891    0.9889     51362

F1-macro tok:  0.9521721636109021
F1-micro tok:  0.989058058486819
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.729000
train_cost_sum: 307597.71031188965
train_cost_avg: 21.907108490270613
train_count_sent: 14041.0
train_total_correct_sent: 13854.0
train_accuracy_sent: 0.9866818602663628
train_count_tok: 203621.0
train_total_correct_tok: 201939.0
train_accuracy_tok: 0.9917395553503814
train_label=0_precision_sent: 0.9696342305037957
train_label=0_recall_sent: 0.9659676864902028
train_label=0_f-score_sent: 0.9677974857930084
train_label=1_precision_sent: 0.9911154985192497
train_label=1_recall_sent: 0.9920948616600791
train_label=1_f-score_sent: 0.991604938271605
train_precision_macro_sent: 0.9803748645115227
train_recall_macro_sent: 0.979031274075141
train_f-score_macro_sent: 0.9797012120323068
train_precision_micro_sent: 0.9866818602663628
train_recall_micro_sent: 0.9866818602663628
train_f-score_micro_sent: 0.9866818602663628
train_label=O_precision_tok: 0.9971177989178485
train_label=O_recall_tok: 0.9976117185012207
train_label=O_f-score_tok: 0.9973646975592502
train_label=LOC_precision_tok: 0.9651274651274652
train_label=LOC_recall_tok: 0.967337591900687
train_label=LOC_f-score_tok: 0.9662312646722447
train_label=MISC_precision_tok: 0.9405764966740576
train_label=MISC_recall_tok: 0.9235793598954931
train_label=MISC_f-score_tok: 0.9320004394155773
train_label=ORG_precision_tok: 0.9567312518823411
train_label=ORG_recall_tok: 0.9506234413965087
train_label=ORG_f-score_tok: 0.9536675672971079
train_label=PER_precision_tok: 0.9817400644468314
train_label=PER_recall_tok: 0.9856218547807333
train_label=PER_f-score_tok: 0.983677130044843
train_precision_macro_tok: 0.9682586154097088
train_recall_macro_tok: 0.9649547932949286
train_f-score_macro_tok: 0.9665882197978046
train_precision_micro_tok: 0.9917395553503814
train_recall_micro_tok: 0.9917395553503814
train_f-score_micro_tok: 0.9917395553503814
train_time: 240.0480568408966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9696    0.9660    0.9678      2909
           1     0.9911    0.9921    0.9916     11132

   micro avg     0.9867    0.9867    0.9867     14041
   macro avg     0.9804    0.9790    0.9797     14041
weighted avg     0.9867    0.9867    0.9867     14041

F1-macro sent:  0.9797012120323068
F1-micro sent:  0.9866818602663628
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9976    0.9974    169578
         LOC     0.9651    0.9673    0.9662      8297
        MISC     0.9406    0.9236    0.9320      4593
         ORG     0.9567    0.9506    0.9537     10025
         PER     0.9817    0.9856    0.9837     11128

   micro avg     0.9917    0.9917    0.9917    203621
   macro avg     0.9683    0.9650    0.9666    203621
weighted avg     0.9917    0.9917    0.9917    203621

F1-macro tok:  0.9665882197978046
F1-micro tok:  0.9917395553503814
**************************************************
dev_cost_sum: 84378.07976150513
dev_cost_avg: 25.962486080463115
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50816.0
dev_accuracy_tok: 0.9893695728359487
dev_label=0_precision_sent: 0.9842767295597484
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9773614363778299
dev_label=1_precision_sent: 0.9927314460596787
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9944433799578463
dev_precision_macro_sent: 0.9885040878097135
dev_recall_macro_sent: 0.9833519320329123
dev_f-score_macro_sent: 0.985902408167838
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9955441502391228
dev_label=O_recall_tok: 0.9980121144086626
dev_label=O_f-score_tok: 0.9967766046902738
dev_label=LOC_precision_tok: 0.9604007633587787
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9608591885441528
dev_label=MISC_precision_tok: 0.9429559204840103
dev_label=MISC_recall_tok: 0.860410094637224
dev_label=MISC_f-score_tok: 0.8997938144329896
dev_label=ORG_precision_tok: 0.9323809523809524
dev_label=ORG_recall_tok: 0.9359464627151052
dev_label=ORG_f-score_tok: 0.9341603053435115
dev_label=PER_precision_tok: 0.9796437659033079
dev_label=PER_recall_tok: 0.9780882819942839
dev_label=PER_f-score_tok: 0.9788654060066742
dev_precision_macro_tok: 0.9621851104732345
dev_recall_macro_tok: 0.9467550010662414
dev_f-score_macro_tok: 0.9540910638035204
dev_precision_micro_tok: 0.9893695728359487
dev_recall_micro_tok: 0.9893695728359487
dev_f-score_micro_tok: 0.9893695728359487
dev_time: 24.580830097198486
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9843    0.9705    0.9774       645
           1     0.9927    0.9962    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9885    0.9834    0.9859      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.985902408167838
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9980    0.9968     42759
         LOC     0.9604    0.9613    0.9609      2094
        MISC     0.9430    0.8604    0.8998      1268
         ORG     0.9324    0.9359    0.9342      2092
         PER     0.9796    0.9781    0.9789      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9622    0.9468    0.9541     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9540910638035204
F1-micro tok:  0.9893695728359487
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 306116.2392272949
train_cost_avg: 21.80159812173598
train_count_sent: 14041.0
train_total_correct_sent: 13859.0
train_accuracy_sent: 0.9870379602592408
train_count_tok: 203621.0
train_total_correct_tok: 202121.0
train_accuracy_tok: 0.9926333727857146
train_label=0_precision_sent: 0.9690402476780186
train_label=0_recall_sent: 0.9683740116878653
train_label=0_f-score_sent: 0.968707015130674
train_label=1_precision_sent: 0.9917370217352255
train_label=1_recall_sent: 0.9919151994250809
train_label=1_f-score_sent: 0.9918261025779216
train_precision_macro_sent: 0.980388634706622
train_recall_macro_sent: 0.9801446055564731
train_f-score_macro_sent: 0.9802665588542978
train_precision_micro_sent: 0.9870379602592408
train_recall_micro_sent: 0.9870379602592408
train_f-score_micro_sent: 0.9870379602592408
train_label=O_precision_tok: 0.9975655331364539
train_label=O_recall_tok: 0.9979714349738763
train_label=O_f-score_tok: 0.9977684427739701
train_label=LOC_precision_tok: 0.9712595097210481
train_label=LOC_recall_tok: 0.9693865252500904
train_label=LOC_f-score_tok: 0.9703221136445892
train_label=MISC_precision_tok: 0.9465665709869728
train_label=MISC_recall_tok: 0.9333768778576094
train_label=MISC_f-score_tok: 0.9399254549440912
train_label=ORG_precision_tok: 0.9568682139655345
train_label=ORG_recall_tok: 0.9582044887780549
train_label=ORG_f-score_tok: 0.9575358851674641
train_label=PER_precision_tok: 0.9843595505617978
train_label=PER_recall_tok: 0.9840941768511862
train_label=PER_f-score_tok: 0.9842268458185415
train_precision_macro_tok: 0.9713238756743614
train_recall_macro_tok: 0.9686067007421635
train_f-score_macro_tok: 0.9699557484697312
train_precision_micro_tok: 0.9926333727857146
train_recall_micro_tok: 0.9926333727857146
train_f-score_micro_tok: 0.9926333727857146
train_time: 240.84961700439453
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9690    0.9684    0.9687      2909
           1     0.9917    0.9919    0.9918     11132

   micro avg     0.9870    0.9870    0.9870     14041
   macro avg     0.9804    0.9801    0.9803     14041
weighted avg     0.9870    0.9870    0.9870     14041

F1-macro sent:  0.9802665588542978
F1-micro sent:  0.9870379602592408
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9980    0.9978    169578
         LOC     0.9713    0.9694    0.9703      8297
        MISC     0.9466    0.9334    0.9399      4593
         ORG     0.9569    0.9582    0.9575     10025
         PER     0.9844    0.9841    0.9842     11128

   micro avg     0.9926    0.9926    0.9926    203621
   macro avg     0.9713    0.9686    0.9700    203621
weighted avg     0.9926    0.9926    0.9926    203621

F1-macro tok:  0.9699557484697312
F1-micro tok:  0.9926333727857146
**************************************************
dev_cost_sum: 84219.64111709595
dev_cost_avg: 25.913735728337215
dev_count_sent: 3250.0
dev_total_correct_sent: 3214.0
dev_accuracy_sent: 0.9889230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50793.0
dev_accuracy_tok: 0.9889217709590749
dev_label=0_precision_sent: 0.9606656580937972
dev_label=0_recall_sent: 0.9844961240310077
dev_label=0_f-score_sent: 0.9724349157733537
dev_label=1_precision_sent: 0.9961375048281189
dev_label=1_recall_sent: 0.9900191938579654
dev_label=1_f-score_sent: 0.9930689256834808
dev_precision_macro_sent: 0.9784015814609581
dev_recall_macro_sent: 0.9872576589444866
dev_f-score_macro_sent: 0.9827519207284172
dev_precision_micro_sent: 0.9889230769230769
dev_recall_micro_sent: 0.9889230769230769
dev_f-score_micro_sent: 0.9889230769230769
dev_label=O_precision_tok: 0.9962406015037594
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9970205059297774
dev_label=LOC_precision_tok: 0.9546528105810108
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9598670149608168
dev_label=MISC_precision_tok: 0.9035087719298246
dev_label=MISC_recall_tok: 0.8935331230283912
dev_label=MISC_f-score_tok: 0.8984932593180016
dev_label=ORG_precision_tok: 0.957840616966581
dev_label=ORG_recall_tok: 0.8905353728489483
dev_label=ORG_f-score_tok: 0.9229625959871192
dev_label=PER_precision_tok: 0.9661490683229814
dev_label=PER_recall_tok: 0.9879326770403303
dev_label=PER_f-score_tok: 0.9769194536033915
dev_precision_macro_tok: 0.9556783738608313
dev_recall_macro_tok: 0.9469882592497999
dev_f-score_macro_tok: 0.9510525659598213
dev_precision_micro_tok: 0.9889217709590749
dev_recall_micro_tok: 0.9889217709590749
dev_f-score_micro_tok: 0.9889217709590749
dev_time: 24.327062845230103
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9607    0.9845    0.9724       645
           1     0.9961    0.9900    0.9931      2605

   micro avg     0.9889    0.9889    0.9889      3250
   macro avg     0.9784    0.9873    0.9828      3250
weighted avg     0.9891    0.9889    0.9890      3250

F1-macro sent:  0.9827519207284172
F1-micro sent:  0.9889230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9978    0.9970     42759
         LOC     0.9547    0.9651    0.9599      2094
        MISC     0.9035    0.8935    0.8985      1268
         ORG     0.9578    0.8905    0.9230      2092
         PER     0.9661    0.9879    0.9769      3149

   micro avg     0.9889    0.9889    0.9889     51362
   macro avg     0.9557    0.9470    0.9511     51362
weighted avg     0.9888    0.9889    0.9888     51362

F1-macro tok:  0.9510525659598213
F1-micro tok:  0.9889217709590749
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 0.729000
train_cost_sum: 305252.5690307617
train_cost_avg: 21.7400875315691
train_count_sent: 14041.0
train_total_correct_sent: 13883.0
train_accuracy_sent: 0.9887472402250552
train_count_tok: 203621.0
train_total_correct_tok: 202126.0
train_accuracy_tok: 0.9926579282097623
train_label=0_precision_sent: 0.9725180350395053
train_label=0_recall_sent: 0.97318666208319
train_label=0_f-score_sent: 0.972852233676976
train_label=1_precision_sent: 0.9929919137466308
train_label=1_recall_sent: 0.9928135106000718
train_label=1_f-score_sent: 0.9929027041595543
train_precision_macro_sent: 0.982754974393068
train_recall_macro_sent: 0.9830000863416309
train_f-score_macro_sent: 0.9828774689182651
train_precision_micro_sent: 0.9887472402250552
train_recall_micro_sent: 0.9887472402250552
train_f-score_micro_sent: 0.9887472402250552
train_label=O_precision_tok: 0.9976595569075496
train_label=O_recall_tok: 0.9979419500171013
train_label=O_f-score_tok: 0.9978007334819166
train_label=LOC_precision_tok: 0.9705953533397871
train_label=LOC_recall_tok: 0.9667349644449801
train_label=LOC_f-score_tok: 0.9686613127226616
train_label=MISC_precision_tok: 0.9471954425942156
train_label=MISC_recall_tok: 0.9412148922273024
train_label=MISC_f-score_tok: 0.9441956972807688
train_label=ORG_precision_tok: 0.9581
train_label=ORG_recall_tok: 0.95571072319202
train_label=ORG_f-score_tok: 0.9569038701622972
train_label=PER_precision_tok: 0.9825378346915018
train_label=PER_recall_tok: 0.985981308411215
train_label=PER_f-score_tok: 0.9842565597667638
train_precision_macro_tok: 0.9712176375066107
train_recall_macro_tok: 0.9695167676585237
train_f-score_macro_tok: 0.9703636346828816
train_precision_micro_tok: 0.9926579282097623
train_recall_micro_tok: 0.9926579282097623
train_f-score_micro_tok: 0.9926579282097623
train_time: 243.68234133720398
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9725    0.9732    0.9729      2909
           1     0.9930    0.9928    0.9929     11132

   micro avg     0.9887    0.9887    0.9887     14041
   macro avg     0.9828    0.9830    0.9829     14041
weighted avg     0.9888    0.9887    0.9887     14041

F1-macro sent:  0.9828774689182651
F1-micro sent:  0.9887472402250552
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9977    0.9979    0.9978    169578
         LOC     0.9706    0.9667    0.9687      8297
        MISC     0.9472    0.9412    0.9442      4593
         ORG     0.9581    0.9557    0.9569     10025
         PER     0.9825    0.9860    0.9843     11128

   micro avg     0.9927    0.9927    0.9927    203621
   macro avg     0.9712    0.9695    0.9704    203621
weighted avg     0.9926    0.9927    0.9927    203621

F1-macro tok:  0.9703636346828816
F1-micro tok:  0.9926579282097623
**************************************************
dev_cost_sum: 83926.31824111938
dev_cost_avg: 25.823482535729042
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50819.0
dev_accuracy_tok: 0.9894279817764106
dev_label=0_precision_sent: 0.9576399394856279
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9693721286370597
dev_label=1_precision_sent: 0.9953650057937428
dev_label=1_recall_sent: 0.9892514395393474
dev_label=1_f-score_sent: 0.9922988063149788
dev_precision_macro_sent: 0.9765024726396854
dev_recall_macro_sent: 0.9853233941882783
dev_f-score_macro_sent: 0.9808354674760192
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.9962638645650905
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9970321555430922
dev_label=LOC_precision_tok: 0.9564393939393939
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9605325725154541
dev_label=MISC_precision_tok: 0.9220563847429519
dev_label=MISC_recall_tok: 0.8769716088328076
dev_label=MISC_f-score_tok: 0.898949070331447
dev_label=ORG_precision_tok: 0.9446891825746452
dev_label=ORG_recall_tok: 0.9225621414913958
dev_label=ORG_f-score_tok: 0.9334945586457074
dev_label=PER_precision_tok: 0.9735516372795969
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.977707509881423
dev_precision_macro_tok: 0.9586000926203357
dev_recall_macro_tok: 0.9487790668594427
dev_f-score_macro_tok: 0.9535431733834248
dev_precision_micro_tok: 0.9894279817764106
dev_recall_micro_tok: 0.9894279817764106
dev_f-score_micro_tok: 0.9894279817764106
dev_time: 24.397029638290405
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9576    0.9814    0.9694       645
           1     0.9954    0.9893    0.9923      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9765    0.9853    0.9808      3250
weighted avg     0.9879    0.9877    0.9877      3250

F1-macro sent:  0.9808354674760192
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9970     42759
         LOC     0.9564    0.9647    0.9605      2094
        MISC     0.9221    0.8770    0.8989      1268
         ORG     0.9447    0.9226    0.9335      2092
         PER     0.9736    0.9819    0.9777      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9586    0.9488    0.9535     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9535431733834248
F1-micro tok:  0.9894279817764106
**************************************************
Best epoch: 20
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 304253.49395751953
train_cost_avg: 21.668933406275872
train_count_sent: 14041.0
train_total_correct_sent: 13887.0
train_accuracy_sent: 0.9890321202193576
train_count_tok: 203621.0
train_total_correct_tok: 202170.0
train_accuracy_tok: 0.9928740159413812
train_label=0_precision_sent: 0.9732050841635177
train_label=0_recall_sent: 0.9738741835682365
train_label=0_f-score_sent: 0.9735395189003437
train_label=1_precision_sent: 0.9931716082659479
train_label=1_recall_sent: 0.99299317283507
train_label=1_f-score_sent: 0.9930823825352618
train_precision_macro_sent: 0.9831883462147328
train_recall_macro_sent: 0.9834336782016533
train_f-score_macro_sent: 0.9833109507178028
train_precision_micro_sent: 0.9890321202193576
train_recall_micro_sent: 0.9890321202193576
train_f-score_micro_sent: 0.9890321202193576
train_label=O_precision_tok: 0.9975772366350116
train_label=O_recall_tok: 0.9979478470084563
train_label=O_f-score_tok: 0.9977625074067196
train_label=LOC_precision_tok: 0.9711874623267028
train_label=LOC_recall_tok: 0.9709533566349283
train_label=LOC_f-score_tok: 0.9710703953712633
train_label=MISC_precision_tok: 0.9494949494949495
train_label=MISC_recall_tok: 0.9414326148486828
train_label=MISC_f-score_tok: 0.9454465945118617
train_label=ORG_precision_tok: 0.9598276898417151
train_label=ORG_recall_tok: 0.95571072319202
train_label=ORG_f-score_tok: 0.9577647823261859
train_label=PER_precision_tok: 0.9847519956946812
train_label=PER_recall_tok: 0.9866103522645578
train_label=PER_f-score_tok: 0.9856802980652691
train_precision_macro_tok: 0.972567866798612
train_recall_macro_tok: 0.970530978789729
train_f-score_macro_tok: 0.9715449155362599
train_precision_micro_tok: 0.9928740159413812
train_recall_micro_tok: 0.9928740159413812
train_f-score_micro_tok: 0.9928740159413812
train_time: 242.49490332603455
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9732    0.9739    0.9735      2909
           1     0.9932    0.9930    0.9931     11132

   micro avg     0.9890    0.9890    0.9890     14041
   macro avg     0.9832    0.9834    0.9833     14041
weighted avg     0.9890    0.9890    0.9890     14041

F1-macro sent:  0.9833109507178028
F1-micro sent:  0.9890321202193576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9979    0.9978    169578
         LOC     0.9712    0.9710    0.9711      8297
        MISC     0.9495    0.9414    0.9454      4593
         ORG     0.9598    0.9557    0.9578     10025
         PER     0.9848    0.9866    0.9857     11128

   micro avg     0.9929    0.9929    0.9929    203621
   macro avg     0.9726    0.9705    0.9715    203621
weighted avg     0.9929    0.9929    0.9929    203621

F1-macro tok:  0.9715449155362599
F1-micro tok:  0.9928740159413812
**************************************************
dev_cost_sum: 83777.36026382446
dev_cost_avg: 25.77764931194599
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50831.0
dev_accuracy_tok: 0.9896616175382579
dev_label=0_precision_sent: 0.9903691813804173
dev_label=0_recall_sent: 0.9565891472868217
dev_label=0_f-score_sent: 0.973186119873817
dev_label=1_precision_sent: 0.9893414541301865
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.9935015290519876
dev_precision_macro_sent: 0.9898553177553019
dev_recall_macro_sent: 0.9771429421654838
dev_f-score_macro_sent: 0.9833438244629022
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9971001613619888
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9971234798877456
dev_label=LOC_precision_tok: 0.9609895337773549
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9628217349857006
dev_label=MISC_precision_tok: 0.9130434782608695
dev_label=MISC_recall_tok: 0.8943217665615142
dev_label=MISC_f-score_tok: 0.903585657370518
dev_label=ORG_precision_tok: 0.9381044487427466
dev_label=ORG_recall_tok: 0.9273422562141491
dev_label=ORG_f-score_tok: 0.9326923076923077
dev_label=PER_precision_tok: 0.9720915647538413
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9782265698958662
dev_precision_macro_tok: 0.9562658373793603
dev_recall_macro_tok: 0.9535822525784277
dev_f-score_macro_tok: 0.9548899499664275
dev_precision_micro_tok: 0.9896616175382579
dev_recall_micro_tok: 0.9896616175382579
dev_f-score_micro_tok: 0.9896616175382579
dev_time: 24.85032296180725
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9904    0.9566    0.9732       645
           1     0.9893    0.9977    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9899    0.9771    0.9833      3250
weighted avg     0.9895    0.9895    0.9895      3250

F1-macro sent:  0.9833438244629022
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9971    0.9971     42759
         LOC     0.9610    0.9647    0.9628      2094
        MISC     0.9130    0.8943    0.9036      1268
         ORG     0.9381    0.9273    0.9327      2092
         PER     0.9721    0.9844    0.9782      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9563    0.9536    0.9549     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.9548899499664275
F1-micro tok:  0.9896616175382579
**************************************************
Best epoch: 20
**************************************************

EPOCH: 24
Learning rate: 0.729000
train_cost_sum: 303070.7230834961
train_cost_avg: 21.584696466312664
train_count_sent: 14041.0
train_total_correct_sent: 13919.0
train_accuracy_sent: 0.9913111601737769
train_count_tok: 203621.0
train_total_correct_tok: 202217.0
train_accuracy_tok: 0.9931048369274289
train_label=0_precision_sent: 0.9787014771556166
train_label=0_recall_sent: 0.9793743554486077
train_label=0_f-score_sent: 0.9790378006872852
train_label=1_precision_sent: 0.9946091644204852
train_label=1_recall_sent: 0.9944304707150557
train_label=1_f-score_sent: 0.9945198095409218
train_precision_macro_sent: 0.9866553207880508
train_recall_macro_sent: 0.9869024130818318
train_f-score_macro_sent: 0.9867788051141035
train_precision_micro_sent: 0.9913111601737769
train_recall_micro_sent: 0.9913111601737769
train_f-score_micro_sent: 0.9913111601737769
train_label=O_precision_tok: 0.9975597536176358
train_label=O_recall_tok: 0.9980127139133614
train_label=O_f-score_tok: 0.9977861823584381
train_label=LOC_precision_tok: 0.9734588008203643
train_label=LOC_recall_tok: 0.9725201880197661
train_label=LOC_f-score_tok: 0.9729892680573977
train_label=MISC_precision_tok: 0.9555408095554081
train_label=MISC_recall_tok: 0.9405617243631613
train_label=MISC_f-score_tok: 0.9479921000658328
train_label=ORG_precision_tok: 0.961515393842463
train_label=ORG_recall_tok: 0.959501246882793
train_label=ORG_f-score_tok: 0.9605072644665235
train_label=PER_precision_tok: 0.9835007173601148
train_label=PER_recall_tok: 0.9856218547807333
train_label=PER_f-score_tok: 0.984560143626571
train_precision_macro_tok: 0.9743150950391971
train_recall_macro_tok: 0.971243545591963
train_f-score_macro_tok: 0.9727669917149526
train_precision_micro_tok: 0.9931048369274289
train_recall_micro_tok: 0.9931048369274289
train_f-score_micro_tok: 0.9931048369274289
train_time: 242.0669825077057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9787    0.9794    0.9790      2909
           1     0.9946    0.9944    0.9945     11132

   micro avg     0.9913    0.9913    0.9913     14041
   macro avg     0.9867    0.9869    0.9868     14041
weighted avg     0.9913    0.9913    0.9913     14041

F1-macro sent:  0.9867788051141035
F1-micro sent:  0.9913111601737769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9980    0.9978    169578
         LOC     0.9735    0.9725    0.9730      8297
        MISC     0.9555    0.9406    0.9480      4593
         ORG     0.9615    0.9595    0.9605     10025
         PER     0.9835    0.9856    0.9846     11128

   micro avg     0.9931    0.9931    0.9931    203621
   macro avg     0.9743    0.9712    0.9728    203621
weighted avg     0.9931    0.9931    0.9931    203621

F1-macro tok:  0.9727669917149526
F1-micro tok:  0.9931048369274289
**************************************************
dev_cost_sum: 83526.44354248047
dev_cost_avg: 25.700444166917066
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50831.0
dev_accuracy_tok: 0.9896616175382579
dev_label=0_precision_sent: 0.9904153354632588
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.9756097560975608
dev_label=1_precision_sent: 0.9904725609756098
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.9940715241920061
dev_precision_macro_sent: 0.9904439482194343
dev_recall_macro_sent: 0.9794685235608327
dev_f-score_macro_sent: 0.9848406401447835
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9972399597689051
dev_label=O_recall_tok: 0.9971000257255782
dev_label=O_f-score_tok: 0.9971699878379643
dev_label=LOC_precision_tok: 0.9578598484848485
dev_label=LOC_recall_tok: 0.9660936007640879
dev_label=LOC_f-score_tok: 0.961959106038992
dev_label=MISC_precision_tok: 0.9228876127973749
dev_label=MISC_recall_tok: 0.887223974763407
dev_label=MISC_f-score_tok: 0.9047044632086853
dev_label=ORG_precision_tok: 0.9300333174678724
dev_label=ORG_recall_tok: 0.9340344168260039
dev_label=ORG_f-score_tok: 0.9320295730980206
dev_label=PER_precision_tok: 0.9738747245829399
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9781852671514385
dev_precision_macro_tok: 0.9563790926203881
dev_recall_macro_tok: 0.9533972311801217
dev_f-score_macro_tok: 0.9548096794670201
dev_precision_micro_tok: 0.9896616175382579
dev_recall_micro_tok: 0.9896616175382579
dev_f-score_micro_tok: 0.9896616175382579
dev_time: 24.103948831558228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9904    0.9612    0.9756       645
           1     0.9905    0.9977    0.9941      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9904    0.9795    0.9848      3250
weighted avg     0.9905    0.9905    0.9904      3250

F1-macro sent:  0.9848406401447835
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9971    0.9972     42759
         LOC     0.9579    0.9661    0.9620      2094
        MISC     0.9229    0.8872    0.9047      1268
         ORG     0.9300    0.9340    0.9320      2092
         PER     0.9739    0.9825    0.9782      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9564    0.9534    0.9548     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.9548096794670201
F1-micro tok:  0.9896616175382579
**************************************************
Best epoch: 20
**************************************************

EPOCH: 25
Learning rate: 0.656100
train_cost_sum: 301947.8056945801
train_cost_avg: 21.50472229147355
train_count_sent: 14041.0
train_total_correct_sent: 13887.0
train_accuracy_sent: 0.9890321202193576
train_count_tok: 203621.0
train_total_correct_tok: 202309.0
train_accuracy_tok: 0.9935566567299051
train_label=0_precision_sent: 0.9728801922416752
train_label=0_recall_sent: 0.9742179443107597
train_label=0_f-score_sent: 0.9735486087255238
train_label=1_precision_sent: 0.9932602444284687
train_label=1_recall_sent: 0.992903341717571
train_label=1_f-score_sent: 0.9930817610062894
train_precision_macro_sent: 0.9830702183350719
train_recall_macro_sent: 0.9835606430141653
train_f-score_macro_sent: 0.9833151848659066
train_precision_micro_sent: 0.9890321202193576
train_recall_micro_sent: 0.9890321202193576
train_f-score_micro_sent: 0.9890321202193576
train_label=O_precision_tok: 0.9978718010694052
train_label=O_recall_tok: 0.9981601386972366
train_label=O_f-score_tok: 0.9980159490573547
train_label=LOC_precision_tok: 0.9731809981960313
train_label=LOC_recall_tok: 0.9752922743160178
train_label=LOC_f-score_tok: 0.9742354924151215
train_label=MISC_precision_tok: 0.9540052816901409
train_label=MISC_recall_tok: 0.9438275636838668
train_label=MISC_f-score_tok: 0.9488891321002517
train_label=ORG_precision_tok: 0.9653271870928951
train_label=ORG_recall_tok: 0.9608977556109726
train_label=ORG_f-score_tok: 0.9631073785242951
train_label=PER_precision_tok: 0.9844926496952313
train_label=PER_recall_tok: 0.9869698058950396
train_label=PER_f-score_tok: 0.9857296715131935
train_precision_macro_tok: 0.9749755835487408
train_recall_macro_tok: 0.9730295076406266
train_f-score_macro_tok: 0.9739955247220433
train_precision_micro_tok: 0.9935566567299051
train_recall_micro_tok: 0.9935566567299051
train_f-score_micro_tok: 0.9935566567299051
train_time: 243.52767777442932
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9729    0.9742    0.9735      2909
           1     0.9933    0.9929    0.9931     11132

   micro avg     0.9890    0.9890    0.9890     14041
   macro avg     0.9831    0.9836    0.9833     14041
weighted avg     0.9890    0.9890    0.9890     14041

F1-macro sent:  0.9833151848659066
F1-micro sent:  0.9890321202193576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9979    0.9982    0.9980    169578
         LOC     0.9732    0.9753    0.9742      8297
        MISC     0.9540    0.9438    0.9489      4593
         ORG     0.9653    0.9609    0.9631     10025
         PER     0.9845    0.9870    0.9857     11128

   micro avg     0.9936    0.9936    0.9936    203621
   macro avg     0.9750    0.9730    0.9740    203621
weighted avg     0.9935    0.9936    0.9935    203621

F1-macro tok:  0.9739955247220433
F1-micro tok:  0.9935566567299051
**************************************************
dev_cost_sum: 83321.28414154053
dev_cost_avg: 25.637318197397086
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50824.0
dev_accuracy_tok: 0.9895253300105136
dev_label=0_precision_sent: 0.973724884080371
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9752321981424149
dev_label=1_precision_sent: 0.9942374183634268
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9938556067588327
dev_precision_macro_sent: 0.9839811512218989
dev_recall_macro_sent: 0.9851091371691292
dev_f-score_macro_sent: 0.9845439024506237
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9967974940975712
dev_label=O_recall_tok: 0.9972637339507472
dev_label=O_f-score_tok: 0.9970305595174075
dev_label=LOC_precision_tok: 0.9687048627828599
dev_label=LOC_recall_tok: 0.9608404966571156
dev_label=LOC_f-score_tok: 0.964756653080796
dev_label=MISC_precision_tok: 0.9053728949478749
dev_label=MISC_recall_tok: 0.8903785488958991
dev_label=MISC_f-score_tok: 0.8978131212723658
dev_label=ORG_precision_tok: 0.9362934362934363
dev_label=ORG_recall_tok: 0.9273422562141491
dev_label=ORG_f-score_tok: 0.9317963496637849
dev_label=PER_precision_tok: 0.9730153749607782
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.97885101010101
dev_precision_macro_tok: 0.9560368126165042
dev_recall_macro_tok: 0.9521164202906129
dev_f-score_macro_tok: 0.9540495387270729
dev_precision_micro_tok: 0.9895253300105136
dev_recall_micro_tok: 0.9895253300105136
dev_f-score_micro_tok: 0.9895253300105136
dev_time: 24.22601842880249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9737    0.9767    0.9752       645
           1     0.9942    0.9935    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9840    0.9851    0.9845      3250
weighted avg     0.9902    0.9902    0.9902      3250

F1-macro sent:  0.9845439024506237
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9973    0.9970     42759
         LOC     0.9687    0.9608    0.9648      2094
        MISC     0.9054    0.8904    0.8978      1268
         ORG     0.9363    0.9273    0.9318      2092
         PER     0.9730    0.9848    0.9789      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9560    0.9521    0.9540     51362
weighted avg     0.9895    0.9895    0.9895     51362

F1-macro tok:  0.9540495387270729
F1-micro tok:  0.9895253300105136
**************************************************
Best epoch: 20
**************************************************

EPOCH: 26
Learning rate: 0.590490
train_cost_sum: 301002.0100402832
train_cost_avg: 21.437362726321716
train_count_sent: 14041.0
train_total_correct_sent: 13908.0
train_accuracy_sent: 0.9905277401894452
train_count_tok: 203621.0
train_total_correct_tok: 202364.0
train_accuracy_tok: 0.9938267663944289
train_label=0_precision_sent: 0.97599451303155
train_label=0_recall_sent: 0.9783430732210382
train_label=0_f-score_sent: 0.9771673819742489
train_label=1_precision_sent: 0.9943370786516854
train_label=1_recall_sent: 0.9937118217750629
train_label=1_f-score_sent: 0.9940243518892932
train_precision_macro_sent: 0.9851657958416178
train_recall_macro_sent: 0.9860274474980506
train_f-score_macro_sent: 0.985595866931771
train_precision_micro_sent: 0.9905277401894452
train_recall_micro_sent: 0.9905277401894452
train_f-score_micro_sent: 0.9905277401894452
train_label=O_precision_tok: 0.9981193699004858
train_label=O_recall_tok: 0.9983901213600821
train_label=O_f-score_tok: 0.9982547272716553
train_label=LOC_precision_tok: 0.9734779987944545
train_label=LOC_recall_tok: 0.9732433409666145
train_label=LOC_f-score_tok: 0.9733606557377049
train_label=MISC_precision_tok: 0.9585537918871252
train_label=MISC_recall_tok: 0.9466579577618115
train_label=MISC_f-score_tok: 0.9525687369920035
train_label=ORG_precision_tok: 0.964125112421305
train_label=ORG_recall_tok: 0.9623940149625935
train_label=ORG_f-score_tok: 0.963258785942492
train_label=PER_precision_tok: 0.9846760462407026
train_label=PER_recall_tok: 0.9874191229331416
train_label=PER_f-score_tok: 0.9860456768519765
train_precision_macro_tok: 0.9757904638488146
train_recall_macro_tok: 0.9736209115968487
train_f-score_macro_tok: 0.9746977165591666
train_precision_micro_tok: 0.9938267663944289
train_recall_micro_tok: 0.9938267663944289
train_f-score_micro_tok: 0.9938267663944289
train_time: 241.79175066947937
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9760    0.9783    0.9772      2909
           1     0.9943    0.9937    0.9940     11132

   micro avg     0.9905    0.9905    0.9905     14041
   macro avg     0.9852    0.9860    0.9856     14041
weighted avg     0.9905    0.9905    0.9905     14041

F1-macro sent:  0.985595866931771
F1-micro sent:  0.9905277401894452
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9981    0.9984    0.9983    169578
         LOC     0.9735    0.9732    0.9734      8297
        MISC     0.9586    0.9467    0.9526      4593
         ORG     0.9641    0.9624    0.9633     10025
         PER     0.9847    0.9874    0.9860     11128

   micro avg     0.9938    0.9938    0.9938    203621
   macro avg     0.9758    0.9736    0.9747    203621
weighted avg     0.9938    0.9938    0.9938    203621

F1-macro tok:  0.9746977165591666
F1-micro tok:  0.9938267663944289
**************************************************
dev_cost_sum: 83237.60408782959
dev_cost_avg: 25.61157048856295
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50812.0
dev_accuracy_tok: 0.9892916942486664
dev_label=0_precision_sent: 0.9797507788161994
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9774669774669774
dev_label=1_precision_sent: 0.9938650306748467
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9944369844619221
dev_precision_macro_sent: 0.986807904745523
dev_recall_macro_sent: 0.9851016976892976
dev_f-score_macro_sent: 0.9859519809644497
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9959378064154644
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9968104868388771
dev_label=LOC_precision_tok: 0.9636189564384873
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9624671288548889
dev_label=MISC_precision_tok: 0.9040767386091128
dev_label=MISC_recall_tok: 0.8919558359621451
dev_label=MISC_f-score_tok: 0.8979753870583566
dev_label=ORG_precision_tok: 0.9460929772502473
dev_label=ORG_recall_tok: 0.9144359464627151
dev_label=ORG_f-score_tok: 0.9299951385512882
dev_label=PER_precision_tok: 0.9775742261528743
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9802058590657166
dev_precision_macro_tok: 0.9574601409732372
dev_recall_macro_tok: 0.9496492461822328
dev_f-score_macro_tok: 0.9534908000738256
dev_precision_micro_tok: 0.9892916942486664
dev_recall_micro_tok: 0.9892916942486664
dev_f-score_micro_tok: 0.9892916942486664
dev_time: 24.22732710838318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9798    0.9752    0.9775       645
           1     0.9939    0.9950    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9868    0.9851    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9859519809644497
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9977    0.9968     42759
         LOC     0.9636    0.9613    0.9625      2094
        MISC     0.9041    0.8920    0.8980      1268
         ORG     0.9461    0.9144    0.9300      2092
         PER     0.9776    0.9829    0.9802      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9575    0.9496    0.9535     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9534908000738256
F1-micro tok:  0.9892916942486664
**************************************************
Best epoch: 26
**************************************************

EPOCH: 27
Learning rate: 0.590490
train_cost_sum: 300165.417388916
train_cost_avg: 21.377780598882985
train_count_sent: 14041.0
train_total_correct_sent: 13896.0
train_accuracy_sent: 0.989673100206538
train_count_tok: 203621.0
train_total_correct_tok: 202363.0
train_accuracy_tok: 0.9938218553096193
train_label=0_precision_sent: 0.9745879120879121
train_label=0_recall_sent: 0.9755929872808525
train_label=0_f-score_sent: 0.975090190688885
train_label=1_precision_sent: 0.9936202713631054
train_label=1_recall_sent: 0.9933524973050665
train_label=1_f-score_sent: 0.9934863662908224
train_precision_macro_sent: 0.9841040917255087
train_recall_macro_sent: 0.9844727422929596
train_f-score_macro_sent: 0.9842882784898537
train_precision_micro_sent: 0.989673100206538
train_recall_micro_sent: 0.989673100206538
train_f-score_micro_sent: 0.989673100206538
train_label=O_precision_tok: 0.9978601871009957
train_label=O_recall_tok: 0.9982309025934968
train_label=O_f-score_tok: 0.9980455104224705
train_label=LOC_precision_tok: 0.9775145067698259
train_label=LOC_recall_tok: 0.9745691213691696
train_label=LOC_f-score_tok: 0.9760395920091738
train_label=MISC_precision_tok: 0.9576475751590959
train_label=MISC_recall_tok: 0.9501415197038973
train_label=MISC_f-score_tok: 0.9538797814207651
train_label=ORG_precision_tok: 0.9632183908045977
train_label=ORG_recall_tok: 0.9612967581047381
train_label=ORG_f-score_tok: 0.9622566150773839
train_label=PER_precision_tok: 0.986721693881213
train_label=PER_recall_tok: 0.9883177570093458
train_label=PER_f-score_tok: 0.9875190805423364
train_precision_macro_tok: 0.9765924707431457
train_recall_macro_tok: 0.9745112117561294
train_f-score_macro_tok: 0.9755481158944258
train_precision_micro_tok: 0.9938218553096193
train_recall_micro_tok: 0.9938218553096193
train_f-score_micro_tok: 0.9938218553096193
train_time: 240.99394583702087
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9746    0.9756    0.9751      2909
           1     0.9936    0.9934    0.9935     11132

   micro avg     0.9897    0.9897    0.9897     14041
   macro avg     0.9841    0.9845    0.9843     14041
weighted avg     0.9897    0.9897    0.9897     14041

F1-macro sent:  0.9842882784898537
F1-micro sent:  0.989673100206538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9979    0.9982    0.9980    169578
         LOC     0.9775    0.9746    0.9760      8297
        MISC     0.9576    0.9501    0.9539      4593
         ORG     0.9632    0.9613    0.9623     10025
         PER     0.9867    0.9883    0.9875     11128

   micro avg     0.9938    0.9938    0.9938    203621
   macro avg     0.9766    0.9745    0.9755    203621
weighted avg     0.9938    0.9938    0.9938    203621

F1-macro tok:  0.9755481158944258
F1-micro tok:  0.9938218553096193
**************************************************
dev_cost_sum: 83034.23748779297
dev_cost_avg: 25.548996150090144
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50830.0
dev_accuracy_tok: 0.9896421478914372
dev_label=0_precision_sent: 0.9797507788161994
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9774669774669774
dev_label=1_precision_sent: 0.9938650306748467
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9944369844619221
dev_precision_macro_sent: 0.986807904745523
dev_recall_macro_sent: 0.9851016976892976
dev_f-score_macro_sent: 0.9859519809644497
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.996658331970182
dev_label=O_recall_tok: 0.9974508290652261
dev_label=O_f-score_tok: 0.9970544230409577
dev_label=LOC_precision_tok: 0.9640976543800862
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.9629452546019603
dev_label=MISC_precision_tok: 0.905103668261563
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.9000793021411577
dev_label=ORG_precision_tok: 0.9420077972709552
dev_label=ORG_recall_tok: 0.9239961759082218
dev_label=ORG_f-score_tok: 0.932915057915058
dev_label=PER_precision_tok: 0.9760554505356017
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9799145975011861
dev_precision_macro_tok: 0.9567845804836776
dev_recall_macro_tok: 0.9524314807812868
dev_f-score_macro_tok: 0.954581727040064
dev_precision_micro_tok: 0.9896421478914372
dev_recall_micro_tok: 0.9896421478914372
dev_f-score_micro_tok: 0.9896421478914372
dev_time: 24.539225339889526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9798    0.9752    0.9775       645
           1     0.9939    0.9950    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9868    0.9851    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9859519809644497
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9975    0.9971     42759
         LOC     0.9641    0.9618    0.9629      2094
        MISC     0.9051    0.8951    0.9001      1268
         ORG     0.9420    0.9240    0.9329      2092
         PER     0.9761    0.9838    0.9799      3149

   micro avg     0.9896    0.9896    0.9896     51362
   macro avg     0.9568    0.9524    0.9546     51362
weighted avg     0.9896    0.9896    0.9896     51362

F1-macro tok:  0.954581727040064
F1-micro tok:  0.9896421478914372
**************************************************
Best epoch: 26
**************************************************

EPOCH: 28
Learning rate: 0.590490
train_cost_sum: 299257.4831237793
train_cost_avg: 21.31311752181321
train_count_sent: 14041.0
train_total_correct_sent: 13914.0
train_accuracy_sent: 0.9909550601808989
train_count_tok: 203621.0
train_total_correct_tok: 202485.0
train_accuracy_tok: 0.9944210076563812
train_label=0_precision_sent: 0.9793246037215714
train_label=0_recall_sent: 0.9769680302509454
train_label=0_f-score_sent: 0.9781448976079848
train_label=1_precision_sent: 0.9939850974055122
train_label=1_recall_sent: 0.9946101329500538
train_label=1_f-score_sent: 0.9942975169502941
train_precision_macro_sent: 0.9866548505635417
train_recall_macro_sent: 0.9857890816004996
train_f-score_macro_sent: 0.9862212072791394
train_precision_micro_sent: 0.9909550601808989
train_recall_micro_sent: 0.9909550601808989
train_f-score_micro_sent: 0.9909550601808989
train_label=O_precision_tok: 0.9981722560256592
train_label=O_recall_tok: 0.998348842420597
train_label=O_f-score_tok: 0.9982605414138556
train_label=LOC_precision_tok: 0.9759181216134859
train_label=LOC_recall_tok: 0.9768591057008558
train_label=LOC_f-score_tok: 0.9763883869413323
train_label=MISC_precision_tok: 0.9624423457061279
train_label=MISC_recall_tok: 0.9540605268887438
train_label=MISC_f-score_tok: 0.9582331073693418
train_label=ORG_precision_tok: 0.9673554956573824
train_label=ORG_recall_tok: 0.9665835411471322
train_label=ORG_f-score_tok: 0.9669693643348967
train_label=PER_precision_tok: 0.9885078110971449
train_label=PER_recall_tok: 0.9893961179007909
train_label=PER_f-score_tok: 0.9889517650229048
train_precision_macro_tok: 0.9784792060199601
train_recall_macro_tok: 0.9770496268116238
train_f-score_macro_tok: 0.9777606330164662
train_precision_micro_tok: 0.9944210076563812
train_recall_micro_tok: 0.9944210076563812
train_f-score_micro_tok: 0.9944210076563812
train_time: 184.9188792705536
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9793    0.9770    0.9781      2909
           1     0.9940    0.9946    0.9943     11132

   micro avg     0.9910    0.9910    0.9910     14041
   macro avg     0.9867    0.9858    0.9862     14041
weighted avg     0.9909    0.9910    0.9910     14041

F1-macro sent:  0.9862212072791394
F1-micro sent:  0.9909550601808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9983    0.9983    169578
         LOC     0.9759    0.9769    0.9764      8297
        MISC     0.9624    0.9541    0.9582      4593
         ORG     0.9674    0.9666    0.9670     10025
         PER     0.9885    0.9894    0.9890     11128

   micro avg     0.9944    0.9944    0.9944    203621
   macro avg     0.9785    0.9770    0.9778    203621
weighted avg     0.9944    0.9944    0.9944    203621

F1-macro tok:  0.9777606330164662
F1-micro tok:  0.9944210076563812
**************************************************
dev_cost_sum: 82889.08127593994
dev_cost_avg: 25.50433270028921
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50817.0
dev_accuracy_tok: 0.9893890424827694
dev_label=0_precision_sent: 0.9754224270353302
dev_label=0_recall_sent: 0.9844961240310077
dev_label=0_f-score_sent: 0.9799382716049382
dev_label=1_precision_sent: 0.9961523662947287
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9950038431975403
dev_precision_macro_sent: 0.9857873966650295
dev_recall_macro_sent: 0.9891770447410317
dev_f-score_macro_sent: 0.9874710574012393
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9964961457603364
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9970900676646917
dev_label=LOC_precision_tok: 0.957325746799431
dev_label=LOC_recall_tok: 0.9641833810888252
dev_label=LOC_f-score_tok: 0.9607423269093505
dev_label=MISC_precision_tok: 0.9078525641025641
dev_label=MISC_recall_tok: 0.8935331230283912
dev_label=MISC_f-score_tok: 0.9006359300476947
dev_label=ORG_precision_tok: 0.9475786320519222
dev_label=ORG_recall_tok: 0.9072657743785851
dev_label=ORG_f-score_tok: 0.926984126984127
dev_label=PER_precision_tok: 0.9733709273182958
dev_label=PER_recall_tok: 0.9866624325182598
dev_label=PER_f-score_tok: 0.9799716133102034
dev_precision_macro_tok: 0.9565248032065099
dev_recall_macro_tok: 0.9498658817944772
dev_f-score_macro_tok: 0.9530848129832135
dev_precision_micro_tok: 0.9893890424827694
dev_recall_micro_tok: 0.9893890424827694
dev_f-score_micro_tok: 0.9893890424827694
dev_time: 14.836883306503296
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9754    0.9845    0.9799       645
           1     0.9962    0.9939    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9858    0.9892    0.9875      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874710574012393
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9977    0.9971     42759
         LOC     0.9573    0.9642    0.9607      2094
        MISC     0.9079    0.8935    0.9006      1268
         ORG     0.9476    0.9073    0.9270      2092
         PER     0.9734    0.9867    0.9800      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9565    0.9499    0.9531     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9530848129832135
F1-micro tok:  0.9893890424827694
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.590490
train_cost_sum: 298620.3748474121
train_cost_avg: 21.267742671277837
train_count_sent: 14041.0
train_total_correct_sent: 13913.0
train_accuracy_sent: 0.9908838401823232
train_count_tok: 203621.0
train_total_correct_tok: 202439.0
train_accuracy_tok: 0.9941950977551431
train_label=0_precision_sent: 0.9763617677286742
train_label=0_recall_sent: 0.979718116191131
train_label=0_f-score_sent: 0.9780370624571038
train_label=1_precision_sent: 0.9946951987052688
train_label=1_recall_sent: 0.993801652892562
train_label=1_f-score_sent: 0.9942482250381953
train_precision_macro_sent: 0.9855284832169715
train_recall_macro_sent: 0.9867598845418465
train_f-score_macro_sent: 0.9861426437476495
train_precision_micro_sent: 0.9908838401823232
train_recall_micro_sent: 0.9908838401823232
train_f-score_micro_sent: 0.9908838401823232
train_label=O_precision_tok: 0.9981898584905661
train_label=O_recall_tok: 0.9983193574638219
train_label=O_f-score_tok: 0.9982546037773676
train_label=LOC_precision_tok: 0.976158940397351
train_label=LOC_recall_tok: 0.9771001566831384
train_label=LOC_f-score_tok: 0.9766293217684615
train_label=MISC_precision_tok: 0.9555019728189391
train_label=MISC_recall_tok: 0.9490529065969955
train_label=MISC_f-score_tok: 0.9522665210267613
train_label=ORG_precision_tok: 0.9673685260952001
train_label=ORG_recall_tok: 0.9669825436408978
train_label=ORG_f-score_tok: 0.9671754963583757
train_label=PER_precision_tok: 0.9867960118566425
train_label=PER_recall_tok: 0.9872393961179008
train_label=PER_f-score_tok: 0.9870176541934326
train_precision_macro_tok: 0.9768030619317398
train_recall_macro_tok: 0.9757388721005509
train_f-score_macro_tok: 0.9762687194248798
train_precision_micro_tok: 0.9941950977551431
train_recall_micro_tok: 0.9941950977551431
train_f-score_micro_tok: 0.9941950977551431
train_time: 159.67679691314697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9764    0.9797    0.9780      2909
           1     0.9947    0.9938    0.9942     11132

   micro avg     0.9909    0.9909    0.9909     14041
   macro avg     0.9855    0.9868    0.9861     14041
weighted avg     0.9909    0.9909    0.9909     14041

F1-macro sent:  0.9861426437476495
F1-micro sent:  0.9908838401823232
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9983    0.9983    169578
         LOC     0.9762    0.9771    0.9766      8297
        MISC     0.9555    0.9491    0.9523      4593
         ORG     0.9674    0.9670    0.9672     10025
         PER     0.9868    0.9872    0.9870     11128

   micro avg     0.9942    0.9942    0.9942    203621
   macro avg     0.9768    0.9757    0.9763    203621
weighted avg     0.9942    0.9942    0.9942    203621

F1-macro tok:  0.9762687194248798
F1-micro tok:  0.9941950977551431
**************************************************
dev_cost_sum: 82876.329662323
dev_cost_avg: 25.500409126868615
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50830.0
dev_accuracy_tok: 0.9896421478914372
dev_label=0_precision_sent: 0.9920255183413078
dev_label=0_recall_sent: 0.9643410852713178
dev_label=0_f-score_sent: 0.9779874213836477
dev_label=1_precision_sent: 0.9912314144109798
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9946442234123947
dev_precision_macro_sent: 0.9916284663761439
dev_recall_macro_sent: 0.9812108497373864
dev_f-score_macro_sent: 0.9863158223980212
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9965195860876878
dev_label=O_recall_tok: 0.9977314717369443
dev_label=O_f-score_tok: 0.9971251606871568
dev_label=LOC_precision_tok: 0.9610080836899667
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9630688587086014
dev_label=MISC_precision_tok: 0.9074074074074074
dev_label=MISC_recall_tok: 0.888801261829653
dev_label=MISC_f-score_tok: 0.8980079681274901
dev_label=ORG_precision_tok: 0.9489846458642892
dev_label=ORG_recall_tok: 0.9158699808795411
dev_label=ORG_f-score_tok: 0.9321333009000242
dev_label=PER_precision_tok: 0.9739566990900533
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9797979797979798
dev_precision_macro_tok: 0.957575284427881
dev_recall_macro_tok: 0.9506501908998605
dev_f-score_macro_tok: 0.9540266536442505
dev_precision_micro_tok: 0.9896421478914372
dev_recall_micro_tok: 0.9896421478914372
dev_f-score_micro_tok: 0.9896421478914372
dev_time: 14.73299765586853
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9920    0.9643    0.9780       645
           1     0.9912    0.9981    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9916    0.9812    0.9863      3250
weighted avg     0.9914    0.9914    0.9913      3250

F1-macro sent:  0.9863158223980212
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9977    0.9971     42759
         LOC     0.9610    0.9651    0.9631      2094
        MISC     0.9074    0.8888    0.8980      1268
         ORG     0.9490    0.9159    0.9321      2092
         PER     0.9740    0.9857    0.9798      3149

   micro avg     0.9896    0.9896    0.9896     51362
   macro avg     0.9576    0.9507    0.9540     51362
weighted avg     0.9896    0.9896    0.9896     51362

F1-macro tok:  0.9540266536442505
F1-micro tok:  0.9896421478914372
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.590490
train_cost_sum: 297900.1212463379
train_cost_avg: 21.21644621083526
train_count_sent: 14041.0
train_total_correct_sent: 13928.0
train_accuracy_sent: 0.9919521401609572
train_count_tok: 203621.0
train_total_correct_tok: 202517.0
train_accuracy_tok: 0.994578162370286
train_label=0_precision_sent: 0.9800824175824175
train_label=0_recall_sent: 0.9810931591612237
train_label=0_f-score_sent: 0.9805875279161657
train_label=1_precision_sent: 0.9950579566897295
train_label=1_recall_sent: 0.9947897951850521
train_label=1_f-score_sent: 0.9949238578680202
train_precision_macro_sent: 0.9875701871360736
train_recall_macro_sent: 0.9879414771731378
train_f-score_macro_sent: 0.987755692892093
train_precision_micro_sent: 0.9919521401609572
train_recall_micro_sent: 0.9919521401609572
train_f-score_micro_sent: 0.9919521401609572
train_label=O_precision_tok: 0.9983488716306662
train_label=O_recall_tok: 0.9983665333946621
train_label=O_f-score_tok: 0.9983577024345514
train_label=LOC_precision_tok: 0.9778932109205122
train_label=LOC_recall_tok: 0.975653850789442
train_label=LOC_f-score_tok: 0.9767722473604827
train_label=MISC_precision_tok: 0.9631578947368421
train_label=MISC_recall_tok: 0.9562377531025473
train_label=MISC_f-score_tok: 0.9596853490658801
train_label=ORG_precision_tok: 0.9669750323286581
train_label=ORG_recall_tok: 0.9696758104738155
train_label=ORG_f-score_tok: 0.968323538201016
train_label=PER_precision_tok: 0.9873531258408826
train_label=PER_recall_tok: 0.9892163910855499
train_label=PER_f-score_tok: 0.9882838802352202
train_precision_macro_tok: 0.9787456270915122
train_recall_macro_tok: 0.9778300677692032
train_f-score_macro_tok: 0.9782845434594301
train_precision_micro_tok: 0.994578162370286
train_recall_micro_tok: 0.994578162370286
train_f-score_micro_tok: 0.994578162370286
train_time: 158.68556785583496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9801    0.9811    0.9806      2909
           1     0.9951    0.9948    0.9949     11132

   micro avg     0.9920    0.9920    0.9920     14041
   macro avg     0.9876    0.9879    0.9878     14041
weighted avg     0.9920    0.9920    0.9920     14041

F1-macro sent:  0.987755692892093
F1-micro sent:  0.9919521401609572
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9984    0.9984    169578
         LOC     0.9779    0.9757    0.9768      8297
        MISC     0.9632    0.9562    0.9597      4593
         ORG     0.9670    0.9697    0.9683     10025
         PER     0.9874    0.9892    0.9883     11128

   micro avg     0.9946    0.9946    0.9946    203621
   macro avg     0.9787    0.9778    0.9783    203621
weighted avg     0.9946    0.9946    0.9946    203621

F1-macro tok:  0.9782845434594301
F1-micro tok:  0.994578162370286
**************************************************
dev_cost_sum: 82844.1997795105
dev_cost_avg: 25.490523009080153
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50816.0
dev_accuracy_tok: 0.9893695728359487
dev_label=0_precision_sent: 0.9753086419753086
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9775715390564579
dev_label=1_precision_sent: 0.9950038431975403
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9944305742270021
dev_precision_macro_sent: 0.9851562425864244
dev_recall_macro_sent: 0.9868514633456829
dev_f-score_macro_sent: 0.98600105664173
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9962871287128713
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9970438054286482
dev_label=LOC_precision_tok: 0.9524033930254477
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9587286527514232
dev_label=MISC_precision_tok: 0.9230132450331126
dev_label=MISC_recall_tok: 0.8793375394321766
dev_label=MISC_f-score_tok: 0.9006462035541194
dev_label=ORG_precision_tok: 0.9426189308484552
dev_label=ORG_recall_tok: 0.9187380497131931
dev_label=ORG_f-score_tok: 0.9305252965383685
dev_label=PER_precision_tok: 0.9760176711896498
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9791073124406459
dev_precision_macro_tok: 0.9580680737619073
dev_recall_macro_tok: 0.9486464578335425
dev_f-score_macro_tok: 0.9532102541426409
dev_precision_micro_tok: 0.9893695728359487
dev_recall_micro_tok: 0.9893695728359487
dev_f-score_micro_tok: 0.9893695728359487
dev_time: 14.671082496643066
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9753    0.9798    0.9776       645
           1     0.9950    0.9939    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9852    0.9869    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.98600105664173
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9970     42759
         LOC     0.9524    0.9651    0.9587      2094
        MISC     0.9230    0.8793    0.9006      1268
         ORG     0.9426    0.9187    0.9305      2092
         PER     0.9760    0.9822    0.9791      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9581    0.9486    0.9532     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9532102541426409
F1-micro tok:  0.9893695728359487
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.590490
train_cost_sum: 297093.9123535156
train_cost_avg: 21.15902801463682
train_count_sent: 14041.0
train_total_correct_sent: 13923.0
train_accuracy_sent: 0.9915960401680792
train_count_tok: 203621.0
train_total_correct_tok: 202539.0
train_accuracy_tok: 0.9946862062360955
train_label=0_precision_sent: 0.9770940170940171
train_label=0_recall_sent: 0.9824682021313166
train_label=0_f-score_sent: 0.9797737401439836
train_label=1_precision_sent: 0.9954120187117669
train_label=1_recall_sent: 0.9939813151275602
train_label=1_f-score_sent: 0.9946961524631428
train_precision_macro_sent: 0.986253017902892
train_recall_macro_sent: 0.9882247586294384
train_f-score_macro_sent: 0.9872349463035632
train_precision_micro_sent: 0.9915960401680792
train_recall_micro_sent: 0.9915960401680792
train_f-score_micro_sent: 0.9915960401680792
train_label=O_precision_tok: 0.9982136645816261
train_label=O_recall_tok: 0.9984667822476972
train_label=O_f-score_tok: 0.9983402073708944
train_label=LOC_precision_tok: 0.9765342960288809
train_label=LOC_recall_tok: 0.9780643606122695
train_label=LOC_f-score_tok: 0.9772987294514361
train_label=MISC_precision_tok: 0.9618169848584596
train_label=MISC_recall_tok: 0.9542782495101241
train_label=MISC_f-score_tok: 0.958032786885246
train_label=ORG_precision_tok: 0.9710144927536232
train_label=ORG_recall_tok: 0.969077306733167
train_label=ORG_f-score_tok: 0.9700449326010983
train_label=PER_precision_tok: 0.9892163910855499
train_label=PER_recall_tok: 0.9892163910855499
train_label=PER_f-score_tok: 0.9892163910855499
train_precision_macro_tok: 0.9793591658616279
train_recall_macro_tok: 0.9778206180377615
train_f-score_macro_tok: 0.9785866094788449
train_precision_micro_tok: 0.9946862062360955
train_recall_micro_tok: 0.9946862062360955
train_f-score_micro_tok: 0.9946862062360955
train_time: 159.60475373268127
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9771    0.9825    0.9798      2909
           1     0.9954    0.9940    0.9947     11132

   micro avg     0.9916    0.9916    0.9916     14041
   macro avg     0.9863    0.9882    0.9872     14041
weighted avg     0.9916    0.9916    0.9916     14041

F1-macro sent:  0.9872349463035632
F1-micro sent:  0.9915960401680792
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9985    0.9983    169578
         LOC     0.9765    0.9781    0.9773      8297
        MISC     0.9618    0.9543    0.9580      4593
         ORG     0.9710    0.9691    0.9700     10025
         PER     0.9892    0.9892    0.9892     11128

   micro avg     0.9947    0.9947    0.9947    203621
   macro avg     0.9794    0.9778    0.9786    203621
weighted avg     0.9947    0.9947    0.9947    203621

F1-macro tok:  0.9785866094788449
F1-micro tok:  0.9946862062360955
**************************************************
dev_cost_sum: 82641.19929504395
dev_cost_avg: 25.428061321551983
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50818.0
dev_accuracy_tok: 0.98940851212959
dev_label=0_precision_sent: 0.9676923076923077
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9714285714285713
dev_label=1_precision_sent: 0.9938461538461538
dev_label=1_recall_sent: 0.9919385796545106
dev_label=1_f-score_sent: 0.9928914505283382
dev_precision_macro_sent: 0.9807692307692308
dev_recall_macro_sent: 0.9835661890520615
dev_f-score_macro_sent: 0.9821600109784547
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9968680612364146
dev_label=O_recall_tok: 0.9974742159545359
dev_label=O_f-score_tok: 0.9971710464790049
dev_label=LOC_precision_tok: 0.9524929444967074
dev_label=LOC_recall_tok: 0.9670487106017192
dev_label=LOC_f-score_tok: 0.9597156398104265
dev_label=MISC_precision_tok: 0.8949019607843137
dev_label=MISC_recall_tok: 0.8998422712933754
dev_label=MISC_f-score_tok: 0.8973653165552495
dev_label=ORG_precision_tok: 0.951
dev_label=ORG_recall_tok: 0.9091778202676865
dev_label=ORG_f-score_tok: 0.9296187683284458
dev_label=PER_precision_tok: 0.9757556675062973
dev_label=PER_recall_tok: 0.9841219434741187
dev_label=PER_f-score_tok: 0.9799209486166008
dev_precision_macro_tok: 0.9542037268047465
dev_recall_macro_tok: 0.951532992318287
dev_f-score_macro_tok: 0.9527583439579456
dev_precision_micro_tok: 0.98940851212959
dev_recall_micro_tok: 0.98940851212959
dev_f-score_micro_tok: 0.98940851212959
dev_time: 14.693863868713379
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9677    0.9752    0.9714       645
           1     0.9938    0.9919    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9808    0.9836    0.9822      3250
weighted avg     0.9887    0.9886    0.9886      3250

F1-macro sent:  0.9821600109784547
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9975    0.9972     42759
         LOC     0.9525    0.9670    0.9597      2094
        MISC     0.8949    0.8998    0.8974      1268
         ORG     0.9510    0.9092    0.9296      2092
         PER     0.9758    0.9841    0.9799      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9542    0.9515    0.9528     51362
weighted avg     0.9894    0.9894    0.9894     51362

F1-macro tok:  0.9527583439579456
F1-micro tok:  0.98940851212959
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.590490
train_cost_sum: 296341.4102783203
train_cost_avg: 21.105434817913277
train_count_sent: 14041.0
train_total_correct_sent: 13935.0
train_accuracy_sent: 0.9924506801509864
train_count_tok: 203621.0
train_total_correct_tok: 202598.0
train_accuracy_tok: 0.9949759602398573
train_label=0_precision_sent: 0.9811191211809132
train_label=0_recall_sent: 0.9824682021313166
train_label=0_f-score_sent: 0.9817931982136722
train_label=1_precision_sent: 0.9954169662113588
train_label=1_recall_sent: 0.9950592885375494
train_label=1_f-score_sent: 0.9952380952380951
train_precision_macro_sent: 0.988268043696136
train_recall_macro_sent: 0.988763745334433
train_f-score_macro_sent: 0.9885156467258837
train_precision_micro_sent: 0.9924506801509864
train_recall_micro_sent: 0.9924506801509864
train_f-score_micro_sent: 0.9924506801509864
train_label=O_precision_tok: 0.9984138402754847
train_label=O_recall_tok: 0.9984962672044723
train_label=O_f-score_tok: 0.9984550520388006
train_label=LOC_precision_tok: 0.9772836538461539
train_label=LOC_recall_tok: 0.9799927684705315
train_label=LOC_f-score_tok: 0.9786363362821208
train_label=MISC_precision_tok: 0.9658643326039388
train_label=MISC_recall_tok: 0.9610276507729153
train_label=MISC_f-score_tok: 0.9634399214231147
train_label=ORG_precision_tok: 0.9705441837244134
train_label=ORG_recall_tok: 0.9695760598503741
train_label=ORG_f-score_tok: 0.970059880239521
train_label=PER_precision_tok: 0.9897518878101402
train_label=PER_recall_tok: 0.9893961179007909
train_label=PER_f-score_tok: 0.9895739708790221
train_precision_macro_tok: 0.9803715796520261
train_recall_macro_tok: 0.9796977728398168
train_f-score_macro_tok: 0.9800330321725159
train_precision_micro_tok: 0.9949759602398573
train_recall_micro_tok: 0.9949759602398573
train_f-score_micro_tok: 0.9949759602398573
train_time: 160.0988805294037
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9811    0.9825    0.9818      2909
           1     0.9954    0.9951    0.9952     11132

   micro avg     0.9925    0.9925    0.9925     14041
   macro avg     0.9883    0.9888    0.9885     14041
weighted avg     0.9925    0.9925    0.9925     14041

F1-macro sent:  0.9885156467258837
F1-micro sent:  0.9924506801509864
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9985    0.9985    169578
         LOC     0.9773    0.9800    0.9786      8297
        MISC     0.9659    0.9610    0.9634      4593
         ORG     0.9705    0.9696    0.9701     10025
         PER     0.9898    0.9894    0.9896     11128

   micro avg     0.9950    0.9950    0.9950    203621
   macro avg     0.9804    0.9797    0.9800    203621
weighted avg     0.9950    0.9950    0.9950    203621

F1-macro tok:  0.9800330321725159
F1-micro tok:  0.9949759602398573
**************************************************
dev_cost_sum: 82567.18962097168
dev_cost_avg: 25.40528911414513
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50854.0
dev_accuracy_tok: 0.9901094194151319
dev_label=0_precision_sent: 0.9767080745341615
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9759503491078355
dev_label=1_precision_sent: 0.9938603223330775
dev_label=1_recall_sent: 0.9942418426103646
dev_label=1_f-score_sent: 0.9940510458645174
dev_precision_macro_sent: 0.9852841984336196
dev_recall_macro_sent: 0.9847178205299885
dev_f-score_macro_sent: 0.9850006974861765
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9968446148092744
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9971359433267479
dev_label=LOC_precision_tok: 0.9756453969800293
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9659995177236558
dev_label=MISC_precision_tok: 0.926530612244898
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.9105495387083835
dev_label=ORG_precision_tok: 0.9320342205323194
dev_label=ORG_recall_tok: 0.9373804971319312
dev_label=ORG_f-score_tok: 0.9346997140133461
dev_label=PER_precision_tok: 0.9718397997496871
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9790386130811664
dev_precision_macro_tok: 0.9605789288632417
dev_recall_macro_tok: 0.9545611446356002
dev_f-score_macro_tok: 0.9574846653706599
dev_precision_micro_tok: 0.9901094194151319
dev_recall_micro_tok: 0.9901094194151319
dev_f-score_micro_tok: 0.9901094194151319
dev_time: 14.80064868927002
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9767    0.9752    0.9760       645
           1     0.9939    0.9942    0.9941      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9853    0.9847    0.9850      3250
weighted avg     0.9905    0.9905    0.9905      3250

F1-macro sent:  0.9850006974861765
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9974    0.9971     42759
         LOC     0.9756    0.9565    0.9660      2094
        MISC     0.9265    0.8951    0.9105      1268
         ORG     0.9320    0.9374    0.9347      2092
         PER     0.9718    0.9863    0.9790      3149

   micro avg     0.9901    0.9901    0.9901     51362
   macro avg     0.9606    0.9546    0.9575     51362
weighted avg     0.9901    0.9901    0.9901     51362

F1-macro tok:  0.9574846653706599
F1-micro tok:  0.9901094194151319
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.531441
train_cost_sum: 295721.6501464844
train_cost_avg: 21.061295502206708
train_count_sent: 14041.0
train_total_correct_sent: 13930.0
train_accuracy_sent: 0.9920945801581084
train_count_tok: 203621.0
train_total_correct_tok: 202614.0
train_accuracy_tok: 0.9950545375968097
train_label=0_precision_sent: 0.9807560137457044
train_label=0_recall_sent: 0.9810931591612237
train_label=0_f-score_sent: 0.9809245574841037
train_label=1_precision_sent: 0.9950588446680442
train_label=1_recall_sent: 0.9949694574200503
train_label=1_f-score_sent: 0.995014149036518
train_precision_macro_sent: 0.9879074292068744
train_recall_macro_sent: 0.988031308290637
train_f-score_macro_sent: 0.9879693532603109
train_precision_micro_sent: 0.9920945801581084
train_recall_micro_sent: 0.9920945801581084
train_f-score_micro_sent: 0.9920945801581084
train_label=O_precision_tok: 0.9984375368505459
train_label=O_recall_tok: 0.9985906190661524
train_label=O_f-score_tok: 0.9985140720910897
train_label=LOC_precision_tok: 0.9815195071868583
train_label=LOC_recall_tok: 0.9793901410148247
train_label=LOC_f-score_tok: 0.980453667953668
train_label=MISC_precision_tok: 0.9629710780017529
train_label=MISC_recall_tok: 0.9568909209666885
train_label=MISC_f-score_tok: 0.9599213716282625
train_label=ORG_precision_tok: 0.9713715710723192
train_label=ORG_recall_tok: 0.9713715710723192
train_label=ORG_f-score_tok: 0.9713715710723192
train_label=PER_precision_tok: 0.9880706789846623
train_label=PER_recall_tok: 0.9899352983465133
train_label=PER_f-score_tok: 0.9890021097993447
train_precision_macro_tok: 0.9804740744192276
train_recall_macro_tok: 0.9792357100932996
train_f-score_macro_tok: 0.9798525585089368
train_precision_micro_tok: 0.9950545375968097
train_recall_micro_tok: 0.9950545375968097
train_f-score_micro_tok: 0.9950545375968097
train_time: 157.75078797340393
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9808    0.9811    0.9809      2909
           1     0.9951    0.9950    0.9950     11132

   micro avg     0.9921    0.9921    0.9921     14041
   macro avg     0.9879    0.9880    0.9880     14041
weighted avg     0.9921    0.9921    0.9921     14041

F1-macro sent:  0.9879693532603109
F1-micro sent:  0.9920945801581084
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9986    0.9985    169578
         LOC     0.9815    0.9794    0.9805      8297
        MISC     0.9630    0.9569    0.9599      4593
         ORG     0.9714    0.9714    0.9714     10025
         PER     0.9881    0.9899    0.9890     11128

   micro avg     0.9951    0.9951    0.9951    203621
   macro avg     0.9805    0.9792    0.9799    203621
weighted avg     0.9950    0.9951    0.9951    203621

F1-macro tok:  0.9798525585089368
F1-micro tok:  0.9950545375968097
**************************************************
dev_cost_sum: 82623.46161270142
dev_cost_avg: 25.422603573138897
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50844.0
dev_accuracy_tok: 0.9899147229469257
dev_label=0_precision_sent: 0.9873817034700315
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.978889757623143
dev_label=1_precision_sent: 0.992737003058104
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9948285769009768
dev_precision_macro_sent: 0.9900593532640678
dev_recall_macro_sent: 0.9837358091922213
dev_f-score_macro_sent: 0.9868591672620599
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9969377498305243
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9971708480441441
dev_label=LOC_precision_tok: 0.9587677725118483
dev_label=LOC_recall_tok: 0.9660936007640879
dev_label=LOC_f-score_tok: 0.9624167459562321
dev_label=MISC_precision_tok: 0.9331103678929766
dev_label=MISC_recall_tok: 0.8801261829652997
dev_label=MISC_f-score_tok: 0.9058441558441559
dev_label=ORG_precision_tok: 0.9335564053537285
dev_label=ORG_recall_tok: 0.9335564053537285
dev_label=ORG_f-score_tok: 0.9335564053537285
dev_label=PER_precision_tok: 0.9745682888540032
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9801073571203032
dev_precision_macro_tok: 0.9593881168886161
dev_recall_macro_tok: 0.9525779986992859
dev_f-score_macro_tok: 0.9558191024637128
dev_precision_micro_tok: 0.9899147229469257
dev_recall_micro_tok: 0.9899147229469257
dev_f-score_micro_tok: 0.9899147229469257
dev_time: 14.68566107749939
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9874    0.9705    0.9789       645
           1     0.9927    0.9969    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9901    0.9837    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9868591672620599
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9974    0.9972     42759
         LOC     0.9588    0.9661    0.9624      2094
        MISC     0.9331    0.8801    0.9058      1268
         ORG     0.9336    0.9336    0.9336      2092
         PER     0.9746    0.9857    0.9801      3149

   micro avg     0.9899    0.9899    0.9899     51362
   macro avg     0.9594    0.9526    0.9558     51362
weighted avg     0.9899    0.9899    0.9899     51362

F1-macro tok:  0.9558191024637128
F1-micro tok:  0.9899147229469257
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.478297
train_cost_sum: 295078.28076171875
train_cost_avg: 21.015474735540113
train_count_sent: 14041.0
train_total_correct_sent: 13939.0
train_accuracy_sent: 0.9927355601452887
train_count_tok: 203621.0
train_total_correct_tok: 202640.0
train_accuracy_tok: 0.9951822258018573
train_label=0_precision_sent: 0.98147512864494
train_label=0_recall_sent: 0.9834994843588862
train_label=0_f-score_sent: 0.9824862637362639
train_label=1_precision_sent: 0.9956857810533885
train_label=1_recall_sent: 0.9951491196550485
train_label=1_f-score_sent: 0.9954173780213855
train_precision_macro_sent: 0.9885804548491642
train_recall_macro_sent: 0.9893243020069673
train_f-score_macro_sent: 0.9889518208788247
train_precision_micro_sent: 0.9927355601452887
train_recall_micro_sent: 0.9927355601452887
train_f-score_micro_sent: 0.9927355601452887
train_label=O_precision_tok: 0.9984492650223765
train_label=O_recall_tok: 0.9985611341093774
train_label=O_f-score_tok: 0.9985051964325201
train_label=LOC_precision_tok: 0.9828585224529213
train_label=LOC_recall_tok: 0.9813185488730867
train_label=LOC_f-score_tok: 0.9820879319703274
train_label=MISC_precision_tok: 0.9653584740188556
train_label=MISC_recall_tok: 0.9586327019377313
train_label=MISC_f-score_tok: 0.9619838322045008
train_label=ORG_precision_tok: 0.9723856046256605
train_label=ORG_recall_tok: 0.9729675810473816
train_label=ORG_f-score_tok: 0.9726765057838054
train_label=PER_precision_tok: 0.9873519913885899
train_label=PER_recall_tok: 0.9891265276779295
train_label=PER_f-score_tok: 0.9882384629197343
train_precision_macro_tok: 0.9812807715016808
train_recall_macro_tok: 0.9801212987291013
train_f-score_macro_tok: 0.9806983858621775
train_precision_micro_tok: 0.9951822258018573
train_recall_micro_tok: 0.9951822258018573
train_f-score_micro_tok: 0.9951822258018573
train_time: 159.06884264945984
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9815    0.9835    0.9825      2909
           1     0.9957    0.9951    0.9954     11132

   micro avg     0.9927    0.9927    0.9927     14041
   macro avg     0.9886    0.9893    0.9890     14041
weighted avg     0.9927    0.9927    0.9927     14041

F1-macro sent:  0.9889518208788247
F1-micro sent:  0.9927355601452887
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9986    0.9985    169578
         LOC     0.9829    0.9813    0.9821      8297
        MISC     0.9654    0.9586    0.9620      4593
         ORG     0.9724    0.9730    0.9727     10025
         PER     0.9874    0.9891    0.9882     11128

   micro avg     0.9952    0.9952    0.9952    203621
   macro avg     0.9813    0.9801    0.9807    203621
weighted avg     0.9952    0.9952    0.9952    203621

F1-macro tok:  0.9806983858621775
F1-micro tok:  0.9951822258018573
**************************************************
dev_cost_sum: 82409.06663894653
dev_cost_avg: 25.356635888906627
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50839.0
dev_accuracy_tok: 0.9898173747128227
dev_label=0_precision_sent: 0.9811616954474097
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.9750390015600624
dev_label=1_precision_sent: 0.9923459624952162
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9938673821387505
dev_precision_macro_sent: 0.9867538289713129
dev_recall_macro_sent: 0.9821928610751536
dev_f-score_macro_sent: 0.9844531918494064
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9968683540162191
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9972179361294244
dev_label=LOC_precision_tok: 0.9521575984990619
dev_label=LOC_recall_tok: 0.9694364851957975
dev_label=LOC_f-score_tok: 0.9607193563653573
dev_label=MISC_precision_tok: 0.9159935379644588
dev_label=MISC_recall_tok: 0.8943217665615142
dev_label=MISC_f-score_tok: 0.9050279329608938
dev_label=ORG_precision_tok: 0.9527598209845848
dev_label=ORG_recall_tok: 0.9158699808795411
dev_label=ORG_f-score_tok: 0.9339507677309286
dev_label=PER_precision_tok: 0.9724310776942355
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9790253903169847
dev_precision_macro_tok: 0.9580420778317119
dev_recall_macro_tok: 0.952581149055067
dev_f-score_macro_tok: 0.9551882767007177
dev_precision_micro_tok: 0.9898173747128227
dev_recall_micro_tok: 0.9898173747128227
dev_f-score_micro_tok: 0.9898173747128227
dev_time: 14.723853349685669
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9812    0.9690    0.9750       645
           1     0.9923    0.9954    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9868    0.9822    0.9845      3250
weighted avg     0.9901    0.9902    0.9901      3250

F1-macro sent:  0.9844531918494064
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9976    0.9972     42759
         LOC     0.9522    0.9694    0.9607      2094
        MISC     0.9160    0.8943    0.9050      1268
         ORG     0.9528    0.9159    0.9340      2092
         PER     0.9724    0.9857    0.9790      3149

   micro avg     0.9898    0.9898    0.9898     51362
   macro avg     0.9580    0.9526    0.9552     51362
weighted avg     0.9898    0.9898    0.9898     51362

F1-macro tok:  0.9551882767007177
F1-micro tok:  0.9898173747128227
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.430467
train_cost_sum: 294326.8712158203
train_cost_avg: 20.961959348751535
train_count_sent: 14041.0
train_total_correct_sent: 13952.0
train_accuracy_sent: 0.9936614201267716
train_count_tok: 203621.0
train_total_correct_tok: 202714.0
train_accuracy_tok: 0.9955456460777621
train_label=0_precision_sent: 0.9835390946502057
train_label=0_recall_sent: 0.9859058095565486
train_label=0_f-score_sent: 0.9847210300429183
train_label=1_precision_sent: 0.996314606741573
train_label=1_recall_sent: 0.9956881063600431
train_label=1_f-score_sent: 0.9960012580311811
train_precision_macro_sent: 0.9899268506958894
train_recall_macro_sent: 0.9907969579582958
train_f-score_macro_sent: 0.9903611440370497
train_precision_micro_sent: 0.9936614201267716
train_recall_micro_sent: 0.9936614201267716
train_f-score_micro_sent: 0.9936614201267716
train_label=O_precision_tok: 0.9985141334213847
train_label=O_recall_tok: 0.9986318980056376
train_label=O_f-score_tok: 0.9985730122414324
train_label=LOC_precision_tok: 0.9811002768749247
train_label=LOC_recall_tok: 0.9822827528022177
train_label=LOC_f-score_tok: 0.981691158756926
train_label=MISC_precision_tok: 0.9699693117053924
train_label=MISC_recall_tok: 0.9634225996080993
train_label=MISC_f-score_tok: 0.9666848716548334
train_label=ORG_precision_tok: 0.9754147511493104
train_label=ORG_recall_tok: 0.97356608478803
train_label=ORG_f-score_tok: 0.9744895412111227
train_label=PER_precision_tok: 0.9896842482956584
train_label=PER_recall_tok: 0.9914629762760604
train_label=PER_f-score_tok: 0.9905728137906267
train_precision_macro_tok: 0.9829365442893343
train_recall_macro_tok: 0.9818732622960089
train_f-score_macro_tok: 0.9824022795309884
train_precision_micro_tok: 0.9955456460777621
train_recall_micro_tok: 0.9955456460777621
train_f-score_micro_tok: 0.9955456460777621
train_time: 159.72182822227478
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9835    0.9859    0.9847      2909
           1     0.9963    0.9957    0.9960     11132

   micro avg     0.9937    0.9937    0.9937     14041
   macro avg     0.9899    0.9908    0.9904     14041
weighted avg     0.9937    0.9937    0.9937     14041

F1-macro sent:  0.9903611440370497
F1-micro sent:  0.9936614201267716
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9985    0.9986    0.9986    169578
         LOC     0.9811    0.9823    0.9817      8297
        MISC     0.9700    0.9634    0.9667      4593
         ORG     0.9754    0.9736    0.9745     10025
         PER     0.9897    0.9915    0.9906     11128

   micro avg     0.9955    0.9955    0.9955    203621
   macro avg     0.9829    0.9819    0.9824    203621
weighted avg     0.9955    0.9955    0.9955    203621

F1-macro tok:  0.9824022795309884
F1-micro tok:  0.9955456460777621
**************************************************
dev_cost_sum: 82365.22730255127
dev_cost_avg: 25.34314686232347
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50845.0
dev_accuracy_tok: 0.9899341925937464
dev_label=0_precision_sent: 0.9723926380368099
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9776407093292212
dev_label=1_precision_sent: 0.9957659738260201
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9944262925235442
dev_precision_macro_sent: 0.984079305931415
dev_recall_macro_sent: 0.988017973783273
dev_f-score_macro_sent: 0.9860335009263828
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.996333917104495
dev_label=O_recall_tok: 0.9978717930728034
dev_label=O_f-score_tok: 0.9971022621050664
dev_label=LOC_precision_tok: 0.9591642924976258
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9619047619047619
dev_label=MISC_precision_tok: 0.9254098360655738
dev_label=MISC_recall_tok: 0.8903785488958991
dev_label=MISC_f-score_tok: 0.907556270096463
dev_label=ORG_precision_tok: 0.9460255152109912
dev_label=ORG_recall_tok: 0.9216061185468452
dev_label=ORG_f-score_tok: 0.9336561743341405
dev_label=PER_precision_tok: 0.9769933816577372
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9807023093957609
dev_precision_macro_tok: 0.9607853885072846
dev_recall_macro_tok: 0.9517913802255651
dev_f-score_macro_tok: 0.9561843555672386
dev_precision_micro_tok: 0.9899341925937464
dev_recall_micro_tok: 0.9899341925937464
dev_f-score_micro_tok: 0.9899341925937464
dev_time: 14.67925763130188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9724    0.9829    0.9776       645
           1     0.9958    0.9931    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9841    0.9880    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9860335009263828
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9979    0.9971     42759
         LOC     0.9592    0.9647    0.9619      2094
        MISC     0.9254    0.8904    0.9076      1268
         ORG     0.9460    0.9216    0.9337      2092
         PER     0.9770    0.9844    0.9807      3149

   micro avg     0.9899    0.9899    0.9899     51362
   macro avg     0.9608    0.9518    0.9562     51362
weighted avg     0.9898    0.9899    0.9899     51362

F1-macro tok:  0.9561843555672386
F1-micro tok:  0.9899341925937464
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 82889.08110046387
test0_cost_avg: 25.504332646296575
test0_count_sent: 3250.0
test0_total_correct_sent: 3224.0
test0_accuracy_sent: 0.992
test0_count_tok: 51362.0
test0_total_correct_tok: 50817.0
test0_accuracy_tok: 0.9893890424827694
test0_label=0_precision_sent: 0.9754224270353302
test0_label=0_recall_sent: 0.9844961240310077
test0_label=0_f-score_sent: 0.9799382716049382
test0_label=1_precision_sent: 0.9961523662947287
test0_label=1_recall_sent: 0.9938579654510556
test0_label=1_f-score_sent: 0.9950038431975403
test0_precision_macro_sent: 0.9857873966650295
test0_recall_macro_sent: 0.9891770447410317
test0_f-score_macro_sent: 0.9874710574012393
test0_precision_micro_sent: 0.992
test0_recall_micro_sent: 0.992
test0_f-score_micro_sent: 0.992
test0_label=O_precision_tok: 0.9964961457603364
test0_label=O_recall_tok: 0.9976846979583246
test0_label=O_f-score_tok: 0.9970900676646917
test0_label=LOC_precision_tok: 0.957325746799431
test0_label=LOC_recall_tok: 0.9641833810888252
test0_label=LOC_f-score_tok: 0.9607423269093505
test0_label=MISC_precision_tok: 0.9078525641025641
test0_label=MISC_recall_tok: 0.8935331230283912
test0_label=MISC_f-score_tok: 0.9006359300476947
test0_label=ORG_precision_tok: 0.9475786320519222
test0_label=ORG_recall_tok: 0.9072657743785851
test0_label=ORG_f-score_tok: 0.926984126984127
test0_label=PER_precision_tok: 0.9733709273182958
test0_label=PER_recall_tok: 0.9866624325182598
test0_label=PER_f-score_tok: 0.9799716133102034
test0_precision_macro_tok: 0.9565248032065099
test0_recall_macro_tok: 0.9498658817944772
test0_f-score_macro_tok: 0.9530848129832135
test0_precision_micro_tok: 0.9893890424827694
test0_recall_micro_tok: 0.9893890424827694
test0_f-score_micro_tok: 0.9893890424827694
test0_time: 14.660432815551758
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9754    0.9845    0.9799       645
           1     0.9962    0.9939    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9858    0.9892    0.9875      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9874710574012393
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9977    0.9971     42759
         LOC     0.9573    0.9642    0.9607      2094
        MISC     0.9079    0.8935    0.9006      1268
         ORG     0.9476    0.9073    0.9270      2092
         PER     0.9734    0.9867    0.9800      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9565    0.9499    0.9531     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9530848129832135
F1-micro tok:  0.9893890424827694
**************************************************
test1_cost_sum: 73571.62769317627
test1_cost_avg: 21.3065820136624
test1_count_sent: 3453.0
test1_total_correct_sent: 3351.0
test1_accuracy_sent: 0.9704604691572546
test1_count_tok: 46435.0
test1_total_correct_tok: 45443.0
test1_accuracy_tok: 0.9786368041348121
test1_label=0_precision_sent: 0.9528158295281582
test1_label=0_recall_sent: 0.8981348637015782
test1_label=0_f-score_sent: 0.9246676514032497
test1_label=1_precision_sent: 0.9746065808297568
test1_label=1_recall_sent: 0.9887518142235123
test1_label=1_f-score_sent: 0.9816282420749279
test1_precision_macro_sent: 0.9637112051789576
test1_recall_macro_sent: 0.9434433389625453
test1_f-score_macro_sent: 0.9531479467390889
test1_precision_micro_sent: 0.9704604691572546
test1_recall_micro_sent: 0.9704604691572546
test1_f-score_micro_sent: 0.9704604691572546
test1_label=O_precision_tok: 0.9952101764120819
test1_label=O_recall_tok: 0.9921718028338073
test1_label=O_f-score_tok: 0.9936886670412522
test1_label=LOC_precision_tok: 0.8881709741550696
test1_label=LOC_recall_tok: 0.9283116883116883
test1_label=LOC_f-score_tok: 0.9077978155956311
test1_label=MISC_precision_tok: 0.7701030927835052
test1_label=MISC_recall_tok: 0.8137254901960784
test1_label=MISC_f-score_tok: 0.7913135593220338
test1_label=ORG_precision_tok: 0.8887530562347188
test1_label=ORG_recall_tok: 0.8737980769230769
test1_label=ORG_f-score_tok: 0.8812121212121211
test1_label=PER_precision_tok: 0.9684926602219835
test1_label=PER_recall_tok: 0.9754778218535882
test1_label=PER_f-score_tok: 0.9719726913402803
test1_precision_macro_tok: 0.9021459919614717
test1_recall_macro_tok: 0.9166969760236479
test1_f-score_macro_tok: 0.9091969709022637
test1_precision_micro_tok: 0.9786368041348121
test1_recall_micro_tok: 0.9786368041348121
test1_f-score_micro_tok: 0.9786368041348121
test1_time: 14.219215631484985
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9528    0.8981    0.9247       697
           1     0.9746    0.9888    0.9816      2756

   micro avg     0.9705    0.9705    0.9705      3453
   macro avg     0.9637    0.9434    0.9531      3453
weighted avg     0.9702    0.9705    0.9701      3453

F1-macro sent:  0.9531479467390889
F1-micro sent:  0.9704604691572546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9922    0.9937     38323
         LOC     0.8882    0.9283    0.9078      1925
        MISC     0.7701    0.8137    0.7913       918
         ORG     0.8888    0.8738    0.8812      2496
         PER     0.9685    0.9755    0.9720      2773

   micro avg     0.9786    0.9786    0.9786     46435
   macro avg     0.9021    0.9167    0.9092     46435
weighted avg     0.9790    0.9786    0.9788     46435

F1-macro tok:  0.9091969709022637
F1-micro tok:  0.9786368041348121
**************************************************
