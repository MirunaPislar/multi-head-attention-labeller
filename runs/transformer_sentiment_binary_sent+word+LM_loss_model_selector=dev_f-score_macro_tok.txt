to_write_filename: runs/transformer_sentiment_binary_sent+word+LM_loss_model_selector=dev_f-score_macro_tok.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_tok:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'1': 1, '0': 0}
{'N': 1, 'O': 0, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033306.
Parameter count without word embeddings: 3232806.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 420456.90588378906
train_cost_avg: 49.210780183027744
train_count_sent: 8544.0
train_total_correct_sent: 8225.0
train_accuracy_sent: 0.9626638576779026
train_count_tok: 163566.0
train_total_correct_tok: 126105.0
train_accuracy_tok: 0.7709731851362752
train_label=0_precision_sent: 0.10526315789473684
train_label=0_recall_sent: 0.01384083044982699
train_label=0_f-score_sent: 0.024464831804281346
train_label=1_precision_sent: 0.9664942393604514
train_label=1_recall_sent: 0.9958812840702604
train_label=1_f-score_sent: 0.980967722689577
train_precision_macro_sent: 0.5358786986275941
train_recall_macro_sent: 0.5048610572600437
train_f-score_macro_sent: 0.5027162772469291
train_precision_micro_sent: 0.9626638576779026
train_recall_micro_sent: 0.9626638576779026
train_f-score_micro_sent: 0.9626638576779026
train_label=O_precision_tok: 0.7982525545569509
train_label=O_recall_tok: 0.949279033671902
train_label=O_f-score_tok: 0.8672397325692455
train_label=N_precision_tok: 0.5029416708690536
train_label=N_recall_tok: 0.21067455287987608
train_label=N_f-score_tok: 0.29695796734653374
train_label=P_precision_tok: 0.520628078817734
train_label=P_recall_tok: 0.20278210816644682
train_label=P_f-score_tok: 0.2918788297229654
train_precision_macro_tok: 0.6072741014145795
train_recall_macro_tok: 0.45424523157274166
train_f-score_macro_tok: 0.48535884321291495
train_precision_micro_tok: 0.7709731851362752
train_recall_micro_tok: 0.7709731851362752
train_f-score_micro_tok: 0.7709731851362752
train_time: 143.301940202713
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.1053    0.0138    0.0245       289
           1     0.9665    0.9959    0.9810      8255

   micro avg     0.9627    0.9627    0.9627      8544
   macro avg     0.5359    0.5049    0.5027      8544
weighted avg     0.9374    0.9627    0.9486      8544

F1-macro sent:  0.5027162772469291
F1-micro sent:  0.9626638576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7983    0.9493    0.8672    124347
           N     0.5029    0.2107    0.2970     14202
           P     0.5206    0.2028    0.2919     25017

   micro avg     0.7710    0.7710    0.7710    163566
   macro avg     0.6073    0.4542    0.4854    163566
weighted avg     0.7301    0.7710    0.7297    163566

F1-macro tok:  0.48535884321291495
F1-micro tok:  0.7709731851362752
**************************************************
dev_cost_sum: 49654.30090332031
dev_cost_avg: 45.09927420828366
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 17487.0
dev_accuracy_tok: 0.8219892826924885
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8428181321682141
dev_label=O_recall_tok: 0.9522986732489972
dev_label=O_f-score_tok: 0.8942199043893959
dev_label=N_precision_tok: 0.6265223274695535
dev_label=N_recall_tok: 0.49865374259558426
dev_label=N_f-score_tok: 0.5553223388305846
dev_label=P_precision_tok: 0.7597577388963661
dev_label=P_recall_tok: 0.351494396014944
dev_label=P_f-score_tok: 0.48063005534269904
dev_precision_macro_tok: 0.7430327328447112
dev_recall_macro_tok: 0.6008156039531751
dev_f-score_macro_tok: 0.6433907661875599
dev_precision_micro_tok: 0.8219892826924885
dev_recall_micro_tok: 0.8219892826924885
dev_f-score_micro_tok: 0.8219892826924885
dev_time: 8.745738506317139
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8428    0.9523    0.8942     16205
           N     0.6265    0.4987    0.5553      1857
           P     0.7598    0.3515    0.4806      3212

   micro avg     0.8220    0.8220    0.8220     21274
   macro avg     0.7430    0.6008    0.6434     21274
weighted avg     0.8114    0.8220    0.8022     21274

F1-macro tok:  0.6433907661875599
F1-micro tok:  0.8219892826924885
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 371276.82067871094
train_cost_avg: 43.45468406820119
train_count_sent: 8544.0
train_total_correct_sent: 8255.0
train_accuracy_sent: 0.9661750936329588
train_count_tok: 163566.0
train_total_correct_tok: 132487.0
train_accuracy_tok: 0.8099910739395718
train_label=0_precision_sent: 0.5
train_label=0_recall_sent: 0.006920415224913495
train_label=0_f-score_sent: 0.013651877133105802
train_label=1_precision_sent: 0.9663934426229508
train_label=1_recall_sent: 0.9997577225923683
train_label=1_f-score_sent: 0.9827924977671926
train_precision_macro_sent: 0.7331967213114754
train_recall_macro_sent: 0.5033390689086409
train_f-score_macro_sent: 0.4982221874501492
train_precision_micro_sent: 0.9661750936329588
train_recall_micro_sent: 0.9661750936329588
train_f-score_micro_sent: 0.9661750936329588
train_label=O_precision_tok: 0.8328473014665483
train_label=O_recall_tok: 0.9508552679196121
train_label=O_f-score_tok: 0.8879476405582905
train_label=N_precision_tok: 0.6455426814849846
train_label=N_recall_tok: 0.3844528939585974
train_label=N_f-score_tok: 0.48190644307149155
train_label=P_precision_tok: 0.6689240602647999
train_label=P_recall_tok: 0.35140104728784427
train_label=P_f-score_tok: 0.46075630912759763
train_precision_macro_tok: 0.7157713477387776
train_recall_macro_tok: 0.5622364030553513
train_f-score_macro_tok: 0.6102034642524599
train_precision_micro_tok: 0.8099910739395718
train_recall_micro_tok: 0.8099910739395718
train_f-score_micro_tok: 0.8099910739395718
train_time: 141.7912938594818
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5000    0.0069    0.0137       289
           1     0.9664    0.9998    0.9828      8255

   micro avg     0.9662    0.9662    0.9662      8544
   macro avg     0.7332    0.5033    0.4982      8544
weighted avg     0.9506    0.9662    0.9500      8544

F1-macro sent:  0.4982221874501492
F1-micro sent:  0.9661750936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8328    0.9509    0.8879    124347
           N     0.6455    0.3845    0.4819     14202
           P     0.6689    0.3514    0.4608     25017

   micro avg     0.8100    0.8100    0.8100    163566
   macro avg     0.7158    0.5622    0.6102    163566
weighted avg     0.7915    0.8100    0.7874    163566

F1-macro tok:  0.6102034642524599
F1-micro tok:  0.8099910739395718
**************************************************
dev_cost_sum: 48131.448486328125
dev_cost_avg: 43.716120332723094
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 17754.0
dev_accuracy_tok: 0.8345398138572906
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8394529587058323
dev_label=O_recall_tok: 0.9734649799444616
dev_label=O_f-score_tok: 0.9015058433580021
dev_label=N_precision_tok: 0.7401869158878505
dev_label=N_recall_tok: 0.42649434571890144
dev_label=N_f-score_tok: 0.5411684318414759
dev_label=P_precision_tok: 0.8406515580736544
dev_label=P_recall_tok: 0.3695516811955168
dev_label=P_f-score_tok: 0.5134083044982699
dev_precision_macro_tok: 0.8067638108891124
dev_recall_macro_tok: 0.5898370022862932
dev_f-score_macro_tok: 0.652027526565916
dev_precision_micro_tok: 0.8345398138572906
dev_recall_micro_tok: 0.8345398138572906
dev_f-score_micro_tok: 0.8345398138572906
dev_time: 8.175723314285278
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8395    0.9735    0.9015     16205
           N     0.7402    0.4265    0.5412      1857
           P     0.8407    0.3696    0.5134      3212

   micro avg     0.8345    0.8345    0.8345     21274
   macro avg     0.8068    0.5898    0.6520     21274
weighted avg     0.8310    0.8345    0.8115     21274

F1-macro tok:  0.652027526565916
F1-micro tok:  0.8345398138572906
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 361372.12982177734
train_cost_avg: 42.29542717951514
train_count_sent: 8544.0
train_total_correct_sent: 8257.0
train_accuracy_sent: 0.9664091760299626
train_count_tok: 163566.0
train_total_correct_tok: 135714.0
train_accuracy_tok: 0.8297201129819155
train_label=0_precision_sent: 0.6666666666666666
train_label=0_recall_sent: 0.01384083044982699
train_label=0_f-score_sent: 0.027118644067796613
train_label=1_precision_sent: 0.966619817287421
train_label=1_recall_sent: 0.9997577225923683
train_label=1_f-score_sent: 0.9829095456440183
train_precision_macro_sent: 0.8166432419770437
train_recall_macro_sent: 0.5067992765210977
train_f-score_macro_sent: 0.5050140948559074
train_precision_micro_sent: 0.9664091760299626
train_recall_micro_sent: 0.9664091760299626
train_f-score_micro_sent: 0.9664091760299626
train_label=O_precision_tok: 0.8498743403764777
train_label=O_recall_tok: 0.9545545931948499
train_label=O_f-score_tok: 0.8991780614370669
train_label=N_precision_tok: 0.6779548472775564
train_label=N_recall_tok: 0.4313476975073933
train_label=N_f-score_tok: 0.5272398657371546
train_label=P_precision_tok: 0.7326293132440976
train_label=P_recall_tok: 0.4353839389215334
train_label=P_f-score_tok: 0.54618393340688
train_precision_macro_tok: 0.7534861669660439
train_recall_macro_tok: 0.6070954098745922
train_f-score_macro_tok: 0.6575339535270338
train_precision_micro_tok: 0.8297201129819155
train_recall_micro_tok: 0.8297201129819155
train_f-score_micro_tok: 0.8297201129819155
train_time: 141.45403718948364
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.0138    0.0271       289
           1     0.9666    0.9998    0.9829      8255

   micro avg     0.9664    0.9664    0.9664      8544
   macro avg     0.8166    0.5068    0.5050      8544
weighted avg     0.9565    0.9664    0.9506      8544

F1-macro sent:  0.5050140948559074
F1-micro sent:  0.9664091760299626
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8499    0.9546    0.8992    124347
           N     0.6780    0.4313    0.5272     14202
           P     0.7326    0.4354    0.5462     25017

   micro avg     0.8297    0.8297    0.8297    163566
   macro avg     0.7535    0.6071    0.6575    163566
weighted avg     0.8170    0.8297    0.8129    163566

F1-macro tok:  0.6575339535270338
F1-micro tok:  0.8297201129819155
**************************************************
dev_cost_sum: 47216.783264160156
dev_cost_avg: 42.88536172948243
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18272.0
dev_accuracy_tok: 0.8588887844317007
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8740869760647264
dev_label=O_recall_tok: 0.9600123418697932
dev_label=O_f-score_tok: 0.9150369085080727
dev_label=N_precision_tok: 0.7240829346092504
dev_label=N_recall_tok: 0.48896068928379105
dev_label=N_f-score_tok: 0.5837351333976213
dev_label=P_precision_tok: 0.8132313231323133
dev_label=P_recall_tok: 0.5625778331257784
dev_label=P_f-score_tok: 0.6650717703349283
dev_precision_macro_tok: 0.8038004112687633
dev_recall_macro_tok: 0.6705169547597875
dev_f-score_macro_tok: 0.7212812707468741
dev_precision_micro_tok: 0.8588887844317007
dev_recall_micro_tok: 0.8588887844317007
dev_f-score_micro_tok: 0.8588887844317007
dev_time: 8.066191911697388
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8741    0.9600    0.9150     16205
           N     0.7241    0.4890    0.5837      1857
           P     0.8132    0.5626    0.6651      3212

   micro avg     0.8589    0.8589    0.8589     21274
   macro avg     0.8038    0.6705    0.7213     21274
weighted avg     0.8518    0.8589    0.8484     21274

F1-macro tok:  0.7212812707468741
F1-micro tok:  0.8588887844317007
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 354788.7971801758
train_cost_avg: 41.52490603700559
train_count_sent: 8544.0
train_total_correct_sent: 8248.0
train_accuracy_sent: 0.9653558052434457
train_count_tok: 163566.0
train_total_correct_tok: 137955.0
train_accuracy_tok: 0.8434210043652104
train_label=0_precision_sent: 0.23076923076923078
train_label=0_recall_sent: 0.010380622837370242
train_label=0_f-score_sent: 0.01986754966887417
train_label=1_precision_sent: 0.9664752080647052
train_label=1_recall_sent: 0.9987886129618413
train_label=1_f-score_sent: 0.9823662575956154
train_precision_macro_sent: 0.598622219416968
train_recall_macro_sent: 0.5045846178996057
train_f-score_macro_sent: 0.5011169036322448
train_precision_micro_sent: 0.9653558052434457
train_recall_micro_sent: 0.9653558052434457
train_f-score_micro_sent: 0.9653558052434457
train_label=O_precision_tok: 0.8614861196568823
train_label=O_recall_tok: 0.9570797847957732
train_label=O_f-score_tok: 0.9067704920530912
train_label=N_precision_tok: 0.6990730760939857
train_label=N_recall_tok: 0.45669623996620196
train_label=N_f-score_tok: 0.5524701873935265
train_label=P_precision_tok: 0.7717896301802639
train_label=P_recall_tok: 0.49802134548507015
train_label=P_f-score_tok: 0.605393586005831
train_precision_macro_tok: 0.7774496086437107
train_recall_macro_tok: 0.6372657900823484
train_f-score_macro_tok: 0.688211421817483
train_precision_micro_tok: 0.8434210043652104
train_recall_micro_tok: 0.8434210043652104
train_f-score_micro_tok: 0.8434210043652104
train_time: 142.77303004264832
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.2308    0.0104    0.0199       289
           1     0.9665    0.9988    0.9824      8255

   micro avg     0.9654    0.9654    0.9654      8544
   macro avg     0.5986    0.5046    0.5011      8544
weighted avg     0.9416    0.9654    0.9498      8544

F1-macro sent:  0.5011169036322448
F1-micro sent:  0.9653558052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8615    0.9571    0.9068    124347
           N     0.6991    0.4567    0.5525     14202
           P     0.7718    0.4980    0.6054     25017

   micro avg     0.8434    0.8434    0.8434    163566
   macro avg     0.7774    0.6373    0.6882    163566
weighted avg     0.8337    0.8434    0.8299    163566

F1-macro tok:  0.688211421817483
F1-micro tok:  0.8434210043652104
**************************************************
dev_cost_sum: 46612.69873046875
dev_cost_avg: 42.336692761552
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18373.0
dev_accuracy_tok: 0.8636363636363636
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8712624584717608
dev_label=O_recall_tok: 0.9709966059858068
dev_label=O_f-score_tok: 0.9184298847220195
dev_label=N_precision_tok: 0.7723880597014925
dev_label=N_recall_tok: 0.4458804523424879
dev_label=N_f-score_tok: 0.5653806759986343
dev_label=P_precision_tok: 0.8450046685340803
dev_label=P_recall_tok: 0.5635118306351183
dev_label=P_f-score_tok: 0.6761299962644752
dev_precision_macro_tok: 0.8295517289024446
dev_recall_macro_tok: 0.6601296296544711
dev_f-score_macro_tok: 0.7199801856617096
dev_precision_micro_tok: 0.8636363636363636
dev_recall_micro_tok: 0.8636363636363636
dev_f-score_micro_tok: 0.8636363636363636
dev_time: 8.173811674118042
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8713    0.9710    0.9184     16205
           N     0.7724    0.4459    0.5654      1857
           P     0.8450    0.5635    0.6761      3212

   micro avg     0.8636    0.8636    0.8636     21274
   macro avg     0.8296    0.6601    0.7200     21274
weighted avg     0.8587    0.8636    0.8510     21274

F1-macro tok:  0.7199801856617096
F1-micro tok:  0.8636363636363636
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 349103.5021972656
train_cost_avg: 40.859492298369105
train_count_sent: 8544.0
train_total_correct_sent: 8251.0
train_accuracy_sent: 0.9657069288389513
train_count_tok: 163566.0
train_total_correct_tok: 139297.0
train_accuracy_tok: 0.851625643471137
train_label=0_precision_sent: 0.4411764705882353
train_label=0_recall_sent: 0.05190311418685121
train_label=0_f-score_sent: 0.09287925696594428
train_label=1_precision_sent: 0.9678025851938895
train_label=1_recall_sent: 0.9976983646274985
train_label=1_f-score_sent: 0.9825231136295853
train_precision_macro_sent: 0.7044895278910623
train_recall_macro_sent: 0.5248007394071749
train_f-score_macro_sent: 0.5377011852977648
train_precision_micro_sent: 0.9657069288389513
train_recall_micro_sent: 0.9657069288389513
train_f-score_micro_sent: 0.9657069288389513
train_label=O_precision_tok: 0.8679084843815864
train_label=O_recall_tok: 0.9603689674861476
train_label=O_f-score_tok: 0.9118007490236352
train_label=N_precision_tok: 0.716262239250745
train_label=N_recall_tok: 0.4738769187438389
train_label=N_f-score_tok: 0.5703873209594034
train_label=P_precision_tok: 0.7931949806949807
train_label=P_recall_tok: 0.5255626174201543
train_label=P_f-score_tok: 0.6322217680859761
train_precision_macro_tok: 0.7924552347757707
train_recall_macro_tok: 0.6532695012167137
train_f-score_macro_tok: 0.7048032793563381
train_precision_micro_tok: 0.851625643471137
train_recall_micro_tok: 0.851625643471137
train_f-score_micro_tok: 0.851625643471137
train_time: 143.0608103275299
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.4412    0.0519    0.0929       289
           1     0.9678    0.9977    0.9825      8255

   micro avg     0.9657    0.9657    0.9657      8544
   macro avg     0.7045    0.5248    0.5377      8544
weighted avg     0.9500    0.9657    0.9524      8544

F1-macro sent:  0.5377011852977648
F1-micro sent:  0.9657069288389513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8679    0.9604    0.9118    124347
           N     0.7163    0.4739    0.5704     14202
           P     0.7932    0.5256    0.6322     25017

   micro avg     0.8516    0.8516    0.8516    163566
   macro avg     0.7925    0.6533    0.7048    163566
weighted avg     0.8433    0.8516    0.8394    163566

F1-macro tok:  0.7048032793563381
F1-micro tok:  0.851625643471137
**************************************************
dev_cost_sum: 45896.513427734375
dev_cost_avg: 41.6862065646997
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18535.0
dev_accuracy_tok: 0.8712512926577043
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8826246127851309
dev_label=O_recall_tok: 0.9670472076519593
dev_label=O_f-score_tok: 0.9229093050647821
dev_label=N_precision_tok: 0.7441332323996972
dev_label=N_recall_tok: 0.5293484114162628
dev_label=N_f-score_tok: 0.618628067967275
dev_label=P_precision_tok: 0.8557779799818016
dev_label=P_recall_tok: 0.5856164383561644
dev_label=P_f-score_tok: 0.6953789279112755
dev_precision_macro_tok: 0.8275119417222099
dev_recall_macro_tok: 0.6940040191414623
dev_f-score_macro_tok: 0.745638766981111
dev_precision_micro_tok: 0.8712512926577043
dev_recall_micro_tok: 0.8712512926577043
dev_f-score_micro_tok: 0.8712512926577043
dev_time: 8.048599243164062
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8826    0.9670    0.9229     16205
           N     0.7441    0.5293    0.6186      1857
           P     0.8558    0.5856    0.6954      3212

   micro avg     0.8713    0.8713    0.8713     21274
   macro avg     0.8275    0.6940    0.7456     21274
weighted avg     0.8665    0.8713    0.8620     21274

F1-macro tok:  0.745638766981111
F1-micro tok:  0.8712512926577043
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 344510.9076538086
train_cost_avg: 40.321969528769735
train_count_sent: 8544.0
train_total_correct_sent: 8246.0
train_accuracy_sent: 0.9651217228464419
train_count_tok: 163566.0
train_total_correct_tok: 140215.0
train_accuracy_tok: 0.8572380568088722
train_label=0_precision_sent: 0.30434782608695654
train_label=0_recall_sent: 0.02422145328719723
train_label=0_f-score_sent: 0.04487179487179487
train_label=1_precision_sent: 0.9669052928060087
train_label=1_recall_sent: 0.9980617807389461
train_label=1_f-score_sent: 0.9822365283738675
train_precision_macro_sent: 0.6356265594464826
train_recall_macro_sent: 0.5111416170130717
train_f-score_macro_sent: 0.5135541616228312
train_precision_micro_sent: 0.9651217228464419
train_recall_micro_sent: 0.9651217228464419
train_f-score_micro_sent: 0.9651217228464419
train_label=O_precision_tok: 0.872296991878217
train_label=O_recall_tok: 0.9621945040893628
train_label=O_f-score_tok: 0.9150430769113108
train_label=N_precision_tok: 0.7218052949760266
train_label=N_recall_tok: 0.48760737924236025
train_label=N_f-score_tok: 0.5820305933770382
train_label=P_precision_tok: 0.8116597263533611
train_label=P_recall_tok: 0.5453891353879362
train_label=P_f-score_tok: 0.652401558801731
train_precision_macro_tok: 0.8019206710692016
train_recall_macro_tok: 0.6650636729065531
train_f-score_macro_tok: 0.7164917430300267
train_precision_micro_tok: 0.8572380568088722
train_recall_micro_tok: 0.8572380568088722
train_f-score_micro_tok: 0.8572380568088723
train_time: 141.96082949638367
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.3043    0.0242    0.0449       289
           1     0.9669    0.9981    0.9822      8255

   micro avg     0.9651    0.9651    0.9651      8544
   macro avg     0.6356    0.5111    0.5136      8544
weighted avg     0.9445    0.9651    0.9505      8544

F1-macro sent:  0.5135541616228312
F1-micro sent:  0.9651217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8723    0.9622    0.9150    124347
           N     0.7218    0.4876    0.5820     14202
           P     0.8117    0.5454    0.6524     25017

   micro avg     0.8572    0.8572    0.8572    163566
   macro avg     0.8019    0.6651    0.7165    163566
weighted avg     0.8500    0.8572    0.8460    163566

F1-macro tok:  0.7164917430300267
F1-micro tok:  0.8572380568088723
**************************************************
dev_cost_sum: 45390.80450439453
dev_cost_avg: 41.226888741502755
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18632.0
dev_accuracy_tok: 0.8758108489235686
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.88297931962114
dev_label=O_recall_tok: 0.9722307929651343
dev_label=O_f-score_tok: 0.9254581766917294
dev_label=N_precision_tok: 0.7950207468879668
dev_label=N_recall_tok: 0.5158858373721056
dev_label=N_f-score_tok: 0.6257348138471587
dev_label=P_precision_tok: 0.862084456424079
dev_label=P_recall_tok: 0.5974470734744707
dev_label=P_f-score_tok: 0.7057741816844428
dev_precision_macro_tok: 0.8466948409777286
dev_recall_macro_tok: 0.6951879012705703
dev_f-score_macro_tok: 0.7523223907411104
dev_precision_micro_tok: 0.8758108489235686
dev_recall_micro_tok: 0.8758108489235686
dev_f-score_micro_tok: 0.8758108489235686
dev_time: 8.254098653793335
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8830    0.9722    0.9255     16205
           N     0.7950    0.5159    0.6257      1857
           P     0.8621    0.5974    0.7058      3212

   micro avg     0.8758    0.8758    0.8758     21274
   macro avg     0.8467    0.6952    0.7523     21274
weighted avg     0.8721    0.8758    0.8661     21274

F1-macro tok:  0.7523223907411104
F1-micro tok:  0.8758108489235686
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 340381.1364135742
train_cost_avg: 39.83861615327414
train_count_sent: 8544.0
train_total_correct_sent: 8256.0
train_accuracy_sent: 0.9662921348314607
train_count_tok: 163566.0
train_total_correct_tok: 141163.0
train_accuracy_tok: 0.863033882347187
train_label=0_precision_sent: 0.5263157894736842
train_label=0_recall_sent: 0.03460207612456748
train_label=0_f-score_sent: 0.06493506493506494
train_label=1_precision_sent: 0.9672727272727273
train_label=1_recall_sent: 0.9989097516656572
train_label=1_f-score_sent: 0.9828367103694876
train_precision_macro_sent: 0.7467942583732057
train_recall_macro_sent: 0.5167559138951123
train_f-score_macro_sent: 0.5238858876522763
train_precision_micro_sent: 0.9662921348314607
train_recall_micro_sent: 0.9662921348314607
train_f-score_micro_sent: 0.9662921348314607
train_label=O_precision_tok: 0.876442153226042
train_label=O_recall_tok: 0.9652585104586359
train_label=O_f-score_tok: 0.9187087391645459
train_label=N_precision_tok: 0.7378940861322894
train_label=N_recall_tok: 0.5042951696944092
train_label=N_f-score_tok: 0.5991299983269198
train_label=P_precision_tok: 0.8262771996215705
train_label=P_recall_tok: 0.5585801654874685
train_label=P_f-score_tok: 0.6665553674068067
train_precision_macro_tok: 0.8135378129933007
train_recall_macro_tok: 0.6760446152135046
train_f-score_macro_tok: 0.7281313682994242
train_precision_micro_tok: 0.863033882347187
train_recall_micro_tok: 0.863033882347187
train_f-score_micro_tok: 0.863033882347187
train_time: 142.236572265625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5263    0.0346    0.0649       289
           1     0.9673    0.9989    0.9828      8255

   micro avg     0.9663    0.9663    0.9663      8544
   macro avg     0.7468    0.5168    0.5239      8544
weighted avg     0.9524    0.9663    0.9518      8544

F1-macro sent:  0.5238858876522763
F1-micro sent:  0.9662921348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8764    0.9653    0.9187    124347
           N     0.7379    0.5043    0.5991     14202
           P     0.8263    0.5586    0.6666     25017

   micro avg     0.8630    0.8630    0.8630    163566
   macro avg     0.8135    0.6760    0.7281    163566
weighted avg     0.8567    0.8630    0.8524    163566

F1-macro tok:  0.7281313682994242
F1-micro tok:  0.863033882347187
**************************************************
dev_cost_sum: 45084.36993408203
dev_cost_avg: 40.94856488109176
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18683.0
dev_accuracy_tok: 0.87820814139325
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.883006645445915
dev_label=O_recall_tok: 0.9757482258562172
dev_label=O_f-score_tok: 0.927063789868668
dev_label=N_precision_tok: 0.8355640535372849
dev_label=N_recall_tok: 0.47065158858373723
dev_label=N_f-score_tok: 0.6021357216672409
dev_label=P_precision_tok: 0.8604049978457562
dev_label=P_recall_tok: 0.6217310087173101
dev_label=P_f-score_tok: 0.7218507138984277
dev_precision_macro_tok: 0.859658565609652
dev_recall_macro_tok: 0.6893769410524215
dev_f-score_macro_tok: 0.7503500751447789
dev_precision_micro_tok: 0.87820814139325
dev_recall_micro_tok: 0.87820814139325
dev_f-score_micro_tok: 0.87820814139325
dev_time: 8.185498714447021
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8830    0.9757    0.9271     16205
           N     0.8356    0.4707    0.6021      1857
           P     0.8604    0.6217    0.7219      3212

   micro avg     0.8782    0.8782    0.8782     21274
   macro avg     0.8597    0.6894    0.7504     21274
weighted avg     0.8755    0.8782    0.8677     21274

F1-macro tok:  0.7503500751447789
F1-micro tok:  0.87820814139325
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 336333.10595703125
train_cost_avg: 39.36482981706826
train_count_sent: 8544.0
train_total_correct_sent: 8246.0
train_accuracy_sent: 0.9651217228464419
train_count_tok: 163566.0
train_total_correct_tok: 141739.0
train_accuracy_tok: 0.866555396598315
train_label=0_precision_sent: 0.3902439024390244
train_label=0_recall_sent: 0.05536332179930796
train_label=0_f-score_sent: 0.09696969696969697
train_label=1_precision_sent: 0.9678936845819123
train_label=1_recall_sent: 0.9969715324046032
train_label=1_f-score_sent: 0.982217448382862
train_precision_macro_sent: 0.6790687935104683
train_recall_macro_sent: 0.5261674271019556
train_f-score_macro_sent: 0.5395935726762795
train_precision_micro_sent: 0.9651217228464419
train_recall_micro_sent: 0.9651217228464419
train_f-score_micro_sent: 0.9651217228464419
train_label=O_precision_tok: 0.879544638736475
train_label=O_recall_tok: 0.9655560648829485
train_label=O_f-score_tok: 0.9205455925536891
train_label=N_precision_tok: 0.7434295348606565
train_label=N_recall_tok: 0.5278129840867484
train_label=N_f-score_tok: 0.617335803994235
train_label=P_precision_tok: 0.8352379830348727
train_label=P_recall_tok: 0.566774593276572
train_label=P_f-score_tok: 0.6753030266949254
train_precision_macro_tok: 0.8194040522106681
train_recall_macro_tok: 0.6867145474154229
train_f-score_macro_tok: 0.7377281410809499
train_precision_micro_tok: 0.866555396598315
train_recall_micro_tok: 0.866555396598315
train_f-score_micro_tok: 0.866555396598315
train_time: 142.43419766426086
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.3902    0.0554    0.0970       289
           1     0.9679    0.9970    0.9822      8255

   micro avg     0.9651    0.9651    0.9651      8544
   macro avg     0.6791    0.5262    0.5396      8544
weighted avg     0.9484    0.9651    0.9523      8544

F1-macro sent:  0.5395935726762795
F1-micro sent:  0.9651217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8795    0.9656    0.9205    124347
           N     0.7434    0.5278    0.6173     14202
           P     0.8352    0.5668    0.6753     25017

   micro avg     0.8666    0.8666    0.8666    163566
   macro avg     0.8194    0.6867    0.7377    163566
weighted avg     0.8609    0.8666    0.8567    163566

F1-macro tok:  0.7377281410809499
F1-micro tok:  0.866555396598315
**************************************************
dev_cost_sum: 44555.769470214844
dev_cost_avg: 40.46845546795172
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18771.0
dev_accuracy_tok: 0.8823446460468177
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8881334981458591
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9297414933976413
dev_label=N_precision_tok: 0.7603186097031137
dev_label=N_recall_tok: 0.5654281098546042
dev_label=N_f-score_tok: 0.6485484867201977
dev_label=P_precision_tok: 0.9136038186157518
dev_label=P_recall_tok: 0.5958904109589042
dev_label=P_f-score_tok: 0.7213114754098362
dev_precision_macro_tok: 0.8540186421549082
dev_recall_macro_tok: 0.712252733308298
dev_f-score_macro_tok: 0.7665338185092251
dev_precision_micro_tok: 0.8823446460468177
dev_recall_micro_tok: 0.8823446460468177
dev_f-score_micro_tok: 0.8823446460468177
dev_time: 8.118892669677734
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8881    0.9754    0.9297     16205
           N     0.7603    0.5654    0.6485      1857
           P     0.9136    0.5959    0.7213      3212

   micro avg     0.8823    0.8823    0.8823     21274
   macro avg     0.8540    0.7123    0.7665     21274
weighted avg     0.8808    0.8823    0.8737     21274

F1-macro tok:  0.7665338185092251
F1-micro tok:  0.8823446460468177
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 332926.54162597656
train_cost_avg: 38.96612144498789
train_count_sent: 8544.0
train_total_correct_sent: 8257.0
train_accuracy_sent: 0.9664091760299626
train_count_tok: 163566.0
train_total_correct_tok: 142282.0
train_accuracy_tok: 0.8698751574288055
train_label=0_precision_sent: 0.5227272727272727
train_label=0_recall_sent: 0.07958477508650519
train_label=0_f-score_sent: 0.13813813813813813
train_label=1_precision_sent: 0.9687058823529412
train_label=1_recall_sent: 0.9974560872198668
train_label=1_f-score_sent: 0.9828707848403462
train_precision_macro_sent: 0.7457165775401069
train_recall_macro_sent: 0.5385204311531859
train_f-score_macro_sent: 0.5605044614892422
train_precision_micro_sent: 0.9664091760299626
train_recall_micro_sent: 0.9664091760299626
train_f-score_micro_sent: 0.9664091760299626
train_label=O_precision_tok: 0.882253223451019
train_label=O_recall_tok: 0.966826702694878
train_label=O_f-score_tok: 0.922605846193988
train_label=N_precision_tok: 0.7472927741681433
train_label=N_recall_tok: 0.5345021827911561
train_label=N_f-score_tok: 0.6232348111658456
train_label=P_precision_tok: 0.844116445948311
train_label=P_recall_tok: 0.578366710636767
train_label=P_f-score_tok: 0.686417761753404
train_precision_macro_tok: 0.8245541478558245
train_recall_macro_tok: 0.6932318653742672
train_f-score_macro_tok: 0.7440861397044124
train_precision_micro_tok: 0.8698751574288055
train_recall_micro_tok: 0.8698751574288055
train_f-score_micro_tok: 0.8698751574288055
train_time: 142.42742562294006
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5227    0.0796    0.1381       289
           1     0.9687    0.9975    0.9829      8255

   micro avg     0.9664    0.9664    0.9664      8544
   macro avg     0.7457    0.5385    0.5605      8544
weighted avg     0.9536    0.9664    0.9543      8544

F1-macro sent:  0.5605044614892422
F1-micro sent:  0.9664091760299626
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8823    0.9668    0.9226    124347
           N     0.7473    0.5345    0.6232     14202
           P     0.8441    0.5784    0.6864     25017

   micro avg     0.8699    0.8699    0.8699    163566
   macro avg     0.8246    0.6932    0.7441    163566
weighted avg     0.8647    0.8699    0.8605    163566

F1-macro tok:  0.7440861397044124
F1-micro tok:  0.8698751574288055
**************************************************
dev_cost_sum: 44245.46105957031
dev_cost_avg: 40.186613133124716
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 18777.0
dev_accuracy_tok: 0.8826266804550155
dev_label=0_precision_sent: 0.6470588235294118
dev_label=0_recall_sent: 0.2972972972972973
dev_label=0_f-score_sent: 0.40740740740740744
dev_label=1_precision_sent: 0.9760147601476015
dev_label=1_recall_sent: 0.9943609022556391
dev_label=1_f-score_sent: 0.9851024208566108
dev_precision_macro_sent: 0.8115367918385066
dev_recall_macro_sent: 0.6458290997764682
dev_f-score_macro_sent: 0.6962549141320091
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.8901805869074492
dev_label=O_recall_tok: 0.9734032705954953
dev_label=O_f-score_tok: 0.929933677229182
dev_label=N_precision_tok: 0.7353535353535353
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6535008976660682
dev_label=P_precision_tok: 0.9236346060898984
dev_label=P_recall_tok: 0.5949564134495642
dev_label=P_f-score_tok: 0.7237265669380799
dev_precision_macro_tok: 0.8497229094502944
dev_recall_macro_tok: 0.7188016394312826
dev_f-score_macro_tok: 0.7690537139444432
dev_precision_micro_tok: 0.8826266804550155
dev_recall_micro_tok: 0.8826266804550155
dev_f-score_micro_tok: 0.8826266804550155
dev_time: 8.156795740127563
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6471    0.2973    0.4074        37
           1     0.9760    0.9944    0.9851      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.8115    0.6458    0.6963      1101
weighted avg     0.9650    0.9709    0.9657      1101

F1-macro sent:  0.6962549141320091
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8902    0.9734    0.9299     16205
           N     0.7354    0.5880    0.6535      1857
           P     0.9236    0.5950    0.7237      3212

   micro avg     0.8826    0.8826    0.8826     21274
   macro avg     0.8497    0.7188    0.7691     21274
weighted avg     0.8817    0.8826    0.8747     21274

F1-macro tok:  0.7690537139444432
F1-micro tok:  0.8826266804550155
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 329539.4859008789
train_cost_avg: 38.56969638352984
train_count_sent: 8544.0
train_total_correct_sent: 8248.0
train_accuracy_sent: 0.9653558052434457
train_count_tok: 163566.0
train_total_correct_tok: 142836.0
train_accuracy_tok: 0.8732621693995084
train_label=0_precision_sent: 0.4426229508196721
train_label=0_recall_sent: 0.09342560553633218
train_label=0_f-score_sent: 0.15428571428571428
train_label=1_precision_sent: 0.9691146999882118
train_label=1_recall_sent: 0.9958812840702604
train_label=1_f-score_sent: 0.9823156888517147
train_precision_macro_sent: 0.7058688254039419
train_recall_macro_sent: 0.5446534448032964
train_f-score_macro_sent: 0.5683007015687145
train_precision_micro_sent: 0.9653558052434457
train_recall_micro_sent: 0.9653558052434457
train_f-score_micro_sent: 0.9653558052434457
train_label=O_precision_tok: 0.8851704202768502
train_label=O_recall_tok: 0.9678239121168987
train_label=O_f-score_tok: 0.9246537715372353
train_label=N_precision_tok: 0.7543045076417102
train_label=N_recall_tok: 0.5490775947049711
train_label=N_f-score_tok: 0.6355338223308883
train_label=P_precision_tok: 0.8507237984944991
train_label=P_recall_tok: 0.5872806491585721
train_label=P_f-score_tok: 0.6948707640646061
train_precision_macro_tok: 0.8300662421376866
train_recall_macro_tok: 0.7013940519934806
train_f-score_macro_tok: 0.7516861193109099
train_precision_micro_tok: 0.8732621693995084
train_recall_micro_tok: 0.8732621693995084
train_f-score_micro_tok: 0.8732621693995084
train_time: 125.70710182189941
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.4426    0.0934    0.1543       289
           1     0.9691    0.9959    0.9823      8255

   micro avg     0.9654    0.9654    0.9654      8544
   macro avg     0.7059    0.5447    0.5683      8544
weighted avg     0.9513    0.9654    0.9543      8544

F1-macro sent:  0.5683007015687145
F1-micro sent:  0.9653558052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8852    0.9678    0.9247    124347
           N     0.7543    0.5491    0.6355     14202
           P     0.8507    0.5873    0.6949     25017

   micro avg     0.8733    0.8733    0.8733    163566
   macro avg     0.8301    0.7014    0.7517    163566
weighted avg     0.8685    0.8733    0.8644    163566

F1-macro tok:  0.7516861193109099
F1-micro tok:  0.8732621693995084
**************************************************
dev_cost_sum: 43905.79357910156
dev_cost_avg: 39.87810497647735
dev_count_sent: 1101.0
dev_total_correct_sent: 1064.0
dev_accuracy_sent: 0.9663941871026339
dev_count_tok: 21274.0
dev_total_correct_tok: 18844.0
dev_accuracy_tok: 0.8857760646798909
dev_label=0_precision_sent: 0.0
dev_label=0_recall_sent: 0.0
dev_label=0_f-score_sent: 0.0
dev_label=1_precision_sent: 0.9663941871026339
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9829099307159352
dev_precision_macro_sent: 0.48319709355131696
dev_recall_macro_sent: 0.5
dev_f-score_macro_sent: 0.4914549653579676
dev_precision_micro_sent: 0.9663941871026339
dev_recall_micro_sent: 0.9663941871026339
dev_f-score_micro_sent: 0.9663941871026339
dev_label=O_precision_tok: 0.8844787387587432
dev_label=O_recall_tok: 0.9832150570811478
dev_label=O_f-score_tok: 0.9312370320582132
dev_label=N_precision_tok: 0.8282740676496098
dev_label=N_recall_tok: 0.5142703284868066
dev_label=N_f-score_tok: 0.6345514950166113
dev_label=P_precision_tok: 0.9283341243474134
dev_label=P_recall_tok: 0.6089663760896638
dev_label=P_f-score_tok: 0.7354765933446136
dev_precision_macro_tok: 0.8803623102519221
dev_recall_macro_tok: 0.7021505872192061
dev_f-score_macro_tok: 0.7670883734731461
dev_precision_micro_tok: 0.8857760646798909
dev_recall_micro_tok: 0.8857760646798909
dev_f-score_micro_tok: 0.8857760646798909
dev_time: 5.123638868331909
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        37
           1     0.9664    1.0000    0.9829      1064

   micro avg     0.9664    0.9664    0.9664      1101
   macro avg     0.4832    0.5000    0.4915      1101
weighted avg     0.9339    0.9664    0.9499      1101

F1-macro sent:  0.4914549653579676
F1-micro sent:  0.9663941871026339
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8845    0.9832    0.9312     16205
           N     0.8283    0.5143    0.6346      1857
           P     0.9283    0.6090    0.7355      3212

   micro avg     0.8858    0.8858    0.8858     21274
   macro avg     0.8804    0.7022    0.7671     21274
weighted avg     0.8862    0.8858    0.8758     21274

F1-macro tok:  0.7670883734731461
F1-micro tok:  0.8857760646798909
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 326975.1441040039
train_cost_avg: 38.26956274625514
train_count_sent: 8544.0
train_total_correct_sent: 8261.0
train_accuracy_sent: 0.96687734082397
train_count_tok: 163566.0
train_total_correct_tok: 143255.0
train_accuracy_tok: 0.8758238264676033
train_label=0_precision_sent: 0.5681818181818182
train_label=0_recall_sent: 0.08650519031141868
train_label=0_f-score_sent: 0.15015015015015015
train_label=1_precision_sent: 0.9689411764705882
train_label=1_recall_sent: 0.9976983646274985
train_label=1_f-score_sent: 0.9831095195464041
train_precision_macro_sent: 0.7685614973262032
train_recall_macro_sent: 0.5421017774694585
train_f-score_macro_sent: 0.5666298348482771
train_precision_micro_sent: 0.96687734082397
train_recall_micro_sent: 0.96687734082397
train_f-score_micro_sent: 0.96687734082397
train_label=O_precision_tok: 0.8872187649593106
train_label=O_recall_tok: 0.9688291635503872
train_label=O_f-score_tok: 0.9262297602755524
train_label=N_precision_tok: 0.7592219986586184
train_label=N_recall_tok: 0.5579495845655541
train_label=N_f-score_tok: 0.6432079223994479
train_label=P_precision_tok: 0.856780442804428
train_label=P_recall_tok: 0.5939960826637887
train_label=P_f-score_tok: 0.7015887254786242
train_precision_macro_tok: 0.8344070688074523
train_recall_macro_tok: 0.7069249435932434
train_f-score_macro_tok: 0.7570088027178749
train_precision_micro_tok: 0.8758238264676033
train_recall_micro_tok: 0.8758238264676033
train_f-score_micro_tok: 0.8758238264676033
train_time: 93.12556028366089
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5682    0.0865    0.1502       289
           1     0.9689    0.9977    0.9831      8255

   micro avg     0.9669    0.9669    0.9669      8544
   macro avg     0.7686    0.5421    0.5666      8544
weighted avg     0.9554    0.9669    0.9549      8544

F1-macro sent:  0.5666298348482771
F1-micro sent:  0.96687734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8872    0.9688    0.9262    124347
           N     0.7592    0.5579    0.6432     14202
           P     0.8568    0.5940    0.7016     25017

   micro avg     0.8758    0.8758    0.8758    163566
   macro avg     0.8344    0.7069    0.7570    163566
weighted avg     0.8714    0.8758    0.8673    163566

F1-macro tok:  0.7570088027178749
F1-micro tok:  0.8758238264676033
**************************************************
dev_cost_sum: 43514.40393066406
dev_cost_avg: 39.52261937390015
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 18936.0
dev_accuracy_tok: 0.8901005922722572
dev_label=0_precision_sent: 1.0
dev_label=0_recall_sent: 0.08108108108108109
dev_label=0_f-score_sent: 0.15
dev_label=1_precision_sent: 0.9690346083788707
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9842738205365403
dev_precision_macro_sent: 0.9845173041894353
dev_recall_macro_sent: 0.5405405405405406
dev_f-score_macro_sent: 0.5671369102682702
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.8940897811865554
dev_label=O_recall_tok: 0.9783400185128047
dev_label=O_f-score_tok: 0.9343194743200637
dev_label=N_precision_tok: 0.8001531393568146
dev_label=N_recall_tok: 0.5627355950457728
dev_label=N_f-score_tok: 0.6607650964274423
dev_label=P_precision_tok: 0.9110017889087657
dev_label=P_recall_tok: 0.6341843088418431
dev_label=P_f-score_tok: 0.7477973568281939
dev_precision_macro_tok: 0.8684149031507119
dev_recall_macro_tok: 0.7250866408001402
dev_f-score_macro_tok: 0.7809606425252333
dev_precision_micro_tok: 0.8901005922722572
dev_recall_micro_tok: 0.8901005922722572
dev_f-score_micro_tok: 0.8901005922722572
dev_time: 5.081290006637573
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     1.0000    0.0811    0.1500        37
           1     0.9690    1.0000    0.9843      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.9845    0.5405    0.5671      1101
weighted avg     0.9701    0.9691    0.9562      1101

F1-macro sent:  0.5671369102682702
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8941    0.9783    0.9343     16205
           N     0.8002    0.5627    0.6608      1857
           P     0.9110    0.6342    0.7478      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8684    0.7251    0.7810     21274
weighted avg     0.8884    0.8901    0.8823     21274

F1-macro tok:  0.7809606425252333
F1-micro tok:  0.8901005922722572
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 324224.89697265625
train_cost_avg: 37.94767052582587
train_count_sent: 8544.0
train_total_correct_sent: 8259.0
train_accuracy_sent: 0.9666432584269663
train_count_tok: 163566.0
train_total_correct_tok: 143626.0
train_accuracy_tok: 0.8780920240147708
train_label=0_precision_sent: 0.5344827586206896
train_label=0_recall_sent: 0.10726643598615918
train_label=0_f-score_sent: 0.17867435158501443
train_label=1_precision_sent: 0.9695969832665566
train_label=1_recall_sent: 0.9967292549969715
train_label=1_f-score_sent: 0.9829759273639568
train_precision_macro_sent: 0.7520398709436231
train_recall_macro_sent: 0.5519978454915654
train_f-score_macro_sent: 0.5808251394744857
train_precision_micro_sent: 0.9666432584269663
train_recall_micro_sent: 0.9666432584269663
train_f-score_micro_sent: 0.9666432584269663
train_label=O_precision_tok: 0.8896404545823764
train_label=O_recall_tok: 0.9688693736077267
train_label=O_f-score_tok: 0.9275661359366819
train_label=N_precision_tok: 0.7605407449423331
train_label=N_recall_tok: 0.5664695113364315
train_label=N_f-score_tok: 0.6493139628732849
train_label=P_precision_tok: 0.8598508567199863
train_label=P_recall_tok: 0.6037894231922293
train_label=P_f-score_tok: 0.7094213789216607
train_precision_macro_tok: 0.8366773520815652
train_recall_macro_tok: 0.7130427693787958
train_f-score_macro_tok: 0.7621004925772091
train_precision_micro_tok: 0.8780920240147708
train_recall_micro_tok: 0.8780920240147708
train_f-score_micro_tok: 0.8780920240147708
train_time: 93.42996096611023
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5345    0.1073    0.1787       289
           1     0.9696    0.9967    0.9830      8255

   micro avg     0.9666    0.9666    0.9666      8544
   macro avg     0.7520    0.5520    0.5808      8544
weighted avg     0.9549    0.9666    0.9558      8544

F1-macro sent:  0.5808251394744857
F1-micro sent:  0.9666432584269663
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8896    0.9689    0.9276    124347
           N     0.7605    0.5665    0.6493     14202
           P     0.8599    0.6038    0.7094     25017

   micro avg     0.8781    0.8781    0.8781    163566
   macro avg     0.8367    0.7130    0.7621    163566
weighted avg     0.8739    0.8781    0.8700    163566

F1-macro tok:  0.7621004925772091
F1-micro tok:  0.8780920240147708
**************************************************
dev_cost_sum: 43280.37780761719
dev_cost_avg: 39.3100615872999
dev_count_sent: 1101.0
dev_total_correct_sent: 1068.0
dev_accuracy_sent: 0.9700272479564033
dev_count_tok: 21274.0
dev_total_correct_tok: 18941.0
dev_accuracy_tok: 0.8903356209457554
dev_label=0_precision_sent: 0.6
dev_label=0_recall_sent: 0.32432432432432434
dev_label=0_f-score_sent: 0.4210526315789474
dev_label=1_precision_sent: 0.9768732654949122
dev_label=1_recall_sent: 0.9924812030075187
dev_label=1_f-score_sent: 0.9846153846153847
dev_precision_macro_sent: 0.7884366327474561
dev_recall_macro_sent: 0.6584027636659215
dev_f-score_macro_sent: 0.702834008097166
dev_precision_micro_sent: 0.9700272479564033
dev_recall_micro_sent: 0.9700272479564033
dev_f-score_micro_sent: 0.9700272479564033
dev_label=O_precision_tok: 0.892175572519084
dev_label=O_recall_tok: 0.9808701018204258
dev_label=O_f-score_tok: 0.9344228564710031
dev_label=N_precision_tok: 0.8091482649842271
dev_label=N_recall_tok: 0.5525040387722132
dev_label=N_f-score_tok: 0.65664
dev_label=P_precision_tok: 0.9223744292237442
dev_label=P_recall_tok: 0.6288916562889165
dev_label=P_f-score_tok: 0.7478711588300628
dev_precision_macro_tok: 0.8745660889090184
dev_recall_macro_tok: 0.7207552656271852
dev_f-score_macro_tok: 0.7796446717670219
dev_precision_micro_tok: 0.8903356209457554
dev_recall_micro_tok: 0.8903356209457554
dev_f-score_micro_tok: 0.8903356209457554
dev_time: 5.092495441436768
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6000    0.3243    0.4211        37
           1     0.9769    0.9925    0.9846      1064

   micro avg     0.9700    0.9700    0.9700      1101
   macro avg     0.7884    0.6584    0.7028      1101
weighted avg     0.9642    0.9700    0.9657      1101

F1-macro sent:  0.702834008097166
F1-micro sent:  0.9700272479564033
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8922    0.9809    0.9344     16205
           N     0.8091    0.5525    0.6566      1857
           P     0.9224    0.6289    0.7479      3212

   micro avg     0.8903    0.8903    0.8903     21274
   macro avg     0.8746    0.7208    0.7796     21274
weighted avg     0.8895    0.8903    0.8820     21274

F1-macro tok:  0.7796446717670219
F1-micro tok:  0.8903356209457554
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 321769.3592529297
train_cost_avg: 37.66027144814252
train_count_sent: 8544.0
train_total_correct_sent: 8254.0
train_accuracy_sent: 0.966058052434457
train_count_tok: 163566.0
train_total_correct_tok: 144132.0
train_accuracy_tok: 0.8811855764645464
train_label=0_precision_sent: 0.49295774647887325
train_label=0_recall_sent: 0.12110726643598616
train_label=0_f-score_sent: 0.19444444444444445
train_label=1_precision_sent: 0.9700224241708958
train_label=1_recall_sent: 0.9956390066626287
train_label=1_f-score_sent: 0.9826637972262076
train_precision_macro_sent: 0.7314900853248845
train_recall_macro_sent: 0.5583731365493074
train_f-score_macro_sent: 0.588554120835326
train_precision_micro_sent: 0.966058052434457
train_recall_micro_sent: 0.966058052434457
train_f-score_micro_sent: 0.966058052434457
train_label=O_precision_tok: 0.8917113188721777
train_label=O_recall_tok: 0.9702928096375465
train_label=O_f-score_tok: 0.9293438910541802
train_label=N_precision_tok: 0.7715260017050298
train_label=N_recall_tok: 0.573510773130545
train_label=N_f-score_tok: 0.657942566339513
train_label=P_precision_tok: 0.8661319475824673
train_label=P_recall_tok: 0.6129431986249351
train_label=P_f-score_tok: 0.717867091126144
train_precision_macro_tok: 0.8431230893865583
train_recall_macro_tok: 0.7189155937976756
train_f-score_macro_tok: 0.7683845161732791
train_precision_micro_tok: 0.8811855764645464
train_recall_micro_tok: 0.8811855764645464
train_f-score_micro_tok: 0.8811855764645464
train_time: 93.10478234291077
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.4930    0.1211    0.1944       289
           1     0.9700    0.9956    0.9827      8255

   micro avg     0.9661    0.9661    0.9661      8544
   macro avg     0.7315    0.5584    0.5886      8544
weighted avg     0.9539    0.9661    0.9560      8544

F1-macro sent:  0.588554120835326
F1-micro sent:  0.966058052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8917    0.9703    0.9293    124347
           N     0.7715    0.5735    0.6579     14202
           P     0.8661    0.6129    0.7179     25017

   micro avg     0.8812    0.8812    0.8812    163566
   macro avg     0.8431    0.7189    0.7684    163566
weighted avg     0.8774    0.8812    0.8734    163566

F1-macro tok:  0.7683845161732791
F1-micro tok:  0.8811855764645464
**************************************************
dev_cost_sum: 42994.895263671875
dev_cost_avg: 39.05076772358935
dev_count_sent: 1101.0
dev_total_correct_sent: 1066.0
dev_accuracy_sent: 0.9682107175295186
dev_count_tok: 21274.0
dev_total_correct_tok: 18954.0
dev_accuracy_tok: 0.8909466954968506
dev_label=0_precision_sent: 0.5555555555555556
dev_label=0_recall_sent: 0.2702702702702703
dev_label=0_f-score_sent: 0.36363636363636365
dev_label=1_precision_sent: 0.9750692520775623
dev_label=1_recall_sent: 0.9924812030075187
dev_label=1_f-score_sent: 0.9836981835118771
dev_precision_macro_sent: 0.765312403816559
dev_recall_macro_sent: 0.6313757366388946
dev_f-score_macro_sent: 0.6736672735741204
dev_precision_micro_sent: 0.9682107175295186
dev_recall_micro_sent: 0.9682107175295186
dev_f-score_micro_sent: 0.9682107175295186
dev_label=O_precision_tok: 0.8937140925988509
dev_label=O_recall_tok: 0.9791422400493675
dev_label=O_f-score_tok: 0.9344798138932241
dev_label=N_precision_tok: 0.8279030910609858
dev_label=N_recall_tok: 0.5336564351103931
dev_label=N_f-score_tok: 0.6489849377865095
dev_label=P_precision_tok: 0.9022815325010762
dev_label=P_recall_tok: 0.6525529265255293
dev_label=P_f-score_tok: 0.7573622402890695
dev_precision_macro_tok: 0.8746329053869711
dev_recall_macro_tok: 0.7217838672284299
dev_f-score_macro_tok: 0.780275663989601
dev_precision_micro_tok: 0.8909466954968506
dev_recall_micro_tok: 0.8909466954968506
dev_f-score_micro_tok: 0.8909466954968506
dev_time: 4.98511815071106
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5556    0.2703    0.3636        37
           1     0.9751    0.9925    0.9837      1064

   micro avg     0.9682    0.9682    0.9682      1101
   macro avg     0.7653    0.6314    0.6737      1101
weighted avg     0.9610    0.9682    0.9629      1101

F1-macro sent:  0.6736672735741204
F1-micro sent:  0.9682107175295186
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8937    0.9791    0.9345     16205
           N     0.8279    0.5337    0.6490      1857
           P     0.9023    0.6526    0.7574      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8746    0.7218    0.7803     21274
weighted avg     0.8893    0.8909    0.8828     21274

F1-macro tok:  0.780275663989601
F1-micro tok:  0.8909466954968506
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 319249.34338378906
train_cost_avg: 37.365325770574565
train_count_sent: 8544.0
train_total_correct_sent: 8260.0
train_accuracy_sent: 0.9667602996254682
train_count_tok: 163566.0
train_total_correct_tok: 144446.0
train_accuracy_tok: 0.8831052908306127
train_label=0_precision_sent: 0.5384615384615384
train_label=0_recall_sent: 0.12110726643598616
train_label=0_f-score_sent: 0.1977401129943503
train_label=1_precision_sent: 0.9700436372213704
train_label=1_recall_sent: 0.9963658388855239
train_label=1_f-score_sent: 0.9830285645990199
train_precision_macro_sent: 0.7542525878414544
train_recall_macro_sent: 0.5587365526607551
train_f-score_macro_sent: 0.5903843387966851
train_precision_micro_sent: 0.9667602996254682
train_recall_micro_sent: 0.9667602996254682
train_f-score_micro_sent: 0.9667602996254682
train_label=O_precision_tok: 0.8939695997272721
train_label=O_recall_tok: 0.9700756753279131
train_label=O_f-score_tok: 0.9304689910521443
train_label=N_precision_tok: 0.7750465549348231
train_label=N_recall_tok: 0.5861146317420082
train_label=N_f-score_tok: 0.6674685269825996
train_label=P_precision_tok: 0.8660369977086011
train_label=P_recall_tok: 0.6194187952192509
train_label=P_f-score_tok: 0.7222558844092286
train_precision_macro_tok: 0.8450177174568987
train_recall_macro_tok: 0.7252030340963908
train_f-score_macro_tok: 0.7733978008146575
train_precision_micro_tok: 0.8831052908306127
train_recall_micro_tok: 0.8831052908306127
train_f-score_micro_tok: 0.8831052908306128
train_time: 93.35466575622559
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5385    0.1211    0.1977       289
           1     0.9700    0.9964    0.9830      8255

   micro avg     0.9668    0.9668    0.9668      8544
   macro avg     0.7543    0.5587    0.5904      8544
weighted avg     0.9554    0.9668    0.9565      8544

F1-macro sent:  0.5903843387966851
F1-micro sent:  0.9667602996254682
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8940    0.9701    0.9305    124347
           N     0.7750    0.5861    0.6675     14202
           P     0.8660    0.6194    0.7223     25017

   micro avg     0.8831    0.8831    0.8831    163566
   macro avg     0.8450    0.7252    0.7734    163566
weighted avg     0.8794    0.8831    0.8758    163566

F1-macro tok:  0.7733978008146575
F1-micro tok:  0.8831052908306128
**************************************************
dev_cost_sum: 42847.621154785156
dev_cost_avg: 38.917003773646826
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 18969.0
dev_accuracy_tok: 0.8916517815173451
dev_label=0_precision_sent: 0.6190476190476191
dev_label=0_recall_sent: 0.35135135135135137
dev_label=0_f-score_sent: 0.4482758620689656
dev_label=1_precision_sent: 0.9777777777777777
dev_label=1_recall_sent: 0.9924812030075187
dev_label=1_f-score_sent: 0.9850746268656717
dev_precision_macro_sent: 0.7984126984126985
dev_recall_macro_sent: 0.671916277179435
dev_f-score_macro_sent: 0.7166752444673187
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.8977401771519419
dev_label=O_recall_tok: 0.9756865165072508
dev_label=O_f-score_tok: 0.935091817724813
dev_label=N_precision_tok: 0.7879884225759769
dev_label=N_recall_tok: 0.5864297253634895
dev_label=N_f-score_tok: 0.6724297622723063
dev_label=P_precision_tok: 0.9074561403508772
dev_label=P_recall_tok: 0.6441469489414695
dev_label=P_f-score_tok: 0.7534595775673707
dev_precision_macro_tok: 0.8643949133595986
dev_recall_macro_tok: 0.73542106360407
dev_f-score_macro_tok: 0.7869937191881634
dev_precision_micro_tok: 0.8916517815173451
dev_recall_micro_tok: 0.8916517815173451
dev_f-score_micro_tok: 0.8916517815173451
dev_time: 5.019733667373657
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6190    0.3514    0.4483        37
           1     0.9778    0.9925    0.9851      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.7984    0.6719    0.7167      1101
weighted avg     0.9657    0.9709    0.9670      1101

F1-macro sent:  0.7166752444673187
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8977    0.9757    0.9351     16205
           N     0.7880    0.5864    0.6724      1857
           P     0.9075    0.6441    0.7535      3212

   micro avg     0.8917    0.8917    0.8917     21274
   macro avg     0.8644    0.7354    0.7870     21274
weighted avg     0.8896    0.8917    0.8847     21274

F1-macro tok:  0.7869937191881634
F1-micro tok:  0.8916517815173451
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 317020.7941894531
train_cost_avg: 37.1044937019491
train_count_sent: 8544.0
train_total_correct_sent: 8263.0
train_accuracy_sent: 0.9671114232209738
train_count_tok: 163566.0
train_total_correct_tok: 144836.0
train_accuracy_tok: 0.8854896494381473
train_label=0_precision_sent: 0.5454545454545454
train_label=0_recall_sent: 0.16608996539792387
train_label=0_f-score_sent: 0.2546419098143236
train_label=1_precision_sent: 0.9714995269631032
train_label=1_recall_sent: 0.9951544518473653
train_label=1_f-score_sent: 0.9831847286218659
train_precision_macro_sent: 0.7584770362088242
train_recall_macro_sent: 0.5806222086226446
train_f-score_macro_sent: 0.6189133192180948
train_precision_micro_sent: 0.9671114232209738
train_recall_micro_sent: 0.9671114232209738
train_f-score_micro_sent: 0.9671114232209738
train_label=O_precision_tok: 0.8958900653701464
train_label=O_recall_tok: 0.9709924646352546
train_label=O_f-score_tok: 0.9319306262011903
train_label=N_precision_tok: 0.7783137000278267
train_label=N_recall_tok: 0.5908322771440642
train_label=N_f-score_tok: 0.6717367810110875
train_label=P_precision_tok: 0.8718219162873321
train_label=P_recall_tok: 0.627773114282288
train_label=P_f-score_tok: 0.7299388812716413
train_precision_macro_tok: 0.8486752272284351
train_recall_macro_tok: 0.7298659520205355
train_f-score_macro_tok: 0.777868762827973
train_precision_micro_tok: 0.8854896494381473
train_recall_micro_tok: 0.8854896494381473
train_f-score_micro_tok: 0.8854896494381473
train_time: 91.75605487823486
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5455    0.1661    0.2546       289
           1     0.9715    0.9952    0.9832      8255

   micro avg     0.9671    0.9671    0.9671      8544
   macro avg     0.7585    0.5806    0.6189      8544
weighted avg     0.9571    0.9671    0.9585      8544

F1-macro sent:  0.6189133192180948
F1-micro sent:  0.9671114232209738
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9710    0.9319    124347
           N     0.7783    0.5908    0.6717     14202
           P     0.8718    0.6278    0.7299     25017

   micro avg     0.8855    0.8855    0.8855    163566
   macro avg     0.8487    0.7299    0.7779    163566
weighted avg     0.8820    0.8855    0.8784    163566

F1-macro tok:  0.777868762827973
F1-micro tok:  0.8854896494381473
**************************************************
dev_cost_sum: 42586.02813720703
dev_cost_avg: 38.67940793570121
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19006.0
dev_accuracy_tok: 0.8933909937012315
dev_label=0_precision_sent: 0.6363636363636364
dev_label=0_recall_sent: 0.3783783783783784
dev_label=0_f-score_sent: 0.4745762711864407
dev_label=1_precision_sent: 0.9786839666357738
dev_label=1_recall_sent: 0.9924812030075187
dev_label=1_f-score_sent: 0.9855342977134857
dev_precision_macro_sent: 0.807523801499705
dev_recall_macro_sent: 0.6854297906929485
dev_f-score_macro_sent: 0.7300552844499631
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9010838562464347
dev_label=O_recall_tok: 0.9747608762727553
dev_label=O_f-score_tok: 0.9364754705795169
dev_label=N_precision_tok: 0.7746870653685675
dev_label=N_recall_tok: 0.5998922994076468
dev_label=N_f-score_tok: 0.6761760242792109
dev_label=P_precision_tok: 0.9089332176929749
dev_label=P_recall_tok: 0.6525529265255293
dev_label=P_f-score_tok: 0.7596955418629938
dev_precision_macro_tok: 0.8615680464359924
dev_recall_macro_tok: 0.7424020340686438
dev_f-score_macro_tok: 0.7907823455739073
dev_precision_micro_tok: 0.8933909937012315
dev_recall_micro_tok: 0.8933909937012315
dev_f-score_micro_tok: 0.8933909937012315
dev_time: 4.9733521938323975
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6364    0.3784    0.4746        37
           1     0.9787    0.9925    0.9855      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.8075    0.6854    0.7301      1101
weighted avg     0.9672    0.9718    0.9684      1101

F1-macro sent:  0.7300552844499631
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9011    0.9748    0.9365     16205
           N     0.7747    0.5999    0.6762      1857
           P     0.9089    0.6526    0.7597      3212

   micro avg     0.8934    0.8934    0.8934     21274
   macro avg     0.8616    0.7424    0.7908     21274
weighted avg     0.8912    0.8934    0.8871     21274

F1-macro tok:  0.7907823455739073
F1-micro tok:  0.8933909937012315
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 314924.5969848633
train_cost_avg: 36.85915226882763
train_count_sent: 8544.0
train_total_correct_sent: 8268.0
train_accuracy_sent: 0.9676966292134831
train_count_tok: 163566.0
train_total_correct_tok: 145007.0
train_accuracy_tok: 0.8865350989814509
train_label=0_precision_sent: 0.5670103092783505
train_label=0_recall_sent: 0.1903114186851211
train_label=0_f-score_sent: 0.2849740932642487
train_label=1_precision_sent: 0.972297857227418
train_label=1_recall_sent: 0.9949121744397335
train_label=1_f-score_sent: 0.9834750329301879
train_precision_macro_sent: 0.7696540832528842
train_recall_macro_sent: 0.5926117965624272
train_f-score_macro_sent: 0.6342245630972183
train_precision_micro_sent: 0.9676966292134831
train_recall_micro_sent: 0.9676966292134831
train_f-score_micro_sent: 0.9676966292134831
train_label=O_precision_tok: 0.897267044736627
train_label=O_recall_tok: 0.9708396664173643
train_label=O_f-score_tok: 0.9326045810962185
train_label=N_precision_tok: 0.7763924281033855
train_label=N_recall_tok: 0.6006900436558231
train_label=N_f-score_tok: 0.6773322747121874
train_label=P_precision_tok: 0.8735791516495702
train_label=P_recall_tok: 0.6297717552064596
train_label=P_f-score_tok: 0.7319056025271764
train_precision_macro_tok: 0.8490795414965276
train_recall_macro_tok: 0.7337671550932156
train_f-score_macro_tok: 0.7806141527785274
train_precision_micro_tok: 0.8865350989814509
train_recall_micro_tok: 0.8865350989814509
train_f-score_micro_tok: 0.8865350989814509
train_time: 92.71532368659973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5670    0.1903    0.2850       289
           1     0.9723    0.9949    0.9835      8255

   micro avg     0.9677    0.9677    0.9677      8544
   macro avg     0.7697    0.5926    0.6342      8544
weighted avg     0.9586    0.9677    0.9598      8544

F1-macro sent:  0.6342245630972183
F1-micro sent:  0.9676966292134831
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8973    0.9708    0.9326    124347
           N     0.7764    0.6007    0.6773     14202
           P     0.8736    0.6298    0.7319     25017

   micro avg     0.8865    0.8865    0.8865    163566
   macro avg     0.8491    0.7338    0.7806    163566
weighted avg     0.8831    0.8865    0.8797    163566

F1-macro tok:  0.7806141527785274
F1-micro tok:  0.8865350989814509
**************************************************
dev_cost_sum: 42441.099609375
dev_cost_avg: 38.547774395435965
dev_count_sent: 1101.0
dev_total_correct_sent: 1066.0
dev_accuracy_sent: 0.9682107175295186
dev_count_tok: 21274.0
dev_total_correct_tok: 19017.0
dev_accuracy_tok: 0.8939080567829275
dev_label=0_precision_sent: 0.75
dev_label=0_recall_sent: 0.08108108108108109
dev_label=0_f-score_sent: 0.14634146341463414
dev_label=1_precision_sent: 0.9690063810391978
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.983803794539565
dev_precision_macro_sent: 0.8595031905195989
dev_recall_macro_sent: 0.5400706157285105
dev_f-score_macro_sent: 0.5650726289770995
dev_precision_micro_sent: 0.9682107175295186
dev_recall_micro_sent: 0.9682107175295186
dev_f-score_micro_sent: 0.9682107175295186
dev_label=O_precision_tok: 0.9006041262965918
dev_label=O_recall_tok: 0.9751311323665536
dev_label=O_f-score_tok: 0.9363870700127405
dev_label=N_precision_tok: 0.8044117647058824
dev_label=N_recall_tok: 0.589122240172321
dev_label=N_f-score_tok: 0.6801367733913584
dev_label=P_precision_tok: 0.8956925675675675
dev_label=P_recall_tok: 0.6603362391033624
dev_label=P_f-score_tok: 0.7602150537634408
dev_precision_macro_tok: 0.8669028195233471
dev_recall_macro_tok: 0.7415298705474123
dev_f-score_macro_tok: 0.7922462990558466
dev_precision_micro_tok: 0.8939080567829275
dev_recall_micro_tok: 0.8939080567829275
dev_f-score_micro_tok: 0.8939080567829275
dev_time: 4.962099313735962
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7500    0.0811    0.1463        37
           1     0.9690    0.9991    0.9838      1064

   micro avg     0.9682    0.9682    0.9682      1101
   macro avg     0.8595    0.5401    0.5651      1101
weighted avg     0.9616    0.9682    0.9557      1101

F1-macro sent:  0.5650726289770995
F1-micro sent:  0.9682107175295186
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9006    0.9751    0.9364     16205
           N     0.8044    0.5891    0.6801      1857
           P     0.8957    0.6603    0.7602      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8669    0.7415    0.7922     21274
weighted avg     0.8915    0.8939    0.8874     21274

F1-macro tok:  0.7922462990558466
F1-micro tok:  0.8939080567829275
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 313202.9407348633
train_cost_avg: 36.65764755791939
train_count_sent: 8544.0
train_total_correct_sent: 8267.0
train_accuracy_sent: 0.9675795880149812
train_count_tok: 163566.0
train_total_correct_tok: 145235.0
train_accuracy_tok: 0.8879290317058557
train_label=0_precision_sent: 0.5714285714285714
train_label=0_recall_sent: 0.16608996539792387
train_label=0_f-score_sent: 0.257372654155496
train_label=1_precision_sent: 0.9715130023640662
train_label=1_recall_sent: 0.9956390066626287
train_label=1_f-score_sent: 0.9834280586299731
train_precision_macro_sent: 0.7714707868963189
train_recall_macro_sent: 0.5808644860302763
train_f-score_macro_sent: 0.6204003563927345
train_precision_micro_sent: 0.9675795880149812
train_recall_micro_sent: 0.9675795880149812
train_f-score_micro_sent: 0.9675795880149812
train_label=O_precision_tok: 0.8989997542210669
train_label=O_recall_tok: 0.9707190362453457
train_label=O_f-score_tok: 0.9334838794496818
train_label=N_precision_tok: 0.7796901893287436
train_label=N_recall_tok: 0.6060414026193494
train_label=N_f-score_tok: 0.6819856582544273
train_label=P_precision_tok: 0.871960569550931
train_label=P_recall_tok: 0.6364472158931926
train_label=P_f-score_tok: 0.7358181019941309
train_precision_macro_tok: 0.8502168377002471
train_recall_macro_tok: 0.7377358849192959
train_f-score_macro_tok: 0.7837625465660799
train_precision_micro_tok: 0.8879290317058557
train_recall_micro_tok: 0.8879290317058557
train_f-score_micro_tok: 0.8879290317058557
train_time: 93.11199879646301
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5714    0.1661    0.2574       289
           1     0.9715    0.9956    0.9834      8255

   micro avg     0.9676    0.9676    0.9676      8544
   macro avg     0.7715    0.5809    0.6204      8544
weighted avg     0.9580    0.9676    0.9589      8544

F1-macro sent:  0.6204003563927345
F1-micro sent:  0.9675795880149812
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9707    0.9335    124347
           N     0.7797    0.6060    0.6820     14202
           P     0.8720    0.6364    0.7358     25017

   micro avg     0.8879    0.8879    0.8879    163566
   macro avg     0.8502    0.7377    0.7838    163566
weighted avg     0.8845    0.8879    0.8814    163566

F1-macro tok:  0.7837625465660799
F1-micro tok:  0.8879290317058557
**************************************************
dev_cost_sum: 42226.49548339844
dev_cost_avg: 38.352856933150264
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 19036.0
dev_accuracy_tok: 0.8948011657422206
dev_label=0_precision_sent: 0.7272727272727273
dev_label=0_recall_sent: 0.21621621621621623
dev_label=0_f-score_sent: 0.33333333333333337
dev_label=1_precision_sent: 0.9733944954128441
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9851439182915506
dev_precision_macro_sent: 0.8503336113427857
dev_recall_macro_sent: 0.6066983336720179
dev_f-score_macro_sent: 0.659238625812442
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.8965809072444143
dev_label=O_recall_tok: 0.9806232644245603
dev_label=O_f-score_tok: 0.9367207993162191
dev_label=N_precision_tok: 0.8199532346063912
dev_label=N_recall_tok: 0.5665051157781368
dev_label=N_f-score_tok: 0.6700636942675159
dev_label=P_precision_tok: 0.9232465813850904
dev_label=P_recall_tok: 0.6516189290161893
dev_label=P_f-score_tok: 0.7640080306625296
dev_precision_macro_tok: 0.8799269077452987
dev_recall_macro_tok: 0.7329157697396288
dev_f-score_macro_tok: 0.790264174748755
dev_precision_micro_tok: 0.8948011657422206
dev_recall_micro_tok: 0.8948011657422206
dev_f-score_micro_tok: 0.8948011657422205
dev_time: 4.9972052574157715
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7273    0.2162    0.3333        37
           1     0.9734    0.9972    0.9851      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.8503    0.6067    0.6592      1101
weighted avg     0.9651    0.9709    0.9632      1101

F1-macro sent:  0.659238625812442
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9806    0.9367     16205
           N     0.8200    0.5665    0.6701      1857
           P     0.9232    0.6516    0.7640      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8799    0.7329    0.7903     21274
weighted avg     0.8939    0.8948    0.8874     21274

F1-macro tok:  0.790264174748755
F1-micro tok:  0.8948011657422205
**************************************************
Best epoch: 15
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 310822.28771972656
train_cost_avg: 36.37901307581069
train_count_sent: 8544.0
train_total_correct_sent: 8269.0
train_accuracy_sent: 0.9678136704119851
train_count_tok: 163566.0
train_total_correct_tok: 145689.0
train_accuracy_tok: 0.8907046696746268
train_label=0_precision_sent: 0.5813953488372093
train_label=0_recall_sent: 0.17301038062283736
train_label=0_f-score_sent: 0.26666666666666666
train_label=1_precision_sent: 0.9717427287774888
train_label=1_recall_sent: 0.9956390066626287
train_label=1_f-score_sent: 0.9835457428349189
train_precision_macro_sent: 0.7765690388073491
train_recall_macro_sent: 0.5843246936427331
train_f-score_macro_sent: 0.6251062047507928
train_precision_micro_sent: 0.9678136704119851
train_recall_micro_sent: 0.9678136704119851
train_f-score_micro_sent: 0.9678136704119851
train_label=O_precision_tok: 0.901253076750951
train_label=O_recall_tok: 0.9717242876788342
train_label=O_f-score_tok: 0.9351629343270761
train_label=N_precision_tok: 0.7850904834788872
train_label=N_recall_tok: 0.6139980284466976
train_label=N_f-score_tok: 0.6890829349243351
train_label=P_precision_tok: 0.8775898635053565
train_label=P_recall_tok: 0.6450813446856137
train_label=P_f-score_tok: 0.7435838363359905
train_precision_macro_tok: 0.8546444745783983
train_recall_macro_tok: 0.7436012202703819
train_f-score_macro_tok: 0.789276568529134
train_precision_micro_tok: 0.8907046696746268
train_recall_micro_tok: 0.8907046696746268
train_f-score_micro_tok: 0.8907046696746268
train_time: 93.49891519546509
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5814    0.1730    0.2667       289
           1     0.9717    0.9956    0.9835      8255

   micro avg     0.9678    0.9678    0.9678      8544
   macro avg     0.7766    0.5843    0.6251      8544
weighted avg     0.9585    0.9678    0.9593      8544

F1-macro sent:  0.6251062047507928
F1-micro sent:  0.9678136704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9013    0.9717    0.9352    124347
           N     0.7851    0.6140    0.6891     14202
           P     0.8776    0.6451    0.7436     25017

   micro avg     0.8907    0.8907    0.8907    163566
   macro avg     0.8546    0.7436    0.7893    163566
weighted avg     0.8875    0.8907    0.8845    163566

F1-macro tok:  0.789276568529134
F1-micro tok:  0.8907046696746268
**************************************************
dev_cost_sum: 42206.072998046875
dev_cost_avg: 38.3343079001334
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19031.0
dev_accuracy_tok: 0.8945661370687223
dev_label=0_precision_sent: 0.6363636363636364
dev_label=0_recall_sent: 0.1891891891891892
dev_label=0_f-score_sent: 0.2916666666666667
dev_label=1_precision_sent: 0.9724770642201835
dev_label=1_recall_sent: 0.9962406015037594
dev_label=1_f-score_sent: 0.9842154131847726
dev_precision_macro_sent: 0.80442035029191
dev_recall_macro_sent: 0.5927148953464743
dev_f-score_macro_sent: 0.6379410399257196
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.89316693715373
dev_label=O_recall_tok: 0.9848812095032398
dev_label=O_f-score_tok: 0.9367846451840113
dev_label=N_precision_tok: 0.8487394957983193
dev_label=N_recall_tok: 0.5438879913839526
dev_label=N_f-score_tok: 0.6629471611421069
dev_label=P_precision_tok: 0.9304740406320542
dev_label=P_recall_tok: 0.6416562889165629
dev_label=P_f-score_tok: 0.7595356550580431
dev_precision_macro_tok: 0.8907934911947012
dev_recall_macro_tok: 0.7234751632679184
dev_f-score_macro_tok: 0.7864224871280537
dev_precision_micro_tok: 0.8945661370687223
dev_recall_micro_tok: 0.8945661370687223
dev_f-score_micro_tok: 0.8945661370687222
dev_time: 4.862359285354614
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6364    0.1892    0.2917        37
           1     0.9725    0.9962    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8044    0.5927    0.6379      1101
weighted avg     0.9612    0.9691    0.9609      1101

F1-macro sent:  0.6379410399257196
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8932    0.9849    0.9368     16205
           N     0.8487    0.5439    0.6629      1857
           P     0.9305    0.6417    0.7595      3212

   micro avg     0.8946    0.8946    0.8946     21274
   macro avg     0.8908    0.7235    0.7864     21274
weighted avg     0.8949    0.8946    0.8861     21274

F1-macro tok:  0.7864224871280537
F1-micro tok:  0.8945661370687222
**************************************************
Best epoch: 15
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 309051.31579589844
train_cost_avg: 36.17173639933268
train_count_sent: 8544.0
train_total_correct_sent: 8270.0
train_accuracy_sent: 0.9679307116104869
train_count_tok: 163566.0
train_total_correct_tok: 145925.0
train_accuracy_tok: 0.8921475123191861
train_label=0_precision_sent: 0.5675675675675675
train_label=0_recall_sent: 0.2179930795847751
train_label=0_f-score_sent: 0.315
train_label=1_precision_sent: 0.9732005217597534
train_label=1_recall_sent: 0.9941853422168383
train_label=1_f-score_sent: 0.983581016299137
train_precision_macro_sent: 0.7703840446636605
train_recall_macro_sent: 0.6060892109008067
train_f-score_macro_sent: 0.6492905081495685
train_precision_micro_sent: 0.9679307116104869
train_recall_micro_sent: 0.9679307116104869
train_f-score_micro_sent: 0.9679307116104869
train_label=O_precision_tok: 0.9029793278755934
train_label=O_recall_tok: 0.9712980610710351
train_label=O_f-score_tok: 0.935893561460198
train_label=N_precision_tok: 0.789210432297249
train_label=N_recall_tok: 0.6221658921278693
train_label=N_f-score_tok: 0.6958028191196157
train_label=P_precision_tok: 0.876228847703465
train_label=P_recall_tok: 0.6519966422832474
train_label=P_f-score_tok: 0.7476622662266226
train_precision_macro_tok: 0.8561395359587691
train_recall_macro_tok: 0.7484868651607174
train_f-score_macro_tok: 0.7931195489354788
train_precision_micro_tok: 0.8921475123191861
train_recall_micro_tok: 0.8921475123191861
train_f-score_micro_tok: 0.8921475123191861
train_time: 93.71404242515564
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5676    0.2180    0.3150       289
           1     0.9732    0.9942    0.9836      8255

   micro avg     0.9679    0.9679    0.9679      8544
   macro avg     0.7704    0.6061    0.6493      8544
weighted avg     0.9595    0.9679    0.9610      8544

F1-macro sent:  0.6492905081495685
F1-micro sent:  0.9679307116104869
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9030    0.9713    0.9359    124347
           N     0.7892    0.6222    0.6958     14202
           P     0.8762    0.6520    0.7477     25017

   micro avg     0.8921    0.8921    0.8921    163566
   macro avg     0.8561    0.7485    0.7931    163566
weighted avg     0.8890    0.8921    0.8863    163566

F1-macro tok:  0.7931195489354788
F1-micro tok:  0.8921475123191861
**************************************************
dev_cost_sum: 41922.15075683594
dev_cost_avg: 38.07643120511893
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=0_precision_sent: 0.8
dev_label=0_recall_sent: 0.21621621621621623
dev_label=0_f-score_sent: 0.3404255319148936
dev_label=1_precision_sent: 0.9734188817598534
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9856148491879351
dev_precision_macro_sent: 0.8867094408799268
dev_recall_macro_sent: 0.607168258484048
dev_f-score_macro_sent: 0.6630201905514144
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.903928632698576
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9383236376587915
dev_label=N_precision_tok: 0.80835734870317
dev_label=N_recall_tok: 0.6042003231017771
dev_label=N_f-score_tok: 0.6915254237288135
dev_label=P_precision_tok: 0.8987077949145478
dev_label=P_recall_tok: 0.6712328767123288
dev_label=P_f-score_tok: 0.7684904651577259
dev_precision_macro_tok: 0.870331258772098
dev_recall_macro_tok: 0.7502909596418305
dev_f-score_macro_tok: 0.7994465088484436
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 4.947449207305908
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8000    0.2162    0.3404        37
           1     0.9734    0.9981    0.9856      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.8867    0.6072    0.6630      1101
weighted avg     0.9676    0.9718    0.9639      1101

F1-macro sent:  0.6630201905514144
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9039    0.9754    0.9383     16205
           N     0.8084    0.6042    0.6915      1857
           P     0.8987    0.6712    0.7685      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8703    0.7503    0.7994     21274
weighted avg     0.8948    0.8971    0.8911     21274

F1-macro tok:  0.7994465088484436
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 307539.37561035156
train_cost_avg: 35.994777107953134
train_count_sent: 8544.0
train_total_correct_sent: 8254.0
train_accuracy_sent: 0.966058052434457
train_count_tok: 163566.0
train_total_correct_tok: 146151.0
train_accuracy_tok: 0.8935292175635523
train_label=0_precision_sent: 0.49514563106796117
train_label=0_recall_sent: 0.17647058823529413
train_label=0_f-score_sent: 0.2602040816326531
train_label=1_precision_sent: 0.9718042885913991
train_label=1_recall_sent: 0.9937007874015747
train_label=1_f-score_sent: 0.9826305701964542
train_precision_macro_sent: 0.7334749598296801
train_recall_macro_sent: 0.5850856878184344
train_f-score_macro_sent: 0.6214173259145537
train_precision_micro_sent: 0.966058052434457
train_recall_micro_sent: 0.966058052434457
train_f-score_micro_sent: 0.966058052434457
train_label=O_precision_tok: 0.9047982976682851
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9367947837757116
train_label=N_precision_tok: 0.7893345085940943
train_label=N_recall_tok: 0.6305449936628644
train_label=N_f-score_tok: 0.7010607899166243
train_label=P_precision_tok: 0.8763661566348563
train_label=P_recall_tok: 0.6570731902306431
train_label=P_f-score_tok: 0.7510394297985106
train_precision_macro_tok: 0.8568329876324118
train_recall_macro_tok: 0.7529184682450616
train_f-score_macro_tok: 0.7962983344969489
train_precision_micro_tok: 0.8935292175635523
train_recall_micro_tok: 0.8935292175635523
train_f-score_micro_tok: 0.8935292175635523
train_time: 92.1853997707367
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.4951    0.1765    0.2602       289
           1     0.9718    0.9937    0.9826      8255

   micro avg     0.9661    0.9661    0.9661      8544
   macro avg     0.7335    0.5851    0.6214      8544
weighted avg     0.9557    0.9661    0.9582      8544

F1-macro sent:  0.6214173259145537
F1-micro sent:  0.966058052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9711    0.9368    124347
           N     0.7893    0.6305    0.7011     14202
           P     0.8764    0.6571    0.7510     25017

   micro avg     0.8935    0.8935    0.8935    163566
   macro avg     0.8568    0.7529    0.7963    163566
weighted avg     0.8904    0.8935    0.8879    163566

F1-macro tok:  0.7962983344969489
F1-micro tok:  0.8935292175635523
**************************************************
dev_cost_sum: 41841.844299316406
dev_cost_avg: 38.00349164333915
dev_count_sent: 1101.0
dev_total_correct_sent: 1065.0
dev_accuracy_sent: 0.9673024523160763
dev_count_tok: 21274.0
dev_total_correct_tok: 19057.0
dev_accuracy_tok: 0.8957882861709129
dev_label=0_precision_sent: 0.6666666666666666
dev_label=0_recall_sent: 0.05405405405405406
dev_label=0_f-score_sent: 0.1
dev_label=1_precision_sent: 0.9681238615664846
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.9833487511563367
dev_precision_macro_sent: 0.8173952641165756
dev_recall_macro_sent: 0.526557102214997
dev_f-score_macro_sent: 0.5416743755781683
dev_precision_micro_sent: 0.9673024523160763
dev_recall_micro_sent: 0.9673024523160763
dev_f-score_micro_sent: 0.9673024523160763
dev_label=O_precision_tok: 0.904838431957757
dev_label=O_recall_tok: 0.9728478864547979
dev_label=O_f-score_tok: 0.9376115142143452
dev_label=N_precision_tok: 0.7926914968376669
dev_label=N_recall_tok: 0.6074313408723748
dev_label=N_f-score_tok: 0.6878048780487804
dev_label=P_precision_tok: 0.8912685337726524
dev_label=P_recall_tok: 0.6737235367372354
dev_label=P_f-score_tok: 0.7673758865248226
dev_precision_macro_tok: 0.8629328208560255
dev_recall_macro_tok: 0.751334254688136
dev_f-score_macro_tok: 0.7975974262626494
dev_precision_micro_tok: 0.8957882861709129
dev_recall_micro_tok: 0.8957882861709129
dev_f-score_micro_tok: 0.8957882861709129
dev_time: 4.802560329437256
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.0541    0.1000        37
           1     0.9681    0.9991    0.9833      1064

   micro avg     0.9673    0.9673    0.9673      1101
   macro avg     0.8174    0.5266    0.5417      1101
weighted avg     0.9580    0.9673    0.9537      1101

F1-macro sent:  0.5416743755781683
F1-micro sent:  0.9673024523160763
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9728    0.9376     16205
           N     0.7927    0.6074    0.6878      1857
           P     0.8913    0.6737    0.7674      3212

   micro avg     0.8958    0.8958    0.8958     21274
   macro avg     0.8629    0.7513    0.7976     21274
weighted avg     0.8930    0.8958    0.8901     21274

F1-macro tok:  0.7975974262626494
F1-micro tok:  0.8957882861709129
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 305707.1240234375
train_cost_avg: 35.78032818626375
train_count_sent: 8544.0
train_total_correct_sent: 8270.0
train_accuracy_sent: 0.9679307116104869
train_count_tok: 163566.0
train_total_correct_tok: 146479.0
train_accuracy_tok: 0.8955345242898891
train_label=0_precision_sent: 0.5714285714285714
train_label=0_recall_sent: 0.20761245674740483
train_label=0_f-score_sent: 0.3045685279187817
train_label=1_precision_sent: 0.9728640834222064
train_label=1_recall_sent: 0.9945487583282859
train_label=1_f-score_sent: 0.9835869174553732
train_precision_macro_sent: 0.7721463274253889
train_recall_macro_sent: 0.6010806075378454
train_f-score_macro_sent: 0.6440777226870774
train_precision_micro_sent: 0.9679307116104869
train_recall_micro_sent: 0.9679307116104869
train_f-score_micro_sent: 0.9679307116104869
train_label=O_precision_tok: 0.9064577112934927
train_label=O_recall_tok: 0.9717082036558984
train_label=O_f-score_tok: 0.9379495041627045
train_label=N_precision_tok: 0.795658287924064
train_label=N_recall_tok: 0.6374454302210956
train_label=N_f-score_tok: 0.7078186082877248
train_label=P_precision_tok: 0.8786130227633668
train_label=P_recall_tok: 0.6634288683695088
train_label=P_f-score_tok: 0.7560070148267929
train_precision_macro_tok: 0.8602430073269746
train_recall_macro_tok: 0.7575275007488343
train_f-score_macro_tok: 0.8005917090924074
train_precision_micro_tok: 0.8955345242898891
train_recall_micro_tok: 0.8955345242898891
train_f-score_micro_tok: 0.8955345242898891
train_time: 93.08995532989502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5714    0.2076    0.3046       289
           1     0.9729    0.9945    0.9836      8255

   micro avg     0.9679    0.9679    0.9679      8544
   macro avg     0.7721    0.6011    0.6441      8544
weighted avg     0.9593    0.9679    0.9606      8544

F1-macro sent:  0.6440777226870774
F1-micro sent:  0.9679307116104869
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9717    0.9379    124347
           N     0.7957    0.6374    0.7078     14202
           P     0.8786    0.6634    0.7560     25017

   micro avg     0.8955    0.8955    0.8955    163566
   macro avg     0.8602    0.7575    0.8006    163566
weighted avg     0.8926    0.8955    0.8901    163566

F1-macro tok:  0.8005917090924074
F1-micro tok:  0.8955345242898891
**************************************************
dev_cost_sum: 41709.692443847656
dev_cost_avg: 37.88346271012503
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=0_precision_sent: 1.0
dev_label=0_recall_sent: 0.08108108108108109
dev_label=0_f-score_sent: 0.15
dev_label=1_precision_sent: 0.9690346083788707
dev_label=1_recall_sent: 1.0
dev_label=1_f-score_sent: 0.9842738205365403
dev_precision_macro_sent: 0.9845173041894353
dev_recall_macro_sent: 0.5405405405405406
dev_f-score_macro_sent: 0.5671369102682702
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9044075558099599
dev_label=O_recall_tok: 0.9750077136686208
dev_label=O_f-score_tok: 0.9383815887156646
dev_label=N_precision_tok: 0.7987243090007087
dev_label=N_recall_tok: 0.6068928379106086
dev_label=N_f-score_tok: 0.689718482252142
dev_label=P_precision_tok: 0.9017969076473047
dev_label=P_recall_tok: 0.6718555417185554
dev_label=P_f-score_tok: 0.7700267618198038
dev_precision_macro_tok: 0.8683095908193245
dev_recall_macro_tok: 0.7512520310992615
dev_f-score_macro_tok: 0.7993756109292035
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 5.028182744979858
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     1.0000    0.0811    0.1500        37
           1     0.9690    1.0000    0.9843      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.9845    0.5405    0.5671      1101
weighted avg     0.9701    0.9691    0.9562      1101

F1-macro sent:  0.5671369102682702
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9044    0.9750    0.9384     16205
           N     0.7987    0.6069    0.6897      1857
           P     0.9018    0.6719    0.7700      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8683    0.7513    0.7994     21274
weighted avg     0.8948    0.8971    0.8913     21274

F1-macro tok:  0.7993756109292035
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 303924.58361816406
train_cost_avg: 35.57169752085254
train_count_sent: 8544.0
train_total_correct_sent: 8281.0
train_accuracy_sent: 0.9692181647940075
train_count_tok: 163566.0
train_total_correct_tok: 146651.0
train_accuracy_tok: 0.896586087573212
train_label=0_precision_sent: 0.5928571428571429
train_label=0_recall_sent: 0.28719723183391005
train_label=0_f-score_sent: 0.38694638694638694
train_label=1_precision_sent: 0.9754878629224178
train_label=1_recall_sent: 0.9930950938824955
train_label=1_f-score_sent: 0.9842127378594153
train_precision_macro_sent: 0.7841725028897804
train_recall_macro_sent: 0.6401461628582028
train_f-score_macro_sent: 0.6855795624029011
train_precision_micro_sent: 0.9692181647940075
train_recall_micro_sent: 0.9692181647940075
train_f-score_micro_sent: 0.9692181647940075
train_label=O_precision_tok: 0.9080128060603327
train_label=O_recall_tok: 0.9716519095756231
train_label=O_f-score_tok: 0.9387550551845507
train_label=N_precision_tok: 0.7963384723195515
train_label=N_recall_tok: 0.6401211097028587
train_label=N_f-score_tok: 0.709735342337419
train_label=P_precision_tok: 0.8768860016764459
train_label=P_recall_tok: 0.6690650357756726
train_label=P_f-score_tok: 0.759006915315724
train_precision_macro_tok: 0.8604124266854433
train_recall_macro_tok: 0.760279351684718
train_f-score_macro_tok: 0.8024991042792312
train_precision_micro_tok: 0.896586087573212
train_recall_micro_tok: 0.896586087573212
train_f-score_micro_tok: 0.896586087573212
train_time: 93.41662931442261
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5929    0.2872    0.3869       289
           1     0.9755    0.9931    0.9842      8255

   micro avg     0.9692    0.9692    0.9692      8544
   macro avg     0.7842    0.6401    0.6856      8544
weighted avg     0.9625    0.9692    0.9640      8544

F1-macro sent:  0.6855795624029011
F1-micro sent:  0.9692181647940075
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9717    0.9388    124347
           N     0.7963    0.6401    0.7097     14202
           P     0.8769    0.6691    0.7590     25017

   micro avg     0.8966    0.8966    0.8966    163566
   macro avg     0.8604    0.7603    0.8025    163566
weighted avg     0.8936    0.8966    0.8914    163566

F1-macro tok:  0.8024991042792312
F1-micro tok:  0.896586087573212
**************************************************
dev_cost_sum: 41621.509826660156
dev_cost_avg: 37.80336950650332
dev_count_sent: 1101.0
dev_total_correct_sent: 1073.0
dev_accuracy_sent: 0.9745685740236149
dev_count_tok: 21274.0
dev_total_correct_tok: 19114.0
dev_accuracy_tok: 0.898467613048792
dev_label=0_precision_sent: 0.8
dev_label=0_recall_sent: 0.32432432432432434
dev_label=0_f-score_sent: 0.46153846153846156
dev_label=1_precision_sent: 0.9769797421731123
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9869767441860465
dev_precision_macro_sent: 0.8884898710865562
dev_recall_macro_sent: 0.6607523877260719
dev_f-score_macro_sent: 0.724257602862254
dev_precision_micro_sent: 0.9745685740236149
dev_recall_micro_sent: 0.9745685740236149
dev_f-score_micro_sent: 0.9745685740236149
dev_label=O_precision_tok: 0.9031688134047646
dev_label=O_recall_tok: 0.9779080530700401
dev_label=O_f-score_tok: 0.9390536576694024
dev_label=N_precision_tok: 0.8035460992907801
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6936026936026934
dev_label=P_precision_tok: 0.9206212251941329
dev_label=P_recall_tok: 0.6643835616438356
dev_label=P_f-score_tok: 0.7717902350813742
dev_precision_macro_tok: 0.8757787126298925
dev_recall_macro_tok: 0.7508051567983607
dev_f-score_macro_tok: 0.8014821954511566
dev_precision_micro_tok: 0.898467613048792
dev_recall_micro_tok: 0.898467613048792
dev_f-score_micro_tok: 0.8984676130487919
dev_time: 5.000782012939453
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8000    0.3243    0.4615        37
           1     0.9770    0.9972    0.9870      1064

   micro avg     0.9746    0.9746    0.9746      1101
   macro avg     0.8885    0.6608    0.7243      1101
weighted avg     0.9710    0.9746    0.9693      1101

F1-macro sent:  0.724257602862254
F1-micro sent:  0.9745685740236149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9032    0.9779    0.9391     16205
           N     0.8035    0.6101    0.6936      1857
           P     0.9206    0.6644    0.7718      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8758    0.7508    0.8015     21274
weighted avg     0.8971    0.8985    0.8924     21274

F1-macro tok:  0.8014821954511566
F1-micro tok:  0.8984676130487919
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 301933.70318603516
train_cost_avg: 35.338682489002245
train_count_sent: 8544.0
train_total_correct_sent: 8299.0
train_accuracy_sent: 0.9713249063670412
train_count_tok: 163566.0
train_total_correct_tok: 147027.0
train_accuracy_tok: 0.8988848538204761
train_label=0_precision_sent: 0.671875
train_label=0_recall_sent: 0.2975778546712803
train_label=0_f-score_sent: 0.41247002398081534
train_label=1_precision_sent: 0.9758792775665399
train_label=1_recall_sent: 0.9949121744397335
train_label=1_f-score_sent: 0.9853038210065382
train_precision_macro_sent: 0.82387713878327
train_recall_macro_sent: 0.6462450145555069
train_f-score_macro_sent: 0.6988869224936768
train_precision_micro_sent: 0.9713249063670412
train_recall_micro_sent: 0.9713249063670412
train_f-score_micro_sent: 0.9713249063670412
train_label=O_precision_tok: 0.9102712798807031
train_label=O_recall_tok: 0.9719896740572752
train_label=O_f-score_tok: 0.9401186193485658
train_label=N_precision_tok: 0.7992921270718232
train_label=N_recall_tok: 0.6519504295169695
train_label=N_f-score_tok: 0.7181416272395874
train_label=P_precision_tok: 0.8802332847323474
train_label=P_recall_tok: 0.6757005236439221
train_label=P_f-score_tok: 0.764523642613238
train_precision_macro_tok: 0.8632655638949579
train_recall_macro_tok: 0.766546875739389
train_f-score_macro_tok: 0.8075946297337971
train_precision_micro_tok: 0.8988848538204761
train_recall_micro_tok: 0.8988848538204761
train_f-score_micro_tok: 0.8988848538204761
train_time: 124.4689872264862
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6719    0.2976    0.4125       289
           1     0.9759    0.9949    0.9853      8255

   micro avg     0.9713    0.9713    0.9713      8544
   macro avg     0.8239    0.6462    0.6989      8544
weighted avg     0.9656    0.9713    0.9659      8544

F1-macro sent:  0.6988869224936768
F1-micro sent:  0.9713249063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9103    0.9720    0.9401    124347
           N     0.7993    0.6520    0.7181     14202
           P     0.8802    0.6757    0.7645     25017

   micro avg     0.8989    0.8989    0.8989    163566
   macro avg     0.8633    0.7665    0.8076    163566
weighted avg     0.8960    0.8989    0.8940    163566

F1-macro tok:  0.8075946297337971
F1-micro tok:  0.8988848538204761
**************************************************
dev_cost_sum: 41546.18377685547
dev_cost_avg: 37.7349534757997
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=0_precision_sent: 0.6666666666666666
dev_label=0_recall_sent: 0.16216216216216217
dev_label=0_f-score_sent: 0.26086956521739135
dev_label=1_precision_sent: 0.9716117216117216
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9842300556586271
dev_precision_macro_sent: 0.8191391941391941
dev_recall_macro_sent: 0.5796713066449908
dev_f-score_macro_sent: 0.6225498104380092
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9008738084430322
dev_label=O_recall_tok: 0.9797593335390312
dev_label=O_f-score_tok: 0.938662094652517
dev_label=N_precision_tok: 0.8529170090386196
dev_label=N_recall_tok: 0.5589660743134087
dev_label=N_f-score_tok: 0.6753415744957709
dev_label=P_precision_tok: 0.8956021372790793
dev_label=P_recall_tok: 0.6783935242839353
dev_label=P_f-score_tok: 0.7720106288751107
dev_precision_macro_tok: 0.8831309849202437
dev_recall_macro_tok: 0.7390396440454584
dev_f-score_macro_tok: 0.7953380993411329
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 8.163586854934692
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.1622    0.2609        37
           1     0.9716    0.9972    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8191    0.5797    0.6225      1101
weighted avg     0.9614    0.9691    0.9599      1101

F1-macro sent:  0.6225498104380092
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9798    0.9387     16205
           N     0.8529    0.5590    0.6753      1857
           P     0.8956    0.6784    0.7720      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8831    0.7390    0.7953     21274
weighted avg     0.8959    0.8975    0.8905     21274

F1-macro tok:  0.7953380993411329
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 300511.77697753906
train_cost_avg: 35.17225854137864
train_count_sent: 8544.0
train_total_correct_sent: 8280.0
train_accuracy_sent: 0.9691011235955056
train_count_tok: 163566.0
train_total_correct_tok: 147199.0
train_accuracy_tok: 0.8999364171037991
train_label=0_precision_sent: 0.6126126126126126
train_label=0_recall_sent: 0.23529411764705882
train_label=0_f-score_sent: 0.33999999999999997
train_label=1_precision_sent: 0.9737934305703783
train_label=1_recall_sent: 0.9947910357359177
train_label=1_f-score_sent: 0.9841802492809204
train_precision_macro_sent: 0.7932030215914954
train_recall_macro_sent: 0.6150425766914882
train_f-score_macro_sent: 0.6620901246404602
train_precision_micro_sent: 0.9691011235955056
train_recall_micro_sent: 0.9691011235955056
train_f-score_micro_sent: 0.9691011235955056
train_label=O_precision_tok: 0.9117742556613533
train_label=O_recall_tok: 0.9710648427384657
train_label=O_f-score_tok: 0.9404860191603707
train_label=N_precision_tok: 0.8050103305785123
train_label=N_recall_tok: 0.6584283903675539
train_label=N_f-score_tok: 0.7243783406925401
train_label=P_precision_tok: 0.8761080084029308
train_label=P_recall_tok: 0.6834952232481912
train_label=P_f-score_tok: 0.7679076660529034
train_precision_macro_tok: 0.8642975315475988
train_recall_macro_tok: 0.7709961521180703
train_f-score_macro_tok: 0.8109240086352715
train_precision_micro_tok: 0.8999364171037991
train_recall_micro_tok: 0.8999364171037991
train_f-score_micro_tok: 0.8999364171037991
train_time: 141.80404114723206
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6126    0.2353    0.3400       289
           1     0.9738    0.9948    0.9842      8255

   micro avg     0.9691    0.9691    0.9691      8544
   macro avg     0.7932    0.6150    0.6621      8544
weighted avg     0.9616    0.9691    0.9624      8544

F1-macro sent:  0.6620901246404602
F1-micro sent:  0.9691011235955056
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9118    0.9711    0.9405    124347
           N     0.8050    0.6584    0.7244     14202
           P     0.8761    0.6835    0.7679     25017

   micro avg     0.8999    0.8999    0.8999    163566
   macro avg     0.8643    0.7710    0.8109    163566
weighted avg     0.8970    0.8999    0.8953    163566

F1-macro tok:  0.8109240086352715
F1-micro tok:  0.8999364171037991
**************************************************
dev_cost_sum: 41439.537841796875
dev_cost_avg: 37.63809068283095
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19077.0
dev_accuracy_tok: 0.8967284008649056
dev_label=0_precision_sent: 0.875
dev_label=0_recall_sent: 0.1891891891891892
dev_label=0_f-score_sent: 0.3111111111111111
dev_label=1_precision_sent: 0.9725526075022873
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.985628187297172
dev_precision_macro_sent: 0.9237763037511437
dev_recall_macro_sent: 0.5941246697825645
dev_f-score_macro_sent: 0.6483696492041415
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9110206455364932
dev_label=O_recall_tok: 0.966676951558161
dev_label=O_f-score_tok: 0.9380239520958084
dev_label=N_precision_tok: 0.7713912475506205
dev_label=N_recall_tok: 0.6359719978459881
dev_label=N_f-score_tok: 0.6971664698937426
dev_label=P_precision_tok: 0.8755886970172685
dev_label=P_recall_tok: 0.6945828144458281
dev_label=P_f-score_tok: 0.7746527777777779
dev_precision_macro_tok: 0.8526668633681274
dev_recall_macro_tok: 0.7657439212833257
dev_f-score_macro_tok: 0.8032810665891096
dev_precision_micro_tok: 0.8967284008649056
dev_recall_micro_tok: 0.8967284008649056
dev_f-score_micro_tok: 0.8967284008649056
dev_time: 8.099094867706299
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8750    0.1892    0.3111        37
           1     0.9726    0.9991    0.9856      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.9238    0.5941    0.6484      1101
weighted avg     0.9693    0.9718    0.9630      1101

F1-macro sent:  0.6483696492041415
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9667    0.9380     16205
           N     0.7714    0.6360    0.6972      1857
           P     0.8756    0.6946    0.7747      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8527    0.7657    0.8033     21274
weighted avg     0.8935    0.8967    0.8923     21274

F1-macro tok:  0.8032810665891096
F1-micro tok:  0.8967284008649056
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 298879.13024902344
train_cost_avg: 34.981171611543004
train_count_sent: 8544.0
train_total_correct_sent: 8285.0
train_accuracy_sent: 0.9696863295880149
train_count_tok: 163566.0
train_total_correct_tok: 147575.0
train_accuracy_tok: 0.9022351833510632
train_label=0_precision_sent: 0.6056338028169014
train_label=0_recall_sent: 0.2975778546712803
train_label=0_f-score_sent: 0.3990719257540603
train_label=1_precision_sent: 0.9758390859319209
train_label=1_recall_sent: 0.9932162325863113
train_label=1_f-score_sent: 0.9844509815693101
train_precision_macro_sent: 0.7907364443744112
train_recall_macro_sent: 0.6453970436287958
train_f-score_macro_sent: 0.6917614536616852
train_precision_micro_sent: 0.9696863295880149
train_recall_micro_sent: 0.9696863295880149
train_f-score_micro_sent: 0.9696863295880149
train_label=O_precision_tok: 0.9143620685739376
train_label=O_recall_tok: 0.971306103082503
train_label=O_f-score_tok: 0.941974278383079
train_label=N_precision_tok: 0.8045170021992895
train_label=N_recall_tok: 0.6696944092381355
train_label=N_f-score_tok: 0.7309406701506302
train_label=P_precision_tok: 0.8795094896453468
train_label=P_recall_tok: 0.6909301674861095
train_label=P_f-score_tok: 0.7738974703380346
train_precision_macro_tok: 0.8661295201395246
train_recall_macro_tok: 0.7773102266022492
train_f-score_macro_tok: 0.8156041396239146
train_precision_micro_tok: 0.9022351833510632
train_recall_micro_tok: 0.9022351833510632
train_f-score_micro_tok: 0.9022351833510632
train_time: 140.98149991035461
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6056    0.2976    0.3991       289
           1     0.9758    0.9932    0.9845      8255

   micro avg     0.9697    0.9697    0.9697      8544
   macro avg     0.7907    0.6454    0.6918      8544
weighted avg     0.9633    0.9697    0.9647      8544

F1-macro sent:  0.6917614536616852
F1-micro sent:  0.9696863295880149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9144    0.9713    0.9420    124347
           N     0.8045    0.6697    0.7309     14202
           P     0.8795    0.6909    0.7739     25017

   micro avg     0.9022    0.9022    0.9022    163566
   macro avg     0.8661    0.7773    0.8156    163566
weighted avg     0.8995    0.9022    0.8979    163566

F1-macro tok:  0.8156041396239146
F1-micro tok:  0.9022351833510632
**************************************************
dev_cost_sum: 41407.004821777344
dev_cost_avg: 37.60854207245899
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 19102.0
dev_accuracy_tok: 0.8979035442323964
dev_label=0_precision_sent: 0.8571428571428571
dev_label=0_recall_sent: 0.16216216216216217
dev_label=0_f-score_sent: 0.27272727272727276
dev_label=1_precision_sent: 0.9716636197440585
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.985171455050973
dev_precision_macro_sent: 0.9144032384434577
dev_recall_macro_sent: 0.580611156269051
dev_f-score_macro_sent: 0.6289493638891229
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.9108749927422632
dev_label=O_recall_tok: 0.9680962665843875
dev_label=O_f-score_tok: 0.9386143352877826
dev_label=N_precision_tok: 0.8158273381294964
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6984909146904835
dev_label=P_precision_tok: 0.8568207440811725
dev_label=P_recall_tok: 0.709838107098381
dev_label=P_f-score_tok: 0.7764345309041376
dev_precision_macro_tok: 0.8611743583176441
dev_recall_macro_tok: 0.7628655774419139
dev_f-score_macro_tok: 0.8045132602941346
dev_precision_micro_tok: 0.8979035442323964
dev_recall_micro_tok: 0.8979035442323964
dev_f-score_micro_tok: 0.8979035442323964
dev_time: 8.167974948883057
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8571    0.1622    0.2727        37
           1     0.9717    0.9991    0.9852      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.9144    0.5806    0.6289      1101
weighted avg     0.9678    0.9709    0.9612      1101

F1-macro sent:  0.6289493638891229
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9681    0.9386     16205
           N     0.8158    0.6107    0.6985      1857
           P     0.8568    0.7098    0.7764      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8612    0.7629    0.8045     21274
weighted avg     0.8944    0.8979    0.8932     21274

F1-macro tok:  0.8045132602941346
F1-micro tok:  0.8979035442323964
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 297647.25927734375
train_cost_avg: 34.83699195661795
train_count_sent: 8544.0
train_total_correct_sent: 8275.0
train_accuracy_sent: 0.9685159176029963
train_count_tok: 163566.0
train_total_correct_tok: 147708.0
train_accuracy_tok: 0.9030483107736327
train_label=0_precision_sent: 0.554945054945055
train_label=0_recall_sent: 0.3494809688581315
train_label=0_f-score_sent: 0.4288747346072187
train_label=1_precision_sent: 0.9775173403491988
train_label=1_recall_sent: 0.9901877649909145
train_label=1_f-score_sent: 0.983811759041945
train_precision_macro_sent: 0.7662311976471269
train_recall_macro_sent: 0.669834366924523
train_f-score_macro_sent: 0.7063432468245818
train_precision_micro_sent: 0.9685159176029963
train_recall_micro_sent: 0.9685159176029963
train_f-score_micro_sent: 0.9685159176029963
train_label=O_precision_tok: 0.9157533051676666
train_label=O_recall_tok: 0.9709281285435113
train_label=O_f-score_tok: 0.942533940184085
train_label=N_precision_tok: 0.8054520826278361
train_label=N_recall_tok: 0.6699056470919589
train_label=N_f-score_tok: 0.7314522949181209
train_label=P_precision_tok: 0.8768265126788852
train_label=P_recall_tok: 0.6980053563576768
train_label=P_f-score_tok: 0.7772634202795337
train_precision_macro_tok: 0.8660106334914627
train_recall_macro_tok: 0.7796130439977157
train_f-score_macro_tok: 0.81708321846058
train_precision_micro_tok: 0.9030483107736327
train_recall_micro_tok: 0.9030483107736327
train_f-score_micro_tok: 0.9030483107736327
train_time: 141.36602640151978
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5549    0.3495    0.4289       289
           1     0.9775    0.9902    0.9838      8255

   micro avg     0.9685    0.9685    0.9685      8544
   macro avg     0.7662    0.6698    0.7063      8544
weighted avg     0.9632    0.9685    0.9650      8544

F1-macro sent:  0.7063432468245818
F1-micro sent:  0.9685159176029963
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9158    0.9709    0.9425    124347
           N     0.8055    0.6699    0.7315     14202
           P     0.8768    0.6980    0.7773     25017

   micro avg     0.9030    0.9030    0.9030    163566
   macro avg     0.8660    0.7796    0.8171    163566
weighted avg     0.9002    0.9030    0.8989    163566

F1-macro tok:  0.81708321846058
F1-micro tok:  0.9030483107736327
**************************************************
dev_cost_sum: 41254.61279296875
dev_cost_avg: 37.47012969388624
dev_count_sent: 1101.0
dev_total_correct_sent: 1068.0
dev_accuracy_sent: 0.9700272479564033
dev_count_tok: 21274.0
dev_total_correct_tok: 19155.0
dev_accuracy_tok: 0.900394848171477
dev_label=0_precision_sent: 0.8333333333333334
dev_label=0_recall_sent: 0.13513513513513514
dev_label=0_f-score_sent: 0.23255813953488372
dev_label=1_precision_sent: 0.9707762557077626
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.98471514590088
dev_precision_macro_sent: 0.9020547945205479
dev_recall_macro_sent: 0.5670976427555375
dev_f-score_macro_sent: 0.6086366427178819
dev_precision_micro_sent: 0.9700272479564033
dev_recall_micro_sent: 0.9700272479564033
dev_f-score_micro_sent: 0.9700272479564033
dev_label=O_precision_tok: 0.9108825059238282
dev_label=O_recall_tok: 0.9726010490589324
dev_label=O_f-score_tok: 0.9407305718037483
dev_label=N_precision_tok: 0.7739637305699482
dev_label=N_recall_tok: 0.6435110393107162
dev_label=N_f-score_tok: 0.7027344898559247
dev_label=P_precision_tok: 0.9060568603213844
dev_label=P_recall_tok: 0.6846201743462017
dev_label=P_f-score_tok: 0.7799255187089911
dev_precision_macro_tok: 0.8636343656050536
dev_recall_macro_tok: 0.7669107542386168
dev_f-score_macro_tok: 0.8077968601228879
dev_precision_micro_tok: 0.900394848171477
dev_recall_micro_tok: 0.900394848171477
dev_f-score_micro_tok: 0.900394848171477
dev_time: 8.190079689025879
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8333    0.1351    0.2326        37
           1     0.9708    0.9991    0.9847      1064

   micro avg     0.9700    0.9700    0.9700      1101
   macro avg     0.9021    0.5671    0.6086      1101
weighted avg     0.9662    0.9700    0.9594      1101

F1-macro sent:  0.6086366427178819
F1-micro sent:  0.9700272479564033
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9726    0.9407     16205
           N     0.7740    0.6435    0.7027      1857
           P     0.9061    0.6846    0.7799      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8636    0.7669    0.8078     21274
weighted avg     0.8982    0.9004    0.8957     21274

F1-macro tok:  0.8077968601228879
F1-micro tok:  0.900394848171477
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 295862.36181640625
train_cost_avg: 34.62808541858687
train_count_sent: 8544.0
train_total_correct_sent: 8300.0
train_accuracy_sent: 0.971441947565543
train_count_tok: 163566.0
train_total_correct_tok: 148024.0
train_accuracy_tok: 0.9049802526197376
train_label=0_precision_sent: 0.630057803468208
train_label=0_recall_sent: 0.3771626297577855
train_label=0_f-score_sent: 0.47186147186147187
train_label=1_precision_sent: 0.9784971926890456
train_label=1_recall_sent: 0.9922471229557843
train_label=1_f-score_sent: 0.9853241910261037
train_precision_macro_sent: 0.8042774980786268
train_recall_macro_sent: 0.6847048763567849
train_f-score_macro_sent: 0.7285928314437877
train_precision_micro_sent: 0.971441947565543
train_recall_micro_sent: 0.971441947565543
train_f-score_micro_sent: 0.971441947565543
train_label=O_precision_tok: 0.9176315069742
train_label=O_recall_tok: 0.9713623971627784
train_label=O_f-score_tok: 0.9437327864049224
train_label=N_precision_tok: 0.8070292887029289
train_label=N_recall_tok: 0.6790592874243064
train_label=N_f-score_tok: 0.737534414193943
train_label=P_precision_tok: 0.8802281368821293
train_label=P_recall_tok: 0.7032817683974897
train_label=P_f-score_tok: 0.781868681257638
train_precision_macro_tok: 0.868296310853086
train_recall_macro_tok: 0.7845678176615248
train_f-score_macro_tok: 0.8210452939521679
train_precision_micro_tok: 0.9049802526197376
train_recall_micro_tok: 0.9049802526197376
train_f-score_micro_tok: 0.9049802526197376
train_time: 142.09829592704773
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6301    0.3772    0.4719       289
           1     0.9785    0.9922    0.9853      8255

   micro avg     0.9714    0.9714    0.9714      8544
   macro avg     0.8043    0.6847    0.7286      8544
weighted avg     0.9667    0.9714    0.9680      8544

F1-macro sent:  0.7285928314437877
F1-micro sent:  0.971441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9176    0.9714    0.9437    124347
           N     0.8070    0.6791    0.7375     14202
           P     0.8802    0.7033    0.7819     25017

   micro avg     0.9050    0.9050    0.9050    163566
   macro avg     0.8683    0.7846    0.8210    163566
weighted avg     0.9023    0.9050    0.9011    163566

F1-macro tok:  0.8210452939521679
F1-micro tok:  0.9049802526197376
**************************************************
dev_cost_sum: 41158.693115234375
dev_cost_avg: 37.38300918731551
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19130.0
dev_accuracy_tok: 0.899219704803986
dev_label=0_precision_sent: 0.7142857142857143
dev_label=0_recall_sent: 0.13513513513513514
dev_label=0_f-score_sent: 0.22727272727272727
dev_label=1_precision_sent: 0.9707495429616088
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9842446709916588
dev_precision_macro_sent: 0.8425176286236615
dev_recall_macro_sent: 0.5666277179435074
dev_f-score_macro_sent: 0.605758699132193
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9092691930553152
dev_label=O_recall_tok: 0.9727861771058315
dev_label=O_f-score_tok: 0.9399558762148947
dev_label=N_precision_tok: 0.7820254862508383
dev_label=N_recall_tok: 0.6278944534194938
dev_label=N_f-score_tok: 0.6965352449223418
dev_label=P_precision_tok: 0.8994276369582993
dev_label=P_recall_tok: 0.684931506849315
dev_label=P_f-score_tok: 0.7776599505125485
dev_precision_macro_tok: 0.8635741054214843
dev_recall_macro_tok: 0.7618707124582135
dev_f-score_macro_tok: 0.8047170238832617
dev_precision_micro_tok: 0.899219704803986
dev_recall_micro_tok: 0.899219704803986
dev_f-score_micro_tok: 0.899219704803986
dev_time: 8.339757442474365
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7143    0.1351    0.2273        37
           1     0.9707    0.9981    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8425    0.5666    0.6058      1101
weighted avg     0.9621    0.9691    0.9588      1101

F1-macro sent:  0.605758699132193
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9093    0.9728    0.9400     16205
           N     0.7820    0.6279    0.6965      1857
           P     0.8994    0.6849    0.7777      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8636    0.7619    0.8047     21274
weighted avg     0.8967    0.8992    0.8942     21274

F1-macro tok:  0.8047170238832617
F1-micro tok:  0.899219704803986
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 1.000000
train_cost_sum: 294076.6864013672
train_cost_avg: 34.41908782787537
train_count_sent: 8544.0
train_total_correct_sent: 8312.0
train_accuracy_sent: 0.9728464419475655
train_count_tok: 163566.0
train_total_correct_tok: 148403.0
train_accuracy_tok: 0.9072973600870596
train_label=0_precision_sent: 0.6476683937823834
train_label=0_recall_sent: 0.43252595155709345
train_label=0_f-score_sent: 0.5186721991701244
train_label=1_precision_sent: 0.9803616333373248
train_label=1_recall_sent: 0.9917625681405209
train_label=1_f-score_sent: 0.9860291460917741
train_precision_macro_sent: 0.8140150135598541
train_recall_macro_sent: 0.7121442598488071
train_f-score_macro_sent: 0.7523506726309492
train_precision_micro_sent: 0.9728464419475655
train_recall_micro_sent: 0.9728464419475655
train_f-score_micro_sent: 0.9728464419475656
train_label=O_precision_tok: 0.9200255966846199
train_label=O_recall_tok: 0.971225682967824
train_label=O_f-score_tok: 0.9449325936764027
train_label=N_precision_tok: 0.8138585824935455
train_label=N_recall_tok: 0.6880721025207717
train_label=N_f-score_tok: 0.7456980426571026
train_label=P_precision_tok: 0.8802483737433471
train_label=P_recall_tok: 0.7139944837510492
train_label=P_f-score_tok: 0.7884526253062305
train_precision_macro_tok: 0.8713775176405042
train_recall_macro_tok: 0.7910974230798816
train_f-score_macro_tok: 0.8263610872132453
train_precision_micro_tok: 0.9072973600870596
train_recall_micro_tok: 0.9072973600870596
train_f-score_micro_tok: 0.9072973600870596
train_time: 142.05331206321716
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6477    0.4325    0.5187       289
           1     0.9804    0.9918    0.9860      8255

   micro avg     0.9728    0.9728    0.9728      8544
   macro avg     0.8140    0.7121    0.7524      8544
weighted avg     0.9691    0.9728    0.9702      8544

F1-macro sent:  0.7523506726309492
F1-micro sent:  0.9728464419475656
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9200    0.9712    0.9449    124347
           N     0.8139    0.6881    0.7457     14202
           P     0.8802    0.7140    0.7885     25017

   micro avg     0.9073    0.9073    0.9073    163566
   macro avg     0.8714    0.7911    0.8264    163566
weighted avg     0.9047    0.9073    0.9037    163566

F1-macro tok:  0.8263610872132453
F1-micro tok:  0.9072973600870596
**************************************************
dev_cost_sum: 41191.48760986328
dev_cost_avg: 37.412795285979364
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 19153.0
dev_accuracy_tok: 0.9003008367020776
dev_label=0_precision_sent: 0.8571428571428571
dev_label=0_recall_sent: 0.16216216216216217
dev_label=0_f-score_sent: 0.27272727272727276
dev_label=1_precision_sent: 0.9716636197440585
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.985171455050973
dev_precision_macro_sent: 0.9144032384434577
dev_recall_macro_sent: 0.580611156269051
dev_f-score_macro_sent: 0.6289493638891229
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.9118891658454582
dev_label=O_recall_tok: 0.9707497685899413
dev_label=O_f-score_tok: 0.9403993304638928
dev_label=N_precision_tok: 0.7695792880258899
dev_label=N_recall_tok: 0.6402800215401184
dev_label=N_f-score_tok: 0.6990005878894767
dev_label=P_precision_tok: 0.9011299435028248
dev_label=P_recall_tok: 0.6952054794520548
dev_label=P_f-score_tok: 0.7848857644991213
dev_precision_macro_tok: 0.8608661324580577
dev_recall_macro_tok: 0.768745089860705
dev_f-score_macro_tok: 0.808095227617497
dev_precision_micro_tok: 0.9003008367020776
dev_recall_micro_tok: 0.9003008367020776
dev_f-score_micro_tok: 0.9003008367020775
dev_time: 7.994887590408325
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8571    0.1622    0.2727        37
           1     0.9717    0.9991    0.9852      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.9144    0.5806    0.6289      1101
weighted avg     0.9678    0.9709    0.9612      1101

F1-macro sent:  0.6289493638891229
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9707    0.9404     16205
           N     0.7696    0.6403    0.6990      1857
           P     0.9011    0.6952    0.7849      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8609    0.7687    0.8081     21274
weighted avg     0.8978    0.9003    0.8958     21274

F1-macro tok:  0.808095227617497
F1-micro tok:  0.9003008367020775
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 1.000000
train_cost_sum: 293031.71142578125
train_cost_avg: 34.29678270432833
train_count_sent: 8544.0
train_total_correct_sent: 8287.0
train_accuracy_sent: 0.9699204119850188
train_count_tok: 163566.0
train_total_correct_tok: 148488.0
train_accuracy_tok: 0.9078170279887018
train_label=0_precision_sent: 0.5975609756097561
train_label=0_recall_sent: 0.3391003460207612
train_label=0_f-score_sent: 0.4326710816777042
train_label=1_precision_sent: 0.9772076372315036
train_label=1_recall_sent: 0.9920048455481526
train_label=1_f-score_sent: 0.9845506462278328
train_precision_macro_sent: 0.7873843064206298
train_recall_macro_sent: 0.6655525957844569
train_f-score_macro_sent: 0.7086108639527685
train_precision_micro_sent: 0.9699204119850188
train_recall_micro_sent: 0.9699204119850188
train_f-score_micro_sent: 0.9699204119850188
train_label=O_precision_tok: 0.9208565042603992
train_label=O_recall_tok: 0.9707994563600247
train_label=O_f-score_tok: 0.9451686906411731
train_label=N_precision_tok: 0.813688844588421
train_label=N_recall_tok: 0.689762005351359
train_label=N_f-score_tok: 0.7466178880378035
train_label=P_precision_tok: 0.8796241926012919
train_label=P_recall_tok: 0.7185513850581604
train_label=P_f-score_tok: 0.7909708930103624
train_precision_macro_tok: 0.8713898471500374
train_recall_macro_tok: 0.7930376155898481
train_f-score_macro_tok: 0.8275858238964463
train_precision_micro_tok: 0.9078170279887018
train_recall_micro_tok: 0.9078170279887018
train_f-score_micro_tok: 0.9078170279887018
train_time: 142.60338163375854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5976    0.3391    0.4327       289
           1     0.9772    0.9920    0.9846      8255

   micro avg     0.9699    0.9699    0.9699      8544
   macro avg     0.7874    0.6656    0.7086      8544
weighted avg     0.9644    0.9699    0.9659      8544

F1-macro sent:  0.7086108639527685
F1-micro sent:  0.9699204119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9209    0.9708    0.9452    124347
           N     0.8137    0.6898    0.7466     14202
           P     0.8796    0.7186    0.7910     25017

   micro avg     0.9078    0.9078    0.9078    163566
   macro avg     0.8714    0.7930    0.8276    163566
weighted avg     0.9052    0.9078    0.9043    163566

F1-macro tok:  0.8275858238964463
F1-micro tok:  0.9078170279887018
**************************************************
dev_cost_sum: 41126.707946777344
dev_cost_avg: 37.353958171459894
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=0_precision_sent: 0.5833333333333334
dev_label=0_recall_sent: 0.5675675675675675
dev_label=0_f-score_sent: 0.5753424657534246
dev_label=1_precision_sent: 0.9849765258215962
dev_label=1_recall_sent: 0.9859022556390977
dev_label=1_f-score_sent: 0.9854391733208079
dev_precision_macro_sent: 0.7841549295774648
dev_recall_macro_sent: 0.7767349116033326
dev_f-score_macro_sent: 0.7803908195371163
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9093626070463819
dev_label=O_recall_tok: 0.9763653193458809
dev_label=O_f-score_tok: 0.9416736102844899
dev_label=N_precision_tok: 0.7791777188328912
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.6983655274888558
dev_label=P_precision_tok: 0.9226869455006337
dev_label=P_recall_tok: 0.6799501867995019
dev_label=P_f-score_tok: 0.7829360100376411
dev_precision_macro_tok: 0.8704090904599688
dev_recall_macro_tok: 0.7630188287402578
dev_f-score_macro_tok: 0.8076583826036624
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 8.049684524536133
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5833    0.5676    0.5753        37
           1     0.9850    0.9859    0.9854      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.7842    0.7767    0.7804      1101
weighted avg     0.9715    0.9718    0.9717      1101

F1-macro sent:  0.7803908195371163
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9094    0.9764    0.9417     16205
           N     0.7792    0.6327    0.6984      1857
           P     0.9227    0.6800    0.7829      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8704    0.7630    0.8077     21274
weighted avg     0.9000    0.9016    0.8965     21274

F1-macro tok:  0.8076583826036624
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 27
**************************************************

EPOCH: 29
Learning rate: 1.000000
train_cost_sum: 291670.32666015625
train_cost_avg: 34.137444599737385
train_count_sent: 8544.0
train_total_correct_sent: 8296.0
train_accuracy_sent: 0.9709737827715356
train_count_tok: 163566.0
train_total_correct_tok: 148856.0
train_accuracy_tok: 0.9100668843158114
train_label=0_precision_sent: 0.6257668711656442
train_label=0_recall_sent: 0.35294117647058826
train_label=0_f-score_sent: 0.4513274336283186
train_label=1_precision_sent: 0.9776876267748479
train_label=1_recall_sent: 0.992610539067232
train_label=1_f-score_sent: 0.9850925703294062
train_precision_macro_sent: 0.801727248970246
train_recall_macro_sent: 0.6727758577689101
train_f-score_macro_sent: 0.7182100019788624
train_precision_micro_sent: 0.9709737827715356
train_recall_micro_sent: 0.9709737827715356
train_f-score_micro_sent: 0.9709737827715356
train_label=O_precision_tok: 0.923230423413918
train_label=O_recall_tok: 0.9710970107843374
train_label=O_f-score_tok: 0.9465589615153973
train_label=N_precision_tok: 0.8178463052571148
train_label=N_recall_tok: 0.7021546261089987
train_label=N_f-score_tok: 0.7555976510702784
train_label=P_precision_tok: 0.88104378249672
train_label=P_recall_tok: 0.7247471719230923
train_label=P_f-score_tok: 0.7952890604438987
train_precision_macro_tok: 0.874040170389251
train_recall_macro_tok: 0.7993329362721427
train_f-score_macro_tok: 0.832481891009858
train_precision_micro_tok: 0.9100668843158114
train_recall_micro_tok: 0.9100668843158114
train_f-score_micro_tok: 0.9100668843158114
train_time: 141.43820548057556
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6258    0.3529    0.4513       289
           1     0.9777    0.9926    0.9851      8255

   micro avg     0.9710    0.9710    0.9710      8544
   macro avg     0.8017    0.6728    0.7182      8544
weighted avg     0.9658    0.9710    0.9670      8544

F1-macro sent:  0.7182100019788624
F1-micro sent:  0.9709737827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9232    0.9711    0.9466    124347
           N     0.8178    0.7022    0.7556     14202
           P     0.8810    0.7247    0.7953     25017

   micro avg     0.9101    0.9101    0.9101    163566
   macro avg     0.8740    0.7993    0.8325    163566
weighted avg     0.9076    0.9101    0.9068    163566

F1-macro tok:  0.832481891009858
F1-micro tok:  0.9100668843158114
**************************************************
dev_cost_sum: 41087.62823486328
dev_cost_avg: 37.318463428577004
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19073.0
dev_accuracy_tok: 0.896540377926107
dev_label=0_precision_sent: 0.7142857142857143
dev_label=0_recall_sent: 0.13513513513513514
dev_label=0_f-score_sent: 0.22727272727272727
dev_label=1_precision_sent: 0.9707495429616088
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9842446709916588
dev_precision_macro_sent: 0.8425176286236615
dev_recall_macro_sent: 0.5666277179435074
dev_f-score_macro_sent: 0.605758699132193
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9186376537369915
dev_label=O_recall_tok: 0.9587164455414995
dev_label=O_f-score_tok: 0.9382492375517105
dev_label=N_precision_tok: 0.7471124620060791
dev_label=N_recall_tok: 0.66182014001077
dev_label=N_f-score_tok: 0.7018846373500857
dev_label=P_precision_tok: 0.8494663231505337
dev_label=P_recall_tok: 0.7185554171855542
dev_label=P_f-score_tok: 0.7785461291954798
dev_precision_macro_tok: 0.8384054796312014
dev_recall_macro_tok: 0.7796973342459412
dev_f-score_macro_tok: 0.8062266680324254
dev_precision_micro_tok: 0.896540377926107
dev_recall_micro_tok: 0.896540377926107
dev_f-score_micro_tok: 0.896540377926107
dev_time: 8.327568531036377
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7143    0.1351    0.2273        37
           1     0.9707    0.9981    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8425    0.5666    0.6058      1101
weighted avg     0.9621    0.9691    0.9588      1101

F1-macro sent:  0.605758699132193
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9186    0.9587    0.9382     16205
           N     0.7471    0.6618    0.7019      1857
           P     0.8495    0.7186    0.7785      3212

   micro avg     0.8965    0.8965    0.8965     21274
   macro avg     0.8384    0.7797    0.8062     21274
weighted avg     0.8932    0.8965    0.8935     21274

F1-macro tok:  0.8062266680324254
F1-micro tok:  0.896540377926107
**************************************************
Best epoch: 27
**************************************************

EPOCH: 30
Learning rate: 1.000000
train_cost_sum: 290283.8474121094
train_cost_avg: 33.97516940684801
train_count_sent: 8544.0
train_total_correct_sent: 8310.0
train_accuracy_sent: 0.9726123595505618
train_count_tok: 163566.0
train_total_correct_tok: 149066.0
train_accuracy_tok: 0.9113507697198684
train_label=0_precision_sent: 0.6410256410256411
train_label=0_recall_sent: 0.43252595155709345
train_label=0_f-score_sent: 0.5165289256198347
train_label=1_precision_sent: 0.9803569289735298
train_label=1_recall_sent: 0.9915202907328892
train_label=1_f-score_sent: 0.9859070103589497
train_precision_macro_sent: 0.8106912849995854
train_recall_macro_sent: 0.7120231211449913
train_f-score_macro_sent: 0.7512179679893922
train_precision_micro_sent: 0.9726123595505618
train_recall_micro_sent: 0.9726123595505618
train_f-score_micro_sent: 0.9726123595505618
train_label=O_precision_tok: 0.9252875765401918
train_label=O_recall_tok: 0.9709763806123187
train_label=O_f-score_tok: 0.9475815628997701
train_label=N_precision_tok: 0.816721044045677
train_label=N_recall_tok: 0.7050415434445853
train_label=N_f-score_tok: 0.7567833119189782
train_label=P_precision_tok: 0.8797252509726692
train_label=P_recall_tok: 0.7321021705240437
train_label=P_f-score_tok: 0.7991535037961427
train_precision_macro_tok: 0.8739112905195127
train_recall_macro_tok: 0.8027066981936493
train_f-score_macro_tok: 0.8345061262049637
train_precision_micro_tok: 0.9113507697198684
train_recall_micro_tok: 0.9113507697198684
train_f-score_micro_tok: 0.9113507697198684
train_time: 141.54278564453125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6410    0.4325    0.5165       289
           1     0.9804    0.9915    0.9859      8255

   micro avg     0.9726    0.9726    0.9726      8544
   macro avg     0.8107    0.7120    0.7512      8544
weighted avg     0.9689    0.9726    0.9700      8544

F1-macro sent:  0.7512179679893922
F1-micro sent:  0.9726123595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9253    0.9710    0.9476    124347
           N     0.8167    0.7050    0.7568     14202
           P     0.8797    0.7321    0.7992     25017

   micro avg     0.9114    0.9114    0.9114    163566
   macro avg     0.8739    0.8027    0.8345    163566
weighted avg     0.9089    0.9114    0.9083    163566

F1-macro tok:  0.8345061262049637
F1-micro tok:  0.9113507697198684
**************************************************
dev_cost_sum: 41278.8583984375
dev_cost_avg: 37.49215113391235
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19208.0
dev_accuracy_tok: 0.9028861521105574
dev_label=0_precision_sent: 0.8
dev_label=0_recall_sent: 0.21621621621621623
dev_label=0_f-score_sent: 0.3404255319148936
dev_label=1_precision_sent: 0.9734188817598534
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9856148491879351
dev_precision_macro_sent: 0.8867094408799268
dev_recall_macro_sent: 0.607168258484048
dev_f-score_macro_sent: 0.6630201905514144
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9105251036388761
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9420665415661394
dev_label=N_precision_tok: 0.8109065155807366
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.7005200367084735
dev_label=P_precision_tok: 0.9017642341619888
dev_label=P_recall_tok: 0.700186799501868
dev_label=P_f-score_tok: 0.788293024886085
dev_precision_macro_tok: 0.8743986177938671
dev_recall_macro_tok: 0.7642147784261398
dev_f-score_macro_tok: 0.810293201053566
dev_precision_micro_tok: 0.9028861521105574
dev_recall_micro_tok: 0.9028861521105574
dev_f-score_micro_tok: 0.9028861521105574
dev_time: 8.298244953155518
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8000    0.2162    0.3404        37
           1     0.9734    0.9981    0.9856      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.8867    0.6072    0.6630      1101
weighted avg     0.9676    0.9718    0.9639      1101

F1-macro sent:  0.6630201905514144
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9759    0.9421     16205
           N     0.8109    0.6166    0.7005      1857
           P     0.9018    0.7002    0.7883      3212

   micro avg     0.9029    0.9029    0.9029     21274
   macro avg     0.8744    0.7642    0.8103     21274
weighted avg     0.9005    0.9029    0.8978     21274

F1-macro tok:  0.810293201053566
F1-micro tok:  0.9028861521105574
**************************************************
Best epoch: 30
**************************************************

EPOCH: 31
Learning rate: 1.000000
train_cost_sum: 288764.0022583008
train_cost_avg: 33.797284908508985
train_count_sent: 8544.0
train_total_correct_sent: 8292.0
train_accuracy_sent: 0.9705056179775281
train_count_tok: 163566.0
train_total_correct_tok: 149534.0
train_accuracy_tok: 0.9142120000489099
train_label=0_precision_sent: 0.6178343949044586
train_label=0_recall_sent: 0.3356401384083045
train_label=0_f-score_sent: 0.4349775784753363
train_label=1_precision_sent: 0.9771074281626326
train_label=1_recall_sent: 0.9927316777710479
train_label=1_f-score_sent: 0.9848575892320636
train_precision_macro_sent: 0.7974709115335457
train_recall_macro_sent: 0.6641859080896761
train_f-score_macro_sent: 0.7099175838537
train_precision_micro_sent: 0.9705056179775281
train_recall_micro_sent: 0.9705056179775281
train_f-score_micro_sent: 0.9705056179775281
train_label=O_precision_tok: 0.9276207153445005
train_label=O_recall_tok: 0.971306103082503
train_label=O_f-score_tok: 0.9489609114122963
train_label=N_precision_tok: 0.8236822870137254
train_label=N_recall_tok: 0.7141247711589916
train_label=N_f-score_tok: 0.7650009428625306
train_label=P_precision_tok: 0.884228028503563
train_label=P_recall_tok: 0.7440140704321062
train_label=P_f-score_tok: 0.808083877830117
train_precision_macro_tok: 0.8785103436205963
train_recall_macro_tok: 0.8098149815578669
train_f-score_macro_tok: 0.840681910701648
train_precision_micro_tok: 0.9142120000489099
train_recall_micro_tok: 0.9142120000489099
train_f-score_micro_tok: 0.91421200004891
train_time: 142.39830446243286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6178    0.3356    0.4350       289
           1     0.9771    0.9927    0.9849      8255

   micro avg     0.9705    0.9705    0.9705      8544
   macro avg     0.7975    0.6642    0.7099      8544
weighted avg     0.9650    0.9705    0.9663      8544

F1-macro sent:  0.7099175838537
F1-micro sent:  0.9705056179775281
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9276    0.9713    0.9490    124347
           N     0.8237    0.7141    0.7650     14202
           P     0.8842    0.7440    0.8081     25017

   micro avg     0.9142    0.9142    0.9142    163566
   macro avg     0.8785    0.8098    0.8407    163566
weighted avg     0.9120    0.9142    0.9114    163566

F1-macro tok:  0.840681910701648
F1-micro tok:  0.91421200004891
**************************************************
dev_cost_sum: 41057.863830566406
dev_cost_avg: 37.29142945555532
dev_count_sent: 1101.0
dev_total_correct_sent: 1071.0
dev_accuracy_sent: 0.9727520435967303
dev_count_tok: 21274.0
dev_total_correct_tok: 19169.0
dev_accuracy_tok: 0.9010529284572718
dev_label=0_precision_sent: 0.6666666666666666
dev_label=0_recall_sent: 0.3783783783783784
dev_label=0_f-score_sent: 0.48275862068965514
dev_label=1_precision_sent: 0.9787037037037037
dev_label=1_recall_sent: 0.993421052631579
dev_label=1_f-score_sent: 0.9860074626865671
dev_precision_macro_sent: 0.8226851851851852
dev_recall_macro_sent: 0.6858997155049786
dev_f-score_macro_sent: 0.7343830416881112
dev_precision_micro_sent: 0.9727520435967303
dev_recall_micro_sent: 0.9727520435967303
dev_f-score_micro_sent: 0.9727520435967303
dev_label=O_precision_tok: 0.9096406357982032
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.9410467991301499
dev_label=N_precision_tok: 0.8042402826855124
dev_label=N_recall_tok: 0.6128163704900377
dev_label=N_f-score_tok: 0.6955990220048899
dev_label=P_precision_tok: 0.8961923847695391
dev_label=P_recall_tok: 0.6961394769613948
dev_label=P_f-score_tok: 0.7835990888382688
dev_precision_macro_tok: 0.8700244344177516
dev_recall_macro_tok: 0.7612183381250738
dev_f-score_macro_tok: 0.8067483033244361
dev_precision_micro_tok: 0.9010529284572718
dev_recall_micro_tok: 0.9010529284572718
dev_f-score_micro_tok: 0.9010529284572718
dev_time: 8.197474002838135
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.3784    0.4828        37
           1     0.9787    0.9934    0.9860      1064

   micro avg     0.9728    0.9728    0.9728      1101
   macro avg     0.8227    0.6859    0.7344      1101
weighted avg     0.9682    0.9728    0.9691      1101

F1-macro sent:  0.7343830416881112
F1-micro sent:  0.9727520435967303
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9096    0.9747    0.9410     16205
           N     0.8042    0.6128    0.6956      1857
           P     0.8962    0.6961    0.7836      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8700    0.7612    0.8067     21274
weighted avg     0.8984    0.9011    0.8958     21274

F1-macro tok:  0.8067483033244361
F1-micro tok:  0.9010529284572718
**************************************************
Best epoch: 30
**************************************************

EPOCH: 32
Learning rate: 1.000000
train_cost_sum: 287849.86737060547
train_cost_avg: 33.69029346566075
train_count_sent: 8544.0
train_total_correct_sent: 8307.0
train_accuracy_sent: 0.9722612359550562
train_count_tok: 163566.0
train_total_correct_tok: 149658.0
train_accuracy_tok: 0.9149701038113055
train_label=0_precision_sent: 0.6171171171171171
train_label=0_recall_sent: 0.4740484429065744
train_label=0_f-score_sent: 0.5362035225048923
train_label=1_precision_sent: 0.9817351598173516
train_label=1_recall_sent: 0.9897032101756511
train_label=1_f-score_sent: 0.9857030825843035
train_precision_macro_sent: 0.7994261384672343
train_recall_macro_sent: 0.7318758265411127
train_f-score_macro_sent: 0.7609533025445979
train_precision_micro_sent: 0.9722612359550562
train_recall_micro_sent: 0.9722612359550562
train_f-score_micro_sent: 0.9722612359550562
train_label=O_precision_tok: 0.9285351865803595
train_label=O_recall_tok: 0.9713302291169067
train_label=O_f-score_tok: 0.9494507222167634
train_label=N_precision_tok: 0.824467654440936
train_label=N_recall_tok: 0.7170116884945782
train_label=N_f-score_tok: 0.766994313260272
train_label=P_precision_tok: 0.8843733737048777
train_label=P_recall_tok: 0.7472118959107806
train_label=P_f-score_tok: 0.8100272999090002
train_precision_macro_tok: 0.8791254049087244
train_recall_macro_tok: 0.8118512711740885
train_f-score_macro_tok: 0.8421574451286785
train_precision_micro_tok: 0.9149701038113055
train_recall_micro_tok: 0.9149701038113055
train_f-score_micro_tok: 0.9149701038113055
train_time: 122.53236627578735
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6171    0.4740    0.5362       289
           1     0.9817    0.9897    0.9857      8255

   micro avg     0.9723    0.9723    0.9723      8544
   macro avg     0.7994    0.7319    0.7610      8544
weighted avg     0.9694    0.9723    0.9705      8544

F1-macro sent:  0.7609533025445979
F1-micro sent:  0.9722612359550562
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9285    0.9713    0.9495    124347
           N     0.8245    0.7170    0.7670     14202
           P     0.8844    0.7472    0.8100     25017

   micro avg     0.9150    0.9150    0.9150    163566
   macro avg     0.8791    0.8119    0.8422    163566
weighted avg     0.9127    0.9150    0.9123    163566

F1-macro tok:  0.8421574451286785
F1-micro tok:  0.9149701038113055
**************************************************
dev_cost_sum: 41065.33630371094
dev_cost_avg: 37.298216442970876
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19126.0
dev_accuracy_tok: 0.8990316818651876
dev_label=0_precision_sent: 0.6666666666666666
dev_label=0_recall_sent: 0.16216216216216217
dev_label=0_f-score_sent: 0.26086956521739135
dev_label=1_precision_sent: 0.9716117216117216
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9842300556586271
dev_precision_macro_sent: 0.8191391941391941
dev_recall_macro_sent: 0.5796713066449908
dev_f-score_macro_sent: 0.6225498104380092
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9132739239326694
dev_label=O_recall_tok: 0.9676025917926566
dev_label=O_f-score_tok: 0.9396536225804518
dev_label=N_precision_tok: 0.8032440056417489
dev_label=N_recall_tok: 0.613354873451804
dev_label=N_f-score_tok: 0.6955725190839694
dev_label=P_precision_tok: 0.8585783401563082
dev_label=P_recall_tok: 0.7182440846824408
dev_label=P_f-score_tok: 0.7821664688930327
dev_precision_macro_tok: 0.8583654232435755
dev_recall_macro_tok: 0.7664005166423005
dev_f-score_macro_tok: 0.8057975368524847
dev_precision_micro_tok: 0.8990316818651876
dev_recall_micro_tok: 0.8990316818651876
dev_f-score_micro_tok: 0.8990316818651876
dev_time: 5.011849641799927
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.1622    0.2609        37
           1     0.9716    0.9972    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8191    0.5797    0.6225      1101
weighted avg     0.9614    0.9691    0.9599      1101

F1-macro sent:  0.6225498104380092
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9133    0.9676    0.9397     16205
           N     0.8032    0.6134    0.6956      1857
           P     0.8586    0.7182    0.7822      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8584    0.7664    0.8058     21274
weighted avg     0.8954    0.8990    0.8946     21274

F1-macro tok:  0.8057975368524847
F1-micro tok:  0.8990316818651876
**************************************************
Best epoch: 30
**************************************************

EPOCH: 33
Learning rate: 1.000000
train_cost_sum: 285877.75231933594
train_cost_avg: 33.45947475647658
train_count_sent: 8544.0
train_total_correct_sent: 8326.0
train_accuracy_sent: 0.9744850187265918
train_count_tok: 163566.0
train_total_correct_tok: 150190.0
train_accuracy_tok: 0.9182226135015834
train_label=0_precision_sent: 0.6820512820512821
train_label=0_recall_sent: 0.4602076124567474
train_label=0_f-score_sent: 0.5495867768595041
train_label=1_precision_sent: 0.9813151275601868
train_label=1_recall_sent: 0.9924894003634162
train_label=1_f-score_sent: 0.9868706335822692
train_precision_macro_sent: 0.8316832048057344
train_recall_macro_sent: 0.7263485064100818
train_f-score_macro_sent: 0.7682287052208867
train_precision_micro_sent: 0.9744850187265918
train_recall_micro_sent: 0.9744850187265918
train_f-score_micro_sent: 0.9744850187265918
train_label=O_precision_tok: 0.9313184696691884
train_label=O_recall_tok: 0.9721746403210371
train_label=O_f-score_tok: 0.9513080909230411
train_label=N_precision_tok: 0.8304662379421222
train_label=N_recall_tok: 0.7274327559498662
train_label=N_f-score_tok: 0.775542376698446
train_label=P_precision_tok: 0.8897017445132246
train_label=P_recall_tok: 0.758364312267658
train_label=P_f-score_tok: 0.8187997669450378
train_precision_macro_tok: 0.883828817374845
train_recall_macro_tok: 0.8193239028461871
train_f-score_macro_tok: 0.8485500781888415
train_precision_micro_tok: 0.9182226135015834
train_recall_micro_tok: 0.9182226135015834
train_f-score_micro_tok: 0.9182226135015834
train_time: 92.74653553962708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6821    0.4602    0.5496       289
           1     0.9813    0.9925    0.9869      8255

   micro avg     0.9745    0.9745    0.9745      8544
   macro avg     0.8317    0.7263    0.7682      8544
weighted avg     0.9712    0.9745    0.9721      8544

F1-macro sent:  0.7682287052208867
F1-micro sent:  0.9744850187265918
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9313    0.9722    0.9513    124347
           N     0.8305    0.7274    0.7755     14202
           P     0.8897    0.7584    0.8188     25017

   micro avg     0.9182    0.9182    0.9182    163566
   macro avg     0.8838    0.8193    0.8486    163566
weighted avg     0.9162    0.9182    0.9158    163566

F1-macro tok:  0.8485500781888415
F1-micro tok:  0.9182226135015834
**************************************************
dev_cost_sum: 41184.400329589844
dev_cost_avg: 37.406358155849084
dev_count_sent: 1101.0
dev_total_correct_sent: 1073.0
dev_accuracy_sent: 0.9745685740236149
dev_count_tok: 21274.0
dev_total_correct_tok: 19171.0
dev_accuracy_tok: 0.901146939926671
dev_label=0_precision_sent: 0.7142857142857143
dev_label=0_recall_sent: 0.40540540540540543
dev_label=0_f-score_sent: 0.5172413793103449
dev_label=1_precision_sent: 0.9796296296296296
dev_label=1_recall_sent: 0.9943609022556391
dev_label=1_f-score_sent: 0.9869402985074627
dev_precision_macro_sent: 0.8469576719576719
dev_recall_macro_sent: 0.6998831538305222
dev_f-score_macro_sent: 0.7520908389089038
dev_precision_micro_sent: 0.9745685740236149
dev_recall_micro_sent: 0.9745685740236149
dev_f-score_micro_sent: 0.9745685740236149
dev_label=O_precision_tok: 0.9146568798788303
dev_label=O_recall_tok: 0.9688984881209504
dev_label=O_f-score_tok: 0.9409966737586527
dev_label=N_precision_tok: 0.7993127147766323
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.7022946859903383
dev_label=P_precision_tok: 0.8695816057293629
dev_label=P_recall_tok: 0.7182440846824408
dev_label=P_f-score_tok: 0.7867007672634271
dev_precision_macro_tok: 0.8611837334616085
dev_recall_macro_tok: 0.7711405057791954
dev_f-score_macro_tok: 0.8099973756708061
dev_precision_micro_tok: 0.901146939926671
dev_recall_micro_tok: 0.901146939926671
dev_f-score_micro_tok: 0.901146939926671
dev_time: 5.018356561660767
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7143    0.4054    0.5172        37
           1     0.9796    0.9944    0.9869      1064

   micro avg     0.9746    0.9746    0.9746      1101
   macro avg     0.8470    0.6999    0.7521      1101
weighted avg     0.9707    0.9746    0.9712      1101

F1-macro sent:  0.7520908389089038
F1-micro sent:  0.9745685740236149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9689    0.9410     16205
           N     0.7993    0.6263    0.7023      1857
           P     0.8696    0.7182    0.7867      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8612    0.7711    0.8100     21274
weighted avg     0.8978    0.9011    0.8969     21274

F1-macro tok:  0.8099973756708061
F1-micro tok:  0.901146939926671
**************************************************
Best epoch: 30
**************************************************

EPOCH: 34
Learning rate: 1.000000
train_cost_sum: 285152.7299194336
train_cost_avg: 33.37461726585131
train_count_sent: 8544.0
train_total_correct_sent: 8313.0
train_accuracy_sent: 0.9729634831460674
train_count_tok: 163566.0
train_total_correct_tok: 150255.0
train_accuracy_tok: 0.9186200066028393
train_label=0_precision_sent: 0.6294642857142857
train_label=0_recall_sent: 0.48788927335640137
train_label=0_f-score_sent: 0.5497076023391813
train_label=1_precision_sent: 0.9822115384615384
train_label=1_recall_sent: 0.9899454875832828
train_label=1_f-score_sent: 0.9860633484162895
train_precision_macro_sent: 0.805837912087912
train_recall_macro_sent: 0.7389173804698421
train_f-score_macro_sent: 0.7678854753777353
train_precision_micro_sent: 0.9729634831460674
train_recall_micro_sent: 0.9729634831460674
train_f-score_micro_sent: 0.9729634831460674
train_label=O_precision_tok: 0.9327156204154119
train_label=O_recall_tok: 0.9714428172774574
train_label=O_f-score_tok: 0.9516853976845231
train_label=N_precision_tok: 0.8300247149804671
train_label=N_recall_tok: 0.733065765385157
train_label=N_f-score_tok: 0.778538044494298
train_label=P_precision_tok: 0.8854181192767164
train_label=P_recall_tok: 0.7614022464723987
train_label=P_f-score_tok: 0.8187405974640016
train_precision_macro_tok: 0.8827194848908652
train_recall_macro_tok: 0.8219702763783377
train_f-score_macro_tok: 0.849654679880941
train_precision_micro_tok: 0.9186200066028393
train_recall_micro_tok: 0.9186200066028393
train_f-score_micro_tok: 0.9186200066028393
train_time: 93.31416249275208
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6295    0.4879    0.5497       289
           1     0.9822    0.9899    0.9861      8255

   micro avg     0.9730    0.9730    0.9730      8544
   macro avg     0.8058    0.7389    0.7679      8544
weighted avg     0.9703    0.9730    0.9713      8544

F1-macro sent:  0.7678854753777353
F1-micro sent:  0.9729634831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9327    0.9714    0.9517    124347
           N     0.8300    0.7331    0.7785     14202
           P     0.8854    0.7614    0.8187     25017

   micro avg     0.9186    0.9186    0.9186    163566
   macro avg     0.8827    0.8220    0.8497    163566
weighted avg     0.9166    0.9186    0.9163    163566

F1-macro tok:  0.849654679880941
F1-micro tok:  0.9186200066028393
**************************************************
dev_cost_sum: 41105.879150390625
dev_cost_avg: 37.33504010026397
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 19175.0
dev_accuracy_tok: 0.9013349628654695
dev_label=0_precision_sent: 0.7272727272727273
dev_label=0_recall_sent: 0.21621621621621623
dev_label=0_f-score_sent: 0.33333333333333337
dev_label=1_precision_sent: 0.9733944954128441
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9851439182915506
dev_precision_macro_sent: 0.8503336113427857
dev_recall_macro_sent: 0.6066983336720179
dev_f-score_macro_sent: 0.659238625812442
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.9145652553724303
dev_label=O_recall_tok: 0.9690836161678494
dev_label=O_f-score_tok: 0.9410354745925216
dev_label=N_precision_tok: 0.8138222849083215
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.7047328244274809
dev_label=P_precision_tok: 0.8629422718808194
dev_label=P_recall_tok: 0.7213574097135741
dev_label=P_f-score_tok: 0.7858232999830422
dev_precision_macro_tok: 0.8637766040538571
dev_recall_macro_tok: 0.7706244812532406
dev_f-score_macro_tok: 0.8105305330010149
dev_precision_micro_tok: 0.9013349628654695
dev_recall_micro_tok: 0.9013349628654695
dev_f-score_micro_tok: 0.9013349628654695
dev_time: 4.8591649532318115
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7273    0.2162    0.3333        37
           1     0.9734    0.9972    0.9851      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.8503    0.6067    0.6592      1101
weighted avg     0.9651    0.9709    0.9632      1101

F1-macro sent:  0.659238625812442
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9146    0.9691    0.9410     16205
           N     0.8138    0.6214    0.7047      1857
           P     0.8629    0.7214    0.7858      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8638    0.7706    0.8105     21274
weighted avg     0.8980    0.9013    0.8970     21274

F1-macro tok:  0.8105305330010149
F1-micro tok:  0.9013349628654695
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 1.000000
train_cost_sum: 283642.3988647461
train_cost_avg: 33.19784630907609
train_count_sent: 8544.0
train_total_correct_sent: 8322.0
train_accuracy_sent: 0.9740168539325843
train_count_tok: 163566.0
train_total_correct_tok: 150546.0
train_accuracy_tok: 0.9203991049484612
train_label=0_precision_sent: 0.6700507614213198
train_label=0_recall_sent: 0.45674740484429066
train_label=0_f-score_sent: 0.5432098765432098
train_label=1_precision_sent: 0.9811908470109021
train_label=1_recall_sent: 0.9921259842519685
train_label=1_f-score_sent: 0.986628117094326
train_precision_macro_sent: 0.825620804216111
train_recall_macro_sent: 0.7244366945481295
train_f-score_macro_sent: 0.764918996818768
train_precision_micro_sent: 0.9740168539325843
train_recall_micro_sent: 0.9740168539325843
train_f-score_micro_sent: 0.9740168539325843
train_label=O_precision_tok: 0.9344297787778267
train_label=O_recall_tok: 0.9718529598623208
train_label=O_f-score_tok: 0.9527740328137688
train_label=N_precision_tok: 0.8304093567251462
train_label=N_recall_tok: 0.7398957893254471
train_label=N_f-score_tok: 0.7825439380399165
train_label=P_precision_tok: 0.8890896455872134
train_label=P_recall_tok: 0.7671183595155294
train_label=P_f-score_tok: 0.8236127204840994
train_precision_macro_tok: 0.8846429270300621
train_recall_macro_tok: 0.8262890362344324
train_f-score_macro_tok: 0.8529768971125948
train_precision_micro_tok: 0.9203991049484612
train_recall_micro_tok: 0.9203991049484612
train_f-score_micro_tok: 0.9203991049484612
train_time: 92.89675545692444
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6701    0.4567    0.5432       289
           1     0.9812    0.9921    0.9866      8255

   micro avg     0.9740    0.9740    0.9740      8544
   macro avg     0.8256    0.7244    0.7649      8544
weighted avg     0.9707    0.9740    0.9716      8544

F1-macro sent:  0.764918996818768
F1-micro sent:  0.9740168539325843
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9344    0.9719    0.9528    124347
           N     0.8304    0.7399    0.7825     14202
           P     0.8891    0.7671    0.8236     25017

   micro avg     0.9204    0.9204    0.9204    163566
   macro avg     0.8846    0.8263    0.8530    163566
weighted avg     0.9185    0.9204    0.9182    163566

F1-macro tok:  0.8529768971125948
F1-micro tok:  0.9203991049484612
**************************************************
dev_cost_sum: 41189.796325683594
dev_cost_avg: 37.41125915139291
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19100.0
dev_accuracy_tok: 0.8978095327629971
dev_label=0_precision_sent: 0.6153846153846154
dev_label=0_recall_sent: 0.21621621621621623
dev_label=0_f-score_sent: 0.32
dev_label=1_precision_sent: 0.9733455882352942
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9842007434944239
dev_precision_macro_sent: 0.7943651018099548
dev_recall_macro_sent: 0.6057584840479577
dev_f-score_macro_sent: 0.6521003717472119
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.917796110783736
dev_label=O_recall_tok: 0.9611231101511879
dev_label=O_f-score_tok: 0.9389600602863601
dev_label=N_precision_tok: 0.7913862718707941
dev_label=N_recall_tok: 0.6332794830371568
dev_label=N_f-score_tok: 0.703559676936883
dev_label=P_precision_tok: 0.8335699077359829
dev_label=P_recall_tok: 0.7313200498132005
dev_label=P_f-score_tok: 0.7791044776119403
dev_precision_macro_tok: 0.8475840967968377
dev_recall_macro_tok: 0.775240881000515
dev_f-score_macro_tok: 0.8072080716117278
dev_precision_micro_tok: 0.8978095327629971
dev_recall_micro_tok: 0.8978095327629971
dev_f-score_micro_tok: 0.8978095327629971
dev_time: 5.19054913520813
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6154    0.2162    0.3200        37
           1     0.9733    0.9953    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.7944    0.6058    0.6521      1101
weighted avg     0.9613    0.9691    0.9619      1101

F1-macro sent:  0.6521003717472119
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9178    0.9611    0.9390     16205
           N     0.7914    0.6333    0.7036      1857
           P     0.8336    0.7313    0.7791      3212

   micro avg     0.8978    0.8978    0.8978     21274
   macro avg     0.8476    0.7752    0.8072     21274
weighted avg     0.8940    0.8978    0.8943     21274

F1-macro tok:  0.8072080716117278
F1-micro tok:  0.8978095327629971
**************************************************
Best epoch: 34
**************************************************

EPOCH: 36
Learning rate: 1.000000
train_cost_sum: 282241.4741821289
train_cost_avg: 33.03388040521172
train_count_sent: 8544.0
train_total_correct_sent: 8345.0
train_accuracy_sent: 0.9767088014981273
train_count_tok: 163566.0
train_total_correct_tok: 150941.0
train_accuracy_tok: 0.9228140322560924
train_label=0_precision_sent: 0.7184466019417476
train_label=0_recall_sent: 0.5121107266435986
train_label=0_f-score_sent: 0.597979797979798
train_label=1_precision_sent: 0.9830894698968577
train_label=1_recall_sent: 0.9929739551786796
train_label=1_f-score_sent: 0.988006990899777
train_precision_macro_sent: 0.8507680359193026
train_recall_macro_sent: 0.7525423409111391
train_f-score_macro_sent: 0.7929933944397874
train_precision_micro_sent: 0.9767088014981273
train_recall_micro_sent: 0.9767088014981273
train_f-score_micro_sent: 0.9767088014981273
train_label=O_precision_tok: 0.9371510545905707
train_label=O_recall_tok: 0.9719172959540641
train_label=O_f-score_tok: 0.9542176094620363
train_label=N_precision_tok: 0.8365226899945325
train_label=N_recall_tok: 0.7541191381495564
train_label=N_f-score_tok: 0.7931864469542677
train_label=P_precision_tok: 0.8886850433426593
train_label=P_recall_tok: 0.7745133309349642
train_label=P_f-score_tok: 0.8276804784280222
train_precision_macro_tok: 0.8874529293092541
train_recall_macro_tok: 0.8335165883461949
train_f-score_macro_tok: 0.8583615116147754
train_precision_micro_tok: 0.9228140322560924
train_recall_micro_tok: 0.9228140322560924
train_f-score_micro_tok: 0.9228140322560924
train_time: 93.51087188720703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7184    0.5121    0.5980       289
           1     0.9831    0.9930    0.9880      8255

   micro avg     0.9767    0.9767    0.9767      8544
   macro avg     0.8508    0.7525    0.7930      8544
weighted avg     0.9741    0.9767    0.9748      8544

F1-macro sent:  0.7929933944397874
F1-micro sent:  0.9767088014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9372    0.9719    0.9542    124347
           N     0.8365    0.7541    0.7932     14202
           P     0.8887    0.7745    0.8277     25017

   micro avg     0.9228    0.9228    0.9228    163566
   macro avg     0.8875    0.8335    0.8584    163566
weighted avg     0.9210    0.9228    0.9209    163566

F1-macro tok:  0.8583615116147754
F1-micro tok:  0.9228140322560924
**************************************************
dev_cost_sum: 41109.287536621094
dev_cost_avg: 37.33813581891108
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19168.0
dev_accuracy_tok: 0.9010059227225722
dev_label=0_precision_sent: 0.6071428571428571
dev_label=0_recall_sent: 0.4594594594594595
dev_label=0_f-score_sent: 0.5230769230769231
dev_label=1_precision_sent: 0.9813606710158435
dev_label=1_recall_sent: 0.9896616541353384
dev_label=1_f-score_sent: 0.985493682732803
dev_precision_macro_sent: 0.7942517640793503
dev_recall_macro_sent: 0.724560556797399
dev_f-score_macro_sent: 0.7542853029048631
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9141743279413476
dev_label=O_recall_tok: 0.969515581610614
dev_label=O_f-score_tok: 0.9410320146147165
dev_label=N_precision_tok: 0.809052333804809
dev_label=N_recall_tok: 0.6160473882606354
dev_label=N_f-score_tok: 0.6994802812595536
dev_label=P_precision_tok: 0.8649962602842184
dev_label=P_recall_tok: 0.7201120797011208
dev_label=P_f-score_tok: 0.7859327217125381
dev_precision_macro_tok: 0.862740974010125
dev_recall_macro_tok: 0.7685583498574567
dev_f-score_macro_tok: 0.8088150058622694
dev_precision_micro_tok: 0.9010059227225722
dev_recall_micro_tok: 0.9010059227225722
dev_f-score_micro_tok: 0.9010059227225722
dev_time: 5.018635034561157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6071    0.4595    0.5231        37
           1     0.9814    0.9897    0.9855      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.7943    0.7246    0.7543      1101
weighted avg     0.9688    0.9718    0.9700      1101

F1-macro sent:  0.7542853029048631
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9142    0.9695    0.9410     16205
           N     0.8091    0.6160    0.6995      1857
           P     0.8650    0.7201    0.7859      3212

   micro avg     0.9010    0.9010    0.9010     21274
   macro avg     0.8627    0.7686    0.8088     21274
weighted avg     0.8976    0.9010    0.8965     21274

F1-macro tok:  0.8088150058622694
F1-micro tok:  0.9010059227225722
**************************************************
Best epoch: 34
**************************************************

EPOCH: 37
Learning rate: 1.000000
train_cost_sum: 281142.4564819336
train_cost_avg: 32.90525005640608
train_count_sent: 8544.0
train_total_correct_sent: 8334.0
train_accuracy_sent: 0.9754213483146067
train_count_tok: 163566.0
train_total_correct_tok: 151099.0
train_accuracy_tok: 0.9237800031791448
train_label=0_precision_sent: 0.6652719665271967
train_label=0_recall_sent: 0.5501730103806228
train_label=0_f-score_sent: 0.6022727272727273
train_label=1_precision_sent: 0.9843467790487658
train_label=1_recall_sent: 0.9903089036947305
train_label=1_f-score_sent: 0.9873188405797102
train_precision_macro_sent: 0.8248093727879813
train_recall_macro_sent: 0.7702409570376767
train_f-score_macro_sent: 0.7947957839262187
train_precision_micro_sent: 0.9754213483146067
train_recall_micro_sent: 0.9754213483146067
train_f-score_micro_sent: 0.9754213483146067
train_label=O_precision_tok: 0.938168828143201
train_label=O_recall_tok: 0.9715393214150724
train_label=O_f-score_tok: 0.9545625145683616
train_label=N_precision_tok: 0.8403774173424828
train_label=N_recall_tok: 0.7588367835516124
train_label=N_f-score_tok: 0.7975283060756309
train_label=P_precision_tok: 0.888130347715274
train_label=P_recall_tok: 0.7800295798856778
train_label=P_f-score_tok: 0.8305773691715083
train_precision_macro_tok: 0.8888921977336525
train_recall_macro_tok: 0.8368018949507876
train_f-score_macro_tok: 0.8608893966051668
train_precision_micro_tok: 0.9237800031791448
train_recall_micro_tok: 0.9237800031791448
train_f-score_micro_tok: 0.9237800031791448
train_time: 92.07987642288208
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6653    0.5502    0.6023       289
           1     0.9843    0.9903    0.9873      8255

   micro avg     0.9754    0.9754    0.9754      8544
   macro avg     0.8248    0.7702    0.7948      8544
weighted avg     0.9736    0.9754    0.9743      8544

F1-macro sent:  0.7947957839262187
F1-micro sent:  0.9754213483146067
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9382    0.9715    0.9546    124347
           N     0.8404    0.7588    0.7975     14202
           P     0.8881    0.7800    0.8306     25017

   micro avg     0.9238    0.9238    0.9238    163566
   macro avg     0.8889    0.8368    0.8609    163566
weighted avg     0.9220    0.9238    0.9220    163566

F1-macro tok:  0.8608893966051668
F1-micro tok:  0.9237800031791448
**************************************************
dev_cost_sum: 40965.583923339844
dev_cost_avg: 37.207614825921745
dev_count_sent: 1101.0
dev_total_correct_sent: 1069.0
dev_accuracy_sent: 0.9709355131698456
dev_count_tok: 21274.0
dev_total_correct_tok: 19111.0
dev_accuracy_tok: 0.8983265958446931
dev_label=0_precision_sent: 0.7777777777777778
dev_label=0_recall_sent: 0.1891891891891892
dev_label=0_f-score_sent: 0.30434782608695654
dev_label=1_precision_sent: 0.9725274725274725
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9851576994434138
dev_precision_macro_sent: 0.8751526251526252
dev_recall_macro_sent: 0.5936547449705345
dev_f-score_macro_sent: 0.6447527627651852
dev_precision_micro_sent: 0.9709355131698456
dev_recall_micro_sent: 0.9709355131698456
dev_f-score_micro_sent: 0.9709355131698456
dev_label=O_precision_tok: 0.9202842759846017
dev_label=O_recall_tok: 0.9589015735883987
dev_label=O_f-score_tok: 0.9391961317618616
dev_label=N_precision_tok: 0.7292271934921557
dev_label=N_recall_tok: 0.6758212170166936
dev_label=N_f-score_tok: 0.7015092230296255
dev_label=P_precision_tok: 0.868440779610195
dev_label=P_recall_tok: 0.7213574097135741
dev_label=P_f-score_tok: 0.7880952380952381
dev_precision_macro_tok: 0.8393174163623174
dev_recall_macro_tok: 0.7853600667728888
dev_f-score_macro_tok: 0.8096001976289083
dev_precision_micro_tok: 0.8983265958446931
dev_recall_micro_tok: 0.8983265958446931
dev_f-score_micro_tok: 0.8983265958446931
dev_time: 4.973994970321655
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7778    0.1892    0.3043        37
           1     0.9725    0.9981    0.9852      1064

   micro avg     0.9709    0.9709    0.9709      1101
   macro avg     0.8752    0.5937    0.6448      1101
weighted avg     0.9660    0.9709    0.9623      1101

F1-macro sent:  0.6447527627651852
F1-micro sent:  0.9709355131698456
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9203    0.9589    0.9392     16205
           N     0.7292    0.6758    0.7015      1857
           P     0.8684    0.7214    0.7881      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8393    0.7854    0.8096     21274
weighted avg     0.8958    0.8983    0.8956     21274

F1-macro tok:  0.8096001976289083
F1-micro tok:  0.8983265958446931
**************************************************
Best epoch: 34
**************************************************

EPOCH: 38
Learning rate: 1.000000
train_cost_sum: 280053.90838623047
train_cost_avg: 32.77784508265806
train_count_sent: 8544.0
train_total_correct_sent: 8340.0
train_accuracy_sent: 0.976123595505618
train_count_tok: 163566.0
train_total_correct_tok: 151403.0
train_accuracy_tok: 0.9256385801450179
train_label=0_precision_sent: 0.6888888888888889
train_label=0_recall_sent: 0.5363321799307958
train_label=0_f-score_sent: 0.603112840466926
train_label=1_precision_sent: 0.9838922947469648
train_label=1_recall_sent: 0.9915202907328892
train_label=1_f-score_sent: 0.9876915651019671
train_precision_macro_sent: 0.8363905918179269
train_recall_macro_sent: 0.7639262353318426
train_f-score_macro_sent: 0.7954022027844465
train_precision_micro_sent: 0.976123595505618
train_recall_micro_sent: 0.976123595505618
train_f-score_micro_sent: 0.976123595505618
train_label=O_precision_tok: 0.9401731339104463
train_label=O_recall_tok: 0.9721103042292938
train_label=O_f-score_tok: 0.955875026688492
train_label=N_precision_tok: 0.8411403713198167
train_label=N_recall_tok: 0.7624278270666104
train_label=N_f-score_tok: 0.7998522622345338
train_label=P_precision_tok: 0.8903354127113281
train_label=P_recall_tok: 0.7873046328496622
train_label=P_f-score_tok: 0.835656250662933
train_precision_macro_tok: 0.8905496393138637
train_recall_macro_tok: 0.8406142547151888
train_f-score_macro_tok: 0.8637945131953195
train_precision_micro_tok: 0.9256385801450179
train_recall_micro_tok: 0.9256385801450179
train_f-score_micro_tok: 0.9256385801450179
train_time: 93.55322432518005
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6889    0.5363    0.6031       289
           1     0.9839    0.9915    0.9877      8255

   micro avg     0.9761    0.9761    0.9761      8544
   macro avg     0.8364    0.7639    0.7954      8544
weighted avg     0.9739    0.9761    0.9747      8544

F1-macro sent:  0.7954022027844465
F1-micro sent:  0.976123595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9402    0.9721    0.9559    124347
           N     0.8411    0.7624    0.7999     14202
           P     0.8903    0.7873    0.8357     25017

   micro avg     0.9256    0.9256    0.9256    163566
   macro avg     0.8905    0.8406    0.8638    163566
weighted avg     0.9240    0.9256    0.9239    163566

F1-macro tok:  0.8637945131953195
F1-micro tok:  0.9256385801450179
**************************************************
dev_cost_sum: 41033.712158203125
dev_cost_avg: 37.26949333170129
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19185.0
dev_accuracy_tok: 0.9018050202124659
dev_label=0_precision_sent: 0.65
dev_label=0_recall_sent: 0.35135135135135137
dev_label=0_f-score_sent: 0.456140350877193
dev_label=1_precision_sent: 0.9777983348751156
dev_label=1_recall_sent: 0.993421052631579
dev_label=1_f-score_sent: 0.9855477855477855
dev_precision_macro_sent: 0.8138991674375577
dev_recall_macro_sent: 0.6723862019914651
dev_f-score_macro_sent: 0.7208440682124893
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9150064080158453
dev_label=O_recall_tok: 0.9692687442147485
dev_label=O_f-score_tok: 0.9413562674178179
dev_label=N_precision_tok: 0.77734375
dev_label=N_recall_tok: 0.6429725363489499
dev_label=N_f-score_tok: 0.7038019451812555
dev_label=P_precision_tok: 0.8880248833592534
dev_label=P_recall_tok: 0.7110834371108343
dev_label=P_f-score_tok: 0.7897648686030427
dev_precision_macro_tok: 0.8601250137916997
dev_recall_macro_tok: 0.7744415725581776
dev_f-score_macro_tok: 0.8116410270673721
dev_precision_micro_tok: 0.9018050202124659
dev_recall_micro_tok: 0.9018050202124659
dev_f-score_micro_tok: 0.9018050202124659
dev_time: 4.9278564453125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6500    0.3514    0.4561        37
           1     0.9778    0.9934    0.9855      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.8139    0.6724    0.7208      1101
weighted avg     0.9668    0.9718    0.9678      1101

F1-macro sent:  0.7208440682124893
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9150    0.9693    0.9414     16205
           N     0.7773    0.6430    0.7038      1857
           P     0.8880    0.7111    0.7898      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8601    0.7744    0.8116     21274
weighted avg     0.8989    0.9018    0.8977     21274

F1-macro tok:  0.8116410270673721
F1-micro tok:  0.9018050202124659
**************************************************
Best epoch: 38
**************************************************

EPOCH: 39
Learning rate: 1.000000
train_cost_sum: 278699.6424560547
train_cost_avg: 32.619340175100035
train_count_sent: 8544.0
train_total_correct_sent: 8348.0
train_accuracy_sent: 0.9770599250936329
train_count_tok: 163566.0
train_total_correct_tok: 151717.0
train_accuracy_tok: 0.9275582945110842
train_label=0_precision_sent: 0.6962025316455697
train_label=0_recall_sent: 0.5709342560553633
train_label=0_f-score_sent: 0.6273764258555133
train_label=1_precision_sent: 0.9850728301432526
train_label=1_recall_sent: 0.9912780133252574
train_label=1_f-score_sent: 0.9881656804733727
train_precision_macro_sent: 0.8406376808944112
train_recall_macro_sent: 0.7811061346903103
train_f-score_macro_sent: 0.8077710531644431
train_precision_micro_sent: 0.9770599250936329
train_recall_micro_sent: 0.9770599250936329
train_f-score_micro_sent: 0.9770599250936329
train_label=O_precision_tok: 0.9414831936370075
train_label=O_recall_tok: 0.9728742953187451
train_label=O_f-score_tok: 0.9569213732004429
train_label=N_precision_tok: 0.8487479649585239
train_label=N_recall_tok: 0.7708773412195465
train_label=N_f-score_tok: 0.8079406663960739
train_label=P_precision_tok: 0.89271218544241
train_label=P_recall_tok: 0.7912619418795219
train_label=P_f-score_tok: 0.8389311521264647
train_precision_macro_tok: 0.894314448012647
train_recall_macro_tok: 0.8450045261392711
train_f-score_macro_tok: 0.8679310639076605
train_precision_micro_tok: 0.9275582945110842
train_recall_micro_tok: 0.9275582945110842
train_f-score_micro_tok: 0.9275582945110842
train_time: 93.13088297843933
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6962    0.5709    0.6274       289
           1     0.9851    0.9913    0.9882      8255

   micro avg     0.9771    0.9771    0.9771      8544
   macro avg     0.8406    0.7811    0.8078      8544
weighted avg     0.9753    0.9771    0.9760      8544

F1-macro sent:  0.8077710531644431
F1-micro sent:  0.9770599250936329
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9415    0.9729    0.9569    124347
           N     0.8487    0.7709    0.8079     14202
           P     0.8927    0.7913    0.8389     25017

   micro avg     0.9276    0.9276    0.9276    163566
   macro avg     0.8943    0.8450    0.8679    163566
weighted avg     0.9260    0.9276    0.9259    163566

F1-macro tok:  0.8679310639076605
F1-micro tok:  0.9275582945110842
**************************************************
dev_cost_sum: 41205.167053222656
dev_cost_avg: 37.42521984852194
dev_count_sent: 1101.0
dev_total_correct_sent: 1072.0
dev_accuracy_sent: 0.9736603088101726
dev_count_tok: 21274.0
dev_total_correct_tok: 19112.0
dev_accuracy_tok: 0.8983736015793927
dev_label=0_precision_sent: 0.7222222222222222
dev_label=0_recall_sent: 0.35135135135135137
dev_label=0_f-score_sent: 0.4727272727272727
dev_label=1_precision_sent: 0.9778393351800554
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9864927806241267
dev_precision_macro_sent: 0.8500307787011387
dev_recall_macro_sent: 0.6733260516155253
dev_f-score_macro_sent: 0.7296100266756997
dev_precision_micro_sent: 0.9736603088101726
dev_recall_micro_sent: 0.9736603088101726
dev_f-score_micro_sent: 0.9736603088101726
dev_label=O_precision_tok: 0.922071751009741
dev_label=O_recall_tok: 0.9579759333539031
dev_label=O_f-score_tok: 0.9396810023909687
dev_label=N_precision_tok: 0.7402826855123675
dev_label=N_recall_tok: 0.6768982229402262
dev_label=N_f-score_tok: 0.7071729957805907
dev_label=P_precision_tok: 0.8507299270072993
dev_label=P_recall_tok: 0.7257160647571607
dev_label=P_f-score_tok: 0.783266129032258
dev_precision_macro_tok: 0.837694787843136
dev_recall_macro_tok: 0.7868634070170967
dev_f-score_macro_tok: 0.8100400424012725
dev_precision_micro_tok: 0.8983736015793927
dev_recall_micro_tok: 0.8983736015793927
dev_f-score_micro_tok: 0.8983736015793927
dev_time: 4.998433828353882
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7222    0.3514    0.4727        37
           1     0.9778    0.9953    0.9865      1064

   micro avg     0.9737    0.9737    0.9737      1101
   macro avg     0.8500    0.6733    0.7296      1101
weighted avg     0.9692    0.9737    0.9692      1101

F1-macro sent:  0.7296100266756997
F1-micro sent:  0.9736603088101726
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9221    0.9580    0.9397     16205
           N     0.7403    0.6769    0.7072      1857
           P     0.8507    0.7257    0.7833      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8377    0.7869    0.8100     21274
weighted avg     0.8954    0.8984    0.8958     21274

F1-macro tok:  0.8100400424012725
F1-micro tok:  0.8983736015793927
**************************************************
Best epoch: 38
**************************************************

EPOCH: 40
Learning rate: 1.000000
train_cost_sum: 277367.57275390625
train_cost_avg: 32.46343314067255
train_count_sent: 8544.0
train_total_correct_sent: 8343.0
train_accuracy_sent: 0.9764747191011236
train_count_tok: 163566.0
train_total_correct_tok: 152172.0
train_accuracy_tok: 0.9303400462198745
train_label=0_precision_sent: 0.6946902654867256
train_label=0_recall_sent: 0.5432525951557093
train_label=0_f-score_sent: 0.6097087378640776
train_label=1_precision_sent: 0.9841308006732388
train_label=1_recall_sent: 0.9916414294367051
train_label=1_f-score_sent: 0.987871839739335
train_precision_macro_sent: 0.8394105330799821
train_recall_macro_sent: 0.7674470122962072
train_f-score_macro_sent: 0.7987902888017063
train_precision_micro_sent: 0.9764747191011236
train_recall_micro_sent: 0.9764747191011236
train_f-score_micro_sent: 0.9764747191011236
train_label=O_precision_tok: 0.9447607444374155
train_label=O_recall_tok: 0.9728421272728734
train_label=O_f-score_tok: 0.9585958239232933
train_label=N_precision_tok: 0.8502111324376199
train_label=N_recall_tok: 0.7797493310801296
train_label=N_f-score_tok: 0.8134572299555588
train_label=P_precision_tok: 0.8946573028713664
train_label=P_recall_tok: 0.8045728904345045
train_label=P_f-score_tok: 0.8472271914132379
train_precision_macro_tok: 0.8965430599154672
train_recall_macro_tok: 0.8523881162625025
train_f-score_macro_tok: 0.8730934150973634
train_precision_micro_tok: 0.9303400462198745
train_recall_micro_tok: 0.9303400462198745
train_f-score_micro_tok: 0.9303400462198745
train_time: 93.4485535621643
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6947    0.5433    0.6097       289
           1     0.9841    0.9916    0.9879      8255

   micro avg     0.9765    0.9765    0.9765      8544
   macro avg     0.8394    0.7674    0.7988      8544
weighted avg     0.9743    0.9765    0.9751      8544

F1-macro sent:  0.7987902888017063
F1-micro sent:  0.9764747191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9448    0.9728    0.9586    124347
           N     0.8502    0.7797    0.8135     14202
           P     0.8947    0.8046    0.8472     25017

   micro avg     0.9303    0.9303    0.9303    163566
   macro avg     0.8965    0.8524    0.8731    163566
weighted avg     0.9289    0.9303    0.9290    163566

F1-macro tok:  0.8730934150973634
F1-micro tok:  0.9303400462198745
**************************************************
dev_cost_sum: 41020.126037597656
dev_cost_avg: 37.25715353096972
dev_count_sent: 1101.0
dev_total_correct_sent: 1075.0
dev_accuracy_sent: 0.9763851044504995
dev_count_tok: 21274.0
dev_total_correct_tok: 19108.0
dev_accuracy_tok: 0.8981855786405941
dev_label=0_precision_sent: 0.8235294117647058
dev_label=0_recall_sent: 0.3783783783783784
dev_label=0_f-score_sent: 0.5185185185185186
dev_label=1_precision_sent: 0.9787822878228782
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9878957169459962
dev_precision_macro_sent: 0.901155849793792
dev_recall_macro_sent: 0.6877794147530989
dev_f-score_macro_sent: 0.7532071177322575
dev_precision_micro_sent: 0.9763851044504995
dev_recall_micro_sent: 0.9763851044504995
dev_f-score_micro_sent: 0.9763851044504995
dev_label=O_precision_tok: 0.9192032626041728
dev_label=O_recall_tok: 0.9597037951249614
dev_label=O_f-score_tok: 0.9390170269291148
dev_label=N_precision_tok: 0.7571606475716065
dev_label=N_recall_tok: 0.6548196015078083
dev_label=N_f-score_tok: 0.7022812590239678
dev_label=P_precision_tok: 0.8512186249545289
dev_label=P_recall_tok: 0.7285180572851806
dev_label=P_f-score_tok: 0.7851031706089582
dev_precision_macro_tok: 0.8425275117101028
dev_recall_macro_tok: 0.7810138179726501
dev_f-score_macro_tok: 0.8088004855206803
dev_precision_micro_tok: 0.8981855786405941
dev_recall_micro_tok: 0.8981855786405941
dev_f-score_micro_tok: 0.8981855786405941
dev_time: 4.944098234176636
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8235    0.3784    0.5185        37
           1     0.9788    0.9972    0.9879      1064

   micro avg     0.9764    0.9764    0.9764      1101
   macro avg     0.9012    0.6878    0.7532      1101
weighted avg     0.9736    0.9764    0.9721      1101

F1-macro sent:  0.7532071177322575
F1-micro sent:  0.9763851044504995
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9192    0.9597    0.9390     16205
           N     0.7572    0.6548    0.7023      1857
           P     0.8512    0.7285    0.7851      3212

   micro avg     0.8982    0.8982    0.8982     21274
   macro avg     0.8425    0.7810    0.8088     21274
weighted avg     0.8948    0.8982    0.8951     21274

F1-macro tok:  0.8088004855206803
F1-micro tok:  0.8981855786405941
**************************************************
Best epoch: 38
**************************************************

EPOCH: 41
Learning rate: 1.000000
train_cost_sum: 276613.02154541016
train_cost_avg: 32.37511956289913
train_count_sent: 8544.0
train_total_correct_sent: 8339.0
train_accuracy_sent: 0.9760065543071161
train_count_tok: 163566.0
train_total_correct_tok: 152179.0
train_accuracy_tok: 0.9303828424000098
train_label=0_precision_sent: 0.6779661016949152
train_label=0_recall_sent: 0.5536332179930796
train_label=0_f-score_sent: 0.6095238095238096
train_label=1_precision_sent: 0.9844727973038035
train_label=1_recall_sent: 0.9907934585099939
train_label=1_f-score_sent: 0.9876230151542594
train_precision_macro_sent: 0.8312194494993594
train_recall_macro_sent: 0.7722133382515368
train_f-score_macro_sent: 0.7985734123390344
train_precision_micro_sent: 0.9760065543071161
train_recall_micro_sent: 0.9760065543071161
train_f-score_micro_sent: 0.9760065543071161
train_label=O_precision_tok: 0.9449945682331518
train_label=O_recall_tok: 0.9723837326192027
train_label=O_f-score_tok: 0.9584935274952636
train_label=N_precision_tok: 0.8520210093628683
train_label=N_recall_tok: 0.7881284326151247
train_label=N_f-score_tok: 0.818830242510699
train_label=P_precision_tok: 0.89300649523979
train_label=P_recall_tok: 0.8023743854179158
train_label=P_f-score_tok: 0.8452679229392567
train_precision_macro_tok: 0.8966740242786034
train_recall_macro_tok: 0.854295516884081
train_f-score_macro_tok: 0.8741972309817397
train_precision_micro_tok: 0.9303828424000098
train_recall_micro_tok: 0.9303828424000098
train_f-score_micro_tok: 0.9303828424000098
train_time: 93.14021825790405
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6780    0.5536    0.6095       289
           1     0.9845    0.9908    0.9876      8255

   micro avg     0.9760    0.9760    0.9760      8544
   macro avg     0.8312    0.7722    0.7986      8544
weighted avg     0.9741    0.9760    0.9748      8544

F1-macro sent:  0.7985734123390344
F1-micro sent:  0.9760065543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9450    0.9724    0.9585    124347
           N     0.8520    0.7881    0.8188     14202
           P     0.8930    0.8024    0.8453     25017

   micro avg     0.9304    0.9304    0.9304    163566
   macro avg     0.8967    0.8543    0.8742    163566
weighted avg     0.9290    0.9304    0.9290    163566

F1-macro tok:  0.8741972309817397
F1-micro tok:  0.9303828424000098
**************************************************
dev_cost_sum: 41118.50646972656
dev_cost_avg: 37.34650905515583
dev_count_sent: 1101.0
dev_total_correct_sent: 1075.0
dev_accuracy_sent: 0.9763851044504995
dev_count_tok: 21274.0
dev_total_correct_tok: 19087.0
dev_accuracy_tok: 0.8971984582119018
dev_label=0_precision_sent: 0.7619047619047619
dev_label=0_recall_sent: 0.43243243243243246
dev_label=0_f-score_sent: 0.5517241379310345
dev_label=1_precision_sent: 0.9805555555555555
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9878731343283581
dev_precision_macro_sent: 0.8712301587301587
dev_recall_macro_sent: 0.7138665921560658
dev_f-score_macro_sent: 0.7697986361296962
dev_precision_micro_sent: 0.9763851044504995
dev_recall_micro_sent: 0.9763851044504995
dev_f-score_micro_sent: 0.9763851044504995
dev_label=O_precision_tok: 0.9208308605341247
dev_label=O_recall_tok: 0.9574822585621722
dev_label=O_f-score_tok: 0.9387989714112843
dev_label=N_precision_tok: 0.733015494636472
dev_label=N_recall_tok: 0.6623586429725363
dev_label=N_f-score_tok: 0.6958981612446958
dev_label=P_precision_tok: 0.8525127458120904
dev_label=P_recall_tok: 0.7288293897882939
dev_label=P_f-score_tok: 0.7858341725411212
dev_precision_macro_tok: 0.8354530336608956
dev_recall_macro_tok: 0.7828900971076674
dev_f-score_macro_tok: 0.8068437683990338
dev_precision_micro_tok: 0.8971984582119018
dev_recall_micro_tok: 0.8971984582119018
dev_f-score_micro_tok: 0.8971984582119018
dev_time: 4.99683141708374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7619    0.4324    0.5517        37
           1     0.9806    0.9953    0.9879      1064

   micro avg     0.9764    0.9764    0.9764      1101
   macro avg     0.8712    0.7139    0.7698      1101
weighted avg     0.9732    0.9764    0.9732      1101

F1-macro sent:  0.7697986361296962
F1-micro sent:  0.9763851044504995
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9208    0.9575    0.9388     16205
           N     0.7330    0.6624    0.6959      1857
           P     0.8525    0.7288    0.7858      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8355    0.7829    0.8068     21274
weighted avg     0.8941    0.8972    0.8945     21274

F1-macro tok:  0.8068437683990338
F1-micro tok:  0.8971984582119018
**************************************************
Best epoch: 38
**************************************************

EPOCH: 42
Learning rate: 1.000000
train_cost_sum: 275275.8001098633
train_cost_avg: 32.21860956342033
train_count_sent: 8544.0
train_total_correct_sent: 8364.0
train_accuracy_sent: 0.9789325842696629
train_count_tok: 163566.0
train_total_correct_tok: 152611.0
train_accuracy_tok: 0.9330239780883558
train_label=0_precision_sent: 0.7261410788381742
train_label=0_recall_sent: 0.6055363321799307
train_label=0_f-score_sent: 0.6603773584905661
train_label=1_precision_sent: 0.9862700228832952
train_label=1_recall_sent: 0.9920048455481526
train_label=1_f-score_sent: 0.9891291218746224
train_precision_macro_sent: 0.8562055508607347
train_recall_macro_sent: 0.7987705888640417
train_f-score_macro_sent: 0.8247532401825943
train_precision_micro_sent: 0.9789325842696629
train_recall_micro_sent: 0.9789325842696629
train_f-score_micro_sent: 0.9789325842696629
train_label=O_precision_tok: 0.9471600378713781
train_label=O_recall_tok: 0.9734694041673704
train_label=O_f-score_tok: 0.9601345241683455
train_label=N_precision_tok: 0.8574151734654976
train_label=N_recall_tok: 0.7917898887480637
train_label=N_f-score_tok: 0.8232968481165575
train_label=P_precision_tok: 0.8970419426048565
train_label=P_recall_tok: 0.8121677259463564
train_label=P_f-score_tok: 0.8524975349822728
train_precision_macro_tok: 0.9005390513139108
train_recall_macro_tok: 0.8591423396205968
train_f-score_macro_tok: 0.8786429690890586
train_precision_micro_tok: 0.9330239780883558
train_recall_micro_tok: 0.9330239780883558
train_f-score_micro_tok: 0.9330239780883558
train_time: 93.84819054603577
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7261    0.6055    0.6604       289
           1     0.9863    0.9920    0.9891      8255

   micro avg     0.9789    0.9789    0.9789      8544
   macro avg     0.8562    0.7988    0.8248      8544
weighted avg     0.9775    0.9789    0.9780      8544

F1-macro sent:  0.8247532401825943
F1-micro sent:  0.9789325842696629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9472    0.9735    0.9601    124347
           N     0.8574    0.7918    0.8233     14202
           P     0.8970    0.8122    0.8525     25017

   micro avg     0.9330    0.9330    0.9330    163566
   macro avg     0.9005    0.8591    0.8786    163566
weighted avg     0.9317    0.9330    0.9318    163566

F1-macro tok:  0.8786429690890586
F1-micro tok:  0.9330239780883558
**************************************************
dev_cost_sum: 41610.279235839844
dev_cost_avg: 37.793169151534826
dev_count_sent: 1101.0
dev_total_correct_sent: 1071.0
dev_accuracy_sent: 0.9727520435967303
dev_count_tok: 21274.0
dev_total_correct_tok: 19110.0
dev_accuracy_tok: 0.8982795901099934
dev_label=0_precision_sent: 0.7692307692307693
dev_label=0_recall_sent: 0.2702702702702703
dev_label=0_f-score_sent: 0.4
dev_label=1_precision_sent: 0.9751838235294118
dev_label=1_recall_sent: 0.9971804511278195
dev_label=1_f-score_sent: 0.9860594795539033
dev_precision_macro_sent: 0.8722072963800905
dev_recall_macro_sent: 0.633725360699045
dev_f-score_macro_sent: 0.6930297397769516
dev_precision_micro_sent: 0.9727520435967303
dev_recall_micro_sent: 0.9727520435967303
dev_f-score_micro_sent: 0.9727520435967303
dev_label=O_precision_tok: 0.9198674320885364
dev_label=O_recall_tok: 0.9591484109842641
dev_label=O_f-score_tok: 0.9390973355084286
dev_label=N_precision_tok: 0.7915549597855228
dev_label=N_recall_tok: 0.6359719978459881
dev_label=N_f-score_tok: 0.7052851597491789
dev_label=P_precision_tok: 0.8270363951473136
dev_label=P_recall_tok: 0.7428393524283935
dev_label=P_f-score_tok: 0.7826800065606034
dev_precision_macro_tok: 0.8461529290071242
dev_recall_macro_tok: 0.7793199204195486
dev_f-score_macro_tok: 0.8090208339394037
dev_precision_micro_tok: 0.8982795901099934
dev_recall_micro_tok: 0.8982795901099934
dev_f-score_micro_tok: 0.8982795901099935
dev_time: 4.80800199508667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7692    0.2703    0.4000        37
           1     0.9752    0.9972    0.9861      1064

   micro avg     0.9728    0.9728    0.9728      1101
   macro avg     0.8722    0.6337    0.6930      1101
weighted avg     0.9683    0.9728    0.9664      1101

F1-macro sent:  0.6930297397769516
F1-micro sent:  0.9727520435967303
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9199    0.9591    0.9391     16205
           N     0.7916    0.6360    0.7053      1857
           P     0.8270    0.7428    0.7827      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8462    0.7793    0.8090     21274
weighted avg     0.8947    0.8983    0.8951     21274

F1-macro tok:  0.8090208339394037
F1-micro tok:  0.8982795901099935
**************************************************
Best epoch: 38
**************************************************

EPOCH: 43
Learning rate: 0.900000
train_cost_sum: 273725.2218017578
train_cost_avg: 32.03712801986866
train_count_sent: 8544.0
train_total_correct_sent: 8360.0
train_accuracy_sent: 0.9784644194756554
train_count_tok: 163566.0
train_total_correct_tok: 152867.0
train_accuracy_tok: 0.9345890955333015
train_label=0_precision_sent: 0.7272727272727273
train_label=0_recall_sent: 0.5813148788927336
train_label=0_f-score_sent: 0.6461538461538462
train_label=1_precision_sent: 0.9854444845422832
train_label=1_recall_sent: 0.9923682616596002
train_label=1_f-score_sent: 0.9888942539835828
train_precision_macro_sent: 0.8563586059075052
train_recall_macro_sent: 0.7868415702761669
train_f-score_macro_sent: 0.8175240500687144
train_precision_micro_sent: 0.9784644194756554
train_recall_micro_sent: 0.9784644194756554
train_f-score_micro_sent: 0.9784644194756554
train_label=O_precision_tok: 0.9492119501293813
train_label=O_recall_tok: 0.9735096142247098
train_label=O_f-score_tok: 0.9612072559225335
train_label=N_precision_tok: 0.8564954682779456
train_label=N_recall_tok: 0.7984790874524715
train_label=N_f-score_tok: 0.8264703738794549
train_label=P_precision_tok: 0.8981400245657133
train_label=P_recall_tok: 0.8184034856297717
train_label=P_f-score_tok: 0.8564198021458598
train_precision_macro_tok: 0.9012824809910134
train_recall_macro_tok: 0.863464062435651
train_f-score_macro_tok: 0.8813658106492827
train_precision_micro_tok: 0.9345890955333015
train_recall_micro_tok: 0.9345890955333015
train_f-score_micro_tok: 0.9345890955333015
train_time: 94.30470204353333
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7273    0.5813    0.6462       289
           1     0.9854    0.9924    0.9889      8255

   micro avg     0.9785    0.9785    0.9785      8544
   macro avg     0.8564    0.7868    0.8175      8544
weighted avg     0.9767    0.9785    0.9773      8544

F1-macro sent:  0.8175240500687144
F1-micro sent:  0.9784644194756554
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9492    0.9735    0.9612    124347
           N     0.8565    0.7985    0.8265     14202
           P     0.8981    0.8184    0.8564     25017

   micro avg     0.9346    0.9346    0.9346    163566
   macro avg     0.9013    0.8635    0.8814    163566
weighted avg     0.9334    0.9346    0.9335    163566

F1-macro tok:  0.8813658106492827
F1-micro tok:  0.9345890955333015
**************************************************
dev_cost_sum: 41425.987854003906
dev_cost_avg: 37.625783700276024
dev_count_sent: 1101.0
dev_total_correct_sent: 1073.0
dev_accuracy_sent: 0.9745685740236149
dev_count_tok: 21274.0
dev_total_correct_tok: 19133.0
dev_accuracy_tok: 0.899360722008085
dev_label=0_precision_sent: 0.6551724137931034
dev_label=0_recall_sent: 0.5135135135135135
dev_label=0_f-score_sent: 0.5757575757575758
dev_label=1_precision_sent: 0.9832089552238806
dev_label=1_recall_sent: 0.9906015037593985
dev_label=1_f-score_sent: 0.9868913857677902
dev_precision_macro_sent: 0.819190684508492
dev_recall_macro_sent: 0.752057508636456
dev_f-score_macro_sent: 0.781324480762683
dev_precision_micro_sent: 0.9745685740236149
dev_recall_micro_sent: 0.9745685740236149
dev_f-score_micro_sent: 0.9745685740236149
dev_label=O_precision_tok: 0.9156076134699853
dev_label=O_recall_tok: 0.9647639617402036
dev_label=O_f-score_tok: 0.9395432692307693
dev_label=N_precision_tok: 0.8151320485367595
dev_label=N_recall_tok: 0.6149703823371029
dev_label=N_f-score_tok: 0.7010435850214856
dev_label=P_precision_tok: 0.8423874195854182
dev_label=P_recall_tok: 0.7338107098381071
dev_label=P_f-score_tok: 0.7843594009983361
dev_precision_macro_tok: 0.8577090271973876
dev_recall_macro_tok: 0.7711816846384711
dev_f-score_macro_tok: 0.8083154184168636
dev_precision_micro_tok: 0.899360722008085
dev_recall_micro_tok: 0.899360722008085
dev_f-score_micro_tok: 0.899360722008085
dev_time: 4.994111061096191
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6552    0.5135    0.5758        37
           1     0.9832    0.9906    0.9869      1064

   micro avg     0.9746    0.9746    0.9746      1101
   macro avg     0.8192    0.7521    0.7813      1101
weighted avg     0.9722    0.9746    0.9731      1101

F1-macro sent:  0.781324480762683
F1-micro sent:  0.9745685740236149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9156    0.9648    0.9395     16205
           N     0.8151    0.6150    0.7010      1857
           P     0.8424    0.7338    0.7844      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8577    0.7712    0.8083     21274
weighted avg     0.8958    0.8994    0.8953     21274

F1-macro tok:  0.8083154184168636
F1-micro tok:  0.899360722008085
**************************************************
Best epoch: 38
**************************************************

EPOCH: 44
Learning rate: 0.810000
train_cost_sum: 272670.07720947266
train_cost_avg: 31.913632632194833
train_count_sent: 8544.0
train_total_correct_sent: 8377.0
train_accuracy_sent: 0.9804541198501873
train_count_tok: 163566.0
train_total_correct_tok: 153328.0
train_accuracy_tok: 0.9374075296822078
train_label=0_precision_sent: 0.744
train_label=0_recall_sent: 0.643598615916955
train_label=0_f-score_sent: 0.6901669758812616
train_label=1_precision_sent: 0.9875813841331083
train_label=1_recall_sent: 0.9922471229557843
train_label=1_f-score_sent: 0.9899087558160613
train_precision_macro_sent: 0.8657906920665541
train_recall_macro_sent: 0.8179228694363696
train_f-score_macro_sent: 0.8400378658486615
train_precision_micro_sent: 0.9804541198501873
train_recall_micro_sent: 0.9804541198501873
train_f-score_micro_sent: 0.9804541198501873
train_label=O_precision_tok: 0.9513893249607536
train_label=O_recall_tok: 0.9747480839907677
train_label=O_f-score_tok: 0.9629270656651321
train_label=N_precision_tok: 0.8634065353558222
train_label=N_recall_tok: 0.8055907618645262
train_label=N_f-score_tok: 0.83349724984519
train_label=P_precision_tok: 0.902465633864281
train_label=P_recall_tok: 0.8266378862373586
train_label=P_f-score_tok: 0.8628890928815822
train_precision_macro_tok: 0.905753831393619
train_recall_macro_tok: 0.868992244030884
train_f-score_macro_tok: 0.8864378027973014
train_precision_micro_tok: 0.9374075296822078
train_recall_micro_tok: 0.9374075296822078
train_f-score_micro_tok: 0.9374075296822078
train_time: 92.09871935844421
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7440    0.6436    0.6902       289
           1     0.9876    0.9922    0.9899      8255

   micro avg     0.9805    0.9805    0.9805      8544
   macro avg     0.8658    0.8179    0.8400      8544
weighted avg     0.9793    0.9805    0.9798      8544

F1-macro sent:  0.8400378658486615
F1-micro sent:  0.9804541198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9514    0.9747    0.9629    124347
           N     0.8634    0.8056    0.8335     14202
           P     0.9025    0.8266    0.8629     25017

   micro avg     0.9374    0.9374    0.9374    163566
   macro avg     0.9058    0.8690    0.8864    163566
weighted avg     0.9363    0.9374    0.9364    163566

F1-macro tok:  0.8864378027973014
F1-micro tok:  0.9374075296822078
**************************************************
dev_cost_sum: 41555.267150878906
dev_cost_avg: 37.74320358844587
dev_count_sent: 1101.0
dev_total_correct_sent: 1070.0
dev_accuracy_sent: 0.971843778383288
dev_count_tok: 21274.0
dev_total_correct_tok: 19208.0
dev_accuracy_tok: 0.9028861521105574
dev_label=0_precision_sent: 0.5833333333333334
dev_label=0_recall_sent: 0.5675675675675675
dev_label=0_f-score_sent: 0.5753424657534246
dev_label=1_precision_sent: 0.9849765258215962
dev_label=1_recall_sent: 0.9859022556390977
dev_label=1_f-score_sent: 0.9854391733208079
dev_precision_macro_sent: 0.7841549295774648
dev_recall_macro_sent: 0.7767349116033326
dev_f-score_macro_sent: 0.7803908195371163
dev_precision_micro_sent: 0.971843778383288
dev_recall_micro_sent: 0.971843778383288
dev_f-score_micro_sent: 0.971843778383288
dev_label=O_precision_tok: 0.9173974044195019
dev_label=O_recall_tok: 0.9684048133292193
dev_label=O_f-score_tok: 0.9422112815586443
dev_label=N_precision_tok: 0.7891963109354414
dev_label=N_recall_tok: 0.6451265481960151
dev_label=N_f-score_tok: 0.709925925925926
dev_label=P_precision_tok: 0.8743396226415094
dev_label=P_recall_tok: 0.7213574097135741
dev_label=P_f-score_tok: 0.7905151825315592
dev_precision_macro_tok: 0.8603111126654843
dev_recall_macro_tok: 0.7782962570796029
dev_f-score_macro_tok: 0.8142174633387098
dev_precision_micro_tok: 0.9028861521105574
dev_recall_micro_tok: 0.9028861521105574
dev_f-score_micro_tok: 0.9028861521105574
dev_time: 5.027066707611084
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5833    0.5676    0.5753        37
           1     0.9850    0.9859    0.9854      1064

   micro avg     0.9718    0.9718    0.9718      1101
   macro avg     0.7842    0.7767    0.7804      1101
weighted avg     0.9715    0.9718    0.9717      1101

F1-macro sent:  0.7803908195371163
F1-micro sent:  0.971843778383288
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9174    0.9684    0.9422     16205
           N     0.7892    0.6451    0.7099      1857
           P     0.8743    0.7214    0.7905      3212

   micro avg     0.9029    0.9029    0.9029     21274
   macro avg     0.8603    0.7783    0.8142     21274
weighted avg     0.8997    0.9029    0.8990     21274

F1-macro tok:  0.8142174633387098
F1-micro tok:  0.9028861521105574
**************************************************
Best epoch: 44
**************************************************

EPOCH: 45
Learning rate: 0.810000
train_cost_sum: 271468.89685058594
train_cost_avg: 31.773045043373823
train_count_sent: 8544.0
train_total_correct_sent: 8371.0
train_accuracy_sent: 0.9797518726591761
train_count_tok: 163566.0
train_total_correct_tok: 153627.0
train_accuracy_tok: 0.9392355379479843
train_label=0_precision_sent: 0.7213740458015268
train_label=0_recall_sent: 0.6539792387543253
train_label=0_f-score_sent: 0.6860254083484574
train_label=1_precision_sent: 0.9879256218304757
train_label=1_recall_sent: 0.9911568746214415
train_label=1_f-score_sent: 0.989538610388825
train_precision_macro_sent: 0.8546498338160012
train_recall_macro_sent: 0.8225680566878835
train_f-score_macro_sent: 0.8377820093686412
train_precision_micro_sent: 0.9797518726591761
train_recall_micro_sent: 0.9797518726591761
train_f-score_micro_sent: 0.9797518726591761
train_label=O_precision_tok: 0.953063967242233
train_label=O_recall_tok: 0.9752145206559064
train_label=O_f-score_tok: 0.9640120198422792
train_label=N_precision_tok: 0.8647266711782841
train_label=N_recall_tok: 0.8097451063230531
train_label=N_f-score_tok: 0.836333224246391
train_label=P_precision_tok: 0.9058619192357794
train_label=P_recall_tok: 0.8339129392013431
train_label=P_f-score_tok: 0.8683996919682812
train_precision_macro_tok: 0.9078841858854321
train_recall_macro_tok: 0.8729575220601009
train_f-score_macro_tok: 0.8895816453523171
train_precision_micro_tok: 0.9392355379479843
train_recall_micro_tok: 0.9392355379479843
train_f-score_micro_tok: 0.9392355379479843
train_time: 93.40490436553955
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7214    0.6540    0.6860       289
           1     0.9879    0.9912    0.9895      8255

   micro avg     0.9798    0.9798    0.9798      8544
   macro avg     0.8546    0.8226    0.8378      8544
weighted avg     0.9789    0.9798    0.9793      8544

F1-macro sent:  0.8377820093686412
F1-micro sent:  0.9797518726591761
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9531    0.9752    0.9640    124347
           N     0.8647    0.8097    0.8363     14202
           P     0.9059    0.8339    0.8684     25017

   micro avg     0.9392    0.9392    0.9392    163566
   macro avg     0.9079    0.8730    0.8896    163566
weighted avg     0.9382    0.9392    0.9383    163566

F1-macro tok:  0.8895816453523171
F1-micro tok:  0.9392355379479843
**************************************************
dev_cost_sum: 41602.17492675781
dev_cost_avg: 37.78580828951663
dev_count_sent: 1101.0
dev_total_correct_sent: 1066.0
dev_accuracy_sent: 0.9682107175295186
dev_count_tok: 21274.0
dev_total_correct_tok: 19031.0
dev_accuracy_tok: 0.8945661370687223
dev_label=0_precision_sent: 0.75
dev_label=0_recall_sent: 0.08108108108108109
dev_label=0_f-score_sent: 0.14634146341463414
dev_label=1_precision_sent: 0.9690063810391978
dev_label=1_recall_sent: 0.9990601503759399
dev_label=1_f-score_sent: 0.983803794539565
dev_precision_macro_sent: 0.8595031905195989
dev_recall_macro_sent: 0.5400706157285105
dev_f-score_macro_sent: 0.5650726289770995
dev_precision_micro_sent: 0.9682107175295186
dev_recall_micro_sent: 0.9682107175295186
dev_f-score_micro_sent: 0.9682107175295186
dev_label=O_precision_tok: 0.923173577454676
dev_label=O_recall_tok: 0.9521135452020981
dev_label=O_f-score_tok: 0.9374202563946776
dev_label=N_precision_tok: 0.7240164415736935
dev_label=N_recall_tok: 0.6639741518578353
dev_label=N_f-score_tok: 0.6926966292134833
dev_label=P_precision_tok: 0.8289013296011196
dev_label=P_recall_tok: 0.737546699875467
dev_label=P_f-score_tok: 0.7805601317957166
dev_precision_macro_tok: 0.8253637828764964
dev_recall_macro_tok: 0.7845447989784669
dev_f-score_macro_tok: 0.8035590058012926
dev_precision_micro_tok: 0.8945661370687223
dev_recall_micro_tok: 0.8945661370687223
dev_f-score_micro_tok: 0.8945661370687222
dev_time: 4.945713043212891
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7500    0.0811    0.1463        37
           1     0.9690    0.9991    0.9838      1064

   micro avg     0.9682    0.9682    0.9682      1101
   macro avg     0.8595    0.5401    0.5651      1101
weighted avg     0.9616    0.9682    0.9557      1101

F1-macro sent:  0.5650726289770995
F1-micro sent:  0.9682107175295186
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9232    0.9521    0.9374     16205
           N     0.7240    0.6640    0.6927      1857
           P     0.8289    0.7375    0.7806      3212

   micro avg     0.8946    0.8946    0.8946     21274
   macro avg     0.8254    0.7845    0.8036     21274
weighted avg     0.8916    0.8946    0.8924     21274

F1-macro tok:  0.8035590058012926
F1-micro tok:  0.8945661370687222
**************************************************
Best epoch: 44
**************************************************

EPOCH: 46
Learning rate: 0.810000
train_cost_sum: 270494.1766357422
train_cost_avg: 31.658962621224507
train_count_sent: 8544.0
train_total_correct_sent: 8383.0
train_accuracy_sent: 0.9811563670411985
train_count_tok: 163566.0
train_total_correct_tok: 153851.0
train_accuracy_tok: 0.9406050157123118
train_label=0_precision_sent: 0.7388059701492538
train_label=0_recall_sent: 0.6851211072664359
train_label=0_f-score_sent: 0.7109515260323159
train_label=1_precision_sent: 0.9890043499275012
train_label=1_recall_sent: 0.9915202907328892
train_label=1_f-score_sent: 0.9902607222793539
train_precision_macro_sent: 0.8639051600383775
train_recall_macro_sent: 0.8383206989996626
train_f-score_macro_sent: 0.8506061241558349
train_precision_micro_sent: 0.9811563670411985
train_recall_micro_sent: 0.9811563670411985
train_f-score_micro_sent: 0.9811563670411985
train_label=O_precision_tok: 0.9544034437440486
train_label=O_recall_tok: 0.9753110247935214
train_label=O_f-score_tok: 0.9647439721897398
train_label=N_precision_tok: 0.8667262969588551
train_label=N_recall_tok: 0.8187579214195184
train_label=N_f-score_tok: 0.8420595263958288
train_label=P_precision_tok: 0.9075783179513843
train_label=P_recall_tok: 0.8372706559539513
train_label=P_f-score_tok: 0.8710079840319361
train_precision_macro_tok: 0.9095693528847626
train_recall_macro_tok: 0.8771132007223303
train_f-score_macro_tok: 0.8926038275391682
train_precision_micro_tok: 0.9406050157123118
train_recall_micro_tok: 0.9406050157123118
train_f-score_micro_tok: 0.9406050157123118
train_time: 93.85673356056213
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7388    0.6851    0.7110       289
           1     0.9890    0.9915    0.9903      8255

   micro avg     0.9812    0.9812    0.9812      8544
   macro avg     0.8639    0.8383    0.8506      8544
weighted avg     0.9805    0.9812    0.9808      8544

F1-macro sent:  0.8506061241558349
F1-micro sent:  0.9811563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9544    0.9753    0.9647    124347
           N     0.8667    0.8188    0.8421     14202
           P     0.9076    0.8373    0.8710     25017

   micro avg     0.9406    0.9406    0.9406    163566
   macro avg     0.9096    0.8771    0.8926    163566
weighted avg     0.9396    0.9406    0.9398    163566

F1-macro tok:  0.8926038275391682
F1-micro tok:  0.9406050157123118
**************************************************
dev_cost_sum: 41436.39385986328
dev_cost_avg: 37.635235113408974
dev_count_sent: 1101.0
dev_total_correct_sent: 1067.0
dev_accuracy_sent: 0.9691189827429609
dev_count_tok: 21274.0
dev_total_correct_tok: 19180.0
dev_accuracy_tok: 0.9015699915389678
dev_label=0_precision_sent: 0.6363636363636364
dev_label=0_recall_sent: 0.1891891891891892
dev_label=0_f-score_sent: 0.2916666666666667
dev_label=1_precision_sent: 0.9724770642201835
dev_label=1_recall_sent: 0.9962406015037594
dev_label=1_f-score_sent: 0.9842154131847726
dev_precision_macro_sent: 0.80442035029191
dev_recall_macro_sent: 0.5927148953464743
dev_f-score_macro_sent: 0.6379410399257196
dev_precision_micro_sent: 0.9691189827429609
dev_recall_micro_sent: 0.9691189827429609
dev_f-score_micro_sent: 0.9691189827429609
dev_label=O_precision_tok: 0.9175161101347393
dev_label=O_recall_tok: 0.966491823511262
dev_label=O_f-score_tok: 0.9413673929376407
dev_label=N_precision_tok: 0.7871777924653007
dev_label=N_recall_tok: 0.6413570274636511
dev_label=N_f-score_tok: 0.7068249258160237
dev_label=P_precision_tok: 0.8647342995169082
dev_label=P_recall_tok: 0.7244707347447074
dev_label=P_f-score_tok: 0.7884126715229545
dev_precision_macro_tok: 0.8564760673723161
dev_recall_macro_tok: 0.7774398619065401
dev_f-score_macro_tok: 0.8122016634255397
dev_precision_micro_tok: 0.9015699915389678
dev_recall_micro_tok: 0.9015699915389678
dev_f-score_micro_tok: 0.9015699915389677
dev_time: 5.030965328216553
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6364    0.1892    0.2917        37
           1     0.9725    0.9962    0.9842      1064

   micro avg     0.9691    0.9691    0.9691      1101
   macro avg     0.8044    0.5927    0.6379      1101
weighted avg     0.9612    0.9691    0.9609      1101

F1-macro sent:  0.6379410399257196
F1-micro sent:  0.9691189827429609
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9175    0.9665    0.9414     16205
           N     0.7872    0.6414    0.7068      1857
           P     0.8647    0.7245    0.7884      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8565    0.7774    0.8122     21274
weighted avg     0.8982    0.9016    0.8978     21274

F1-macro tok:  0.8122016634255397
F1-micro tok:  0.9015699915389677
**************************************************
Best epoch: 44
**************************************************

EPOCH: 47
Learning rate: 0.810000
train_cost_sum: 269838.67559814453
train_cost_avg: 31.582241994164857
train_count_sent: 8544.0
train_total_correct_sent: 8383.0
train_accuracy_sent: 0.9811563670411985
train_count_tok: 163566.0
train_total_correct_tok: 154103.0
train_accuracy_tok: 0.9421456781971803
train_label=0_precision_sent: 0.748062015503876
train_label=0_recall_sent: 0.6678200692041523
train_label=0_f-score_sent: 0.7056672760511883
train_label=1_precision_sent: 0.9884141926140478
train_label=1_recall_sent: 0.9921259842519685
train_label=1_f-score_sent: 0.9902666102412188
train_precision_macro_sent: 0.868238104058962
train_recall_macro_sent: 0.8299730267280604
train_f-score_macro_sent: 0.8479669431462036
train_precision_micro_sent: 0.9811563670411985
train_recall_micro_sent: 0.9811563670411985
train_f-score_micro_sent: 0.9811563670411985
train_label=O_precision_tok: 0.9557498424700693
train_label=O_recall_tok: 0.9758337555389354
train_label=O_f-score_tok: 0.9656873863441925
train_label=N_precision_tok: 0.8703178630055216
train_label=N_recall_tok: 0.8212927756653993
train_label=N_f-score_tok: 0.8450949137806115
train_label=P_precision_tok: 0.9091966902258232
train_label=P_recall_tok: 0.8433065515449495
train_label=P_f-score_tok: 0.8750129611580016
train_precision_macro_tok: 0.911754798567138
train_recall_macro_tok: 0.880144360916428
train_f-score_macro_tok: 0.8952650870942686
train_precision_micro_tok: 0.9421456781971803
train_recall_micro_tok: 0.9421456781971803
train_f-score_micro_tok: 0.9421456781971803
train_time: 92.82502627372742
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7481    0.6678    0.7057       289
           1     0.9884    0.9921    0.9903      8255

   micro avg     0.9812    0.9812    0.9812      8544
   macro avg     0.8682    0.8300    0.8480      8544
weighted avg     0.9803    0.9812    0.9806      8544

F1-macro sent:  0.8479669431462036
F1-micro sent:  0.9811563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9557    0.9758    0.9657    124347
           N     0.8703    0.8213    0.8451     14202
           P     0.9092    0.8433    0.8750     25017

   micro avg     0.9421    0.9421    0.9421    163566
   macro avg     0.9118    0.8801    0.8953    163566
weighted avg     0.9412    0.9421    0.9413    163566

F1-macro tok:  0.8952650870942686
F1-micro tok:  0.9421456781971803
**************************************************
dev_cost_sum: 41660.572204589844
dev_cost_avg: 37.838848505531196
dev_count_sent: 1101.0
dev_total_correct_sent: 1073.0
dev_accuracy_sent: 0.9745685740236149
dev_count_tok: 21274.0
dev_total_correct_tok: 19238.0
dev_accuracy_tok: 0.9042963241515465
dev_label=0_precision_sent: 0.7368421052631579
dev_label=0_recall_sent: 0.3783783783783784
dev_label=0_f-score_sent: 0.5
dev_label=1_precision_sent: 0.9787430683918669
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9869524697110903
dev_precision_macro_sent: 0.8577925868275124
dev_recall_macro_sent: 0.6868395651290389
dev_f-score_macro_sent: 0.7434762348555451
dev_precision_micro_sent: 0.9745685740236149
dev_recall_micro_sent: 0.9745685740236149
dev_f-score_micro_sent: 0.9745685740236149
dev_label=O_precision_tok: 0.9157166123778502
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.9427792915531336
dev_label=N_precision_tok: 0.8081155433287482
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.7097553609181515
dev_label=P_precision_tok: 0.882800608828006
dev_label=P_recall_tok: 0.7222914072229141
dev_label=P_f-score_tok: 0.7945205479452054
dev_precision_macro_tok: 0.8688775881782016
dev_recall_macro_tok: 0.7755075560252808
dev_f-score_macro_tok: 0.8156850668054969
dev_precision_micro_tok: 0.9042963241515465
dev_recall_micro_tok: 0.9042963241515465
dev_f-score_micro_tok: 0.9042963241515465
dev_time: 4.904378890991211
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7368    0.3784    0.5000        37
           1     0.9787    0.9953    0.9870      1064

   micro avg     0.9746    0.9746    0.9746      1101
   macro avg     0.8578    0.6868    0.7435      1101
weighted avg     0.9706    0.9746    0.9706      1101

F1-macro sent:  0.7434762348555451
F1-micro sent:  0.9745685740236149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9715    0.9428     16205
           N     0.8081    0.6327    0.7098      1857
           P     0.8828    0.7223    0.7945      3212

   micro avg     0.9043    0.9043    0.9043     21274
   macro avg     0.8689    0.7755    0.8157     21274
weighted avg     0.9014    0.9043    0.9001     21274

F1-macro tok:  0.8156850668054969
F1-micro tok:  0.9042963241515465
**************************************************
Best epoch: 47
**************************************************

EPOCH: 48
Learning rate: 0.810000
train_cost_sum: 268921.76287841797
train_cost_avg: 31.474925430526447
train_count_sent: 8544.0
train_total_correct_sent: 8391.0
train_accuracy_sent: 0.9820926966292135
train_count_tok: 163566.0
train_total_correct_tok: 154167.0
train_accuracy_tok: 0.9425369575584168
train_label=0_precision_sent: 0.7698412698412699
train_label=0_recall_sent: 0.671280276816609
train_label=0_f-score_sent: 0.7171903881700554
train_label=1_precision_sent: 0.988543174143753
train_label=1_recall_sent: 0.9929739551786796
train_label=1_f-score_sent: 0.990753610926452
train_precision_macro_sent: 0.8791922219925115
train_recall_macro_sent: 0.8321271159976442
train_f-score_macro_sent: 0.8539719995482538
train_precision_micro_sent: 0.9820926966292135
train_recall_micro_sent: 0.9820926966292135
train_f-score_micro_sent: 0.9820926966292135
train_label=O_precision_tok: 0.9559988335710852
train_label=O_recall_tok: 0.9754959910572832
train_label=O_f-score_tok: 0.9656490068861202
train_label=N_precision_tok: 0.8745985510493689
train_label=N_recall_tok: 0.8245317560906914
train_label=N_f-score_tok: 0.8488275162190569
train_label=P_precision_tok: 0.9082596376749378
train_label=P_recall_tok: 0.8457049206539553
train_label=P_f-score_tok: 0.8758667798224007
train_precision_macro_tok: 0.9129523407651307
train_recall_macro_tok: 0.88191088926731
train_f-score_macro_tok: 0.8967811009758592
train_precision_micro_tok: 0.9425369575584168
train_recall_micro_tok: 0.9425369575584168
train_f-score_micro_tok: 0.9425369575584168
train_time: 92.64716935157776
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7698    0.6713    0.7172       289
           1     0.9885    0.9930    0.9908      8255

   micro avg     0.9821    0.9821    0.9821      8544
   macro avg     0.8792    0.8321    0.8540      8544
weighted avg     0.9811    0.9821    0.9815      8544

F1-macro sent:  0.8539719995482538
F1-micro sent:  0.9820926966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9560    0.9755    0.9656    124347
           N     0.8746    0.8245    0.8488     14202
           P     0.9083    0.8457    0.8759     25017

   micro avg     0.9425    0.9425    0.9425    163566
   macro avg     0.9130    0.8819    0.8968    163566
weighted avg     0.9416    0.9425    0.9418    163566

F1-macro tok:  0.8967811009758592
F1-micro tok:  0.9425369575584168
**************************************************
dev_cost_sum: 41941.63641357422
dev_cost_avg: 38.094129349295386
dev_count_sent: 1101.0
dev_total_correct_sent: 1072.0
dev_accuracy_sent: 0.9736603088101726
dev_count_tok: 21274.0
dev_total_correct_tok: 19212.0
dev_accuracy_tok: 0.903074175049356
dev_label=0_precision_sent: 0.6666666666666666
dev_label=0_recall_sent: 0.43243243243243246
dev_label=0_f-score_sent: 0.5245901639344263
dev_label=1_precision_sent: 0.9805013927576601
dev_label=1_recall_sent: 0.9924812030075187
dev_label=1_f-score_sent: 0.9864549276039233
dev_precision_macro_sent: 0.8235840297121634
dev_recall_macro_sent: 0.7124568177199756
dev_f-score_macro_sent: 0.7555225457691748
dev_precision_micro_sent: 0.9736603088101726
dev_recall_micro_sent: 0.9736603088101726
dev_f-score_micro_sent: 0.9736603088101726
dev_label=O_precision_tok: 0.9170609193388237
dev_label=O_recall_tok: 0.9688984881209504
dev_label=O_f-score_tok: 0.9422672988057373
dev_label=N_precision_tok: 0.8165969316596932
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.7116378000607717
dev_label=P_precision_tok: 0.8606105185730047
dev_label=P_recall_tok: 0.7285180572851806
dev_label=P_f-score_tok: 0.7890743550834598
dev_precision_macro_tok: 0.8647561231905073
dev_recall_macro_tok: 0.7760011712114855
dev_f-score_macro_tok: 0.8143264846499897
dev_precision_micro_tok: 0.903074175049356
dev_recall_micro_tok: 0.903074175049356
dev_f-score_micro_tok: 0.903074175049356
dev_time: 4.918978452682495
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6667    0.4324    0.5246        37
           1     0.9805    0.9925    0.9865      1064

   micro avg     0.9737    0.9737    0.9737      1101
   macro avg     0.8236    0.7125    0.7555      1101
weighted avg     0.9700    0.9737    0.9709      1101

F1-macro sent:  0.7555225457691748
F1-micro sent:  0.9736603088101726
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9171    0.9689    0.9423     16205
           N     0.8166    0.6306    0.7116      1857
           P     0.8606    0.7285    0.7891      3212

   micro avg     0.9031    0.9031    0.9031     21274
   macro avg     0.8648    0.7760    0.8143     21274
weighted avg     0.8998    0.9031    0.8990     21274

F1-macro tok:  0.8143264846499897
F1-micro tok:  0.903074175049356
**************************************************
Best epoch: 47
**************************************************

EPOCH: 49
Learning rate: 0.810000
train_cost_sum: 267828.29705810547
train_cost_avg: 31.34694488039624
train_count_sent: 8544.0
train_total_correct_sent: 8378.0
train_accuracy_sent: 0.9805711610486891
train_count_tok: 163566.0
train_total_correct_tok: 154599.0
train_accuracy_tok: 0.9451780932467628
train_label=0_precision_sent: 0.7286245353159851
train_label=0_recall_sent: 0.6782006920415224
train_label=0_f-score_sent: 0.7025089605734767
train_label=1_precision_sent: 0.9887613293051359
train_label=1_recall_sent: 0.9911568746214415
train_label=1_f-score_sent: 0.9899576527525711
train_precision_macro_sent: 0.8586929323105605
train_recall_macro_sent: 0.8346787833314819
train_f-score_macro_sent: 0.8462333066630239
train_precision_micro_sent: 0.9805711610486891
train_recall_micro_sent: 0.9805711610486891
train_f-score_micro_sent: 0.9805711610486891
train_label=O_precision_tok: 0.9585047171673311
train_label=O_recall_tok: 0.9763725703072853
train_label=O_f-score_tok: 0.9673561423358246
train_label=N_precision_tok: 0.8806314692084295
train_label=N_recall_tok: 0.8326996197718631
train_label=N_f-score_tok: 0.8559950779921103
train_label=P_precision_tok: 0.9101908657123381
train_label=P_recall_tok: 0.8539792940800256
train_label=P_f-score_tok: 0.8811895481449401
train_precision_macro_tok: 0.9164423506960327
train_recall_macro_tok: 0.887683828053058
train_f-score_macro_tok: 0.9015135894909583
train_precision_micro_tok: 0.9451780932467628
train_recall_micro_tok: 0.9451780932467628
train_f-score_micro_tok: 0.9451780932467628
train_time: 93.40059757232666
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7286    0.6782    0.7025       289
           1     0.9888    0.9912    0.9900      8255

   micro avg     0.9806    0.9806    0.9806      8544
   macro avg     0.8587    0.8347    0.8462      8544
weighted avg     0.9800    0.9806    0.9802      8544

F1-macro sent:  0.8462333066630239
F1-micro sent:  0.9805711610486891
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9585    0.9764    0.9674    124347
           N     0.8806    0.8327    0.8560     14202
           P     0.9102    0.8540    0.8812     25017

   micro avg     0.9452    0.9452    0.9452    163566
   macro avg     0.9164    0.8877    0.9015    163566
weighted avg     0.9444    0.9452    0.9445    163566

F1-macro tok:  0.9015135894909583
F1-micro tok:  0.9451780932467628
**************************************************
dev_cost_sum: 41598.35021972656
dev_cost_avg: 37.78233444116854
dev_count_sent: 1101.0
dev_total_correct_sent: 1071.0
dev_accuracy_sent: 0.9727520435967303
dev_count_tok: 21274.0
dev_total_correct_tok: 19129.0
dev_accuracy_tok: 0.8991726990692864
dev_label=0_precision_sent: 0.6060606060606061
dev_label=0_recall_sent: 0.5405405405405406
dev_label=0_f-score_sent: 0.5714285714285714
dev_label=1_precision_sent: 0.9840823970037453
dev_label=1_recall_sent: 0.9877819548872181
dev_label=1_f-score_sent: 0.9859287054409006
dev_precision_macro_sent: 0.7950715015321757
dev_recall_macro_sent: 0.7641612477138793
dev_f-score_macro_sent: 0.778678638434736
dev_precision_micro_sent: 0.9727520435967303
dev_recall_micro_sent: 0.9727520435967303
dev_f-score_micro_sent: 0.9727520435967303
dev_label=O_precision_tok: 0.9198347107438016
dev_label=O_recall_tok: 0.9615550755939525
dev_label=O_f-score_tok: 0.9402323125659979
dev_label=N_precision_tok: 0.7935656836461126
dev_label=N_recall_tok: 0.6375875067312871
dev_label=N_f-score_tok: 0.7070767393251717
dev_label=P_precision_tok: 0.8314567206192822
dev_label=P_recall_tok: 0.7356787048567871
dev_label=P_f-score_tok: 0.7806408985794516
dev_precision_macro_tok: 0.8482857050030654
dev_recall_macro_tok: 0.7782737623940089
dev_f-score_macro_tok: 0.8093166501568737
dev_precision_micro_tok: 0.8991726990692864
dev_recall_micro_tok: 0.8991726990692864
dev_f-score_micro_tok: 0.8991726990692864
dev_time: 4.934357404708862
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6061    0.5405    0.5714        37
           1     0.9841    0.9878    0.9859      1064

   micro avg     0.9728    0.9728    0.9728      1101
   macro avg     0.7951    0.7642    0.7787      1101
weighted avg     0.9714    0.9728    0.9720      1101

F1-macro sent:  0.778678638434736
F1-micro sent:  0.9727520435967303
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9198    0.9616    0.9402     16205
           N     0.7936    0.6376    0.7071      1857
           P     0.8315    0.7357    0.7806      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8483    0.7783    0.8093     21274
weighted avg     0.8955    0.8992    0.8958     21274

F1-macro tok:  0.8093166501568737
F1-micro tok:  0.8991726990692864
**************************************************
Best epoch: 47
**************************************************

EPOCH: 50
Learning rate: 0.810000
train_cost_sum: 267046.63427734375
train_cost_avg: 31.25545813171158
train_count_sent: 8544.0
train_total_correct_sent: 8407.0
train_accuracy_sent: 0.9839653558052435
train_count_tok: 163566.0
train_total_correct_tok: 154753.0
train_accuracy_tok: 0.9461196092097379
train_label=0_precision_sent: 0.7794117647058824
train_label=0_recall_sent: 0.7335640138408305
train_label=0_f-score_sent: 0.7557932263814616
train_label=1_precision_sent: 0.9906914893617021
train_label=1_recall_sent: 0.9927316777710479
train_label=1_f-score_sent: 0.9917105342772433
train_precision_macro_sent: 0.8850516270337923
train_recall_macro_sent: 0.8631478458059392
train_f-score_macro_sent: 0.8737518803293525
train_precision_micro_sent: 0.9839653558052435
train_recall_micro_sent: 0.9839653558052435
train_f-score_micro_sent: 0.9839653558052435
train_label=O_precision_tok: 0.959303473939528
train_label=O_recall_tok: 0.9764610324334323
train_label=O_f-score_tok: 0.9678062155764035
train_label=N_precision_tok: 0.8805970149253731
train_label=N_recall_tok: 0.8391775806224475
train_label=N_f-score_tok: 0.8593885203345832
train_label=P_precision_tok: 0.912791441115042
train_label=P_recall_tok: 0.8560179078226806
train_label=P_f-score_tok: 0.8834935434630141
train_precision_macro_tok: 0.9175639766599811
train_recall_macro_tok: 0.8905521736261868
train_f-score_macro_tok: 0.9035627597913337
train_precision_micro_tok: 0.9461196092097379
train_recall_micro_tok: 0.9461196092097379
train_f-score_micro_tok: 0.9461196092097379
train_time: 93.27106642723083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7794    0.7336    0.7558       289
           1     0.9907    0.9927    0.9917      8255

   micro avg     0.9840    0.9840    0.9840      8544
   macro avg     0.8851    0.8631    0.8738      8544
weighted avg     0.9835    0.9840    0.9837      8544

F1-macro sent:  0.8737518803293525
F1-micro sent:  0.9839653558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9593    0.9765    0.9678    124347
           N     0.8806    0.8392    0.8594     14202
           P     0.9128    0.8560    0.8835     25017

   micro avg     0.9461    0.9461    0.9461    163566
   macro avg     0.9176    0.8906    0.9036    163566
weighted avg     0.9454    0.9461    0.9455    163566

F1-macro tok:  0.9035627597913337
F1-micro tok:  0.9461196092097379
**************************************************
dev_cost_sum: 41996.10046386719
dev_cost_avg: 38.14359715155966
dev_count_sent: 1101.0
dev_total_correct_sent: 1076.0
dev_accuracy_sent: 0.9772933696639419
dev_count_tok: 21274.0
dev_total_correct_tok: 19141.0
dev_accuracy_tok: 0.899736767885682
dev_label=0_precision_sent: 0.7727272727272727
dev_label=0_recall_sent: 0.4594594594594595
dev_label=0_f-score_sent: 0.576271186440678
dev_label=1_precision_sent: 0.9814643188137164
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9883341110592627
dev_precision_macro_sent: 0.8770957957704946
dev_recall_macro_sent: 0.7273801056695793
dev_f-score_macro_sent: 0.7823026487499704
dev_precision_micro_sent: 0.9772933696639419
dev_recall_micro_sent: 0.9772933696639419
dev_f-score_micro_sent: 0.9772933696639419
dev_label=O_precision_tok: 0.9200377960196067
dev_label=O_recall_tok: 0.9613699475470534
dev_label=O_f-score_tok: 0.9402498642042368
dev_label=N_precision_tok: 0.7852480417754569
dev_label=N_recall_tok: 0.6478190630048465
dev_label=N_f-score_tok: 0.7099439362643847
dev_label=P_precision_tok: 0.8398006407974368
dev_label=P_recall_tok: 0.7344333748443338
dev_label=P_f-score_tok: 0.7835907656535459
dev_precision_macro_tok: 0.8483621595308334
dev_recall_macro_tok: 0.7812074617987447
dev_f-score_macro_tok: 0.8112615220407223
dev_precision_micro_tok: 0.899736767885682
dev_recall_micro_tok: 0.899736767885682
dev_f-score_micro_tok: 0.899736767885682
dev_time: 4.950141191482544
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7727    0.4595    0.5763        37
           1     0.9815    0.9953    0.9883      1064

   micro avg     0.9773    0.9773    0.9773      1101
   macro avg     0.8771    0.7274    0.7823      1101
weighted avg     0.9744    0.9773    0.9745      1101

F1-macro sent:  0.7823026487499704
F1-micro sent:  0.9772933696639419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9200    0.9614    0.9402     16205
           N     0.7852    0.6478    0.7099      1857
           P     0.8398    0.7344    0.7836      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8484    0.7812    0.8113     21274
weighted avg     0.8962    0.8997    0.8965     21274

F1-macro tok:  0.8112615220407223
F1-micro tok:  0.899736767885682
**************************************************
Best epoch: 47
**************************************************

EPOCH: 51
Learning rate: 0.810000
train_cost_sum: 266696.94439697266
train_cost_avg: 31.21453000900897
train_count_sent: 8544.0
train_total_correct_sent: 8388.0
train_accuracy_sent: 0.9817415730337079
train_count_tok: 163566.0
train_total_correct_tok: 154845.0
train_accuracy_tok: 0.9466820732915153
train_label=0_precision_sent: 0.7547892720306514
train_label=0_recall_sent: 0.6816608996539792
train_label=0_f-score_sent: 0.7163636363636363
train_label=1_precision_sent: 0.988892913195702
train_label=1_recall_sent: 0.9922471229557843
train_label=1_f-score_sent: 0.9905671786189383
train_precision_macro_sent: 0.8718410926131768
train_recall_macro_sent: 0.8369540113048818
train_f-score_macro_sent: 0.8534654074912873
train_precision_micro_sent: 0.9817415730337079
train_recall_micro_sent: 0.9817415730337079
train_f-score_micro_sent: 0.9817415730337079
train_label=O_precision_tok: 0.9601830410419746
train_label=O_recall_tok: 0.9770320152476537
train_label=O_f-score_tok: 0.9685342559670914
train_label=N_precision_tok: 0.8787050040653411
train_label=N_recall_tok: 0.8370652020842135
train_label=N_f-score_tok: 0.8573798276297284
train_label=P_precision_tok: 0.9131359537178833
train_label=P_recall_tok: 0.8580565215653355
train_label=P_f-score_tok: 0.8847398248325605
train_precision_macro_tok: 0.9173413329417329
train_recall_macro_tok: 0.8907179129657342
train_f-score_macro_tok: 0.9035513028097935
train_precision_micro_tok: 0.9466820732915153
train_recall_micro_tok: 0.9466820732915153
train_f-score_micro_tok: 0.9466820732915153
train_time: 113.51343011856079
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7548    0.6817    0.7164       289
           1     0.9889    0.9922    0.9906      8255

   micro avg     0.9817    0.9817    0.9817      8544
   macro avg     0.8718    0.8370    0.8535      8544
weighted avg     0.9810    0.9817    0.9813      8544

F1-macro sent:  0.8534654074912873
F1-micro sent:  0.9817415730337079
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9602    0.9770    0.9685    124347
           N     0.8787    0.8371    0.8574     14202
           P     0.9131    0.8581    0.8847     25017

   micro avg     0.9467    0.9467    0.9467    163566
   macro avg     0.9173    0.8907    0.9036    163566
weighted avg     0.9459    0.9467    0.9461    163566

F1-macro tok:  0.9035513028097935
F1-micro tok:  0.9466820732915153
**************************************************
dev_cost_sum: 42014.249755859375
dev_cost_avg: 38.16008152212477
dev_count_sent: 1101.0
dev_total_correct_sent: 1072.0
dev_accuracy_sent: 0.9736603088101726
dev_count_tok: 21274.0
dev_total_correct_tok: 19116.0
dev_accuracy_tok: 0.8985616245181912
dev_label=0_precision_sent: 0.6333333333333333
dev_label=0_recall_sent: 0.5135135135135135
dev_label=0_f-score_sent: 0.5671641791044775
dev_label=1_precision_sent: 0.9831932773109243
dev_label=1_recall_sent: 0.9896616541353384
dev_label=1_f-score_sent: 0.9864168618266979
dev_precision_macro_sent: 0.8082633053221289
dev_recall_macro_sent: 0.7515875838244259
dev_f-score_macro_sent: 0.7767905204655876
dev_precision_micro_sent: 0.9736603088101726
dev_recall_micro_sent: 0.9736603088101726
dev_f-score_micro_sent: 0.9736603088101726
dev_label=O_precision_tok: 0.9184382545197574
dev_label=O_recall_tok: 0.9624190064794816
dev_label=O_f-score_tok: 0.939914421744109
dev_label=N_precision_tok: 0.7801324503311259
dev_label=N_recall_tok: 0.6343564889606893
dev_label=N_f-score_tok: 0.6997326997326998
dev_label=P_precision_tok: 0.8415379087315846
dev_label=P_recall_tok: 0.7291407222914073
dev_label=P_f-score_tok: 0.7813177648040034
dev_precision_macro_tok: 0.8467028711941559
dev_recall_macro_tok: 0.775305405910526
dev_f-score_macro_tok: 0.8069882954269373
dev_precision_micro_tok: 0.8985616245181912
dev_recall_micro_tok: 0.8985616245181912
dev_f-score_micro_tok: 0.8985616245181912
dev_time: 8.086555480957031
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6333    0.5135    0.5672        37
           1     0.9832    0.9897    0.9864      1064

   micro avg     0.9737    0.9737    0.9737      1101
   macro avg     0.8083    0.7516    0.7768      1101
weighted avg     0.9714    0.9737    0.9723      1101

F1-macro sent:  0.7767905204655876
F1-micro sent:  0.9736603088101726
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9624    0.9399     16205
           N     0.7801    0.6344    0.6997      1857
           P     0.8415    0.7291    0.7813      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8467    0.7753    0.8070     21274
weighted avg     0.8948    0.8986    0.8950     21274

F1-macro tok:  0.8069882954269373
F1-micro tok:  0.8985616245181912
**************************************************
Best epoch: 47
**************************************************

EPOCH: 52
Learning rate: 0.729000
train_cost_sum: 265747.1162109375
train_cost_avg: 31.103360979744558
train_count_sent: 8544.0
train_total_correct_sent: 8396.0
train_accuracy_sent: 0.9826779026217228
train_count_tok: 163566.0
train_total_correct_tok: 155049.0
train_accuracy_tok: 0.9479292762554565
train_label=0_precision_sent: 0.7701149425287356
train_label=0_recall_sent: 0.6955017301038062
train_label=0_f-score_sent: 0.7309090909090908
train_label=1_precision_sent: 0.9893758300132802
train_label=1_recall_sent: 0.9927316777710479
train_label=1_f-score_sent: 0.9910509130487363
train_precision_macro_sent: 0.8797453862710078
train_recall_macro_sent: 0.8441167039374271
train_f-score_macro_sent: 0.8609800019789136
train_precision_micro_sent: 0.9826779026217228
train_recall_micro_sent: 0.9826779026217228
train_f-score_micro_sent: 0.9826779026217228
train_label=O_precision_tok: 0.9616160976497875
train_label=O_recall_tok: 0.9769435531215067
train_label=O_f-score_tok: 0.9692192311988383
train_label=N_precision_tok: 0.8797737955346651
train_label=N_recall_tok: 0.8434727503168568
train_label=N_f-score_tok: 0.8612409231432885
train_label=P_precision_tok: 0.9140171880953389
train_label=P_recall_tok: 0.863013151057281
train_label=P_f-score_tok: 0.8877832147703442
train_precision_macro_tok: 0.918469027093264
train_recall_macro_tok: 0.8944764848318815
train_f-score_macro_tok: 0.9060811230374903
train_precision_micro_tok: 0.9479292762554565
train_recall_micro_tok: 0.9479292762554565
train_f-score_micro_tok: 0.9479292762554565
train_time: 142.15823435783386
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7701    0.6955    0.7309       289
           1     0.9894    0.9927    0.9911      8255

   micro avg     0.9827    0.9827    0.9827      8544
   macro avg     0.8797    0.8441    0.8610      8544
weighted avg     0.9820    0.9827    0.9823      8544

F1-macro sent:  0.8609800019789136
F1-micro sent:  0.9826779026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9616    0.9769    0.9692    124347
           N     0.8798    0.8435    0.8612     14202
           P     0.9140    0.8630    0.8878     25017

   micro avg     0.9479    0.9479    0.9479    163566
   macro avg     0.9185    0.8945    0.9061    163566
weighted avg     0.9472    0.9479    0.9474    163566

F1-macro tok:  0.9060811230374903
F1-micro tok:  0.9479292762554565
**************************************************
dev_cost_sum: 41924.02520751953
dev_cost_avg: 38.07813370346915
dev_count_sent: 1101.0
dev_total_correct_sent: 1071.0
dev_accuracy_sent: 0.9727520435967303
dev_count_tok: 21274.0
dev_total_correct_tok: 19182.0
dev_accuracy_tok: 0.901664003008367
dev_label=0_precision_sent: 0.8181818181818182
dev_label=0_recall_sent: 0.24324324324324326
dev_label=0_f-score_sent: 0.375
dev_label=1_precision_sent: 0.9743119266055046
dev_label=1_recall_sent: 0.9981203007518797
dev_label=1_f-score_sent: 0.9860724233983286
dev_precision_macro_sent: 0.8962468723936614
dev_recall_macro_sent: 0.6206817719975615
dev_f-score_macro_sent: 0.6805362116991642
dev_precision_micro_sent: 0.9727520435967303
dev_recall_micro_sent: 0.9727520435967303
dev_f-score_micro_sent: 0.9727520435967303
dev_label=O_precision_tok: 0.9197338201519345
dev_label=O_recall_tok: 0.9637766121567417
dev_label=O_f-score_tok: 0.9412402820466462
dev_label=N_precision_tok: 0.7833655705996132
dev_label=N_recall_tok: 0.654281098546042
dev_label=N_f-score_tok: 0.7130281690140845
dev_label=P_precision_tok: 0.8566739606126915
dev_label=P_recall_tok: 0.7313200498132005
dev_label=P_f-score_tok: 0.7890493785690292
dev_precision_macro_tok: 0.8532577837880798
dev_recall_macro_tok: 0.7831259201719947
dev_f-score_macro_tok: 0.8144392765432533
dev_precision_micro_tok: 0.901664003008367
dev_recall_micro_tok: 0.901664003008367
dev_f-score_micro_tok: 0.901664003008367
dev_time: 8.073062181472778
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8182    0.2432    0.3750        37
           1     0.9743    0.9981    0.9861      1064

   micro avg     0.9728    0.9728    0.9728      1101
   macro avg     0.8962    0.6207    0.6805      1101
weighted avg     0.9691    0.9728    0.9655      1101

F1-macro sent:  0.6805362116991642
F1-micro sent:  0.9727520435967303
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9197    0.9638    0.9412     16205
           N     0.7834    0.6543    0.7130      1857
           P     0.8567    0.7313    0.7890      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8533    0.7831    0.8144     21274
weighted avg     0.8983    0.9017    0.8983     21274

F1-macro tok:  0.8144392765432533
F1-micro tok:  0.901664003008367
**************************************************
Best epoch: 47
**************************************************

EPOCH: 53
Learning rate: 0.656100
train_cost_sum: 264692.07678222656
train_cost_avg: 30.9798779005415
train_count_sent: 8544.0
train_total_correct_sent: 8413.0
train_accuracy_sent: 0.9846676029962547
train_count_tok: 163566.0
train_total_correct_tok: 155469.0
train_accuracy_tok: 0.9504970470635706
train_label=0_precision_sent: 0.7969924812030075
train_label=0_recall_sent: 0.7335640138408305
train_label=0_f-score_sent: 0.7639639639639639
train_label=1_precision_sent: 0.9906982362889587
train_label=1_recall_sent: 0.993458509993943
train_label=1_f-score_sent: 0.9920764531542975
train_precision_macro_sent: 0.8938453587459831
train_recall_macro_sent: 0.8635112619173868
train_f-score_macro_sent: 0.8780202085591307
train_precision_micro_sent: 0.9846676029962547
train_recall_micro_sent: 0.9846676029962547
train_f-score_micro_sent: 0.9846676029962547
train_label=O_precision_tok: 0.9633930905547677
train_label=O_recall_tok: 0.9780050986352706
train_label=O_f-score_tok: 0.9706441056748345
train_label=N_precision_tok: 0.8858907433276965
train_label=N_recall_tok: 0.8484016335727362
train_label=N_f-score_tok: 0.8667409991727512
train_label=P_precision_tok: 0.9189280296645879
train_label=P_recall_tok: 0.871727225486669
train_label=P_f-score_tok: 0.8947055324211779
train_precision_macro_tok: 0.9227372878490173
train_recall_macro_tok: 0.8993779858982253
train_f-score_macro_tok: 0.9106968790895879
train_precision_micro_tok: 0.9504970470635706
train_recall_micro_tok: 0.9504970470635706
train_f-score_micro_tok: 0.9504970470635706
train_time: 141.68606162071228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7970    0.7336    0.7640       289
           1     0.9907    0.9935    0.9921      8255

   micro avg     0.9847    0.9847    0.9847      8544
   macro avg     0.8938    0.8635    0.8780      8544
weighted avg     0.9841    0.9847    0.9844      8544

F1-macro sent:  0.8780202085591307
F1-micro sent:  0.9846676029962547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9634    0.9780    0.9706    124347
           N     0.8859    0.8484    0.8667     14202
           P     0.9189    0.8717    0.8947     25017

   micro avg     0.9505    0.9505    0.9505    163566
   macro avg     0.9227    0.8994    0.9107    163566
weighted avg     0.9499    0.9505    0.9500    163566

F1-macro tok:  0.9106968790895879
F1-micro tok:  0.9504970470635706
**************************************************
dev_cost_sum: 42137.82556152344
dev_cost_avg: 38.27232112763255
dev_count_sent: 1101.0
dev_total_correct_sent: 1074.0
dev_accuracy_sent: 0.9754768392370572
dev_count_tok: 21274.0
dev_total_correct_tok: 19147.0
dev_accuracy_tok: 0.9000188022938799
dev_label=0_precision_sent: 0.75
dev_label=0_recall_sent: 0.40540540540540543
dev_label=0_f-score_sent: 0.5263157894736842
dev_label=1_precision_sent: 0.9796484736355227
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9874125874125874
dev_precision_macro_sent: 0.8648242368177613
dev_recall_macro_sent: 0.7003530786425524
dev_f-score_macro_sent: 0.7568641884431357
dev_precision_micro_sent: 0.9754768392370572
dev_recall_micro_sent: 0.9754768392370572
dev_f-score_micro_sent: 0.9754768392370572
dev_label=O_precision_tok: 0.9177389975909278
dev_label=O_recall_tok: 0.9638383215057081
dev_label=O_f-score_tok: 0.940223934505177
dev_label=N_precision_tok: 0.7922511690046761
dev_label=N_recall_tok: 0.6386645126548196
dev_label=N_f-score_tok: 0.7072152653548003
dev_label=P_precision_tok: 0.8491660623640319
dev_label=P_recall_tok: 0.7291407222914073
dev_label=P_f-score_tok: 0.7845896147403685
dev_precision_macro_tok: 0.8530520763198787
dev_recall_macro_tok: 0.7772145188173116
dev_f-score_macro_tok: 0.8106762715334486
dev_precision_micro_tok: 0.9000188022938799
dev_recall_micro_tok: 0.9000188022938799
dev_f-score_micro_tok: 0.9000188022938799
dev_time: 8.188982248306274
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7500    0.4054    0.5263        37
           1     0.9796    0.9953    0.9874      1064

   micro avg     0.9755    0.9755    0.9755      1101
   macro avg     0.8648    0.7004    0.7569      1101
weighted avg     0.9719    0.9755    0.9719      1101

F1-macro sent:  0.7568641884431357
F1-micro sent:  0.9754768392370572
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9177    0.9638    0.9402     16205
           N     0.7923    0.6387    0.7072      1857
           P     0.8492    0.7291    0.7846      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8531    0.7772    0.8107     21274
weighted avg     0.8964    0.9000    0.8964     21274

F1-macro tok:  0.8106762715334486
F1-micro tok:  0.9000188022938799
**************************************************
Best epoch: 47
**************************************************

EPOCH: 54
Learning rate: 0.590490
train_cost_sum: 264051.4127807617
train_cost_avg: 30.904893817973047
train_count_sent: 8544.0
train_total_correct_sent: 8384.0
train_accuracy_sent: 0.9812734082397003
train_count_tok: 163566.0
train_total_correct_tok: 155561.0
train_accuracy_tok: 0.951059511145348
train_label=0_precision_sent: 0.7509727626459144
train_label=0_recall_sent: 0.6678200692041523
train_label=0_f-score_sent: 0.706959706959707
train_label=1_precision_sent: 0.9884155906842041
train_label=1_recall_sent: 0.9922471229557843
train_label=1_f-score_sent: 0.9903276508281947
train_precision_macro_sent: 0.8696941766650592
train_recall_macro_sent: 0.8300335960799683
train_f-score_macro_sent: 0.8486436788939509
train_precision_micro_sent: 0.9812734082397003
train_recall_micro_sent: 0.9812734082397003
train_f-score_micro_sent: 0.9812734082397003
train_label=O_precision_tok: 0.9639293328789164
train_label=O_recall_tok: 0.9780533507040781
train_label=O_f-score_tok: 0.9709399798815245
train_label=N_precision_tok: 0.8897360703812317
train_label=N_recall_tok: 0.854527531333615
train_label=N_f-score_tok: 0.8717764528410316
train_label=P_precision_tok: 0.9179189291577219
train_label=P_recall_tok: 0.8716872526681856
train_label=P_f-score_tok: 0.8942059293886087
train_precision_macro_tok: 0.92386144413929
train_recall_macro_tok: 0.9014227115686263
train_f-score_macro_tok: 0.9123074540370549
train_precision_micro_tok: 0.951059511145348
train_recall_micro_tok: 0.951059511145348
train_f-score_micro_tok: 0.951059511145348
train_time: 142.29105639457703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7510    0.6678    0.7070       289
           1     0.9884    0.9922    0.9903      8255

   micro avg     0.9813    0.9813    0.9813      8544
   macro avg     0.8697    0.8300    0.8486      8544
weighted avg     0.9804    0.9813    0.9807      8544

F1-macro sent:  0.8486436788939509
F1-micro sent:  0.9812734082397003
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9639    0.9781    0.9709    124347
           N     0.8897    0.8545    0.8718     14202
           P     0.9179    0.8717    0.8942     25017

   micro avg     0.9511    0.9511    0.9511    163566
   macro avg     0.9239    0.9014    0.9123    163566
weighted avg     0.9505    0.9511    0.9506    163566

F1-macro tok:  0.9123074540370549
F1-micro tok:  0.951059511145348
**************************************************
dev_cost_sum: 42197.667541503906
dev_cost_avg: 38.32667351635232
dev_count_sent: 1101.0
dev_total_correct_sent: 1076.0
dev_accuracy_sent: 0.9772933696639419
dev_count_tok: 21274.0
dev_total_correct_tok: 19144.0
dev_accuracy_tok: 0.899877785089781
dev_label=0_precision_sent: 0.7727272727272727
dev_label=0_recall_sent: 0.4594594594594595
dev_label=0_f-score_sent: 0.576271186440678
dev_label=1_precision_sent: 0.9814643188137164
dev_label=1_recall_sent: 0.9953007518796992
dev_label=1_f-score_sent: 0.9883341110592627
dev_precision_macro_sent: 0.8770957957704946
dev_recall_macro_sent: 0.7273801056695793
dev_f-score_macro_sent: 0.7823026487499704
dev_precision_micro_sent: 0.9772933696639419
dev_recall_micro_sent: 0.9772933696639419
dev_f-score_micro_sent: 0.9772933696639419
dev_label=O_precision_tok: 0.9190080697414148
dev_label=O_recall_tok: 0.9627892625732799
dev_label=O_f-score_tok: 0.940389367729492
dev_label=N_precision_tok: 0.7883211678832117
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7063020214030917
dev_label=P_precision_tok: 0.8437275985663082
dev_label=P_recall_tok: 0.7328767123287672
dev_label=P_f-score_tok: 0.7844051982672442
dev_precision_macro_tok: 0.8503522787303116
dev_recall_macro_tok: 0.7784691644934664
dev_f-score_macro_tok: 0.8103655291332759
dev_precision_micro_tok: 0.899877785089781
dev_recall_micro_tok: 0.899877785089781
dev_f-score_micro_tok: 0.899877785089781
dev_time: 8.096433162689209
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7727    0.4595    0.5763        37
           1     0.9815    0.9953    0.9883      1064

   micro avg     0.9773    0.9773    0.9773      1101
   macro avg     0.8771    0.7274    0.7823      1101
weighted avg     0.9744    0.9773    0.9745      1101

F1-macro sent:  0.7823026487499704
F1-micro sent:  0.9772933696639419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9190    0.9628    0.9404     16205
           N     0.7883    0.6397    0.7063      1857
           P     0.8437    0.7329    0.7844      3212

   micro avg     0.8999    0.8999    0.8999     21274
   macro avg     0.8504    0.7785    0.8104     21274
weighted avg     0.8962    0.8999    0.8964     21274

F1-macro tok:  0.8103655291332759
F1-micro tok:  0.899877785089781
**************************************************
Best epoch: 47
**************************************************

test0_cost_sum: 41660.572265625
test0_cost_avg: 37.8388485609673
test0_count_sent: 1101.0
test0_total_correct_sent: 1073.0
test0_accuracy_sent: 0.9745685740236149
test0_count_tok: 21274.0
test0_total_correct_tok: 19238.0
test0_accuracy_tok: 0.9042963241515465
test0_label=0_precision_sent: 0.7368421052631579
test0_label=0_recall_sent: 0.3783783783783784
test0_label=0_f-score_sent: 0.5
test0_label=1_precision_sent: 0.9787430683918669
test0_label=1_recall_sent: 0.9953007518796992
test0_label=1_f-score_sent: 0.9869524697110903
test0_precision_macro_sent: 0.8577925868275124
test0_recall_macro_sent: 0.6868395651290389
test0_f-score_macro_sent: 0.7434762348555451
test0_precision_micro_sent: 0.9745685740236149
test0_recall_micro_sent: 0.9745685740236149
test0_f-score_micro_sent: 0.9745685740236149
test0_label=O_precision_tok: 0.9157166123778502
test0_label=O_recall_tok: 0.9714902807775379
test0_label=O_f-score_tok: 0.9427792915531336
test0_label=N_precision_tok: 0.8081155433287482
test0_label=N_recall_tok: 0.6327409800753904
test0_label=N_f-score_tok: 0.7097553609181515
test0_label=P_precision_tok: 0.882800608828006
test0_label=P_recall_tok: 0.7222914072229141
test0_label=P_f-score_tok: 0.7945205479452054
test0_precision_macro_tok: 0.8688775881782016
test0_recall_macro_tok: 0.7755075560252808
test0_f-score_macro_tok: 0.8156850668054969
test0_precision_micro_tok: 0.9042963241515465
test0_recall_micro_tok: 0.9042963241515465
test0_f-score_micro_tok: 0.9042963241515465
test0_time: 8.223123550415039
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7368    0.3784    0.5000        37
           1     0.9787    0.9953    0.9870      1064

   micro avg     0.9746    0.9746    0.9746      1101
   macro avg     0.8578    0.6868    0.7435      1101
weighted avg     0.9706    0.9746    0.9706      1101

F1-macro sent:  0.7434762348555451
F1-micro sent:  0.9745685740236149
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9715    0.9428     16205
           N     0.8081    0.6327    0.7098      1857
           P     0.8828    0.7223    0.7945      3212

   micro avg     0.9043    0.9043    0.9043     21274
   macro avg     0.8689    0.7755    0.8157     21274
weighted avg     0.9014    0.9043    0.9001     21274

F1-macro tok:  0.8156850668054969
F1-micro tok:  0.9042963241515465
**************************************************
test1_cost_sum: 81289.19984817505
test1_cost_avg: 36.782443370214956
test1_count_sent: 2210.0
test1_total_correct_sent: 2155.0
test1_accuracy_sent: 0.9751131221719457
test1_count_tok: 42405.0
test1_total_correct_tok: 37974.0
test1_accuracy_tok: 0.8955076052352317
test1_label=0_precision_sent: 0.7058823529411765
test1_label=0_recall_sent: 0.34782608695652173
test1_label=0_f-score_sent: 0.4660194174757282
test1_label=1_precision_sent: 0.9793198529411765
test1_label=1_recall_sent: 0.9953292853806632
test1_label=1_f-score_sent: 0.9872596710678713
test1_precision_macro_sent: 0.8426011029411765
test1_recall_macro_sent: 0.6715776861685925
test1_f-score_macro_sent: 0.7266395442717998
test1_precision_micro_sent: 0.9751131221719457
test1_recall_micro_sent: 0.9751131221719457
test1_f-score_micro_sent: 0.9751131221719457
test1_label=O_precision_tok: 0.9059721938849864
test1_label=O_recall_tok: 0.9714044627789237
test1_label=O_f-score_tok: 0.9375480718476179
test1_label=N_precision_tok: 0.7934382323401407
test1_label=N_recall_tok: 0.6303191489361702
test1_label=N_f-score_tok: 0.7025344597598934
test1_label=P_precision_tok: 0.8849089841456254
test1_label=P_recall_tok: 0.6801564615616067
test1_label=P_f-score_tok: 0.7691391629806056
test1_precision_macro_tok: 0.8614398034569174
test1_recall_macro_tok: 0.7606266910922335
test1_f-score_macro_tok: 0.8030738981960389
test1_precision_micro_tok: 0.8955076052352317
test1_recall_micro_tok: 0.8955076052352317
test1_f-score_micro_tok: 0.8955076052352317
test1_time: 16.493770122528076
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7059    0.3478    0.4660        69
           1     0.9793    0.9953    0.9873      2141

   micro avg     0.9751    0.9751    0.9751      2210
   macro avg     0.8426    0.6716    0.7266      2210
weighted avg     0.9708    0.9751    0.9710      2210

F1-macro sent:  0.7266395442717998
F1-micro sent:  0.9751131221719457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9060    0.9714    0.9375     31998
           N     0.7934    0.6303    0.7025      3760
           P     0.8849    0.6802    0.7691      6647

   micro avg     0.8955    0.8955    0.8955     42405
   macro avg     0.8614    0.7606    0.8031     42405
weighted avg     0.8927    0.8955    0.8903     42405

F1-macro tok:  0.8030738981960389
F1-micro tok:  0.8955076052352317
**************************************************
