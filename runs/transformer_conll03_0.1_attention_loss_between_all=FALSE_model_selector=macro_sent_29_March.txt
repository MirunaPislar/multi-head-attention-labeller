to_write_filename: runs/transformer_conll03_0.1_attention_loss_between_all=FALSE_model_selector=macro_sent_29_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'1': 1, '0': 0}
{'PER': 4, 'MISC': 2, 'ORG': 3, 'LOC': 1, 'O': 0}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-29 09:05:30.701299: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-29 09:05:36.294939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 81fa:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-29 09:05:36.294996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-29 09:06:01.398638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-29 09:06:01.398684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-29 09:06:01.398696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-29 09:06:01.398962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 81fa:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 9797652.
Parameter count without word embeddings: 3230652.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 452205.55895996094
train_cost_avg: 32.206079265006835
train_count_sent: 14041.0
train_total_correct_sent: 11824.0
train_accuracy_sent: 0.8421052631578947
train_count_tok: 203621.0
train_total_correct_tok: 186504.0
train_accuracy_tok: 0.9159369613153849
train_label=0_precision_sent: 0.6787190082644629
train_label=0_recall_sent: 0.45170161567548983
train_label=0_f-score_sent: 0.5424148606811147
train_label=1_precision_sent: 0.8682362660057827
train_label=1_recall_sent: 0.9441250449155587
train_label=1_f-score_sent: 0.9045918147781555
train_precision_macro_sent: 0.7734776371351229
train_recall_macro_sent: 0.6979133302955243
train_f-score_macro_sent: 0.7235033377296352
train_precision_micro_sent: 0.8421052631578947
train_recall_micro_sent: 0.8421052631578947
train_f-score_micro_sent: 0.8421052631578947
train_label=O_precision_tok: 0.9472262196613331
train_label=O_recall_tok: 0.9820200733585724
train_label=O_f-score_tok: 0.9643093938648175
train_label=LOC_precision_tok: 0.7022092666462105
train_label=LOC_recall_tok: 0.5516451729540798
train_label=LOC_f-score_tok: 0.6178872764090448
train_label=MISC_precision_tok: 0.593108504398827
train_label=MISC_recall_tok: 0.3522752013934248
train_label=MISC_f-score_tok: 0.44201611801666435
train_label=ORG_precision_tok: 0.6702237078940602
train_label=ORG_recall_tok: 0.52
train_label=ORG_f-score_tok: 0.5856316351176767
train_label=PER_precision_tok: 0.7939759036144578
train_label=PER_recall_tok: 0.7698598130841121
train_label=PER_f-score_tok: 0.7817319098457888
train_precision_macro_tok: 0.7413487204429778
train_recall_macro_tok: 0.6351600521580378
train_f-score_macro_tok: 0.6783152666507984
train_precision_micro_tok: 0.9159369613153849
train_recall_micro_tok: 0.9159369613153849
train_f-score_micro_tok: 0.9159369613153849
train_time: 90.23169660568237
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6787    0.4517    0.5424      2909
           1     0.8682    0.9441    0.9046     11132

   micro avg     0.8421    0.8421    0.8421     14041
   macro avg     0.7735    0.6979    0.7235     14041
weighted avg     0.8290    0.8421    0.8296     14041

F1-macro sent:  0.7235033377296352
F1-micro sent:  0.8421052631578947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9472    0.9820    0.9643    169578
         LOC     0.7022    0.5516    0.6179      8297
        MISC     0.5931    0.3523    0.4420      4593
         ORG     0.6702    0.5200    0.5856     10025
         PER     0.7940    0.7699    0.7817     11128

   micro avg     0.9159    0.9159    0.9159    203621
   macro avg     0.7413    0.6352    0.6783    203621
weighted avg     0.9072    0.9159    0.9098    203621

F1-macro tok:  0.6783152666507984
F1-micro tok:  0.9159369613153849
**************************************************
dev_cost_sum: 101355.08598327637
dev_cost_avg: 31.186180302546575
dev_count_sent: 3250.0
dev_total_correct_sent: 2998.0
dev_accuracy_sent: 0.9224615384615384
dev_count_tok: 51362.0
dev_total_correct_tok: 49928.0
dev_accuracy_tok: 0.97208052645925
dev_label=0_precision_sent: 0.8490230905861457
dev_label=0_recall_sent: 0.7410852713178294
dev_label=0_f-score_sent: 0.7913907284768211
dev_label=1_precision_sent: 0.9378489021213249
dev_label=1_recall_sent: 0.9673704414587332
dev_label=1_f-score_sent: 0.9523809523809524
dev_precision_macro_sent: 0.8934359963537353
dev_recall_macro_sent: 0.8542278563882812
dev_f-score_macro_sent: 0.8718858404288867
dev_precision_micro_sent: 0.9224615384615384
dev_recall_micro_sent: 0.9224615384615384
dev_f-score_micro_sent: 0.9224615384615384
dev_label=O_precision_tok: 0.987727641804895
dev_label=O_recall_tok: 0.995720199256297
dev_label=O_f-score_tok: 0.9917078170129507
dev_label=LOC_precision_tok: 0.9210392256749873
dev_label=LOC_recall_tok: 0.8634192932187201
dev_label=LOC_f-score_tok: 0.8912989894010352
dev_label=MISC_precision_tok: 0.8634146341463415
dev_label=MISC_recall_tok: 0.6979495268138801
dev_label=MISC_f-score_tok: 0.7719145224596599
dev_label=ORG_precision_tok: 0.8569114470842333
dev_label=ORG_recall_tok: 0.7586042065009561
dev_label=ORG_f-score_tok: 0.804766734279919
dev_label=PER_precision_tok: 0.8990342405618964
dev_label=PER_recall_tok: 0.9755477929501429
dev_label=PER_f-score_tok: 0.9357295156868718
dev_precision_macro_tok: 0.9056254378544708
dev_recall_macro_tok: 0.8582482037479991
dev_f-score_macro_tok: 0.8790835157680874
dev_precision_micro_tok: 0.97208052645925
dev_recall_micro_tok: 0.97208052645925
dev_f-score_micro_tok: 0.97208052645925
dev_time: 7.353550672531128
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8490    0.7411    0.7914       645
           1     0.9378    0.9674    0.9524      2605

   micro avg     0.9225    0.9225    0.9225      3250
   macro avg     0.8934    0.8542    0.8719      3250
weighted avg     0.9202    0.9225    0.9204      3250

F1-macro sent:  0.8718858404288867
F1-micro sent:  0.9224615384615384
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9877    0.9957    0.9917     42759
         LOC     0.9210    0.8634    0.8913      2094
        MISC     0.8634    0.6979    0.7719      1268
         ORG     0.8569    0.7586    0.8048      2092
         PER     0.8990    0.9755    0.9357      3149

   micro avg     0.9721    0.9721    0.9721     51362
   macro avg     0.9056    0.8582    0.8791     51362
weighted avg     0.9712    0.9721    0.9711     51362

F1-macro tok:  0.8790835157680874
F1-micro tok:  0.97208052645925
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 381827.3521118164
train_cost_avg: 27.193743473528695
train_count_sent: 14041.0
train_total_correct_sent: 12614.0
train_accuracy_sent: 0.8983690620326188
train_count_tok: 203621.0
train_total_correct_tok: 196071.0
train_accuracy_tok: 0.962921309688097
train_label=0_precision_sent: 0.7883268482490272
train_label=0_recall_sent: 0.696459264352011
train_label=0_f-score_sent: 0.7395510129585691
train_label=1_precision_sent: 0.9230232760875251
train_label=1_recall_sent: 0.9511318720804887
train_label=1_f-score_sent: 0.9368667875945671
train_precision_macro_sent: 0.8556750621682762
train_recall_macro_sent: 0.8237955682162499
train_f-score_macro_sent: 0.838208900276568
train_precision_micro_sent: 0.8983690620326188
train_recall_micro_sent: 0.8983690620326188
train_f-score_micro_sent: 0.8983690620326188
train_label=O_precision_tok: 0.9872870164400125
train_label=O_recall_tok: 0.9919388128177004
train_label=O_f-score_tok: 0.9896074480445941
train_label=LOC_precision_tok: 0.8383039885016169
train_label=LOC_recall_tok: 0.8435579124984934
train_label=LOC_f-score_tok: 0.8409227442028114
train_label=MISC_precision_tok: 0.745607333842628
train_label=MISC_recall_tok: 0.6374918354016982
train_label=MISC_f-score_tok: 0.6873239436619718
train_label=ORG_precision_tok: 0.7927363807138385
train_label=ORG_recall_tok: 0.7577057356608479
train_label=ORG_f-score_tok: 0.774825317488652
train_label=PER_precision_tok: 0.9078693131916389
train_label=PER_recall_tok: 0.9289180445722501
train_label=PER_f-score_tok: 0.9182730745314027
train_precision_macro_tok: 0.854360806537947
train_recall_macro_tok: 0.831922468190198
train_f-score_macro_tok: 0.8421905055858865
train_precision_micro_tok: 0.962921309688097
train_recall_micro_tok: 0.962921309688097
train_f-score_micro_tok: 0.962921309688097
train_time: 84.55109310150146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7883    0.6965    0.7396      2909
           1     0.9230    0.9511    0.9369     11132

   micro avg     0.8984    0.8984    0.8984     14041
   macro avg     0.8557    0.8238    0.8382     14041
weighted avg     0.8951    0.8984    0.8960     14041

F1-macro sent:  0.838208900276568
F1-micro sent:  0.8983690620326188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9873    0.9919    0.9896    169578
         LOC     0.8383    0.8436    0.8409      8297
        MISC     0.7456    0.6375    0.6873      4593
         ORG     0.7927    0.7577    0.7748     10025
         PER     0.9079    0.9289    0.9183     11128

   micro avg     0.9629    0.9629    0.9629    203621
   macro avg     0.8544    0.8319    0.8422    203621
weighted avg     0.9618    0.9629    0.9623    203621

F1-macro tok:  0.8421905055858865
F1-micro tok:  0.962921309688097
**************************************************
dev_cost_sum: 99181.91554260254
dev_cost_avg: 30.517512474646935
dev_count_sent: 3250.0
dev_total_correct_sent: 2796.0
dev_accuracy_sent: 0.8603076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50104.0
dev_accuracy_tok: 0.9755071842996768
dev_label=0_precision_sent: 0.5922705314009662
dev_label=0_recall_sent: 0.9503875968992248
dev_label=0_f-score_sent: 0.7297619047619048
dev_label=1_precision_sent: 0.9855530474040632
dev_label=1_recall_sent: 0.8380038387715931
dev_label=1_f-score_sent: 0.9058091286307054
dev_precision_macro_sent: 0.7889117894025147
dev_recall_macro_sent: 0.894195717835409
dev_f-score_macro_sent: 0.8177855166963051
dev_precision_micro_sent: 0.8603076923076923
dev_recall_micro_sent: 0.8603076923076923
dev_f-score_micro_sent: 0.8603076923076924
dev_label=O_precision_tok: 0.9934976844271881
dev_label=O_recall_tok: 0.9933815103253116
dev_label=O_f-score_tok: 0.9934395939798627
dev_label=LOC_precision_tok: 0.9475374732334048
dev_label=LOC_recall_tok: 0.8452722063037249
dev_label=LOC_f-score_tok: 0.8934881373043917
dev_label=MISC_precision_tok: 0.9209445585215605
dev_label=MISC_recall_tok: 0.7074132492113565
dev_label=MISC_f-score_tok: 0.800178412132025
dev_label=ORG_precision_tok: 0.7493058310194367
dev_label=ORG_recall_tok: 0.902963671128107
dev_label=ORG_f-score_tok: 0.8189898114025579
dev_label=PER_precision_tok: 0.9466872110939908
dev_label=PER_recall_tok: 0.9755477929501429
dev_label=PER_f-score_tok: 0.960900844541758
dev_precision_macro_tok: 0.9115945516591163
dev_recall_macro_tok: 0.8849156859837286
dev_f-score_macro_tok: 0.893399359872119
dev_precision_micro_tok: 0.9755071842996768
dev_recall_micro_tok: 0.9755071842996768
dev_f-score_micro_tok: 0.9755071842996768
dev_time: 6.846694707870483
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.5923    0.9504    0.7298       645
           1     0.9856    0.8380    0.9058      2605

   micro avg     0.8603    0.8603    0.8603      3250
   macro avg     0.7889    0.8942    0.8178      3250
weighted avg     0.9075    0.8603    0.8709      3250

F1-macro sent:  0.8177855166963051
F1-micro sent:  0.8603076923076924
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9935    0.9934    0.9934     42759
         LOC     0.9475    0.8453    0.8935      2094
        MISC     0.9209    0.7074    0.8002      1268
         ORG     0.7493    0.9030    0.8190      2092
         PER     0.9467    0.9755    0.9609      3149

   micro avg     0.9755    0.9755    0.9755     51362
   macro avg     0.9116    0.8849    0.8934     51362
weighted avg     0.9770    0.9755    0.9755     51362

F1-macro tok:  0.893399359872119
F1-micro tok:  0.9755071842996768
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369714.4861755371
train_cost_avg: 26.33106517880045
train_count_sent: 14041.0
train_total_correct_sent: 12963.0
train_accuracy_sent: 0.9232248415355032
train_count_tok: 203621.0
train_total_correct_tok: 197393.0
train_accuracy_tok: 0.9694137638062872
train_label=0_precision_sent: 0.8280186313149409
train_label=0_recall_sent: 0.7944310759711241
train_label=0_f-score_sent: 0.8108771929824563
train_label=1_precision_sent: 0.9468444444444445
train_label=1_recall_sent: 0.9568810636004312
train_label=1_f-score_sent: 0.9518362970243948
train_precision_macro_sent: 0.8874315378796926
train_recall_macro_sent: 0.8756560697857776
train_f-score_macro_sent: 0.8813567450034255
train_precision_micro_sent: 0.9232248415355032
train_recall_micro_sent: 0.9232248415355032
train_f-score_micro_sent: 0.9232248415355032
train_label=O_precision_tok: 0.9900238088239617
train_label=O_recall_tok: 0.9931005201146376
train_label=O_f-score_tok: 0.9915597777928246
train_label=LOC_precision_tok: 0.8692473633748802
train_label=LOC_recall_tok: 0.874171387248403
train_label=LOC_f-score_tok: 0.8717024217294634
train_label=MISC_precision_tok: 0.7821078431372549
train_label=MISC_recall_tok: 0.6947528848247333
train_label=MISC_f-score_tok: 0.7358468811253314
train_label=ORG_precision_tok: 0.8231494771375846
train_label=ORG_recall_tok: 0.8008977556109725
train_label=ORG_f-score_tok: 0.8118711765003287
train_label=PER_precision_tok: 0.927147645087317
train_label=PER_recall_tok: 0.9446441409058232
train_label=PER_f-score_tok: 0.9358141191133268
train_precision_macro_tok: 0.8783352275121997
train_recall_macro_tok: 0.8615133377409139
train_f-score_macro_tok: 0.869358875252255
train_precision_micro_tok: 0.9694137638062872
train_recall_micro_tok: 0.9694137638062872
train_f-score_micro_tok: 0.9694137638062872
train_time: 83.94044399261475
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8280    0.7944    0.8109      2909
           1     0.9468    0.9569    0.9518     11132

   micro avg     0.9232    0.9232    0.9232     14041
   macro avg     0.8874    0.8757    0.8814     14041
weighted avg     0.9222    0.9232    0.9226     14041

F1-macro sent:  0.8813567450034255
F1-micro sent:  0.9232248415355032
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9900    0.9931    0.9916    169578
         LOC     0.8692    0.8742    0.8717      8297
        MISC     0.7821    0.6948    0.7358      4593
         ORG     0.8231    0.8009    0.8119     10025
         PER     0.9271    0.9446    0.9358     11128

   micro avg     0.9694    0.9694    0.9694    203621
   macro avg     0.8783    0.8615    0.8694    203621
weighted avg     0.9688    0.9694    0.9690    203621

F1-macro tok:  0.869358875252255
F1-micro tok:  0.9694137638062872
**************************************************
dev_cost_sum: 96007.62760925293
dev_cost_avg: 29.540808495154746
dev_count_sent: 3250.0
dev_total_correct_sent: 3132.0
dev_accuracy_sent: 0.9636923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50394.0
dev_accuracy_tok: 0.9811533818776528
dev_label=0_precision_sent: 0.9298531810766721
dev_label=0_recall_sent: 0.8837209302325582
dev_label=0_f-score_sent: 0.9062003179650239
dev_label=1_precision_sent: 0.9715585893060296
dev_label=1_recall_sent: 0.9834932821497121
dev_label=1_f-score_sent: 0.9774895078214422
dev_precision_macro_sent: 0.9507058851913508
dev_recall_macro_sent: 0.9336071061911351
dev_f-score_macro_sent: 0.941844912893233
dev_precision_micro_sent: 0.9636923076923077
dev_recall_micro_sent: 0.9636923076923077
dev_f-score_micro_sent: 0.9636923076923077
dev_label=O_precision_tok: 0.9922227914124715
dev_label=O_recall_tok: 0.9965621272714517
dev_label=O_f-score_tok: 0.9943877253369116
dev_label=LOC_precision_tok: 0.9262957679505468
dev_label=LOC_recall_tok: 0.9302769818529131
dev_label=LOC_f-score_tok: 0.9282821062663807
dev_label=MISC_precision_tok: 0.9039704524469068
dev_label=MISC_recall_tok: 0.7720820189274448
dev_label=MISC_f-score_tok: 0.8328370905997449
dev_label=ORG_precision_tok: 0.8853439680957128
dev_label=ORG_recall_tok: 0.8489483747609943
dev_label=ORG_f-score_tok: 0.8667642752562226
dev_label=PER_precision_tok: 0.9550248138957816
dev_label=PER_recall_tok: 0.9777707208637663
dev_label=PER_f-score_tok: 0.9662639259375491
dev_precision_macro_tok: 0.9325715587602839
dev_recall_macro_tok: 0.9051280447353139
dev_f-score_macro_tok: 0.9177070246793617
dev_precision_micro_tok: 0.9811533818776528
dev_recall_micro_tok: 0.9811533818776528
dev_f-score_micro_tok: 0.9811533818776528
dev_time: 6.920210123062134
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9299    0.8837    0.9062       645
           1     0.9716    0.9835    0.9775      2605

   micro avg     0.9637    0.9637    0.9637      3250
   macro avg     0.9507    0.9336    0.9418      3250
weighted avg     0.9633    0.9637    0.9633      3250

F1-macro sent:  0.941844912893233
F1-micro sent:  0.9636923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9922    0.9966    0.9944     42759
         LOC     0.9263    0.9303    0.9283      2094
        MISC     0.9040    0.7721    0.8328      1268
         ORG     0.8853    0.8489    0.8668      2092
         PER     0.9550    0.9778    0.9663      3149

   micro avg     0.9812    0.9812    0.9812     51362
   macro avg     0.9326    0.9051    0.9177     51362
weighted avg     0.9807    0.9812    0.9808     51362

F1-macro tok:  0.9177070246793617
F1-micro tok:  0.9811533818776528
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361261.69873046875
train_cost_avg: 25.72905766900283
train_count_sent: 14041.0
train_total_correct_sent: 13147.0
train_accuracy_sent: 0.9363293212734136
train_count_tok: 203621.0
train_total_correct_tok: 198140.0
train_accuracy_tok: 0.9730823441590013
train_label=0_precision_sent: 0.856637168141593
train_label=0_recall_sent: 0.8319009969061533
train_label=0_f-score_sent: 0.8440878967561911
train_label=1_precision_sent: 0.9564015691868759
train_label=1_recall_sent: 0.9636183974128638
train_label=1_f-score_sent: 0.9599964202613209
train_precision_macro_sent: 0.9065193686642344
train_recall_macro_sent: 0.8977596971595085
train_f-score_macro_sent: 0.902042158508756
train_precision_micro_sent: 0.9363293212734136
train_recall_micro_sent: 0.9363293212734136
train_f-score_micro_sent: 0.9363293212734136
train_label=O_precision_tok: 0.9913135020054813
train_label=O_recall_tok: 0.9939791718265341
train_label=O_f-score_tok: 0.9926445473069267
train_label=LOC_precision_tok: 0.8853679030128436
train_label=LOC_recall_tok: 0.8889960226587923
train_label=LOC_f-score_tok: 0.8871782535482319
train_label=MISC_precision_tok: 0.8111938505885179
train_label=MISC_recall_tok: 0.7352492924014805
train_label=MISC_f-score_tok: 0.7713567839195978
train_label=ORG_precision_tok: 0.8448011450771905
train_label=ORG_recall_tok: 0.8242394014962594
train_label=ORG_f-score_tok: 0.8343936180955266
train_label=PER_precision_tok: 0.9341407355021216
train_label=PER_recall_tok: 0.9495866283249461
train_label=PER_f-score_tok: 0.9418003565062388
train_precision_macro_tok: 0.893363427237231
train_recall_macro_tok: 0.8784101033416025
train_f-score_macro_tok: 0.8854747118753045
train_precision_micro_tok: 0.9730823441590013
train_recall_micro_tok: 0.9730823441590013
train_f-score_micro_tok: 0.9730823441590013
train_time: 101.23191571235657
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8566    0.8319    0.8441      2909
           1     0.9564    0.9636    0.9600     11132

   micro avg     0.9363    0.9363    0.9363     14041
   macro avg     0.9065    0.8978    0.9020     14041
weighted avg     0.9357    0.9363    0.9360     14041

F1-macro sent:  0.902042158508756
F1-micro sent:  0.9363293212734136
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9913    0.9940    0.9926    169578
         LOC     0.8854    0.8890    0.8872      8297
        MISC     0.8112    0.7352    0.7714      4593
         ORG     0.8448    0.8242    0.8344     10025
         PER     0.9341    0.9496    0.9418     11128

   micro avg     0.9731    0.9731    0.9731    203621
   macro avg     0.8934    0.8784    0.8855    203621
weighted avg     0.9726    0.9731    0.9728    203621

F1-macro tok:  0.8854747118753045
F1-micro tok:  0.9730823441590013
**************************************************
dev_cost_sum: 94253.85007476807
dev_cost_avg: 29.001184638390175
dev_count_sent: 3250.0
dev_total_correct_sent: 3138.0
dev_accuracy_sent: 0.9655384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50461.0
dev_accuracy_tok: 0.9824578482146333
dev_label=0_precision_sent: 0.9494097807757167
dev_label=0_recall_sent: 0.8728682170542635
dev_label=0_f-score_sent: 0.9095315024232633
dev_label=1_precision_sent: 0.9691381257056831
dev_label=1_recall_sent: 0.9884836852207294
dev_label=1_f-score_sent: 0.9787153173698214
dev_precision_macro_sent: 0.9592739532407
dev_recall_macro_sent: 0.9306759511374965
dev_f-score_macro_sent: 0.9441234098965423
dev_precision_micro_sent: 0.9655384615384616
dev_recall_micro_sent: 0.9655384615384616
dev_f-score_micro_sent: 0.9655384615384616
dev_label=O_precision_tok: 0.992827868852459
dev_label=O_recall_tok: 0.9971234126148881
dev_label=O_f-score_tok: 0.9949710045155945
dev_label=LOC_precision_tok: 0.925
dev_label=LOC_recall_tok: 0.9364851957975168
dev_label=LOC_f-score_tok: 0.9307071665875652
dev_label=MISC_precision_tok: 0.9114963503649635
dev_label=MISC_recall_tok: 0.7878548895899053
dev_label=MISC_f-score_tok: 0.8451776649746191
dev_label=ORG_precision_tok: 0.8976023976023976
dev_label=ORG_recall_tok: 0.8589866156787763
dev_label=ORG_f-score_tok: 0.8778700537371764
dev_label=PER_precision_tok: 0.95875
dev_label=PER_recall_tok: 0.9742775484280723
dev_label=PER_f-score_tok: 0.9664514096708142
dev_precision_macro_tok: 0.937135323363964
dev_recall_macro_tok: 0.9109455324218318
dev_f-score_macro_tok: 0.9230354598971537
dev_precision_micro_tok: 0.9824578482146333
dev_recall_micro_tok: 0.9824578482146333
dev_f-score_micro_tok: 0.9824578482146333
dev_time: 14.805195569992065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9494    0.8729    0.9095       645
           1     0.9691    0.9885    0.9787      2605

   micro avg     0.9655    0.9655    0.9655      3250
   macro avg     0.9593    0.9307    0.9441      3250
weighted avg     0.9652    0.9655    0.9650      3250

F1-macro sent:  0.9441234098965423
F1-micro sent:  0.9655384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9928    0.9971    0.9950     42759
         LOC     0.9250    0.9365    0.9307      2094
        MISC     0.9115    0.7879    0.8452      1268
         ORG     0.8976    0.8590    0.8779      2092
         PER     0.9587    0.9743    0.9665      3149

   micro avg     0.9825    0.9825    0.9825     51362
   macro avg     0.9371    0.9109    0.9230     51362
weighted avg     0.9821    0.9825    0.9821     51362

F1-macro tok:  0.9230354598971537
F1-micro tok:  0.9824578482146333
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 354001.3809814453
train_cost_avg: 25.21197784925898
train_count_sent: 14041.0
train_total_correct_sent: 13297.0
train_accuracy_sent: 0.9470123210597535
train_count_tok: 203621.0
train_total_correct_tok: 198787.0
train_accuracy_tok: 0.9762598160307631
train_label=0_precision_sent: 0.8812962310672772
train_label=0_recall_sent: 0.860089377793056
train_label=0_f-score_sent: 0.8705636743215031
train_label=1_precision_sent: 0.9636672022853062
train_label=1_recall_sent: 0.9697269134028027
train_label=1_f-score_sent: 0.9666875615653264
train_precision_macro_sent: 0.9224817166762918
train_recall_macro_sent: 0.9149081455979293
train_f-score_macro_sent: 0.9186256179434147
train_precision_micro_sent: 0.9470123210597535
train_recall_micro_sent: 0.9470123210597535
train_f-score_micro_sent: 0.9470123210597535
train_label=O_precision_tok: 0.9924382407287535
train_label=O_recall_tok: 0.994521695031195
train_label=O_f-score_tok: 0.9934788755625722
train_label=LOC_precision_tok: 0.901863504356244
train_label=LOC_recall_tok: 0.8982764854766783
train_label=LOC_f-score_tok: 0.9000664211098364
train_label=MISC_precision_tok: 0.8234187632259582
train_label=MISC_recall_tok: 0.7624646200740257
train_label=MISC_f-score_tok: 0.7917702916572463
train_label=ORG_precision_tok: 0.8620445344129555
train_label=ORG_recall_tok: 0.8495760598503741
train_label=ORG_f-score_tok: 0.8557648831951771
train_label=PER_precision_tok: 0.9447298494242693
train_label=PER_recall_tok: 0.9584831056793673
train_label=PER_f-score_tok: 0.9515567847265591
train_precision_macro_tok: 0.9048989784296362
train_recall_macro_tok: 0.8926643932223282
train_f-score_macro_tok: 0.8985274512502782
train_precision_micro_tok: 0.9762598160307631
train_recall_micro_tok: 0.9762598160307631
train_f-score_micro_tok: 0.9762598160307631
train_time: 157.29439330101013
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8813    0.8601    0.8706      2909
           1     0.9637    0.9697    0.9667     11132

   micro avg     0.9470    0.9470    0.9470     14041
   macro avg     0.9225    0.9149    0.9186     14041
weighted avg     0.9466    0.9470    0.9468     14041

F1-macro sent:  0.9186256179434147
F1-micro sent:  0.9470123210597535
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9924    0.9945    0.9935    169578
         LOC     0.9019    0.8983    0.9001      8297
        MISC     0.8234    0.7625    0.7918      4593
         ORG     0.8620    0.8496    0.8558     10025
         PER     0.9447    0.9585    0.9516     11128

   micro avg     0.9763    0.9763    0.9763    203621
   macro avg     0.9049    0.8927    0.8985    203621
weighted avg     0.9759    0.9763    0.9761    203621

F1-macro tok:  0.8985274512502782
F1-micro tok:  0.9762598160307631
**************************************************
dev_cost_sum: 92916.75827789307
dev_cost_avg: 28.58977177781325
dev_count_sent: 3250.0
dev_total_correct_sent: 3123.0
dev_accuracy_sent: 0.9609230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50504.0
dev_accuracy_tok: 0.9832950430279195
dev_label=0_precision_sent: 0.861731843575419
dev_label=0_recall_sent: 0.9565891472868217
dev_label=0_f-score_sent: 0.9066862601028656
dev_label=1_precision_sent: 0.988950276243094
dev_label=1_recall_sent: 0.9619961612284069
dev_label=1_f-score_sent: 0.9752870208211715
dev_precision_macro_sent: 0.9253410599092564
dev_recall_macro_sent: 0.9592926542576143
dev_f-score_macro_sent: 0.9409866404620185
dev_precision_micro_sent: 0.9609230769230769
dev_recall_micro_sent: 0.9609230769230769
dev_f-score_micro_sent: 0.9609230769230769
dev_label=O_precision_tok: 0.9937520399123421
dev_label=O_recall_tok: 0.9968895437217896
dev_label=O_f-score_tok: 0.9953183192649411
dev_label=LOC_precision_tok: 0.9566929133858267
dev_label=LOC_recall_tok: 0.9283667621776505
dev_label=LOC_f-score_tok: 0.9423170140571983
dev_label=MISC_precision_tok: 0.8459752321981424
dev_label=MISC_recall_tok: 0.86198738170347
dev_label=MISC_f-score_tok: 0.85390625
dev_label=ORG_precision_tok: 0.9276980329611909
dev_label=ORG_recall_tok: 0.8341300191204589
dev_label=ORG_f-score_tok: 0.8784293984394664
dev_label=PER_precision_tok: 0.9488201041985903
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9656893325015596
dev_precision_macro_tok: 0.9345876645312184
dev_recall_macro_tok: 0.920908593361187
dev_f-score_macro_tok: 0.927132062852633
dev_precision_micro_tok: 0.9832950430279195
dev_recall_micro_tok: 0.9832950430279195
dev_f-score_micro_tok: 0.9832950430279195
dev_time: 14.85185980796814
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8617    0.9566    0.9067       645
           1     0.9890    0.9620    0.9753      2605

   micro avg     0.9609    0.9609    0.9609      3250
   macro avg     0.9253    0.9593    0.9410      3250
weighted avg     0.9637    0.9609    0.9617      3250

F1-macro sent:  0.9409866404620185
F1-micro sent:  0.9609230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9938    0.9969    0.9953     42759
         LOC     0.9567    0.9284    0.9423      2094
        MISC     0.8460    0.8620    0.8539      1268
         ORG     0.9277    0.8341    0.8784      2092
         PER     0.9488    0.9832    0.9657      3149

   micro avg     0.9833    0.9833    0.9833     51362
   macro avg     0.9346    0.9209    0.9271     51362
weighted avg     0.9831    0.9833    0.9831     51362

F1-macro tok:  0.927132062852633
F1-micro tok:  0.9832950430279195
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 347816.4375305176
train_cost_avg: 24.77148618549374
train_count_sent: 14041.0
train_total_correct_sent: 13383.0
train_accuracy_sent: 0.9531372409372552
train_count_tok: 203621.0
train_total_correct_tok: 199296.0
train_accuracy_tok: 0.9787595581988106
train_label=0_precision_sent: 0.8925706313219393
train_label=0_recall_sent: 0.8796837401168787
train_label=0_f-score_sent: 0.8860803324099723
train_label=1_precision_sent: 0.9686772865580813
train_label=1_recall_sent: 0.9723320158102767
train_label=1_f-score_sent: 0.9705012104366538
train_precision_macro_sent: 0.9306239589400103
train_recall_macro_sent: 0.9260078779635776
train_f-score_macro_sent: 0.9282907714233131
train_precision_micro_sent: 0.9531372409372552
train_recall_micro_sent: 0.9531372409372552
train_f-score_micro_sent: 0.9531372409372552
train_label=O_precision_tok: 0.9932703743391071
train_label=O_recall_tok: 0.9948401325643657
train_label=O_f-score_tok: 0.9940546337324409
train_label=LOC_precision_tok: 0.9105720492396814
train_label=LOC_recall_tok: 0.9093648306616849
train_label=LOC_f-score_tok: 0.9099680395585841
train_label=MISC_precision_tok: 0.8514989542179875
train_label=MISC_recall_tok: 0.7977356847376442
train_label=MISC_f-score_tok: 0.8237410071942445
train_label=ORG_precision_tok: 0.8748738647830474
train_label=ORG_recall_tok: 0.8648379052369077
train_label=ORG_f-score_tok: 0.8698269375470278
train_label=PER_precision_tok: 0.9501596310748492
train_label=PER_recall_tok: 0.9627965492451473
train_label=PER_f-score_tok: 0.9564363506516693
train_precision_macro_tok: 0.9160749747309346
train_recall_macro_tok: 0.90591502048915
train_f-score_macro_tok: 0.9108053937367933
train_precision_micro_tok: 0.9787595581988106
train_recall_micro_tok: 0.9787595581988106
train_f-score_micro_tok: 0.9787595581988106
train_time: 157.47753071784973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8926    0.8797    0.8861      2909
           1     0.9687    0.9723    0.9705     11132

   micro avg     0.9531    0.9531    0.9531     14041
   macro avg     0.9306    0.9260    0.9283     14041
weighted avg     0.9529    0.9531    0.9530     14041

F1-macro sent:  0.9282907714233131
F1-micro sent:  0.9531372409372552
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9933    0.9948    0.9941    169578
         LOC     0.9106    0.9094    0.9100      8297
        MISC     0.8515    0.7977    0.8237      4593
         ORG     0.8749    0.8648    0.8698     10025
         PER     0.9502    0.9628    0.9564     11128

   micro avg     0.9788    0.9788    0.9788    203621
   macro avg     0.9161    0.9059    0.9108    203621
weighted avg     0.9785    0.9788    0.9786    203621

F1-macro tok:  0.9108053937367933
F1-micro tok:  0.9787595581988106
**************************************************
dev_cost_sum: 91489.56288909912
dev_cost_avg: 28.15063473510742
dev_count_sent: 3250.0
dev_total_correct_sent: 3165.0
dev_accuracy_sent: 0.9738461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50564.0
dev_accuracy_tok: 0.9844632218371558
dev_label=0_precision_sent: 0.9472843450479234
dev_label=0_recall_sent: 0.9193798449612403
dev_label=0_f-score_sent: 0.9331235247836349
dev_label=1_precision_sent: 0.9801829268292683
dev_label=1_recall_sent: 0.9873320537428023
dev_label=1_f-score_sent: 0.983744501816791
dev_precision_macro_sent: 0.9637336359385958
dev_recall_macro_sent: 0.9533559493520213
dev_f-score_macro_sent: 0.9584340133002129
dev_precision_micro_sent: 0.9738461538461538
dev_recall_micro_sent: 0.9738461538461538
dev_f-score_micro_sent: 0.9738461538461538
dev_label=O_precision_tok: 0.9937310650198089
dev_label=O_recall_tok: 0.9972403470614374
dev_label=O_f-score_tok: 0.9954826133140342
dev_label=LOC_precision_tok: 0.9328638497652583
dev_label=LOC_recall_tok: 0.9489016236867239
dev_label=LOC_f-score_tok: 0.9408143939393939
dev_label=MISC_precision_tok: 0.9224526600541028
dev_label=MISC_recall_tok: 0.806782334384858
dev_label=MISC_f-score_tok: 0.8607488430795119
dev_label=ORG_precision_tok: 0.9140271493212669
dev_label=ORG_recall_tok: 0.8690248565965584
dev_label=ORG_f-score_tok: 0.8909580985052682
dev_label=PER_precision_tok: 0.9599875930521092
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9712851090538209
dev_precision_macro_tok: 0.9446124634425092
dev_recall_macro_tok: 0.9209601721363253
dev_f-score_macro_tok: 0.9318578115784059
dev_precision_micro_tok: 0.9844632218371558
dev_recall_micro_tok: 0.9844632218371558
dev_f-score_micro_tok: 0.9844632218371558
dev_time: 14.714787244796753
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9473    0.9194    0.9331       645
           1     0.9802    0.9873    0.9837      2605

   micro avg     0.9738    0.9738    0.9738      3250
   macro avg     0.9637    0.9534    0.9584      3250
weighted avg     0.9737    0.9738    0.9737      3250

F1-macro sent:  0.9584340133002129
F1-micro sent:  0.9738461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9937    0.9972    0.9955     42759
         LOC     0.9329    0.9489    0.9408      2094
        MISC     0.9225    0.8068    0.8607      1268
         ORG     0.9140    0.8690    0.8910      2092
         PER     0.9600    0.9829    0.9713      3149

   micro avg     0.9845    0.9845    0.9845     51362
   macro avg     0.9446    0.9210    0.9319     51362
weighted avg     0.9842    0.9845    0.9842     51362

F1-macro tok:  0.9318578115784059
F1-micro tok:  0.9844632218371558
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 342143.4673156738
train_cost_avg: 24.367457254873145
train_count_sent: 14041.0
train_total_correct_sent: 13501.0
train_accuracy_sent: 0.9615412007691759
train_count_tok: 203621.0
train_total_correct_tok: 199697.0
train_accuracy_tok: 0.9807289032074294
train_label=0_precision_sent: 0.9111419645956265
train_label=0_recall_sent: 0.9023719491234101
train_label=0_f-score_sent: 0.9067357512953368
train_label=1_precision_sent: 0.9745519713261649
train_label=1_recall_sent: 0.9770032339202299
train_label=1_f-score_sent: 0.9757760631616723
train_precision_macro_sent: 0.9428469679608957
train_recall_macro_sent: 0.93968759152182
train_f-score_macro_sent: 0.9412559072285045
train_precision_micro_sent: 0.9615412007691759
train_recall_micro_sent: 0.9615412007691759
train_f-score_micro_sent: 0.9615412007691759
train_label=O_precision_tok: 0.9938252710641253
train_label=O_recall_tok: 0.9956303294059371
train_label=O_f-score_tok: 0.994726981358848
train_label=LOC_precision_tok: 0.9159947045372487
train_label=LOC_recall_tok: 0.9173195130770158
train_label=LOC_f-score_tok: 0.9166566301336866
train_label=MISC_precision_tok: 0.8639908256880734
train_label=MISC_recall_tok: 0.8201611147398215
train_label=MISC_f-score_tok: 0.8415056405674075
train_label=ORG_precision_tok: 0.8861285743256946
train_label=ORG_recall_tok: 0.871720698254364
train_label=ORG_f-score_tok: 0.8788655905868155
train_label=PER_precision_tok: 0.958853980721171
train_label=PER_recall_tok: 0.9654025880661394
train_label=PER_f-score_tok: 0.96211714132187
train_precision_macro_tok: 0.9237586712672627
train_recall_macro_tok: 0.9140468487086555
train_f-score_macro_tok: 0.9187743967937255
train_precision_micro_tok: 0.9807289032074294
train_recall_micro_tok: 0.9807289032074294
train_f-score_micro_tok: 0.9807289032074294
train_time: 207.16014790534973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9111    0.9024    0.9067      2909
           1     0.9746    0.9770    0.9758     11132

   micro avg     0.9615    0.9615    0.9615     14041
   macro avg     0.9428    0.9397    0.9413     14041
weighted avg     0.9614    0.9615    0.9615     14041

F1-macro sent:  0.9412559072285045
F1-micro sent:  0.9615412007691759
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9938    0.9956    0.9947    169578
         LOC     0.9160    0.9173    0.9167      8297
        MISC     0.8640    0.8202    0.8415      4593
         ORG     0.8861    0.8717    0.8789     10025
         PER     0.9589    0.9654    0.9621     11128

   micro avg     0.9807    0.9807    0.9807    203621
   macro avg     0.9238    0.9140    0.9188    203621
weighted avg     0.9805    0.9807    0.9806    203621

F1-macro tok:  0.9187743967937255
F1-micro tok:  0.9807289032074294
**************************************************
dev_cost_sum: 90455.47563934326
dev_cost_avg: 27.83245404287485
dev_count_sent: 3250.0
dev_total_correct_sent: 3137.0
dev_accuracy_sent: 0.9652307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50638.0
dev_accuracy_tok: 0.9859039757018808
dev_label=0_precision_sent: 0.8746478873239436
dev_label=0_recall_sent: 0.9627906976744186
dev_label=0_f-score_sent: 0.9166051660516604
dev_label=1_precision_sent: 0.9905511811023622
dev_label=1_recall_sent: 0.9658349328214971
dev_label=1_f-score_sent: 0.9780369290573372
dev_precision_macro_sent: 0.9325995342131529
dev_recall_macro_sent: 0.9643128152479579
dev_f-score_macro_sent: 0.9473210475544989
dev_precision_micro_sent: 0.9652307692307692
dev_recall_micro_sent: 0.9652307692307692
dev_f-score_micro_sent: 0.9652307692307692
dev_label=O_precision_tok: 0.9944036376355369
dev_label=O_recall_tok: 0.9973338946186767
dev_label=O_f-score_tok: 0.9958666106207089
dev_label=LOC_precision_tok: 0.9526798647996138
dev_label=LOC_recall_tok: 0.9422158548233047
dev_label=LOC_f-score_tok: 0.9474189675870348
dev_label=MISC_precision_tok: 0.9056122448979592
dev_label=MISC_recall_tok: 0.8399053627760252
dev_label=MISC_f-score_tok: 0.8715220949263502
dev_label=ORG_precision_tok: 0.9093553078041687
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.9030084235860409
dev_label=PER_precision_tok: 0.9722134512156615
dev_label=PER_recall_tok: 0.9777707208637663
dev_label=PER_f-score_tok: 0.9749841671944268
dev_precision_macro_tok: 0.946852901270588
dev_recall_macro_tok: 0.93079507101406
dev_f-score_macro_tok: 0.9385600527829123
dev_precision_micro_tok: 0.9859039757018808
dev_recall_micro_tok: 0.9859039757018808
dev_f-score_micro_tok: 0.9859039757018808
dev_time: 24.124999284744263
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8746    0.9628    0.9166       645
           1     0.9906    0.9658    0.9780      2605

   micro avg     0.9652    0.9652    0.9652      3250
   macro avg     0.9326    0.9643    0.9473      3250
weighted avg     0.9675    0.9652    0.9658      3250

F1-macro sent:  0.9473210475544989
F1-micro sent:  0.9652307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9944    0.9973    0.9959     42759
         LOC     0.9527    0.9422    0.9474      2094
        MISC     0.9056    0.8399    0.8715      1268
         ORG     0.9094    0.8967    0.9030      2092
         PER     0.9722    0.9778    0.9750      3149

   micro avg     0.9859    0.9859    0.9859     51362
   macro avg     0.9469    0.9308    0.9386     51362
weighted avg     0.9857    0.9859    0.9858     51362

F1-macro tok:  0.9385600527829123
F1-micro tok:  0.9859039757018808
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 337347.54278564453
train_cost_avg: 24.025891516675774
train_count_sent: 14041.0
train_total_correct_sent: 13525.0
train_accuracy_sent: 0.9632504807349904
train_count_tok: 203621.0
train_total_correct_tok: 199968.0
train_accuracy_tok: 0.9820598071908104
train_label=0_precision_sent: 0.9110271384403985
train_label=0_recall_sent: 0.9116534891715367
train_label=0_f-score_sent: 0.911340206185567
train_label=1_precision_sent: 0.9769092542677449
train_label=1_recall_sent: 0.9767337405677327
train_label=1_f-score_sent: 0.9768214895337347
train_precision_macro_sent: 0.9439681963540717
train_recall_macro_sent: 0.9441936148696346
train_f-score_macro_sent: 0.9440808478596509
train_precision_micro_sent: 0.9632504807349904
train_recall_micro_sent: 0.9632504807349904
train_f-score_micro_sent: 0.9632504807349904
train_label=O_precision_tok: 0.9944512511191744
train_label=O_recall_tok: 0.995565462501032
train_label=O_f-score_tok: 0.9950080448863402
train_label=LOC_precision_tok: 0.9249397590361446
train_label=LOC_recall_tok: 0.9252741954923467
train_label=LOC_f-score_tok: 0.9251069470386214
train_label=MISC_precision_tok: 0.8589108910891089
train_label=MISC_recall_tok: 0.8310472458088395
train_label=MISC_f-score_tok: 0.8447493637269005
train_label=ORG_precision_tok: 0.8966596023816732
train_label=ORG_recall_tok: 0.886284289276808
train_label=ORG_f-score_tok: 0.8914417578007424
train_label=PER_precision_tok: 0.9609821428571429
train_label=PER_recall_tok: 0.9671998562185478
train_label=PER_f-score_tok: 0.9640809745610892
train_precision_macro_tok: 0.9271887292966488
train_recall_macro_tok: 0.9210742098595148
train_f-score_macro_tok: 0.9240774176027386
train_precision_micro_tok: 0.9820598071908104
train_recall_micro_tok: 0.9820598071908104
train_f-score_micro_tok: 0.9820598071908104
train_time: 284.5441677570343
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9110    0.9117    0.9113      2909
           1     0.9769    0.9767    0.9768     11132

   micro avg     0.9633    0.9633    0.9633     14041
   macro avg     0.9440    0.9442    0.9441     14041
weighted avg     0.9633    0.9633    0.9633     14041

F1-macro sent:  0.9440808478596509
F1-micro sent:  0.9632504807349904
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9956    0.9950    169578
         LOC     0.9249    0.9253    0.9251      8297
        MISC     0.8589    0.8310    0.8447      4593
         ORG     0.8967    0.8863    0.8914     10025
         PER     0.9610    0.9672    0.9641     11128

   micro avg     0.9821    0.9821    0.9821    203621
   macro avg     0.9272    0.9211    0.9241    203621
weighted avg     0.9819    0.9821    0.9820    203621

F1-macro tok:  0.9240774176027386
F1-micro tok:  0.9820598071908104
**************************************************
dev_cost_sum: 89439.67401123047
dev_cost_avg: 27.519899695763222
dev_count_sent: 3250.0
dev_total_correct_sent: 3160.0
dev_accuracy_sent: 0.9723076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50669.0
dev_accuracy_tok: 0.9865075347533195
dev_label=0_precision_sent: 0.9894179894179894
dev_label=0_recall_sent: 0.8697674418604651
dev_label=0_f-score_sent: 0.9257425742574258
dev_label=1_precision_sent: 0.9686917629519195
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.982980332829047
dev_precision_macro_sent: 0.9790548761849545
dev_recall_macro_sent: 0.9337320894523055
dev_f-score_macro_sent: 0.9543614535432363
dev_precision_micro_sent: 0.9723076923076923
dev_recall_micro_sent: 0.9723076923076923
dev_f-score_micro_sent: 0.9723076923076923
dev_label=O_precision_tok: 0.9957939994391999
dev_label=O_recall_tok: 0.996655674828691
dev_label=O_f-score_tok: 0.9962246508094208
dev_label=LOC_precision_tok: 0.9551158301158301
dev_label=LOC_recall_tok: 0.9450811843361987
dev_label=LOC_f-score_tok: 0.9500720115218435
dev_label=MISC_precision_tok: 0.9018302828618968
dev_label=MISC_recall_tok: 0.8548895899053628
dev_label=MISC_f-score_tok: 0.8777327935222672
dev_label=ORG_precision_tok: 0.9137349397590362
dev_label=ORG_recall_tok: 0.9063097514340345
dev_label=ORG_f-score_tok: 0.9100071994240462
dev_label=PER_precision_tok: 0.9617656201429904
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9720389569588439
dev_precision_macro_tok: 0.9456481344637906
dev_recall_macro_tok: 0.9370940676651636
dev_f-score_macro_tok: 0.9412151224472843
dev_precision_micro_tok: 0.9865075347533195
dev_recall_micro_tok: 0.9865075347533195
dev_f-score_micro_tok: 0.9865075347533195
dev_time: 34.6091046333313
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9894    0.8698    0.9257       645
           1     0.9687    0.9977    0.9830      2605

   micro avg     0.9723    0.9723    0.9723      3250
   macro avg     0.9791    0.9337    0.9544      3250
weighted avg     0.9728    0.9723    0.9716      3250

F1-macro sent:  0.9543614535432363
F1-micro sent:  0.9723076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9967    0.9962     42759
         LOC     0.9551    0.9451    0.9501      2094
        MISC     0.9018    0.8549    0.8777      1268
         ORG     0.9137    0.9063    0.9100      2092
         PER     0.9618    0.9825    0.9720      3149

   micro avg     0.9865    0.9865    0.9865     51362
   macro avg     0.9456    0.9371    0.9412     51362
weighted avg     0.9864    0.9865    0.9864     51362

F1-macro tok:  0.9412151224472843
F1-micro tok:  0.9865075347533195
**************************************************
Best epoch: 5
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 333231.2903137207
train_cost_avg: 23.732732021488548
train_count_sent: 14041.0
train_total_correct_sent: 13586.0
train_accuracy_sent: 0.9675949006481019
train_count_tok: 203621.0
train_total_correct_tok: 200258.0
train_accuracy_tok: 0.9834840217855723
train_label=0_precision_sent: 0.9225206611570248
train_label=0_recall_sent: 0.9209350292196631
train_label=0_f-score_sent: 0.9217271632547738
train_label=1_precision_sent: 0.9793481188830025
train_label=1_recall_sent: 0.9797879985627022
train_label=1_f-score_sent: 0.9795680093403386
train_precision_macro_sent: 0.9509343900200137
train_recall_macro_sent: 0.9503615138911826
train_f-score_macro_sent: 0.9506475862975562
train_precision_micro_sent: 0.9675949006481019
train_recall_micro_sent: 0.9675949006481019
train_f-score_micro_sent: 0.9675949006481019
train_label=O_precision_tok: 0.9946643109540636
train_label=O_recall_tok: 0.9959664579131727
train_label=O_f-score_tok: 0.9953149585418029
train_label=LOC_precision_tok: 0.9327294685990338
train_label=LOC_recall_tok: 0.93081836808485
train_label=LOC_f-score_tok: 0.9317729384086385
train_label=MISC_precision_tok: 0.8737601442741209
train_label=MISC_recall_tok: 0.8438928804702809
train_label=MISC_f-score_tok: 0.858566840181637
train_label=ORG_precision_tok: 0.9050748079255965
train_label=ORG_recall_tok: 0.893067331670823
train_label=ORG_f-score_tok: 0.8990309785610283
train_label=PER_precision_tok: 0.9642379381075538
train_label=PER_recall_tok: 0.9716031631919483
train_label=PER_f-score_tok: 0.9679065395461259
train_precision_macro_tok: 0.9340933339720738
train_recall_macro_tok: 0.927069640266215
train_f-score_macro_tok: 0.9305184510478466
train_precision_micro_tok: 0.9834840217855723
train_recall_micro_tok: 0.9834840217855723
train_f-score_micro_tok: 0.9834840217855723
train_time: 325.2732002735138
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9225    0.9209    0.9217      2909
           1     0.9793    0.9798    0.9796     11132

   micro avg     0.9676    0.9676    0.9676     14041
   macro avg     0.9509    0.9504    0.9506     14041
weighted avg     0.9676    0.9676    0.9676     14041

F1-macro sent:  0.9506475862975562
F1-micro sent:  0.9675949006481019
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9960    0.9953    169578
         LOC     0.9327    0.9308    0.9318      8297
        MISC     0.8738    0.8439    0.8586      4593
         ORG     0.9051    0.8931    0.8990     10025
         PER     0.9642    0.9716    0.9679     11128

   micro avg     0.9835    0.9835    0.9835    203621
   macro avg     0.9341    0.9271    0.9305    203621
weighted avg     0.9833    0.9835    0.9834    203621

F1-macro tok:  0.9305184510478466
F1-micro tok:  0.9834840217855723
**************************************************
dev_cost_sum: 88703.80833435059
dev_cost_avg: 27.293479487492487
dev_count_sent: 3250.0
dev_total_correct_sent: 3183.0
dev_accuracy_sent: 0.9793846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50667.0
dev_accuracy_tok: 0.9864685954596784
dev_label=0_precision_sent: 0.9352409638554217
dev_label=0_recall_sent: 0.9627906976744186
dev_label=0_f-score_sent: 0.9488158899923606
dev_label=1_precision_sent: 0.9907192575406032
dev_label=1_recall_sent: 0.9834932821497121
dev_label=1_f-score_sent: 0.9870930456559429
dev_precision_macro_sent: 0.9629801106980125
dev_recall_macro_sent: 0.9731419899120654
dev_f-score_macro_sent: 0.9679544678241517
dev_precision_micro_sent: 0.9793846153846154
dev_recall_micro_sent: 0.9793846153846154
dev_f-score_micro_sent: 0.9793846153846154
dev_label=O_precision_tok: 0.9945920745920745
dev_label=O_recall_tok: 0.9978717930728034
dev_label=O_f-score_tok: 0.9962292345229339
dev_label=LOC_precision_tok: 0.9530137636449929
dev_label=LOC_recall_tok: 0.958930276981853
dev_label=LOC_f-score_tok: 0.9559628659842895
dev_label=MISC_precision_tok: 0.858359133126935
dev_label=MISC_recall_tok: 0.8746056782334385
dev_label=MISC_f-score_tok: 0.86640625
dev_label=ORG_precision_tok: 0.9447340980187695
dev_label=ORG_recall_tok: 0.8661567877629063
dev_label=ORG_f-score_tok: 0.9037406483790524
dev_label=PER_precision_tok: 0.9761526232114467
dev_label=PER_recall_tok: 0.9749126706891077
dev_label=PER_f-score_tok: 0.9755322529393072
dev_precision_macro_tok: 0.9453703385188437
dev_recall_macro_tok: 0.9344954413480219
dev_f-score_macro_tok: 0.9395742503651165
dev_precision_micro_tok: 0.9864685954596784
dev_recall_micro_tok: 0.9864685954596784
dev_f-score_micro_tok: 0.9864685954596784
dev_time: 34.60694479942322
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9352    0.9628    0.9488       645
           1     0.9907    0.9835    0.9871      2605

   micro avg     0.9794    0.9794    0.9794      3250
   macro avg     0.9630    0.9731    0.9680      3250
weighted avg     0.9797    0.9794    0.9795      3250

F1-macro sent:  0.9679544678241517
F1-micro sent:  0.9793846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9979    0.9962     42759
         LOC     0.9530    0.9589    0.9560      2094
        MISC     0.8584    0.8746    0.8664      1268
         ORG     0.9447    0.8662    0.9037      2092
         PER     0.9762    0.9749    0.9755      3149

   micro avg     0.9865    0.9865    0.9865     51362
   macro avg     0.9454    0.9345    0.9396     51362
weighted avg     0.9864    0.9865    0.9863     51362

F1-macro tok:  0.9395742503651165
F1-micro tok:  0.9864685954596784
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 329471.98529052734
train_cost_avg: 23.46499432309147
train_count_sent: 14041.0
train_total_correct_sent: 13649.0
train_accuracy_sent: 0.9720817605583648
train_count_tok: 203621.0
train_total_correct_tok: 200484.0
train_accuracy_tok: 0.9845939269525246
train_label=0_precision_sent: 0.9359196397644614
train_label=0_recall_sent: 0.9288415262976968
train_label=0_f-score_sent: 0.932367149758454
train_label=1_precision_sent: 0.9814416352877892
train_label=1_recall_sent: 0.9833812432626662
train_label=1_f-score_sent: 0.9824104819168985
train_precision_macro_sent: 0.9586806375261252
train_recall_macro_sent: 0.9561113847801814
train_f-score_macro_sent: 0.9573888158376762
train_precision_micro_sent: 0.9720817605583648
train_recall_micro_sent: 0.9720817605583648
train_f-score_micro_sent: 0.9720817605583648
train_label=O_precision_tok: 0.9949350389295264
train_label=O_recall_tok: 0.9962023375673731
train_label=O_f-score_tok: 0.9955682849498485
train_label=LOC_precision_tok: 0.9346413095811267
train_label=LOC_recall_tok: 0.9358804387127878
train_label=LOC_f-score_tok: 0.9352604637157483
train_label=MISC_precision_tok: 0.8882339605531625
train_label=MISC_recall_tok: 0.8530372305682561
train_label=MISC_f-score_tok: 0.8702798756108397
train_label=ORG_precision_tok: 0.9120967741935484
train_label=ORG_recall_tok: 0.9025436408977556
train_label=ORG_f-score_tok: 0.907295061418902
train_label=PER_precision_tok: 0.9670182338219521
train_label=PER_recall_tok: 0.9722322070452911
train_label=PER_f-score_tok: 0.9696182111489514
train_precision_macro_tok: 0.9393850634158631
train_recall_macro_tok: 0.9319791709582927
train_f-score_macro_tok: 0.935604379368858
train_precision_micro_tok: 0.9845939269525246
train_recall_micro_tok: 0.9845939269525246
train_f-score_micro_tok: 0.9845939269525246
train_time: 324.70546793937683
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9359    0.9288    0.9324      2909
           1     0.9814    0.9834    0.9824     11132

   micro avg     0.9721    0.9721    0.9721     14041
   macro avg     0.9587    0.9561    0.9574     14041
weighted avg     0.9720    0.9721    0.9720     14041

F1-macro sent:  0.9573888158376762
F1-micro sent:  0.9720817605583648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9949    0.9962    0.9956    169578
         LOC     0.9346    0.9359    0.9353      8297
        MISC     0.8882    0.8530    0.8703      4593
         ORG     0.9121    0.9025    0.9073     10025
         PER     0.9670    0.9722    0.9696     11128

   micro avg     0.9846    0.9846    0.9846    203621
   macro avg     0.9394    0.9320    0.9356    203621
weighted avg     0.9845    0.9846    0.9845    203621

F1-macro tok:  0.935604379368858
F1-micro tok:  0.9845939269525246
**************************************************
dev_cost_sum: 87930.57332611084
dev_cost_avg: 27.05556102341872
dev_count_sent: 3250.0
dev_total_correct_sent: 3189.0
dev_accuracy_sent: 0.9812307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50726.0
dev_accuracy_tok: 0.9876173046220942
dev_label=0_precision_sent: 0.9850498338870431
dev_label=0_recall_sent: 0.9193798449612403
dev_label=0_f-score_sent: 0.9510825982357658
dev_label=1_precision_sent: 0.9803625377643505
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9883875880449267
dev_precision_macro_sent: 0.9827061858256968
dev_recall_macro_sent: 0.9579624752637295
dev_f-score_macro_sent: 0.9697350931403462
dev_precision_micro_sent: 0.9812307692307692
dev_recall_micro_sent: 0.9812307692307692
dev_f-score_micro_sent: 0.9812307692307692
dev_label=O_precision_tok: 0.995818245532064
dev_label=O_recall_tok: 0.9968895437217896
dev_label=O_f-score_tok: 0.9963536066570053
dev_label=LOC_precision_tok: 0.9601536245799328
dev_label=LOC_recall_tok: 0.9551098376313276
dev_label=LOC_f-score_tok: 0.9576250897773523
dev_label=MISC_precision_tok: 0.8805970149253731
dev_label=MISC_recall_tok: 0.8840694006309149
dev_label=MISC_f-score_tok: 0.8823297914207004
dev_label=ORG_precision_tok: 0.9368473396320238
dev_label=ORG_recall_tok: 0.9005736137667304
dev_label=ORG_f-score_tok: 0.9183524250548378
dev_label=PER_precision_tok: 0.9702194357366771
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9764947152547719
dev_precision_macro_tok: 0.9487271320812141
dev_recall_macro_tok: 0.9438988189405622
dev_f-score_macro_tok: 0.9462311256329334
dev_precision_micro_tok: 0.9876173046220942
dev_recall_micro_tok: 0.9876173046220942
dev_f-score_micro_tok: 0.9876173046220942
dev_time: 34.59931516647339
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9850    0.9194    0.9511       645
           1     0.9804    0.9965    0.9884      2605

   micro avg     0.9812    0.9812    0.9812      3250
   macro avg     0.9827    0.9580    0.9697      3250
weighted avg     0.9813    0.9812    0.9810      3250

F1-macro sent:  0.9697350931403462
F1-micro sent:  0.9812307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9969    0.9964     42759
         LOC     0.9602    0.9551    0.9576      2094
        MISC     0.8806    0.8841    0.8823      1268
         ORG     0.9368    0.9006    0.9184      2092
         PER     0.9702    0.9829    0.9765      3149

   micro avg     0.9876    0.9876    0.9876     51362
   macro avg     0.9487    0.9439    0.9462     51362
weighted avg     0.9875    0.9876    0.9876     51362

F1-macro tok:  0.9462311256329334
F1-micro tok:  0.9876173046220942
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 326138.46255493164
train_cost_avg: 23.227580838610614
train_count_sent: 14041.0
train_total_correct_sent: 13677.0
train_accuracy_sent: 0.9740759205184816
train_count_tok: 203621.0
train_total_correct_tok: 200754.0
train_accuracy_tok: 0.985919919851096
train_label=0_precision_sent: 0.9386418476387453
train_label=0_recall_sent: 0.9360605018906841
train_label=0_f-score_sent: 0.9373493975903615
train_label=1_precision_sent: 0.9833034111310592
train_label=1_recall_sent: 0.9840100610851599
train_label=1_f-score_sent: 0.9836566091954023
train_precision_macro_sent: 0.9609726293849022
train_recall_macro_sent: 0.960035281487922
train_f-score_macro_sent: 0.9605030033928819
train_precision_micro_sent: 0.9740759205184816
train_recall_micro_sent: 0.9740759205184816
train_f-score_micro_sent: 0.9740759205184816
train_label=O_precision_tok: 0.995745658745264
train_label=O_recall_tok: 0.9965148781091887
train_label=O_f-score_tok: 0.9961301199279665
train_label=LOC_precision_tok: 0.9415169419992765
train_label=LOC_recall_tok: 0.9410630348318669
train_label=LOC_f-score_tok: 0.941289933694997
train_label=MISC_precision_tok: 0.8915716521350324
train_label=MISC_recall_tok: 0.8682778140648814
train_label=MISC_f-score_tok: 0.8797705713655416
train_label=ORG_precision_tok: 0.9181151411634683
train_label=ORG_recall_tok: 0.9115211970074812
train_label=ORG_f-score_tok: 0.9148062869156072
train_label=PER_precision_tok: 0.9678370410077727
train_label=PER_recall_tok: 0.973490294751977
train_label=PER_f-score_tok: 0.9706554365843825
train_precision_macro_tok: 0.9429572870101628
train_recall_macro_tok: 0.9381734437530792
train_f-score_macro_tok: 0.9405304696976989
train_precision_micro_tok: 0.985919919851096
train_recall_micro_tok: 0.985919919851096
train_f-score_micro_tok: 0.985919919851096
train_time: 325.3843982219696
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9386    0.9361    0.9373      2909
           1     0.9833    0.9840    0.9837     11132

   micro avg     0.9741    0.9741    0.9741     14041
   macro avg     0.9610    0.9600    0.9605     14041
weighted avg     0.9741    0.9741    0.9741     14041

F1-macro sent:  0.9605030033928819
F1-micro sent:  0.9740759205184816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9965    0.9961    169578
         LOC     0.9415    0.9411    0.9413      8297
        MISC     0.8916    0.8683    0.8798      4593
         ORG     0.9181    0.9115    0.9148     10025
         PER     0.9678    0.9735    0.9707     11128

   micro avg     0.9859    0.9859    0.9859    203621
   macro avg     0.9430    0.9382    0.9405    203621
weighted avg     0.9858    0.9859    0.9859    203621

F1-macro tok:  0.9405304696976989
F1-micro tok:  0.985919919851096
**************************************************
dev_cost_sum: 87340.17357635498
dev_cost_avg: 26.87389956195538
dev_count_sent: 3250.0
dev_total_correct_sent: 3212.0
dev_accuracy_sent: 0.9883076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50708.0
dev_accuracy_tok: 0.9872668509793232
dev_label=0_precision_sent: 0.9794628751974723
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.9702660406885758
dev_label=1_precision_sent: 0.9904470768055025
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9927230945997703
dev_precision_macro_sent: 0.9849549760014874
dev_recall_macro_sent: 0.978124953503251
dev_f-score_macro_sent: 0.9814945676441731
dev_precision_micro_sent: 0.9883076923076923
dev_recall_micro_sent: 0.9883076923076923
dev_f-score_micro_sent: 0.9883076923076923
dev_label=O_precision_tok: 0.9958888110254613
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9964823709520971
dev_label=LOC_precision_tok: 0.948292220113852
dev_label=LOC_recall_tok: 0.954632282712512
dev_label=LOC_f-score_tok: 0.951451689671585
dev_label=MISC_precision_tok: 0.8987034035656402
dev_label=MISC_recall_tok: 0.8746056782334385
dev_label=MISC_f-score_tok: 0.8864908073541167
dev_label=ORG_precision_tok: 0.923790913531998
dev_label=ORG_recall_tok: 0.9039196940726577
dev_label=ORG_f-score_tok: 0.9137472819521624
dev_label=PER_precision_tok: 0.9721783117293709
dev_label=PER_recall_tok: 0.9765004763416958
dev_label=PER_f-score_tok: 0.9743346007604562
dev_precision_macro_tok: 0.9477707319932644
dev_recall_macro_tok: 0.9413469540393145
dev_f-score_macro_tok: 0.9445013501380835
dev_precision_micro_tok: 0.9872668509793232
dev_recall_micro_tok: 0.9872668509793232
dev_f-score_micro_tok: 0.9872668509793232
dev_time: 34.70654010772705
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9795    0.9612    0.9703       645
           1     0.9904    0.9950    0.9927      2605

   micro avg     0.9883    0.9883    0.9883      3250
   macro avg     0.9850    0.9781    0.9815      3250
weighted avg     0.9883    0.9883    0.9883      3250

F1-macro sent:  0.9814945676441731
F1-micro sent:  0.9883076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9971    0.9965     42759
         LOC     0.9483    0.9546    0.9515      2094
        MISC     0.8987    0.8746    0.8865      1268
         ORG     0.9238    0.9039    0.9137      2092
         PER     0.9722    0.9765    0.9743      3149

   micro avg     0.9873    0.9873    0.9873     51362
   macro avg     0.9478    0.9413    0.9445     51362
weighted avg     0.9872    0.9873    0.9872     51362

F1-macro tok:  0.9445013501380835
F1-micro tok:  0.9872668509793232
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 322925.1403198242
train_cost_avg: 22.99872803360332
train_count_sent: 14041.0
train_total_correct_sent: 13722.0
train_accuracy_sent: 0.9772808204543836
train_count_tok: 203621.0
train_total_correct_tok: 200955.0
train_accuracy_tok: 0.9869070478978101
train_label=0_precision_sent: 0.9474775397373877
train_label=0_recall_sent: 0.942591955998625
train_label=0_f-score_sent: 0.9450284335688438
train_label=1_precision_sent: 0.9850183905983673
train_label=1_recall_sent: 0.9863456701401365
train_label=1_f-score_sent: 0.9856815835540194
train_precision_macro_sent: 0.9662479651678775
train_recall_macro_sent: 0.9644688130693808
train_f-score_macro_sent: 0.9653550085614315
train_precision_micro_sent: 0.9772808204543836
train_recall_micro_sent: 0.9772808204543836
train_f-score_micro_sent: 0.9772808204543836
train_label=O_precision_tok: 0.9958047314615679
train_label=O_recall_tok: 0.9966092299708689
train_label=O_f-score_tok: 0.9962068182956914
train_label=LOC_precision_tok: 0.9426298662167049
train_label=LOC_recall_tok: 0.9426298662167049
train_label=LOC_f-score_tok: 0.9426298662167049
train_label=MISC_precision_tok: 0.9027777777777778
train_label=MISC_recall_tok: 0.8774221641628566
train_label=MISC_f-score_tok: 0.8899193993596113
train_label=ORG_precision_tok: 0.9257883109058044
train_label=ORG_recall_tok: 0.9196009975062344
train_label=ORG_f-score_tok: 0.9226842816393934
train_label=PER_precision_tok: 0.9727362116742647
train_label=PER_recall_tok: 0.9778936017253774
train_label=PER_f-score_tok: 0.9753080887295542
train_precision_macro_tok: 0.947947379607224
train_recall_macro_tok: 0.9428311719164084
train_f-score_macro_tok: 0.945349690848191
train_precision_micro_tok: 0.9869070478978101
train_recall_micro_tok: 0.9869070478978101
train_f-score_micro_tok: 0.9869070478978101
train_time: 326.70235323905945
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9475    0.9426    0.9450      2909
           1     0.9850    0.9863    0.9857     11132

   micro avg     0.9773    0.9773    0.9773     14041
   macro avg     0.9662    0.9645    0.9654     14041
weighted avg     0.9772    0.9773    0.9773     14041

F1-macro sent:  0.9653550085614315
F1-micro sent:  0.9772808204543836
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9966    0.9962    169578
         LOC     0.9426    0.9426    0.9426      8297
        MISC     0.9028    0.8774    0.8899      4593
         ORG     0.9258    0.9196    0.9227     10025
         PER     0.9727    0.9779    0.9753     11128

   micro avg     0.9869    0.9869    0.9869    203621
   macro avg     0.9479    0.9428    0.9453    203621
weighted avg     0.9868    0.9869    0.9869    203621

F1-macro tok:  0.945349690848191
F1-micro tok:  0.9869070478978101
**************************************************
dev_cost_sum: 86813.91929626465
dev_cost_avg: 26.71197516808143
dev_count_sent: 3250.0
dev_total_correct_sent: 3194.0
dev_accuracy_sent: 0.9827692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50706.0
dev_accuracy_tok: 0.987227911685682
dev_label=0_precision_sent: 0.9362962962962963
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9575757575757575
dev_label=1_precision_sent: 0.9949514563106796
dev_label=1_recall_sent: 0.9834932821497121
dev_label=1_f-score_sent: 0.9891891891891893
dev_precision_macro_sent: 0.9656238763034879
dev_recall_macro_sent: 0.9816691216950111
dev_f-score_macro_sent: 0.9733824733824734
dev_precision_micro_sent: 0.9827692307692307
dev_recall_micro_sent: 0.9827692307692307
dev_f-score_micro_sent: 0.9827692307692307
dev_label=O_precision_tok: 0.9949401916664724
dev_label=O_recall_tok: 0.9979185668514231
dev_label=O_f-score_tok: 0.9964271536323938
dev_label=LOC_precision_tok: 0.9494997617913292
dev_label=LOC_recall_tok: 0.9517669531996179
dev_label=LOC_f-score_tok: 0.9506320057238254
dev_label=MISC_precision_tok: 0.8991049633848658
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8850620744893873
dev_label=ORG_precision_tok: 0.9451282051282052
dev_label=ORG_recall_tok: 0.8809751434034416
dev_label=ORG_f-score_tok: 0.9119247897080652
dev_label=PER_precision_tok: 0.9680950891460745
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9754175858808698
dev_precision_macro_tok: 0.9513536422233895
dev_recall_macro_tok: 0.9369926933014956
dev_f-score_macro_tok: 0.9438927218869082
dev_precision_micro_tok: 0.987227911685682
dev_recall_micro_tok: 0.987227911685682
dev_f-score_micro_tok: 0.987227911685682
dev_time: 34.53205895423889
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9363    0.9798    0.9576       645
           1     0.9950    0.9835    0.9892      2605

   micro avg     0.9828    0.9828    0.9828      3250
   macro avg     0.9656    0.9817    0.9734      3250
weighted avg     0.9833    0.9828    0.9829      3250

F1-macro sent:  0.9733824733824734
F1-micro sent:  0.9827692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9949    0.9979    0.9964     42759
         LOC     0.9495    0.9518    0.9506      2094
        MISC     0.8991    0.8715    0.8851      1268
         ORG     0.9451    0.8810    0.9119      2092
         PER     0.9681    0.9829    0.9754      3149

   micro avg     0.9872    0.9872    0.9872     51362
   macro avg     0.9514    0.9370    0.9439     51362
weighted avg     0.9870    0.9872    0.9871     51362

F1-macro tok:  0.9438927218869082
F1-micro tok:  0.987227911685682
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 320206.4653015137
train_cost_avg: 22.805104002671722
train_count_sent: 14041.0
train_total_correct_sent: 13746.0
train_accuracy_sent: 0.978990100420198
train_count_tok: 203621.0
train_total_correct_tok: 201063.0
train_accuracy_tok: 0.9874374450572387
train_label=0_precision_sent: 0.9491408934707903
train_label=0_recall_sent: 0.949467170849089
train_label=0_f-score_sent: 0.94930400412442
train_label=1_precision_sent: 0.9867936393854999
train_label=1_recall_sent: 0.986704994610133
train_label=1_f-score_sent: 0.9867493150069622
train_precision_macro_sent: 0.9679672664281451
train_recall_macro_sent: 0.9680860827296109
train_f-score_macro_sent: 0.968026659565691
train_precision_micro_sent: 0.978990100420198
train_recall_micro_sent: 0.978990100420198
train_f-score_micro_sent: 0.978990100420198
train_label=O_precision_tok: 0.9960405140261256
train_label=O_recall_tok: 0.9968686975904893
train_label=O_f-score_tok: 0.9964544337262045
train_label=LOC_precision_tok: 0.9503683130056756
train_label=LOC_recall_tok: 0.9485356152826323
train_label=LOC_f-score_tok: 0.9494510797442394
train_label=MISC_precision_tok: 0.9029817534490432
train_label=MISC_recall_tok: 0.8835183975615066
train_label=MISC_f-score_tok: 0.8931440519423351
train_label=ORG_precision_tok: 0.9271556494617165
train_label=ORG_recall_tok: 0.9192019950124688
train_label=ORG_f-score_tok: 0.9231616910438789
train_label=PER_precision_tok: 0.971844833750447
train_label=PER_recall_tok: 0.9770848310567937
train_label=PER_f-score_tok: 0.9744577881340742
train_precision_macro_tok: 0.9496782127386016
train_recall_macro_tok: 0.9450419073007781
train_f-score_macro_tok: 0.9473338089181464
train_precision_micro_tok: 0.9874374450572387
train_recall_micro_tok: 0.9874374450572387
train_f-score_micro_tok: 0.9874374450572387
train_time: 324.62523317337036
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9491    0.9495    0.9493      2909
           1     0.9868    0.9867    0.9867     11132

   micro avg     0.9790    0.9790    0.9790     14041
   macro avg     0.9680    0.9681    0.9680     14041
weighted avg     0.9790    0.9790    0.9790     14041

F1-macro sent:  0.968026659565691
F1-micro sent:  0.978990100420198
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9969    0.9965    169578
         LOC     0.9504    0.9485    0.9495      8297
        MISC     0.9030    0.8835    0.8931      4593
         ORG     0.9272    0.9192    0.9232     10025
         PER     0.9718    0.9771    0.9745     11128

   micro avg     0.9874    0.9874    0.9874    203621
   macro avg     0.9497    0.9450    0.9473    203621
weighted avg     0.9874    0.9874    0.9874    203621

F1-macro tok:  0.9473338089181464
F1-micro tok:  0.9874374450572387
**************************************************
dev_cost_sum: 86473.23788452148
dev_cost_avg: 26.6071501183143
dev_count_sent: 3250.0
dev_total_correct_sent: 3209.0
dev_accuracy_sent: 0.9873846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50677.0
dev_accuracy_tok: 0.9866632919278844
dev_label=0_precision_sent: 0.9748427672955975
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.9679937548790009
dev_label=1_precision_sent: 0.9904361132364193
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9921440889059207
dev_precision_macro_sent: 0.9826394402660084
dev_recall_macro_sent: 0.9775491377642875
dev_f-score_macro_sent: 0.9800689218924608
dev_precision_micro_sent: 0.9873846153846154
dev_recall_micro_sent: 0.9873846153846154
dev_f-score_micro_sent: 0.9873846153846154
dev_label=O_precision_tok: 0.9948929620819924
dev_label=O_recall_tok: 0.9977548586262541
dev_label=O_f-score_tok: 0.9963218551861841
dev_label=LOC_precision_tok: 0.9099821746880571
dev_label=LOC_recall_tok: 0.9751671442215855
dev_label=LOC_f-score_tok: 0.9414476717381283
dev_label=MISC_precision_tok: 0.9236111111111112
dev_label=MISC_recall_tok: 0.8391167192429022
dev_label=MISC_f-score_tok: 0.8793388429752066
dev_label=ORG_precision_tok: 0.9529042386185244
dev_label=ORG_recall_tok: 0.8704588910133844
dev_label=ORG_f-score_tok: 0.9098176367724207
dev_label=PER_precision_tok: 0.9728963126378821
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9765896868079721
dev_precision_macro_tok: 0.9508573598275134
dev_recall_macro_tok: 0.9325617646024067
dev_f-score_macro_tok: 0.9407031386959824
dev_precision_micro_tok: 0.9866632919278844
dev_recall_micro_tok: 0.9866632919278844
dev_f-score_micro_tok: 0.9866632919278844
dev_time: 34.61273813247681
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9748    0.9612    0.9680       645
           1     0.9904    0.9939    0.9921      2605

   micro avg     0.9874    0.9874    0.9874      3250
   macro avg     0.9826    0.9775    0.9801      3250
weighted avg     0.9873    0.9874    0.9874      3250

F1-macro sent:  0.9800689218924608
F1-micro sent:  0.9873846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9949    0.9978    0.9963     42759
         LOC     0.9100    0.9752    0.9414      2094
        MISC     0.9236    0.8391    0.8793      1268
         ORG     0.9529    0.8705    0.9098      2092
         PER     0.9729    0.9803    0.9766      3149

   micro avg     0.9867    0.9867    0.9867     51362
   macro avg     0.9509    0.9326    0.9407     51362
weighted avg     0.9866    0.9867    0.9865     51362

F1-macro tok:  0.9407031386959824
F1-micro tok:  0.9866632919278844
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 317955.79693603516
train_cost_avg: 22.644811404888195
train_count_sent: 14041.0
train_total_correct_sent: 13749.0
train_accuracy_sent: 0.9792037604159248
train_count_tok: 203621.0
train_total_correct_tok: 201166.0
train_accuracy_tok: 0.9879432867926197
train_label=0_precision_sent: 0.9498109315916122
train_label=0_recall_sent: 0.9498109315916122
train_label=0_f-score_sent: 0.9498109315916122
train_label=1_precision_sent: 0.9868846568451312
train_label=1_recall_sent: 0.9868846568451312
train_label=1_f-score_sent: 0.9868846568451312
train_precision_macro_sent: 0.9683477942183717
train_recall_macro_sent: 0.9683477942183717
train_f-score_macro_sent: 0.9683477942183717
train_precision_micro_sent: 0.9792037604159248
train_recall_micro_sent: 0.9792037604159248
train_f-score_micro_sent: 0.9792037604159248
train_label=O_precision_tok: 0.9960812968844837
train_label=O_recall_tok: 0.9967920367028742
train_label=O_f-score_tok: 0.9964365400542919
train_label=LOC_precision_tok: 0.9472038484666265
train_label=LOC_recall_tok: 0.9492587682294805
train_label=LOC_f-score_tok: 0.9482301950397303
train_label=MISC_precision_tok: 0.9115887436295147
train_label=MISC_recall_tok: 0.8957108643588069
train_label=MISC_f-score_tok: 0.9035800571052054
train_label=ORG_precision_tok: 0.9312254556439432
train_label=ORG_recall_tok: 0.9224937655860349
train_label=ORG_f-score_tok: 0.9268390459009822
train_label=PER_precision_tok: 0.9759025351607991
train_label=PER_recall_tok: 0.9789719626168224
train_label=PER_f-score_tok: 0.9774348391727602
train_precision_macro_tok: 0.9524003759570734
train_recall_macro_tok: 0.9486454794988038
train_f-score_macro_tok: 0.950504135454594
train_precision_micro_tok: 0.9879432867926197
train_recall_micro_tok: 0.9879432867926197
train_f-score_micro_tok: 0.9879432867926197
train_time: 326.1678445339203
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9498    0.9498    0.9498      2909
           1     0.9869    0.9869    0.9869     11132

   micro avg     0.9792    0.9792    0.9792     14041
   macro avg     0.9683    0.9683    0.9683     14041
weighted avg     0.9792    0.9792    0.9792     14041

F1-macro sent:  0.9683477942183717
F1-micro sent:  0.9792037604159248
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9968    0.9964    169578
         LOC     0.9472    0.9493    0.9482      8297
        MISC     0.9116    0.8957    0.9036      4593
         ORG     0.9312    0.9225    0.9268     10025
         PER     0.9759    0.9790    0.9774     11128

   micro avg     0.9879    0.9879    0.9879    203621
   macro avg     0.9524    0.9486    0.9505    203621
weighted avg     0.9879    0.9879    0.9879    203621

F1-macro tok:  0.950504135454594
F1-micro tok:  0.9879432867926197
**************************************************
dev_cost_sum: 85772.71012878418
dev_cost_avg: 26.39160311654898
dev_count_sent: 3250.0
dev_total_correct_sent: 3205.0
dev_accuracy_sent: 0.9861538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50773.0
dev_accuracy_tok: 0.9885323780226627
dev_label=0_precision_sent: 0.9807692307692307
dev_label=0_recall_sent: 0.9488372093023256
dev_label=0_f-score_sent: 0.9645390070921986
dev_label=1_precision_sent: 0.9874333587204874
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9913974383483082
dev_precision_macro_sent: 0.9841012947448591
dev_recall_macro_sent: 0.9721153416953087
dev_f-score_macro_sent: 0.9779682227202534
dev_precision_micro_sent: 0.9861538461538462
dev_recall_micro_sent: 0.9861538461538462
dev_f-score_micro_sent: 0.9861538461538462
dev_label=O_precision_tok: 0.9965408437536519
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9968437295426914
dev_label=LOC_precision_tok: 0.951864086833412
dev_label=LOC_recall_tok: 0.9632282712511939
dev_label=LOC_f-score_tok: 0.9575124614289106
dev_label=MISC_precision_tok: 0.9096826688364524
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.8954745694833801
dev_label=ORG_precision_tok: 0.9334312285854136
dev_label=ORG_recall_tok: 0.9115678776290631
dev_label=ORG_f-score_tok: 0.9223700120918983
dev_label=PER_precision_tok: 0.9711236660389203
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9767955801104974
dev_precision_macro_tok: 0.95252849880957
dev_recall_macro_tok: 0.9472361112475062
dev_f-score_macro_tok: 0.9497992705314756
dev_precision_micro_tok: 0.9885323780226627
dev_recall_micro_tok: 0.9885323780226627
dev_f-score_micro_tok: 0.9885323780226627
dev_time: 34.57302141189575
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9808    0.9488    0.9645       645
           1     0.9874    0.9954    0.9914      2605

   micro avg     0.9862    0.9862    0.9862      3250
   macro avg     0.9841    0.9721    0.9780      3250
weighted avg     0.9861    0.9862    0.9861      3250

F1-macro sent:  0.9779682227202534
F1-micro sent:  0.9861538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9971    0.9968     42759
         LOC     0.9519    0.9632    0.9575      2094
        MISC     0.9097    0.8817    0.8955      1268
         ORG     0.9334    0.9116    0.9224      2092
         PER     0.9711    0.9825    0.9768      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9525    0.9472    0.9498     51362
weighted avg     0.9884    0.9885    0.9885     51362

F1-macro tok:  0.9497992705314756
F1-micro tok:  0.9885323780226627
**************************************************
Best epoch: 10
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 315413.92071533203
train_cost_avg: 22.463778984070366
train_count_sent: 14041.0
train_total_correct_sent: 13790.0
train_accuracy_sent: 0.9821237803575243
train_count_tok: 203621.0
train_total_correct_tok: 201338.0
train_accuracy_tok: 0.9887879933798577
train_label=0_precision_sent: 0.957960027567195
train_label=0_recall_sent: 0.9556548642145067
train_label=0_f-score_sent: 0.9568060574771984
train_label=1_precision_sent: 0.9884190681389712
train_label=1_recall_sent: 0.9890406036651096
train_label=1_f-score_sent: 0.988729738224597
train_precision_macro_sent: 0.9731895478530831
train_recall_macro_sent: 0.9723477339398081
train_f-score_macro_sent: 0.9727678978508977
train_precision_micro_sent: 0.9821237803575243
train_recall_micro_sent: 0.9821237803575243
train_f-score_micro_sent: 0.9821237803575243
train_label=O_precision_tok: 0.9964054425135974
train_label=O_recall_tok: 0.9971281652101098
train_label=O_f-score_tok: 0.9967666728562629
train_label=LOC_precision_tok: 0.9512048192771084
train_label=LOC_recall_tok: 0.9515487525611667
train_label=LOC_f-score_tok: 0.9513767548352112
train_label=MISC_precision_tok: 0.9207589285714286
train_label=MISC_recall_tok: 0.8981058131939909
train_label=MISC_f-score_tok: 0.9092913038686212
train_label=ORG_precision_tok: 0.9354935794542536
train_label=ORG_recall_tok: 0.9301745635910225
train_label=ORG_f-score_tok: 0.932826489271245
train_label=PER_precision_tok: 0.9758324382384532
train_label=PER_recall_tok: 0.9796908698777858
train_label=PER_f-score_tok: 0.9777578475336323
train_precision_macro_tok: 0.9559390416109682
train_recall_macro_tok: 0.951329632886815
train_f-score_macro_tok: 0.9536038136729946
train_precision_micro_tok: 0.9887879933798577
train_recall_micro_tok: 0.9887879933798577
train_f-score_micro_tok: 0.9887879933798577
train_time: 323.66550040245056
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9580    0.9557    0.9568      2909
           1     0.9884    0.9890    0.9887     11132

   micro avg     0.9821    0.9821    0.9821     14041
   macro avg     0.9732    0.9723    0.9728     14041
weighted avg     0.9821    0.9821    0.9821     14041

F1-macro sent:  0.9727678978508977
F1-micro sent:  0.9821237803575243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9971    0.9968    169578
         LOC     0.9512    0.9515    0.9514      8297
        MISC     0.9208    0.8981    0.9093      4593
         ORG     0.9355    0.9302    0.9328     10025
         PER     0.9758    0.9797    0.9778     11128

   micro avg     0.9888    0.9888    0.9888    203621
   macro avg     0.9559    0.9513    0.9536    203621
weighted avg     0.9887    0.9888    0.9888    203621

F1-macro tok:  0.9536038136729946
F1-micro tok:  0.9887879933798577
**************************************************
dev_cost_sum: 85445.36609649658
dev_cost_avg: 26.290881875845102
dev_count_sent: 3250.0
dev_total_correct_sent: 3207.0
dev_accuracy_sent: 0.9867692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50776.0
dev_accuracy_tok: 0.9885907869631245
dev_label=0_precision_sent: 0.9792993630573248
dev_label=0_recall_sent: 0.9534883720930233
dev_label=0_f-score_sent: 0.9662215239591517
dev_label=1_precision_sent: 0.988558352402746
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9917734838339393
dev_precision_macro_sent: 0.9839288577300354
dev_recall_macro_sent: 0.974248984511003
dev_f-score_macro_sent: 0.9789975038965455
dev_precision_micro_sent: 0.9867692307692307
dev_recall_micro_sent: 0.9867692307692307
dev_f-score_micro_sent: 0.9867692307692307
dev_label=O_precision_tok: 0.9960303561004087
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9967984670031782
dev_label=LOC_precision_tok: 0.9597122302158273
dev_label=LOC_recall_tok: 0.9555873925501432
dev_label=LOC_f-score_tok: 0.9576453697056712
dev_label=MISC_precision_tok: 0.9308016877637131
dev_label=MISC_recall_tok: 0.8698738170347003
dev_label=MISC_f-score_tok: 0.8993069710558501
dev_label=ORG_precision_tok: 0.9193702290076335
dev_label=ORG_recall_tok: 0.9211281070745698
dev_label=ORG_f-score_tok: 0.9202483285577842
dev_label=PER_precision_tok: 0.9744560075685903
dev_label=PER_recall_tok: 0.9812638932994602
dev_label=PER_f-score_tok: 0.9778481012658228
dev_precision_macro_tok: 0.9560741021312346
dev_recall_macro_tok: 0.94508419469413
dev_f-score_macro_tok: 0.9503694475176612
dev_precision_micro_tok: 0.9885907869631245
dev_recall_micro_tok: 0.9885907869631245
dev_f-score_micro_tok: 0.9885907869631245
dev_time: 34.637300968170166
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9793    0.9535    0.9662       645
           1     0.9886    0.9950    0.9918      2605

   micro avg     0.9868    0.9868    0.9868      3250
   macro avg     0.9839    0.9742    0.9790      3250
weighted avg     0.9867    0.9868    0.9867      3250

F1-macro sent:  0.9789975038965455
F1-micro sent:  0.9867692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9976    0.9968     42759
         LOC     0.9597    0.9556    0.9576      2094
        MISC     0.9308    0.8699    0.8993      1268
         ORG     0.9194    0.9211    0.9202      2092
         PER     0.9745    0.9813    0.9778      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9561    0.9451    0.9504     51362
weighted avg     0.9885    0.9886    0.9885     51362

F1-macro tok:  0.9503694475176612
F1-micro tok:  0.9885907869631245
**************************************************
Best epoch: 10
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 313101.3447265625
train_cost_avg: 22.299077325444234
train_count_sent: 14041.0
train_total_correct_sent: 13770.0
train_accuracy_sent: 0.9806993803860123
train_count_tok: 203621.0
train_total_correct_tok: 201518.0
train_accuracy_tok: 0.9896719886455719
train_label=0_precision_sent: 0.9538885065381968
train_label=0_recall_sent: 0.9529047782743211
train_label=0_f-score_sent: 0.9533963886500428
train_label=1_precision_sent: 0.9876964526268522
train_label=1_recall_sent: 0.9879626302551203
train_label=1_f-score_sent: 0.9878295235101271
train_precision_macro_sent: 0.9707924795825245
train_recall_macro_sent: 0.9704337042647206
train_f-score_macro_sent: 0.9706129560800849
train_precision_micro_sent: 0.9806993803860123
train_recall_micro_sent: 0.9806993803860123
train_f-score_micro_sent: 0.9806993803860123
train_label=O_precision_tok: 0.9967347997265248
train_label=O_recall_tok: 0.997263796011275
train_label=O_f-score_tok: 0.9969992276990738
train_label=LOC_precision_tok: 0.9557991087558714
train_label=LOC_recall_tok: 0.9564902976979631
train_label=LOC_f-score_tok: 0.956144578313253
train_label=MISC_precision_tok: 0.9259176863181312
train_label=MISC_recall_tok: 0.9061615501850643
train_label=MISC_f-score_tok: 0.9159330985915494
train_label=ORG_precision_tok: 0.9389450505454909
train_label=ORG_recall_tok: 0.9357605985037406
train_label=ORG_f-score_tok: 0.9373501199040768
train_label=PER_precision_tok: 0.9785919025438911
train_label=PER_recall_tok: 0.9817577282530554
train_label=PER_f-score_tok: 0.9801722591064058
train_precision_macro_tok: 0.959197709577982
train_recall_macro_tok: 0.9554867941302196
train_f-score_macro_tok: 0.9573198567228717
train_precision_micro_tok: 0.9896719886455719
train_recall_micro_tok: 0.9896719886455719
train_f-score_micro_tok: 0.9896719886455719
train_time: 326.70481395721436
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9539    0.9529    0.9534      2909
           1     0.9877    0.9880    0.9878     11132

   micro avg     0.9807    0.9807    0.9807     14041
   macro avg     0.9708    0.9704    0.9706     14041
weighted avg     0.9807    0.9807    0.9807     14041

F1-macro sent:  0.9706129560800849
F1-micro sent:  0.9806993803860123
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9973    0.9970    169578
         LOC     0.9558    0.9565    0.9561      8297
        MISC     0.9259    0.9062    0.9159      4593
         ORG     0.9389    0.9358    0.9374     10025
         PER     0.9786    0.9818    0.9802     11128

   micro avg     0.9897    0.9897    0.9897    203621
   macro avg     0.9592    0.9555    0.9573    203621
weighted avg     0.9896    0.9897    0.9896    203621

F1-macro tok:  0.9573198567228717
F1-micro tok:  0.9896719886455719
**************************************************
dev_cost_sum: 85204.2919845581
dev_cost_avg: 26.21670522601788
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50758.0
dev_accuracy_tok: 0.9882403333203535
dev_label=0_precision_sent: 0.9778830963665087
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.968701095461659
dev_label=1_precision_sent: 0.9900649598777226
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9923400995787056
dev_precision_macro_sent: 0.9839740281221157
dev_recall_macro_sent: 0.9771578211251469
dev_f-score_macro_sent: 0.9805205975201823
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.9960068187656166
dev_label=O_recall_tok: 0.9974976028438457
dev_label=O_f-score_tok: 0.9967516533850577
dev_label=LOC_precision_tok: 0.9466791393826005
dev_label=LOC_recall_tok: 0.9665711556829035
dev_label=LOC_f-score_tok: 0.9565217391304347
dev_label=MISC_precision_tok: 0.8973747016706444
dev_label=MISC_recall_tok: 0.889589905362776
dev_label=MISC_f-score_tok: 0.8934653465346535
dev_label=ORG_precision_tok: 0.9576008273009308
dev_label=ORG_recall_tok: 0.8852772466539197
dev_label=ORG_f-score_tok: 0.9200198708395431
dev_label=PER_precision_tok: 0.9663551401869159
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.975625098285894
dev_precision_macro_tok: 0.9528033254613415
dev_recall_macro_tok: 0.9448021074818233
dev_f-score_macro_tok: 0.9484767416351165
dev_precision_micro_tok: 0.9882403333203535
dev_recall_micro_tok: 0.9882403333203535
dev_f-score_micro_tok: 0.9882403333203535
dev_time: 34.88168215751648
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9779    0.9597    0.9687       645
           1     0.9901    0.9946    0.9923      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9840    0.9772    0.9805      3250
weighted avg     0.9876    0.9877    0.9876      3250

F1-macro sent:  0.9805205975201823
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9975    0.9968     42759
         LOC     0.9467    0.9666    0.9565      2094
        MISC     0.8974    0.8896    0.8935      1268
         ORG     0.9576    0.8853    0.9200      2092
         PER     0.9664    0.9851    0.9756      3149

   micro avg     0.9882    0.9882    0.9882     51362
   macro avg     0.9528    0.9448    0.9485     51362
weighted avg     0.9882    0.9882    0.9881     51362

F1-macro tok:  0.9484767416351165
F1-micro tok:  0.9882403333203535
**************************************************
Best epoch: 10
**************************************************

EPOCH: 16
Learning rate: 0.810000
train_cost_sum: 311053.82485961914
train_cost_avg: 22.153252963437016
train_count_sent: 14041.0
train_total_correct_sent: 13803.0
train_accuracy_sent: 0.9830496403390072
train_count_tok: 203621.0
train_total_correct_tok: 201661.0
train_accuracy_tok: 0.9903742737733338
train_label=0_precision_sent: 0.9584620665980089
train_label=0_recall_sent: 0.9597799931247851
train_label=0_f-score_sent: 0.9591205771212642
train_label=1_precision_sent: 0.9894859813084113
train_label=1_recall_sent: 0.9891304347826086
train_label=1_f-score_sent: 0.9893081761006288
train_precision_macro_sent: 0.9739740239532101
train_recall_macro_sent: 0.9744552139536968
train_f-score_macro_sent: 0.9742143766109466
train_precision_micro_sent: 0.9830496403390072
train_recall_micro_sent: 0.9830496403390072
train_f-score_micro_sent: 0.9830496403390072
train_label=O_precision_tok: 0.9969588023810927
train_label=O_recall_tok: 0.9974996756654755
train_label=O_f-score_tok: 0.9972291656841014
train_label=LOC_precision_tok: 0.960472402988672
train_label=LOC_recall_tok: 0.96058816439677
train_label=LOC_f-score_tok: 0.9605302802048811
train_label=MISC_precision_tok: 0.9285872208711032
train_label=MISC_recall_tok: 0.914435009797518
train_label=MISC_f-score_tok: 0.921456779289162
train_label=ORG_precision_tok: 0.9444166249374061
train_label=ORG_recall_tok: 0.9406483790523691
train_label=ORG_f-score_tok: 0.9425287356321839
train_label=PER_precision_tok: 0.9786451323463436
train_label=PER_recall_tok: 0.9801401869158879
train_label=PER_f-score_tok: 0.9793920890764602
train_precision_macro_tok: 0.9618160367049235
train_recall_macro_tok: 0.958662283165604
train_f-score_macro_tok: 0.9602274099773578
train_precision_micro_tok: 0.9903742737733338
train_recall_micro_tok: 0.9903742737733338
train_f-score_micro_tok: 0.9903742737733338
train_time: 326.75836658477783
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9585    0.9598    0.9591      2909
           1     0.9895    0.9891    0.9893     11132

   micro avg     0.9830    0.9830    0.9830     14041
   macro avg     0.9740    0.9745    0.9742     14041
weighted avg     0.9831    0.9830    0.9831     14041

F1-macro sent:  0.9742143766109466
F1-micro sent:  0.9830496403390072
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9975    0.9972    169578
         LOC     0.9605    0.9606    0.9605      8297
        MISC     0.9286    0.9144    0.9215      4593
         ORG     0.9444    0.9406    0.9425     10025
         PER     0.9786    0.9801    0.9794     11128

   micro avg     0.9904    0.9904    0.9904    203621
   macro avg     0.9618    0.9587    0.9602    203621
weighted avg     0.9903    0.9904    0.9904    203621

F1-macro tok:  0.9602274099773578
F1-micro tok:  0.9903742737733338
**************************************************
dev_cost_sum: 84651.72162628174
dev_cost_avg: 26.04668357731746
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50770.0
dev_accuracy_tok: 0.9884739690822009
dev_label=0_precision_sent: 0.9796557120500783
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9750778816199377
dev_label=1_precision_sent: 0.9927230945997702
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9938650306748467
dev_precision_macro_sent: 0.9861894033249242
dev_recall_macro_sent: 0.9827761162939488
dev_f-score_macro_sent: 0.9844714561473922
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9963549698584045
dev_label=O_recall_tok: 0.9972637339507472
dev_label=O_f-score_tok: 0.9968091447806725
dev_label=LOC_precision_tok: 0.9622009569377991
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9612810707456979
dev_label=MISC_precision_tok: 0.8713096139288418
dev_label=MISC_recall_tok: 0.9077287066246057
dev_label=MISC_f-score_tok: 0.8891463885670143
dev_label=ORG_precision_tok: 0.9530612244897959
dev_label=ORG_recall_tok: 0.892925430210325
dev_label=ORG_f-score_tok: 0.9220138203356367
dev_label=PER_precision_tok: 0.9702474162229878
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9769788710186061
dev_precision_macro_tok: 0.950634836287566
dev_recall_macro_tok: 0.9484170389735158
dev_f-score_macro_tok: 0.9492458590895255
dev_precision_micro_tok: 0.9884739690822009
dev_recall_micro_tok: 0.9884739690822009
dev_f-score_micro_tok: 0.9884739690822009
dev_time: 34.65630602836609
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9797    0.9705    0.9751       645
           1     0.9927    0.9950    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9862    0.9828    0.9845      3250
weighted avg     0.9901    0.9902    0.9901      3250

F1-macro sent:  0.9844714561473922
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9973    0.9968     42759
         LOC     0.9622    0.9604    0.9613      2094
        MISC     0.8713    0.9077    0.8891      1268
         ORG     0.9531    0.8929    0.9220      2092
         PER     0.9702    0.9838    0.9770      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9506    0.9484    0.9492     51362
weighted avg     0.9885    0.9885    0.9884     51362

F1-macro tok:  0.9492458590895255
F1-micro tok:  0.9884739690822009
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 0.810000
train_cost_sum: 309389.9839477539
train_cost_avg: 22.03475421606395
train_count_sent: 14041.0
train_total_correct_sent: 13813.0
train_accuracy_sent: 0.9837618403247632
train_count_tok: 203621.0
train_total_correct_tok: 201721.0
train_accuracy_tok: 0.9906689388619052
train_label=0_precision_sent: 0.9646447140381282
train_label=0_recall_sent: 0.9566861464420763
train_label=0_f-score_sent: 0.9606489471867449
train_label=1_precision_sent: 0.9887056292577985
train_label=1_recall_sent: 0.9908372260150916
train_label=1_f-score_sent: 0.989770279971285
train_precision_macro_sent: 0.9766751716479634
train_recall_macro_sent: 0.973761686228584
train_f-score_macro_sent: 0.9752096135790149
train_precision_micro_sent: 0.9837618403247632
train_recall_micro_sent: 0.9837618403247632
train_f-score_micro_sent: 0.9837618403247631
train_label=O_precision_tok: 0.9969821641184029
train_label=O_recall_tok: 0.9974524997346353
train_label=O_f-score_tok: 0.9972172764682993
train_label=LOC_precision_tok: 0.9620192307692308
train_label=LOC_recall_tok: 0.9646860310955767
train_label=LOC_f-score_tok: 0.9633507853403142
train_label=MISC_precision_tok: 0.9320603907637656
train_label=MISC_recall_tok: 0.9139995645547573
train_label=MISC_f-score_tok: 0.9229416291084974
train_label=ORG_precision_tok: 0.9467520768691823
train_label=ORG_recall_tok: 0.9435411471321695
train_label=ORG_f-score_tok: 0.9451438848920862
train_label=PER_precision_tok: 0.9790096878363832
train_label=PER_recall_tok: 0.9807692307692307
train_label=PER_f-score_tok: 0.9798886694200036
train_precision_macro_tok: 0.9633647100713929
train_recall_macro_tok: 0.9600896946572739
train_f-score_macro_tok: 0.9617084490458401
train_precision_micro_tok: 0.9906689388619052
train_recall_micro_tok: 0.9906689388619052
train_f-score_micro_tok: 0.9906689388619052
train_time: 327.543662071228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9646    0.9567    0.9606      2909
           1     0.9887    0.9908    0.9898     11132

   micro avg     0.9838    0.9838    0.9838     14041
   macro avg     0.9767    0.9738    0.9752     14041
weighted avg     0.9837    0.9838    0.9837     14041

F1-macro sent:  0.9752096135790149
F1-micro sent:  0.9837618403247631
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9975    0.9972    169578
         LOC     0.9620    0.9647    0.9634      8297
        MISC     0.9321    0.9140    0.9229      4593
         ORG     0.9468    0.9435    0.9451     10025
         PER     0.9790    0.9808    0.9799     11128

   micro avg     0.9907    0.9907    0.9907    203621
   macro avg     0.9634    0.9601    0.9617    203621
weighted avg     0.9906    0.9907    0.9907    203621

F1-macro tok:  0.9617084490458401
F1-micro tok:  0.9906689388619052
**************************************************
dev_cost_sum: 84307.09239196777
dev_cost_avg: 25.940643812913162
dev_count_sent: 3250.0
dev_total_correct_sent: 3209.0
dev_accuracy_sent: 0.9873846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50786.0
dev_accuracy_tok: 0.9887854834313305
dev_label=0_precision_sent: 0.9674922600619195
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.968241673121611
dev_label=1_precision_sent: 0.9923195084485407
dev_label=1_recall_sent: 0.9919385796545106
dev_label=1_f-score_sent: 0.9921290074870418
dev_precision_macro_sent: 0.9799058842552301
dev_recall_macro_sent: 0.980465413858263
dev_f-score_macro_sent: 0.9801853403043264
dev_precision_micro_sent: 0.9873846153846154
dev_recall_micro_sent: 0.9873846153846154
dev_f-score_micro_sent: 0.9873846153846154
dev_label=O_precision_tok: 0.9958222471175839
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.9968342970620876
dev_label=LOC_precision_tok: 0.9582938388625593
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.961941008563273
dev_label=MISC_precision_tok: 0.9001610305958132
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.8908366533864542
dev_label=ORG_precision_tok: 0.9548452562151192
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9264090573467881
dev_label=PER_precision_tok: 0.9699342311305982
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9766635130873541
dev_precision_macro_tok: 0.9558113207843348
dev_recall_macro_tok: 0.9456544668191149
dev_f-score_macro_tok: 0.9505369058891915
dev_precision_micro_tok: 0.9887854834313305
dev_recall_micro_tok: 0.9887854834313305
dev_f-score_micro_tok: 0.9887854834313305
dev_time: 34.66444706916809
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9675    0.9690    0.9682       645
           1     0.9923    0.9919    0.9921      2605

   micro avg     0.9874    0.9874    0.9874      3250
   macro avg     0.9799    0.9805    0.9802      3250
weighted avg     0.9874    0.9874    0.9874      3250

F1-macro sent:  0.9801853403043264
F1-micro sent:  0.9873846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9978    0.9968     42759
         LOC     0.9583    0.9656    0.9619      2094
        MISC     0.9002    0.8817    0.8908      1268
         ORG     0.9548    0.8996    0.9264      2092
         PER     0.9699    0.9835    0.9767      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9558    0.9457    0.9505     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9505369058891915
F1-micro tok:  0.9887854834313305
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 0.810000
train_cost_sum: 307725.7787475586
train_cost_avg: 21.91622952407653
train_count_sent: 14041.0
train_total_correct_sent: 13833.0
train_accuracy_sent: 0.9851862402962752
train_count_tok: 203621.0
train_total_correct_tok: 201859.0
train_accuracy_tok: 0.9913466685656195
train_label=0_precision_sent: 0.9642488827775868
train_label=0_recall_sent: 0.9642488827775868
train_label=0_f-score_sent: 0.9642488827775868
train_label=1_precision_sent: 0.9906575637800934
train_label=1_recall_sent: 0.9906575637800934
train_label=1_f-score_sent: 0.9906575637800934
train_precision_macro_sent: 0.9774532232788401
train_recall_macro_sent: 0.9774532232788401
train_f-score_macro_sent: 0.9774532232788401
train_precision_micro_sent: 0.9851862402962752
train_recall_micro_sent: 0.9851862402962752
train_f-score_micro_sent: 0.9851862402962752
train_label=O_precision_tok: 0.9970887060653921
train_label=O_recall_tok: 0.9977119673542558
train_label=O_f-score_tok: 0.9974002393430446
train_label=LOC_precision_tok: 0.9625616949560611
train_label=LOC_recall_tok: 0.9637218271664457
train_label=LOC_f-score_tok: 0.9631414117080221
train_label=MISC_precision_tok: 0.9394074404098909
train_label=MISC_recall_tok: 0.9181362943609841
train_label=MISC_f-score_tok: 0.928650077075534
train_label=ORG_precision_tok: 0.9499849954986496
train_label=ORG_recall_tok: 0.9473316708229427
train_label=ORG_f-score_tok: 0.9486564778743383
train_label=PER_precision_tok: 0.9833991385498924
train_label=PER_recall_tok: 0.9848130841121495
train_label=PER_f-score_tok: 0.9841056034482758
train_precision_macro_tok: 0.9664883950959773
train_recall_macro_tok: 0.9623429687633556
train_f-score_macro_tok: 0.964390761889843
train_precision_micro_tok: 0.9913466685656195
train_recall_micro_tok: 0.9913466685656195
train_f-score_micro_tok: 0.9913466685656195
train_time: 300.9099702835083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9642    0.9642    0.9642      2909
           1     0.9907    0.9907    0.9907     11132

   micro avg     0.9852    0.9852    0.9852     14041
   macro avg     0.9775    0.9775    0.9775     14041
weighted avg     0.9852    0.9852    0.9852     14041

F1-macro sent:  0.9774532232788401
F1-micro sent:  0.9851862402962752
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9977    0.9974    169578
         LOC     0.9626    0.9637    0.9631      8297
        MISC     0.9394    0.9181    0.9287      4593
         ORG     0.9500    0.9473    0.9487     10025
         PER     0.9834    0.9848    0.9841     11128

   micro avg     0.9913    0.9913    0.9913    203621
   macro avg     0.9665    0.9623    0.9644    203621
weighted avg     0.9913    0.9913    0.9913    203621

F1-macro tok:  0.964390761889843
F1-micro tok:  0.9913466685656195
**************************************************
dev_cost_sum: 84148.44882202148
dev_cost_avg: 25.891830406775842
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50801.0
dev_accuracy_tok: 0.9890775281336397
dev_label=0_precision_sent: 0.985553772070626
dev_label=0_recall_sent: 0.951937984496124
dev_label=0_f-score_sent: 0.9684542586750788
dev_label=1_precision_sent: 0.9881994670727066
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9923547400611621
dev_precision_macro_sent: 0.9868766195716663
dev_recall_macro_sent: 0.9742415450311714
dev_f-score_macro_sent: 0.9804044993681205
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.997192654111592
dev_label=O_recall_tok: 0.9968661568324797
dev_label=O_f-score_tok: 0.9970293787425148
dev_label=LOC_precision_tok: 0.9596007604562737
dev_label=LOC_recall_tok: 0.9641833810888252
dev_label=LOC_f-score_tok: 0.9618866126727013
dev_label=MISC_precision_tok: 0.8912037037037037
dev_label=MISC_recall_tok: 0.9108832807570978
dev_label=MISC_f-score_tok: 0.9009360374414978
dev_label=ORG_precision_tok: 0.937100737100737
dev_label=ORG_recall_tok: 0.9115678776290631
dev_label=ORG_f-score_tok: 0.9241579840077538
dev_label=PER_precision_tok: 0.9726587052168447
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9777286368662139
dev_precision_macro_tok: 0.9515513121178302
dev_recall_macro_tok: 0.9532704790519027
dev_f-score_macro_tok: 0.9523477299461364
dev_precision_micro_tok: 0.9890775281336397
dev_recall_micro_tok: 0.9890775281336397
dev_f-score_micro_tok: 0.9890775281336397
dev_time: 24.51208186149597
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9856    0.9519    0.9685       645
           1     0.9882    0.9965    0.9924      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9869    0.9742    0.9804      3250
weighted avg     0.9877    0.9877    0.9876      3250

F1-macro sent:  0.9804044993681205
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9969    0.9970     42759
         LOC     0.9596    0.9642    0.9619      2094
        MISC     0.8912    0.9109    0.9009      1268
         ORG     0.9371    0.9116    0.9242      2092
         PER     0.9727    0.9829    0.9777      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9516    0.9533    0.9523     51362
weighted avg     0.9891    0.9891    0.9891     51362

F1-macro tok:  0.9523477299461364
F1-micro tok:  0.9890775281336397
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 0.810000
train_cost_sum: 306573.0115966797
train_cost_avg: 21.83412944923294
train_count_sent: 14041.0
train_total_correct_sent: 13829.0
train_accuracy_sent: 0.9849013603019728
train_count_tok: 203621.0
train_total_correct_tok: 201863.0
train_accuracy_tok: 0.9913663129048575
train_label=0_precision_sent: 0.9651604001379787
train_label=0_recall_sent: 0.9618425575799243
train_label=0_f-score_sent: 0.9634986225895317
train_label=1_precision_sent: 0.9900376952073237
train_label=1_recall_sent: 0.9909270571325908
train_label=1_f-score_sent: 0.9904821765286881
train_precision_macro_sent: 0.9775990476726512
train_recall_macro_sent: 0.9763848073562575
train_f-score_macro_sent: 0.9769903995591098
train_precision_micro_sent: 0.9849013603019728
train_recall_micro_sent: 0.9849013603019728
train_f-score_micro_sent: 0.9849013603019728
train_label=O_precision_tok: 0.99739984080658
train_label=O_recall_tok: 0.9975586455790256
train_label=O_f-score_tok: 0.997479236872131
train_label=LOC_precision_tok: 0.9638205499276411
train_label=LOC_recall_tok: 0.9632397252018802
train_label=LOC_f-score_tok: 0.9635300500331545
train_label=MISC_precision_tok: 0.9346145350121493
train_label=MISC_recall_tok: 0.9211844110603091
train_label=MISC_f-score_tok: 0.9278508771929824
train_label=ORG_precision_tok: 0.9494919306634788
train_label=ORG_recall_tok: 0.9507231920199501
train_label=ORG_f-score_tok: 0.9501071624383193
train_label=PER_precision_tok: 0.9808226543597096
train_label=PER_recall_tok: 0.9835549964054637
train_label=PER_f-score_tok: 0.9821869251132948
train_precision_macro_tok: 0.9652299021539117
train_recall_macro_tok: 0.9632521940533257
train_f-score_macro_tok: 0.9642308503299765
train_precision_micro_tok: 0.9913663129048575
train_recall_micro_tok: 0.9913663129048575
train_f-score_micro_tok: 0.9913663129048575
train_time: 241.83790040016174
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9652    0.9618    0.9635      2909
           1     0.9900    0.9909    0.9905     11132

   micro avg     0.9849    0.9849    0.9849     14041
   macro avg     0.9776    0.9764    0.9770     14041
weighted avg     0.9849    0.9849    0.9849     14041

F1-macro sent:  0.9769903995591098
F1-micro sent:  0.9849013603019728
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9974    0.9976    0.9975    169578
         LOC     0.9638    0.9632    0.9635      8297
        MISC     0.9346    0.9212    0.9279      4593
         ORG     0.9495    0.9507    0.9501     10025
         PER     0.9808    0.9836    0.9822     11128

   micro avg     0.9914    0.9914    0.9914    203621
   macro avg     0.9652    0.9633    0.9642    203621
weighted avg     0.9914    0.9914    0.9914    203621

F1-macro tok:  0.9642308503299765
F1-micro tok:  0.9913663129048575
**************************************************
dev_cost_sum: 84017.05841445923
dev_cost_avg: 25.851402589064378
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50767.0
dev_accuracy_tok: 0.988415560141739
dev_label=0_precision_sent: 0.9721792890262752
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9736842105263158
dev_label=1_precision_sent: 0.9938532462543219
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9934715821812595
dev_precision_macro_sent: 0.9830162676402985
dev_recall_macro_sent: 0.984142004791025
dev_f-score_macro_sent: 0.9835778963537877
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9959144604753234
dev_label=O_recall_tok: 0.9976613110690147
dev_label=O_f-score_tok: 0.9967871204420923
dev_label=LOC_precision_tok: 0.9504672897196261
dev_label=LOC_recall_tok: 0.9713467048710601
dev_label=LOC_f-score_tok: 0.9607935758148323
dev_label=MISC_precision_tok: 0.8732824427480916
dev_label=MISC_recall_tok: 0.9022082018927445
dev_label=MISC_f-score_tok: 0.887509697439876
dev_label=ORG_precision_tok: 0.9622839182818229
dev_label=ORG_recall_tok: 0.8781070745697896
dev_label=ORG_f-score_tok: 0.918270432391902
dev_label=PER_precision_tok: 0.9760176711896498
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9791073124406459
dev_precision_macro_tok: 0.9515931564829028
dev_recall_macro_tok: 0.9463079738187246
dev_f-score_macro_tok: 0.9484936277058698
dev_precision_micro_tok: 0.988415560141739
dev_recall_micro_tok: 0.988415560141739
dev_f-score_micro_tok: 0.988415560141739
dev_time: 24.53379797935486
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9722    0.9752    0.9737       645
           1     0.9939    0.9931    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9830    0.9841    0.9836      3250
weighted avg     0.9896    0.9895    0.9895      3250

F1-macro sent:  0.9835778963537877
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9977    0.9968     42759
         LOC     0.9505    0.9713    0.9608      2094
        MISC     0.8733    0.9022    0.8875      1268
         ORG     0.9623    0.8781    0.9183      2092
         PER     0.9760    0.9822    0.9791      3149

   micro avg     0.9884    0.9884    0.9884     51362
   macro avg     0.9516    0.9463    0.9485     51362
weighted avg     0.9884    0.9884    0.9883     51362

F1-macro tok:  0.9484936277058698
F1-micro tok:  0.988415560141739
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 305072.0571594238
train_cost_avg: 21.727231476349534
train_count_sent: 14041.0
train_total_correct_sent: 13842.0
train_accuracy_sent: 0.9858272202834556
train_count_tok: 203621.0
train_total_correct_tok: 201979.0
train_accuracy_tok: 0.9919359987427623
train_label=0_precision_sent: 0.9649965682910089
train_label=0_recall_sent: 0.9666552079752492
train_label=0_f-score_sent: 0.9658251760261033
train_label=1_precision_sent: 0.9912824660735149
train_label=1_recall_sent: 0.9908372260150916
train_label=1_f-score_sent: 0.9910597960375579
train_precision_macro_sent: 0.9781395171822619
train_recall_macro_sent: 0.9787462169951704
train_f-score_macro_sent: 0.9784424860318306
train_precision_micro_sent: 0.9858272202834556
train_recall_micro_sent: 0.9858272202834556
train_f-score_micro_sent: 0.9858272202834556
train_label=O_precision_tok: 0.9974591458957247
train_label=O_recall_tok: 0.997753246293741
train_label=O_f-score_tok: 0.9976061744190845
train_label=LOC_precision_tok: 0.9649777349861596
train_label=LOC_recall_tok: 0.966373387971556
train_label=LOC_f-score_tok: 0.9656750572082381
train_label=MISC_precision_tok: 0.9355404516553387
train_label=MISC_recall_tok: 0.9290224254300021
train_label=MISC_f-score_tok: 0.9322700458815818
train_label=ORG_precision_tok: 0.956025242912952
train_label=ORG_recall_tok: 0.9520199501246883
train_label=ORG_f-score_tok: 0.9540183926429429
train_label=PER_precision_tok: 0.983213644524237
train_label=PER_recall_tok: 0.9842739036664271
train_label=PER_f-score_tok: 0.9837434884138674
train_precision_macro_tok: 0.9674432439948824
train_recall_macro_tok: 0.965888582697283
train_f-score_macro_tok: 0.9666626317131428
train_precision_micro_tok: 0.9919359987427623
train_recall_micro_tok: 0.9919359987427623
train_f-score_micro_tok: 0.9919359987427623
train_time: 240.20057845115662
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9650    0.9667    0.9658      2909
           1     0.9913    0.9908    0.9911     11132

   micro avg     0.9858    0.9858    0.9858     14041
   macro avg     0.9781    0.9787    0.9784     14041
weighted avg     0.9858    0.9858    0.9858     14041

F1-macro sent:  0.9784424860318306
F1-micro sent:  0.9858272202834556
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9975    0.9978    0.9976    169578
         LOC     0.9650    0.9664    0.9657      8297
        MISC     0.9355    0.9290    0.9323      4593
         ORG     0.9560    0.9520    0.9540     10025
         PER     0.9832    0.9843    0.9837     11128

   micro avg     0.9919    0.9919    0.9919    203621
   macro avg     0.9674    0.9659    0.9667    203621
weighted avg     0.9919    0.9919    0.9919    203621

F1-macro tok:  0.9666626317131428
F1-micro tok:  0.9919359987427623
**************************************************
dev_cost_sum: 83601.0325088501
dev_cost_avg: 25.723394618107722
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50821.0
dev_accuracy_tok: 0.9894669210700517
dev_label=0_precision_sent: 0.9735202492211839
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.9712509712509713
dev_label=1_precision_sent: 0.9923312883435583
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9929023594859007
dev_precision_macro_sent: 0.9829257687823711
dev_recall_macro_sent: 0.9812331681768811
dev_f-score_macro_sent: 0.982076665368436
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9962866951586913
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9969852064783005
dev_label=LOC_precision_tok: 0.9612995699952221
dev_label=LOC_recall_tok: 0.9608404966571156
dev_label=LOC_f-score_tok: 0.9610699785048962
dev_label=MISC_precision_tok: 0.9176854115729421
dev_label=MISC_recall_tok: 0.88801261829653
dev_label=MISC_f-score_tok: 0.9026052104208416
dev_label=ORG_precision_tok: 0.943359375
dev_label=ORG_recall_tok: 0.9235181644359465
dev_label=ORG_f-score_tok: 0.9333333333333333
dev_label=PER_precision_tok: 0.9735433070866142
dev_label=PER_recall_tok: 0.9815814544299778
dev_label=PER_f-score_tok: 0.9775458570524984
dev_precision_macro_tok: 0.9584348717626939
dev_recall_macro_tok: 0.9503274863555788
dev_f-score_macro_tok: 0.9543079171579739
dev_precision_micro_tok: 0.9894669210700517
dev_recall_micro_tok: 0.9894669210700517
dev_f-score_micro_tok: 0.9894669210700517
dev_time: 24.59708523750305
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9735    0.9690    0.9713       645
           1     0.9923    0.9935    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9829    0.9812    0.9821      3250
weighted avg     0.9886    0.9886    0.9886      3250

F1-macro sent:  0.982076665368436
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9977    0.9970     42759
         LOC     0.9613    0.9608    0.9611      2094
        MISC     0.9177    0.8880    0.9026      1268
         ORG     0.9434    0.9235    0.9333      2092
         PER     0.9735    0.9816    0.9775      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9584    0.9503    0.9543     51362
weighted avg     0.9894    0.9895    0.9894     51362

F1-macro tok:  0.9543079171579739
F1-micro tok:  0.9894669210700517
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 303476.4503479004
train_cost_avg: 21.613592361505617
train_count_sent: 14041.0
train_total_correct_sent: 13859.0
train_accuracy_sent: 0.9870379602592408
train_count_tok: 203621.0
train_total_correct_tok: 202076.0
train_accuracy_tok: 0.992412373969286
train_label=0_precision_sent: 0.9690402476780186
train_label=0_recall_sent: 0.9683740116878653
train_label=0_f-score_sent: 0.968707015130674
train_label=1_precision_sent: 0.9917370217352255
train_label=1_recall_sent: 0.9919151994250809
train_label=1_f-score_sent: 0.9918261025779216
train_precision_macro_sent: 0.980388634706622
train_recall_macro_sent: 0.9801446055564731
train_f-score_macro_sent: 0.9802665588542978
train_precision_micro_sent: 0.9870379602592408
train_recall_micro_sent: 0.9870379602592408
train_f-score_micro_sent: 0.9870379602592408
train_label=O_precision_tok: 0.9976007875547486
train_label=O_recall_tok: 0.9979596409911663
train_label=O_f-score_tok: 0.9977801820073875
train_label=LOC_precision_tok: 0.9692140528793916
train_label=LOC_recall_tok: 0.9675786428829698
train_label=LOC_f-score_tok: 0.9683956574185766
train_label=MISC_precision_tok: 0.9418245923314236
train_label=MISC_recall_tok: 0.9305464837796648
train_label=MISC_f-score_tok: 0.9361515715693791
train_label=ORG_precision_tok: 0.9564869460838251
train_label=ORG_recall_tok: 0.9538154613466334
train_label=ORG_f-score_tok: 0.9551493357306963
train_label=PER_precision_tok: 0.9835184521676819
train_label=PER_recall_tok: 0.9867002156721782
train_label=PER_f-score_tok: 0.9851067647586578
train_precision_macro_tok: 0.9697289662034141
train_recall_macro_tok: 0.9673200889345225
train_f-score_macro_tok: 0.9685167022969395
train_precision_micro_tok: 0.992412373969286
train_recall_micro_tok: 0.992412373969286
train_f-score_micro_tok: 0.992412373969286
train_time: 239.57237672805786
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9690    0.9684    0.9687      2909
           1     0.9917    0.9919    0.9918     11132

   micro avg     0.9870    0.9870    0.9870     14041
   macro avg     0.9804    0.9801    0.9803     14041
weighted avg     0.9870    0.9870    0.9870     14041

F1-macro sent:  0.9802665588542978
F1-micro sent:  0.9870379602592408
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9976    0.9980    0.9978    169578
         LOC     0.9692    0.9676    0.9684      8297
        MISC     0.9418    0.9305    0.9362      4593
         ORG     0.9565    0.9538    0.9551     10025
         PER     0.9835    0.9867    0.9851     11128

   micro avg     0.9924    0.9924    0.9924    203621
   macro avg     0.9697    0.9673    0.9685    203621
weighted avg     0.9924    0.9924    0.9924    203621

F1-macro tok:  0.9685167022969395
F1-micro tok:  0.992412373969286
**************************************************
dev_cost_sum: 83460.80808639526
dev_cost_avg: 25.680248641967772
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50815.0
dev_accuracy_tok: 0.9893501031891282
dev_label=0_precision_sent: 0.9766355140186916
dev_label=0_recall_sent: 0.9720930232558139
dev_label=0_f-score_sent: 0.9743589743589743
dev_label=1_precision_sent: 0.9930981595092024
dev_label=1_recall_sent: 0.9942418426103646
dev_label=1_f-score_sent: 0.9936696719739113
dev_precision_macro_sent: 0.984866836763947
dev_recall_macro_sent: 0.9831674329330893
dev_f-score_macro_sent: 0.9840143231664429
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9959152233789272
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.9968808775598416
dev_label=LOC_precision_tok: 0.9619047619047619
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9632808774439676
dev_label=MISC_precision_tok: 0.9219917012448133
dev_label=MISC_recall_tok: 0.8761829652996845
dev_label=MISC_f-score_tok: 0.8985038414880713
dev_label=ORG_precision_tok: 0.9454905847373637
dev_label=ORG_recall_tok: 0.9120458891013384
dev_label=ORG_f-score_tok: 0.9284671532846716
dev_label=PER_precision_tok: 0.9724741945573976
dev_label=PER_recall_tok: 0.987297554779295
dev_label=PER_f-score_tok: 0.9798298140560984
dev_precision_macro_tok: 0.9595552931646528
dev_recall_macro_tok: 0.9476071502742904
dev_f-score_macro_tok: 0.95339251276653
dev_precision_micro_tok: 0.9893501031891282
dev_recall_micro_tok: 0.9893501031891282
dev_f-score_micro_tok: 0.9893501031891282
dev_time: 24.336877822875977
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9766    0.9721    0.9744       645
           1     0.9931    0.9942    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9849    0.9832    0.9840      3250
weighted avg     0.9898    0.9898    0.9898      3250

F1-macro sent:  0.9840143231664429
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9978    0.9969     42759
         LOC     0.9619    0.9647    0.9633      2094
        MISC     0.9220    0.8762    0.8985      1268
         ORG     0.9455    0.9120    0.9285      2092
         PER     0.9725    0.9873    0.9798      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9596    0.9476    0.9534     51362
weighted avg     0.9892    0.9894    0.9893     51362

F1-macro tok:  0.95339251276653
F1-micro tok:  0.9893501031891282
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.656100
train_cost_sum: 302219.59439086914
train_cost_avg: 21.524079082036117
train_count_sent: 14041.0
train_total_correct_sent: 13879.0
train_accuracy_sent: 0.9884623602307528
train_count_tok: 203621.0
train_total_correct_tok: 202137.0
train_accuracy_tok: 0.992711950142667
train_label=0_precision_sent: 0.971830985915493
train_label=0_recall_sent: 0.9724991405981437
train_label=0_f-score_sent: 0.9721649484536082
train_label=1_precision_sent: 0.9928122192273136
train_label=1_recall_sent: 0.9926338483650736
train_label=1_f-score_sent: 0.9927230257838469
train_precision_macro_sent: 0.9823216025714032
train_recall_macro_sent: 0.9825664944816086
train_f-score_macro_sent: 0.9824439871187276
train_precision_micro_sent: 0.9884623602307528
train_recall_micro_sent: 0.9884623602307528
train_f-score_micro_sent: 0.9884623602307528
train_label=O_precision_tok: 0.9976890062726973
train_label=O_recall_tok: 0.9979596409911663
train_label=O_f-score_tok: 0.9978243052812189
train_label=LOC_precision_tok: 0.9696823869104908
train_label=LOC_recall_tok: 0.9714354585994938
train_label=LOC_f-score_tok: 0.9705581311337227
train_label=MISC_precision_tok: 0.9444811632518176
train_label=MISC_recall_tok: 0.9333768778576094
train_label=MISC_f-score_tok: 0.9388961892247043
train_label=ORG_precision_tok: 0.9582083583283343
train_label=ORG_recall_tok: 0.9560099750623441
train_label=ORG_f-score_tok: 0.9571079043291556
train_label=PER_precision_tok: 0.9847451543431442
train_label=PER_recall_tok: 0.9861610352264558
train_label=PER_f-score_tok: 0.9854525862068966
train_precision_macro_tok: 0.9709612138212969
train_recall_macro_tok: 0.968988597547414
train_f-score_macro_tok: 0.9699678232351395
train_precision_micro_tok: 0.992711950142667
train_recall_micro_tok: 0.992711950142667
train_f-score_micro_tok: 0.992711950142667
train_time: 242.33461332321167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9718    0.9725    0.9722      2909
           1     0.9928    0.9926    0.9927     11132

   micro avg     0.9885    0.9885    0.9885     14041
   macro avg     0.9823    0.9826    0.9824     14041
weighted avg     0.9885    0.9885    0.9885     14041

F1-macro sent:  0.9824439871187276
F1-micro sent:  0.9884623602307528
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9977    0.9980    0.9978    169578
         LOC     0.9697    0.9714    0.9706      8297
        MISC     0.9445    0.9334    0.9389      4593
         ORG     0.9582    0.9560    0.9571     10025
         PER     0.9847    0.9862    0.9855     11128

   micro avg     0.9927    0.9927    0.9927    203621
   macro avg     0.9710    0.9690    0.9700    203621
weighted avg     0.9927    0.9927    0.9927    203621

F1-macro tok:  0.9699678232351395
F1-micro tok:  0.992711950142667
**************************************************
dev_cost_sum: 83347.78775787354
dev_cost_avg: 25.64547315626878
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50800.0
dev_accuracy_tok: 0.989058058486819
dev_label=0_precision_sent: 0.9604261796042618
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9692780337941628
dev_label=1_precision_sent: 0.9946008484381026
dev_label=1_recall_sent: 0.9900191938579654
dev_label=1_f-score_sent: 0.9923047325894575
dev_precision_macro_sent: 0.9775135140211821
dev_recall_macro_sent: 0.9841568837506882
dev_f-score_macro_sent: 0.9807913831918101
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.9961701928915043
dev_label=O_recall_tok: 0.9976379241797049
dev_label=O_f-score_tok: 0.9969035183042965
dev_label=LOC_precision_tok: 0.9636363636363636
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.9627151051625239
dev_label=MISC_precision_tok: 0.8966061562746646
dev_label=MISC_recall_tok: 0.8958990536277602
dev_label=MISC_f-score_tok: 0.8962524654832348
dev_label=ORG_precision_tok: 0.9484742371185593
dev_label=ORG_recall_tok: 0.9063097514340345
dev_label=ORG_f-score_tok: 0.9269127352725495
dev_label=PER_precision_tok: 0.9723618090452262
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9777356702984368
dev_precision_macro_tok: 0.9554497517932635
dev_recall_macro_tok: 0.9489623191637623
dev_f-score_macro_tok: 0.9521038989042083
dev_precision_micro_tok: 0.989058058486819
dev_recall_micro_tok: 0.989058058486819
dev_f-score_micro_tok: 0.989058058486819
dev_time: 24.470035791397095
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9604    0.9783    0.9693       645
           1     0.9946    0.9900    0.9923      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9775    0.9842    0.9808      3250
weighted avg     0.9878    0.9877    0.9877      3250

F1-macro sent:  0.9807913831918101
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9976    0.9969     42759
         LOC     0.9636    0.9618    0.9627      2094
        MISC     0.8966    0.8959    0.8963      1268
         ORG     0.9485    0.9063    0.9269      2092
         PER     0.9724    0.9832    0.9777      3149

   micro avg     0.9891    0.9891    0.9891     51362
   macro avg     0.9554    0.9490    0.9521     51362
weighted avg     0.9890    0.9891    0.9890     51362

F1-macro tok:  0.9521038989042083
F1-micro tok:  0.989058058486819
**************************************************
Best epoch: 16
**************************************************

EPOCH: 23
Learning rate: 0.590490
train_cost_sum: 301123.23974609375
train_cost_avg: 21.445996705796862
train_count_sent: 14041.0
train_total_correct_sent: 13876.0
train_accuracy_sent: 0.988248700235026
train_count_tok: 203621.0
train_total_correct_tok: 202222.0
train_accuracy_tok: 0.9931293923514766
train_label=0_precision_sent: 0.9695414099931554
train_label=0_recall_sent: 0.9738741835682365
train_label=0_f-score_sent: 0.9717029669010462
train_label=1_precision_sent: 0.9931648529544024
train_label=1_recall_sent: 0.9920050305425799
train_label=1_f-score_sent: 0.9925846029391938
train_precision_macro_sent: 0.9813531314737789
train_recall_macro_sent: 0.9829396070554082
train_f-score_macro_sent: 0.98214378492012
train_precision_micro_sent: 0.988248700235026
train_recall_micro_sent: 0.988248700235026
train_f-score_micro_sent: 0.988248700235026
train_label=O_precision_tok: 0.9976890062726973
train_label=O_recall_tok: 0.9979596409911663
train_label=O_f-score_tok: 0.9978243052812189
train_label=LOC_precision_tok: 0.970584704046104
train_label=LOC_recall_tok: 0.9743280703868868
train_label=LOC_f-score_tok: 0.9724527847948996
train_label=MISC_precision_tok: 0.9503311258278145
train_label=MISC_recall_tok: 0.9372958850424559
train_label=MISC_f-score_tok: 0.9437684972048669
train_label=ORG_precision_tok: 0.962784632360317
train_label=ORG_recall_tok: 0.9574064837905237
train_label=ORG_f-score_tok: 0.9600880264079225
train_label=PER_precision_tok: 0.9851374339690214
train_label=PER_recall_tok: 0.9887670740474479
train_label=PER_f-score_tok: 0.9869489168946495
train_precision_macro_tok: 0.9733053804951908
train_recall_macro_tok: 0.9711514308516961
train_f-score_macro_tok: 0.9722165061167114
train_precision_micro_tok: 0.9931293923514766
train_recall_micro_tok: 0.9931293923514766
train_f-score_micro_tok: 0.9931293923514766
train_time: 241.6760036945343
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9695    0.9739    0.9717      2909
           1     0.9932    0.9920    0.9926     11132

   micro avg     0.9882    0.9882    0.9882     14041
   macro avg     0.9814    0.9829    0.9821     14041
weighted avg     0.9883    0.9882    0.9883     14041

F1-macro sent:  0.98214378492012
F1-micro sent:  0.988248700235026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9977    0.9980    0.9978    169578
         LOC     0.9706    0.9743    0.9725      8297
        MISC     0.9503    0.9373    0.9438      4593
         ORG     0.9628    0.9574    0.9601     10025
         PER     0.9851    0.9888    0.9869     11128

   micro avg     0.9931    0.9931    0.9931    203621
   macro avg     0.9733    0.9712    0.9722    203621
weighted avg     0.9931    0.9931    0.9931    203621

F1-macro tok:  0.9722165061167114
F1-micro tok:  0.9931293923514766
**************************************************
dev_cost_sum: 83064.19086074829
dev_cost_avg: 25.558212572537936
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50798.0
dev_accuracy_tok: 0.9890191191931779
dev_label=0_precision_sent: 0.9842767295597484
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9773614363778299
dev_label=1_precision_sent: 0.9927314460596787
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9944433799578463
dev_precision_macro_sent: 0.9885040878097135
dev_recall_macro_sent: 0.9833519320329123
dev_f-score_macro_sent: 0.985902408167838
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9962397234678625
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9969033011977797
dev_label=LOC_precision_tok: 0.956953642384106
dev_label=LOC_recall_tok: 0.9660936007640879
dev_label=LOC_f-score_tok: 0.9615019011406843
dev_label=MISC_precision_tok: 0.9035369774919614
dev_label=MISC_recall_tok: 0.886435331230284
dev_label=MISC_f-score_tok: 0.8949044585987261
dev_label=ORG_precision_tok: 0.9477351916376306
dev_label=ORG_recall_tok: 0.9101338432122371
dev_label=ORG_f-score_tok: 0.9285540112167763
dev_label=PER_precision_tok: 0.9726329034287512
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.97724399494311
dev_precision_macro_tok: 0.9554196876820624
dev_recall_macro_tok: 0.948425910855776
dev_f-score_macro_tok: 0.9518215334194153
dev_precision_micro_tok: 0.9890191191931779
dev_recall_micro_tok: 0.9890191191931779
dev_f-score_micro_tok: 0.9890191191931779
dev_time: 24.574348211288452
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9843    0.9705    0.9774       645
           1     0.9927    0.9962    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9885    0.9834    0.9859      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.985902408167838
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9976    0.9969     42759
         LOC     0.9570    0.9661    0.9615      2094
        MISC     0.9035    0.8864    0.8949      1268
         ORG     0.9477    0.9101    0.9286      2092
         PER     0.9726    0.9819    0.9772      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9554    0.9484    0.9518     51362
weighted avg     0.9889    0.9890    0.9890     51362

F1-macro tok:  0.9518215334194153
F1-micro tok:  0.9890191191931779
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 0.590490
train_cost_sum: 300164.08282470703
train_cost_avg: 21.377685551221923
train_count_sent: 14041.0
train_total_correct_sent: 13902.0
train_accuracy_sent: 0.9901004201979916
train_count_tok: 203621.0
train_total_correct_tok: 202296.0
train_accuracy_tok: 0.9934928126273813
train_label=0_precision_sent: 0.9769283746556474
train_label=0_recall_sent: 0.9752492265383294
train_label=0_f-score_sent: 0.976088078444865
train_label=1_precision_sent: 0.9935350633025052
train_label=1_recall_sent: 0.9939813151275602
train_label=1_f-score_sent: 0.9937581391171584
train_precision_macro_sent: 0.9852317189790762
train_recall_macro_sent: 0.9846152708329448
train_f-score_macro_sent: 0.9849231087810117
train_precision_micro_sent: 0.9901004201979916
train_recall_micro_sent: 0.9901004201979916
train_f-score_micro_sent: 0.9901004201979916
train_label=O_precision_tok: 0.9979423504371768
train_label=O_recall_tok: 0.9981365507318166
train_label=O_f-score_tok: 0.998039441137537
train_label=LOC_precision_tok: 0.9734779987944545
train_label=LOC_recall_tok: 0.9732433409666145
train_label=LOC_f-score_tok: 0.9733606557377049
train_label=MISC_precision_tok: 0.9516164504068617
train_label=MISC_recall_tok: 0.9420857827128238
train_label=MISC_f-score_tok: 0.9468271334792123
train_label=ORG_precision_tok: 0.9622980251346499
train_label=ORG_recall_tok: 0.9623940149625935
train_label=ORG_f-score_tok: 0.9623460176549797
train_label=PER_precision_tok: 0.985819422006821
train_label=PER_recall_tok: 0.98705966930266
train_label=PER_f-score_tok: 0.9864391558149977
train_precision_macro_tok: 0.9742308493559928
train_recall_macro_tok: 0.9725838717353017
train_f-score_macro_tok: 0.9734024807648863
train_precision_micro_tok: 0.9934928126273813
train_recall_micro_tok: 0.9934928126273813
train_f-score_micro_tok: 0.9934928126273813
train_time: 240.78353476524353
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9769    0.9752    0.9761      2909
           1     0.9935    0.9940    0.9938     11132

   micro avg     0.9901    0.9901    0.9901     14041
   macro avg     0.9852    0.9846    0.9849     14041
weighted avg     0.9901    0.9901    0.9901     14041

F1-macro sent:  0.9849231087810117
F1-micro sent:  0.9901004201979916
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9979    0.9981    0.9980    169578
         LOC     0.9735    0.9732    0.9734      8297
        MISC     0.9516    0.9421    0.9468      4593
         ORG     0.9623    0.9624    0.9623     10025
         PER     0.9858    0.9871    0.9864     11128

   micro avg     0.9935    0.9935    0.9935    203621
   macro avg     0.9742    0.9726    0.9734    203621
weighted avg     0.9935    0.9935    0.9935    203621

F1-macro tok:  0.9734024807648863
F1-micro tok:  0.9934928126273813
**************************************************
dev_cost_sum: 82833.98998641968
dev_cost_avg: 25.487381534282978
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50810.0
dev_accuracy_tok: 0.9892527549550251
dev_label=0_precision_sent: 0.9738863287250384
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9783950617283951
dev_label=1_precision_sent: 0.9957676029242016
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.994619523443505
dev_precision_macro_sent: 0.98482696582462
dev_recall_macro_sent: 0.9882099123629275
dev_f-score_macro_sent: 0.98650729258595
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9963102216202331
dev_label=O_recall_tok: 0.9977548586262541
dev_label=O_f-score_tok: 0.9970320168263613
dev_label=LOC_precision_tok: 0.9631931166347992
dev_label=LOC_recall_tok: 0.9622731614135626
dev_label=LOC_f-score_tok: 0.9627329192546583
dev_label=MISC_precision_tok: 0.8986539984164688
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.8968787040695377
dev_label=ORG_precision_tok: 0.9504752376188094
dev_label=ORG_recall_tok: 0.9082217973231358
dev_label=ORG_f-score_tok: 0.9288682473722806
dev_label=PER_precision_tok: 0.9717602761217445
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9775883838383838
dev_precision_macro_tok: 0.9560785700824109
dev_recall_macro_tok: 0.9493694097341348
dev_f-score_macro_tok: 0.9526200542722444
dev_precision_micro_tok: 0.9892527549550251
dev_recall_micro_tok: 0.9892527549550251
dev_f-score_micro_tok: 0.9892527549550251
dev_time: 24.549880743026733
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9739    0.9829    0.9784       645
           1     0.9958    0.9935    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9848    0.9882    0.9865      3250
weighted avg     0.9914    0.9914    0.9914      3250

F1-macro sent:  0.98650729258595
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9970     42759
         LOC     0.9632    0.9623    0.9627      2094
        MISC     0.8987    0.8951    0.8969      1268
         ORG     0.9505    0.9082    0.9289      2092
         PER     0.9718    0.9835    0.9776      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9561    0.9494    0.9526     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9526200542722444
F1-micro tok:  0.9892527549550251
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 0.590490
train_cost_sum: 299133.8501281738
train_cost_avg: 21.304312380042294
train_count_sent: 14041.0
train_total_correct_sent: 13902.0
train_accuracy_sent: 0.9901004201979916
train_count_tok: 203621.0
train_total_correct_tok: 202409.0
train_accuracy_tok: 0.9940477652108575
train_label=0_precision_sent: 0.9759450171821306
train_label=0_recall_sent: 0.9762805087658989
train_label=0_f-score_sent: 0.9761127341467606
train_label=1_precision_sent: 0.9938010960380919
train_label=1_recall_sent: 0.9937118217750629
train_label=1_f-score_sent: 0.9937564569015856
train_precision_macro_sent: 0.9848730566101112
train_recall_macro_sent: 0.9849961652704808
train_f-score_macro_sent: 0.9849345955241731
train_precision_micro_sent: 0.9901004201979916
train_recall_micro_sent: 0.9901004201979916
train_f-score_micro_sent: 0.9901004201979916
train_label=O_precision_tok: 0.9980488322467314
train_label=O_recall_tok: 0.9984255033082121
train_label=O_f-score_tok: 0.998237132244561
train_label=LOC_precision_tok: 0.9740995060836044
train_label=LOC_recall_tok: 0.9745691213691696
train_label=LOC_f-score_tok: 0.9743342571394145
train_label=MISC_precision_tok: 0.9601233751927737
train_label=MISC_recall_tok: 0.9488351839756151
train_label=MISC_f-score_tok: 0.9544459045116075
train_label=ORG_precision_tok: 0.9653173413293353
train_label=ORG_recall_tok: 0.9633915211970074
train_label=ORG_f-score_tok: 0.964353469795307
train_label=PER_precision_tok: 0.9876055326028381
train_label=PER_recall_tok: 0.988138030194105
train_label=PER_f-score_tok: 0.9878717096397448
train_precision_macro_tok: 0.9770389174910565
train_recall_macro_tok: 0.9746718720088218
train_f-score_macro_tok: 0.975848494666127
train_precision_micro_tok: 0.9940477652108575
train_recall_micro_tok: 0.9940477652108575
train_f-score_micro_tok: 0.9940477652108575
train_time: 241.9339816570282
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9759    0.9763    0.9761      2909
           1     0.9938    0.9937    0.9938     11132

   micro avg     0.9901    0.9901    0.9901     14041
   macro avg     0.9849    0.9850    0.9849     14041
weighted avg     0.9901    0.9901    0.9901     14041

F1-macro sent:  0.9849345955241731
F1-micro sent:  0.9901004201979916
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9984    0.9982    169578
         LOC     0.9741    0.9746    0.9743      8297
        MISC     0.9601    0.9488    0.9544      4593
         ORG     0.9653    0.9634    0.9644     10025
         PER     0.9876    0.9881    0.9879     11128

   micro avg     0.9940    0.9940    0.9940    203621
   macro avg     0.9770    0.9747    0.9758    203621
weighted avg     0.9940    0.9940    0.9940    203621

F1-macro tok:  0.975848494666127
F1-micro tok:  0.9940477652108575
**************************************************
dev_cost_sum: 82982.27057647705
dev_cost_avg: 25.533006331223707
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50817.0
dev_accuracy_tok: 0.9893890424827694
dev_label=0_precision_sent: 0.9723076923076923
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9760617760617761
dev_label=1_precision_sent: 0.995
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9940441882804996
dev_precision_macro_sent: 0.9836538461538462
dev_recall_macro_sent: 0.9864675861863739
dev_f-score_macro_sent: 0.9850529821711378
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.996774947417621
dev_label=O_recall_tok: 0.9974976028438457
dev_label=O_f-score_tok: 0.9971361441980618
dev_label=LOC_precision_tok: 0.9587090650213573
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9616757914782195
dev_label=MISC_precision_tok: 0.9197379197379197
dev_label=MISC_recall_tok: 0.8856466876971609
dev_label=MISC_f-score_tok: 0.9023704298915228
dev_label=ORG_precision_tok: 0.9432938856015779
dev_label=ORG_recall_tok: 0.9144359464627151
dev_label=ORG_f-score_tok: 0.9286407766990291
dev_label=PER_precision_tok: 0.966728855721393
dev_label=PER_recall_tok: 0.987297554779295
dev_label=PER_f-score_tok: 0.9769049489395131
dev_precision_macro_tok: 0.9570489346999738
dev_recall_macro_tok: 0.9499077455581315
dev_f-score_macro_tok: 0.9533456182412692
dev_precision_micro_tok: 0.9893890424827694
dev_recall_micro_tok: 0.9893890424827694
dev_f-score_micro_tok: 0.9893890424827694
dev_time: 24.509867429733276
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9723    0.9798    0.9761       645
           1     0.9950    0.9931    0.9940      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9837    0.9865    0.9851      3250
weighted avg     0.9905    0.9905    0.9905      3250

F1-macro sent:  0.9850529821711378
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9975    0.9971     42759
         LOC     0.9587    0.9647    0.9617      2094
        MISC     0.9197    0.8856    0.9024      1268
         ORG     0.9433    0.9144    0.9286      2092
         PER     0.9667    0.9873    0.9769      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9570    0.9499    0.9533     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9533456182412692
F1-micro tok:  0.9893890424827694
**************************************************
Best epoch: 24
**************************************************

EPOCH: 26
Learning rate: 0.590490
train_cost_sum: 298520.05850219727
train_cost_avg: 21.260598141314528
train_count_sent: 14041.0
train_total_correct_sent: 13899.0
train_accuracy_sent: 0.9898867602022648
train_count_tok: 203621.0
train_total_correct_tok: 202358.0
train_accuracy_tok: 0.9937972998855717
train_label=0_precision_sent: 0.9762478485370052
train_label=0_recall_sent: 0.9749054657958062
train_label=0_f-score_sent: 0.9755761953904368
train_label=1_precision_sent: 0.993444683908046
train_label=1_recall_sent: 0.993801652892562
train_label=1_f-score_sent: 0.9936231363391413
train_precision_macro_sent: 0.9848462662225256
train_recall_macro_sent: 0.9843535593441841
train_f-score_macro_sent: 0.9845996658647891
train_precision_micro_sent: 0.9898867602022648
train_recall_micro_sent: 0.9898867602022648
train_f-score_micro_sent: 0.9898867602022648
train_label=O_precision_tok: 0.9980016034332335
train_label=O_recall_tok: 0.998342945429242
train_label=O_f-score_tok: 0.9981722452493116
train_label=LOC_precision_tok: 0.9722055107688605
train_label=LOC_recall_tok: 0.9738459684223213
train_label=LOC_f-score_tok: 0.9730250481695568
train_label=MISC_precision_tok: 0.955956837700947
train_label=MISC_recall_tok: 0.9451338994121489
train_label=MISC_f-score_tok: 0.9505145609809503
train_label=ORG_precision_tok: 0.965813674530188
train_label=ORG_recall_tok: 0.9637905236907731
train_label=ORG_f-score_tok: 0.9648010384941835
train_label=PER_precision_tok: 0.9864318447299847
train_label=PER_recall_tok: 0.9865204888569374
train_label=PER_f-score_tok: 0.9864761648020848
train_precision_macro_tok: 0.9756818942326427
train_recall_macro_tok: 0.9735267651622846
train_f-score_macro_tok: 0.9745978115392173
train_precision_micro_tok: 0.9937972998855717
train_recall_micro_tok: 0.9937972998855717
train_f-score_micro_tok: 0.9937972998855717
train_time: 240.02826166152954
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9762    0.9749    0.9756      2909
           1     0.9934    0.9938    0.9936     11132

   micro avg     0.9899    0.9899    0.9899     14041
   macro avg     0.9848    0.9844    0.9846     14041
weighted avg     0.9899    0.9899    0.9899     14041

F1-macro sent:  0.9845996658647891
F1-micro sent:  0.9898867602022648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9983    0.9982    169578
         LOC     0.9722    0.9738    0.9730      8297
        MISC     0.9560    0.9451    0.9505      4593
         ORG     0.9658    0.9638    0.9648     10025
         PER     0.9864    0.9865    0.9865     11128

   micro avg     0.9938    0.9938    0.9938    203621
   macro avg     0.9757    0.9735    0.9746    203621
weighted avg     0.9938    0.9938    0.9938    203621

F1-macro tok:  0.9745978115392173
F1-micro tok:  0.9937972998855717
**************************************************
dev_cost_sum: 82611.46514129639
dev_cost_avg: 25.418912351168117
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50826.0
dev_accuracy_tok: 0.9895642693041549
dev_label=0_precision_sent: 0.9736842105263158
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9744384198295896
dev_label=1_precision_sent: 0.9938556067588326
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9936648109042043
dev_precision_macro_sent: 0.9837699086425742
dev_recall_macro_sent: 0.9843339433706795
dev_f-score_macro_sent: 0.984051615366897
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9963563320409212
dev_label=O_recall_tok: 0.9976379241797049
dev_label=O_f-score_tok: 0.9969967162539587
dev_label=LOC_precision_tok: 0.9669064748201439
dev_label=LOC_recall_tok: 0.9627507163323782
dev_label=LOC_f-score_tok: 0.964824120603015
dev_label=MISC_precision_tok: 0.9082202713487629
dev_label=MISC_recall_tok: 0.8974763406940063
dev_label=MISC_f-score_tok: 0.9028163427211424
dev_label=ORG_precision_tok: 0.9492031872509961
dev_label=ORG_recall_tok: 0.9110898661567878
dev_label=ORG_f-score_tok: 0.9297560975609757
dev_label=PER_precision_tok: 0.9706433479075578
dev_label=PER_recall_tok: 0.9869799936487774
dev_label=PER_f-score_tok: 0.978743504959849
dev_precision_macro_tok: 0.9582659226736764
dev_recall_macro_tok: 0.9511869682023308
dev_f-score_macro_tok: 0.954627356419788
dev_precision_micro_tok: 0.9895642693041549
dev_recall_micro_tok: 0.9895642693041549
dev_f-score_micro_tok: 0.9895642693041549
dev_time: 24.601196765899658
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9737    0.9752    0.9744       645
           1     0.9939    0.9935    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9838    0.9843    0.9841      3250
weighted avg     0.9899    0.9898    0.9898      3250

F1-macro sent:  0.984051615366897
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9976    0.9970     42759
         LOC     0.9669    0.9628    0.9648      2094
        MISC     0.9082    0.8975    0.9028      1268
         ORG     0.9492    0.9111    0.9298      2092
         PER     0.9706    0.9870    0.9787      3149

   micro avg     0.9896    0.9896    0.9896     51362
   macro avg     0.9583    0.9512    0.9546     51362
weighted avg     0.9895    0.9896    0.9895     51362

F1-macro tok:  0.954627356419788
F1-micro tok:  0.9895642693041549
**************************************************
Best epoch: 24
**************************************************

EPOCH: 27
Learning rate: 0.590490
train_cost_sum: 297829.2797546387
train_cost_avg: 21.211400879897347
train_count_sent: 14041.0
train_total_correct_sent: 13897.0
train_accuracy_sent: 0.9897443202051136
train_count_tok: 203621.0
train_total_correct_tok: 202358.0
train_accuracy_tok: 0.9937972998855717
train_label=0_precision_sent: 0.9713603818615751
train_label=0_recall_sent: 0.9793743554486077
train_label=0_f-score_sent: 0.9753509072235536
train_label=1_precision_sent: 0.9945984875765215
train_label=1_recall_sent: 0.9924541861300754
train_label=1_f-score_sent: 0.993525179856115
train_precision_macro_sent: 0.9829794347190484
train_recall_macro_sent: 0.9859142707893416
train_f-score_macro_sent: 0.9844380435398343
train_precision_micro_sent: 0.9897443202051136
train_recall_micro_sent: 0.9897443202051136
train_f-score_micro_sent: 0.9897443202051136
train_label=O_precision_tok: 0.9979602544376256
train_label=O_recall_tok: 0.9982603875502718
train_label=O_f-score_tok: 0.9981102984313414
train_label=LOC_precision_tok: 0.9748586551184891
train_label=LOC_recall_tok: 0.9767385802097144
train_label=LOC_f-score_tok: 0.9757977122215533
train_label=MISC_precision_tok: 0.9569041336851363
train_label=MISC_recall_tok: 0.9475288482473329
train_label=MISC_f-score_tok: 0.9521934142872771
train_label=ORG_precision_tok: 0.9646823411705853
train_label=ORG_recall_tok: 0.9617955112219452
train_label=ORG_f-score_tok: 0.9632367632367632
train_label=PER_precision_tok: 0.9857219827586207
train_label=PER_recall_tok: 0.986430625449317
train_label=PER_f-score_tok: 0.9860761767876391
train_precision_macro_tok: 0.9760254734340913
train_recall_macro_tok: 0.9741507905357162
train_f-score_macro_tok: 0.9750828729929149
train_precision_micro_tok: 0.9937972998855717
train_recall_micro_tok: 0.9937972998855717
train_f-score_micro_tok: 0.9937972998855717
train_time: 240.79302620887756
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9714    0.9794    0.9754      2909
           1     0.9946    0.9925    0.9935     11132

   micro avg     0.9897    0.9897    0.9897     14041
   macro avg     0.9830    0.9859    0.9844     14041
weighted avg     0.9898    0.9897    0.9898     14041

F1-macro sent:  0.9844380435398343
F1-micro sent:  0.9897443202051136
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9983    0.9981    169578
         LOC     0.9749    0.9767    0.9758      8297
        MISC     0.9569    0.9475    0.9522      4593
         ORG     0.9647    0.9618    0.9632     10025
         PER     0.9857    0.9864    0.9861     11128

   micro avg     0.9938    0.9938    0.9938    203621
   macro avg     0.9760    0.9742    0.9751    203621
weighted avg     0.9938    0.9938    0.9938    203621

F1-macro tok:  0.9750828729929149
F1-micro tok:  0.9937972998855717
**************************************************
dev_cost_sum: 82399.88669586182
dev_cost_avg: 25.353811291034404
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50844.0
dev_accuracy_tok: 0.9899147229469257
dev_label=0_precision_sent: 0.9782945736434109
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9782945736434109
dev_label=1_precision_sent: 0.9946257197696737
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9946257197696737
dev_precision_macro_sent: 0.9864601467065424
dev_recall_macro_sent: 0.9864601467065424
dev_f-score_macro_sent: 0.9864601467065424
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9965422984370255
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9970547673032422
dev_label=LOC_precision_tok: 0.9691566265060241
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9647397457423843
dev_label=MISC_precision_tok: 0.913322632423756
dev_label=MISC_recall_tok: 0.8974763406940063
dev_label=MISC_f-score_tok: 0.9053301511535401
dev_label=ORG_precision_tok: 0.9410058027079303
dev_label=ORG_recall_tok: 0.9302103250478011
dev_label=ORG_f-score_tok: 0.9355769230769231
dev_label=PER_precision_tok: 0.97602523659306
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9792688716569077
dev_precision_macro_tok: 0.9592105193335592
dev_recall_macro_tok: 0.9536303017626826
dev_f-score_macro_tok: 0.9563940917865994
dev_precision_micro_tok: 0.9899147229469257
dev_recall_micro_tok: 0.9899147229469257
dev_f-score_micro_tok: 0.9899147229469257
dev_time: 24.324378490447998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9783    0.9783    0.9783       645
           1     0.9946    0.9946    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9865    0.9865    0.9865      3250
weighted avg     0.9914    0.9914    0.9914      3250

F1-macro sent:  0.9864601467065424
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9976    0.9971     42759
         LOC     0.9692    0.9604    0.9647      2094
        MISC     0.9133    0.8975    0.9053      1268
         ORG     0.9410    0.9302    0.9356      2092
         PER     0.9760    0.9825    0.9793      3149

   micro avg     0.9899    0.9899    0.9899     51362
   macro avg     0.9592    0.9536    0.9564     51362
weighted avg     0.9899    0.9899    0.9899     51362

F1-macro tok:  0.9563940917865994
F1-micro tok:  0.9899147229469257
**************************************************
Best epoch: 24
**************************************************

EPOCH: 28
Learning rate: 0.590490
train_cost_sum: 296823.16064453125
train_cost_avg: 21.139745078308614
train_count_sent: 14041.0
train_total_correct_sent: 13916.0
train_accuracy_sent: 0.99109750017805
train_count_tok: 203621.0
train_total_correct_tok: 202478.0
train_accuracy_tok: 0.9943866300627145
train_label=0_precision_sent: 0.9803312629399586
train_label=0_recall_sent: 0.9766242695084222
train_label=0_f-score_sent: 0.9784742552092303
train_label=1_precision_sent: 0.9938975141344342
train_label=1_recall_sent: 0.9948796263025512
train_label=1_f-score_sent: 0.9943883277216611
train_precision_macro_sent: 0.9871143885371965
train_recall_macro_sent: 0.9857519479054867
train_f-score_macro_sent: 0.9864312914654456
train_precision_micro_sent: 0.99109750017805
train_recall_micro_sent: 0.99109750017805
train_f-score_micro_sent: 0.99109750017805
train_label=O_precision_tok: 0.9982370802747561
train_label=O_recall_tok: 0.9983960183514371
train_label=O_f-score_tok: 0.9983165429871191
train_label=LOC_precision_tok: 0.9767133204633205
train_label=LOC_recall_tok: 0.975653850789442
train_label=LOC_f-score_tok: 0.9761832981609889
train_label=MISC_precision_tok: 0.9602459916538546
train_label=MISC_recall_tok: 0.9518833006749401
train_label=MISC_f-score_tok: 0.9560463590640718
train_label=ORG_precision_tok: 0.9678254806255603
train_label=ORG_recall_tok: 0.9691770573566085
train_label=ORG_f-score_tok: 0.968500797448166
train_label=PER_precision_tok: 0.9867995689655172
train_label=PER_recall_tok: 0.987508986340762
train_label=PER_f-score_tok: 0.9871541501976284
train_precision_macro_tok: 0.9779642883966018
train_recall_macro_tok: 0.9765238427026379
train_f-score_macro_tok: 0.977240229571595
train_precision_micro_tok: 0.9943866300627145
train_recall_micro_tok: 0.9943866300627145
train_f-score_micro_tok: 0.9943866300627145
train_time: 241.15355944633484
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9803    0.9766    0.9785      2909
           1     0.9939    0.9949    0.9944     11132

   micro avg     0.9911    0.9911    0.9911     14041
   macro avg     0.9871    0.9858    0.9864     14041
weighted avg     0.9911    0.9911    0.9911     14041

F1-macro sent:  0.9864312914654456
F1-micro sent:  0.99109750017805
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9984    0.9983    169578
         LOC     0.9767    0.9757    0.9762      8297
        MISC     0.9602    0.9519    0.9560      4593
         ORG     0.9678    0.9692    0.9685     10025
         PER     0.9868    0.9875    0.9872     11128

   micro avg     0.9944    0.9944    0.9944    203621
   macro avg     0.9780    0.9765    0.9772    203621
weighted avg     0.9944    0.9944    0.9944    203621

F1-macro tok:  0.977240229571595
F1-micro tok:  0.9943866300627145
**************************************************
dev_cost_sum: 82291.1019897461
dev_cost_avg: 25.32033907376803
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50833.0
dev_accuracy_tok: 0.9897005568318991
dev_label=0_precision_sent: 0.9649923896499238
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9738863287250384
dev_label=1_precision_sent: 0.9957578094870806
dev_label=1_recall_sent: 0.9911708253358925
dev_label=1_f-score_sent: 0.9934590227010388
dev_precision_macro_sent: 0.9803750995685022
dev_recall_macro_sent: 0.9870582808850006
dev_f-score_macro_sent: 0.9836726757130386
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9964501739881828
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.9971487999252144
dev_label=LOC_precision_tok: 0.9623450905624404
dev_label=LOC_recall_tok: 0.9641833810888252
dev_label=LOC_f-score_tok: 0.963263358778626
dev_label=MISC_precision_tok: 0.9033018867924528
dev_label=MISC_recall_tok: 0.9061514195583596
dev_label=MISC_f-score_tok: 0.9047244094488189
dev_label=ORG_precision_tok: 0.9557344064386318
dev_label=ORG_recall_tok: 0.9082217973231358
dev_label=ORG_f-score_tok: 0.9313725490196079
dev_label=PER_precision_tok: 0.9726844583987441
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.978212819703189
dev_precision_macro_tok: 0.9581032032360903
dev_recall_macro_tok: 0.952041877299483
dev_f-score_macro_tok: 0.9549443873750914
dev_precision_micro_tok: 0.9897005568318991
dev_recall_micro_tok: 0.9897005568318991
dev_f-score_micro_tok: 0.9897005568318991
dev_time: 24.434733867645264
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9650    0.9829    0.9739       645
           1     0.9958    0.9912    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9804    0.9871    0.9837      3250
weighted avg     0.9897    0.9895    0.9896      3250

F1-macro sent:  0.9836726757130386
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9978    0.9971     42759
         LOC     0.9623    0.9642    0.9633      2094
        MISC     0.9033    0.9062    0.9047      1268
         ORG     0.9557    0.9082    0.9314      2092
         PER     0.9727    0.9838    0.9782      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9581    0.9520    0.9549     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.9549443873750914
F1-micro tok:  0.9897005568318991
**************************************************
Best epoch: 24
**************************************************

EPOCH: 29
Learning rate: 0.531441
train_cost_sum: 296061.044342041
train_cost_avg: 21.085467156330818
train_count_sent: 14041.0
train_total_correct_sent: 13924.0
train_accuracy_sent: 0.9916672601666549
train_count_tok: 203621.0
train_total_correct_tok: 202500.0
train_accuracy_tok: 0.9944946739285241
train_label=0_precision_sent: 0.9797250859106529
train_label=0_recall_sent: 0.9800618769336542
train_label=0_f-score_sent: 0.9798934524832444
train_label=1_precision_sent: 0.994789327104483
train_label=1_recall_sent: 0.994699964067553
train_label=1_f-score_sent: 0.9947446435790324
train_precision_macro_sent: 0.987257206507568
train_recall_macro_sent: 0.9873809205006037
train_f-score_macro_sent: 0.9873190480311385
train_precision_micro_sent: 0.9916672601666549
train_recall_micro_sent: 0.9916672601666549
train_f-score_micro_sent: 0.9916672601666549
train_label=O_precision_tok: 0.9982254555744866
train_label=O_recall_tok: 0.9984785762304073
train_label=O_f-score_tok: 0.9983519998584901
train_label=LOC_precision_tok: 0.9757626914265043
train_label=LOC_recall_tok: 0.9752922743160178
train_label=LOC_f-score_tok: 0.9755274261603376
train_label=MISC_precision_tok: 0.9595893403232852
train_label=MISC_recall_tok: 0.9564554757239278
train_label=MISC_f-score_tok: 0.9580198451641042
train_label=ORG_precision_tok: 0.9692
train_label=ORG_recall_tok: 0.9667830423940149
train_label=ORG_f-score_tok: 0.9679900124843944
train_label=PER_precision_tok: 0.9886782280528349
train_label=PER_recall_tok: 0.9887670740474479
train_label=PER_f-score_tok: 0.9887226490542301
train_precision_macro_tok: 0.9782911430754222
train_recall_macro_tok: 0.9771552885423631
train_f-score_macro_tok: 0.9777223865443112
train_precision_micro_tok: 0.9944946739285241
train_recall_micro_tok: 0.9944946739285241
train_f-score_micro_tok: 0.9944946739285241
train_time: 241.22654819488525
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9797    0.9801    0.9799      2909
           1     0.9948    0.9947    0.9947     11132

   micro avg     0.9917    0.9917    0.9917     14041
   macro avg     0.9873    0.9874    0.9873     14041
weighted avg     0.9917    0.9917    0.9917     14041

F1-macro sent:  0.9873190480311385
F1-micro sent:  0.9916672601666549
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9985    0.9984    169578
         LOC     0.9758    0.9753    0.9755      8297
        MISC     0.9596    0.9565    0.9580      4593
         ORG     0.9692    0.9668    0.9680     10025
         PER     0.9887    0.9888    0.9887     11128

   micro avg     0.9945    0.9945    0.9945    203621
   macro avg     0.9783    0.9772    0.9777    203621
weighted avg     0.9945    0.9945    0.9945    203621

F1-macro tok:  0.9777223865443112
F1-micro tok:  0.9944946739285241
**************************************************
dev_cost_sum: 82249.13195037842
dev_cost_avg: 25.307425215501052
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50816.0
dev_accuracy_tok: 0.9893695728359487
dev_label=0_precision_sent: 0.9888178913738019
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.974036191974823
dev_label=1_precision_sent: 0.9900914634146342
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9936890418818131
dev_precision_macro_sent: 0.9894546773942181
dev_recall_macro_sent: 0.9785013911827285
dev_f-score_macro_sent: 0.983862616928318
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9963570978212642
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.9971021943866701
dev_label=LOC_precision_tok: 0.9534117647058824
dev_label=LOC_recall_tok: 0.9675262655205349
dev_label=LOC_f-score_tok: 0.9604171604645652
dev_label=MISC_precision_tok: 0.9065495207667732
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.9007936507936508
dev_label=ORG_precision_tok: 0.9531722054380665
dev_label=ORG_recall_tok: 0.9048757170172084
dev_label=ORG_f-score_tok: 0.9283962726826877
dev_label=PER_precision_tok: 0.9744962216624685
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9786561264822135
dev_precision_macro_tok: 0.956797362078891
dev_recall_macro_tok: 0.9496424995535845
dev_f-score_macro_tok: 0.9530730809619575
dev_precision_micro_tok: 0.9893695728359487
dev_recall_micro_tok: 0.9893695728359487
dev_f-score_micro_tok: 0.9893695728359487
dev_time: 24.540080785751343
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9888    0.9597    0.9740       645
           1     0.9901    0.9973    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9895    0.9785    0.9839      3250
weighted avg     0.9898    0.9898    0.9898      3250

F1-macro sent:  0.983862616928318
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9978    0.9971     42759
         LOC     0.9534    0.9675    0.9604      2094
        MISC     0.9065    0.8951    0.9008      1268
         ORG     0.9532    0.9049    0.9284      2092
         PER     0.9745    0.9829    0.9787      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9568    0.9496    0.9531     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9530730809619575
F1-micro tok:  0.9893695728359487
**************************************************
Best epoch: 24
**************************************************

EPOCH: 30
Learning rate: 0.478297
train_cost_sum: 295345.07275390625
train_cost_avg: 21.03447566084369
train_count_sent: 14041.0
train_total_correct_sent: 13933.0
train_accuracy_sent: 0.9923082401538352
train_count_tok: 203621.0
train_total_correct_tok: 202504.0
train_accuracy_tok: 0.9945143182677622
train_label=0_precision_sent: 0.9801165581076449
train_label=0_recall_sent: 0.9828119628738398
train_label=0_f-score_sent: 0.9814624098867147
train_label=1_precision_sent: 0.9955052139518159
train_label=1_recall_sent: 0.9947897951850521
train_label=1_f-score_sent: 0.9951473759884975
train_precision_macro_sent: 0.9878108860297303
train_recall_macro_sent: 0.9888008790294459
train_f-score_macro_sent: 0.9883048929376061
train_precision_micro_sent: 0.9923082401538352
train_recall_micro_sent: 0.9923082401538352
train_f-score_micro_sent: 0.9923082401538352
train_label=O_precision_tok: 0.9983313679245283
train_label=O_recall_tok: 0.9984608852563422
train_label=O_f-score_tok: 0.9983961223900135
train_label=LOC_precision_tok: 0.9732260775603314
train_label=LOC_recall_tok: 0.9769796311919972
train_label=LOC_f-score_tok: 0.9750992421508481
train_label=MISC_precision_tok: 0.9584517821998688
train_label=MISC_recall_tok: 0.9542782495101241
train_label=MISC_f-score_tok: 0.9563604625790966
train_label=ORG_precision_tok: 0.9712482468443198
train_label=ORG_recall_tok: 0.9670822942643391
train_label=ORG_f-score_tok: 0.9691607937221972
train_label=PER_precision_tok: 0.9879680344796624
train_label=PER_recall_tok: 0.9887670740474479
train_label=PER_f-score_tok: 0.9883673927689198
train_precision_macro_tok: 0.9778451018017421
train_recall_macro_tok: 0.9771136268540502
train_f-score_macro_tok: 0.9774768027222152
train_precision_micro_tok: 0.9945143182677622
train_recall_micro_tok: 0.9945143182677622
train_f-score_micro_tok: 0.9945143182677622
train_time: 241.09104990959167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9801    0.9828    0.9815      2909
           1     0.9955    0.9948    0.9951     11132

   micro avg     0.9923    0.9923    0.9923     14041
   macro avg     0.9878    0.9888    0.9883     14041
weighted avg     0.9923    0.9923    0.9923     14041

F1-macro sent:  0.9883048929376061
F1-micro sent:  0.9923082401538352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9985    0.9984    169578
         LOC     0.9732    0.9770    0.9751      8297
        MISC     0.9585    0.9543    0.9564      4593
         ORG     0.9712    0.9671    0.9692     10025
         PER     0.9880    0.9888    0.9884     11128

   micro avg     0.9945    0.9945    0.9945    203621
   macro avg     0.9778    0.9771    0.9775    203621
weighted avg     0.9945    0.9945    0.9945    203621

F1-macro tok:  0.9774768027222152
F1-micro tok:  0.9945143182677622
**************************************************
dev_cost_sum: 82242.01131057739
dev_cost_avg: 25.30523424940843
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50823.0
dev_accuracy_tok: 0.989505860363693
dev_label=0_precision_sent: 0.9738461538461538
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9776061776061776
dev_label=1_precision_sent: 0.9953846153846154
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9944284341978867
dev_precision_macro_sent: 0.9846153846153847
dev_recall_macro_sent: 0.987434718564478
dev_f-score_macro_sent: 0.9860173059020322
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9963103939471779
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9970554555864551
dev_label=LOC_precision_tok: 0.9587090650213573
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9616757914782195
dev_label=MISC_precision_tok: 0.9074221867517956
dev_label=MISC_recall_tok: 0.8966876971608833
dev_label=MISC_f-score_tok: 0.9020230067433558
dev_label=ORG_precision_tok: 0.9511221945137157
dev_label=ORG_recall_tok: 0.9115678776290631
dev_label=ORG_f-score_tok: 0.9309250671222846
dev_label=PER_precision_tok: 0.9747952110901071
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9786493752965364
dev_precision_macro_tok: 0.9576718102648307
dev_recall_macro_tok: 0.9506504562047983
dev_f-score_macro_tok: 0.9540657392453703
dev_precision_micro_tok: 0.989505860363693
dev_recall_micro_tok: 0.989505860363693
dev_f-score_micro_tok: 0.989505860363693
dev_time: 24.210684061050415
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9738    0.9814    0.9776       645
           1     0.9954    0.9935    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9846    0.9874    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9860173059020322
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9971     42759
         LOC     0.9587    0.9647    0.9617      2094
        MISC     0.9074    0.8967    0.9020      1268
         ORG     0.9511    0.9116    0.9309      2092
         PER     0.9748    0.9825    0.9786      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9577    0.9507    0.9541     51362
weighted avg     0.9894    0.9895    0.9894     51362

F1-macro tok:  0.9540657392453703
F1-micro tok:  0.989505860363693
**************************************************
Best epoch: 24
**************************************************

EPOCH: 31
Learning rate: 0.430467
train_cost_sum: 294773.94299316406
train_cost_avg: 20.993799800097147
train_count_sent: 14041.0
train_total_correct_sent: 13935.0
train_accuracy_sent: 0.9924506801509864
train_count_tok: 203621.0
train_total_correct_tok: 202529.0
train_accuracy_tok: 0.9946370953880003
train_label=0_precision_sent: 0.9807890222984562
train_label=0_recall_sent: 0.9828119628738398
train_label=0_f-score_sent: 0.9817994505494505
train_label=1_precision_sent: 0.995506021930613
train_label=1_recall_sent: 0.9949694574200503
train_label=1_f-score_sent: 0.9952376673555575
train_precision_macro_sent: 0.9881475221145346
train_recall_macro_sent: 0.9888907101469451
train_f-score_macro_sent: 0.9885185589525041
train_precision_micro_sent: 0.9924506801509864
train_recall_micro_sent: 0.9924506801509864
train_f-score_micro_sent: 0.9924506801509864
train_label=O_precision_tok: 0.998272731560083
train_label=O_recall_tok: 0.9985906190661524
train_label=O_f-score_tok: 0.9984316500103181
train_label=LOC_precision_tok: 0.9764253067115708
train_label=LOC_recall_tok: 0.9784259370856936
train_label=LOC_f-score_tok: 0.9774245981578472
train_label=MISC_precision_tok: 0.9621811785400176
train_label=MISC_recall_tok: 0.9527541911604616
train_label=MISC_f-score_tok: 0.957444480910185
train_label=ORG_precision_tok: 0.9709825895537323
train_label=ORG_recall_tok: 0.9679800498753117
train_label=ORG_f-score_tok: 0.9694789949547931
train_label=PER_precision_tok: 0.987334950148208
train_label=PER_recall_tok: 0.9877785765636233
train_label=PER_f-score_tok: 0.9875567135348816
train_precision_macro_tok: 0.9790393513027225
train_recall_macro_tok: 0.9771058747502485
train_f-score_macro_tok: 0.9780672875136049
train_precision_micro_tok: 0.9946370953880003
train_recall_micro_tok: 0.9946370953880003
train_f-score_micro_tok: 0.9946370953880003
train_time: 241.08922743797302
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9808    0.9828    0.9818      2909
           1     0.9955    0.9950    0.9952     11132

   micro avg     0.9925    0.9925    0.9925     14041
   macro avg     0.9881    0.9889    0.9885     14041
weighted avg     0.9925    0.9925    0.9925     14041

F1-macro sent:  0.9885185589525041
F1-micro sent:  0.9924506801509864
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9986    0.9984    169578
         LOC     0.9764    0.9784    0.9774      8297
        MISC     0.9622    0.9528    0.9574      4593
         ORG     0.9710    0.9680    0.9695     10025
         PER     0.9873    0.9878    0.9876     11128

   micro avg     0.9946    0.9946    0.9946    203621
   macro avg     0.9790    0.9771    0.9781    203621
weighted avg     0.9946    0.9946    0.9946    203621

F1-macro tok:  0.9780672875136049
F1-micro tok:  0.9946370953880003
**************************************************
dev_cost_sum: 82060.88623809814
dev_cost_avg: 25.24950345787635
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50812.0
dev_accuracy_tok: 0.9892916942486664
dev_label=0_precision_sent: 0.9738058551617874
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9768160741885625
dev_label=1_precision_sent: 0.9950019223375625
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9942374183634268
dev_precision_macro_sent: 0.9844038887496749
dev_recall_macro_sent: 0.9866595247660284
dev_f-score_macro_sent: 0.9855267462759947
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9964956546117185
dev_label=O_recall_tok: 0.9975443766224654
dev_label=O_f-score_tok: 0.997019739840819
dev_label=LOC_precision_tok: 0.9452943903569773
dev_label=LOC_recall_tok: 0.9737344794651385
dev_label=LOC_f-score_tok: 0.9593036932486474
dev_label=MISC_precision_tok: 0.8997632202052092
dev_label=MISC_recall_tok: 0.8990536277602523
dev_label=MISC_f-score_tok: 0.8994082840236687
dev_label=ORG_precision_tok: 0.9568965517241379
dev_label=ORG_recall_tok: 0.9020076481835564
dev_label=ORG_f-score_tok: 0.9286417322834646
dev_label=PER_precision_tok: 0.9778621125869703
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9798764062747584
dev_precision_macro_tok: 0.9552623858970026
dev_recall_macro_tok: 0.9508478295183818
dev_f-score_macro_tok: 0.9528499711342716
dev_precision_micro_tok: 0.9892916942486664
dev_recall_micro_tok: 0.9892916942486664
dev_f-score_micro_tok: 0.9892916942486664
dev_time: 24.54807209968567
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9738    0.9798    0.9768       645
           1     0.9950    0.9935    0.9942      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9844    0.9867    0.9855      3250
weighted avg     0.9908    0.9908    0.9908      3250

F1-macro sent:  0.9855267462759947
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9975    0.9970     42759
         LOC     0.9453    0.9737    0.9593      2094
        MISC     0.8998    0.8991    0.8994      1268
         ORG     0.9569    0.9020    0.9286      2092
         PER     0.9779    0.9819    0.9799      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9553    0.9508    0.9528     51362
weighted avg     0.9893    0.9893    0.9892     51362

F1-macro tok:  0.9528499711342716
F1-micro tok:  0.9892916942486664
**************************************************
Best epoch: 24
**************************************************

test0_cost_sum: 82833.99006271362
test0_cost_avg: 25.487381557758038
test0_count_sent: 3250.0
test0_total_correct_sent: 3222.0
test0_accuracy_sent: 0.9913846153846154
test0_count_tok: 51362.0
test0_total_correct_tok: 50810.0
test0_accuracy_tok: 0.9892527549550251
test0_label=0_precision_sent: 0.9738863287250384
test0_label=0_recall_sent: 0.9829457364341085
test0_label=0_f-score_sent: 0.9783950617283951
test0_label=1_precision_sent: 0.9957676029242016
test0_label=1_recall_sent: 0.9934740882917467
test0_label=1_f-score_sent: 0.994619523443505
test0_precision_macro_sent: 0.98482696582462
test0_recall_macro_sent: 0.9882099123629275
test0_f-score_macro_sent: 0.98650729258595
test0_precision_micro_sent: 0.9913846153846154
test0_recall_micro_sent: 0.9913846153846154
test0_f-score_micro_sent: 0.9913846153846154
test0_label=O_precision_tok: 0.9963102216202331
test0_label=O_recall_tok: 0.9977548586262541
test0_label=O_f-score_tok: 0.9970320168263613
test0_label=LOC_precision_tok: 0.9631931166347992
test0_label=LOC_recall_tok: 0.9622731614135626
test0_label=LOC_f-score_tok: 0.9627329192546583
test0_label=MISC_precision_tok: 0.8986539984164688
test0_label=MISC_recall_tok: 0.8951104100946372
test0_label=MISC_f-score_tok: 0.8968787040695377
test0_label=ORG_precision_tok: 0.9504752376188094
test0_label=ORG_recall_tok: 0.9082217973231358
test0_label=ORG_f-score_tok: 0.9288682473722806
test0_label=PER_precision_tok: 0.9717602761217445
test0_label=PER_recall_tok: 0.9834868212130835
test0_label=PER_f-score_tok: 0.9775883838383838
test0_precision_macro_tok: 0.9560785700824109
test0_recall_macro_tok: 0.9493694097341348
test0_f-score_macro_tok: 0.9526200542722444
test0_precision_micro_tok: 0.9892527549550251
test0_recall_micro_tok: 0.9892527549550251
test0_f-score_micro_tok: 0.9892527549550251
test0_time: 24.34834098815918
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9739    0.9829    0.9784       645
           1     0.9958    0.9935    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9848    0.9882    0.9865      3250
weighted avg     0.9914    0.9914    0.9914      3250

F1-macro sent:  0.98650729258595
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9978    0.9970     42759
         LOC     0.9632    0.9623    0.9627      2094
        MISC     0.8987    0.8951    0.8969      1268
         ORG     0.9505    0.9082    0.9289      2092
         PER     0.9718    0.9835    0.9776      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9561    0.9494    0.9526     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9526200542722444
F1-micro tok:  0.9892527549550251
**************************************************
test1_cost_sum: 73423.86879730225
test1_cost_avg: 21.26379055815298
test1_count_sent: 3453.0
test1_total_correct_sent: 3346.0
test1_accuracy_sent: 0.9690124529394729
test1_count_tok: 46435.0
test1_total_correct_tok: 45438.0
test1_accuracy_tok: 0.9785291267362981
test1_label=0_precision_sent: 0.945619335347432
test1_label=0_recall_sent: 0.8981348637015782
test1_label=0_f-score_sent: 0.9212656364974247
test1_label=1_precision_sent: 0.974561089215335
test1_label=1_recall_sent: 0.9869375907111756
test1_label=1_f-score_sent: 0.9807102938525329
test1_precision_macro_sent: 0.9600902122813835
test1_recall_macro_sent: 0.9425362272063769
test1_f-score_macro_sent: 0.9509879651749789
test1_precision_micro_sent: 0.9690124529394729
test1_recall_micro_sent: 0.9690124529394729
test1_f-score_micro_sent: 0.9690124529394729
test1_label=O_precision_tok: 0.9946121253334729
test1_label=O_recall_tok: 0.9923022727865772
test1_label=O_f-score_tok: 0.9934558564207061
test1_label=LOC_precision_tok: 0.8960645812310797
test1_label=LOC_recall_tok: 0.9225974025974026
test1_label=LOC_f-score_tok: 0.9091374456104429
test1_label=MISC_precision_tok: 0.7651905252317199
test1_label=MISC_recall_tok: 0.809368191721133
test1_label=MISC_f-score_tok: 0.7866596082583379
test1_label=ORG_precision_tok: 0.8872210953346856
test1_label=ORG_recall_tok: 0.8762019230769231
test1_label=ORG_f-score_tok: 0.8816770812336223
test1_label=PER_precision_tok: 0.9716133668702839
test1_label=PER_recall_tok: 0.9751172015867292
test1_label=PER_f-score_tok: 0.9733621310295176
test1_precision_macro_tok: 0.9029403388002484
test1_recall_macro_tok: 0.915117398353753
test1_f-score_macro_tok: 0.9088584245105255
test1_precision_micro_tok: 0.9785291267362981
test1_recall_micro_tok: 0.9785291267362981
test1_f-score_micro_tok: 0.9785291267362981
test1_time: 23.796451091766357
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9456    0.8981    0.9213       697
           1     0.9746    0.9869    0.9807      2756

   micro avg     0.9690    0.9690    0.9690      3453
   macro avg     0.9601    0.9425    0.9510      3453
weighted avg     0.9687    0.9690    0.9687      3453

F1-macro sent:  0.9509879651749789
F1-micro sent:  0.9690124529394729
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9923    0.9935     38323
         LOC     0.8961    0.9226    0.9091      1925
        MISC     0.7652    0.8094    0.7867       918
         ORG     0.8872    0.8762    0.8817      2496
         PER     0.9716    0.9751    0.9734      2773

   micro avg     0.9785    0.9785    0.9785     46435
   macro avg     0.9029    0.9151    0.9089     46435
weighted avg     0.9788    0.9785    0.9787     46435

F1-macro tok:  0.9088584245105255
F1-micro tok:  0.9785291267362981
**************************************************
