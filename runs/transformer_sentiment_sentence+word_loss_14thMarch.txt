debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'O': 0, 'P': 2}
{'N': 1, 'O': 0, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 19:32:55.717458: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 19:32:55.792306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 10.48GiB
2019-03-14 19:32:55.792348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 19:32:56.123542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 19:32:56.123596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 19:32:56.123610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 19:32:56.123850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7835707.
Parameter count without word embeddings: 2035207.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 109212.86666870117
train_cost_avg: 12.782404806730007
train_count_sent: 8544.0
train_total_correct_sent: 4458.0
train_accuracy_sent: 0.5217696629213483
train_count_tok: 163566.0
train_total_correct_tok: 126763.0
train_accuracy_tok: 0.7749960260689874
train_label=O_precision_sent: 0.24567474048442905
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.07422895974908521
train_label=N_precision_sent: 0.5089686098654709
train_label=N_recall_sent: 0.6172205438066465
train_label=N_f-score_sent: 0.5578918623702894
train_label=P_precision_sent: 0.5526998349445885
train_label=P_recall_sent: 0.6493074792243767
train_label=P_f-score_sent: 0.5971213858107248
train_precision_macro_sent: 0.4357810617648295
train_recall_macro_sent: 0.4367490782845611
train_f-score_macro_sent: 0.4097474026433665
train_precision_micro_sent: 0.5217696629213483
train_recall_micro_sent: 0.5217696629213483
train_f-score_micro_sent: 0.5217696629213483
train_label=O_precision_tok: 0.7992135278604046
train_label=O_recall_tok: 0.9528898968209929
train_label=O_f-score_tok: 0.8693122624759724
train_label=N_precision_tok: 0.5200570794355478
train_label=N_recall_tok: 0.23095338684692296
train_label=N_f-score_tok: 0.3198595738456287
train_label=P_precision_tok: 0.5547656076427461
train_label=P_recall_tok: 0.19962425550625573
train_label=P_f-score_tok: 0.2936006349392986
train_precision_macro_tok: 0.6246787383128994
train_recall_macro_tok: 0.4611558463913905
train_f-score_macro_tok: 0.49425749042029987
train_precision_micro_tok: 0.7749960260689874
train_recall_micro_tok: 0.7749960260689874
train_f-score_micro_tok: 0.7749960260689874
train_time: 46.472453117370605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2457    0.0437    0.0742      1624
           N     0.5090    0.6172    0.5579      3310
           P     0.5527    0.6493    0.5971      3610

   micro avg     0.5218    0.5218    0.5218      8544
   macro avg     0.4358    0.4367    0.4097      8544
weighted avg     0.4774    0.5218    0.4825      8544

F1-macro sent:  0.4097474026433665
F1-micro sent:  0.5217696629213483
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7992    0.9529    0.8693    124347
           N     0.5201    0.2310    0.3199     14202
           P     0.5548    0.1996    0.2936     25017

   micro avg     0.7750    0.7750    0.7750    163566
   macro avg     0.6247    0.4612    0.4943    163566
weighted avg     0.7376    0.7750    0.7336    163566

F1-macro tok:  0.49425749042029987
F1-micro tok:  0.7749960260689874
**************************************************
dev_cost_sum: 11342.606811523438
dev_cost_avg: 10.302095196660707
dev_count_sent: 1101.0
dev_total_correct_sent: 658.0
dev_accuracy_sent: 0.59763851044505
dev_count_tok: 21274.0
dev_total_correct_tok: 17512.0
dev_accuracy_tok: 0.8231644260599793
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6570048309178744
dev_label=N_recall_sent: 0.6355140186915887
dev_label=N_f-score_sent: 0.6460807600950119
dev_label=P_precision_sent: 0.5618631732168851
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.6825817860300619
dev_precision_macro_sent: 0.4062893347115865
dev_recall_macro_sent: 0.5016277960203194
dev_f-score_macro_sent: 0.44288751537502463
dev_precision_micro_sent: 0.59763851044505
dev_recall_micro_sent: 0.59763851044505
dev_f-score_micro_sent: 0.59763851044505
dev_label=O_precision_tok: 0.8476758967556514
dev_label=O_recall_tok: 0.9464362850971922
dev_label=O_f-score_tok: 0.8943378622660213
dev_label=N_precision_tok: 0.6298568507157464
dev_label=N_recall_tok: 0.4975767366720517
dev_label=N_f-score_tok: 0.555956678700361
dev_label=P_precision_tok: 0.7298716452742123
dev_label=P_recall_tok: 0.3894769613947696
dev_label=P_f-score_tok: 0.5079171741778319
dev_precision_macro_tok: 0.7358014642485368
dev_recall_macro_tok: 0.6111633277213379
dev_f-score_macro_tok: 0.6527372383814047
dev_precision_micro_tok: 0.8231644260599793
dev_recall_micro_tok: 0.8231644260599793
dev_f-score_micro_tok: 0.8231644260599793
dev_time: 2.284447431564331
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6570    0.6355    0.6461       428
           P     0.5619    0.8694    0.6826       444

   micro avg     0.5976    0.5976    0.5976      1101
   macro avg     0.4063    0.5016    0.4429      1101
weighted avg     0.4820    0.5976    0.5264      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.44288751537502463
F1-micro sent:  0.59763851044505
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8477    0.9464    0.8943     16205
           N     0.6299    0.4976    0.5560      1857
           P     0.7299    0.3895    0.5079      3212

   micro avg     0.8232    0.8232    0.8232     21274
   macro avg     0.7358    0.6112    0.6527     21274
weighted avg     0.8109    0.8232    0.8065     21274

F1-macro tok:  0.6527372383814047
F1-micro tok:  0.8231644260599793
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 90544.65902709961
train_cost_avg: 10.597455410475142
train_count_sent: 8544.0
train_total_correct_sent: 4983.0
train_accuracy_sent: 0.5832162921348315
train_count_tok: 163566.0
train_total_correct_tok: 132608.0
train_accuracy_tok: 0.8107308364819095
train_label=O_precision_sent: 0.4666666666666667
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008541793776693106
train_label=N_precision_sent: 0.5490018148820327
train_label=N_recall_sent: 0.7311178247734139
train_label=N_f-score_sent: 0.6271054677377559
train_label=P_precision_sent: 0.6202378063576802
train_label=P_recall_sent: 0.7080332409972299
train_label=P_f-score_sent: 0.6612339930151339
train_precision_macro_sent: 0.5453020959687932
train_recall_macro_sent: 0.48115380353274334
train_f-score_macro_sent: 0.4322937515098609
train_precision_micro_sent: 0.5832162921348315
train_recall_micro_sent: 0.5832162921348315
train_f-score_micro_sent: 0.5832162921348315
train_label=O_precision_tok: 0.8348110357125167
train_label=O_recall_tok: 0.9487804289608917
train_label=O_f-score_tok: 0.8881544773591297
train_label=N_precision_tok: 0.6370064179266833
train_label=N_recall_tok: 0.41233629066328686
train_label=N_f-score_tok: 0.500619790553537
train_label=P_precision_tok: 0.6723371647509578
train_label=P_recall_tok: 0.35072150937362595
train_label=P_f-score_tok: 0.46097669897811755
train_precision_macro_tok: 0.7147182061300527
train_recall_macro_tok: 0.5706127429992681
train_f-score_macro_tok: 0.6165836556302614
train_precision_micro_tok: 0.8107308364819095
train_recall_micro_tok: 0.8107308364819095
train_f-score_micro_tok: 0.8107308364819095
train_time: 45.46348309516907
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0043    0.0085      1624
           N     0.5490    0.7311    0.6271      3310
           P     0.6202    0.7080    0.6612      3610

   micro avg     0.5832    0.5832    0.5832      8544
   macro avg     0.5453    0.4812    0.4323      8544
weighted avg     0.5635    0.5832    0.5240      8544

F1-macro sent:  0.4322937515098609
F1-micro sent:  0.5832162921348315
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8348    0.9488    0.8882    124347
           N     0.6370    0.4123    0.5006     14202
           P     0.6723    0.3507    0.4610     25017

   micro avg     0.8107    0.8107    0.8107    163566
   macro avg     0.7147    0.5706    0.6166    163566
weighted avg     0.7928    0.8107    0.7892    163566

F1-macro tok:  0.6165836556302614
F1-micro tok:  0.8107308364819095
**************************************************
dev_cost_sum: 10384.948822021484
dev_cost_avg: 9.432287758420967
dev_count_sent: 1101.0
dev_total_correct_sent: 665.0
dev_accuracy_sent: 0.6039963669391463
dev_count_tok: 21274.0
dev_total_correct_tok: 17789.0
dev_accuracy_tok: 0.8361850145717777
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5258964143426295
dev_label=N_recall_sent: 0.9252336448598131
dev_label=N_f-score_sent: 0.6706181202370872
dev_label=P_precision_sent: 0.7729885057471264
dev_label=P_recall_sent: 0.6058558558558559
dev_label=P_f-score_sent: 0.6792929292929294
dev_precision_macro_sent: 0.4329616400299186
dev_recall_macro_sent: 0.510363166905223
dev_f-score_macro_sent: 0.4499703498433389
dev_precision_micro_sent: 0.6039963669391463
dev_recall_micro_sent: 0.6039963669391463
dev_f-score_micro_sent: 0.6039963669391463
dev_label=O_precision_tok: 0.845917210858654
dev_label=O_recall_tok: 0.9672323356988584
dev_label=O_f-score_tok: 0.9025162664824092
dev_label=N_precision_tok: 0.7047244094488189
dev_label=N_recall_tok: 0.4819601507808293
dev_label=N_f-score_tok: 0.57243364246882
dev_label=P_precision_tok: 0.8271186440677966
dev_label=P_recall_tok: 0.37982565379825656
dev_label=P_f-score_tok: 0.5205888628120333
dev_precision_macro_tok: 0.7925867547917566
dev_recall_macro_tok: 0.6096727134259814
dev_f-score_macro_tok: 0.6651795905877541
dev_precision_micro_tok: 0.8361850145717777
dev_recall_micro_tok: 0.8361850145717777
dev_f-score_micro_tok: 0.8361850145717777
dev_time: 2.0094311237335205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5259    0.9252    0.6706       428
           P     0.7730    0.6059    0.6793       444

   micro avg     0.6040    0.6040    0.6040      1101
   macro avg     0.4330    0.5104    0.4500      1101
weighted avg     0.5162    0.6040    0.5346      1101

F1-macro sent:  0.4499703498433389
F1-micro sent:  0.6039963669391463
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8459    0.9672    0.9025     16205
           N     0.7047    0.4820    0.5724      1857
           P     0.8271    0.3798    0.5206      3212

   micro avg     0.8362    0.8362    0.8362     21274
   macro avg     0.7926    0.6097    0.6652     21274
weighted avg     0.8308    0.8362    0.8160     21274

F1-macro tok:  0.6651795905877541
F1-micro tok:  0.8361850145717777
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 84933.76811218262
train_cost_avg: 9.940750013129987
train_count_sent: 8544.0
train_total_correct_sent: 5099.0
train_accuracy_sent: 0.5967930711610487
train_count_tok: 163566.0
train_total_correct_tok: 135137.0
train_accuracy_tok: 0.8261924849907682
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012285012285012285
train_label=N_precision_sent: 0.5589171974522293
train_label=N_recall_sent: 0.7422960725075529
train_label=N_f-score_sent: 0.6376849208409032
train_label=P_precision_sent: 0.6373069498069498
train_label=P_recall_sent: 0.7315789473684211
train_label=P_f-score_sent: 0.6811968016507609
train_precision_macro_sent: 0.48207471575305966
train_recall_macro_sent: 0.4914969278075907
train_f-score_macro_sent: 0.44003674124005515
train_precision_micro_sent: 0.5967930711610487
train_recall_micro_sent: 0.5967930711610487
train_f-score_micro_sent: 0.5967930711610487
train_label=O_precision_tok: 0.8477723747251724
train_label=O_recall_tok: 0.9519891915365871
train_label=O_f-score_tok: 0.896863398742329
train_label=N_precision_tok: 0.6699245723998725
train_label=N_recall_tok: 0.4440219687367976
train_label=N_f-score_tok: 0.5340673300868092
train_label=P_precision_tok: 0.7199724517906336
train_label=P_recall_tok: 0.41787584442579045
train_label=P_f-score_tok: 0.528821104282065
train_precision_macro_tok: 0.7458897996385595
train_recall_macro_tok: 0.6046290015663917
train_f-score_macro_tok: 0.6532506110370677
train_precision_micro_tok: 0.8261924849907682
train_recall_micro_tok: 0.8261924849907682
train_f-score_micro_tok: 0.8261924849907682
train_time: 81.96816158294678
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0006    0.0012      1624
           N     0.5589    0.7423    0.6377      3310
           P     0.6373    0.7316    0.6812      3610

   micro avg     0.5968    0.5968    0.5968      8544
   macro avg     0.4821    0.4915    0.4400      8544
weighted avg     0.5333    0.5968    0.5351      8544

F1-macro sent:  0.44003674124005515
F1-micro sent:  0.5967930711610487
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8478    0.9520    0.8969    124347
           N     0.6699    0.4440    0.5341     14202
           P     0.7200    0.4179    0.5288     25017

   micro avg     0.8262    0.8262    0.8262    163566
   macro avg     0.7459    0.6046    0.6533    163566
weighted avg     0.8128    0.8262    0.8091    163566

F1-macro tok:  0.6532506110370677
F1-micro tok:  0.8261924849907682
**************************************************
dev_cost_sum: 9754.092712402344
dev_cost_avg: 8.859303099366343
dev_count_sent: 1101.0
dev_total_correct_sent: 668.0
dev_accuracy_sent: 0.6067211625794732
dev_count_tok: 21274.0
dev_total_correct_tok: 18277.0
dev_accuracy_tok: 0.8591238131051988
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6186440677966102
dev_label=N_recall_sent: 0.6822429906542056
dev_label=N_f-score_sent: 0.648888888888889
dev_label=P_precision_sent: 0.5977742448330684
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7008387698042869
dev_precision_macro_sent: 0.40547277087655953
dev_recall_macro_sent: 0.5096966125003508
dev_f-score_macro_sent: 0.44990921956439195
dev_precision_micro_sent: 0.6067211625794732
dev_recall_micro_sent: 0.6067211625794732
dev_f-score_micro_sent: 0.6067211625794732
dev_label=O_precision_tok: 0.8735703072437766
dev_label=O_recall_tok: 0.9614933662449862
dev_label=O_f-score_tok: 0.9154255162891807
dev_label=N_precision_tok: 0.7238866396761133
dev_label=N_recall_tok: 0.481421647819063
dev_label=N_f-score_tok: 0.5782664941785252
dev_label=P_precision_tok: 0.8179754879709487
dev_label=P_recall_tok: 0.5610211706102117
dev_label=P_f-score_tok: 0.6655586334256695
dev_precision_macro_tok: 0.8051441449636129
dev_recall_macro_tok: 0.6679787282247537
dev_f-score_macro_tok: 0.7197502146311251
dev_precision_micro_tok: 0.8591238131051988
dev_recall_micro_tok: 0.8591238131051988
dev_f-score_micro_tok: 0.8591238131051988
dev_time: 4.3306214809417725
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6186    0.6822    0.6489       428
           P     0.5978    0.8468    0.7008       444

   micro avg     0.6067    0.6067    0.6067      1101
   macro avg     0.4055    0.5097    0.4499      1101
weighted avg     0.4816    0.6067    0.5349      1101

F1-macro sent:  0.44990921956439195
F1-micro sent:  0.6067211625794732
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8736    0.9615    0.9154     16205
           N     0.7239    0.4814    0.5783      1857
           P     0.8180    0.5610    0.6656      3212

   micro avg     0.8591    0.8591    0.8591     21274
   macro avg     0.8051    0.6680    0.7198     21274
weighted avg     0.8521    0.8591    0.8483     21274

F1-macro tok:  0.7197502146311251
F1-micro tok:  0.8591238131051988
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 80755.14372253418
train_cost_avg: 9.451678806476378
train_count_sent: 8544.0
train_total_correct_sent: 5180.0
train_accuracy_sent: 0.6062734082397003
train_count_tok: 163566.0
train_total_correct_tok: 137505.0
train_accuracy_tok: 0.8406698213565167
train_label=O_precision_sent: 0.2222222222222222
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002449479485609308
train_label=N_precision_sent: 0.5746638358103326
train_label=N_recall_sent: 0.7359516616314199
train_label=N_f-score_sent: 0.6453834945025831
train_label=P_precision_sent: 0.638268156424581
train_label=P_recall_sent: 0.7595567867036012
train_label=P_f-score_sent: 0.6936503921072603
train_precision_macro_sent: 0.47838473815237864
train_recall_macro_sent: 0.4989133251428724
train_f-score_macro_sent: 0.4471611220318176
train_precision_micro_sent: 0.6062734082397003
train_recall_micro_sent: 0.6062734082397003
train_f-score_micro_sent: 0.6062734082397003
train_label=O_precision_tok: 0.8607069059271343
train_label=O_recall_tok: 0.9546913073898043
train_label=O_f-score_tok: 0.9052662884333821
train_label=N_precision_tok: 0.6912800331400166
train_label=N_recall_tok: 0.4700042247570765
train_label=N_f-score_tok: 0.5595607343448739
train_label=P_precision_tok: 0.7580231467000312
train_label=P_recall_tok: 0.48435064156373664
train_label=P_f-score_tok: 0.591044339300522
train_precision_macro_tok: 0.7700033619223942
train_recall_macro_tok: 0.6363487245702059
train_f-score_macro_tok: 0.6852904540262593
train_precision_micro_tok: 0.8406698213565167
train_recall_micro_tok: 0.8406698213565167
train_f-score_micro_tok: 0.8406698213565167
train_time: 83.89194345474243
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2222    0.0012    0.0024      1624
           N     0.5747    0.7360    0.6454      3310
           P     0.6383    0.7596    0.6937      3610

   micro avg     0.6063    0.6063    0.6063      8544
   macro avg     0.4784    0.4989    0.4472      8544
weighted avg     0.5345    0.6063    0.5436      8544

F1-macro sent:  0.4471611220318176
F1-micro sent:  0.6062734082397003
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8607    0.9547    0.9053    124347
           N     0.6913    0.4700    0.5596     14202
           P     0.7580    0.4844    0.5910     25017

   micro avg     0.8407    0.8407    0.8407    163566
   macro avg     0.7700    0.6363    0.6853    163566
weighted avg     0.8303    0.8407    0.8272    163566

F1-macro tok:  0.6852904540262593
F1-micro tok:  0.8406698213565167
**************************************************
dev_cost_sum: 9397.707794189453
dev_cost_avg: 8.535611075558087
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18405.0
dev_accuracy_tok: 0.8651405471467519
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6318897637795275
dev_label=N_recall_sent: 0.75
dev_label=N_f-score_sent: 0.6858974358974359
dev_label=P_precision_sent: 0.6155143338954469
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.703953712632594
dev_precision_macro_sent: 0.4158013658916581
dev_recall_macro_sent: 0.524024024024024
dev_f-score_macro_sent: 0.4632837161766766
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8821892920002271
dev_label=O_recall_tok: 0.9588398642394322
dev_label=O_f-score_tok: 0.918918918918919
dev_label=N_precision_tok: 0.7179104477611941
dev_label=N_recall_tok: 0.5180398492191707
dev_label=N_f-score_tok: 0.6018142008132624
dev_label=P_precision_tok: 0.8207669108143042
dev_label=P_recall_tok: 0.5930884184308842
dev_label=P_f-score_tok: 0.6885956985360565
dev_precision_macro_tok: 0.8069555501919085
dev_recall_macro_tok: 0.6899893772964957
dev_f-score_macro_tok: 0.736442939422746
dev_precision_micro_tok: 0.8651405471467519
dev_recall_micro_tok: 0.8651405471467519
dev_f-score_micro_tok: 0.8651405471467519
dev_time: 4.288938045501709
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6319    0.7500    0.6859       428
           P     0.6155    0.8221    0.7040       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4158    0.5240    0.4633      1101
weighted avg     0.4939    0.6231    0.5505      1101

F1-macro sent:  0.4632837161766766
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8822    0.9588    0.9189     16205
           N     0.7179    0.5180    0.6018      1857
           P     0.8208    0.5931    0.6886      3212

   micro avg     0.8651    0.8651    0.8651     21274
   macro avg     0.8070    0.6900    0.7364     21274
weighted avg     0.8586    0.8651    0.8565     21274

F1-macro tok:  0.736442939422746
F1-micro tok:  0.8651405471467519
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 77342.72703552246
train_cost_avg: 9.052285467640738
train_count_sent: 8544.0
train_total_correct_sent: 5278.0
train_accuracy_sent: 0.6177434456928839
train_count_tok: 163566.0
train_total_correct_tok: 139034.0
train_accuracy_tok: 0.8500177298460561
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5889541715628672
train_label=N_recall_sent: 0.7570996978851964
train_label=N_f-score_sent: 0.6625247851949768
train_label=P_precision_sent: 0.6463044998834228
train_label=P_recall_sent: 0.7678670360110803
train_label=P_f-score_sent: 0.7018609950626662
train_precision_macro_sent: 0.4117528904820967
train_recall_macro_sent: 0.5083222446320922
train_f-score_macro_sent: 0.45479526008588095
train_precision_micro_sent: 0.6177434456928839
train_recall_micro_sent: 0.6177434456928839
train_f-score_micro_sent: 0.6177434456928839
train_label=O_precision_tok: 0.8681552675908438
train_label=O_recall_tok: 0.9574095072659574
train_label=O_f-score_tok: 0.9106005094118816
train_label=N_precision_tok: 0.7078409207686774
train_label=N_recall_tok: 0.48500211237853824
train_label=N_f-score_tok: 0.5756069026031003
train_label=P_precision_tok: 0.7839439655172413
train_label=P_recall_tok: 0.5234440580405324
train_label=P_f-score_tok: 0.6277414251815632
train_precision_macro_tok: 0.7866467179589209
train_recall_macro_tok: 0.6552852258950094
train_f-score_macro_tok: 0.7046496123988484
train_precision_micro_tok: 0.8500177298460561
train_recall_micro_tok: 0.8500177298460561
train_f-score_micro_tok: 0.8500177298460562
train_time: 82.43064570426941
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5890    0.7571    0.6625      3310
           P     0.6463    0.7679    0.7019      3610

   micro avg     0.6177    0.6177    0.6177      8544
   macro avg     0.4118    0.5083    0.4548      8544
weighted avg     0.5012    0.6177    0.5532      8544

F1-macro sent:  0.45479526008588095
F1-micro sent:  0.6177434456928839
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8682    0.9574    0.9106    124347
           N     0.7078    0.4850    0.5756     14202
           P     0.7839    0.5234    0.6277     25017

   micro avg     0.8500    0.8500    0.8500    163566
   macro avg     0.7866    0.6553    0.7046    163566
weighted avg     0.8414    0.8500    0.8383    163566

F1-macro tok:  0.7046496123988484
F1-micro tok:  0.8500177298460562
**************************************************
dev_cost_sum: 8939.994216918945
dev_cost_avg: 8.119885755603038
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18547.0
dev_accuracy_tok: 0.8718153614740999
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6391129032258065
dev_label=N_recall_sent: 0.7406542056074766
dev_label=N_f-score_sent: 0.6861471861471862
dev_label=P_precision_sent: 0.6132231404958678
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.707340324118208
dev_precision_macro_sent: 0.4174453479072248
dev_recall_macro_sent: 0.5254132637310208
dev_f-score_macro_sent: 0.46449583675513145
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8848069738480697
dev_label=O_recall_tok: 0.9645788336933045
dev_label=O_f-score_tok: 0.9229724543119483
dev_label=N_precision_tok: 0.7316363636363636
dev_label=N_recall_tok: 0.5417339795368874
dev_label=N_f-score_tok: 0.6225247524752475
dev_label=P_precision_tok: 0.8553515450067174
dev_label=P_recall_tok: 0.5946450809464509
dev_label=P_f-score_tok: 0.7015610651974288
dev_precision_macro_tok: 0.8239316274970503
dev_recall_macro_tok: 0.7003192980588809
dev_f-score_macro_tok: 0.7490194239948749
dev_precision_micro_tok: 0.8718153614740999
dev_recall_micro_tok: 0.8718153614740999
dev_f-score_micro_tok: 0.8718153614741
dev_time: 4.314822196960449
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6391    0.7407    0.6861       428
           P     0.6132    0.8356    0.7073       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.4174    0.5254    0.4645      1101
weighted avg     0.4957    0.6249    0.5520      1101

F1-macro sent:  0.46449583675513145
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8848    0.9646    0.9230     16205
           N     0.7316    0.5417    0.6225      1857
           P     0.8554    0.5946    0.7016      3212

   micro avg     0.8718    0.8718    0.8718     21274
   macro avg     0.8239    0.7003    0.7490     21274
weighted avg     0.8670    0.8718    0.8633     21274

F1-macro tok:  0.7490194239948749
F1-micro tok:  0.8718153614741
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 74384.24736022949
train_cost_avg: 8.706021460701017
train_count_sent: 8544.0
train_total_correct_sent: 5315.0
train_accuracy_sent: 0.6220739700374532
train_count_tok: 163566.0
train_total_correct_tok: 140201.0
train_accuracy_tok: 0.8571524644486018
train_label=O_precision_sent: 0.5714285714285714
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004904966278356836
train_label=N_precision_sent: 0.5842950893867391
train_label=N_recall_sent: 0.7800604229607251
train_label=N_f-score_sent: 0.6681330055634623
train_label=P_precision_sent: 0.6627003399708596
train_label=P_recall_sent: 0.7559556786703601
train_label=P_f-score_sent: 0.7062629399585921
train_precision_macro_sent: 0.60614133359539
train_recall_macro_sent: 0.5128263852727591
train_f-score_macro_sent: 0.4597669706001371
train_precision_micro_sent: 0.6220739700374532
train_recall_micro_sent: 0.6220739700374532
train_f-score_micro_sent: 0.6220739700374532
train_label=O_precision_tok: 0.8746618376967573
train_label=O_recall_tok: 0.9594360941558703
train_label=O_f-score_tok: 0.9150897808595337
train_label=N_precision_tok: 0.7134831460674157
train_label=N_recall_tok: 0.5007745387973525
train_label=N_f-score_tok: 0.5884981381878361
train_label=P_precision_tok: 0.8015582301296587
train_label=P_recall_tok: 0.5510652756125834
train_label=P_f-score_tok: 0.6531173014970627
train_precision_macro_tok: 0.7965677379646104
train_recall_macro_tok: 0.6704253028552687
train_f-score_macro_tok: 0.7189017401814776
train_precision_micro_tok: 0.8571524644486018
train_recall_micro_tok: 0.8571524644486018
train_f-score_micro_tok: 0.8571524644486018
train_time: 83.14652633666992
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0025    0.0049      1624
           N     0.5843    0.7801    0.6681      3310
           P     0.6627    0.7560    0.7063      3610

   micro avg     0.6221    0.6221    0.6221      8544
   macro avg     0.6061    0.5128    0.4598      8544
weighted avg     0.6150    0.6221    0.5582      8544

F1-macro sent:  0.4597669706001371
F1-micro sent:  0.6220739700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8747    0.9594    0.9151    124347
           N     0.7135    0.5008    0.5885     14202
           P     0.8016    0.5511    0.6531     25017

   micro avg     0.8572    0.8572    0.8572    163566
   macro avg     0.7966    0.6704    0.7189    163566
weighted avg     0.8495    0.8572    0.8467    163566

F1-macro tok:  0.7189017401814776
F1-micro tok:  0.8571524644486018
**************************************************
dev_cost_sum: 8703.865821838379
dev_cost_avg: 7.905418548445394
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18657.0
dev_accuracy_tok: 0.8769859922910596
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6600441501103753
dev_label=N_recall_sent: 0.6985981308411215
dev_label=N_f-score_sent: 0.6787741203178207
dev_label=P_precision_sent: 0.5987654320987654
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7106227106227105
dev_precision_macro_sent: 0.4196031940697136
dev_recall_macro_sent: 0.5241573349049985
dev_f-score_macro_sent: 0.46313227698017706
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.884002692393987
dev_label=O_recall_tok: 0.9725393397099661
dev_label=O_f-score_tok: 0.9261599036229542
dev_label=N_precision_tok: 0.790133779264214
dev_label=N_recall_tok: 0.5088852988691438
dev_label=N_f-score_tok: 0.6190632165083524
dev_label=P_precision_tok: 0.8675555555555555
dev_label=P_recall_tok: 0.6077210460772104
dev_label=P_f-score_tok: 0.7147564994507507
dev_precision_macro_tok: 0.8472306757379188
dev_recall_macro_tok: 0.6963818948854401
dev_f-score_macro_tok: 0.7533265398606858
dev_precision_micro_tok: 0.8769859922910596
dev_recall_micro_tok: 0.8769859922910596
dev_f-score_micro_tok: 0.8769859922910596
dev_time: 4.297932147979736
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6600    0.6986    0.6788       428
           P     0.5988    0.8739    0.7106       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4196    0.5242    0.4631      1101
weighted avg     0.4980    0.6240    0.5504      1101

F1-macro sent:  0.46313227698017706
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8840    0.9725    0.9262     16205
           N     0.7901    0.5089    0.6191      1857
           P     0.8676    0.6077    0.7148      3212

   micro avg     0.8770    0.8770    0.8770     21274
   macro avg     0.8472    0.6964    0.7533     21274
weighted avg     0.8733    0.8770    0.8674     21274

F1-macro tok:  0.7533265398606858
F1-micro tok:  0.8769859922910596
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 72682.84638977051
train_cost_avg: 8.506887451986248
train_count_sent: 8544.0
train_total_correct_sent: 5376.0
train_accuracy_sent: 0.6292134831460674
train_count_tok: 163566.0
train_total_correct_tok: 141136.0
train_accuracy_tok: 0.8628688113666655
train_label=O_precision_sent: 0.6
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003683241252302025
train_label=N_precision_sent: 0.5903153153153153
train_label=N_recall_sent: 0.7918429003021148
train_label=N_f-score_sent: 0.6763870967741935
train_label=P_precision_sent: 0.6713832642107831
train_label=P_recall_sent: 0.7623268698060942
train_label=P_f-score_sent: 0.7139706836165521
train_precision_macro_sent: 0.6205661931753661
train_recall_macro_sent: 0.5186723535828678
train_f-score_macro_sent: 0.46468034054768254
train_precision_micro_sent: 0.6292134831460674
train_recall_micro_sent: 0.6292134831460674
train_f-score_micro_sent: 0.6292134831460674
train_label=O_precision_tok: 0.8783176746917205
train_label=O_recall_tok: 0.9623231762728494
train_label=O_f-score_tok: 0.918403450670985
train_label=N_precision_tok: 0.7321481775747344
train_label=N_recall_tok: 0.5190818194620476
train_label=N_f-score_tok: 0.6074739400931153
train_label=P_precision_tok: 0.8171756388711827
train_label=P_recall_tok: 0.5636966862533477
train_label=P_f-score_tok: 0.6671713109712825
train_precision_macro_tok: 0.8092138303792126
train_recall_macro_tok: 0.6817005606627481
train_f-score_macro_tok: 0.7310162339117943
train_precision_micro_tok: 0.8628688113666655
train_recall_micro_tok: 0.8628688113666655
train_f-score_micro_tok: 0.8628688113666655
train_time: 83.36105108261108
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0018    0.0037      1624
           N     0.5903    0.7918    0.6764      3310
           P     0.6714    0.7623    0.7140      3610

   micro avg     0.6292    0.6292    0.6292      8544
   macro avg     0.6206    0.5187    0.4647      8544
weighted avg     0.6264    0.6292    0.5644      8544

F1-macro sent:  0.46468034054768254
F1-micro sent:  0.6292134831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8783    0.9623    0.9184    124347
           N     0.7321    0.5191    0.6075     14202
           P     0.8172    0.5637    0.6672     25017

   micro avg     0.8629    0.8629    0.8629    163566
   macro avg     0.8092    0.6817    0.7310    163566
weighted avg     0.8563    0.8629    0.8530    163566

F1-macro tok:  0.7310162339117943
F1-micro tok:  0.8628688113666655
**************************************************
dev_cost_sum: 8734.467041015625
dev_cost_avg: 7.933212571313011
dev_count_sent: 1101.0
dev_total_correct_sent: 657.0
dev_accuracy_sent: 0.5967302452316077
dev_count_tok: 21274.0
dev_total_correct_tok: 18704.0
dev_accuracy_tok: 0.8791952618219423
dev_label=O_precision_sent: 0.42857142857142855
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02542372881355932
dev_label=N_precision_sent: 0.7093023255813954
dev_label=N_recall_sent: 0.5700934579439252
dev_label=N_f-score_sent: 0.6321243523316061
dev_label=P_precision_sent: 0.5466666666666666
dev_label=P_recall_sent: 0.9234234234234234
dev_label=P_f-score_sent: 0.6867671691792295
dev_precision_macro_sent: 0.5615134736064968
dev_recall_macro_sent: 0.5022057726828572
dev_f-score_macro_sent: 0.448105083441465
dev_precision_micro_sent: 0.5967302452316077
dev_recall_micro_sent: 0.5967302452316077
dev_f-score_micro_sent: 0.5967302452316077
dev_label=O_precision_tok: 0.8841552051884155
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9277521926608195
dev_label=N_precision_tok: 0.8345864661654135
dev_label=N_recall_tok: 0.4781906300484653
dev_label=N_f-score_tok: 0.6080109551523452
dev_label=P_precision_tok: 0.8614457831325302
dev_label=P_recall_tok: 0.6232876712328768
dev_label=P_f-score_tok: 0.7232658959537572
dev_precision_macro_tok: 0.8600624848287864
dev_recall_macro_tok: 0.692449981945164
dev_f-score_macro_tok: 0.7530096812556405
dev_precision_micro_tok: 0.8791952618219423
dev_recall_micro_tok: 0.8791952618219423
dev_f-score_micro_tok: 0.8791952618219423
dev_time: 4.4507668018341064
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0131    0.0254       229
           N     0.7093    0.5701    0.6321       428
           P     0.5467    0.9234    0.6868       444

   micro avg     0.5967    0.5967    0.5967      1101
   macro avg     0.5615    0.5022    0.4481      1101
weighted avg     0.5853    0.5967    0.5280      1101

F1-macro sent:  0.448105083441465
F1-micro sent:  0.5967302452316077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8842    0.9759    0.9278     16205
           N     0.8346    0.4782    0.6080      1857
           P     0.8614    0.6233    0.7233      3212

   micro avg     0.8792    0.8792    0.8792     21274
   macro avg     0.8601    0.6924    0.7530     21274
weighted avg     0.8764    0.8792    0.8690     21274

F1-macro tok:  0.7530096812556405
F1-micro tok:  0.8791952618219423
**************************************************
Best epoch: 4
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 70546.06887817383
train_cost_avg: 8.256796451097124
train_count_sent: 8544.0
train_total_correct_sent: 5358.0
train_accuracy_sent: 0.6271067415730337
train_count_tok: 163566.0
train_total_correct_tok: 141745.0
train_accuracy_tok: 0.8665920790384309
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.01680672268907563
train_label=N_precision_sent: 0.5829528158295282
train_label=N_recall_sent: 0.8099697885196374
train_label=N_f-score_sent: 0.6779618156530535
train_label=P_precision_sent: 0.6822956699974378
train_label=P_recall_sent: 0.7376731301939058
train_label=P_f-score_sent: 0.7089045654199387
train_precision_macro_sent: 0.5328606063867665
train_recall_macro_sent: 0.5187545361229052
train_f-score_macro_sent: 0.4678910345873559
train_precision_micro_sent: 0.6271067415730337
train_recall_micro_sent: 0.6271067415730337
train_f-score_micro_sent: 0.6271067415730337
train_label=O_precision_tok: 0.8815142865550423
train_label=O_recall_tok: 0.9636420661535864
train_label=O_f-score_tok: 0.9207504255049389
train_label=N_precision_tok: 0.7409438026238496
train_label=N_recall_tok: 0.5328826925785101
train_label=N_f-score_tok: 0.6199213630406291
train_label=P_precision_tok: 0.8238231917336395
train_label=P_recall_tok: 0.5736499180557221
train_label=P_f-score_tok: 0.6763437566274713
train_precision_macro_tok: 0.8154270936375104
train_recall_macro_tok: 0.6900582255959394
train_f-score_macro_tok: 0.7390051817243464
train_precision_micro_tok: 0.8665920790384309
train_recall_micro_tok: 0.8665920790384309
train_f-score_micro_tok: 0.8665920790384309
train_time: 82.44682621955872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0086    0.0168      1624
           N     0.5830    0.8100    0.6780      3310
           P     0.6823    0.7377    0.7089      3610

   micro avg     0.6271    0.6271    0.6271      8544
   macro avg     0.5329    0.5188    0.4679      8544
weighted avg     0.5775    0.6271    0.5654      8544

F1-macro sent:  0.4678910345873559
F1-micro sent:  0.6271067415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8815    0.9636    0.9208    124347
           N     0.7409    0.5329    0.6199     14202
           P     0.8238    0.5736    0.6763     25017

   micro avg     0.8666    0.8666    0.8666    163566
   macro avg     0.8154    0.6901    0.7390    163566
weighted avg     0.8605    0.8666    0.8572    163566

F1-macro tok:  0.7390051817243464
F1-micro tok:  0.8665920790384309
**************************************************
dev_cost_sum: 8359.824745178223
dev_cost_avg: 7.59293800651973
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18780.0
dev_accuracy_tok: 0.8827676976591144
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5674891146589259
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.7000895255147715
dev_label=P_precision_sent: 0.7354368932038835
dev_label=P_recall_sent: 0.6824324324324325
dev_label=P_f-score_sent: 0.7079439252336449
dev_precision_macro_sent: 0.4343086692876031
dev_recall_macro_sent: 0.5319946114338637
dev_f-score_macro_sent: 0.4693444835828055
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8916685533167308
dev_label=O_recall_tok: 0.9721690836161678
dev_label=O_f-score_tok: 0.9301803796534113
dev_label=N_precision_tok: 0.7553191489361702
dev_label=N_recall_tok: 0.5735056542810986
dev_label=N_f-score_tok: 0.6519742883379247
dev_label=P_precision_tok: 0.8929872495446266
dev_label=P_recall_tok: 0.6105230386052304
dev_label=P_f-score_tok: 0.7252218934911243
dev_precision_macro_tok: 0.8466583172658425
dev_recall_macro_tok: 0.7187325921674989
dev_f-score_macro_tok: 0.7691255204941534
dev_precision_micro_tok: 0.8827676976591144
dev_recall_micro_tok: 0.8827676976591144
dev_f-score_micro_tok: 0.8827676976591146
dev_time: 4.3188605308532715
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5675    0.9136    0.7001       428
           P     0.7354    0.6824    0.7079       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4343    0.5320    0.4693      1101
weighted avg     0.5172    0.6303    0.5576      1101

F1-macro sent:  0.4693444835828055
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8917    0.9722    0.9302     16205
           N     0.7553    0.5735    0.6520      1857
           P     0.8930    0.6105    0.7252      3212

   micro avg     0.8828    0.8828    0.8828     21274
   macro avg     0.8467    0.7187    0.7691     21274
weighted avg     0.8800    0.8828    0.8750     21274

F1-macro tok:  0.7691255204941534
F1-micro tok:  0.8827676976591146
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 69043.0765991211
train_cost_avg: 8.080884433417731
train_count_sent: 8544.0
train_total_correct_sent: 5460.0
train_accuracy_sent: 0.6390449438202247
train_count_tok: 163566.0
train_total_correct_tok: 142298.0
train_accuracy_tok: 0.8699729772691146
train_label=O_precision_sent: 0.43137254901960786
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.02626865671641791
train_label=N_precision_sent: 0.601952770208901
train_label=N_recall_sent: 0.8009063444108762
train_label=N_f-score_sent: 0.6873217526575058
train_label=P_precision_sent: 0.6815847395451211
train_label=P_recall_sent: 0.77202216066482
train_label=P_f-score_sent: 0.7239901285881285
train_precision_macro_sent: 0.5716366862578767
train_recall_macro_sent: 0.5288251010350843
train_f-score_macro_sent: 0.47919351265401744
train_precision_micro_sent: 0.6390449438202247
train_recall_micro_sent: 0.6390449438202247
train_f-score_micro_sent: 0.6390449438202247
train_label=O_precision_tok: 0.8843732027782284
train_label=O_recall_tok: 0.9645910235067995
train_label=O_f-score_tok: 0.922741977051463
train_label=N_precision_tok: 0.7475933769734309
train_label=N_recall_tok: 0.5468243909308548
train_label=N_f-score_tok: 0.6316388775925172
train_label=P_precision_tok: 0.831130355515041
train_label=P_recall_tok: 0.5831234760362953
train_label=P_f-score_tok: 0.6853813808170265
train_precision_macro_tok: 0.8210323117555668
train_recall_macro_tok: 0.6981796301579832
train_f-score_macro_tok: 0.7465874118203355
train_precision_micro_tok: 0.8699729772691146
train_recall_micro_tok: 0.8699729772691146
train_f-score_micro_tok: 0.8699729772691146
train_time: 83.05928611755371
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4314    0.0135    0.0263      1624
           N     0.6020    0.8009    0.6873      3310
           P     0.6816    0.7720    0.7240      3610

   micro avg     0.6390    0.6390    0.6390      8544
   macro avg     0.5716    0.5288    0.4792      8544
weighted avg     0.6032    0.6390    0.5772      8544

F1-macro sent:  0.47919351265401744
F1-micro sent:  0.6390449438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8844    0.9646    0.9227    124347
           N     0.7476    0.5468    0.6316     14202
           P     0.8311    0.5831    0.6854     25017

   micro avg     0.8700    0.8700    0.8700    163566
   macro avg     0.8210    0.6982    0.7466    163566
weighted avg     0.8644    0.8700    0.8612    163566

F1-macro tok:  0.7465874118203355
F1-micro tok:  0.8699729772691146
**************************************************
dev_cost_sum: 8292.843826293945
dev_cost_avg: 7.532101567932739
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18823.0
dev_accuracy_tok: 0.8847889442511987
dev_label=O_precision_sent: 0.3333333333333333
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06324110671936758
dev_label=N_precision_sent: 0.6431297709923665
dev_label=N_recall_sent: 0.7873831775700935
dev_label=N_f-score_sent: 0.707983193277311
dev_label=P_precision_sent: 0.6528028933092225
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7241725175526581
dev_precision_macro_sent: 0.5430886658783074
dev_recall_macro_sent: 0.5451269128165834
dev_f-score_macro_sent: 0.4984656058497789
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8884964682139254
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9311165290955556
dev_label=N_precision_tok: 0.7996870109546166
dev_label=N_recall_tok: 0.5503500269251481
dev_label=N_f-score_tok: 0.6519936204146731
dev_label=P_precision_tok: 0.9045412418906394
dev_label=P_recall_tok: 0.6077210460772104
dev_label=P_f-score_tok: 0.7270018621973929
dev_precision_macro_tok: 0.8642415736863938
dev_recall_macro_tok: 0.7120341815901104
dev_f-score_macro_tok: 0.7700373372358739
dev_precision_micro_tok: 0.8847889442511987
dev_recall_micro_tok: 0.8847889442511987
dev_f-score_micro_tok: 0.8847889442511987
dev_time: 4.213120698928833
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0349    0.0632       229
           N     0.6431    0.7874    0.7080       428
           P     0.6528    0.8131    0.7242       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.5431    0.5451    0.4985      1101
weighted avg     0.5826    0.6412    0.5804      1101

F1-macro sent:  0.4984656058497789
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8885    0.9780    0.9311     16205
           N     0.7997    0.5504    0.6520      1857
           P     0.9045    0.6077    0.7270      3212

   micro avg     0.8848    0.8848    0.8848     21274
   macro avg     0.8642    0.7120    0.7700     21274
weighted avg     0.8832    0.8848    0.8759     21274

F1-macro tok:  0.7700373372358739
F1-micro tok:  0.8847889442511987
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 67278.49403381348
train_cost_avg: 7.874355575118619
train_count_sent: 8544.0
train_total_correct_sent: 5470.0
train_accuracy_sent: 0.6402153558052435
train_count_tok: 163566.0
train_total_correct_tok: 142937.0
train_accuracy_tok: 0.8738796571414598
train_label=O_precision_sent: 0.2571428571428571
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.07563025210084033
train_label=N_precision_sent: 0.6222330333252251
train_label=N_recall_sent: 0.7728096676737161
train_label=N_f-score_sent: 0.689394960247945
train_label=P_precision_sent: 0.6838430050565856
train_label=P_recall_sent: 0.7867036011080333
train_label=P_f-score_sent: 0.7316758984928506
train_precision_macro_sent: 0.5210729651748892
train_recall_macro_sent: 0.5346160813837358
train_f-score_macro_sent: 0.4989003702805453
train_precision_micro_sent: 0.6402153558052435
train_recall_micro_sent: 0.6402153558052435
train_f-score_micro_sent: 0.6402153558052435
train_label=O_precision_tok: 0.8874524152714639
train_label=O_recall_tok: 0.965515854825609
train_label=O_f-score_tok: 0.924839773217477
train_label=N_precision_tok: 0.7573761099971354
train_label=N_recall_tok: 0.5585128855090832
train_label=N_f-score_tok: 0.6429179331306991
train_label=P_precision_tok: 0.8392857142857143
train_label=P_recall_tok: 0.5974337450533637
train_label=P_f-score_tok: 0.6980035026269702
train_precision_macro_tok: 0.8280380798514378
train_recall_macro_tok: 0.7071541617960185
train_f-score_macro_tok: 0.7552537363250488
train_precision_micro_tok: 0.8738796571414598
train_recall_micro_tok: 0.8738796571414598
train_f-score_micro_tok: 0.8738796571414598
train_time: 82.56858921051025
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2571    0.0443    0.0756      1624
           N     0.6222    0.7728    0.6894      3310
           P     0.6838    0.7867    0.7317      3610

   micro avg     0.6402    0.6402    0.6402      8544
   macro avg     0.5211    0.5346    0.4989      8544
weighted avg     0.5789    0.6402    0.5906      8544

F1-macro sent:  0.4989003702805453
F1-micro sent:  0.6402153558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8875    0.9655    0.9248    124347
           N     0.7574    0.5585    0.6429     14202
           P     0.8393    0.5974    0.6980     25017

   micro avg     0.8739    0.8739    0.8739    163566
   macro avg     0.8280    0.7072    0.7553    163566
weighted avg     0.8688    0.8739    0.8657    163566

F1-macro tok:  0.7552537363250488
F1-micro tok:  0.8738796571414598
**************************************************
dev_cost_sum: 8150.436325073242
dev_cost_avg: 7.402757788440729
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18857.0
dev_accuracy_tok: 0.8863871392309862
dev_label=O_precision_sent: 0.3508771929824561
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.13986013986013987
dev_label=N_precision_sent: 0.6491228070175439
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7077577045696067
dev_label=P_precision_sent: 0.664783427495292
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.724102564102564
dev_precision_macro_sent: 0.5549278091650973
dev_recall_macro_sent: 0.5534728909213666
dev_f-score_macro_sent: 0.5239068028441035
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8882237762237762
dev_label=O_recall_tok: 0.9797593335390312
dev_label=O_f-score_tok: 0.9317488262910798
dev_label=N_precision_tok: 0.8285229202037352
dev_label=N_recall_tok: 0.5255788906838987
dev_label=N_f-score_tok: 0.6431630971993411
dev_label=P_precision_tok: 0.9022962629446195
dev_label=P_recall_tok: 0.6239103362391034
dev_label=P_f-score_tok: 0.7377139701822198
dev_precision_macro_tok: 0.8730143197907103
dev_recall_macro_tok: 0.7097495201540113
dev_f-score_macro_tok: 0.7708752978908802
dev_precision_micro_tok: 0.8863871392309862
dev_recall_micro_tok: 0.8863871392309862
dev_f-score_micro_tok: 0.8863871392309862
dev_time: 4.266133069992065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3509    0.0873    0.1399       229
           N     0.6491    0.7780    0.7078       428
           P     0.6648    0.7950    0.7241       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.5549    0.5535    0.5239      1101
weighted avg     0.5934    0.6412    0.5962      1101

F1-macro sent:  0.5239068028441035
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8882    0.9798    0.9317     16205
           N     0.8285    0.5256    0.6432      1857
           P     0.9023    0.6239    0.7377      3212

   micro avg     0.8864    0.8864    0.8864     21274
   macro avg     0.8730    0.7097    0.7709     21274
weighted avg     0.8851    0.8864    0.8773     21274

F1-macro tok:  0.7708752978908802
F1-micro tok:  0.8863871392309862
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 65848.06616210938
train_cost_avg: 7.706936582643888
train_count_sent: 8544.0
train_total_correct_sent: 5508.0
train_accuracy_sent: 0.6446629213483146
train_count_tok: 163566.0
train_total_correct_tok: 143451.0
train_accuracy_tok: 0.8770221195113899
train_label=O_precision_sent: 0.45714285714285713
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.019288728149487643
train_label=N_precision_sent: 0.6144156752974108
train_label=N_recall_sent: 0.7957703927492447
train_label=N_f-score_sent: 0.6934316177438463
train_label=P_precision_sent: 0.6769303647560397
train_label=P_recall_sent: 0.7916897506925208
train_label=P_f-score_sent: 0.7298263534218591
train_precision_macro_sent: 0.5828296323987692
train_recall_macro_sent: 0.5324374533968447
train_f-score_macro_sent: 0.480848899771731
train_precision_micro_sent: 0.6446629213483146
train_recall_micro_sent: 0.6446629213483146
train_f-score_micro_sent: 0.6446629213483146
train_label=O_precision_tok: 0.889685057420266
train_label=O_recall_tok: 0.9675585257384577
train_label=O_f-score_tok: 0.9269891901470849
train_label=N_precision_tok: 0.7631653857102192
train_label=N_recall_tok: 0.5663286861005492
train_label=N_f-score_tok: 0.6501758215108524
train_label=P_precision_tok: 0.8482243200719263
train_label=P_recall_tok: 0.6033896950073949
train_label=P_f-score_tok: 0.705159647770537
train_precision_macro_tok: 0.8336915877341372
train_recall_macro_tok: 0.7124256356154671
train_f-score_macro_tok: 0.760774886476158
train_precision_micro_tok: 0.8770221195113899
train_recall_micro_tok: 0.8770221195113899
train_f-score_micro_tok: 0.8770221195113898
train_time: 83.5796251296997
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4571    0.0099    0.0193      1624
           N     0.6144    0.7958    0.6934      3310
           P     0.6769    0.7917    0.7298      3610

   micro avg     0.6447    0.6447    0.6447      8544
   macro avg     0.5828    0.5324    0.4808      8544
weighted avg     0.6109    0.6447    0.5807      8544

F1-macro sent:  0.480848899771731
F1-micro sent:  0.6446629213483146
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8897    0.9676    0.9270    124347
           N     0.7632    0.5663    0.6502     14202
           P     0.8482    0.6034    0.7052     25017

   micro avg     0.8770    0.8770    0.8770    163566
   macro avg     0.8337    0.7124    0.7608    163566
weighted avg     0.8724    0.8770    0.8690    163566

F1-macro tok:  0.760774886476158
F1-micro tok:  0.8770221195113898
**************************************************
dev_cost_sum: 8056.316787719727
dev_cost_avg: 7.317272286757245
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18882.0
dev_accuracy_tok: 0.887562282598477
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7150395778364116
dev_label=N_recall_sent: 0.633177570093458
dev_label=N_f-score_sent: 0.6716232961586122
dev_label=P_precision_sent: 0.574792243767313
dev_label=P_recall_sent: 0.9346846846846847
dev_label=P_f-score_sent: 0.7118353344768438
dev_precision_macro_sent: 0.42994394053457485
dev_recall_macro_sent: 0.5226207515927143
dev_f-score_macro_sent: 0.46115287687848533
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8941529405105564
dev_label=O_recall_tok: 0.9748225856217216
dev_label=O_f-score_tok: 0.9327468115257439
dev_label=N_precision_tok: 0.8096348096348096
dev_label=N_recall_tok: 0.5611200861604739
dev_label=N_f-score_tok: 0.6628498727735369
dev_label=P_precision_tok: 0.8806034482758621
dev_label=P_recall_tok: 0.636052303860523
dev_label=P_f-score_tok: 0.7386117136659436
dev_precision_macro_tok: 0.861463732807076
dev_recall_macro_tok: 0.7239983252142395
dev_f-score_macro_tok: 0.7780694659884082
dev_precision_micro_tok: 0.887562282598477
dev_recall_micro_tok: 0.887562282598477
dev_f-score_micro_tok: 0.887562282598477
dev_time: 4.230860948562622
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7150    0.6332    0.6716       428
           P     0.5748    0.9347    0.7118       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4299    0.5226    0.4612      1101
weighted avg     0.5098    0.6231    0.5481      1101

F1-macro sent:  0.46115287687848533
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8942    0.9748    0.9327     16205
           N     0.8096    0.5611    0.6628      1857
           P     0.8806    0.6361    0.7386      3212

   micro avg     0.8876    0.8876    0.8876     21274
   macro avg     0.8615    0.7240    0.7781     21274
weighted avg     0.8847    0.8876    0.8799     21274

F1-macro tok:  0.7780694659884082
F1-micro tok:  0.887562282598477
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 64750.45327758789
train_cost_avg: 7.578470655148395
train_count_sent: 8544.0
train_total_correct_sent: 5550.0
train_accuracy_sent: 0.6495786516853933
train_count_tok: 163566.0
train_total_correct_tok: 143781.0
train_accuracy_tok: 0.8790396537177653
train_label=O_precision_sent: 0.3617021276595745
train_label=O_recall_sent: 0.020935960591133004
train_label=O_f-score_sent: 0.039580908032596035
train_label=N_precision_sent: 0.6127717391304348
train_label=N_recall_sent: 0.817522658610272
train_label=N_f-score_sent: 0.7004918457157651
train_label=P_precision_sent: 0.6965790778383738
train_label=P_recall_sent: 0.778393351800554
train_label=P_f-score_sent: 0.7352171637885925
train_precision_macro_sent: 0.557017648209461
train_recall_macro_sent: 0.5389506570006529
train_f-score_macro_sent: 0.4917633058456512
train_precision_micro_sent: 0.6495786516853933
train_recall_micro_sent: 0.6495786516853933
train_f-score_micro_sent: 0.6495786516853933
train_label=O_precision_tok: 0.891718470988345
train_label=O_recall_tok: 0.9678480381513024
train_label=O_f-score_tok: 0.9282249045543943
train_label=N_precision_tok: 0.7652453436702279
train_label=N_recall_tok: 0.5699197296155472
train_label=N_f-score_tok: 0.6532951289398281
train_label=P_precision_tok: 0.8508820592477533
train_label=P_recall_tok: 0.6131030898988687
train_label=P_f-score_tok: 0.7126826661710383
train_precision_macro_tok: 0.8359486246354421
train_recall_macro_tok: 0.7169569525552394
train_f-score_macro_tok: 0.7647342332217536
train_precision_micro_tok: 0.8790396537177653
train_recall_micro_tok: 0.8790396537177653
train_f-score_micro_tok: 0.8790396537177653
train_time: 83.54960346221924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3617    0.0209    0.0396      1624
           N     0.6128    0.8175    0.7005      3310
           P     0.6966    0.7784    0.7352      3610

   micro avg     0.6496    0.6496    0.6496      8544
   macro avg     0.5570    0.5390    0.4918      8544
weighted avg     0.6005    0.6496    0.5895      8544

F1-macro sent:  0.4917633058456512
F1-micro sent:  0.6495786516853933
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8917    0.9678    0.9282    124347
           N     0.7652    0.5699    0.6533     14202
           P     0.8509    0.6131    0.7127     25017

   micro avg     0.8790    0.8790    0.8790    163566
   macro avg     0.8359    0.7170    0.7647    163566
weighted avg     0.8745    0.8790    0.8714    163566

F1-macro tok:  0.7647342332217536
F1-micro tok:  0.8790396537177653
**************************************************
dev_cost_sum: 7882.128059387207
dev_cost_avg: 7.159062724239062
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 18953.0
dev_accuracy_tok: 0.890899689762151
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06611570247933884
dev_label=N_precision_sent: 0.6047244094488189
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.722483537158984
dev_label=P_precision_sent: 0.7240618101545254
dev_label=P_recall_sent: 0.7387387387387387
dev_label=P_f-score_sent: 0.7313266443701225
dev_precision_macro_sent: 0.6480569449959867
dev_recall_macro_sent: 0.5569564994125252
dev_f-score_macro_sent: 0.5066419613361485
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.8960502489814396
dev_label=O_recall_tok: 0.9771675408824437
dev_label=O_f-score_tok: 0.9348525548307112
dev_label=N_precision_tok: 0.7860230547550432
dev_label=N_recall_tok: 0.5875067312870221
dev_label=N_f-score_tok: 0.6724191063174115
dev_label=P_precision_tok: 0.9155374887082204
dev_label=P_recall_tok: 0.6310709838107098
dev_label=P_f-score_tok: 0.7471433837080722
dev_precision_macro_tok: 0.8658702641482344
dev_recall_macro_tok: 0.7319150853267251
dev_f-score_macro_tok: 0.784805014952065
dev_precision_micro_tok: 0.890899689762151
dev_recall_micro_tok: 0.890899689762151
dev_f-score_micro_tok: 0.890899689762151
dev_time: 4.302579879760742
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0349    0.0661       229
           N     0.6047    0.8972    0.7225       428
           P     0.7241    0.7387    0.7313       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6481    0.5570    0.5066      1101
weighted avg     0.6551    0.6540    0.5895      1101

F1-macro sent:  0.5066419613361485
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9772    0.9349     16205
           N     0.7860    0.5875    0.6724      1857
           P     0.9155    0.6311    0.7471      3212

   micro avg     0.8909    0.8909    0.8909     21274
   macro avg     0.8659    0.7319    0.7848     21274
weighted avg     0.8894    0.8909    0.8836     21274

F1-macro tok:  0.784805014952065
F1-micro tok:  0.890899689762151
**************************************************
Best epoch: 9
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 63397.41191101074
train_cost_avg: 7.420109071981594
train_count_sent: 8544.0
train_total_correct_sent: 5533.0
train_accuracy_sent: 0.6475889513108615
train_count_tok: 163566.0
train_total_correct_tok: 144156.0
train_accuracy_tok: 0.8813323062250101
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010843373493975903
train_label=N_precision_sent: 0.6093926394219914
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.6975061377438946
train_label=P_precision_sent: 0.6925717087521451
train_label=P_recall_sent: 0.7825484764542936
train_label=P_f-score_sent: 0.7348159708674731
train_precision_macro_sent: 0.5173214493913788
train_recall_macro_sent: 0.5344994011201233
train_f-score_macro_sent: 0.4810551607017812
train_precision_micro_sent: 0.6475889513108615
train_recall_micro_sent: 0.6475889513108615
train_f-score_micro_sent: 0.6475889513108615
train_label=O_precision_tok: 0.893992827922102
train_label=O_recall_tok: 0.9683466428623128
train_label=O_f-score_tok: 0.9296854491267623
train_label=N_precision_tok: 0.7705498602050326
train_label=N_recall_tok: 0.5821715251373046
train_label=N_f-score_tok: 0.6632440237445852
train_label=P_precision_tok: 0.8528682426847413
train_label=P_recall_tok: 0.6186593116680658
train_label=P_f-score_tok: 0.717125382262997
train_precision_macro_tok: 0.839136976937292
train_recall_macro_tok: 0.7230591598892278
train_f-score_macro_tok: 0.7700182850447815
train_precision_micro_tok: 0.8813323062250101
train_recall_micro_tok: 0.8813323062250101
train_f-score_micro_tok: 0.8813323062250101
train_time: 84.11888241767883
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0055    0.0108      1624
           N     0.6094    0.8154    0.6975      3310
           P     0.6926    0.7825    0.7348      3610

   micro avg     0.6476    0.6476    0.6476      8544
   macro avg     0.5173    0.5345    0.4811      8544
weighted avg     0.5762    0.6476    0.5828      8544

F1-macro sent:  0.4810551607017812
F1-micro sent:  0.6475889513108615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8940    0.9683    0.9297    124347
           N     0.7705    0.5822    0.6632     14202
           P     0.8529    0.6187    0.7171     25017

   micro avg     0.8813    0.8813    0.8813    163566
   macro avg     0.8391    0.7231    0.7700    163566
weighted avg     0.8770    0.8813    0.8740    163566

F1-macro tok:  0.7700182850447815
F1-micro tok:  0.8813323062250101
**************************************************
dev_cost_sum: 7802.41584777832
dev_cost_avg: 7.086662895348156
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18982.0
dev_accuracy_tok: 0.8922628560684404
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5765765765765766
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7020109689213894
dev_label=P_precision_sent: 0.7241379310344828
dev_label=P_recall_sent: 0.7094594594594594
dev_label=P_f-score_sent: 0.7167235494880545
dev_precision_macro_sent: 0.43357150253701976
dev_recall_macro_sent: 0.5355519070472341
dev_f-score_macro_sent: 0.4729115061364813
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8959674686546933
dev_label=O_recall_tok: 0.9789571120024684
dev_label=O_f-score_tok: 0.9356256082097254
dev_label=N_precision_tok: 0.8125948406676783
dev_label=N_recall_tok: 0.5767366720516963
dev_label=N_f-score_tok: 0.6746456692913386
dev_label=P_precision_tok: 0.9097777777777778
dev_label=P_recall_tok: 0.6372976338729763
dev_label=P_f-score_tok: 0.7495422922006592
dev_precision_macro_tok: 0.872780029033383
dev_recall_macro_tok: 0.730997139309047
dev_f-score_macro_tok: 0.7866045232339077
dev_precision_micro_tok: 0.8922628560684404
dev_recall_micro_tok: 0.8922628560684404
dev_f-score_micro_tok: 0.8922628560684405
dev_time: 4.202526330947876
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5766    0.8972    0.7020       428
           P     0.7241    0.7095    0.7167       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.4336    0.5356    0.4729      1101
weighted avg     0.5162    0.6349    0.5619      1101

F1-macro sent:  0.4729115061364813
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8960    0.9790    0.9356     16205
           N     0.8126    0.5767    0.6746      1857
           P     0.9098    0.6373    0.7495      3212

   micro avg     0.8923    0.8923    0.8923     21274
   macro avg     0.8728    0.7310    0.7866     21274
weighted avg     0.8908    0.8923    0.8847     21274

F1-macro tok:  0.7866045232339077
F1-micro tok:  0.8922628560684405
**************************************************
Best epoch: 9
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 62366.90724182129
train_cost_avg: 7.299497570437885
train_count_sent: 8544.0
train_total_correct_sent: 5550.0
train_accuracy_sent: 0.6495786516853933
train_count_tok: 163566.0
train_total_correct_tok: 144529.0
train_accuracy_tok: 0.8836127312522162
train_label=O_precision_sent: 0.5862068965517241
train_label=O_recall_sent: 0.010467980295566502
train_label=O_f-score_sent: 0.0205686630369026
train_label=N_precision_sent: 0.6140552995391705
train_label=N_recall_sent: 0.8051359516616314
train_label=N_f-score_sent: 0.6967320261437908
train_label=P_precision_sent: 0.6869461077844311
train_label=P_recall_sent: 0.7944598337950138
train_label=P_f-score_sent: 0.7368015414258189
train_precision_macro_sent: 0.6290694346251086
train_recall_macro_sent: 0.5366879219174039
train_f-score_macro_sent: 0.48470074353550413
train_precision_micro_sent: 0.6495786516853933
train_recall_micro_sent: 0.6495786516853933
train_f-score_micro_sent: 0.6495786516853933
train_label=O_precision_tok: 0.8951952420199141
train_label=O_recall_tok: 0.9695770706169027
train_label=O_f-score_tok: 0.9309026893053207
train_label=N_precision_tok: 0.7746557499069594
train_label=N_recall_tok: 0.5862554569778904
train_label=N_f-score_tok: 0.6674148296593185
train_label=P_precision_tok: 0.862175423121451
train_label=P_recall_tok: 0.6251349082623816
train_label=P_f-score_tok: 0.7247659653350635
train_precision_macro_tok: 0.8440088050161081
train_recall_macro_tok: 0.7269891452857249
train_f-score_macro_tok: 0.7743611614332343
train_precision_micro_tok: 0.8836127312522162
train_recall_micro_tok: 0.8836127312522162
train_f-score_micro_tok: 0.8836127312522162
train_time: 83.46131992340088
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5862    0.0105    0.0206      1624
           N     0.6141    0.8051    0.6967      3310
           P     0.6869    0.7945    0.7368      3610

   micro avg     0.6496    0.6496    0.6496      8544
   macro avg     0.6291    0.5367    0.4847      8544
weighted avg     0.6396    0.6496    0.5851      8544

F1-macro sent:  0.48470074353550413
F1-micro sent:  0.6495786516853933
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8952    0.9696    0.9309    124347
           N     0.7747    0.5863    0.6674     14202
           P     0.8622    0.6251    0.7248     25017

   micro avg     0.8836    0.8836    0.8836    163566
   macro avg     0.8440    0.7270    0.7744    163566
weighted avg     0.8797    0.8836    0.8765    163566

F1-macro tok:  0.7743611614332343
F1-micro tok:  0.8836127312522162
**************************************************
dev_cost_sum: 7811.2789306640625
dev_cost_avg: 7.094712925217133
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19002.0
dev_accuracy_tok: 0.893202970762433
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6394927536231884
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7204081632653061
dev_label=P_precision_sent: 0.6557377049180327
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7250755287009063
dev_precision_macro_sent: 0.43174348618040703
dev_recall_macro_sent: 0.5451923886503326
dev_f-score_macro_sent: 0.4818278973220708
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.9007302601551803
dev_label=O_recall_tok: 0.9742672014810244
dev_label=O_f-score_tok: 0.9360566804019803
dev_label=N_precision_tok: 0.8005865102639296
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6780502949394599
dev_label=P_precision_tok: 0.890848026868178
dev_label=P_recall_tok: 0.6606475716064757
dev_label=P_f-score_tok: 0.7586700035752592
dev_precision_macro_tok: 0.864054932429096
dev_recall_macro_tok: 0.7409866691120962
dev_f-score_macro_tok: 0.7909256596388997
dev_precision_micro_tok: 0.893202970762433
dev_recall_micro_tok: 0.893202970762433
dev_f-score_micro_tok: 0.893202970762433
dev_time: 4.258219957351685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6395    0.8248    0.7204       428
           P     0.6557    0.8108    0.7251       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.4317    0.5452    0.4818      1101
weighted avg     0.5130    0.6476    0.5725      1101

F1-macro sent:  0.4818278973220708
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9007    0.9743    0.9361     16205
           N     0.8006    0.5880    0.6781      1857
           P     0.8908    0.6606    0.7587      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8641    0.7410    0.7909     21274
weighted avg     0.8905    0.8932    0.8868     21274

F1-macro tok:  0.7909256596388997
F1-micro tok:  0.893202970762433
**************************************************
Best epoch: 9
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 61119.47596740723
train_cost_avg: 7.153496719031745
train_count_sent: 8544.0
train_total_correct_sent: 5600.0
train_accuracy_sent: 0.6554307116104869
train_count_tok: 163566.0
train_total_correct_tok: 144796.0
train_accuracy_tok: 0.8852450998373745
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012285012285012285
train_label=N_precision_sent: 0.6280718336483931
train_label=N_recall_sent: 0.8030211480362538
train_label=N_f-score_sent: 0.7048528241845663
train_label=P_precision_sent: 0.6826833797585887
train_label=P_recall_sent: 0.8146814404432133
train_label=P_f-score_sent: 0.7428643596867897
train_precision_macro_sent: 0.5202517378023273
train_recall_macro_sent: 0.5394394506754218
train_f-score_macro_sent: 0.48298189503328576
train_precision_micro_sent: 0.6554307116104869
train_recall_micro_sent: 0.6554307116104869
train_f-score_micro_sent: 0.6554307116104869
train_label=O_precision_tok: 0.8967257966187382
train_label=O_recall_tok: 0.9699872132017661
train_label=O_f-score_tok: 0.9319188883265792
train_label=N_precision_tok: 0.7797047970479705
train_label=N_recall_tok: 0.5951274468384734
train_label=N_f-score_tok: 0.6750259563932592
train_label=P_precision_tok: 0.8632821075740944
train_label=P_recall_tok: 0.6287324619258904
train_label=P_f-score_tok: 0.7275712931054421
train_precision_macro_tok: 0.846570900413601
train_recall_macro_tok: 0.73128237398871
train_f-score_macro_tok: 0.7781720459417603
train_precision_micro_tok: 0.8852450998373745
train_recall_micro_tok: 0.8852450998373745
train_f-score_micro_tok: 0.8852450998373745
train_time: 83.29450845718384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0006    0.0012      1624
           N     0.6281    0.8030    0.7049      3310
           P     0.6827    0.8147    0.7429      3610

   micro avg     0.6554    0.6554    0.6554      8544
   macro avg     0.5203    0.5394    0.4830      8544
weighted avg     0.5793    0.6554    0.5872      8544

F1-macro sent:  0.48298189503328576
F1-micro sent:  0.6554307116104869
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8967    0.9700    0.9319    124347
           N     0.7797    0.5951    0.6750     14202
           P     0.8633    0.6287    0.7276     25017

   micro avg     0.8852    0.8852    0.8852    163566
   macro avg     0.8466    0.7313    0.7782    163566
weighted avg     0.8815    0.8852    0.8784    163566

F1-macro tok:  0.7781720459417603
F1-micro tok:  0.8852450998373745
**************************************************
dev_cost_sum: 7650.5776290893555
dev_cost_avg: 6.948753523241922
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19041.0
dev_accuracy_tok: 0.8950361944157187
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6073717948717948
dev_label=N_recall_sent: 0.8855140186915887
dev_label=N_f-score_sent: 0.7205323193916349
dev_label=P_precision_sent: 0.7040169133192389
dev_label=P_recall_sent: 0.75
dev_label=P_f-score_sent: 0.7262813522355506
dev_precision_macro_sent: 0.6871295693970113
dev_recall_macro_sent: 0.5495381517909371
dev_f-score_macro_sent: 0.49085491486285293
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8982628868896056
dev_label=O_recall_tok: 0.9796359148410985
dev_label=O_f-score_tok: 0.9371863746384085
dev_label=N_precision_tok: 0.798980335032775
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6792569659442724
dev_label=P_precision_tok: 0.9286355475763016
dev_label=P_recall_tok: 0.6441469489414695
dev_label=P_f-score_tok: 0.7606617647058824
dev_precision_macro_tok: 0.8752929231662274
dev_recall_macro_tok: 0.7381735376133959
dev_f-score_macro_tok: 0.7923683684295212
dev_precision_micro_tok: 0.8950361944157187
dev_recall_micro_tok: 0.8950361944157187
dev_f-score_micro_tok: 0.8950361944157187
dev_time: 4.303515672683716
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6074    0.8855    0.7205       428
           P     0.7040    0.7500    0.7263       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.6871    0.5495    0.4909      1101
weighted avg     0.6760    0.6494    0.5783      1101

F1-macro sent:  0.49085491486285293
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8983    0.9796    0.9372     16205
           N     0.7990    0.5907    0.6793      1857
           P     0.9286    0.6441    0.7607      3212

   micro avg     0.8950    0.8950    0.8950     21274
   macro avg     0.8753    0.7382    0.7924     21274
weighted avg     0.8942    0.8950    0.8880     21274

F1-macro tok:  0.7923683684295212
F1-micro tok:  0.8950361944157187
**************************************************
Best epoch: 9
**************************************************

EPOCH: 15
Learning rate: 0.810000
train_cost_sum: 59843.77035522461
train_cost_avg: 7.004186605246326
train_count_sent: 8544.0
train_total_correct_sent: 5582.0
train_accuracy_sent: 0.6533239700374532
train_count_tok: 163566.0
train_total_correct_tok: 145292.0
train_accuracy_tok: 0.8882775148869569
train_label=O_precision_sent: 0.4520547945205479
train_label=O_recall_sent: 0.020320197044334975
train_label=O_f-score_sent: 0.038892162639952856
train_label=N_precision_sent: 0.6273573645261399
train_label=N_recall_sent: 0.7939577039274924
train_label=N_f-score_sent: 0.700893452460328
train_label=P_precision_sent: 0.6821578701541335
train_label=P_recall_sent: 0.8091412742382271
train_label=P_f-score_sent: 0.7402432843385708
train_precision_macro_sent: 0.5871900097336071
train_recall_macro_sent: 0.5411397250700182
train_f-score_macro_sent: 0.49334296647961723
train_precision_micro_sent: 0.6533239700374532
train_recall_micro_sent: 0.6533239700374532
train_f-score_micro_sent: 0.6533239700374532
train_label=O_precision_tok: 0.8994356768523143
train_label=O_recall_tok: 0.9702928096375465
train_label=O_f-score_tok: 0.9335216062516926
train_label=N_precision_tok: 0.7893922852983989
train_label=N_recall_tok: 0.6109702858752288
train_label=N_f-score_tok: 0.6888147971739302
train_label=P_precision_tok: 0.8660409093375292
train_label=P_recall_tok: 0.6380461286325299
train_label=P_f-score_tok: 0.7347633953231449
train_precision_macro_tok: 0.8516229571627475
train_recall_macro_tok: 0.7397697413817683
train_f-score_macro_tok: 0.785699932916256
train_precision_micro_tok: 0.8882775148869569
train_recall_micro_tok: 0.8882775148869569
train_f-score_micro_tok: 0.8882775148869569
train_time: 83.82276272773743
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4521    0.0203    0.0389      1624
           N     0.6274    0.7940    0.7009      3310
           P     0.6822    0.8091    0.7402      3610

   micro avg     0.6533    0.6533    0.6533      8544
   macro avg     0.5872    0.5411    0.4933      8544
weighted avg     0.6172    0.6533    0.5917      8544

F1-macro sent:  0.49334296647961723
F1-micro sent:  0.6533239700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8994    0.9703    0.9335    124347
           N     0.7894    0.6110    0.6888     14202
           P     0.8660    0.6380    0.7348     25017

   micro avg     0.8883    0.8883    0.8883    163566
   macro avg     0.8516    0.7398    0.7857    163566
weighted avg     0.8848    0.8883    0.8819    163566

F1-macro tok:  0.785699932916256
F1-micro tok:  0.8882775148869569
**************************************************
dev_cost_sum: 7633.065490722656
dev_cost_avg: 6.93284785715046
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19037.0
dev_accuracy_tok: 0.8948481714769202
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6686390532544378
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.725133689839572
dev_label=P_precision_sent: 0.6451612903225806
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7357212003872217
dev_precision_macro_sent: 0.7046001145256727
dev_recall_macro_sent: 0.555126393176836
dev_f-score_macro_sent: 0.4983476414716093
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9011001539075415
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.9368258859784283
dev_label=N_precision_tok: 0.8033261026753434
dev_label=N_recall_tok: 0.5982767905223478
dev_label=N_f-score_tok: 0.6858024691358025
dev_label=P_precision_tok: 0.9020442930153322
dev_label=P_recall_tok: 0.6594022415940224
dev_label=P_f-score_tok: 0.7618705035971223
dev_precision_macro_tok: 0.868823516532739
dev_recall_macro_tok: 0.744393473525574
dev_f-score_macro_tok: 0.7948329529037843
dev_precision_micro_tok: 0.8948481714769202
dev_recall_micro_tok: 0.8948481714769202
dev_f-score_micro_tok: 0.8948481714769202
dev_time: 4.29094386100769
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6686    0.7921    0.7251       428
           P     0.6452    0.8559    0.7357       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.7046    0.5551    0.4983      1101
weighted avg     0.6865    0.6567    0.5857      1101

F1-macro sent:  0.4983476414716093
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9011    0.9755    0.9368     16205
           N     0.8033    0.5983    0.6858      1857
           P     0.9020    0.6594    0.7619      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8688    0.7444    0.7948     21274
weighted avg     0.8927    0.8948    0.8885     21274

F1-macro tok:  0.7948329529037843
F1-micro tok:  0.8948481714769202
**************************************************
Best epoch: 9
**************************************************

EPOCH: 16
Learning rate: 0.729000
train_cost_sum: 58584.46960449219
train_cost_avg: 6.8567965361062955
train_count_sent: 8544.0
train_total_correct_sent: 5666.0
train_accuracy_sent: 0.6631554307116105
train_count_tok: 163566.0
train_total_correct_tok: 145522.0
train_accuracy_tok: 0.8896836750914004
train_label=O_precision_sent: 0.4868421052631579
train_label=O_recall_sent: 0.022783251231527094
train_label=O_f-score_sent: 0.043529411764705886
train_label=N_precision_sent: 0.6391013384321224
train_label=N_recall_sent: 0.8078549848942598
train_label=N_f-score_sent: 0.7136375767280491
train_label=P_precision_sent: 0.6897759103641457
train_label=P_recall_sent: 0.8185595567867036
train_label=P_f-score_sent: 0.7486698758550797
train_precision_macro_sent: 0.6052397846864753
train_recall_macro_sent: 0.5497325976374968
train_f-score_macro_sent: 0.5019456214492782
train_precision_micro_sent: 0.6631554307116105
train_recall_micro_sent: 0.6631554307116105
train_f-score_micro_sent: 0.6631554307116105
train_label=O_precision_tok: 0.9008440235520631
train_label=O_recall_tok: 0.970783372337089
train_label=O_f-score_tok: 0.9345069441218822
train_label=N_precision_tok: 0.7875736961451247
train_label=N_recall_tok: 0.6113927615828757
train_label=N_f-score_tok: 0.6883894240298093
train_label=P_precision_tok: 0.8697411003236246
train_label=P_recall_tok: 0.6445616980453291
train_label=P_f-score_tok: 0.7404091190853364
train_precision_macro_tok: 0.8527196066736042
train_recall_macro_tok: 0.7422459439884314
train_f-score_macro_tok: 0.787768495745676
train_precision_micro_tok: 0.8896836750914004
train_recall_micro_tok: 0.8896836750914004
train_f-score_micro_tok: 0.8896836750914004
train_time: 60.4803352355957
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4868    0.0228    0.0435      1624
           N     0.6391    0.8079    0.7136      3310
           P     0.6898    0.8186    0.7487      3610

   micro avg     0.6632    0.6632    0.6632      8544
   macro avg     0.6052    0.5497    0.5019      8544
weighted avg     0.6316    0.6632    0.6011      8544

F1-macro sent:  0.5019456214492782
F1-micro sent:  0.6631554307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9008    0.9708    0.9345    124347
           N     0.7876    0.6114    0.6884     14202
           P     0.8697    0.6446    0.7404     25017

   micro avg     0.8897    0.8897    0.8897    163566
   macro avg     0.8527    0.7422    0.7878    163566
weighted avg     0.8863    0.8897    0.8835    163566

F1-macro tok:  0.787768495745676
F1-micro tok:  0.8896836750914004
**************************************************
dev_cost_sum: 7518.903465270996
dev_cost_avg: 6.8291584607366
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19065.0
dev_accuracy_tok: 0.8961643320485099
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.6493506493506493
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7238883143743536
dev_label=P_precision_sent: 0.6654545454545454
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7364185110663984
dev_precision_macro_sent: 0.7160461760461762
dev_recall_macro_sent: 0.5619164853136204
dev_f-score_macro_sent: 0.5144314591026573
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9021677124928693
dev_label=O_recall_tok: 0.9759333539031163
dev_label=O_f-score_tok: 0.9376018971394694
dev_label=N_precision_tok: 0.8054363376251789
dev_label=N_recall_tok: 0.6063543349488422
dev_label=N_f-score_tok: 0.6918586789554532
dev_label=P_precision_tok: 0.9053708439897699
dev_label=P_recall_tok: 0.6612702366127023
dev_label=P_f-score_tok: 0.7643037063691975
dev_precision_macro_tok: 0.8709916313692728
dev_recall_macro_tok: 0.7478526418215536
dev_f-score_macro_tok: 0.7979214274880401
dev_precision_micro_tok: 0.8961643320485099
dev_recall_micro_tok: 0.8961643320485099
dev_f-score_micro_tok: 0.89616433204851
dev_time: 1.9801411628723145
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.6494    0.8178    0.7239       428
           P     0.6655    0.8243    0.7364       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.7160    0.5619    0.5144      1101
weighted avg     0.6941    0.6594    0.5956      1101

F1-macro sent:  0.5144314591026573
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9022    0.9759    0.9376     16205
           N     0.8054    0.6064    0.6919      1857
           P     0.9054    0.6613    0.7643      3212

   micro avg     0.8962    0.8962    0.8962     21274
   macro avg     0.8710    0.7479    0.7979     21274
weighted avg     0.8942    0.8962    0.8900     21274

F1-macro tok:  0.7979214274880401
F1-micro tok:  0.89616433204851
**************************************************
Best epoch: 9
**************************************************

test0_cost_sum: 8150.436325073242
test0_cost_avg: 7.402757788440729
test0_count_sent: 1101.0
test0_total_correct_sent: 706.0
test0_accuracy_sent: 0.6412352406902816
test0_count_tok: 21274.0
test0_total_correct_tok: 18857.0
test0_accuracy_tok: 0.8863871392309862
test0_label=O_precision_sent: 0.3508771929824561
test0_label=O_recall_sent: 0.08733624454148471
test0_label=O_f-score_sent: 0.13986013986013987
test0_label=N_precision_sent: 0.6491228070175439
test0_label=N_recall_sent: 0.7780373831775701
test0_label=N_f-score_sent: 0.7077577045696067
test0_label=P_precision_sent: 0.664783427495292
test0_label=P_recall_sent: 0.795045045045045
test0_label=P_f-score_sent: 0.724102564102564
test0_precision_macro_sent: 0.5549278091650973
test0_recall_macro_sent: 0.5534728909213666
test0_f-score_macro_sent: 0.5239068028441035
test0_precision_micro_sent: 0.6412352406902816
test0_recall_micro_sent: 0.6412352406902816
test0_f-score_micro_sent: 0.6412352406902816
test0_label=O_precision_tok: 0.8882237762237762
test0_label=O_recall_tok: 0.9797593335390312
test0_label=O_f-score_tok: 0.9317488262910798
test0_label=N_precision_tok: 0.8285229202037352
test0_label=N_recall_tok: 0.5255788906838987
test0_label=N_f-score_tok: 0.6431630971993411
test0_label=P_precision_tok: 0.9022962629446195
test0_label=P_recall_tok: 0.6239103362391034
test0_label=P_f-score_tok: 0.7377139701822198
test0_precision_macro_tok: 0.8730143197907103
test0_recall_macro_tok: 0.7097495201540113
test0_f-score_macro_tok: 0.7708752978908802
test0_precision_micro_tok: 0.8863871392309862
test0_recall_micro_tok: 0.8863871392309862
test0_f-score_micro_tok: 0.8863871392309862
test0_time: 2.003856897354126
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3509    0.0873    0.1399       229
           N     0.6491    0.7780    0.7078       428
           P     0.6648    0.7950    0.7241       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.5549    0.5535    0.5239      1101
weighted avg     0.5934    0.6412    0.5962      1101

F1-macro sent:  0.5239068028441035
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8882    0.9798    0.9317     16205
           N     0.8285    0.5256    0.6432      1857
           P     0.9023    0.6239    0.7377      3212

   micro avg     0.8864    0.8864    0.8864     21274
   macro avg     0.8730    0.7097    0.7709     21274
weighted avg     0.8851    0.8864    0.8773     21274

F1-macro tok:  0.7708752978908802
F1-micro tok:  0.8863871392309862
**************************************************
test1_cost_sum: 16851.089698791504
test1_cost_avg: 7.624927465516517
test1_count_sent: 2210.0
test1_total_correct_sent: 1470.0
test1_accuracy_sent: 0.665158371040724
test1_count_tok: 42405.0
test1_total_correct_tok: 37206.0
test1_accuracy_tok: 0.8773965334276619
test1_label=O_precision_sent: 0.2714285714285714
test1_label=O_recall_sent: 0.09768637532133675
test1_label=O_f-score_sent: 0.1436672967863894
test1_label=N_precision_sent: 0.6842629482071713
test1_label=N_recall_sent: 0.7532894736842105
test1_label=N_f-score_sent: 0.7171189979123174
test1_label=P_precision_sent: 0.698874296435272
test1_label=P_recall_sent: 0.8195819581958196
test1_label=P_f-score_sent: 0.7544303797468355
test1_precision_macro_sent: 0.5515219386903382
test1_recall_macro_sent: 0.5568526024004555
test1_f-score_macro_sent: 0.5384055581485141
test1_precision_micro_sent: 0.665158371040724
test1_recall_micro_sent: 0.665158371040724
test1_f-score_micro_sent: 0.665158371040724
test1_label=O_precision_tok: 0.8782263031185265
test1_label=O_recall_tok: 0.9804362772673292
test1_label=O_f-score_tok: 0.9265209686946249
test1_label=N_precision_tok: 0.8222789115646258
test1_label=N_recall_tok: 0.5143617021276595
test1_label=N_f-score_tok: 0.6328534031413612
test1_label=P_precision_tok: 0.9004848764719464
test1_label=P_recall_tok: 0.5867308560252745
test1_label=P_f-score_tok: 0.7105119329568226
test1_precision_macro_tok: 0.8669966970516997
test1_recall_macro_tok: 0.6938429451400877
test1_f-score_macro_tok: 0.7566287682642695
test1_precision_micro_tok: 0.8773965334276619
test1_recall_micro_tok: 0.8773965334276619
test1_f-score_micro_tok: 0.8773965334276619
test1_time: 4.074045896530151
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2714    0.0977    0.1437       389
           N     0.6843    0.7533    0.7171       912
           P     0.6989    0.8196    0.7544       909

   micro avg     0.6652    0.6652    0.6652      2210
   macro avg     0.5515    0.5569    0.5384      2210
weighted avg     0.6176    0.6652    0.6315      2210

F1-macro sent:  0.5384055581485141
F1-micro sent:  0.665158371040724
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8782    0.9804    0.9265     31998
           N     0.8223    0.5144    0.6329      3760
           P     0.9005    0.5867    0.7105      6647

   micro avg     0.8774    0.8774    0.8774     42405
   macro avg     0.8670    0.6938    0.7566     42405
weighted avg     0.8768    0.8774    0.8666     42405

F1-macro tok:  0.7566287682642695
F1-micro tok:  0.8773965334276619
**************************************************
