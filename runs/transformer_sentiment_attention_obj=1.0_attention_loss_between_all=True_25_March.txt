to_write_filename: runs/transformer_sentiment_attention_obj=1.0_attention_loss_between_all=True_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 1.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 437195.3826904297
train_cost_avg: 51.16987156957276
train_count_sent: 8544.0
train_total_correct_sent: 4182.0
train_accuracy_sent: 0.48946629213483145
train_count_tok: 163566.0
train_total_correct_tok: 126065.0
train_accuracy_tok: 0.7707286355355025
train_label=O_precision_sent: 0.23770491803278687
train_label=O_recall_sent: 0.03571428571428571
train_label=O_f-score_sent: 0.06209850107066381
train_label=N_precision_sent: 0.47121094758585075
train_label=N_recall_sent: 0.5513595166163142
train_label=N_f-score_sent: 0.5081442294306
train_label=P_precision_sent: 0.51931330472103
train_label=P_recall_sent: 0.6368421052631579
train_label=P_f-score_sent: 0.5721040189125295
train_precision_macro_sent: 0.40940972344655585
train_recall_macro_sent: 0.4079719691979193
train_f-score_macro_sent: 0.3807822498045978
train_precision_micro_sent: 0.48946629213483145
train_recall_micro_sent: 0.48946629213483145
train_f-score_micro_sent: 0.48946629213483145
train_label=O_precision_tok: 0.7956917043821597
train_label=O_recall_tok: 0.9529461909012682
train_label=O_f-score_tok: 0.8672480230102939
train_label=N_precision_tok: 0.49930963065239903
train_label=N_recall_tok: 0.2037037037037037
train_label=N_f-score_tok: 0.28935787157431486
train_label=P_precision_tok: 0.528361581920904
train_label=P_recall_tok: 0.1869128992285246
train_label=P_f-score_tok: 0.2761390143797798
train_precision_macro_tok: 0.6077876389851543
train_recall_macro_tok: 0.44785426461116556
train_f-score_macro_tok: 0.47758163632146283
train_precision_micro_tok: 0.7707286355355025
train_recall_micro_tok: 0.7707286355355025
train_f-score_micro_tok: 0.7707286355355026
train_time: 146.80800485610962
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2377    0.0357    0.0621      1624
           N     0.4712    0.5514    0.5081      3310
           P     0.5193    0.6368    0.5721      3610

   micro avg     0.4895    0.4895    0.4895      8544
   macro avg     0.4094    0.4080    0.3808      8544
weighted avg     0.4472    0.4895    0.4504      8544

F1-macro sent:  0.3807822498045978
F1-micro sent:  0.48946629213483145
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7957    0.9529    0.8672    124347
           N     0.4993    0.2037    0.2894     14202
           P     0.5284    0.1869    0.2761     25017

   micro avg     0.7707    0.7707    0.7707    163566
   macro avg     0.6078    0.4479    0.4776    163566
weighted avg     0.7291    0.7707    0.7267    163566

F1-macro tok:  0.47758163632146283
F1-micro tok:  0.7707286355355026
**************************************************
dev_cost_sum: 51827.247314453125
dev_cost_avg: 47.07288584418994
dev_count_sent: 1101.0
dev_total_correct_sent: 630.0
dev_accuracy_sent: 0.5722070844686649
dev_count_tok: 21274.0
dev_total_correct_tok: 17433.0
dev_accuracy_tok: 0.8194509730187083
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6440217391304348
dev_label=N_recall_sent: 0.5537383177570093
dev_label=N_f-score_sent: 0.5954773869346733
dev_label=P_precision_sent: 0.5361527967257844
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.6677994902293968
dev_precision_macro_sent: 0.39339151195207306
dev_recall_macro_sent: 0.4796244842973814
dev_f-score_macro_sent: 0.42109229238802337
dev_precision_micro_sent: 0.5722070844686649
dev_recall_micro_sent: 0.5722070844686649
dev_f-score_micro_sent: 0.5722070844686649
dev_label=O_precision_tok: 0.83102714209686
dev_label=O_recall_tok: 0.9635914841098426
dev_label=O_f-score_tok: 0.8924132018859837
dev_label=N_precision_tok: 0.7078891257995735
dev_label=N_recall_tok: 0.35756596661281637
dev_label=N_f-score_tok: 0.47513416815742404
dev_label=P_precision_tok: 0.7464424320827943
dev_label=P_recall_tok: 0.3592777085927771
dev_label=P_f-score_tok: 0.4850777637662883
dev_precision_macro_tok: 0.7617862333264093
dev_recall_macro_tok: 0.5601450531051454
dev_f-score_macro_tok: 0.6175417112698987
dev_precision_micro_tok: 0.8194509730187083
dev_recall_micro_tok: 0.8194509730187083
dev_f-score_micro_tok: 0.8194509730187083
dev_time: 8.800348043441772
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6440    0.5537    0.5955       428
           P     0.5362    0.8851    0.6678       444

   micro avg     0.5722    0.5722    0.5722      1101
   macro avg     0.3934    0.4796    0.4211      1101
weighted avg     0.4666    0.5722    0.5008      1101

F1-macro sent:  0.42109229238802337
F1-micro sent:  0.5722070844686649
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8310    0.9636    0.8924     16205
           N     0.7079    0.3576    0.4751      1857
           P     0.7464    0.3593    0.4851      3212

   micro avg     0.8195    0.8195    0.8195     21274
   macro avg     0.7618    0.5601    0.6175     21274
weighted avg     0.8075    0.8195    0.7945     21274

F1-macro tok:  0.6175417112698987
F1-micro tok:  0.8194509730187083
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 389111.9367675781
train_cost_avg: 45.542127430662234
train_count_sent: 8544.0
train_total_correct_sent: 4915.0
train_accuracy_sent: 0.5752574906367042
train_count_tok: 163566.0
train_total_correct_tok: 132319.0
train_accuracy_tok: 0.8089639656163261
train_label=O_precision_sent: 0.34615384615384615
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010909090909090908
train_label=N_precision_sent: 0.5412087912087912
train_label=N_recall_sent: 0.7141993957703927
train_label=N_f-score_sent: 0.6157853607710341
train_label=P_precision_sent: 0.6125301204819277
train_label=P_recall_sent: 0.7041551246537396
train_label=P_f-score_sent: 0.6551546391752576
train_precision_macro_sent: 0.49996425261485494
train_recall_macro_sent: 0.4746321307817715
train_f-score_macro_sent: 0.42728303028512754
train_precision_micro_sent: 0.5752574906367042
train_recall_micro_sent: 0.5752574906367042
train_f-score_micro_sent: 0.5752574906367042
train_label=O_precision_tok: 0.8288930634021663
train_label=O_recall_tok: 0.9545465511833819
train_label=O_f-score_tok: 0.887293305026463
train_label=N_precision_tok: 0.6479872751743546
train_label=N_recall_tok: 0.37290522461625125
train_label=N_f-score_tok: 0.4733854748603352
train_label=P_precision_tok: 0.682846835027878
train_label=P_recall_tok: 0.33289363233001557
train_label=P_f-score_tok: 0.4475855211888318
train_precision_macro_tok: 0.719909057868133
train_recall_macro_tok: 0.5534484693765496
train_f-score_macro_tok: 0.60275476702521
train_precision_micro_tok: 0.8089639656163261
train_recall_micro_tok: 0.8089639656163261
train_f-score_micro_tok: 0.8089639656163262
train_time: 145.66822910308838
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3462    0.0055    0.0109      1624
           N     0.5412    0.7142    0.6158      3310
           P     0.6125    0.7042    0.6552      3610

   micro avg     0.5753    0.5753    0.5753      8544
   macro avg     0.5000    0.4746    0.4273      8544
weighted avg     0.5343    0.5753    0.5174      8544

F1-macro sent:  0.42728303028512754
F1-micro sent:  0.5752574906367042
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8289    0.9545    0.8873    124347
           N     0.6480    0.3729    0.4734     14202
           P     0.6828    0.3329    0.4476     25017

   micro avg     0.8090    0.8090    0.8090    163566
   macro avg     0.7199    0.5534    0.6028    163566
weighted avg     0.7908    0.8090    0.7841    163566

F1-macro tok:  0.60275476702521
F1-micro tok:  0.8089639656163262
**************************************************
dev_cost_sum: 50592.44696044922
dev_cost_avg: 45.95135963710192
dev_count_sent: 1101.0
dev_total_correct_sent: 647.0
dev_accuracy_sent: 0.5876475930971844
dev_count_tok: 21274.0
dev_total_correct_tok: 17688.0
dev_accuracy_tok: 0.8314374353671148
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5036764705882353
dev_label=N_recall_sent: 0.9602803738317757
dev_label=N_f-score_sent: 0.6607717041800644
dev_label=P_precision_sent: 0.8309859154929577
dev_label=P_recall_sent: 0.5315315315315315
dev_label=P_f-score_sent: 0.6483516483516483
dev_precision_macro_sent: 0.44488746202706436
dev_recall_macro_sent: 0.4972706351211024
dev_f-score_macro_sent: 0.43637445084390425
dev_precision_micro_sent: 0.5876475930971844
dev_recall_micro_sent: 0.5876475930971844
dev_f-score_micro_sent: 0.5876475930971844
dev_label=O_precision_tok: 0.8397003745318352
dev_label=O_recall_tok: 0.9684665226781858
dev_label=O_f-score_tok: 0.8994984954864594
dev_label=N_precision_tok: 0.6877897990726429
dev_label=N_recall_tok: 0.47926763597199784
dev_label=N_f-score_tok: 0.5649000317359568
dev_label=P_precision_tok: 0.8558139534883721
dev_label=P_recall_tok: 0.3437110834371108
dev_label=P_f-score_tok: 0.49044868947134607
dev_precision_macro_tok: 0.7944347090309501
dev_recall_macro_tok: 0.5971484140290982
dev_f-score_macro_tok: 0.6516157388979208
dev_precision_micro_tok: 0.8314374353671148
dev_recall_micro_tok: 0.8314374353671148
dev_f-score_micro_tok: 0.8314374353671148
dev_time: 8.414108037948608
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5037    0.9603    0.6608       428
           P     0.8310    0.5315    0.6484       444

   micro avg     0.5876    0.5876    0.5876      1101
   macro avg     0.4449    0.4973    0.4364      1101
weighted avg     0.5309    0.5876    0.5183      1101

F1-macro sent:  0.43637445084390425
F1-micro sent:  0.5876475930971844
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8397    0.9685    0.8995     16205
           N     0.6878    0.4793    0.5649      1857
           P     0.8558    0.3437    0.4904      3212

   micro avg     0.8314    0.8314    0.8314     21274
   macro avg     0.7944    0.5971    0.6516     21274
weighted avg     0.8289    0.8314    0.8085     21274

F1-macro tok:  0.6516157388979208
F1-micro tok:  0.8314374353671148
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 380318.3887939453
train_cost_avg: 44.51292003674453
train_count_sent: 8544.0
train_total_correct_sent: 5087.0
train_accuracy_sent: 0.5953885767790262
train_count_tok: 163566.0
train_total_correct_tok: 135022.0
train_accuracy_tok: 0.8254894048885465
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5593142857142858
train_label=N_recall_sent: 0.739274924471299
train_label=N_f-score_sent: 0.6368249837345479
train_label=P_precision_sent: 0.634158059092001
train_label=P_recall_sent: 0.7313019390581718
train_label=P_f-score_sent: 0.6792744114241606
train_precision_macro_sent: 0.3978241149354289
train_recall_macro_sent: 0.490192287843157
train_f-score_macro_sent: 0.43869979838623613
train_precision_micro_sent: 0.5953885767790262
train_recall_micro_sent: 0.5953885767790262
train_f-score_micro_sent: 0.5953885767790262
train_label=O_precision_tok: 0.84286280673435
train_label=O_recall_tok: 0.9574095072659574
train_label=O_f-score_tok: 0.896492000918699
train_label=N_precision_tok: 0.6836923789668752
train_label=N_recall_tok: 0.4156456837065202
train_label=N_f-score_tok: 0.5169907164126818
train_label=P_precision_tok: 0.7356422621657168
train_label=P_recall_tok: 0.402446336491186
train_label=P_f-score_tok: 0.5202697465312767
train_precision_macro_tok: 0.7540658159556474
train_recall_macro_tok: 0.5918338424878878
train_f-score_macro_tok: 0.6445841546208858
train_precision_micro_tok: 0.8254894048885465
train_recall_micro_tok: 0.8254894048885465
train_f-score_micro_tok: 0.8254894048885465
train_time: 145.04900765419006
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5593    0.7393    0.6368      3310
           P     0.6342    0.7313    0.6793      3610

   micro avg     0.5954    0.5954    0.5954      8544
   macro avg     0.3978    0.4902    0.4387      8544
weighted avg     0.4846    0.5954    0.5337      8544

F1-macro sent:  0.43869979838623613
F1-micro sent:  0.5953885767790262
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8429    0.9574    0.8965    124347
           N     0.6837    0.4156    0.5170     14202
           P     0.7356    0.4024    0.5203     25017

   micro avg     0.8255    0.8255    0.8255    163566
   macro avg     0.7541    0.5918    0.6446    163566
weighted avg     0.8126    0.8255    0.8060    163566

F1-macro tok:  0.6445841546208858
F1-micro tok:  0.8254894048885465
**************************************************
dev_cost_sum: 49674.94598388672
dev_cost_avg: 45.11802541679084
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18196.0
dev_accuracy_tok: 0.8553163485945285
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6095764272559853
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.6817713697219361
dev_label=P_precision_sent: 0.6362007168458781
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7085828343313373
dev_precision_macro_sent: 0.4152590480339544
dev_recall_macro_sent: 0.524304678510286
dev_f-score_macro_sent: 0.4634514013510911
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8673067317831178
dev_label=O_recall_tok: 0.9643937056464055
dev_label=O_f-score_tok: 0.9132772323515661
dev_label=N_precision_tok: 0.7870563674321504
dev_label=N_recall_tok: 0.40603123317178247
dev_label=N_f-score_tok: 0.5357015985790409
dev_label=P_precision_tok: 0.7897257292120157
dev_label=P_recall_tok: 0.5647571606475716
dev_label=P_f-score_tok: 0.6585587220911236
dev_precision_macro_tok: 0.814696276142428
dev_recall_macro_tok: 0.6450606998219198
dev_f-score_macro_tok: 0.7025125176739101
dev_precision_micro_tok: 0.8553163485945285
dev_recall_micro_tok: 0.8553163485945285
dev_f-score_micro_tok: 0.8553163485945284
dev_time: 8.162352323532104
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6096    0.7734    0.6818       428
           P     0.6362    0.7995    0.7086       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4153    0.5243    0.4635      1101
weighted avg     0.4935    0.6231    0.5508      1101

F1-macro sent:  0.4634514013510911
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8673    0.9644    0.9133     16205
           N     0.7871    0.4060    0.5357      1857
           P     0.7897    0.5648    0.6586      3212

   micro avg     0.8553    0.8553    0.8553     21274
   macro avg     0.8147    0.6451    0.7025     21274
weighted avg     0.8486    0.8553    0.8419     21274

F1-macro tok:  0.7025125176739101
F1-micro tok:  0.8553163485945284
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 373916.0139160156
train_cost_avg: 43.763578407773366
train_count_sent: 8544.0
train_total_correct_sent: 5146.0
train_accuracy_sent: 0.6022940074906367
train_count_tok: 163566.0
train_total_correct_tok: 137081.0
train_accuracy_tok: 0.8380775955883252
train_label=O_precision_sent: 0.26666666666666666
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004881025015253204
train_label=N_precision_sent: 0.5705635770843037
train_label=N_recall_sent: 0.7401812688821753
train_label=N_f-score_sent: 0.6443976854287218
train_label=P_precision_sent: 0.635655253837072
train_label=P_recall_sent: 0.7457063711911357
train_label=P_f-score_sent: 0.6862970044614404
train_precision_macro_sent: 0.4909618325293475
train_recall_macro_sent: 0.4961168980868344
train_f-score_macro_sent: 0.4451919049684718
train_precision_micro_sent: 0.6022940074906367
train_recall_micro_sent: 0.6022940074906367
train_f-score_micro_sent: 0.6022940074906367
train_label=O_precision_tok: 0.8544384973094588
train_label=O_recall_tok: 0.9589937835251353
train_label=O_f-score_tok: 0.9037020196279034
train_label=N_precision_tok: 0.6954003786613209
train_label=N_recall_tok: 0.43965638642444727
train_label=N_f-score_tok: 0.5387170527587248
train_label=P_precision_tok: 0.7713658146964856
train_label=P_recall_tok: 0.46324499340448494
train_label=P_f-score_tok: 0.5788566719112909
train_precision_macro_tok: 0.7737348968890885
train_recall_macro_tok: 0.6206317211180225
train_f-score_macro_tok: 0.6737585814326398
train_precision_micro_tok: 0.8380775955883252
train_recall_micro_tok: 0.8380775955883252
train_f-score_micro_tok: 0.8380775955883252
train_time: 146.14241695404053
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2667    0.0025    0.0049      1624
           N     0.5706    0.7402    0.6444      3310
           P     0.6357    0.7457    0.6863      3610

   micro avg     0.6023    0.6023    0.6023      8544
   macro avg     0.4910    0.4961    0.4452      8544
weighted avg     0.5403    0.6023    0.5405      8544

F1-macro sent:  0.4451919049684718
F1-micro sent:  0.6022940074906367
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8544    0.9590    0.9037    124347
           N     0.6954    0.4397    0.5387     14202
           P     0.7714    0.4632    0.5789     25017

   micro avg     0.8381    0.8381    0.8381    163566
   macro avg     0.7737    0.6206    0.6738    163566
weighted avg     0.8279    0.8381    0.8223    163566

F1-macro tok:  0.6737585814326398
F1-micro tok:  0.8380775955883252
**************************************************
dev_cost_sum: 48968.1728515625
dev_cost_avg: 44.476087966905084
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18367.0
dev_accuracy_tok: 0.8633543292281658
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6203208556149733
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7037411526794743
dev_label=P_precision_sent: 0.6573556797020484
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7196738022426097
dev_precision_macro_sent: 0.7592255117723407
dev_recall_macro_sent: 0.5404098646252669
dev_f-score_macro_sent: 0.48309234129586703
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8701155142872934
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.9180127121114935
dev_label=N_precision_tok: 0.7874165872259294
dev_label=N_recall_tok: 0.4448034464189553
dev_label=N_f-score_tok: 0.5684790089470062
dev_label=P_precision_tok: 0.8433395872420263
dev_label=P_recall_tok: 0.5597758405977584
dev_label=P_f-score_tok: 0.6729041916167665
dev_precision_macro_tok: 0.8336238962517498
dev_recall_macro_tok: 0.6586898559314173
dev_f-score_macro_tok: 0.719798637558422
dev_precision_micro_tok: 0.8633543292281658
dev_recall_micro_tok: 0.8633543292281658
dev_f-score_micro_tok: 0.8633543292281658
dev_time: 8.33874797821045
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6203    0.8131    0.7037       428
           P     0.6574    0.7950    0.7197       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7592    0.5404    0.4831      1101
weighted avg     0.7142    0.6394    0.5692      1101

F1-macro sent:  0.48309234129586703
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8701    0.9715    0.9180     16205
           N     0.7874    0.4448    0.5685      1857
           P     0.8433    0.5598    0.6729      3212

   micro avg     0.8634    0.8634    0.8634     21274
   macro avg     0.8336    0.6587    0.7198     21274
weighted avg     0.8589    0.8634    0.8505     21274

F1-macro tok:  0.719798637558422
F1-micro tok:  0.8633543292281658
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 367867.65100097656
train_cost_avg: 43.05567076322291
train_count_sent: 8544.0
train_total_correct_sent: 5224.0
train_accuracy_sent: 0.6114232209737828
train_count_tok: 163566.0
train_total_correct_tok: 138980.0
train_accuracy_tok: 0.8496875878850128
train_label=O_precision_sent: 0.37209302325581395
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.019196160767846433
train_label=N_precision_sent: 0.587823145687364
train_label=N_recall_sent: 0.7350453172205438
train_label=N_f-score_sent: 0.653242045912203
train_label=P_precision_sent: 0.6361760660247593
train_label=P_recall_sent: 0.7686980609418282
train_label=P_f-score_sent: 0.6961866532865029
train_precision_macro_sent: 0.5320307449893124
train_recall_macro_sent: 0.5045318649703802
train_f-score_macro_sent: 0.45620828665551744
train_precision_micro_sent: 0.6114232209737828
train_recall_micro_sent: 0.6114232209737828
train_f-score_micro_sent: 0.6114232209737828
train_label=O_precision_tok: 0.8637012780935345
train_label=O_recall_tok: 0.9630067472476216
train_label=O_f-score_tok: 0.910654737234354
train_label=N_precision_tok: 0.7159004456037388
train_label=N_recall_tok: 0.4638079143782566
train_label=N_f-score_tok: 0.5629192838524976
train_label=P_precision_tok: 0.8044017556135106
train_label=P_recall_tok: 0.5054962625414718
train_label=P_f-score_tok: 0.6208454023270656
train_precision_macro_tok: 0.7946678264369279
train_recall_macro_tok: 0.6441036413891167
train_f-score_macro_tok: 0.698139807804639
train_precision_micro_tok: 0.8496875878850128
train_recall_micro_tok: 0.8496875878850128
train_f-score_micro_tok: 0.8496875878850128
train_time: 145.8290069103241
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3721    0.0099    0.0192      1624
           N     0.5878    0.7350    0.6532      3310
           P     0.6362    0.7687    0.6962      3610

   micro avg     0.6114    0.6114    0.6114      8544
   macro avg     0.5320    0.5045    0.4562      8544
weighted avg     0.5672    0.6114    0.5509      8544

F1-macro sent:  0.45620828665551744
F1-micro sent:  0.6114232209737828
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8637    0.9630    0.9107    124347
           N     0.7159    0.4638    0.5629     14202
           P     0.8044    0.5055    0.6208     25017

   micro avg     0.8497    0.8497    0.8497    163566
   macro avg     0.7947    0.6441    0.6981    163566
weighted avg     0.8418    0.8497    0.8361    163566

F1-macro tok:  0.698139807804639
F1-micro tok:  0.8496875878850128
**************************************************
dev_cost_sum: 48360.29345703125
dev_cost_avg: 43.92397225888397
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18457.0
dev_accuracy_tok: 0.8675848453511328
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5913621262458472
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.6912621359223302
dev_label=P_precision_sent: 0.6693386773547094
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7083775185577942
dev_precision_macro_sent: 0.42023360120018555
dev_recall_macro_sent: 0.5280093177289439
dev_f-score_macro_sent: 0.4665465514933748
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8794760807240429
dev_label=O_recall_tok: 0.9654427645788337
dev_label=O_f-score_tok: 0.9204565511560864
dev_label=N_precision_tok: 0.7097701149425287
dev_label=N_recall_tok: 0.5320409262250942
dev_label=N_f-score_tok: 0.608187134502924
dev_label=P_precision_tok: 0.8714763497372193
dev_label=P_recall_tok: 0.5678704856787049
dev_label=P_f-score_tok: 0.6876531573986806
dev_precision_macro_tok: 0.8202408484679303
dev_recall_macro_tok: 0.6884513921608777
dev_f-score_macro_tok: 0.7387656143525637
dev_precision_micro_tok: 0.8675848453511328
dev_recall_micro_tok: 0.8675848453511328
dev_f-score_micro_tok: 0.8675848453511328
dev_time: 8.308177471160889
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5914    0.8318    0.6913       428
           P     0.6693    0.7523    0.7084       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4202    0.5280    0.4665      1101
weighted avg     0.4998    0.6267    0.5544      1101

F1-macro sent:  0.4665465514933748
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8795    0.9654    0.9205     16205
           N     0.7098    0.5320    0.6082      1857
           P     0.8715    0.5679    0.6877      3212

   micro avg     0.8676    0.8676    0.8676     21274
   macro avg     0.8202    0.6885    0.7388     21274
weighted avg     0.8635    0.8676    0.8580     21274

F1-macro tok:  0.7387656143525637
F1-micro tok:  0.8675848453511328
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 363424.185546875
train_cost_avg: 42.5356022409732
train_count_sent: 8544.0
train_total_correct_sent: 5261.0
train_accuracy_sent: 0.615753745318352
train_count_tok: 163566.0
train_total_correct_tok: 139793.0
train_accuracy_tok: 0.8546580585207194
train_label=O_precision_sent: 0.46153846153846156
train_label=O_recall_sent: 0.011083743842364532
train_label=O_f-score_sent: 0.02164762477450391
train_label=N_precision_sent: 0.589719181342218
train_label=N_recall_sent: 0.7486404833836858
train_label=N_f-score_sent: 0.659744408945687
train_label=P_precision_sent: 0.6425749477108994
train_label=P_recall_sent: 0.7659279778393352
train_label=P_f-score_sent: 0.698849993681284
train_precision_macro_sent: 0.5646108635305263
train_recall_macro_sent: 0.5085507350217952
train_f-score_macro_sent: 0.4600806758004916
train_precision_micro_sent: 0.615753745318352
train_recall_micro_sent: 0.615753745318352
train_f-score_micro_sent: 0.615753745318352
train_label=O_precision_tok: 0.8686078464070532
train_label=O_recall_tok: 0.9634410158668886
train_label=O_f-score_tok: 0.9135699851298279
train_label=N_precision_tok: 0.7202083554799618
train_label=N_recall_tok: 0.47704548655118995
train_label=N_f-score_tok: 0.5739336693633783
train_label=P_precision_tok: 0.8140551860064055
train_label=P_recall_tok: 0.528320741895511
train_label=P_f-score_tok: 0.6407776404140305
train_precision_macro_tok: 0.8009571292978069
train_recall_macro_tok: 0.6562690814378632
train_f-score_macro_tok: 0.7094270983024122
train_precision_micro_tok: 0.8546580585207194
train_recall_micro_tok: 0.8546580585207194
train_f-score_micro_tok: 0.8546580585207194
train_time: 144.65888333320618
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0111    0.0216      1624
           N     0.5897    0.7486    0.6597      3310
           P     0.6426    0.7659    0.6988      3610

   micro avg     0.6158    0.6158    0.6158      8544
   macro avg     0.5646    0.5086    0.4601      8544
weighted avg     0.5877    0.6158    0.5550      8544

F1-macro sent:  0.4600806758004916
F1-micro sent:  0.615753745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8686    0.9634    0.9136    124347
           N     0.7202    0.4770    0.5739     14202
           P     0.8141    0.5283    0.6408     25017

   micro avg     0.8547    0.8547    0.8547    163566
   macro avg     0.8010    0.6563    0.7094    163566
weighted avg     0.8474    0.8547    0.8424    163566

F1-macro tok:  0.7094270983024122
F1-micro tok:  0.8546580585207194
**************************************************
dev_cost_sum: 47872.44934082031
dev_cost_avg: 43.48088041854706
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18546.0
dev_accuracy_tok: 0.8717683557394003
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5364583333333334
dev_label=N_recall_sent: 0.9626168224299065
dev_label=N_f-score_sent: 0.6889632107023412
dev_label=P_precision_sent: 0.7957957957957958
dev_label=P_recall_sent: 0.5968468468468469
dev_label=P_f-score_sent: 0.6821106821106822
dev_precision_macro_sent: 0.44408470970970976
dev_recall_macro_sent: 0.5198212230922511
dev_f-score_macro_sent: 0.4570246309376745
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8729172394830904
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9231753416690898
dev_label=N_precision_tok: 0.7891617273497037
dev_label=N_recall_tok: 0.501884760366182
dev_label=N_f-score_tok: 0.6135615536537197
dev_label=P_precision_tok: 0.9119496855345912
dev_label=P_recall_tok: 0.5417185554171855
dev_label=P_f-score_tok: 0.6796875
dev_precision_macro_tok: 0.8580095507891284
dev_recall_macro_tok: 0.6743925070918332
dev_f-score_macro_tok: 0.7388081317742698
dev_precision_micro_tok: 0.8717683557394003
dev_recall_micro_tok: 0.8717683557394003
dev_f-score_micro_tok: 0.8717683557394003
dev_time: 8.218525648117065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5365    0.9626    0.6890       428
           P     0.7958    0.5968    0.6821       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4441    0.5198    0.4570      1101
weighted avg     0.5295    0.6149    0.5429      1101

F1-macro sent:  0.4570246309376745
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8729    0.9796    0.9232     16205
           N     0.7892    0.5019    0.6136      1857
           P     0.9119    0.5417    0.6797      3212

   micro avg     0.8718    0.8718    0.8718     21274
   macro avg     0.8580    0.6744    0.7388     21274
weighted avg     0.8715    0.8718    0.8594     21274

F1-macro tok:  0.7388081317742698
F1-micro tok:  0.8717683557394003
**************************************************
Best epoch: 3
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 358924.8270263672
train_cost_avg: 42.00899192724335
train_count_sent: 8544.0
train_total_correct_sent: 5388.0
train_accuracy_sent: 0.6306179775280899
train_count_tok: 163566.0
train_total_correct_tok: 140818.0
train_accuracy_tok: 0.8609246420405219
train_label=O_precision_sent: 0.35
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.016826923076923076
train_label=N_precision_sent: 0.599814083197769
train_label=N_recall_sent: 0.7797583081570997
train_label=N_f-score_sent: 0.6780507027453041
train_label=P_precision_sent: 0.6648417043561057
train_label=P_recall_sent: 0.7736842105263158
train_label=P_f-score_sent: 0.7151453078991166
train_precision_macro_sent: 0.5382185958512915
train_recall_macro_sent: 0.5206877361128627
train_f-score_macro_sent: 0.4700076445737813
train_precision_micro_sent: 0.6306179775280899
train_recall_micro_sent: 0.6306179775280899
train_f-score_micro_sent: 0.6306179775280899
train_label=O_precision_tok: 0.8732443513914333
train_label=O_recall_tok: 0.9660064175251514
train_label=O_f-score_tok: 0.9172861708342402
train_label=N_precision_tok: 0.7422519044140665
train_label=N_recall_tok: 0.5008449514152936
train_label=N_f-score_tok: 0.5981080512928315
train_label=P_precision_tok: 0.8269921470749376
train_label=P_recall_tok: 0.5430307390974137
train_label=P_f-score_tok: 0.6555834378920953
train_precision_macro_tok: 0.8141628009601458
train_recall_macro_tok: 0.6699607026792863
train_f-score_macro_tok: 0.723659220006389
train_precision_micro_tok: 0.8609246420405219
train_recall_micro_tok: 0.8609246420405219
train_f-score_micro_tok: 0.8609246420405219
train_time: 145.1596658229828
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3500    0.0086    0.0168      1624
           N     0.5998    0.7798    0.6781      3310
           P     0.6648    0.7737    0.7151      3610

   micro avg     0.6306    0.6306    0.6306      8544
   macro avg     0.5382    0.5207    0.4700      8544
weighted avg     0.5798    0.6306    0.5680      8544

F1-macro sent:  0.4700076445737813
F1-micro sent:  0.6306179775280899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8732    0.9660    0.9173    124347
           N     0.7423    0.5008    0.5981     14202
           P     0.8270    0.5430    0.6556     25017

   micro avg     0.8609    0.8609    0.8609    163566
   macro avg     0.8142    0.6700    0.7237    163566
weighted avg     0.8548    0.8609    0.8495    163566

F1-macro tok:  0.723659220006389
F1-micro tok:  0.8609246420405219
**************************************************
dev_cost_sum: 47517.53674316406
dev_cost_avg: 43.15852565228344
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18626.0
dev_accuracy_tok: 0.8755288145153709
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6525252525252525
dev_label=N_recall_sent: 0.7546728971962616
dev_label=N_f-score_sent: 0.6998916576381365
dev_label=P_precision_sent: 0.6274834437086093
dev_label=P_recall_sent: 0.8536036036036037
dev_label=P_f-score_sent: 0.7232824427480917
dev_precision_macro_sent: 0.7600028987446206
dev_recall_macro_sent: 0.5390033750846713
dev_f-score_macro_sent: 0.4801633725674152
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8787205686361617
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9250284979393797
dev_label=N_precision_tok: 0.8338278931750742
dev_label=N_recall_tok: 0.45395799676898224
dev_label=N_f-score_tok: 0.5878661087866109
dev_label=P_precision_tok: 0.8687361419068736
dev_label=P_recall_tok: 0.6099003735990037
dev_label=P_f-score_tok: 0.7166636180720687
dev_precision_macro_tok: 0.8604282012393698
dev_recall_macro_tok: 0.6801157028039332
dev_f-score_macro_tok: 0.7431860749326864
dev_precision_micro_tok: 0.8755288145153709
dev_recall_micro_tok: 0.8755288145153709
dev_f-score_micro_tok: 0.8755288145153709
dev_time: 8.536304235458374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6525    0.7547    0.6999       428
           P     0.6275    0.8536    0.7233       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7600    0.5390    0.4802      1101
weighted avg     0.7147    0.6394    0.5674      1101

F1-macro sent:  0.4801633725674152
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8787    0.9765    0.9250     16205
           N     0.8338    0.4540    0.5879      1857
           P     0.8687    0.6099    0.7167      3212

   micro avg     0.8755    0.8755    0.8755     21274
   macro avg     0.8604    0.6801    0.7432     21274
weighted avg     0.8733    0.8755    0.8641     21274

F1-macro tok:  0.7431860749326864
F1-micro tok:  0.8755288145153709
**************************************************
Best epoch: 3
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 355239.6544189453
train_cost_avg: 41.57767490858442
train_count_sent: 8544.0
train_total_correct_sent: 5424.0
train_accuracy_sent: 0.6348314606741573
train_count_tok: 163566.0
train_total_correct_tok: 141394.0
train_accuracy_tok: 0.8644461562916499
train_label=O_precision_sent: 0.6153846153846154
train_label=O_recall_sent: 0.014778325123152709
train_label=O_f-score_sent: 0.028863499699338546
train_label=N_precision_sent: 0.6037071797278273
train_label=N_recall_sent: 0.7773413897280966
train_label=N_f-score_sent: 0.6796090861067089
train_label=P_precision_sent: 0.6662738628329012
train_label=P_recall_sent: 0.7831024930747923
train_label=P_f-score_sent: 0.7199796256207819
train_precision_macro_sent: 0.6284552193151146
train_recall_macro_sent: 0.5250740693086805
train_f-score_macro_sent: 0.47615073714227646
train_precision_micro_sent: 0.6348314606741573
train_recall_micro_sent: 0.6348314606741573
train_f-score_micro_sent: 0.6348314606741573
train_label=O_precision_tok: 0.8766888441448539
train_label=O_recall_tok: 0.9664326441329505
train_label=O_f-score_tok: 0.9193758774094093
train_label=N_precision_tok: 0.7376414228926715
train_label=N_recall_tok: 0.5095761160399944
train_label=N_f-score_tok: 0.6027568400449757
train_label=P_precision_tok: 0.8384195695185562
train_label=P_recall_tok: 0.5589798936723028
train_label=P_f-score_tok: 0.6707597851112816
train_precision_macro_tok: 0.8175832788520272
train_recall_macro_tok: 0.6783295512817492
train_f-score_macro_tok: 0.7309641675218889
train_precision_micro_tok: 0.8644461562916499
train_recall_micro_tok: 0.8644461562916499
train_f-score_micro_tok: 0.8644461562916498
train_time: 145.0925600528717
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0148    0.0289      1624
           N     0.6037    0.7773    0.6796      3310
           P     0.6663    0.7831    0.7200      3610

   micro avg     0.6348    0.6348    0.6348      8544
   macro avg     0.6285    0.5251    0.4762      8544
weighted avg     0.6324    0.6348    0.5730      8544

F1-macro sent:  0.47615073714227646
F1-micro sent:  0.6348314606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8767    0.9664    0.9194    124347
           N     0.7376    0.5096    0.6028     14202
           P     0.8384    0.5590    0.6708     25017

   micro avg     0.8644    0.8644    0.8644    163566
   macro avg     0.8176    0.6783    0.7310    163566
weighted avg     0.8588    0.8644    0.8539    163566

F1-macro tok:  0.7309641675218889
F1-micro tok:  0.8644461562916498
**************************************************
dev_cost_sum: 46978.02227783203
dev_cost_avg: 42.668503431273415
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18778.0
dev_accuracy_tok: 0.8826736861897151
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6112054329371817
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7079646017699115
dev_label=P_precision_sent: 0.68359375
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7322175732217573
dev_precision_macro_sent: 0.43159972764572724
dev_recall_macro_sent: 0.5431365945384637
dev_f-score_macro_sent: 0.4800607249972229
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8868421052631579
dev_label=O_recall_tok: 0.9774143782783091
dev_label=O_f-score_tok: 0.9299280786731249
dev_label=N_precision_tok: 0.7716827279466272
dev_label=N_recall_tok: 0.5605815831987075
dev_label=N_f-score_tok: 0.6494073611977542
dev_label=P_precision_tok: 0.9191283292978208
dev_label=P_recall_tok: 0.5909090909090909
dev_label=P_f-score_tok: 0.719348114458973
dev_precision_macro_tok: 0.8592177208358686
dev_recall_macro_tok: 0.7096350174620358
dev_f-score_macro_tok: 0.7662278514432841
dev_precision_micro_tok: 0.8826736861897151
dev_recall_micro_tok: 0.8826736861897151
dev_f-score_micro_tok: 0.8826736861897151
dev_time: 8.36193323135376
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6112    0.8411    0.7080       428
           P     0.6836    0.7883    0.7322       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.4316    0.5431    0.4801      1101
weighted avg     0.5133    0.6449    0.5705      1101

F1-macro sent:  0.4800607249972229
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8868    0.9774    0.9299     16205
           N     0.7717    0.5606    0.6494      1857
           P     0.9191    0.5909    0.7193      3212

   micro avg     0.8827    0.8827    0.8827     21274
   macro avg     0.8592    0.7096    0.7662     21274
weighted avg     0.8817    0.8827    0.8736     21274

F1-macro tok:  0.7662278514432841
F1-micro tok:  0.8826736861897151
**************************************************
Best epoch: 3
**************************************************

EPOCH: 8
Learning rate: 0.900000
train_cost_sum: 351719.3243408203
train_cost_avg: 41.16565125711848
train_count_sent: 8544.0
train_total_correct_sent: 5416.0
train_accuracy_sent: 0.6338951310861424
train_count_tok: 163566.0
train_total_correct_tok: 142026.0
train_accuracy_tok: 0.8683100399838597
train_label=O_precision_sent: 0.7368421052631579
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.01704199634814364
train_label=N_precision_sent: 0.5970940959409594
train_label=N_recall_sent: 0.7821752265861027
train_label=N_f-score_sent: 0.6772168454093643
train_label=P_precision_sent: 0.6715206493196467
train_label=P_recall_sent: 0.779224376731302
train_label=P_f-score_sent: 0.7213745351968202
train_precision_macro_sent: 0.6684856168412546
train_recall_macro_sent: 0.5233400976575256
train_f-score_macro_sent: 0.4718777923181094
train_precision_micro_sent: 0.6338951310861424
train_recall_micro_sent: 0.6338951310861424
train_f-score_micro_sent: 0.6338951310861424
train_label=O_precision_tok: 0.8791691004672897
train_label=O_recall_tok: 0.9683466428623128
train_label=O_f-score_tok: 0.9216056209745626
train_label=N_precision_tok: 0.7518011161846778
train_label=N_recall_tok: 0.5216870863258696
train_label=N_f-score_tok: 0.6159537764476036
train_label=P_precision_tok: 0.8480687720136111
train_label=P_recall_tok: 0.5678538593756246
train_label=P_f-score_tok: 0.6802336717104003
train_precision_macro_tok: 0.8263463295551929
train_recall_macro_tok: 0.6859625295212689
train_f-score_macro_tok: 0.7392643563775222
train_precision_micro_tok: 0.8683100399838597
train_recall_micro_tok: 0.8683100399838597
train_f-score_micro_tok: 0.8683100399838597
train_time: 145.13100337982178
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7368    0.0086    0.0170      1624
           N     0.5971    0.7822    0.6772      3310
           P     0.6715    0.7792    0.7214      3610

   micro avg     0.6339    0.6339    0.6339      8544
   macro avg     0.6685    0.5233    0.4719      8544
weighted avg     0.6551    0.6339    0.5704      8544

F1-macro sent:  0.4718777923181094
F1-micro sent:  0.6338951310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8792    0.9683    0.9216    124347
           N     0.7518    0.5217    0.6160     14202
           P     0.8481    0.5679    0.6802     25017

   micro avg     0.8683    0.8683    0.8683    163566
   macro avg     0.8263    0.6860    0.7393    163566
weighted avg     0.8634    0.8683    0.8581    163566

F1-macro tok:  0.7392643563775222
F1-micro tok:  0.8683100399838597
**************************************************
dev_cost_sum: 46690.52624511719
dev_cost_avg: 42.40738078575585
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18763.0
dev_accuracy_tok: 0.8819686001692206
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6597510373443983
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.6989010989010989
dev_label=P_precision_sent: 0.6264274061990212
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7265846736045412
dev_precision_macro_sent: 0.7065039256255843
dev_recall_macro_sent: 0.5432298600686146
dev_f-score_macro_sent: 0.48934632133166717
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8815126515696805
dev_label=O_recall_tok: 0.9824745448935513
dev_label=O_f-score_tok: 0.929259324111364
dev_label=N_precision_tok: 0.820738137082601
dev_label=N_recall_tok: 0.5029617662897146
dev_label=N_f-score_tok: 0.6237061769616026
dev_label=P_precision_tok: 0.9195180722891566
dev_label=P_recall_tok: 0.5940224159402242
dev_label=P_f-score_tok: 0.7217703801777946
dev_precision_macro_tok: 0.873922953647146
dev_recall_macro_tok: 0.6931529090411633
dev_f-score_macro_tok: 0.7582452937502536
dev_precision_micro_tok: 0.8819686001692206
dev_recall_micro_tok: 0.8819686001692206
dev_f-score_micro_tok: 0.8819686001692206
dev_time: 8.221291303634644
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6598    0.7430    0.6989       428
           P     0.6264    0.8649    0.7266       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7065    0.5432    0.4893      1101
weighted avg     0.6824    0.6421    0.5735      1101

F1-macro sent:  0.48934632133166717
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8815    0.9825    0.9293     16205
           N     0.8207    0.5030    0.6237      1857
           P     0.9195    0.5940    0.7218      3212

   micro avg     0.8820    0.8820    0.8820     21274
   macro avg     0.8739    0.6932    0.7582     21274
weighted avg     0.8819    0.8820    0.8713     21274

F1-macro tok:  0.7582452937502536
F1-micro tok:  0.8819686001692206
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 0.900000
train_cost_sum: 348636.91076660156
train_cost_avg: 40.80488187811348
train_count_sent: 8544.0
train_total_correct_sent: 5456.0
train_accuracy_sent: 0.6385767790262172
train_count_tok: 163566.0
train_total_correct_tok: 142504.0
train_accuracy_tok: 0.8712324077130944
train_label=O_precision_sent: 0.46511627906976744
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.02399520095980804
train_label=N_precision_sent: 0.6082621082621082
train_label=N_recall_sent: 0.7740181268882175
train_label=N_f-score_sent: 0.6812018080297794
train_label=P_precision_sent: 0.6700862671951504
train_label=P_recall_sent: 0.7961218836565097
train_label=P_f-score_sent: 0.7276870489935435
train_precision_macro_sent: 0.581154884842342
train_recall_macro_sent: 0.5274850938268959
train_f-score_macro_sent: 0.47762801932771026
train_precision_micro_sent: 0.6385767790262172
train_recall_micro_sent: 0.6385767790262172
train_f-score_micro_sent: 0.6385767790262172
train_label=O_precision_tok: 0.8820157263555563
train_label=O_recall_tok: 0.9688291635503872
train_label=O_f-score_tok: 0.9233864631917006
train_label=N_precision_tok: 0.7573786893446723
train_label=N_recall_tok: 0.5330235178143924
train_label=N_f-score_tok: 0.6256974005041946
train_label=P_precision_tok: 0.851516043567854
train_label=P_recall_tok: 0.5781268737258665
train_label=P_f-score_tok: 0.6886814913575545
train_precision_macro_tok: 0.8303034864226942
train_recall_macro_tok: 0.6933265183635487
train_f-score_macro_tok: 0.7459217850178166
train_precision_micro_tok: 0.8712324077130944
train_recall_micro_tok: 0.8712324077130944
train_f-score_micro_tok: 0.8712324077130944
train_time: 145.6059513092041
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4651    0.0123    0.0240      1624
           N     0.6083    0.7740    0.6812      3310
           P     0.6701    0.7961    0.7277      3610

   micro avg     0.6386    0.6386    0.6386      8544
   macro avg     0.5812    0.5275    0.4776      8544
weighted avg     0.6072    0.6386    0.5759      8544

F1-macro sent:  0.47762801932771026
F1-micro sent:  0.6385767790262172
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8820    0.9688    0.9234    124347
           N     0.7574    0.5330    0.6257     14202
           P     0.8515    0.5781    0.6887     25017

   micro avg     0.8712    0.8712    0.8712    163566
   macro avg     0.8303    0.6933    0.7459    163566
weighted avg     0.8665    0.8712    0.8616    163566

F1-macro tok:  0.7459217850178166
F1-micro tok:  0.8712324077130944
**************************************************
dev_cost_sum: 46443.3154296875
dev_cost_avg: 42.18284780171435
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18751.0
dev_accuracy_tok: 0.881404531352825
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.6515748031496063
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7072649572649572
dev_label=P_precision_sent: 0.6360485268630849
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7189030362389813
dev_precision_macro_sent: 0.6375411100042304
dev_recall_macro_sent: 0.5478697282762091
dev_f-score_macro_sent: 0.502600215521721
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8780300115429012
dev_label=O_recall_tok: 0.9857451403887689
dev_label=O_f-score_tok: 0.9287749287749288
dev_label=N_precision_tok: 0.8617801047120419
dev_label=N_recall_tok: 0.44318793753365643
dev_label=N_f-score_tok: 0.585348506401138
dev_label=P_precision_tok: 0.9190968955785512
dev_label=P_recall_tok: 0.6083437110834371
dev_label=P_f-score_tok: 0.7321094042712627
dev_precision_macro_tok: 0.8863023372778315
dev_recall_macro_tok: 0.6790922630019542
dev_f-score_macro_tok: 0.7487442798157765
dev_precision_micro_tok: 0.881404531352825
dev_recall_micro_tok: 0.881404531352825
dev_f-score_micro_tok: 0.881404531352825
dev_time: 8.346650838851929
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6516    0.7734    0.7073       428
           P     0.6360    0.8266    0.7189       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6375    0.5479    0.5026      1101
weighted avg     0.6398    0.6431    0.5818      1101

F1-macro sent:  0.502600215521721
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8780    0.9857    0.9288     16205
           N     0.8618    0.4432    0.5853      1857
           P     0.9191    0.6083    0.7321      3212

   micro avg     0.8814    0.8814    0.8814     21274
   macro avg     0.8863    0.6791    0.7487     21274
weighted avg     0.8828    0.8814    0.8691     21274

F1-macro tok:  0.7487442798157765
F1-micro tok:  0.881404531352825
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 0.900000
train_cost_sum: 346025.3795776367
train_cost_avg: 40.49922513783201
train_count_sent: 8544.0
train_total_correct_sent: 5533.0
train_accuracy_sent: 0.6475889513108615
train_count_tok: 163566.0
train_total_correct_tok: 142953.0
train_accuracy_tok: 0.8739774769817689
train_label=O_precision_sent: 0.3723404255319149
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.04074505238649593
train_label=N_precision_sent: 0.6145055970149254
train_label=N_recall_sent: 0.7960725075528701
train_label=N_f-score_sent: 0.6936035798894445
train_label=P_precision_sent: 0.6878904372897645
train_label=P_recall_sent: 0.7930747922437673
train_label=P_f-score_sent: 0.7367472979927947
train_precision_macro_sent: 0.5582454866122016
train_recall_macro_sent: 0.5368996746448561
train_f-score_macro_sent: 0.4903653100895784
train_precision_micro_sent: 0.6475889513108615
train_recall_micro_sent: 0.6475889513108615
train_f-score_micro_sent: 0.6475889513108615
train_label=O_precision_tok: 0.8843189734188818
train_label=O_recall_tok: 0.9698585410182795
train_label=O_f-score_tok: 0.9251156404139276
train_label=N_precision_tok: 0.76400239186765
train_label=N_recall_tok: 0.5397831291367413
train_label=N_f-score_tok: 0.6326126423502229
train_label=P_precision_tok: 0.85609372267879
train_label=P_recall_tok: 0.5871207578846385
train_label=P_f-score_tok: 0.6965428937259924
train_precision_macro_tok: 0.834805029321774
train_recall_macro_tok: 0.6989208093465531
train_f-score_macro_tok: 0.7514237254967142
train_precision_micro_tok: 0.8739774769817689
train_recall_micro_tok: 0.8739774769817689
train_f-score_micro_tok: 0.8739774769817689
train_time: 144.5743248462677
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3723    0.0216    0.0407      1624
           N     0.6145    0.7961    0.6936      3310
           P     0.6879    0.7931    0.7367      3610

   micro avg     0.6476    0.6476    0.6476      8544
   macro avg     0.5582    0.5369    0.4904      8544
weighted avg     0.5995    0.6476    0.5877      8544

F1-macro sent:  0.4903653100895784
F1-micro sent:  0.6475889513108615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8843    0.9699    0.9251    124347
           N     0.7640    0.5398    0.6326     14202
           P     0.8561    0.5871    0.6965     25017

   micro avg     0.8740    0.8740    0.8740    163566
   macro avg     0.8348    0.6989    0.7514    163566
weighted avg     0.8696    0.8740    0.8648    163566

F1-macro tok:  0.7514237254967142
F1-micro tok:  0.8739774769817689
**************************************************
dev_cost_sum: 46055.22375488281
dev_cost_avg: 41.83035763386268
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 18877.0
dev_accuracy_tok: 0.8873272539249788
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.033898305084745756
dev_label=N_precision_sent: 0.5856269113149847
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7079482439926063
dev_label=P_precision_sent: 0.7227272727272728
dev_label=P_recall_sent: 0.7162162162162162
dev_label=P_f-score_sent: 0.7194570135746606
dev_precision_macro_sent: 0.6265942518236095
dev_recall_macro_sent: 0.5428477594028751
dev_f-score_macro_sent: 0.48710118755067083
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.8928571428571429
dev_label=O_recall_tok: 0.97655044739278
dev_label=O_f-score_tok: 0.9328303221432991
dev_label=N_precision_tok: 0.7773668639053254
dev_label=N_recall_tok: 0.5659666128163705
dev_label=N_f-score_tok: 0.6550327204736679
dev_label=P_precision_tok: 0.9103730664240218
dev_label=P_recall_tok: 0.6229763387297634
dev_label=P_f-score_tok: 0.7397412199630314
dev_precision_macro_tok: 0.8601990243954968
dev_recall_macro_tok: 0.721831132979638
dev_f-score_macro_tok: 0.775868087526666
dev_precision_micro_tok: 0.8873272539249788
dev_recall_micro_tok: 0.8873272539249788
dev_f-score_micro_tok: 0.8873272539249788
dev_time: 8.393101930618286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0175    0.0339       229
           N     0.5856    0.8949    0.7079       428
           P     0.7227    0.7162    0.7195       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.6266    0.5428    0.4871      1101
weighted avg     0.6380    0.6403    0.5724      1101

F1-macro sent:  0.48710118755067083
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8929    0.9766    0.9328     16205
           N     0.7774    0.5660    0.6550      1857
           P     0.9104    0.6230    0.7397      3212

   micro avg     0.8873    0.8873    0.8873     21274
   macro avg     0.8602    0.7218    0.7759     21274
weighted avg     0.8854    0.8873    0.8794     21274

F1-macro tok:  0.775868087526666
F1-micro tok:  0.8873272539249788
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 0.900000
train_cost_sum: 343971.26403808594
train_cost_avg: 40.25880899322167
train_count_sent: 8544.0
train_total_correct_sent: 5571.0
train_accuracy_sent: 0.6520365168539326
train_count_tok: 163566.0
train_total_correct_tok: 143333.0
train_accuracy_tok: 0.8763006981891102
train_label=O_precision_sent: 0.4900662251655629
train_label=O_recall_sent: 0.04556650246305419
train_label=O_f-score_sent: 0.08338028169014085
train_label=N_precision_sent: 0.6190364826941066
train_label=N_recall_sent: 0.7996978851963746
train_label=N_f-score_sent: 0.6978644872132875
train_label=P_precision_sent: 0.6922516395433568
train_label=P_recall_sent: 0.7894736842105263
train_label=P_f-score_sent: 0.7376730943445061
train_precision_macro_sent: 0.6004514491343421
train_recall_macro_sent: 0.5449126906233184
train_f-score_macro_sent: 0.5063059544159781
train_precision_micro_sent: 0.6520365168539326
train_recall_micro_sent: 0.6520365168539326
train_f-score_micro_sent: 0.6520365168539326
train_label=O_precision_tok: 0.8864886701678357
train_label=O_recall_tok: 0.970598406073327
train_label=O_f-score_tok: 0.9266388219215945
train_label=N_precision_tok: 0.768958742632613
train_label=N_recall_tok: 0.5511899732432052
train_label=N_f-score_tok: 0.6421130342055614
train_label=P_precision_tok: 0.8592309030798677
train_label=P_recall_tok: 0.5921573330135508
train_label=P_f-score_tok: 0.7011216811018032
train_precision_macro_tok: 0.8382261052934389
train_recall_macro_tok: 0.7046485707766944
train_f-score_macro_tok: 0.756624512409653
train_precision_micro_tok: 0.8763006981891102
train_recall_micro_tok: 0.8763006981891102
train_f-score_micro_tok: 0.8763006981891102
train_time: 145.7318732738495
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4901    0.0456    0.0834      1624
           N     0.6190    0.7997    0.6979      3310
           P     0.6923    0.7895    0.7377      3610

   micro avg     0.6520    0.6520    0.6520      8544
   macro avg     0.6005    0.5449    0.5063      8544
weighted avg     0.6255    0.6520    0.5979      8544

F1-macro sent:  0.5063059544159781
F1-micro sent:  0.6520365168539326
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8865    0.9706    0.9266    124347
           N     0.7690    0.5512    0.6421     14202
           P     0.8592    0.5922    0.7011     25017

   micro avg     0.8763    0.8763    0.8763    163566
   macro avg     0.8382    0.7046    0.7566    163566
weighted avg     0.8721    0.8763    0.8674    163566

F1-macro tok:  0.756624512409653
F1-micro tok:  0.8763006981891102
**************************************************
dev_cost_sum: 45812.376037597656
dev_cost_avg: 41.6097875000887
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 18918.0
dev_accuracy_tok: 0.8892544890476638
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6435272045028143
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7138397502601457
dev_label=P_precision_sent: 0.6536412078152753
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7308838133068521
dev_precision_macro_sent: 0.6990561374393632
dev_recall_macro_sent: 0.5492326489653347
dev_f-score_macro_sent: 0.49297053258501067
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8908062076306796
dev_label=O_recall_tok: 0.9811786485652576
dev_label=O_f-score_tok: 0.9338110060492161
dev_label=N_precision_tok: 0.8101667990468626
dev_label=N_recall_tok: 0.5492730210016155
dev_label=N_f-score_tok: 0.6546854942233633
dev_label=P_precision_tok: 0.9224376731301939
dev_label=P_recall_tok: 0.6220423412204235
dev_label=P_f-score_tok: 0.7430271476385273
dev_precision_macro_tok: 0.8744702266025787
dev_recall_macro_tok: 0.7174980035957654
dev_f-score_macro_tok: 0.7771745493037022
dev_precision_micro_tok: 0.8892544890476638
dev_recall_micro_tok: 0.8892544890476638
dev_f-score_micro_tok: 0.8892544890476638
dev_time: 8.062691450119019
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6435    0.8014    0.7138       428
           P     0.6536    0.8288    0.7309       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.6991    0.5492    0.4930      1101
weighted avg     0.6802    0.6494    0.5794      1101

F1-macro sent:  0.49297053258501067
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9812    0.9338     16205
           N     0.8102    0.5493    0.6547      1857
           P     0.9224    0.6220    0.7430      3212

   micro avg     0.8893    0.8893    0.8893     21274
   macro avg     0.8745    0.7175    0.7772     21274
weighted avg     0.8885    0.8893    0.8806     21274

F1-macro tok:  0.7771745493037022
F1-micro tok:  0.8892544890476638
**************************************************
Best epoch: 9
**************************************************

EPOCH: 12
Learning rate: 0.900000
train_cost_sum: 341321.05322265625
train_cost_avg: 39.948625143101154
train_count_sent: 8544.0
train_total_correct_sent: 5519.0
train_accuracy_sent: 0.6459503745318352
train_count_tok: 163566.0
train_total_correct_tok: 143730.0
train_accuracy_tok: 0.87872785297678
train_label=O_precision_sent: 0.359375
train_label=O_recall_sent: 0.02832512315270936
train_label=O_f-score_sent: 0.05251141552511416
train_label=N_precision_sent: 0.6132493585257756
train_label=N_recall_sent: 0.7942598187311178
train_label=N_f-score_sent: 0.6921153086744768
train_label=P_precision_sent: 0.6887866311455558
train_label=P_recall_sent: 0.7878116343490305
train_label=P_f-score_sent: 0.7349786794159452
train_precision_macro_sent: 0.5538036632237772
train_recall_macro_sent: 0.5367988587442859
train_f-score_macro_sent: 0.4932018012051787
train_precision_micro_sent: 0.6459503745318352
train_recall_micro_sent: 0.6459503745318352
train_f-score_micro_sent: 0.6459503745318352
train_label=O_precision_tok: 0.8886876895445043
train_label=O_recall_tok: 0.9709120445205754
train_label=O_f-score_tok: 0.927982044512085
train_label=N_precision_tok: 0.7692084381652796
train_label=N_recall_tok: 0.5597099000140825
train_label=N_f-score_tok: 0.6479458754483208
train_label=P_precision_tok: 0.8659953970080553
train_label=P_recall_tok: 0.601630890994124
train_label=P_f-score_tok: 0.7100030662546879
train_precision_macro_tok: 0.8412971749059465
train_recall_macro_tok: 0.7107509451762607
train_f-score_macro_tok: 0.7619769954050312
train_precision_micro_tok: 0.87872785297678
train_recall_micro_tok: 0.87872785297678
train_f-score_micro_tok: 0.87872785297678
train_time: 145.02229642868042
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3594    0.0283    0.0525      1624
           N     0.6132    0.7943    0.6921      3310
           P     0.6888    0.7878    0.7350      3610

   micro avg     0.6460    0.6460    0.6460      8544
   macro avg     0.5538    0.5368    0.4932      8544
weighted avg     0.5969    0.6460    0.5887      8544

F1-macro sent:  0.4932018012051787
F1-micro sent:  0.6459503745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8887    0.9709    0.9280    124347
           N     0.7692    0.5597    0.6479     14202
           P     0.8660    0.6016    0.7100     25017

   micro avg     0.8787    0.8787    0.8787    163566
   macro avg     0.8413    0.7108    0.7620    163566
weighted avg     0.8748    0.8787    0.8703    163566

F1-macro tok:  0.7619769954050312
F1-micro tok:  0.87872785297678
**************************************************
dev_cost_sum: 45538.85498046875
dev_cost_avg: 41.36135783875454
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18949.0
dev_accuracy_tok: 0.8907116668233525
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.5955766192733017
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7106503298774741
dev_label=P_precision_sent: 0.7010752688172043
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7172717271727174
dev_precision_macro_sent: 0.765550629363502
dev_recall_macro_sent: 0.5427252641369281
dev_f-score_macro_sent: 0.4845947086719029
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8941760162372442
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.9345353838901655
dev_label=N_precision_tok: 0.8255528255528255
dev_label=N_recall_tok: 0.5428109854604201
dev_label=N_f-score_tok: 0.6549707602339182
dev_label=P_precision_tok: 0.8985319516407599
dev_label=P_recall_tok: 0.6478829389788294
dev_label=P_f-score_tok: 0.7528943560057887
dev_precision_macro_tok: 0.8727535978102766
dev_recall_macro_tok: 0.7231347330152841
dev_f-score_macro_tok: 0.7808001667099576
dev_precision_micro_tok: 0.8907116668233525
dev_recall_micro_tok: 0.8907116668233525
dev_f-score_micro_tok: 0.8907116668233525
dev_time: 8.22696590423584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.5956    0.8808    0.7107       428
           P     0.7011    0.7342    0.7173       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.7656    0.5427    0.4846      1101
weighted avg     0.7222    0.6412    0.5709      1101

F1-macro sent:  0.4845947086719029
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8942    0.9787    0.9345     16205
           N     0.8256    0.5428    0.6550      1857
           P     0.8985    0.6479    0.7529      3212

   micro avg     0.8907    0.8907    0.8907     21274
   macro avg     0.8728    0.7231    0.7808     21274
weighted avg     0.8888    0.8907    0.8827     21274

F1-macro tok:  0.7808001667099576
F1-micro tok:  0.8907116668233525
**************************************************
Best epoch: 9
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 339565.5653076172
train_cost_avg: 39.743160733569425
train_count_sent: 8544.0
train_total_correct_sent: 5604.0
train_accuracy_sent: 0.6558988764044944
train_count_tok: 163566.0
train_total_correct_tok: 143844.0
train_accuracy_tok: 0.8794248193389824
train_label=O_precision_sent: 0.5056179775280899
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.05253940455341506
train_label=N_precision_sent: 0.6254708097928436
train_label=N_recall_sent: 0.8027190332326284
train_label=N_f-score_sent: 0.7030960571579783
train_label=P_precision_sent: 0.6898027097694319
train_label=P_recall_sent: 0.8038781163434903
train_label=P_f-score_sent: 0.7424843290264806
train_precision_macro_sent: 0.6069638323634551
train_recall_macro_sent: 0.54476883639401
train_f-score_macro_sent: 0.49937326357929135
train_precision_micro_sent: 0.6558988764044944
train_recall_micro_sent: 0.6558988764044944
train_f-score_micro_sent: 0.6558988764044944
train_label=O_precision_tok: 0.8894570855930205
train_label=O_recall_tok: 0.9707512042912173
train_label=O_f-score_tok: 0.9283278025371166
train_label=N_precision_tok: 0.7724498692240628
train_label=N_recall_tok: 0.5614702154626109
train_label=N_f-score_tok: 0.6502752293577981
train_label=P_precision_tok: 0.8647538645827392
train_label=P_recall_tok: 0.605987928208818
train_label=P_f-score_tok: 0.7126069380464417
train_precision_macro_tok: 0.8422202731332741
train_recall_macro_tok: 0.712736449320882
train_f-score_macro_tok: 0.7637366566471188
train_precision_micro_tok: 0.8794248193389824
train_recall_micro_tok: 0.8794248193389824
train_f-score_micro_tok: 0.8794248193389824
train_time: 144.56612586975098
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5056    0.0277    0.0525      1624
           N     0.6255    0.8027    0.7031      3310
           P     0.6898    0.8039    0.7425      3610

   micro avg     0.6559    0.6559    0.6559      8544
   macro avg     0.6070    0.5448    0.4994      8544
weighted avg     0.6299    0.6559    0.5961      8544

F1-macro sent:  0.49937326357929135
F1-micro sent:  0.6558988764044944
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8895    0.9708    0.9283    124347
           N     0.7724    0.5615    0.6503     14202
           P     0.8648    0.6060    0.7126     25017

   micro avg     0.8794    0.8794    0.8794    163566
   macro avg     0.8422    0.7127    0.7637    163566
weighted avg     0.8755    0.8794    0.8712    163566

F1-macro tok:  0.7637366566471188
F1-micro tok:  0.8794248193389824
**************************************************
dev_cost_sum: 45418.64489746094
dev_cost_avg: 41.25217520205353
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18967.0
dev_accuracy_tok: 0.8915577700479459
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06751054852320675
dev_label=N_precision_sent: 0.6794871794871795
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7098214285714286
dev_label=P_precision_sent: 0.624
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7296538821328346
dev_precision_macro_sent: 0.7678290598290598
dev_recall_macro_sent: 0.5521011768001932
dev_f-score_macro_sent: 0.50232861974249
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8971088435374149
dev_label=O_recall_tok: 0.97655044739278
dev_label=O_f-score_tok: 0.93514551632442
dev_label=N_precision_tok: 0.8019726858877086
dev_label=N_recall_tok: 0.5691976305869683
dev_label=N_f-score_tok: 0.6658267716535433
dev_label=P_precision_tok: 0.9002590673575129
dev_label=P_recall_tok: 0.6491282689912827
dev_label=P_f-score_tok: 0.754341534008683
dev_precision_macro_tok: 0.8664468655942121
dev_recall_macro_tok: 0.7316254489903437
dev_f-score_macro_tok: 0.7851046073288822
dev_precision_micro_tok: 0.8915577700479459
dev_recall_micro_tok: 0.8915577700479459
dev_f-score_micro_tok: 0.8915577700479459
dev_time: 8.2264084815979
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0349    0.0675       229
           N     0.6795    0.7430    0.7098       428
           P     0.6240    0.8784    0.7297       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.7678    0.5521    0.5023      1101
weighted avg     0.7238    0.6503    0.5842      1101

F1-macro sent:  0.50232861974249
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8971    0.9766    0.9351     16205
           N     0.8020    0.5692    0.6658      1857
           P     0.9003    0.6491    0.7543      3212

   micro avg     0.8916    0.8916    0.8916     21274
   macro avg     0.8664    0.7316    0.7851     21274
weighted avg     0.8893    0.8916    0.8843     21274

F1-macro tok:  0.7851046073288822
F1-micro tok:  0.8915577700479459
**************************************************
Best epoch: 9
**************************************************

EPOCH: 14
Learning rate: 0.810000
train_cost_sum: 336954.0303955078
train_cost_avg: 39.43750355752666
train_count_sent: 8544.0
train_total_correct_sent: 5651.0
train_accuracy_sent: 0.6613998127340824
train_count_tok: 163566.0
train_total_correct_tok: 144308.0
train_accuracy_tok: 0.8822615947079466
train_label=O_precision_sent: 0.54
train_label=O_recall_sent: 0.0166256157635468
train_label=O_f-score_sent: 0.03225806451612903
train_label=N_precision_sent: 0.6352517985611511
train_label=N_recall_sent: 0.8003021148036253
train_label=N_f-score_sent: 0.7082887700534759
train_label=P_precision_sent: 0.6880203515263644
train_label=P_recall_sent: 0.8240997229916898
train_label=P_f-score_sent: 0.749936980085707
train_precision_macro_sent: 0.6210907166958385
train_recall_macro_sent: 0.5470091511862872
train_f-score_macro_sent: 0.4968279382184373
train_precision_micro_sent: 0.6613998127340824
train_recall_micro_sent: 0.6613998127340824
train_f-score_micro_sent: 0.6613998127340824
train_label=O_precision_tok: 0.8918232867715966
train_label=O_recall_tok: 0.9719494639999356
train_label=O_f-score_tok: 0.9301640076039189
train_label=N_precision_tok: 0.7790182868142445
train_label=N_recall_tok: 0.5699197296155472
train_label=N_f-score_tok: 0.6582628497072218
train_label=P_precision_tok: 0.8696267769156708
train_label=P_recall_tok: 0.6137826278130871
train_label=P_f-score_tok: 0.7196419365421568
train_precision_macro_tok: 0.846822783500504
train_recall_macro_tok: 0.7185506071428568
train_f-score_macro_tok: 0.769356264617766
train_precision_micro_tok: 0.8822615947079466
train_recall_micro_tok: 0.8822615947079466
train_f-score_micro_tok: 0.8822615947079466
train_time: 144.49587774276733
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5400    0.0166    0.0323      1624
           N     0.6353    0.8003    0.7083      3310
           P     0.6880    0.8241    0.7499      3610

   micro avg     0.6614    0.6614    0.6614      8544
   macro avg     0.6211    0.5470    0.4968      8544
weighted avg     0.6394    0.6614    0.5974      8544

F1-macro sent:  0.4968279382184373
F1-micro sent:  0.6613998127340824
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9719    0.9302    124347
           N     0.7790    0.5699    0.6583     14202
           P     0.8696    0.6138    0.7196     25017

   micro avg     0.8823    0.8823    0.8823    163566
   macro avg     0.8468    0.7186    0.7694    163566
weighted avg     0.8786    0.8823    0.8744    163566

F1-macro tok:  0.769356264617766
F1-micro tok:  0.8822615947079466
**************************************************
dev_cost_sum: 45183.258056640625
dev_cost_avg: 41.03838152283436
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 18983.0
dev_accuracy_tok: 0.89230986180314
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.5962145110410094
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.711864406779661
dev_label=P_precision_sent: 0.7149122807017544
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7244444444444444
dev_precision_macro_sent: 0.6491634760354668
dev_recall_macro_sent: 0.5493264966390706
dev_f-score_macro_sent: 0.4982140615191463
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.8986313816798228
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9359436919619092
dev_label=N_precision_tok: 0.773876404494382
dev_label=N_recall_tok: 0.5934302638664513
dev_label=N_f-score_tok: 0.6717464187747637
dev_label=P_precision_tok: 0.9178937974118697
dev_label=P_recall_tok: 0.6404109589041096
dev_label=P_f-score_tok: 0.7544470933431139
dev_precision_macro_tok: 0.8634671945286915
dev_recall_macro_tok: 0.7367766536047915
dev_f-score_macro_tok: 0.7873790680265956
dev_precision_micro_tok: 0.89230986180314
dev_recall_micro_tok: 0.89230986180314
dev_f-score_micro_tok: 0.89230986180314
dev_time: 8.248571872711182
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.5962    0.8832    0.7119       428
           P     0.7149    0.7342    0.7244       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.6492    0.5493    0.4982      1101
weighted avg     0.6524    0.6458    0.5810      1101

F1-macro sent:  0.4982140615191463
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8986    0.9765    0.9359     16205
           N     0.7739    0.5934    0.6717      1857
           P     0.9179    0.6404    0.7544      3212

   micro avg     0.8923    0.8923    0.8923     21274
   macro avg     0.8635    0.7368    0.7874     21274
weighted avg     0.8906    0.8923    0.8855     21274

F1-macro tok:  0.7873790680265956
F1-micro tok:  0.89230986180314
**************************************************
Best epoch: 9
**************************************************

EPOCH: 15
Learning rate: 0.729000
train_cost_sum: 334914.4958496094
train_cost_avg: 39.198793989888735
train_count_sent: 8544.0
train_total_correct_sent: 5657.0
train_accuracy_sent: 0.6621020599250936
train_count_tok: 163566.0
train_total_correct_tok: 144759.0
train_accuracy_tok: 0.8850188914566597
train_label=O_precision_sent: 0.4639175257731959
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.052295177222545036
train_label=N_precision_sent: 0.6274238227146814
train_label=N_recall_sent: 0.8211480362537764
train_label=N_f-score_sent: 0.7113321120125622
train_label=P_precision_sent: 0.7032806804374241
train_label=P_recall_sent: 0.8016620498614958
train_label=P_f-score_sent: 0.7492556634304208
train_precision_macro_sent: 0.5982073429751005
train_recall_macro_sent: 0.5501731485737279
train_f-score_macro_sent: 0.5042943175551761
train_precision_micro_sent: 0.6621020599250936
train_recall_micro_sent: 0.6621020599250936
train_f-score_micro_sent: 0.6621020599250936
train_label=O_precision_tok: 0.894408651463485
train_label=O_recall_tok: 0.9724078586536065
train_label=O_f-score_tok: 0.9317787761329748
train_label=N_precision_tok: 0.7824323049344277
train_label=N_recall_tok: 0.583931840585833
train_label=N_f-score_tok: 0.6687633563162776
train_label=P_precision_tok: 0.8747749774977498
train_label=P_recall_tok: 0.6215773274173562
train_label=P_f-score_tok: 0.7267543757156544
train_precision_macro_tok: 0.8505386446318876
train_recall_macro_tok: 0.7259723422189319
train_f-score_macro_tok: 0.7757655027216356
train_precision_micro_tok: 0.8850188914566597
train_recall_micro_tok: 0.8850188914566597
train_f-score_micro_tok: 0.8850188914566598
train_time: 144.64840483665466
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4639    0.0277    0.0523      1624
           N     0.6274    0.8211    0.7113      3310
           P     0.7033    0.8017    0.7493      3610

   micro avg     0.6621    0.6621    0.6621      8544
   macro avg     0.5982    0.5502    0.5043      8544
weighted avg     0.6284    0.6621    0.6021      8544

F1-macro sent:  0.5042943175551761
F1-micro sent:  0.6621020599250936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9724    0.9318    124347
           N     0.7824    0.5839    0.6688     14202
           P     0.8748    0.6216    0.7268     25017

   micro avg     0.8850    0.8850    0.8850    163566
   macro avg     0.8505    0.7260    0.7758    163566
weighted avg     0.8817    0.8850    0.8776    163566

F1-macro tok:  0.7757655027216356
F1-micro tok:  0.8850188914566598
**************************************************
dev_cost_sum: 45060.05603027344
dev_cost_avg: 40.92648140805944
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 18977.0
dev_accuracy_tok: 0.8920278273949421
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6533333333333333
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.719832109129066
dev_label=P_precision_sent: 0.6472663139329806
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7260138476755689
dev_precision_macro_sent: 0.6927924750146972
dev_recall_macro_sent: 0.5528487104416583
dev_f-score_macro_sent: 0.5015564954054665
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9001483510213397
dev_label=O_recall_tok: 0.973526689293428
dev_label=O_f-score_tok: 0.9354006700068187
dev_label=N_precision_tok: 0.7837643678160919
dev_label=N_recall_tok: 0.5875067312870221
dev_label=N_f-score_tok: 0.6715912588488766
dev_label=P_precision_tok: 0.8955857385398981
dev_label=P_recall_tok: 0.6569115815691158
dev_label=P_f-score_tok: 0.7579022988505747
dev_precision_macro_tok: 0.8598328191257766
dev_recall_macro_tok: 0.739315000716522
dev_f-score_macro_tok: 0.78829807590209
dev_precision_micro_tok: 0.8920278273949421
dev_recall_micro_tok: 0.8920278273949421
dev_f-score_micro_tok: 0.8920278273949421
dev_time: 8.303466558456421
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6533    0.8014    0.7198       428
           P     0.6473    0.8266    0.7260       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6928    0.5528    0.5016      1101
weighted avg     0.6768    0.6512    0.5848      1101

F1-macro sent:  0.5015564954054665
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9001    0.9735    0.9354     16205
           N     0.7838    0.5875    0.6716      1857
           P     0.8956    0.6569    0.7579      3212

   micro avg     0.8920    0.8920    0.8920     21274
   macro avg     0.8598    0.7393    0.7883     21274
weighted avg     0.8893    0.8920    0.8856     21274

F1-macro tok:  0.78829807590209
F1-micro tok:  0.8920278273949421
**************************************************
Best epoch: 9
**************************************************

EPOCH: 16
Learning rate: 0.656100
train_cost_sum: 333504.34576416016
train_cost_avg: 39.03374833382024
train_count_sent: 8544.0
train_total_correct_sent: 5719.0
train_accuracy_sent: 0.6693586142322098
train_count_tok: 163566.0
train_total_correct_tok: 144891.0
train_accuracy_tok: 0.8858259051392099
train_label=O_precision_sent: 0.48
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.08117249154453213
train_label=N_precision_sent: 0.6392585551330798
train_label=N_recall_sent: 0.8126888217522659
train_label=N_f-score_sent: 0.7156158552806597
train_label=P_precision_sent: 0.7064022933588151
train_label=P_recall_sent: 0.8191135734072023
train_label=P_f-score_sent: 0.758594150846588
train_precision_macro_sent: 0.608553616163965
train_recall_macro_sent: 0.5587124568429754
train_f-score_macro_sent: 0.5184608325572599
train_precision_micro_sent: 0.6693586142322098
train_recall_micro_sent: 0.6693586142322098
train_f-score_micro_sent: 0.6693586142322098
train_label=O_precision_tok: 0.89543451697708
train_label=O_recall_tok: 0.9723998166421385
train_label=O_f-score_tok: 0.932331464789384
train_label=N_precision_tok: 0.7829691032403918
train_label=N_recall_tok: 0.5852696803267146
train_label=N_f-score_tok: 0.6698364090579418
train_label=P_precision_tok: 0.8743511024281329
train_label=P_recall_tok: 0.6261342287244673
train_label=P_f-score_tok: 0.7297121028603373
train_precision_macro_tok: 0.8509182408818683
train_recall_macro_tok: 0.7279345752311067
train_f-score_macro_tok: 0.777293325569221
train_precision_micro_tok: 0.8858259051392099
train_recall_micro_tok: 0.8858259051392099
train_f-score_micro_tok: 0.8858259051392099
train_time: 145.2019498348236
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4800    0.0443    0.0812      1624
           N     0.6393    0.8127    0.7156      3310
           P     0.7064    0.8191    0.7586      3610

   micro avg     0.6694    0.6694    0.6694      8544
   macro avg     0.6086    0.5587    0.5185      8544
weighted avg     0.6374    0.6694    0.6132      8544

F1-macro sent:  0.5184608325572599
F1-micro sent:  0.6693586142322098
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8954    0.9724    0.9323    124347
           N     0.7830    0.5853    0.6698     14202
           P     0.8744    0.6261    0.7297     25017

   micro avg     0.8858    0.8858    0.8858    163566
   macro avg     0.8509    0.7279    0.7773    163566
weighted avg     0.8824    0.8858    0.8785    163566

F1-macro tok:  0.777293325569221
F1-micro tok:  0.8858259051392099
**************************************************
dev_cost_sum: 44888.05499267578
dev_cost_avg: 40.7702588489335
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 0.72
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.14173228346456695
dev_label=N_precision_sent: 0.6436170212765957
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7318548387096774
dev_label=P_precision_sent: 0.6875
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7364016736401674
dev_precision_macro_sent: 0.6837056737588653
dev_recall_macro_sent: 0.5731754180005414
dev_f-score_macro_sent: 0.5366629319381372
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.8933714349750659
dev_label=O_recall_tok: 0.9838938599197778
dev_label=O_f-score_tok: 0.9364501350875133
dev_label=N_precision_tok: 0.8338788870703764
dev_label=N_recall_tok: 0.5487345180398492
dev_label=N_f-score_tok: 0.6619032153296526
dev_label=P_precision_tok: 0.9310657596371882
dev_label=P_recall_tok: 0.6391656288916563
dev_label=P_f-score_tok: 0.7579841240539045
dev_precision_macro_tok: 0.8861053605608769
dev_recall_macro_tok: 0.7239313356170944
dev_f-score_macro_tok: 0.7854458248236901
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 8.273720026016235
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7200    0.0786    0.1417       229
           N     0.6436    0.8481    0.7319       428
           P     0.6875    0.7928    0.7364       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6837    0.5732    0.5367      1101
weighted avg     0.6772    0.6658    0.6109      1101

F1-macro sent:  0.5366629319381372
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9839    0.9365     16205
           N     0.8339    0.5487    0.6619      1857
           P     0.9311    0.6392    0.7580      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8861    0.7239    0.7854     21274
weighted avg     0.8939    0.8939    0.8855     21274

F1-macro tok:  0.7854458248236901
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 0.656100
train_cost_sum: 331869.01525878906
train_cost_avg: 38.84234729152494
train_count_sent: 8544.0
train_total_correct_sent: 5735.0
train_accuracy_sent: 0.6712312734082397
train_count_tok: 163566.0
train_total_correct_tok: 145200.0
train_accuracy_tok: 0.8877150508051795
train_label=O_precision_sent: 0.4608695652173913
train_label=O_recall_sent: 0.06527093596059114
train_label=O_f-score_sent: 0.11434735706580366
train_label=N_precision_sent: 0.6339430423709191
train_label=N_recall_sent: 0.827190332326284
train_label=N_f-score_sent: 0.717787390221523
train_label=P_precision_sent: 0.7236545682102629
train_label=P_recall_sent: 0.8008310249307479
train_label=P_f-score_sent: 0.7602892833662063
train_precision_macro_sent: 0.6061557252661911
train_recall_macro_sent: 0.5644307644058744
train_f-score_macro_sent: 0.5308080102178443
train_precision_micro_sent: 0.6712312734082397
train_recall_micro_sent: 0.6712312734082397
train_f-score_micro_sent: 0.6712312734082397
train_label=O_precision_tok: 0.8970385419601679
train_label=O_recall_tok: 0.9729225473875526
train_label=O_f-score_tok: 0.9334408382295643
train_label=N_precision_tok: 0.7875128709164092
train_label=N_recall_tok: 0.5923813547387692
train_label=N_f-score_tok: 0.6761502913401648
train_label=P_precision_tok: 0.8773380696009324
train_label=P_recall_tok: 0.631850341767598
train_label=P_f-score_tok: 0.7346284333317842
train_precision_macro_tok: 0.8539631608258365
train_recall_macro_tok: 0.7323847479646398
train_f-score_macro_tok: 0.7814065209671711
train_precision_micro_tok: 0.8877150508051795
train_recall_micro_tok: 0.8877150508051795
train_f-score_micro_tok: 0.8877150508051795
train_time: 145.46219778060913
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4609    0.0653    0.1143      1624
           N     0.6339    0.8272    0.7178      3310
           P     0.7237    0.8008    0.7603      3610

   micro avg     0.6712    0.6712    0.6712      8544
   macro avg     0.6062    0.5644    0.5308      8544
weighted avg     0.6390    0.6712    0.6210      8544

F1-macro sent:  0.5308080102178443
F1-micro sent:  0.6712312734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9729    0.9334    124347
           N     0.7875    0.5924    0.6762     14202
           P     0.8773    0.6319    0.7346     25017

   micro avg     0.8877    0.8877    0.8877    163566
   macro avg     0.8540    0.7324    0.7814    163566
weighted avg     0.8845    0.8877    0.8807    163566

F1-macro tok:  0.7814065209671711
F1-micro tok:  0.8877150508051795
**************************************************
dev_cost_sum: 44856.06201171875
dev_cost_avg: 40.7412007372559
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19008.0
dev_accuracy_tok: 0.8934850051706308
dev_label=O_precision_sent: 0.4166666666666667
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04149377593360996
dev_label=N_precision_sent: 0.6443202979515829
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.717098445595855
dev_label=P_precision_sent: 0.6630434782608695
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7349397590361446
dev_precision_macro_sent: 0.5746768142930397
dev_recall_macro_sent: 0.5515232001376555
dev_f-score_macro_sent: 0.49784399352186987
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8959120383422611
dev_label=O_recall_tok: 0.9804998457266276
dev_label=O_f-score_tok: 0.9362993517972893
dev_label=N_precision_tok: 0.8235294117647058
dev_label=N_recall_tok: 0.5578890683898762
dev_label=N_f-score_tok: 0.6651685393258427
dev_label=P_precision_tok: 0.9131959666812801
dev_label=P_recall_tok: 0.6485056039850561
dev_label=P_f-score_tok: 0.7584198070271254
dev_precision_macro_tok: 0.8775458055960824
dev_recall_macro_tok: 0.7289648393671865
dev_f-score_macro_tok: 0.7866292327167526
dev_precision_micro_tok: 0.8934850051706308
dev_recall_micro_tok: 0.8934850051706308
dev_f-score_micro_tok: 0.8934850051706308
dev_time: 8.654540061950684
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0218    0.0415       229
           N     0.6443    0.8084    0.7171       428
           P     0.6630    0.8243    0.7349       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.5747    0.5515    0.4978      1101
weighted avg     0.6045    0.6512    0.5838      1101

F1-macro sent:  0.49784399352186987
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9805    0.9363     16205
           N     0.8235    0.5579    0.6652      1857
           P     0.9132    0.6485    0.7584      3212

   micro avg     0.8935    0.8935    0.8935     21274
   macro avg     0.8775    0.7290    0.7866     21274
weighted avg     0.8922    0.8935    0.8858     21274

F1-macro tok:  0.7866292327167526
F1-micro tok:  0.8934850051706308
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 0.656100
train_cost_sum: 330423.3172607422
train_cost_avg: 38.67314106516177
train_count_sent: 8544.0
train_total_correct_sent: 5734.0
train_accuracy_sent: 0.6711142322097379
train_count_tok: 163566.0
train_total_correct_tok: 145306.0
train_accuracy_tok: 0.8883631072472274
train_label=O_precision_sent: 0.5172413793103449
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.10011123470522804
train_label=N_precision_sent: 0.6586477589263104
train_label=N_recall_sent: 0.7858006042296073
train_label=N_f-score_sent: 0.7166276346604217
train_label=P_precision_sent: 0.6883058131644424
train_label=P_recall_sent: 0.8429362880886426
train_label=P_f-score_sent: 0.7578134727929273
train_precision_macro_sent: 0.6213983171336992
train_recall_macro_sent: 0.5613852038433574
train_f-score_macro_sent: 0.5248507807195256
train_precision_micro_sent: 0.6711142322097379
train_recall_micro_sent: 0.6711142322097379
train_f-score_micro_sent: 0.6711142322097379
train_label=O_precision_tok: 0.8980722802065149
train_label=O_recall_tok: 0.9722309344013125
train_label=O_f-score_tok: 0.9336813895475012
train_label=N_precision_tok: 0.7888083286856293
train_label=N_recall_tok: 0.597521475848472
train_label=N_f-score_tok: 0.6799679487179487
train_label=P_precision_tok: 0.8753916341450009
train_label=P_recall_tok: 0.6366071071671263
train_label=P_f-score_tok: 0.7371441795880583
train_precision_macro_tok: 0.8540907476790484
train_recall_macro_tok: 0.7354531724723037
train_f-score_macro_tok: 0.7835978392845028
train_precision_micro_tok: 0.8883631072472274
train_recall_micro_tok: 0.8883631072472274
train_f-score_micro_tok: 0.8883631072472274
train_time: 146.08199048042297
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5172    0.0554    0.1001      1624
           N     0.6586    0.7858    0.7166      3310
           P     0.6883    0.8429    0.7578      3610

   micro avg     0.6711    0.6711    0.6711      8544
   macro avg     0.6214    0.5614    0.5249      8544
weighted avg     0.6443    0.6711    0.6168      8544

F1-macro sent:  0.5248507807195256
F1-micro sent:  0.6711142322097379
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8981    0.9722    0.9337    124347
           N     0.7888    0.5975    0.6800     14202
           P     0.8754    0.6366    0.7371     25017

   micro avg     0.8884    0.8884    0.8884    163566
   macro avg     0.8541    0.7355    0.7836    163566
weighted avg     0.8851    0.8884    0.8816    163566

F1-macro tok:  0.7835978392845028
F1-micro tok:  0.8883631072472274
**************************************************
dev_cost_sum: 44670.39953613281
dev_cost_avg: 40.57256996923961
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19023.0
dev_accuracy_tok: 0.8941900911911254
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.622895622895623
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7240704500978473
dev_label=P_precision_sent: 0.6972111553784861
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7399577167019028
dev_precision_macro_sent: 0.6400355927580363
dev_recall_macro_sent: 0.5552915687593075
dev_f-score_macro_sent: 0.49655639748025865
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9010030776245298
dev_label=O_recall_tok: 0.9755630978093182
dev_label=O_f-score_tok: 0.93680187253711
dev_label=N_precision_tok: 0.7912482065997131
dev_label=N_recall_tok: 0.5939687668282175
dev_label=N_f-score_tok: 0.6785604429406337
dev_label=P_precision_tok: 0.9044558697514996
dev_label=P_recall_tok: 0.6572229140722291
dev_label=P_f-score_tok: 0.7612693833393437
dev_precision_macro_tok: 0.8655690513252475
dev_recall_macro_tok: 0.7422515929032549
dev_f-score_macro_tok: 0.7922105662723625
dev_precision_micro_tok: 0.8941900911911254
dev_recall_micro_tok: 0.8941900911911254
dev_f-score_micro_tok: 0.8941900911911254
dev_time: 8.443653583526611
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6229    0.8645    0.7241       428
           P     0.6972    0.7883    0.7400       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6400    0.5553    0.4966      1101
weighted avg     0.6481    0.6567    0.5852      1101

F1-macro sent:  0.49655639748025865
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9010    0.9756    0.9368     16205
           N     0.7912    0.5940    0.6786      1857
           P     0.9045    0.6572    0.7613      3212

   micro avg     0.8942    0.8942    0.8942     21274
   macro avg     0.8656    0.7423    0.7922     21274
weighted avg     0.8919    0.8942    0.8878     21274

F1-macro tok:  0.7922105662723625
F1-micro tok:  0.8941900911911254
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 0.656100
train_cost_sum: 329392.3950805664
train_cost_avg: 38.552480697631836
train_count_sent: 8544.0
train_total_correct_sent: 5739.0
train_accuracy_sent: 0.6716994382022472
train_count_tok: 163566.0
train_total_correct_tok: 145402.0
train_accuracy_tok: 0.888950026289082
train_label=O_precision_sent: 0.42748091603053434
train_label=O_recall_sent: 0.06896551724137931
train_label=O_f-score_sent: 0.11876988335100742
train_label=N_precision_sent: 0.63091985428051
train_label=N_recall_sent: 0.8371601208459214
train_label=N_f-score_sent: 0.7195533627629186
train_label=P_precision_sent: 0.7341902313624679
train_label=P_recall_sent: 0.7911357340720222
train_label=P_f-score_sent: 0.7615999999999999
train_precision_macro_sent: 0.5975303338911707
train_recall_macro_sent: 0.5657537907197744
train_f-score_macro_sent: 0.533307748704642
train_precision_micro_sent: 0.6716994382022472
train_recall_micro_sent: 0.6716994382022472
train_f-score_micro_sent: 0.6716994382022472
train_label=O_precision_tok: 0.8985860447145713
train_label=O_recall_tok: 0.9725847829059004
train_label=O_f-score_tok: 0.9341222087481752
train_label=N_precision_tok: 0.7883259094283593
train_label=N_recall_tok: 0.5981551894099423
train_label=N_f-score_tok: 0.6801985747457763
train_label=P_precision_tok: 0.8772729769818162
train_label=P_recall_tok: 0.6383259383619139
train_label=P_f-score_tok: 0.7389634428505322
train_precision_macro_tok: 0.8547283103749157
train_recall_macro_tok: 0.7363553035592522
train_f-score_macro_tok: 0.7844280754481612
train_precision_micro_tok: 0.888950026289082
train_recall_micro_tok: 0.888950026289082
train_f-score_micro_tok: 0.888950026289082
train_time: 145.01088047027588
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4275    0.0690    0.1188      1624
           N     0.6309    0.8372    0.7196      3310
           P     0.7342    0.7911    0.7616      3610

   micro avg     0.6717    0.6717    0.6717      8544
   macro avg     0.5975    0.5658    0.5333      8544
weighted avg     0.6359    0.6717    0.6231      8544

F1-macro sent:  0.533307748704642
F1-micro sent:  0.6716994382022472
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8986    0.9726    0.9341    124347
           N     0.7883    0.5982    0.6802     14202
           P     0.8773    0.6383    0.7390     25017

   micro avg     0.8890    0.8890    0.8890    163566
   macro avg     0.8547    0.7364    0.7844    163566
weighted avg     0.8858    0.8890    0.8822    163566

F1-macro tok:  0.7844280754481612
F1-micro tok:  0.888950026289082
**************************************************
dev_cost_sum: 44641.45642089844
dev_cost_avg: 40.546281944503576
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 18994.0
dev_accuracy_tok: 0.892826924884836
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04184100418410041
dev_label=N_precision_sent: 0.629881154499151
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7295968534906587
dev_label=P_precision_sent: 0.703187250996016
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7463002114164905
dev_precision_macro_sent: 0.6110228018317223
dev_recall_macro_sent: 0.5612338453623195
dev_f-score_macro_sent: 0.5059126896970833
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.905352405121698
dev_label=O_recall_tok: 0.9686516507250849
dev_label=O_f-score_tok: 0.9359329815460752
dev_label=N_precision_tok: 0.7934705464868701
dev_label=N_recall_tok: 0.6020463112547119
dev_label=N_f-score_tok: 0.6846295162278015
dev_label=P_precision_tok: 0.8622872971903442
dev_label=P_recall_tok: 0.6783935242839353
dev_label=P_f-score_tok: 0.7593657431608294
dev_precision_macro_tok: 0.8537034162663041
dev_recall_macro_tok: 0.7496971620879106
dev_f-score_macro_tok: 0.7933094136449022
dev_precision_micro_tok: 0.892826924884836
dev_recall_micro_tok: 0.892826924884836
dev_f-score_micro_tok: 0.892826924884836
dev_time: 8.068026304244995
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0218    0.0418       229
           N     0.6299    0.8668    0.7296       428
           P     0.7032    0.7950    0.7463       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6110    0.5612    0.5059      1101
weighted avg     0.6324    0.6621    0.5933      1101

F1-macro sent:  0.5059126896970833
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9054    0.9687    0.9359     16205
           N     0.7935    0.6020    0.6846      1857
           P     0.8623    0.6784    0.7594      3212

   micro avg     0.8928    0.8928    0.8928     21274
   macro avg     0.8537    0.7497    0.7933     21274
weighted avg     0.8891    0.8928    0.8873     21274

F1-macro tok:  0.7933094136449022
F1-micro tok:  0.892826924884836
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 0.656100
train_cost_sum: 327975.6762084961
train_cost_avg: 38.3866662229045
train_count_sent: 8544.0
train_total_correct_sent: 5781.0
train_accuracy_sent: 0.6766151685393258
train_count_tok: 163566.0
train_total_correct_tok: 145764.0
train_accuracy_tok: 0.8911632001760758
train_label=O_precision_sent: 0.5274725274725275
train_label=O_recall_sent: 0.059113300492610835
train_label=O_f-score_sent: 0.10631229235880398
train_label=N_precision_sent: 0.6422745280820321
train_label=N_recall_sent: 0.8326283987915408
train_label=N_f-score_sent: 0.7251677410866991
train_label=P_precision_sent: 0.7194792434291329
train_label=P_recall_sent: 0.8113573407202216
train_label=P_f-score_sent: 0.7626611118343967
train_precision_macro_sent: 0.629742099661231
train_recall_macro_sent: 0.5676996800014578
train_f-score_macro_sent: 0.5313803817599666
train_precision_micro_sent: 0.6766151685393258
train_recall_micro_sent: 0.6766151685393258
train_f-score_micro_sent: 0.6766151685393258
train_label=O_precision_tok: 0.9008129112944049
train_label=O_recall_tok: 0.973147723708654
train_label=O_f-score_tok: 0.9355842569362027
train_label=N_precision_tok: 0.7947602295871135
train_label=N_recall_tok: 0.6044923250246445
train_label=N_f-score_tok: 0.6866901295792673
train_label=P_precision_tok: 0.8773328993055556
train_label=P_recall_tok: 0.646400447695567
train_label=P_f-score_tok: 0.7443669589633825
train_precision_macro_tok: 0.8576353467290246
train_recall_macro_tok: 0.7413468321429552
train_f-score_macro_tok: 0.7888804484929509
train_precision_micro_tok: 0.8911632001760758
train_recall_micro_tok: 0.8911632001760758
train_f-score_micro_tok: 0.8911632001760758
train_time: 145.18435311317444
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5275    0.0591    0.1063      1624
           N     0.6423    0.8326    0.7252      3310
           P     0.7195    0.8114    0.7627      3610

   micro avg     0.6766    0.6766    0.6766      8544
   macro avg     0.6297    0.5677    0.5314      8544
weighted avg     0.6531    0.6766    0.6234      8544

F1-macro sent:  0.5313803817599666
F1-micro sent:  0.6766151685393258
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9008    0.9731    0.9356    124347
           N     0.7948    0.6045    0.6867     14202
           P     0.8773    0.6464    0.7444     25017

   micro avg     0.8912    0.8912    0.8912    163566
   macro avg     0.8576    0.7413    0.7889    163566
weighted avg     0.8880    0.8912    0.8847    163566

F1-macro tok:  0.7888804484929509
F1-micro tok:  0.8911632001760758
**************************************************
dev_cost_sum: 44521.441650390625
dev_cost_avg: 40.43727670335207
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19040.0
dev_accuracy_tok: 0.8949891886810191
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.6599264705882353
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7386831275720165
dev_label=P_precision_sent: 0.673992673992674
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.7434343434343434
dev_precision_macro_sent: 0.6567609269815152
dev_recall_macro_sent: 0.5660605203824401
dev_f-score_macro_sent: 0.5134836014465645
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9048329698082884
dev_label=O_recall_tok: 0.9727861771058315
dev_label=O_f-score_tok: 0.9375799208968983
dev_label=N_precision_tok: 0.768918918918919
dev_label=N_recall_tok: 0.6128163704900377
dev_label=N_f-score_tok: 0.6820497452801917
dev_label=P_precision_tok: 0.9013490725126475
dev_label=P_recall_tok: 0.6656288916562889
dev_label=P_f-score_tok: 0.765759312320917
dev_precision_macro_tok: 0.8583669870799516
dev_recall_macro_tok: 0.7504104797507193
dev_f-score_macro_tok: 0.7951296594993357
dev_precision_micro_tok: 0.8949891886810191
dev_recall_micro_tok: 0.8949891886810191
dev_f-score_micro_tok: 0.8949891886810191
dev_time: 8.221910953521729
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.6599    0.8388    0.7387       428
           P     0.6740    0.8288    0.7434       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6568    0.5661    0.5135      1101
weighted avg     0.6607    0.6667    0.5991      1101

F1-macro sent:  0.5134836014465645
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9728    0.9376     16205
           N     0.7689    0.6128    0.6820      1857
           P     0.9013    0.6656    0.7658      3212

   micro avg     0.8950    0.8950    0.8950     21274
   macro avg     0.8584    0.7504    0.7951     21274
weighted avg     0.8924    0.8950    0.8893     21274

F1-macro tok:  0.7951296594993357
F1-micro tok:  0.8949891886810191
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.590490
train_cost_sum: 326544.60583496094
train_cost_avg: 38.21917203124543
train_count_sent: 8544.0
train_total_correct_sent: 5834.0
train_accuracy_sent: 0.6828183520599251
train_count_tok: 163566.0
train_total_correct_tok: 145949.0
train_accuracy_tok: 0.8922942420796498
train_label=O_precision_sent: 0.5816993464052288
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.10016882386043896
train_label=N_precision_sent: 0.6560266793711291
train_label=N_recall_sent: 0.83202416918429
train_label=N_f-score_sent: 0.7336174746936601
train_label=P_precision_sent: 0.7133317433818268
train_label=P_recall_sent: 0.8285318559556787
train_label=P_f-score_sent: 0.7666282199154171
train_precision_macro_sent: 0.6503525897193949
train_recall_macro_sent: 0.5717863269349978
train_f-score_macro_sent: 0.5334715061565054
train_precision_micro_sent: 0.6828183520599251
train_recall_micro_sent: 0.6828183520599251
train_f-score_micro_sent: 0.6828183520599251
train_label=O_precision_tok: 0.9026534801268894
train_label=O_recall_tok: 0.9725445728485609
train_label=O_f-score_tok: 0.936296560107153
train_label=N_precision_tok: 0.7969959035047792
train_label=N_recall_tok: 0.6164624700746374
train_label=N_f-score_tok: 0.6951999047127486
train_label=P_precision_tok: 0.8739653875094056
train_label=P_recall_tok: 0.6499980013590758
train_label=P_f-score_tok: 0.7455241501043027
train_precision_macro_tok: 0.8578715903803581
train_recall_macro_tok: 0.7463350147607581
train_f-score_macro_tok: 0.7923402049747348
train_precision_micro_tok: 0.8922942420796498
train_recall_micro_tok: 0.8922942420796498
train_f-score_micro_tok: 0.8922942420796498
train_time: 145.725811958313
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5817    0.0548    0.1002      1624
           N     0.6560    0.8320    0.7336      3310
           P     0.7133    0.8285    0.7666      3610

   micro avg     0.6828    0.6828    0.6828      8544
   macro avg     0.6504    0.5718    0.5335      8544
weighted avg     0.6661    0.6828    0.6272      8544

F1-macro sent:  0.5334715061565054
F1-micro sent:  0.6828183520599251
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9027    0.9725    0.9363    124347
           N     0.7970    0.6165    0.6952     14202
           P     0.8740    0.6500    0.7455     25017

   micro avg     0.8923    0.8923    0.8923    163566
   macro avg     0.8579    0.7463    0.7923    163566
weighted avg     0.8891    0.8923    0.8862    163566

F1-macro tok:  0.7923402049747348
F1-micro tok:  0.8922942420796498
**************************************************
dev_cost_sum: 44419.133239746094
dev_cost_avg: 40.34435353292107
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19075.0
dev_accuracy_tok: 0.8966343893955062
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6875
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.7268722466960352
dev_label=P_precision_sent: 0.6448445171849427
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.7469194312796209
dev_precision_macro_sent: 0.7107815057283142
dev_recall_macro_sent: 0.5644499741957196
dev_f-score_macro_sent: 0.5135790948900723
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.8994676030811056
dev_label=O_recall_tok: 0.9800061709348966
dev_label=O_f-score_tok: 0.9380112814151974
dev_label=N_precision_tok: 0.82568093385214
dev_label=N_recall_tok: 0.5713516424340334
dev_label=N_f-score_tok: 0.6753660089115213
dev_label=P_precision_tok: 0.914273467638234
dev_label=P_recall_tok: 0.6640722291407223
dev_label=P_f-score_tok: 0.769341749323715
dev_precision_macro_tok: 0.8798073348571599
dev_recall_macro_tok: 0.7384766808365507
dev_f-score_macro_tok: 0.794239679883478
dev_precision_micro_tok: 0.8966343893955062
dev_recall_micro_tok: 0.8966343893955062
dev_f-score_micro_tok: 0.8966343893955062
dev_time: 8.280345678329468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6875    0.7710    0.7269       428
           P     0.6448    0.8874    0.7469       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7108    0.5644    0.5136      1101
weighted avg     0.6937    0.6649    0.5977      1101

F1-macro sent:  0.5135790948900723
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8995    0.9800    0.9380     16205
           N     0.8257    0.5714    0.6754      1857
           P     0.9143    0.6641    0.7693      3212

   micro avg     0.8966    0.8966    0.8966     21274
   macro avg     0.8798    0.7385    0.7942     21274
weighted avg     0.8953    0.8966    0.8896     21274

F1-macro tok:  0.794239679883478
F1-micro tok:  0.8966343893955062
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.531441
train_cost_sum: 325499.93743896484
train_cost_avg: 38.096902790141016
train_count_sent: 8544.0
train_total_correct_sent: 5820.0
train_accuracy_sent: 0.6811797752808989
train_count_tok: 163566.0
train_total_correct_tok: 146102.0
train_accuracy_tok: 0.8932296443026057
train_label=O_precision_sent: 0.5105263157894737
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10694597574421169
train_label=N_precision_sent: 0.6574118783196523
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7308105206655932
train_label=P_precision_sent: 0.7122507122507122
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.767067246228586
train_precision_macro_sent: 0.6267296354532794
train_recall_macro_sent: 0.5711375350197448
train_f-score_macro_sent: 0.5349412475461303
train_precision_micro_sent: 0.6811797752808989
train_recall_micro_sent: 0.6811797752808989
train_f-score_micro_sent: 0.6811797752808989
train_label=O_precision_tok: 0.9031319259441671
train_label=O_recall_tok: 0.9732924799150764
train_label=O_f-score_tok: 0.9369005318284215
train_label=N_precision_tok: 0.7954317954317954
train_label=N_recall_tok: 0.6154766934234615
train_label=N_f-score_tok: 0.6939780080187369
train_label=P_precision_tok: 0.8796445880452343
train_label=P_recall_tok: 0.6529559899268498
train_label=P_f-score_tok: 0.7495354119347513
train_precision_macro_tok: 0.8594027698070655
train_recall_macro_tok: 0.7472417210884625
train_f-score_macro_tok: 0.7934713172606366
train_precision_micro_tok: 0.8932296443026057
train_recall_micro_tok: 0.8932296443026057
train_f-score_micro_tok: 0.8932296443026057
train_time: 106.82492566108704
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5105    0.0597    0.1069      1624
           N     0.6574    0.8227    0.7308      3310
           P     0.7123    0.8310    0.7671      3610

   micro avg     0.6812    0.6812    0.6812      8544
   macro avg     0.6267    0.5711    0.5349      8544
weighted avg     0.6527    0.6812    0.6275      8544

F1-macro sent:  0.5349412475461303
F1-micro sent:  0.6811797752808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9733    0.9369    124347
           N     0.7954    0.6155    0.6940     14202
           P     0.8796    0.6530    0.7495     25017

   micro avg     0.8932    0.8932    0.8932    163566
   macro avg     0.8594    0.7472    0.7935    163566
weighted avg     0.8902    0.8932    0.8872    163566

F1-macro tok:  0.7934713172606366
F1-micro tok:  0.8932296443026057
**************************************************
dev_cost_sum: 44356.53546142578
dev_cost_avg: 40.287498148433954
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19064.0
dev_accuracy_tok: 0.8961173263138102
dev_label=O_precision_sent: 0.5384615384615384
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10980392156862745
dev_label=N_precision_sent: 0.6431034482758621
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7400793650793651
dev_label=P_precision_sent: 0.7090909090909091
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7476038338658146
dev_precision_macro_sent: 0.6302186319427698
dev_recall_macro_sent: 0.5743904129407945
dev_f-score_macro_sent: 0.5324957068379358
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9031410622501428
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9380987690938751
dev_label=N_precision_tok: 0.8070432868672047
dev_label=N_recall_tok: 0.5923532579429187
dev_label=N_f-score_tok: 0.6832298136645962
dev_label=P_precision_tok: 0.8954602249062891
dev_label=P_recall_tok: 0.6693648816936488
dev_label=P_f-score_tok: 0.7660787457687512
dev_precision_macro_tok: 0.8685481913412122
dev_recall_macro_tok: 0.7458632613969058
dev_f-score_macro_tok: 0.7958024428424076
dev_precision_micro_tok: 0.8961173263138102
dev_recall_micro_tok: 0.8961173263138102
dev_f-score_micro_tok: 0.8961173263138102
dev_time: 5.109195709228516
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0611    0.1098       229
           N     0.6431    0.8715    0.7401       428
           P     0.7091    0.7905    0.7476       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6302    0.5744    0.5325      1101
weighted avg     0.6479    0.6703    0.6120      1101

F1-macro sent:  0.5324957068379358
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9759    0.9381     16205
           N     0.8070    0.5924    0.6832      1857
           P     0.8955    0.6694    0.7661      3212

   micro avg     0.8961    0.8961    0.8961     21274
   macro avg     0.8685    0.7459    0.7958     21274
weighted avg     0.8936    0.8961    0.8899     21274

F1-macro tok:  0.7958024428424076
F1-micro tok:  0.8961173263138102
**************************************************
Best epoch: 16
**************************************************

EPOCH: 23
Learning rate: 0.478297
train_cost_sum: 324238.28619384766
train_cost_avg: 37.94923761632112
train_count_sent: 8544.0
train_total_correct_sent: 5850.0
train_accuracy_sent: 0.6846910112359551
train_count_tok: 163566.0
train_total_correct_tok: 146357.0
train_accuracy_tok: 0.8947886480075321
train_label=O_precision_sent: 0.5191489361702127
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.1312533620225928
train_label=N_precision_sent: 0.6563400576368876
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.7313352956917314
train_label=P_precision_sent: 0.7225572979493365
train_label=P_recall_sent: 0.8296398891966759
train_label=P_f-score_sent: 0.7724049000644745
train_precision_macro_sent: 0.6326820972521455
train_recall_macro_sent: 0.5768142667380642
train_f-score_macro_sent: 0.544997852592933
train_precision_micro_sent: 0.6846910112359551
train_recall_micro_sent: 0.6846910112359551
train_f-score_micro_sent: 0.6846910112359551
train_label=O_precision_tok: 0.9042341043700378
train_label=O_recall_tok: 0.9736222023852606
train_label=O_f-score_tok: 0.9376461841106585
train_label=N_precision_tok: 0.8006171158907341
train_label=N_recall_tok: 0.6211801154766934
train_label=N_f-score_tok: 0.6995757503667578
train_label=P_precision_tok: 0.8826240754636081
train_label=P_recall_tok: 0.6582723747851461
train_label=P_f-score_tok: 0.7541156267887806
train_precision_macro_tok: 0.86249176524146
train_recall_macro_tok: 0.7510248975490335
train_f-score_macro_tok: 0.7971125204220656
train_precision_micro_tok: 0.8947886480075321
train_recall_micro_tok: 0.8947886480075321
train_f-score_micro_tok: 0.8947886480075321
train_time: 96.02021741867065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5191    0.0751    0.1313      1624
           N     0.6563    0.8257    0.7313      3310
           P     0.7226    0.8296    0.7724      3610

   micro avg     0.6847    0.6847    0.6847      8544
   macro avg     0.6327    0.5768    0.5450      8544
weighted avg     0.6582    0.6847    0.6346      8544

F1-macro sent:  0.544997852592933
F1-micro sent:  0.6846910112359551
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9736    0.9376    124347
           N     0.8006    0.6212    0.6996     14202
           P     0.8826    0.6583    0.7541     25017

   micro avg     0.8948    0.8948    0.8948    163566
   macro avg     0.8625    0.7510    0.7971    163566
weighted avg     0.8919    0.8948    0.8889    163566

F1-macro tok:  0.7971125204220656
F1-micro tok:  0.8947886480075321
**************************************************
dev_cost_sum: 44352.44226074219
dev_cost_avg: 40.28378043664141
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19024.0
dev_accuracy_tok: 0.894237096925825
dev_label=O_precision_sent: 0.9
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07531380753138077
dev_label=N_precision_sent: 0.7234567901234568
dev_label=N_recall_sent: 0.6845794392523364
dev_label=N_f-score_sent: 0.7034813925570228
dev_label=P_precision_sent: 0.5991253644314869
dev_label=P_recall_sent: 0.9256756756756757
dev_label=P_f-score_sent: 0.727433628318584
dev_precision_macro_sent: 0.7408607181849813
dev_recall_macro_sent: 0.5498521416572267
dev_f-score_macro_sent: 0.5020762761356625
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.9029048490393413
dev_label=O_recall_tok: 0.9743906201789572
dev_label=O_f-score_tok: 0.9372866767577835
dev_label=N_precision_tok: 0.8043315907393578
dev_label=N_recall_tok: 0.5799676898222941
dev_label=N_f-score_tok: 0.6739674593241552
dev_label=P_precision_tok: 0.8814875357580712
dev_label=P_recall_tok: 0.6715442092154421
dev_label=P_f-score_tok: 0.7623254992048065
dev_precision_macro_tok: 0.8629079918455901
dev_recall_macro_tok: 0.7419675064055644
dev_f-score_macro_tok: 0.7911932117622484
dev_precision_micro_tok: 0.894237096925825
dev_recall_micro_tok: 0.894237096925825
dev_f-score_micro_tok: 0.894237096925825
dev_time: 5.069675445556641
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9000    0.0393    0.0753       229
           N     0.7235    0.6846    0.7035       428
           P     0.5991    0.9257    0.7274       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7409    0.5499    0.5021      1101
weighted avg     0.7100    0.6476    0.5825      1101

F1-macro sent:  0.5020762761356625
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9029    0.9744    0.9373     16205
           N     0.8043    0.5800    0.6740      1857
           P     0.8815    0.6715    0.7623      3212

   micro avg     0.8942    0.8942    0.8942     21274
   macro avg     0.8629    0.7420    0.7912     21274
weighted avg     0.8911    0.8942    0.8879     21274

F1-macro tok:  0.7911932117622484
F1-micro tok:  0.894237096925825
**************************************************
Best epoch: 16
**************************************************

test0_cost_sum: 44888.054748535156
test0_cost_avg: 40.77025862718906
test0_count_sent: 1101.0
test0_total_correct_sent: 733.0
test0_accuracy_sent: 0.6657584014532243
test0_count_tok: 21274.0
test0_total_correct_tok: 19016.0
test0_accuracy_tok: 0.8938610510482279
test0_label=O_precision_sent: 0.72
test0_label=O_recall_sent: 0.07860262008733625
test0_label=O_f-score_sent: 0.14173228346456695
test0_label=N_precision_sent: 0.6436170212765957
test0_label=N_recall_sent: 0.8481308411214953
test0_label=N_f-score_sent: 0.7318548387096774
test0_label=P_precision_sent: 0.6875
test0_label=P_recall_sent: 0.7927927927927928
test0_label=P_f-score_sent: 0.7364016736401674
test0_precision_macro_sent: 0.6837056737588653
test0_recall_macro_sent: 0.5731754180005414
test0_f-score_macro_sent: 0.5366629319381372
test0_precision_micro_sent: 0.6657584014532243
test0_recall_micro_sent: 0.6657584014532243
test0_f-score_micro_sent: 0.6657584014532243
test0_label=O_precision_tok: 0.8933714349750659
test0_label=O_recall_tok: 0.9838938599197778
test0_label=O_f-score_tok: 0.9364501350875133
test0_label=N_precision_tok: 0.8338788870703764
test0_label=N_recall_tok: 0.5487345180398492
test0_label=N_f-score_tok: 0.6619032153296526
test0_label=P_precision_tok: 0.9310657596371882
test0_label=P_recall_tok: 0.6391656288916563
test0_label=P_f-score_tok: 0.7579841240539045
test0_precision_macro_tok: 0.8861053605608769
test0_recall_macro_tok: 0.7239313356170944
test0_f-score_macro_tok: 0.7854458248236901
test0_precision_micro_tok: 0.8938610510482279
test0_recall_micro_tok: 0.8938610510482279
test0_f-score_micro_tok: 0.8938610510482279
test0_time: 5.024035692214966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7200    0.0786    0.1417       229
           N     0.6436    0.8481    0.7319       428
           P     0.6875    0.7928    0.7364       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6837    0.5732    0.5367      1101
weighted avg     0.6772    0.6658    0.6109      1101

F1-macro sent:  0.5366629319381372
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9839    0.9365     16205
           N     0.8339    0.5487    0.6619      1857
           P     0.9311    0.6392    0.7580      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8861    0.7239    0.7854     21274
weighted avg     0.8939    0.8939    0.8855     21274

F1-macro tok:  0.7854458248236901
F1-micro tok:  0.8938610510482279
**************************************************
test1_cost_sum: 87209.81533813477
test1_cost_avg: 39.461454904133376
test1_count_sent: 2210.0
test1_total_correct_sent: 1526.0
test1_accuracy_sent: 0.6904977375565611
test1_count_tok: 42405.0
test1_total_correct_tok: 37532.0
test1_accuracy_tok: 0.8850843060959792
test1_label=O_precision_sent: 0.5
test1_label=O_recall_sent: 0.06683804627249357
test1_label=O_f-score_sent: 0.11791383219954647
test1_label=N_precision_sent: 0.6655202063628547
test1_label=N_recall_sent: 0.8486842105263158
test1_label=N_f-score_sent: 0.7460240963855421
test1_label=P_precision_sent: 0.7296482412060301
test1_label=P_recall_sent: 0.7986798679867987
test1_label=P_f-score_sent: 0.7626050420168068
test1_precision_macro_sent: 0.631722815856295
test1_recall_macro_sent: 0.5714007082618694
test1_f-score_macro_sent: 0.5421809902006318
test1_precision_micro_sent: 0.6904977375565611
test1_recall_micro_sent: 0.6904977375565611
test1_f-score_micro_sent: 0.6904977375565611
test1_label=O_precision_tok: 0.8842652430457993
test1_label=O_recall_tok: 0.9835302206387899
test1_label=O_f-score_tok: 0.9312599869799373
test1_label=N_precision_tok: 0.8201121794871795
test1_label=N_recall_tok: 0.5444148936170212
test1_label=N_f-score_tok: 0.6544117647058824
test1_label=P_precision_tok: 0.9293818013429035
test1_label=P_recall_tok: 0.6038814502783211
test1_label=P_f-score_tok: 0.7320809775670253
test1_precision_macro_tok: 0.8779197412919607
test1_recall_macro_tok: 0.7106088548447107
test1_f-score_macro_tok: 0.7725842430842816
test1_precision_micro_tok: 0.8850843060959792
test1_recall_micro_tok: 0.8850843060959792
test1_f-score_micro_tok: 0.8850843060959792
test1_time: 10.51780390739441
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0668    0.1179       389
           N     0.6655    0.8487    0.7460       912
           P     0.7296    0.7987    0.7626       909

   micro avg     0.6905    0.6905    0.6905      2210
   macro avg     0.6317    0.5714    0.5422      2210
weighted avg     0.6628    0.6905    0.6423      2210

F1-macro sent:  0.5421809902006318
F1-micro sent:  0.6904977375565611
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8843    0.9835    0.9313     31998
           N     0.8201    0.5444    0.6544      3760
           P     0.9294    0.6039    0.7321      6647

   micro avg     0.8851    0.8851    0.8851     42405
   macro avg     0.8779    0.7106    0.7726     42405
weighted avg     0.8856    0.8851    0.8755     42405

F1-macro tok:  0.7725842430842816
F1-micro tok:  0.8850843060959792
**************************************************
