to_write_filename: runs/transformer_conll03_sent+word+LM_loss.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'PER': 4, 'LOC': 1, 'MISC': 2, 'ORG': 3, 'O': 0}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-16 12:02:19.402101: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-16 12:02:19.491806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 8191:00:00.0
totalMemory: 11.17GiB freeMemory: 8.98GiB
2019-03-16 12:02:19.491859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-16 12:02:19.915066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-16 12:02:19.915127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-16 12:02:19.915136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-16 12:02:19.915385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 8191:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 9797652.
Parameter count without word embeddings: 3230652.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 452193.06103515625
train_cost_avg: 32.20518916282005
train_count_sent: 14041.0
train_total_correct_sent: 11819.0
train_accuracy_sent: 0.8417491631650167
train_count_tok: 203621.0
train_total_correct_tok: 186505.0
train_accuracy_tok: 0.9159418724001945
train_label=0_precision_sent: 0.6880131362889984
train_label=0_recall_sent: 0.4321072533516672
train_label=0_f-score_sent: 0.5308277027027027
train_label=1_precision_sent: 0.8647453741607991
train_label=1_recall_sent: 0.948796263025512
train_label=1_f-score_sent: 0.9048230960335818
train_precision_macro_sent: 0.7763792552248987
train_recall_macro_sent: 0.6904517581885896
train_f-score_macro_sent: 0.7178253993681423
train_precision_micro_sent: 0.8417491631650167
train_recall_micro_sent: 0.8417491631650167
train_f-score_micro_sent: 0.8417491631650167
train_label=O_precision_tok: 0.9468351121264819
train_label=O_recall_tok: 0.9824800386842633
train_label=O_f-score_tok: 0.9643282977368757
train_label=LOC_precision_tok: 0.7172595929780954
train_label=LOC_recall_tok: 0.5564661925997348
train_label=LOC_f-score_tok: 0.626713723360934
train_label=MISC_precision_tok: 0.6043745203376822
train_label=MISC_recall_tok: 0.34291312867406926
train_label=MISC_f-score_tok: 0.43756077232949026
train_label=ORG_precision_tok: 0.6634578847371754
train_label=ORG_recall_tok: 0.5224937655860349
train_label=ORG_f-score_tok: 0.5845982142857143
train_label=PER_precision_tok: 0.7898516929390915
train_label=PER_recall_tok: 0.7609633357296909
train_label=PER_f-score_tok: 0.7751384502723236
train_precision_macro_tok: 0.7443557606237052
train_recall_macro_tok: 0.6330632922547587
train_f-score_macro_tok: 0.6776678915970675
train_precision_micro_tok: 0.9159418724001945
train_recall_micro_tok: 0.9159418724001945
train_f-score_micro_tok: 0.9159418724001945
train_time: 158.14136791229248
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6880    0.4321    0.5308      2909
           1     0.8647    0.9488    0.9048     11132

   micro avg     0.8417    0.8417    0.8417     14041
   macro avg     0.7764    0.6905    0.7178     14041
weighted avg     0.8281    0.8417    0.8273     14041

F1-macro sent:  0.7178253993681423
F1-micro sent:  0.8417491631650167
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9468    0.9825    0.9643    169578
         LOC     0.7173    0.5565    0.6267      8297
        MISC     0.6044    0.3429    0.4376      4593
         ORG     0.6635    0.5225    0.5846     10025
         PER     0.7899    0.7610    0.7751     11128

   micro avg     0.9159    0.9159    0.9159    203621
   macro avg     0.7444    0.6331    0.6777    203621
weighted avg     0.9072    0.9159    0.9097    203621

F1-macro tok:  0.6776678915970675
F1-micro tok:  0.9159418724001945
**************************************************
dev_cost_sum: 101753.41400146484
dev_cost_avg: 31.30874276968149
dev_count_sent: 3250.0
dev_total_correct_sent: 2904.0
dev_accuracy_sent: 0.8935384615384615
dev_count_tok: 51362.0
dev_total_correct_tok: 49949.0
dev_accuracy_tok: 0.9724893890424827
dev_label=0_precision_sent: 0.9118457300275482
dev_label=0_recall_sent: 0.5131782945736434
dev_label=0_f-score_sent: 0.6567460317460317
dev_label=1_precision_sent: 0.8912365777623831
dev_label=1_recall_sent: 0.9877159309021113
dev_label=1_f-score_sent: 0.9369992716678804
dev_precision_macro_sent: 0.9015411538949656
dev_recall_macro_sent: 0.7504471127378773
dev_f-score_macro_sent: 0.7968726517069561
dev_precision_micro_sent: 0.8935384615384615
dev_recall_micro_sent: 0.8935384615384615
dev_f-score_micro_sent: 0.8935384615384615
dev_label=O_precision_tok: 0.9879540443309737
dev_label=O_recall_tok: 0.9954863303631984
dev_label=O_f-score_tok: 0.9917058850938912
dev_label=LOC_precision_tok: 0.890961262553802
dev_label=LOC_recall_tok: 0.8896848137535817
dev_label=LOC_f-score_tok: 0.8903225806451613
dev_label=MISC_precision_tok: 0.8586744639376218
dev_label=MISC_recall_tok: 0.694794952681388
dev_label=MISC_f-score_tok: 0.7680906713164778
dev_label=ORG_precision_tok: 0.865934065934066
dev_label=ORG_recall_tok: 0.7533460803059273
dev_label=ORG_f-score_tok: 0.8057259713701432
dev_label=PER_precision_tok: 0.917065868263473
dev_label=PER_recall_tok: 0.9726897427754843
dev_label=PER_f-score_tok: 0.9440591770688859
dev_precision_macro_tok: 0.9041179410039873
dev_recall_macro_tok: 0.8612003839759159
dev_f-score_macro_tok: 0.8799808570989119
dev_precision_micro_tok: 0.9724893890424827
dev_recall_micro_tok: 0.9724893890424827
dev_f-score_micro_tok: 0.9724893890424827
dev_time: 14.36654257774353
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9118    0.5132    0.6567       645
           1     0.8912    0.9877    0.9370      2605

   micro avg     0.8935    0.8935    0.8935      3250
   macro avg     0.9015    0.7504    0.7969      3250
weighted avg     0.8953    0.8935    0.8814      3250

F1-macro sent:  0.7968726517069561
F1-micro sent:  0.8935384615384615
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9880    0.9955    0.9917     42759
         LOC     0.8910    0.8897    0.8903      2094
        MISC     0.8587    0.6948    0.7681      1268
         ORG     0.8659    0.7533    0.8057      2092
         PER     0.9171    0.9727    0.9441      3149

   micro avg     0.9725    0.9725    0.9725     51362
   macro avg     0.9041    0.8612    0.8800     51362
weighted avg     0.9715    0.9725    0.9716     51362

F1-macro tok:  0.8799808570989119
F1-micro tok:  0.9724893890424827
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 383772.58990478516
train_cost_avg: 27.33228330637313
train_count_sent: 14041.0
train_total_correct_sent: 12648.0
train_accuracy_sent: 0.9007905419841892
train_count_tok: 203621.0
train_total_correct_tok: 196072.0
train_accuracy_tok: 0.9629262207729066
train_label=0_precision_sent: 0.7864701436130007
train_label=0_recall_sent: 0.7153661051907872
train_label=0_f-score_sent: 0.7492349234923492
train_label=1_precision_sent: 0.9273365511189118
train_label=1_recall_sent: 0.9492454186130076
train_label=1_f-score_sent: 0.9381630931770764
train_precision_macro_sent: 0.8569033473659562
train_recall_macro_sent: 0.8323057619018974
train_f-score_macro_sent: 0.8436990083347128
train_precision_micro_sent: 0.9007905419841892
train_recall_micro_sent: 0.9007905419841892
train_f-score_micro_sent: 0.9007905419841892
train_label=O_precision_tok: 0.9877096349884906
train_label=O_recall_tok: 0.9918916368868603
train_label=O_f-score_tok: 0.9897962185986572
train_label=LOC_precision_tok: 0.841041162227603
train_label=LOC_recall_tok: 0.8372905869591418
train_label=LOC_f-score_tok: 0.83916168387993
train_label=MISC_precision_tok: 0.7478481012658228
train_label=MISC_recall_tok: 0.6431526235575876
train_label=MISC_f-score_tok: 0.6915603418003043
train_label=ORG_precision_tok: 0.7851905401218631
train_label=ORG_recall_tok: 0.7584039900249376
train_label=ORG_f-score_tok: 0.7715648467627358
train_label=PER_precision_tok: 0.906665500349895
train_label=PER_recall_tok: 0.9314342199856218
train_label=PER_f-score_tok: 0.9188829787234043
train_precision_macro_tok: 0.8536909877907348
train_recall_macro_tok: 0.8324346114828298
train_f-score_macro_tok: 0.8421932139530064
train_precision_micro_tok: 0.9629262207729066
train_recall_micro_tok: 0.9629262207729066
train_f-score_micro_tok: 0.9629262207729066
train_time: 157.88089036941528
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7865    0.7154    0.7492      2909
           1     0.9273    0.9492    0.9382     11132

   micro avg     0.9008    0.9008    0.9008     14041
   macro avg     0.8569    0.8323    0.8437     14041
weighted avg     0.8982    0.9008    0.8990     14041

F1-macro sent:  0.8436990083347128
F1-micro sent:  0.9007905419841892
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9877    0.9919    0.9898    169578
         LOC     0.8410    0.8373    0.8392      8297
        MISC     0.7478    0.6432    0.6916      4593
         ORG     0.7852    0.7584    0.7716     10025
         PER     0.9067    0.9314    0.9189     11128

   micro avg     0.9629    0.9629    0.9629    203621
   macro avg     0.8537    0.8324    0.8422    203621
weighted avg     0.9619    0.9629    0.9623    203621

F1-macro tok:  0.8421932139530064
F1-micro tok:  0.9629262207729066
**************************************************
dev_cost_sum: 98828.58345031738
dev_cost_avg: 30.408794907789964
dev_count_sent: 3250.0
dev_total_correct_sent: 3045.0
dev_accuracy_sent: 0.936923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50139.0
dev_accuracy_tok: 0.9761886219383981
dev_label=0_precision_sent: 0.8064066852367688
dev_label=0_recall_sent: 0.8976744186046511
dev_label=0_f-score_sent: 0.8495964783565664
dev_label=1_precision_sent: 0.9739336492890995
dev_label=1_recall_sent: 0.9466410748560461
dev_label=1_f-score_sent: 0.9600934397508273
dev_precision_macro_sent: 0.8901701672629342
dev_recall_macro_sent: 0.9221577467303486
dev_f-score_macro_sent: 0.9048449590536969
dev_precision_micro_sent: 0.936923076923077
dev_recall_micro_sent: 0.936923076923077
dev_f-score_micro_sent: 0.936923076923077
dev_label=O_precision_tok: 0.9929034968952799
dev_label=O_recall_tok: 0.9947379499052831
dev_label=O_f-score_tok: 0.9938198768648433
dev_label=LOC_precision_tok: 0.9376310272536688
dev_label=LOC_recall_tok: 0.8543457497612226
dev_label=LOC_f-score_tok: 0.8940529735132434
dev_label=MISC_precision_tok: 0.9031311154598826
dev_label=MISC_recall_tok: 0.7279179810725552
dev_label=MISC_f-score_tok: 0.806113537117904
dev_label=ORG_precision_tok: 0.7740709459459459
dev_label=ORG_recall_tok: 0.8761950286806883
dev_label=ORG_f-score_tok: 0.8219730941704035
dev_label=PER_precision_tok: 0.9485430874147551
dev_label=PER_recall_tok: 0.9717370593839314
dev_label=PER_f-score_tok: 0.96
dev_precision_macro_tok: 0.9112559345939065
dev_recall_macro_tok: 0.8849867537607361
dev_f-score_macro_tok: 0.8951918963332789
dev_precision_micro_tok: 0.9761886219383981
dev_recall_micro_tok: 0.9761886219383981
dev_f-score_micro_tok: 0.9761886219383981
dev_time: 10.960428953170776
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8064    0.8977    0.8496       645
           1     0.9739    0.9466    0.9601      2605

   micro avg     0.9369    0.9369    0.9369      3250
   macro avg     0.8902    0.9222    0.9048      3250
weighted avg     0.9407    0.9369    0.9382      3250

F1-macro sent:  0.9048449590536969
F1-micro sent:  0.936923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9929    0.9947    0.9938     42759
         LOC     0.9376    0.8543    0.8941      2094
        MISC     0.9031    0.7279    0.8061      1268
         ORG     0.7741    0.8762    0.8220      2092
         PER     0.9485    0.9717    0.9600      3149

   micro avg     0.9762    0.9762    0.9762     51362
   macro avg     0.9113    0.8850    0.8952     51362
weighted avg     0.9768    0.9762    0.9760     51362

F1-macro tok:  0.8951918963332789
F1-micro tok:  0.9761886219383981
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 371291.18841552734
train_cost_avg: 26.4433579100867
train_count_sent: 14041.0
train_total_correct_sent: 12925.0
train_accuracy_sent: 0.9205184815896303
train_count_tok: 203621.0
train_total_correct_tok: 197458.0
train_accuracy_tok: 0.9697329843189062
train_label=0_precision_sent: 0.8205219878441187
train_label=0_recall_sent: 0.7889309040907528
train_label=0_f-score_sent: 0.804416403785489
train_label=1_precision_sent: 0.9453930985414444
train_label=1_recall_sent: 0.9549047790154509
train_label=1_f-score_sent: 0.9501251340722202
train_precision_macro_sent: 0.8829575431927815
train_recall_macro_sent: 0.8719178415531019
train_f-score_macro_sent: 0.8772707689288546
train_precision_micro_sent: 0.9205184815896303
train_recall_micro_sent: 0.9205184815896303
train_f-score_micro_sent: 0.9205184815896303
train_label=O_precision_tok: 0.9900596655203833
train_label=O_recall_tok: 0.9931948719763177
train_label=O_f-score_tok: 0.9916247906197655
train_label=LOC_precision_tok: 0.8637176582806725
train_label=LOC_recall_tok: 0.8730866578281307
train_label=LOC_f-score_tok: 0.8683768880364421
train_label=MISC_precision_tok: 0.7942396875762753
train_label=MISC_recall_tok: 0.708469409971696
train_label=MISC_f-score_tok: 0.7489067894131185
train_label=ORG_precision_tok: 0.8271998355263158
train_label=ORG_recall_tok: 0.8026932668329178
train_label=ORG_f-score_tok: 0.8147623145851263
train_label=PER_precision_tok: 0.9287232158668319
train_label=PER_recall_tok: 0.9425772825305535
train_label=PER_f-score_tok: 0.9355989653019356
train_precision_macro_tok: 0.8807880125540958
train_recall_macro_tok: 0.8640042978279231
train_f-score_macro_tok: 0.8718539495912776
train_precision_micro_tok: 0.9697329843189062
train_recall_micro_tok: 0.9697329843189062
train_f-score_micro_tok: 0.9697329843189062
train_time: 157.40950226783752
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8205    0.7889    0.8044      2909
           1     0.9454    0.9549    0.9501     11132

   micro avg     0.9205    0.9205    0.9205     14041
   macro avg     0.8830    0.8719    0.8773     14041
weighted avg     0.9195    0.9205    0.9199     14041

F1-macro sent:  0.8772707689288546
F1-micro sent:  0.9205184815896303
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9901    0.9932    0.9916    169578
         LOC     0.8637    0.8731    0.8684      8297
        MISC     0.7942    0.7085    0.7489      4593
         ORG     0.8272    0.8027    0.8148     10025
         PER     0.9287    0.9426    0.9356     11128

   micro avg     0.9697    0.9697    0.9697    203621
   macro avg     0.8808    0.8640    0.8719    203621
weighted avg     0.9691    0.9697    0.9694    203621

F1-macro tok:  0.8718539495912776
F1-micro tok:  0.9697329843189062
**************************************************
dev_cost_sum: 96372.89028167725
dev_cost_avg: 29.653197009746844
dev_count_sent: 3250.0
dev_total_correct_sent: 3097.0
dev_accuracy_sent: 0.9529230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50356.0
dev_accuracy_tok: 0.9804135352984696
dev_label=0_precision_sent: 0.8324324324324325
dev_label=0_recall_sent: 0.9550387596899225
dev_label=0_f-score_sent: 0.8895306859205776
dev_label=1_precision_sent: 0.9884462151394422
dev_label=1_recall_sent: 0.9523992322456813
dev_label=1_f-score_sent: 0.9700879765395893
dev_precision_macro_sent: 0.9104393237859374
dev_recall_macro_sent: 0.9537189959678019
dev_f-score_macro_sent: 0.9298093312300835
dev_precision_micro_sent: 0.9529230769230769
dev_recall_micro_sent: 0.9529230769230769
dev_f-score_micro_sent: 0.9529230769230768
dev_label=O_precision_tok: 0.9908442358190226
dev_label=O_recall_tok: 0.9971935732828177
dev_label=O_f-score_tok: 0.99400876538605
dev_label=LOC_precision_tok: 0.9128205128205128
dev_label=LOC_recall_tok: 0.9350525310410697
dev_label=LOC_f-score_tok: 0.923802783675395
dev_label=MISC_precision_tok: 0.9123314065510597
dev_label=MISC_recall_tok: 0.7468454258675079
dev_label=MISC_f-score_tok: 0.821335646140503
dev_label=ORG_precision_tok: 0.8922764227642277
dev_label=ORG_recall_tok: 0.8393881453154876
dev_label=ORG_f-score_tok: 0.865024630541872
dev_label=PER_precision_tok: 0.961611076148521
dev_label=PER_recall_tok: 0.9704668148618609
dev_label=PER_f-score_tok: 0.9660186502291765
dev_precision_macro_tok: 0.9339767308206687
dev_recall_macro_tok: 0.8977892980737489
dev_f-score_macro_tok: 0.9140380951945992
dev_precision_micro_tok: 0.9804135352984696
dev_recall_micro_tok: 0.9804135352984696
dev_f-score_micro_tok: 0.9804135352984696
dev_time: 14.00121283531189
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8324    0.9550    0.8895       645
           1     0.9884    0.9524    0.9701      2605

   micro avg     0.9529    0.9529    0.9529      3250
   macro avg     0.9104    0.9537    0.9298      3250
weighted avg     0.9575    0.9529    0.9541      3250

F1-macro sent:  0.9298093312300835
F1-micro sent:  0.9529230769230768
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9908    0.9972    0.9940     42759
         LOC     0.9128    0.9351    0.9238      2094
        MISC     0.9123    0.7468    0.8213      1268
         ORG     0.8923    0.8394    0.8650      2092
         PER     0.9616    0.9705    0.9660      3149

   micro avg     0.9804    0.9804    0.9804     51362
   macro avg     0.9340    0.8978    0.9140     51362
weighted avg     0.9799    0.9804    0.9799     51362

F1-macro tok:  0.9140380951945992
F1-micro tok:  0.9804135352984696
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362080.541595459
train_cost_avg: 25.787375656681075
train_count_sent: 14041.0
train_total_correct_sent: 13106.0
train_accuracy_sent: 0.933409301331814
train_count_tok: 203621.0
train_total_correct_tok: 198237.0
train_accuracy_tok: 0.9735587193855251
train_label=0_precision_sent: 0.8443824145150035
train_label=0_recall_sent: 0.8319009969061533
train_label=0_f-score_sent: 0.838095238095238
train_label=1_precision_sent: 0.9562416107382551
train_label=1_recall_sent: 0.9599353215954006
train_label=1_f-score_sent: 0.9580849060832923
train_precision_macro_sent: 0.9003120126266293
train_recall_macro_sent: 0.895918159250777
train_f-score_macro_sent: 0.8980900720892652
train_precision_micro_sent: 0.933409301331814
train_recall_micro_sent: 0.933409301331814
train_f-score_micro_sent: 0.933409301331814
train_label=O_precision_tok: 0.9911993980082539
train_label=O_recall_tok: 0.9942622274115747
train_label=O_f-score_tok: 0.9927284503061705
train_label=LOC_precision_tok: 0.8903545927629191
train_label=LOC_recall_tok: 0.8867060383271061
train_label=LOC_f-score_tok: 0.8885265700483093
train_label=MISC_precision_tok: 0.8103489771359808
train_label=MISC_recall_tok: 0.733072066187677
train_label=MISC_f-score_tok: 0.7697759487882945
train_label=ORG_precision_tok: 0.8487720370936512
train_label=ORG_recall_tok: 0.8308229426433915
train_label=ORG_f-score_tok: 0.8397015828208488
train_label=PER_precision_tok: 0.93718993621545
train_label=PER_recall_tok: 0.9506649892163911
train_label=PER_f-score_tok: 0.9438793718772306
train_precision_macro_tok: 0.8955729882432509
train_recall_macro_tok: 0.8791056527572281
train_f-score_macro_tok: 0.8869223847681708
train_precision_micro_tok: 0.9735587193855251
train_recall_micro_tok: 0.9735587193855251
train_f-score_micro_tok: 0.9735587193855251
train_time: 155.6139190196991
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8444    0.8319    0.8381      2909
           1     0.9562    0.9599    0.9581     11132

   micro avg     0.9334    0.9334    0.9334     14041
   macro avg     0.9003    0.8959    0.8981     14041
weighted avg     0.9331    0.9334    0.9332     14041

F1-macro sent:  0.8980900720892652
F1-micro sent:  0.933409301331814
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9912    0.9943    0.9927    169578
         LOC     0.8904    0.8867    0.8885      8297
        MISC     0.8103    0.7331    0.7698      4593
         ORG     0.8488    0.8308    0.8397     10025
         PER     0.9372    0.9507    0.9439     11128

   micro avg     0.9736    0.9736    0.9736    203621
   macro avg     0.8956    0.8791    0.8869    203621
weighted avg     0.9730    0.9736    0.9732    203621

F1-macro tok:  0.8869223847681708
F1-micro tok:  0.9735587193855251
**************************************************
dev_cost_sum: 94504.34098052979
dev_cost_avg: 29.078258763239933
dev_count_sent: 3250.0
dev_total_correct_sent: 3132.0
dev_accuracy_sent: 0.9636923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50399.0
dev_accuracy_tok: 0.9812507301117558
dev_label=0_precision_sent: 0.9647266313932981
dev_label=0_recall_sent: 0.8480620155038759
dev_label=0_f-score_sent: 0.9026402640264027
dev_label=1_precision_sent: 0.963473723443906
dev_label=1_recall_sent: 0.9923224568138196
dev_label=1_f-score_sent: 0.9776853252647504
dev_precision_macro_sent: 0.964100177418602
dev_recall_macro_sent: 0.9201922361588477
dev_f-score_macro_sent: 0.9401627946455766
dev_precision_micro_sent: 0.9636923076923077
dev_recall_micro_sent: 0.9636923076923077
dev_f-score_micro_sent: 0.9636923076923077
dev_label=O_precision_tok: 0.9936328015673104
dev_label=O_recall_tok: 0.996351645267663
dev_label=O_f-score_tok: 0.994990366088632
dev_label=LOC_precision_tok: 0.9072786277236903
dev_label=LOC_recall_tok: 0.934574976122254
dev_label=LOC_f-score_tok: 0.9207245354034345
dev_label=MISC_precision_tok: 0.8635214827295703
dev_label=MISC_recall_tok: 0.8083596214511041
dev_label=MISC_f-score_tok: 0.8350305498981669
dev_label=ORG_precision_tok: 0.9048856548856549
dev_label=ORG_recall_tok: 0.8322179732313576
dev_label=ORG_f-score_tok: 0.8670318725099602
dev_label=PER_precision_tok: 0.9549409571162213
dev_label=PER_recall_tok: 0.9758653540806606
dev_label=PER_f-score_tok: 0.9652897754044291
dev_precision_macro_tok: 0.9248519048044894
dev_recall_macro_tok: 0.9094739140306078
dev_f-score_macro_tok: 0.9166134198609246
dev_precision_micro_tok: 0.9812507301117558
dev_recall_micro_tok: 0.9812507301117558
dev_f-score_micro_tok: 0.9812507301117558
dev_time: 15.032279253005981
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9647    0.8481    0.9026       645
           1     0.9635    0.9923    0.9777      2605

   micro avg     0.9637    0.9637    0.9637      3250
   macro avg     0.9641    0.9202    0.9402      3250
weighted avg     0.9637    0.9637    0.9628      3250

F1-macro sent:  0.9401627946455766
F1-micro sent:  0.9636923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9964    0.9950     42759
         LOC     0.9073    0.9346    0.9207      2094
        MISC     0.8635    0.8084    0.8350      1268
         ORG     0.9049    0.8322    0.8670      2092
         PER     0.9549    0.9759    0.9653      3149

   micro avg     0.9813    0.9813    0.9813     51362
   macro avg     0.9249    0.9095    0.9166     51362
weighted avg     0.9809    0.9813    0.9810     51362

F1-macro tok:  0.9166134198609246
F1-micro tok:  0.9812507301117558
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355041.9536743164
train_cost_avg: 25.286087434963065
train_count_sent: 14041.0
train_total_correct_sent: 13266.0
train_accuracy_sent: 0.94480450110391
train_count_tok: 203621.0
train_total_correct_tok: 198778.0
train_accuracy_tok: 0.9762156162674773
train_label=0_precision_sent: 0.8717770034843205
train_label=0_recall_sent: 0.860089377793056
train_label=0_f-score_sent: 0.8658937532445061
train_label=1_precision_sent: 0.9635663772267479
train_label=1_recall_sent: 0.9669421487603306
train_label=1_f-score_sent: 0.9652513114827601
train_precision_macro_sent: 0.9176716903555342
train_recall_macro_sent: 0.9135157632766933
train_f-score_macro_sent: 0.9155725323636331
train_precision_micro_sent: 0.94480450110391
train_recall_micro_sent: 0.94480450110391
train_f-score_micro_sent: 0.94480450110391
train_label=O_precision_tok: 0.9921575779682655
train_label=O_recall_tok: 0.994468622109
train_label=O_f-score_tok: 0.9933117558187134
train_label=LOC_precision_tok: 0.9016806722689076
train_label=LOC_recall_tok: 0.9052669639628782
train_label=LOC_f-score_tok: 0.9034702592169364
train_label=MISC_precision_tok: 0.8361434338636904
train_label=MISC_recall_tok: 0.7666013498802525
train_label=MISC_f-score_tok: 0.7998636983189459
train_label=ORG_precision_tok: 0.86299004671948
train_label=ORG_recall_tok: 0.8475810473815462
train_label=ORG_f-score_tok: 0.8552161441296362
train_label=PER_precision_tok: 0.9421010567445165
train_label=PER_recall_tok: 0.9533608914450036
train_label=PER_f-score_tok: 0.9476975300370718
train_precision_macro_tok: 0.907014557512972
train_recall_macro_tok: 0.893455774955736
train_f-score_macro_tok: 0.8999118775042607
train_precision_micro_tok: 0.9762156162674773
train_recall_micro_tok: 0.9762156162674773
train_f-score_micro_tok: 0.9762156162674773
train_time: 155.87505841255188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8718    0.8601    0.8659      2909
           1     0.9636    0.9669    0.9653     11132

   micro avg     0.9448    0.9448    0.9448     14041
   macro avg     0.9177    0.9135    0.9156     14041
weighted avg     0.9445    0.9448    0.9447     14041

F1-macro sent:  0.9155725323636331
F1-micro sent:  0.94480450110391
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9922    0.9945    0.9933    169578
         LOC     0.9017    0.9053    0.9035      8297
        MISC     0.8361    0.7666    0.7999      4593
         ORG     0.8630    0.8476    0.8552     10025
         PER     0.9421    0.9534    0.9477     11128

   micro avg     0.9762    0.9762    0.9762    203621
   macro avg     0.9070    0.8935    0.8999    203621
weighted avg     0.9759    0.9762    0.9760    203621

F1-macro tok:  0.8999118775042607
F1-micro tok:  0.9762156162674773
**************************************************
dev_cost_sum: 93260.2950515747
dev_cost_avg: 28.695475400484526
dev_count_sent: 3250.0
dev_total_correct_sent: 3083.0
dev_accuracy_sent: 0.9486153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50433.0
dev_accuracy_tok: 0.9819126981036564
dev_label=0_precision_sent: 0.8136482939632546
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.8813077469793887
dev_label=1_precision_sent: 0.989951768488746
dev_label=1_recall_sent: 0.945489443378119
dev_label=1_f-score_sent: 0.9672098959355979
dev_precision_macro_sent: 0.9018000312260003
dev_recall_macro_sent: 0.9533648767278192
dev_f-score_macro_sent: 0.9242588214574934
dev_precision_micro_sent: 0.9486153846153846
dev_recall_micro_sent: 0.9486153846153846
dev_f-score_micro_sent: 0.9486153846153846
dev_label=O_precision_tok: 0.994629179899122
dev_label=O_recall_tok: 0.9961411632638743
dev_label=O_f-score_tok: 0.9953845974083639
dev_label=LOC_precision_tok: 0.9362208472156116
dev_label=LOC_recall_tok: 0.9393505253104107
dev_label=LOC_f-score_tok: 0.9377830750893922
dev_label=MISC_precision_tok: 0.8010057471264368
dev_label=MISC_recall_tok: 0.8793375394321766
dev_label=MISC_f-score_tok: 0.8383458646616542
dev_label=ORG_precision_tok: 0.9394453876627051
dev_label=ORG_recall_tok: 0.7934990439770554
dev_label=ORG_f-score_tok: 0.8603265094584087
dev_label=PER_precision_tok: 0.9447834045149481
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9637466936362221
dev_precision_macro_tok: 0.9232169132837648
dev_recall_macro_tok: 0.9183630186393202
dev_f-score_macro_tok: 0.9191173480508082
dev_precision_micro_tok: 0.9819126981036564
dev_recall_micro_tok: 0.9819126981036564
dev_f-score_micro_tok: 0.9819126981036564
dev_time: 14.957923650741577
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8136    0.9612    0.8813       645
           1     0.9900    0.9455    0.9672      2605

   micro avg     0.9486    0.9486    0.9486      3250
   macro avg     0.9018    0.9534    0.9243      3250
weighted avg     0.9550    0.9486    0.9502      3250

F1-macro sent:  0.9242588214574934
F1-micro sent:  0.9486153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9961    0.9954     42759
         LOC     0.9362    0.9394    0.9378      2094
        MISC     0.8010    0.8793    0.8383      1268
         ORG     0.9394    0.7935    0.8603      2092
         PER     0.9448    0.9835    0.9637      3149

   micro avg     0.9819    0.9819    0.9819     51362
   macro avg     0.9232    0.9184    0.9191     51362
weighted avg     0.9822    0.9819    0.9817     51362

F1-macro tok:  0.9191173480508082
F1-micro tok:  0.9819126981036564
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 348764.2832336426
train_cost_avg: 24.83899175512019
train_count_sent: 14041.0
train_total_correct_sent: 13384.0
train_accuracy_sent: 0.9532084609358308
train_count_tok: 203621.0
train_total_correct_tok: 199219.0
train_accuracy_tok: 0.9783814046684772
train_label=0_precision_sent: 0.8827328348062542
train_label=0_recall_sent: 0.8927466483327604
train_label=0_f-score_sent: 0.8877115023072979
train_label=1_precision_sent: 0.9718893594017479
train_label=1_recall_sent: 0.96900826446281
train_label=1_f-score_sent: 0.9704466735639423
train_precision_macro_sent: 0.9273110971040011
train_recall_macro_sent: 0.9308774563977852
train_f-score_macro_sent: 0.9290790879356201
train_precision_micro_sent: 0.9532084609358308
train_recall_micro_sent: 0.9532084609358308
train_f-score_micro_sent: 0.9532084609358308
train_label=O_precision_tok: 0.9929716334182938
train_label=O_recall_tok: 0.9947575746853955
train_label=O_f-score_tok: 0.9938638017327469
train_label=LOC_precision_tok: 0.9116723054615756
train_label=LOC_recall_tok: 0.9093648306616849
train_label=LOC_f-score_tok: 0.910517106136487
train_label=MISC_precision_tok: 0.8470969234328013
train_label=MISC_recall_tok: 0.7973002394948835
train_label=MISC_f-score_tok: 0.8214445939883356
train_label=ORG_precision_tok: 0.8731426260992621
train_label=ORG_recall_tok: 0.8616458852867831
train_label=ORG_f-score_tok: 0.867356160257054
train_label=PER_precision_tok: 0.950115596656589
train_label=PER_recall_tok: 0.9601905104241553
train_label=PER_f-score_tok: 0.9551264860999374
train_precision_macro_tok: 0.9149998170137044
train_recall_macro_tok: 0.9046518081105805
train_f-score_macro_tok: 0.9096616296429121
train_precision_micro_tok: 0.9783814046684772
train_recall_micro_tok: 0.9783814046684772
train_f-score_micro_tok: 0.9783814046684772
train_time: 155.5191719532013
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8827    0.8927    0.8877      2909
           1     0.9719    0.9690    0.9704     11132

   micro avg     0.9532    0.9532    0.9532     14041
   macro avg     0.9273    0.9309    0.9291     14041
weighted avg     0.9534    0.9532    0.9533     14041

F1-macro sent:  0.9290790879356201
F1-micro sent:  0.9532084609358308
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9930    0.9948    0.9939    169578
         LOC     0.9117    0.9094    0.9105      8297
        MISC     0.8471    0.7973    0.8214      4593
         ORG     0.8731    0.8616    0.8674     10025
         PER     0.9501    0.9602    0.9551     11128

   micro avg     0.9784    0.9784    0.9784    203621
   macro avg     0.9150    0.9047    0.9097    203621
weighted avg     0.9781    0.9784    0.9782    203621

F1-macro tok:  0.9096616296429121
F1-micro tok:  0.9783814046684772
**************************************************
dev_cost_sum: 91594.35619354248
dev_cost_avg: 28.1828788287823
dev_count_sent: 3250.0
dev_total_correct_sent: 3155.0
dev_accuracy_sent: 0.9707692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50586.0
dev_accuracy_tok: 0.9848915540672092
dev_label=0_precision_sent: 0.9270186335403726
dev_label=0_recall_sent: 0.9255813953488372
dev_label=0_f-score_sent: 0.9262994569433669
dev_label=1_precision_sent: 0.9815809669992326
dev_label=1_recall_sent: 0.981957773512476
dev_label=1_f-score_sent: 0.9817693341009404
dev_precision_macro_sent: 0.9542998002698027
dev_recall_macro_sent: 0.9537695844306566
dev_f-score_macro_sent: 0.9540343955221536
dev_precision_micro_sent: 0.9707692307692307
dev_recall_micro_sent: 0.9707692307692307
dev_f-score_micro_sent: 0.9707692307692307
dev_label=O_precision_tok: 0.9938710353988488
dev_label=O_recall_tok: 0.9974040552866064
dev_label=O_f-score_tok: 0.9956344111124081
dev_label=LOC_precision_tok: 0.9449497367161321
dev_label=LOC_recall_tok: 0.9426934097421203
dev_label=LOC_f-score_tok: 0.9438202247191012
dev_label=MISC_precision_tok: 0.8898233809924306
dev_label=MISC_recall_tok: 0.8343848580441641
dev_label=MISC_f-score_tok: 0.8612128612128613
dev_label=ORG_precision_tok: 0.9238191975622143
dev_label=ORG_recall_tok: 0.8695028680688337
dev_label=ORG_f-score_tok: 0.895838463432652
dev_label=PER_precision_tok: 0.9634831460674157
dev_label=PER_recall_tok: 0.9803112099079073
dev_label=PER_f-score_tok: 0.9718243349598614
dev_precision_macro_tok: 0.9431892993474085
dev_recall_macro_tok: 0.9248592802099264
dev_f-score_macro_tok: 0.933666059087377
dev_precision_micro_tok: 0.9848915540672092
dev_recall_micro_tok: 0.9848915540672092
dev_f-score_micro_tok: 0.9848915540672092
dev_time: 15.145957231521606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9270    0.9256    0.9263       645
           1     0.9816    0.9820    0.9818      2605

   micro avg     0.9708    0.9708    0.9708      3250
   macro avg     0.9543    0.9538    0.9540      3250
weighted avg     0.9708    0.9708    0.9708      3250

F1-macro sent:  0.9540343955221536
F1-micro sent:  0.9707692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9939    0.9974    0.9956     42759
         LOC     0.9449    0.9427    0.9438      2094
        MISC     0.8898    0.8344    0.8612      1268
         ORG     0.9238    0.8695    0.8958      2092
         PER     0.9635    0.9803    0.9718      3149

   micro avg     0.9849    0.9849    0.9849     51362
   macro avg     0.9432    0.9249    0.9337     51362
weighted avg     0.9846    0.9849    0.9847     51362

F1-macro tok:  0.933666059087377
F1-micro tok:  0.9848915540672092
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 343031.1880187988
train_cost_avg: 24.43068072208524
train_count_sent: 14041.0
train_total_correct_sent: 13470.0
train_accuracy_sent: 0.9593333808133324
train_count_tok: 203621.0
train_total_correct_tok: 199598.0
train_accuracy_tok: 0.9802427058112867
train_label=0_precision_sent: 0.9076011157601116
train_label=0_recall_sent: 0.8948092127878996
train_label=0_f-score_sent: 0.901159771507703
train_label=1_precision_sent: 0.9726125481070438
train_label=1_recall_sent: 0.976194753862738
train_label=1_f-score_sent: 0.9744003586639767
train_precision_macro_sent: 0.9401068319335777
train_recall_macro_sent: 0.9355019833253189
train_f-score_macro_sent: 0.9377800650858399
train_precision_micro_sent: 0.9593333808133324
train_recall_micro_sent: 0.9593333808133324
train_f-score_micro_sent: 0.9593333808133324
train_label=O_precision_tok: 0.9936360478738748
train_label=O_recall_tok: 0.9953059948814115
train_label=O_f-score_tok: 0.9944703203207627
train_label=LOC_precision_tok: 0.9166666666666666
train_label=LOC_recall_tok: 0.9200915993732675
train_label=LOC_f-score_tok: 0.918375939849624
train_label=MISC_precision_tok: 0.8566497929130235
train_label=MISC_recall_tok: 0.8105813193990856
train_label=MISC_f-score_tok: 0.832979080434053
train_label=ORG_precision_tok: 0.8867943650552346
train_label=ORG_recall_tok: 0.8728179551122195
train_label=ORG_f-score_tok: 0.8797506535290569
train_label=PER_precision_tok: 0.9547115984666131
train_label=PER_recall_tok: 0.9623472322070453
train_label=PER_f-score_tok: 0.958514208995301
train_precision_macro_tok: 0.9216916941950826
train_recall_macro_tok: 0.9122288201946059
train_f-score_macro_tok: 0.9168180406257596
train_precision_micro_tok: 0.9802427058112867
train_recall_micro_tok: 0.9802427058112867
train_f-score_micro_tok: 0.9802427058112867
train_time: 155.8849959373474
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9076    0.8948    0.9012      2909
           1     0.9726    0.9762    0.9744     11132

   micro avg     0.9593    0.9593    0.9593     14041
   macro avg     0.9401    0.9355    0.9378     14041
weighted avg     0.9591    0.9593    0.9592     14041

F1-macro sent:  0.9377800650858399
F1-micro sent:  0.9593333808133324
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9953    0.9945    169578
         LOC     0.9167    0.9201    0.9184      8297
        MISC     0.8566    0.8106    0.8330      4593
         ORG     0.8868    0.8728    0.8798     10025
         PER     0.9547    0.9623    0.9585     11128

   micro avg     0.9802    0.9802    0.9802    203621
   macro avg     0.9217    0.9122    0.9168    203621
weighted avg     0.9800    0.9802    0.9801    203621

F1-macro tok:  0.9168180406257596
F1-micro tok:  0.9802427058112867
**************************************************
dev_cost_sum: 90548.7628326416
dev_cost_avg: 27.861157794658954
dev_count_sent: 3250.0
dev_total_correct_sent: 3143.0
dev_accuracy_sent: 0.9670769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50638.0
dev_accuracy_tok: 0.9859039757018808
dev_label=0_precision_sent: 0.8715469613259669
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9218407596785975
dev_label=1_precision_sent: 0.9944576405384006
dev_label=1_recall_sent: 0.9642994241842611
dev_label=1_f-score_sent: 0.979146365230949
dev_precision_macro_sent: 0.9330023009321837
dev_recall_macro_sent: 0.971296998913836
dev_f-score_macro_sent: 0.9504935624547732
dev_precision_micro_sent: 0.9670769230769231
dev_recall_micro_sent: 0.9670769230769231
dev_f-score_micro_sent: 0.9670769230769231
dev_label=O_precision_tok: 0.9944733344215656
dev_label=O_recall_tok: 0.9973572815079866
dev_label=O_f-score_tok: 0.9959132201489922
dev_label=LOC_precision_tok: 0.9624320316361838
dev_label=LOC_recall_tok: 0.9297994269340975
dev_label=LOC_f-score_tok: 0.9458343453971338
dev_label=MISC_precision_tok: 0.905852417302799
dev_label=MISC_recall_tok: 0.8422712933753943
dev_label=MISC_f-score_tok: 0.8729055986922762
dev_label=ORG_precision_tok: 0.9108003857280618
dev_label=ORG_recall_tok: 0.902963671128107
dev_label=ORG_f-score_tok: 0.9068650984157465
dev_label=PER_precision_tok: 0.9640961598501405
dev_label=PER_recall_tok: 0.9806287710384249
dev_label=PER_f-score_tok: 0.9722921914357683
dev_precision_macro_tok: 0.9475308657877501
dev_recall_macro_tok: 0.930604088796802
dev_f-score_macro_tok: 0.9387620908179833
dev_precision_micro_tok: 0.9859039757018808
dev_recall_micro_tok: 0.9859039757018808
dev_f-score_micro_tok: 0.9859039757018808
dev_time: 15.024716854095459
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8715    0.9783    0.9218       645
           1     0.9945    0.9643    0.9791      2605

   micro avg     0.9671    0.9671    0.9671      3250
   macro avg     0.9330    0.9713    0.9505      3250
weighted avg     0.9701    0.9671    0.9678      3250

F1-macro sent:  0.9504935624547732
F1-micro sent:  0.9670769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9974    0.9959     42759
         LOC     0.9624    0.9298    0.9458      2094
        MISC     0.9059    0.8423    0.8729      1268
         ORG     0.9108    0.9030    0.9069      2092
         PER     0.9641    0.9806    0.9723      3149

   micro avg     0.9859    0.9859    0.9859     51362
   macro avg     0.9475    0.9306    0.9388     51362
weighted avg     0.9857    0.9859    0.9858     51362

F1-macro tok:  0.9387620908179833
F1-micro tok:  0.9859039757018808
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 338236.79302978516
train_cost_avg: 24.089223917796822
train_count_sent: 14041.0
train_total_correct_sent: 13520.0
train_accuracy_sent: 0.9628943807421124
train_count_tok: 203621.0
train_total_correct_tok: 200027.0
train_accuracy_tok: 0.9823495611945723
train_label=0_precision_sent: 0.9134349030470914
train_label=0_recall_sent: 0.9068408387762118
train_label=0_f-score_sent: 0.910125927203726
train_label=1_precision_sent: 0.975701604949341
train_label=1_recall_sent: 0.9775422206252246
train_label=1_f-score_sent: 0.9766210455463316
train_precision_macro_sent: 0.9445682539982162
train_recall_macro_sent: 0.9421915297007182
train_f-score_macro_sent: 0.9433734863750287
train_precision_micro_sent: 0.9628943807421124
train_recall_micro_sent: 0.9628943807421124
train_f-score_micro_sent: 0.9628943807421124
train_label=O_precision_tok: 0.9943403671399714
train_label=O_recall_tok: 0.9956362263972921
train_label=O_f-score_tok: 0.9949878748412533
train_label=LOC_precision_tok: 0.9219183034100494
train_label=LOC_recall_tok: 0.9221405327226708
train_label=LOC_f-score_tok: 0.9220294046758255
train_label=MISC_precision_tok: 0.8674807779285392
train_label=MISC_recall_tok: 0.8351839756150664
train_label=MISC_f-score_tok: 0.8510260676650028
train_label=ORG_precision_tok: 0.9006769728200464
train_label=ORG_recall_tok: 0.8891770573566085
train_label=ORG_f-score_tok: 0.894890071277984
train_label=PER_precision_tok: 0.9628704034273474
train_label=PER_recall_tok: 0.9694464414090582
train_label=PER_f-score_tok: 0.9661472326706072
train_precision_macro_tok: 0.9294573649451907
train_recall_macro_tok: 0.9223168467001391
train_f-score_macro_tok: 0.9258161302261346
train_precision_micro_tok: 0.9823495611945723
train_recall_micro_tok: 0.9823495611945723
train_f-score_micro_tok: 0.9823495611945723
train_time: 155.2015404701233
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9134    0.9068    0.9101      2909
           1     0.9757    0.9775    0.9766     11132

   micro avg     0.9629    0.9629    0.9629     14041
   macro avg     0.9446    0.9422    0.9434     14041
weighted avg     0.9628    0.9629    0.9628     14041

F1-macro sent:  0.9433734863750287
F1-micro sent:  0.9628943807421124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9943    0.9956    0.9950    169578
         LOC     0.9219    0.9221    0.9220      8297
        MISC     0.8675    0.8352    0.8510      4593
         ORG     0.9007    0.8892    0.8949     10025
         PER     0.9629    0.9694    0.9661     11128

   micro avg     0.9823    0.9823    0.9823    203621
   macro avg     0.9295    0.9223    0.9258    203621
weighted avg     0.9822    0.9823    0.9823    203621

F1-macro tok:  0.9258161302261346
F1-micro tok:  0.9823495611945723
**************************************************
dev_cost_sum: 89755.94603729248
dev_cost_avg: 27.617214165320764
dev_count_sent: 3250.0
dev_total_correct_sent: 3112.0
dev_accuracy_sent: 0.9575384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50655.0
dev_accuracy_tok: 0.986234959697831
dev_label=0_precision_sent: 0.9903288201160542
dev_label=0_recall_sent: 0.7937984496124031
dev_label=0_f-score_sent: 0.8812392426850258
dev_label=1_precision_sent: 0.951335528723015
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9741476208317722
dev_precision_macro_sent: 0.9708321744195345
dev_recall_macro_sent: 0.895939531907929
dev_f-score_macro_sent: 0.927693431758399
dev_precision_micro_sent: 0.9575384615384616
dev_recall_micro_sent: 0.9575384615384616
dev_f-score_micro_sent: 0.9575384615384616
dev_label=O_precision_tok: 0.9963053035263305
dev_label=O_recall_tok: 0.9964218059355925
dev_label=O_f-score_tok: 0.9963635513253744
dev_label=LOC_precision_tok: 0.945480631276901
dev_label=LOC_recall_tok: 0.9441260744985673
dev_label=LOC_f-score_tok: 0.9448028673835125
dev_label=MISC_precision_tok: 0.8986099754701553
dev_label=MISC_recall_tok: 0.8667192429022083
dev_label=MISC_f-score_tok: 0.8823765556001605
dev_label=ORG_precision_tok: 0.9164631167562286
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.9064991543851172
dev_label=PER_precision_tok: 0.9567500772320049
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9699342311305982
dev_precision_macro_tok: 0.9427218208523241
dev_recall_macro_tok: 0.9375006933075959
dev_f-score_macro_tok: 0.9399952719649527
dev_precision_micro_tok: 0.986234959697831
dev_recall_micro_tok: 0.986234959697831
dev_f-score_micro_tok: 0.986234959697831
dev_time: 14.95624566078186
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9903    0.7938    0.8812       645
           1     0.9513    0.9981    0.9741      2605

   micro avg     0.9575    0.9575    0.9575      3250
   macro avg     0.9708    0.8959    0.9277      3250
weighted avg     0.9591    0.9575    0.9557      3250

F1-macro sent:  0.927693431758399
F1-micro sent:  0.9575384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9964    0.9964     42759
         LOC     0.9455    0.9441    0.9448      2094
        MISC     0.8986    0.8667    0.8824      1268
         ORG     0.9165    0.8967    0.9065      2092
         PER     0.9568    0.9835    0.9699      3149

   micro avg     0.9862    0.9862    0.9862     51362
   macro avg     0.9427    0.9375    0.9400     51362
weighted avg     0.9861    0.9862    0.9862     51362

F1-macro tok:  0.9399952719649527
F1-micro tok:  0.986234959697831
**************************************************
Best epoch: 5
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 334208.7773742676
train_cost_avg: 23.802348648548364
train_count_sent: 14041.0
train_total_correct_sent: 13549.0
train_accuracy_sent: 0.9649597607008048
train_count_tok: 203621.0
train_total_correct_tok: 200246.0
train_accuracy_tok: 0.983425088767858
train_label=0_precision_sent: 0.912035458574838
train_label=0_recall_sent: 0.9195599862495702
train_label=0_f-score_sent: 0.9157822663471413
train_label=1_precision_sent: 0.9789341015484335
train_label=1_recall_sent: 0.9768235716852318
train_label=1_f-score_sent: 0.9778776978417265
train_precision_macro_sent: 0.9454847800616357
train_recall_macro_sent: 0.948191778967401
train_f-score_macro_sent: 0.9468299820944339
train_precision_micro_sent: 0.9649597607008048
train_recall_micro_sent: 0.9649597607008048
train_f-score_micro_sent: 0.9649597607008048
train_label=O_precision_tok: 0.9947589098532494
train_label=O_recall_tok: 0.996131573671113
train_label=O_f-score_tok: 0.9954447685553492
train_label=LOC_precision_tok: 0.9288303528274529
train_label=LOC_recall_tok: 0.9264794504037603
train_label=LOC_f-score_tok: 0.9276534121764315
train_label=MISC_precision_tok: 0.8794551645856981
train_label=MISC_recall_tok: 0.8434574352275201
train_label=MISC_f-score_tok: 0.8610802400533453
train_label=ORG_precision_tok: 0.903349089811928
train_label=ORG_recall_tok: 0.8959600997506234
train_label=ORG_f-score_tok: 0.899639423076923
train_label=PER_precision_tok: 0.9638801966919982
train_label=PER_recall_tok: 0.9688173975557153
train_label=PER_f-score_tok: 0.9663424909245731
train_precision_macro_tok: 0.9340547427540653
train_recall_macro_tok: 0.9261691913217465
train_f-score_macro_tok: 0.9300320669573244
train_precision_micro_tok: 0.983425088767858
train_recall_micro_tok: 0.983425088767858
train_f-score_micro_tok: 0.983425088767858
train_time: 155.77514791488647
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9120    0.9196    0.9158      2909
           1     0.9789    0.9768    0.9779     11132

   micro avg     0.9650    0.9650    0.9650     14041
   macro avg     0.9455    0.9482    0.9468     14041
weighted avg     0.9651    0.9650    0.9650     14041

F1-macro sent:  0.9468299820944339
F1-micro sent:  0.9649597607008048
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9948    0.9961    0.9954    169578
         LOC     0.9288    0.9265    0.9277      8297
        MISC     0.8795    0.8435    0.8611      4593
         ORG     0.9033    0.8960    0.8996     10025
         PER     0.9639    0.9688    0.9663     11128

   micro avg     0.9834    0.9834    0.9834    203621
   macro avg     0.9341    0.9262    0.9300    203621
weighted avg     0.9833    0.9834    0.9833    203621

F1-macro tok:  0.9300320669573244
F1-micro tok:  0.983425088767858
**************************************************
dev_cost_sum: 88859.4663696289
dev_cost_avg: 27.341374267578125
dev_count_sent: 3250.0
dev_total_correct_sent: 3193.0
dev_accuracy_sent: 0.9824615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50677.0
dev_accuracy_tok: 0.9866632919278844
dev_label=0_precision_sent: 0.959375
dev_label=0_recall_sent: 0.951937984496124
dev_label=0_f-score_sent: 0.9556420233463035
dev_label=1_precision_sent: 0.9881226053639847
dev_label=1_recall_sent: 0.9900191938579654
dev_label=1_f-score_sent: 0.9890699904122723
dev_precision_macro_sent: 0.9737488026819923
dev_recall_macro_sent: 0.9709785891770447
dev_f-score_macro_sent: 0.9723560068792879
dev_precision_micro_sent: 0.9824615384615385
dev_recall_micro_sent: 0.9824615384615385
dev_f-score_micro_sent: 0.9824615384615385
dev_label=O_precision_tok: 0.9954946542789113
dev_label=O_recall_tok: 0.9973338946186767
dev_label=O_f-score_tok: 0.9964134257041718
dev_label=LOC_precision_tok: 0.9617083946980854
dev_label=LOC_recall_tok: 0.9355300859598854
dev_label=LOC_f-score_tok: 0.9484386347131445
dev_label=MISC_precision_tok: 0.8670253651037664
dev_label=MISC_recall_tok: 0.889589905362776
dev_label=MISC_f-score_tok: 0.8781627092253795
dev_label=ORG_precision_tok: 0.9344758064516129
dev_label=ORG_recall_tok: 0.8862332695984704
dev_label=ORG_f-score_tok: 0.9097154072620216
dev_label=PER_precision_tok: 0.9653341661461586
dev_label=PER_recall_tok: 0.9815814544299778
dev_label=PER_f-score_tok: 0.9733900173201071
dev_precision_macro_tok: 0.9448076773357069
dev_recall_macro_tok: 0.9380537219939573
dev_f-score_macro_tok: 0.941224038844965
dev_precision_micro_tok: 0.9866632919278844
dev_recall_micro_tok: 0.9866632919278844
dev_f-score_micro_tok: 0.9866632919278844
dev_time: 15.223354578018188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9594    0.9519    0.9556       645
           1     0.9881    0.9900    0.9891      2605

   micro avg     0.9825    0.9825    0.9825      3250
   macro avg     0.9737    0.9710    0.9724      3250
weighted avg     0.9824    0.9825    0.9824      3250

F1-macro sent:  0.9723560068792879
F1-micro sent:  0.9824615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9973    0.9964     42759
         LOC     0.9617    0.9355    0.9484      2094
        MISC     0.8670    0.8896    0.8782      1268
         ORG     0.9345    0.8862    0.9097      2092
         PER     0.9653    0.9816    0.9734      3149

   micro avg     0.9867    0.9867    0.9867     51362
   macro avg     0.9448    0.9381    0.9412     51362
weighted avg     0.9866    0.9867    0.9866     51362

F1-macro tok:  0.941224038844965
F1-micro tok:  0.9866632919278844
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 330566.80993652344
train_cost_avg: 23.542967732819843
train_count_sent: 14041.0
train_total_correct_sent: 13593.0
train_accuracy_sent: 0.9680934406381312
train_count_tok: 203621.0
train_total_correct_tok: 200447.0
train_accuracy_tok: 0.9844122168145721
train_label=0_precision_sent: 0.9256312694569353
train_label=0_recall_sent: 0.9199037469920935
train_label=0_f-score_sent: 0.9227586206896553
train_label=1_precision_sent: 0.9791031390134529
train_label=1_recall_sent: 0.9806863097376931
train_label=1_f-score_sent: 0.9798940849115878
train_precision_macro_sent: 0.952367204235194
train_recall_macro_sent: 0.9502950283648933
train_f-score_macro_sent: 0.9513263528006215
train_precision_micro_sent: 0.9680934406381312
train_recall_micro_sent: 0.9680934406381312
train_f-score_micro_sent: 0.9680934406381312
train_label=O_precision_tok: 0.9950335807705903
train_label=O_recall_tok: 0.9959841488872377
train_label=O_f-score_tok: 0.9955086379148762
train_label=LOC_precision_tok: 0.9353983367482223
train_label=LOC_recall_tok: 0.9353983367482223
train_label=LOC_f-score_tok: 0.9353983367482223
train_label=MISC_precision_tok: 0.8846067162497183
train_label=MISC_recall_tok: 0.8545612889179186
train_label=MISC_f-score_tok: 0.869324473975637
train_label=ORG_precision_tok: 0.9105453813644596
train_label=ORG_recall_tok: 0.902643391521197
train_label=ORG_f-score_tok: 0.9065771677603567
train_label=PER_precision_tok: 0.9648496743688108
train_label=PER_recall_tok: 0.9718727534148095
train_label=PER_f-score_tok: 0.9683484801002821
train_precision_macro_tok: 0.9380867379003602
train_recall_macro_tok: 0.9320919838978771
train_f-score_macro_tok: 0.9350314192998749
train_precision_micro_tok: 0.9844122168145721
train_recall_micro_tok: 0.9844122168145721
train_f-score_micro_tok: 0.9844122168145721
train_time: 156.1265971660614
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9256    0.9199    0.9228      2909
           1     0.9791    0.9807    0.9799     11132

   micro avg     0.9681    0.9681    0.9681     14041
   macro avg     0.9524    0.9503    0.9513     14041
weighted avg     0.9680    0.9681    0.9681     14041

F1-macro sent:  0.9513263528006215
F1-micro sent:  0.9680934406381312
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9950    0.9960    0.9955    169578
         LOC     0.9354    0.9354    0.9354      8297
        MISC     0.8846    0.8546    0.8693      4593
         ORG     0.9105    0.9026    0.9066     10025
         PER     0.9648    0.9719    0.9683     11128

   micro avg     0.9844    0.9844    0.9844    203621
   macro avg     0.9381    0.9321    0.9350    203621
weighted avg     0.9843    0.9844    0.9844    203621

F1-macro tok:  0.9350314192998749
F1-micro tok:  0.9844122168145721
**************************************************
dev_cost_sum: 88225.0888671875
dev_cost_avg: 27.146181189903846
dev_count_sent: 3250.0
dev_total_correct_sent: 3168.0
dev_accuracy_sent: 0.9747692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50721.0
dev_accuracy_tok: 0.9875199563879912
dev_label=0_precision_sent: 0.9861830742659758
dev_label=0_recall_sent: 0.8852713178294573
dev_label=0_f-score_sent: 0.9330065359477124
dev_label=1_precision_sent: 0.9722950205915387
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9844579226686884
dev_precision_macro_sent: 0.9792390474287573
dev_recall_macro_sent: 0.9411001502774926
dev_f-score_macro_sent: 0.9587322293082003
dev_precision_micro_sent: 0.9747692307692307
dev_recall_micro_sent: 0.9747692307692307
dev_f-score_micro_sent: 0.9747692307692307
dev_label=O_precision_tok: 0.9964682493275641
dev_label=O_recall_tok: 0.9963750321569728
dev_label=O_f-score_tok: 0.9964216385621069
dev_label=LOC_precision_tok: 0.9528571428571428
dev_label=LOC_recall_tok: 0.9555873925501432
dev_label=LOC_f-score_tok: 0.9542203147353362
dev_label=MISC_precision_tok: 0.8766485647788984
dev_label=MISC_recall_tok: 0.8911671924290221
dev_label=MISC_f-score_tok: 0.8838482596793118
dev_label=ORG_precision_tok: 0.9301075268817204
dev_label=ORG_recall_tok: 0.9096558317399618
dev_label=ORG_f-score_tok: 0.9197680038666023
dev_label=PER_precision_tok: 0.9719419924337958
dev_label=PER_recall_tok: 0.9790409653858367
dev_label=PER_f-score_tok: 0.9754785635184307
dev_precision_macro_tok: 0.9456046952558242
dev_recall_macro_tok: 0.9463652828523873
dev_f-score_macro_tok: 0.9459473560723577
dev_precision_micro_tok: 0.9875199563879912
dev_recall_micro_tok: 0.9875199563879912
dev_f-score_micro_tok: 0.9875199563879912
dev_time: 15.175222158432007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9862    0.8853    0.9330       645
           1     0.9723    0.9969    0.9845      2605

   micro avg     0.9748    0.9748    0.9748      3250
   macro avg     0.9792    0.9411    0.9587      3250
weighted avg     0.9751    0.9748    0.9742      3250

F1-macro sent:  0.9587322293082003
F1-micro sent:  0.9747692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9964    0.9964     42759
         LOC     0.9529    0.9556    0.9542      2094
        MISC     0.8766    0.8912    0.8838      1268
         ORG     0.9301    0.9097    0.9198      2092
         PER     0.9719    0.9790    0.9755      3149

   micro avg     0.9875    0.9875    0.9875     51362
   macro avg     0.9456    0.9464    0.9459     51362
weighted avg     0.9875    0.9875    0.9875     51362

F1-macro tok:  0.9459473560723577
F1-micro tok:  0.9875199563879912
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 327275.8569641113
train_cost_avg: 23.30858606681229
train_count_sent: 14041.0
train_total_correct_sent: 13716.0
train_accuracy_sent: 0.97685350046293
train_count_tok: 203621.0
train_total_correct_tok: 200661.0
train_accuracy_tok: 0.9854631889638102
train_label=0_precision_sent: 0.9461325966850829
train_label=0_recall_sent: 0.9419044345135785
train_label=0_f-score_sent: 0.9440137812230834
train_label=1_precision_sent: 0.9848362494392104
train_label=1_recall_sent: 0.9859863456701401
train_label=1_f-score_sent: 0.9854109619787225
train_precision_macro_sent: 0.9654844230621467
train_recall_macro_sent: 0.9639453900918593
train_f-score_macro_sent: 0.964712371600903
train_precision_micro_sent: 0.97685350046293
train_recall_micro_sent: 0.97685350046293
train_f-score_micro_sent: 0.97685350046293
train_label=O_precision_tok: 0.9953692520694023
train_label=O_recall_tok: 0.9962907924376982
train_label=O_f-score_tok: 0.9958298090553558
train_label=LOC_precision_tok: 0.9398287712528639
train_label=LOC_recall_tok: 0.9393756779558877
train_label=LOC_f-score_tok: 0.9396021699819169
train_label=MISC_precision_tok: 0.8921524663677131
train_label=MISC_recall_tok: 0.8663183104724581
train_label=MISC_f-score_tok: 0.8790456202363857
train_label=ORG_precision_tok: 0.9179899497487437
train_label=ORG_recall_tok: 0.9111221945137157
train_label=ORG_f-score_tok: 0.9145431789737171
train_label=PER_precision_tok: 0.9661986944469284
train_label=PER_recall_tok: 0.9709741193386053
train_label=PER_f-score_tok: 0.9685805208193269
train_precision_macro_tok: 0.9423078267771302
train_recall_macro_tok: 0.936816218943673
train_f-score_macro_tok: 0.9395202598133403
train_precision_micro_tok: 0.9854631889638102
train_recall_micro_tok: 0.9854631889638102
train_f-score_micro_tok: 0.9854631889638102
train_time: 155.7766091823578
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9461    0.9419    0.9440      2909
           1     0.9848    0.9860    0.9854     11132

   micro avg     0.9769    0.9769    0.9769     14041
   macro avg     0.9655    0.9639    0.9647     14041
weighted avg     0.9768    0.9769    0.9768     14041

F1-macro sent:  0.964712371600903
F1-micro sent:  0.97685350046293
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9963    0.9958    169578
         LOC     0.9398    0.9394    0.9396      8297
        MISC     0.8922    0.8663    0.8790      4593
         ORG     0.9180    0.9111    0.9145     10025
         PER     0.9662    0.9710    0.9686     11128

   micro avg     0.9855    0.9855    0.9855    203621
   macro avg     0.9423    0.9368    0.9395    203621
weighted avg     0.9854    0.9855    0.9854    203621

F1-macro tok:  0.9395202598133403
F1-micro tok:  0.9854631889638102
**************************************************
dev_cost_sum: 87559.21240997314
dev_cost_avg: 26.941296126145584
dev_count_sent: 3250.0
dev_total_correct_sent: 3207.0
dev_accuracy_sent: 0.9867692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50727.0
dev_accuracy_tok: 0.9876367742689147
dev_label=0_precision_sent: 0.9717868338557993
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.9664848012470773
dev_label=1_precision_sent: 0.9904287901990811
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9917577151619705
dev_precision_macro_sent: 0.9811078120274402
dev_recall_macro_sent: 0.9771652606049785
dev_f-score_macro_sent: 0.9791212582045239
dev_precision_micro_sent: 0.9867692307692307
dev_recall_micro_sent: 0.9867692307692307
dev_f-score_micro_sent: 0.9867692307692307
dev_label=O_precision_tok: 0.9959356240218635
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9965408437536519
dev_label=LOC_precision_tok: 0.9571703561116458
dev_label=LOC_recall_tok: 0.9498567335243553
dev_label=LOC_f-score_tok: 0.9534995206136146
dev_label=MISC_precision_tok: 0.9087921117502055
dev_label=MISC_recall_tok: 0.8722397476340694
dev_label=MISC_f-score_tok: 0.8901408450704226
dev_label=ORG_precision_tok: 0.9236752552260573
dev_label=ORG_recall_tok: 0.9082217973231358
dev_label=ORG_f-score_tok: 0.91588334538443
dev_label=PER_precision_tok: 0.9674898405751797
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9751102709514807
dev_precision_macro_tok: 0.9506126375369904
dev_recall_macro_tok: 0.9420633553875613
dev_f-score_macro_tok: 0.9462349651547199
dev_precision_micro_tok: 0.9876367742689147
dev_recall_micro_tok: 0.9876367742689147
dev_f-score_micro_tok: 0.9876367742689147
dev_time: 15.12874722480774
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9718    0.9612    0.9665       645
           1     0.9904    0.9931    0.9918      2605

   micro avg     0.9868    0.9868    0.9868      3250
   macro avg     0.9811    0.9772    0.9791      3250
weighted avg     0.9867    0.9868    0.9867      3250

F1-macro sent:  0.9791212582045239
F1-micro sent:  0.9867692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9971    0.9965     42759
         LOC     0.9572    0.9499    0.9535      2094
        MISC     0.9088    0.8722    0.8901      1268
         ORG     0.9237    0.9082    0.9159      2092
         PER     0.9675    0.9829    0.9751      3149

   micro avg     0.9876    0.9876    0.9876     51362
   macro avg     0.9506    0.9421    0.9462     51362
weighted avg     0.9875    0.9876    0.9876     51362

F1-macro tok:  0.9462349651547199
F1-micro tok:  0.9876367742689147
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 324353.9477844238
train_cost_avg: 23.10048769919691
train_count_sent: 14041.0
train_total_correct_sent: 13677.0
train_accuracy_sent: 0.9740759205184816
train_count_tok: 203621.0
train_total_correct_tok: 200830.0
train_accuracy_tok: 0.9862931622966197
train_label=0_precision_sent: 0.9368348781325094
train_label=0_recall_sent: 0.9381230663458233
train_label=0_f-score_sent: 0.9374785297148747
train_label=1_precision_sent: 0.983824586628325
train_label=1_recall_sent: 0.9834710743801653
train_label=1_f-score_sent: 0.9836477987421385
train_precision_macro_sent: 0.9603297323804172
train_recall_macro_sent: 0.9607970703629943
train_f-score_macro_sent: 0.9605631642285066
train_precision_micro_sent: 0.9740759205184816
train_recall_micro_sent: 0.9740759205184816
train_f-score_micro_sent: 0.9740759205184816
train_label=O_precision_tok: 0.9957280569435278
train_label=O_recall_tok: 0.9965148781091887
train_label=O_f-score_tok: 0.9961213121518464
train_label=LOC_precision_tok: 0.9401514241076794
train_label=LOC_recall_tok: 0.9428709171989876
train_label=LOC_f-score_tok: 0.9415092068841017
train_label=MISC_precision_tok: 0.8970323741007195
train_label=MISC_recall_tok: 0.8687132593076421
train_label=MISC_f-score_tok: 0.8826457250304169
train_label=ORG_precision_tok: 0.9199158063546156
train_label=ORG_recall_tok: 0.9155112219451371
train_label=ORG_f-score_tok: 0.9177082291770823
train_label=PER_precision_tok: 0.9721401057063513
train_label=PER_recall_tok: 0.9751976994967649
train_label=PER_f-score_tok: 0.973666502175766
train_precision_macro_tok: 0.9449935534425787
train_recall_macro_tok: 0.9397615952115441
train_f-score_macro_tok: 0.9423301950838427
train_precision_micro_tok: 0.9862931622966197
train_recall_micro_tok: 0.9862931622966197
train_f-score_micro_tok: 0.9862931622966197
train_time: 154.82447934150696
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9368    0.9381    0.9375      2909
           1     0.9838    0.9835    0.9836     11132

   micro avg     0.9741    0.9741    0.9741     14041
   macro avg     0.9603    0.9608    0.9606     14041
weighted avg     0.9741    0.9741    0.9741     14041

F1-macro sent:  0.9605631642285066
F1-micro sent:  0.9740759205184816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9965    0.9961    169578
         LOC     0.9402    0.9429    0.9415      8297
        MISC     0.8970    0.8687    0.8826      4593
         ORG     0.9199    0.9155    0.9177     10025
         PER     0.9721    0.9752    0.9737     11128

   micro avg     0.9863    0.9863    0.9863    203621
   macro avg     0.9450    0.9398    0.9423    203621
weighted avg     0.9862    0.9863    0.9862    203621

F1-macro tok:  0.9423301950838427
F1-micro tok:  0.9862931622966197
**************************************************
dev_cost_sum: 87107.50552368164
dev_cost_avg: 26.802309391902043
dev_count_sent: 3250.0
dev_total_correct_sent: 3203.0
dev_accuracy_sent: 0.9855384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50716.0
dev_accuracy_tok: 0.987422608153888
dev_label=0_precision_sent: 0.953030303030303
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.963984674329502
dev_label=1_precision_sent: 0.9938223938223938
dev_label=1_recall_sent: 0.9880998080614204
dev_label=1_f-score_sent: 0.9909528392685275
dev_precision_macro_sent: 0.9734263484263483
dev_recall_macro_sent: 0.9816468032555163
dev_f-score_macro_sent: 0.9774687567990148
dev_precision_micro_sent: 0.9855384615384616
dev_recall_micro_sent: 0.9855384615384616
dev_f-score_micro_sent: 0.9855384615384616
dev_label=O_precision_tok: 0.9958420929689324
dev_label=O_recall_tok: 0.9970298650576487
dev_label=O_f-score_tok: 0.9964356250511283
dev_label=LOC_precision_tok: 0.9428035630567276
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9515022474568252
dev_label=MISC_precision_tok: 0.9039735099337748
dev_label=MISC_recall_tok: 0.861198738170347
dev_label=MISC_f-score_tok: 0.8820678513731824
dev_label=ORG_precision_tok: 0.9281875915974597
dev_label=ORG_recall_tok: 0.9082217973231358
dev_label=ORG_f-score_tok: 0.9180961584923895
dev_label=PER_precision_tok: 0.9737673830594185
dev_label=PER_recall_tok: 0.9784058431248015
dev_label=PER_f-score_tok: 0.9760811024869317
dev_precision_macro_tok: 0.9489148281232627
dev_recall_macro_tok: 0.9410438370828466
dev_f-score_macro_tok: 0.9448365969720914
dev_precision_micro_tok: 0.987422608153888
dev_recall_micro_tok: 0.987422608153888
dev_f-score_micro_tok: 0.987422608153888
dev_time: 15.159529447555542
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9530    0.9752    0.9640       645
           1     0.9938    0.9881    0.9910      2605

   micro avg     0.9855    0.9855    0.9855      3250
   macro avg     0.9734    0.9816    0.9775      3250
weighted avg     0.9857    0.9855    0.9856      3250

F1-macro sent:  0.9774687567990148
F1-micro sent:  0.9855384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9970    0.9964     42759
         LOC     0.9428    0.9604    0.9515      2094
        MISC     0.9040    0.8612    0.8821      1268
         ORG     0.9282    0.9082    0.9181      2092
         PER     0.9738    0.9784    0.9761      3149

   micro avg     0.9874    0.9874    0.9874     51362
   macro avg     0.9489    0.9410    0.9448     51362
weighted avg     0.9873    0.9874    0.9873     51362

F1-macro tok:  0.9448365969720914
F1-micro tok:  0.987422608153888
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 321682.4888000488
train_cost_avg: 22.91022639413495
train_count_sent: 14041.0
train_total_correct_sent: 13693.0
train_accuracy_sent: 0.9752154404956912
train_count_tok: 203621.0
train_total_correct_tok: 201074.0
train_accuracy_tok: 0.9874914669901435
train_label=0_precision_sent: 0.9410954185325525
train_label=0_recall_sent: 0.939154348573393
train_label=0_f-score_sent: 0.9401238816242258
train_label=1_precision_sent: 0.9841084575327707
train_label=1_recall_sent: 0.9846388789076536
train_label=1_f-score_sent: 0.984373596766951
train_precision_macro_sent: 0.9626019380326616
train_recall_macro_sent: 0.9618966137405233
train_f-score_macro_sent: 0.9622487391955884
train_precision_micro_sent: 0.9752154404956912
train_recall_micro_sent: 0.9752154404956912
train_f-score_micro_sent: 0.9752154404956912
train_label=O_precision_tok: 0.99594001355293
train_label=O_recall_tok: 0.996685890858484
train_label=O_f-score_tok: 0.9963128126077639
train_label=LOC_precision_tok: 0.9467099723324913
train_label=LOC_recall_tok: 0.9485356152826323
train_label=LOC_f-score_tok: 0.9476219145093316
train_label=MISC_precision_tok: 0.9103139013452914
train_label=MISC_recall_tok: 0.8839538428042674
train_label=MISC_f-score_tok: 0.8969402408041532
train_label=ORG_precision_tok: 0.9262705082032813
train_label=ORG_recall_tok: 0.9235910224438902
train_label=ORG_f-score_tok: 0.9249288247340292
train_label=PER_precision_tok: 0.9750605544092581
train_label=PER_recall_tok: 0.976725377426312
train_label=PER_f-score_tok: 0.9758922558922559
train_precision_macro_tok: 0.9508589899686506
train_recall_macro_tok: 0.9458983497631172
train_f-score_macro_tok: 0.9483392097095068
train_precision_micro_tok: 0.9874914669901435
train_recall_micro_tok: 0.9874914669901435
train_f-score_micro_tok: 0.9874914669901435
train_time: 155.16069626808167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9411    0.9392    0.9401      2909
           1     0.9841    0.9846    0.9844     11132

   micro avg     0.9752    0.9752    0.9752     14041
   macro avg     0.9626    0.9619    0.9622     14041
weighted avg     0.9752    0.9752    0.9752     14041

F1-macro sent:  0.9622487391955884
F1-micro sent:  0.9752154404956912
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9967    0.9963    169578
         LOC     0.9467    0.9485    0.9476      8297
        MISC     0.9103    0.8840    0.8969      4593
         ORG     0.9263    0.9236    0.9249     10025
         PER     0.9751    0.9767    0.9759     11128

   micro avg     0.9875    0.9875    0.9875    203621
   macro avg     0.9509    0.9459    0.9483    203621
weighted avg     0.9874    0.9875    0.9875    203621

F1-macro tok:  0.9483392097095068
F1-micro tok:  0.9874914669901435
**************************************************
dev_cost_sum: 86469.44549942017
dev_cost_avg: 26.60598323059082
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50714.0
dev_accuracy_tok: 0.9873836688602469
dev_label=0_precision_sent: 0.9778830963665087
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.968701095461659
dev_label=1_precision_sent: 0.9900649598777226
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9923400995787056
dev_precision_macro_sent: 0.9839740281221157
dev_recall_macro_sent: 0.9771578211251469
dev_f-score_macro_sent: 0.9805205975201823
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.9958657417139654
dev_label=O_recall_tok: 0.9971234126148881
dev_label=O_f-score_tok: 0.9964941803393633
dev_label=LOC_precision_tok: 0.932780847145488
dev_label=LOC_recall_tok: 0.9675262655205349
dev_label=LOC_f-score_tok: 0.9498359118612284
dev_label=MISC_precision_tok: 0.9120603015075377
dev_label=MISC_recall_tok: 0.8588328075709779
dev_label=MISC_f-score_tok: 0.884646628757108
dev_label=ORG_precision_tok: 0.9479857215706272
dev_label=ORG_recall_tok: 0.888623326959847
dev_label=ORG_f-score_tok: 0.917345176412534
dev_label=PER_precision_tok: 0.9633767846058349
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9744153194161043
dev_precision_macro_tok: 0.9504138793086906
dev_recall_macro_tok: 0.9395631123585909
dev_f-score_macro_tok: 0.9445474433572676
dev_precision_micro_tok: 0.9873836688602469
dev_recall_micro_tok: 0.9873836688602469
dev_f-score_micro_tok: 0.9873836688602469
dev_time: 14.82948088645935
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9779    0.9597    0.9687       645
           1     0.9901    0.9946    0.9923      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9840    0.9772    0.9805      3250
weighted avg     0.9876    0.9877    0.9876      3250

F1-macro sent:  0.9805205975201823
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9971    0.9965     42759
         LOC     0.9328    0.9675    0.9498      2094
        MISC     0.9121    0.8588    0.8846      1268
         ORG     0.9480    0.8886    0.9173      2092
         PER     0.9634    0.9857    0.9744      3149

   micro avg     0.9874    0.9874    0.9874     51362
   macro avg     0.9504    0.9396    0.9445     51362
weighted avg     0.9873    0.9874    0.9873     51362

F1-macro tok:  0.9445474433572676
F1-micro tok:  0.9873836688602469
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 319154.1841125488
train_cost_avg: 22.730160537892516
train_count_sent: 14041.0
train_total_correct_sent: 13732.0
train_accuracy_sent: 0.9779930204401396
train_count_tok: 203621.0
train_total_correct_tok: 201190.0
train_accuracy_tok: 0.9880611528280482
train_label=0_precision_sent: 0.9482758620689655
train_label=0_recall_sent: 0.9453420419388106
train_label=0_f-score_sent: 0.9468066792907557
train_label=1_precision_sent: 0.9857283906292075
train_label=1_recall_sent: 0.9865253323751347
train_label=1_f-score_sent: 0.9861267004893818
train_precision_macro_sent: 0.9670021263490864
train_recall_macro_sent: 0.9659336871569726
train_f-score_macro_sent: 0.9664666898900687
train_precision_micro_sent: 0.9779930204401396
train_recall_micro_sent: 0.9779930204401396
train_f-score_micro_sent: 0.9779930204401396
train_label=O_precision_tok: 0.9961108754065903
train_label=O_recall_tok: 0.9968510066164243
train_label=O_f-score_tok: 0.9964808035793234
train_label=LOC_precision_tok: 0.9505428226779252
train_label=LOC_recall_tok: 0.9497408701940461
train_label=LOC_f-score_tok: 0.9501416772170977
train_label=MISC_precision_tok: 0.9109772423025435
train_label=MISC_recall_tok: 0.8889614630960156
train_label=MISC_f-score_tok: 0.8998347107438017
train_label=ORG_precision_tok: 0.9330258672548627
train_label=ORG_recall_tok: 0.9282793017456359
train_label=ORG_f-score_tok: 0.9306465323266163
train_label=PER_precision_tok: 0.9736818548026139
train_label=PER_recall_tok: 0.9774442846872753
train_label=PER_f-score_tok: 0.9755594421274496
train_precision_macro_tok: 0.9528677324889072
train_recall_macro_tok: 0.9482553852678794
train_f-score_macro_tok: 0.9505326331988577
train_precision_micro_tok: 0.9880611528280482
train_recall_micro_tok: 0.9880611528280482
train_f-score_micro_tok: 0.9880611528280482
train_time: 155.86863589286804
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9483    0.9453    0.9468      2909
           1     0.9857    0.9865    0.9861     11132

   micro avg     0.9780    0.9780    0.9780     14041
   macro avg     0.9670    0.9659    0.9665     14041
weighted avg     0.9780    0.9780    0.9780     14041

F1-macro sent:  0.9664666898900687
F1-micro sent:  0.9779930204401396
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9969    0.9965    169578
         LOC     0.9505    0.9497    0.9501      8297
        MISC     0.9110    0.8890    0.8998      4593
         ORG     0.9330    0.9283    0.9306     10025
         PER     0.9737    0.9774    0.9756     11128

   micro avg     0.9881    0.9881    0.9881    203621
   macro avg     0.9529    0.9483    0.9505    203621
weighted avg     0.9880    0.9881    0.9880    203621

F1-macro tok:  0.9505326331988577
F1-micro tok:  0.9880611528280482
**************************************************
dev_cost_sum: 86069.65307617188
dev_cost_avg: 26.482970177283654
dev_count_sent: 3250.0
dev_total_correct_sent: 3211.0
dev_accuracy_sent: 0.988
dev_count_tok: 51362.0
dev_total_correct_tok: 50759.0
dev_accuracy_tok: 0.9882598029671742
dev_label=0_precision_sent: 0.9871382636655949
dev_label=0_recall_sent: 0.951937984496124
dev_label=0_f-score_sent: 0.9692186266771902
dev_label=1_precision_sent: 0.9882039573820396
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9925472960061151
dev_precision_macro_sent: 0.9876711105238172
dev_recall_macro_sent: 0.9744334836108259
dev_f-score_macro_sent: 0.9808829613416526
dev_precision_micro_sent: 0.988
dev_recall_micro_sent: 0.988
dev_f-score_micro_sent: 0.988
dev_label=O_precision_tok: 0.9966789840497685
dev_label=O_recall_tok: 0.996655674828691
dev_label=O_f-score_tok: 0.9966673293029457
dev_label=LOC_precision_tok: 0.9540937056318031
dev_label=LOC_recall_tok: 0.9627507163323782
dev_label=LOC_f-score_tok: 0.9584026622296173
dev_label=MISC_precision_tok: 0.8818958818958819
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.8884540117416829
dev_label=ORG_precision_tok: 0.9377162629757786
dev_label=ORG_recall_tok: 0.9067877629063098
dev_label=ORG_f-score_tok: 0.921992709599028
dev_label=PER_precision_tok: 0.9729644765796919
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9778830963665086
dev_precision_macro_tok: 0.9486698622265848
dev_recall_macro_tok: 0.9488312526228129
dev_f-score_macro_tok: 0.9486799618479566
dev_precision_micro_tok: 0.9882598029671742
dev_recall_micro_tok: 0.9882598029671742
dev_f-score_micro_tok: 0.9882598029671742
dev_time: 14.880272388458252
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9871    0.9519    0.9692       645
           1     0.9882    0.9969    0.9925      2605

   micro avg     0.9880    0.9880    0.9880      3250
   macro avg     0.9877    0.9744    0.9809      3250
weighted avg     0.9880    0.9880    0.9879      3250

F1-macro sent:  0.9808829613416526
F1-micro sent:  0.988
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9967    0.9967     42759
         LOC     0.9541    0.9628    0.9584      2094
        MISC     0.8819    0.8951    0.8885      1268
         ORG     0.9377    0.9068    0.9220      2092
         PER     0.9730    0.9829    0.9779      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9487    0.9488    0.9487     51362
weighted avg     0.9883    0.9883    0.9882     51362

F1-macro tok:  0.9486799618479566
F1-micro tok:  0.9882598029671742
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 316802.34634399414
train_cost_avg: 22.562662655366008
train_count_sent: 14041.0
train_total_correct_sent: 13772.0
train_accuracy_sent: 0.9808418203831636
train_count_tok: 203621.0
train_total_correct_tok: 201367.0
train_accuracy_tok: 0.9889304148393339
train_label=0_precision_sent: 0.9498977505112475
train_label=0_recall_sent: 0.9580611894121691
train_label=0_f-score_sent: 0.9539620058189285
train_label=1_precision_sent: 0.9890159358962817
train_label=1_recall_sent: 0.986794825727632
train_label=1_f-score_sent: 0.987904132380053
train_precision_macro_sent: 0.9694568432037646
train_recall_macro_sent: 0.9724280075699006
train_f-score_macro_sent: 0.9709330690994908
train_precision_micro_sent: 0.9808418203831636
train_recall_micro_sent: 0.9808418203831636
train_f-score_micro_sent: 0.9808418203831636
train_label=O_precision_tok: 0.9964231417425841
train_label=O_recall_tok: 0.9971517531755298
train_label=O_f-score_tok: 0.996787314312662
train_label=LOC_precision_tok: 0.9547429398986241
train_label=LOC_recall_tok: 0.9534771604194288
train_label=LOC_f-score_tok: 0.9541096303443284
train_label=MISC_precision_tok: 0.9172429176890475
train_label=MISC_recall_tok: 0.8952754191160461
train_label=MISC_f-score_tok: 0.9061260467166152
train_label=ORG_precision_tok: 0.9370055082623936
train_label=ORG_recall_tok: 0.9332668329177057
train_label=ORG_f-score_tok: 0.9351324337831085
train_label=PER_precision_tok: 0.9756381549484998
train_label=PER_recall_tok: 0.978882099209202
train_label=PER_f-score_tok: 0.9772574350693043
train_precision_macro_tok: 0.9562105325082297
train_recall_macro_tok: 0.9516106529675824
train_f-score_macro_tok: 0.9538825720452037
train_precision_micro_tok: 0.9889304148393339
train_recall_micro_tok: 0.9889304148393339
train_f-score_micro_tok: 0.9889304148393339
train_time: 154.13678169250488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9499    0.9581    0.9540      2909
           1     0.9890    0.9868    0.9879     11132

   micro avg     0.9808    0.9808    0.9808     14041
   macro avg     0.9695    0.9724    0.9709     14041
weighted avg     0.9809    0.9808    0.9809     14041

F1-macro sent:  0.9709330690994908
F1-micro sent:  0.9808418203831636
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9972    0.9968    169578
         LOC     0.9547    0.9535    0.9541      8297
        MISC     0.9172    0.8953    0.9061      4593
         ORG     0.9370    0.9333    0.9351     10025
         PER     0.9756    0.9789    0.9773     11128

   micro avg     0.9889    0.9889    0.9889    203621
   macro avg     0.9562    0.9516    0.9539    203621
weighted avg     0.9889    0.9889    0.9889    203621

F1-macro tok:  0.9538825720452037
F1-micro tok:  0.9889304148393339
**************************************************
dev_cost_sum: 85734.79872894287
dev_cost_avg: 26.37993807044396
dev_count_sent: 3250.0
dev_total_correct_sent: 3214.0
dev_accuracy_sent: 0.9889230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50763.0
dev_accuracy_tok: 0.9883376815544566
dev_label=0_precision_sent: 0.973561430793157
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9720496894409939
dev_label=1_precision_sent: 0.9927119294207902
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9930928626247123
dev_precision_macro_sent: 0.9831366801069736
dev_recall_macro_sent: 0.9820083619753307
dev_f-score_macro_sent: 0.9825712760328531
dev_precision_micro_sent: 0.9889230769230769
dev_recall_micro_sent: 0.9889230769230769
dev_f-score_micro_sent: 0.9889230769230769
dev_label=O_precision_tok: 0.9965395496738292
dev_label=O_recall_tok: 0.9967726092752403
dev_label=O_f-score_tok: 0.9966560658497802
dev_label=LOC_precision_tok: 0.9484294421003282
dev_label=LOC_recall_tok: 0.9660936007640879
dev_label=LOC_f-score_tok: 0.9571800331204164
dev_label=MISC_precision_tok: 0.8958333333333334
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.8887122416534181
dev_label=ORG_precision_tok: 0.93505859375
dev_label=ORG_recall_tok: 0.9153919694072657
dev_label=ORG_f-score_tok: 0.9251207729468599
dev_label=PER_precision_tok: 0.9753476611883691
dev_label=PER_recall_tok: 0.9799936487773896
dev_label=PER_f-score_tok: 0.977665135434817
dev_precision_macro_tok: 0.9502417160091721
dev_recall_macro_tok: 0.9479910596511057
dev_f-score_macro_tok: 0.9490668498010584
dev_precision_micro_tok: 0.9883376815544566
dev_recall_micro_tok: 0.9883376815544566
dev_f-score_micro_tok: 0.9883376815544566
dev_time: 13.747818946838379
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9736    0.9705    0.9720       645
           1     0.9927    0.9935    0.9931      2605

   micro avg     0.9889    0.9889    0.9889      3250
   macro avg     0.9831    0.9820    0.9826      3250
weighted avg     0.9889    0.9889    0.9889      3250

F1-macro sent:  0.9825712760328531
F1-micro sent:  0.9889230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9968    0.9967     42759
         LOC     0.9484    0.9661    0.9572      2094
        MISC     0.8958    0.8817    0.8887      1268
         ORG     0.9351    0.9154    0.9251      2092
         PER     0.9753    0.9800    0.9777      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9502    0.9480    0.9491     51362
weighted avg     0.9883    0.9883    0.9883     51362

F1-macro tok:  0.9490668498010584
F1-micro tok:  0.9883376815544566
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 314718.97302246094
train_cost_avg: 22.41428481037397
train_count_sent: 14041.0
train_total_correct_sent: 13784.0
train_accuracy_sent: 0.9816964603660708
train_count_tok: 203621.0
train_total_correct_tok: 201493.0
train_accuracy_tok: 0.9895492115253338
train_label=0_precision_sent: 0.9559834938101788
train_label=0_recall_sent: 0.9556548642145067
train_label=0_f-score_sent: 0.9558191507649992
train_label=1_precision_sent: 0.9884128267313392
train_label=1_recall_sent: 0.988501616960115
train_label=1_f-score_sent: 0.9884572198517854
train_precision_macro_sent: 0.972198160270759
train_recall_macro_sent: 0.9720782405873108
train_f-score_macro_sent: 0.9721381853083924
train_precision_micro_sent: 0.9816964603660708
train_recall_micro_sent: 0.9816964603660708
train_f-score_micro_sent: 0.9816964603660708
train_label=O_precision_tok: 0.9967171374853391
train_label=O_recall_tok: 0.997252002028565
train_label=O_f-score_tok: 0.9969844980206163
train_label=LOC_precision_tok: 0.9540312876052949
train_label=LOC_recall_tok: 0.9555260937688321
train_label=LOC_f-score_tok: 0.9547781056181129
train_label=MISC_precision_tok: 0.9257690592955863
train_label=MISC_recall_tok: 0.904202046592641
train_label=MISC_f-score_tok: 0.9148584645886111
train_label=ORG_precision_tok: 0.9384507606084868
train_label=ORG_recall_tok: 0.935361596009975
train_label=ORG_f-score_tok: 0.9369036319128741
train_label=PER_precision_tok: 0.9784127552848442
train_label=PER_recall_tok: 0.9815780014378145
train_label=PER_f-score_tok: 0.9799928225372332
train_precision_macro_tok: 0.9586762000559104
train_recall_macro_tok: 0.9547839479675655
train_f-score_macro_tok: 0.9567035045354896
train_precision_micro_tok: 0.9895492115253338
train_recall_micro_tok: 0.9895492115253338
train_f-score_micro_tok: 0.9895492115253338
train_time: 157.30795288085938
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9560    0.9557    0.9558      2909
           1     0.9884    0.9885    0.9885     11132

   micro avg     0.9817    0.9817    0.9817     14041
   macro avg     0.9722    0.9721    0.9721     14041
weighted avg     0.9817    0.9817    0.9817     14041

F1-macro sent:  0.9721381853083924
F1-micro sent:  0.9816964603660708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9973    0.9970    169578
         LOC     0.9540    0.9555    0.9548      8297
        MISC     0.9258    0.9042    0.9149      4593
         ORG     0.9385    0.9354    0.9369     10025
         PER     0.9784    0.9816    0.9800     11128

   micro avg     0.9895    0.9895    0.9895    203621
   macro avg     0.9587    0.9548    0.9567    203621
weighted avg     0.9895    0.9895    0.9895    203621

F1-macro tok:  0.9567035045354896
F1-micro tok:  0.9895492115253338
**************************************************
dev_cost_sum: 85244.06978988647
dev_cost_avg: 26.2289445507343
dev_count_sent: 3250.0
dev_total_correct_sent: 3215.0
dev_accuracy_sent: 0.9892307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50734.0
dev_accuracy_tok: 0.987773061796659
dev_label=0_precision_sent: 0.9810725552050473
dev_label=0_recall_sent: 0.9643410852713178
dev_label=0_f-score_sent: 0.9726348709929632
dev_label=1_precision_sent: 0.9912079510703364
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9932963033901552
dev_precision_macro_sent: 0.9861402531376919
dev_recall_macro_sent: 0.9798672796798047
dev_f-score_macro_sent: 0.9829655871915592
dev_precision_micro_sent: 0.9892307692307692
dev_recall_micro_sent: 0.9892307692307692
dev_f-score_micro_sent: 0.9892307692307692
dev_label=O_precision_tok: 0.9956816059757236
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9966237923340227
dev_label=LOC_precision_tok: 0.9358560221504384
dev_label=LOC_recall_tok: 0.9684813753581661
dev_label=LOC_f-score_tok: 0.9518892278807791
dev_label=MISC_precision_tok: 0.9029363784665579
dev_label=MISC_recall_tok: 0.8730283911671924
dev_label=MISC_f-score_tok: 0.8877305533279872
dev_label=ORG_precision_tok: 0.9546858908341915
dev_label=ORG_recall_tok: 0.8862332695984704
dev_label=ORG_f-score_tok: 0.9191869112543383
dev_label=PER_precision_tok: 0.9695638531534359
dev_label=PER_recall_tok: 0.9812638932994602
dev_label=PER_f-score_tok: 0.9753787878787878
dev_precision_macro_tok: 0.9517447501160694
dev_recall_macro_tok: 0.941314938587013
dev_f-score_macro_tok: 0.9461618545351831
dev_precision_micro_tok: 0.987773061796659
dev_recall_micro_tok: 0.987773061796659
dev_f-score_micro_tok: 0.987773061796659
dev_time: 11.022594690322876
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9811    0.9643    0.9726       645
           1     0.9912    0.9954    0.9933      2605

   micro avg     0.9892    0.9892    0.9892      3250
   macro avg     0.9861    0.9799    0.9830      3250
weighted avg     0.9892    0.9892    0.9892      3250

F1-macro sent:  0.9829655871915592
F1-micro sent:  0.9892307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9976    0.9966     42759
         LOC     0.9359    0.9685    0.9519      2094
        MISC     0.9029    0.8730    0.8877      1268
         ORG     0.9547    0.8862    0.9192      2092
         PER     0.9696    0.9813    0.9754      3149

   micro avg     0.9878    0.9878    0.9878     51362
   macro avg     0.9517    0.9413    0.9462     51362
weighted avg     0.9877    0.9878    0.9877     51362

F1-macro tok:  0.9461618545351831
F1-micro tok:  0.987773061796659
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 312702.56915283203
train_cost_avg: 22.270676529651166
train_count_sent: 14041.0
train_total_correct_sent: 13804.0
train_accuracy_sent: 0.9831208603375828
train_count_tok: 203621.0
train_total_correct_tok: 201560.0
train_accuracy_tok: 0.9898782542075719
train_label=0_precision_sent: 0.958161865569273
train_label=0_recall_sent: 0.9604675146098316
train_label=0_f-score_sent: 0.95931330472103
train_label=1_precision_sent: 0.9896629213483146
train_label=1_recall_sent: 0.9890406036651096
train_label=1_f-score_sent: 0.9893516646448308
train_precision_macro_sent: 0.9739123934587938
train_recall_macro_sent: 0.9747540591374706
train_f-score_macro_sent: 0.9743324846829304
train_precision_micro_sent: 0.9831208603375828
train_recall_micro_sent: 0.9831208603375828
train_f-score_micro_sent: 0.9831208603375828
train_label=O_precision_tok: 0.9967815902245224
train_label=O_recall_tok: 0.99719892910637
train_label=O_f-score_tok: 0.9969902159910621
train_label=LOC_precision_tok: 0.9568613314107186
train_label=LOC_recall_tok: 0.9597444859587803
train_label=LOC_f-score_tok: 0.9583007401167338
train_label=MISC_precision_tok: 0.9284921163668666
train_label=MISC_recall_tok: 0.9102982799912911
train_label=MISC_f-score_tok: 0.9193051890941072
train_label=ORG_precision_tok: 0.9405356785928443
train_label=ORG_recall_tok: 0.9387531172069825
train_label=ORG_f-score_tok: 0.9396435524936348
train_label=PER_precision_tok: 0.9785477066690602
train_label=PER_recall_tok: 0.9796908698777858
train_label=PER_f-score_tok: 0.9791189546005657
train_precision_macro_tok: 0.9602436846528024
train_recall_macro_tok: 0.9571371364282418
train_f-score_macro_tok: 0.9586717304592206
train_precision_micro_tok: 0.9898782542075719
train_recall_micro_tok: 0.9898782542075719
train_f-score_micro_tok: 0.9898782542075719
train_time: 157.36848044395447
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9582    0.9605    0.9593      2909
           1     0.9897    0.9890    0.9894     11132

   micro avg     0.9831    0.9831    0.9831     14041
   macro avg     0.9739    0.9748    0.9743     14041
weighted avg     0.9831    0.9831    0.9831     14041

F1-macro sent:  0.9743324846829304
F1-micro sent:  0.9831208603375828
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9972    0.9970    169578
         LOC     0.9569    0.9597    0.9583      8297
        MISC     0.9285    0.9103    0.9193      4593
         ORG     0.9405    0.9388    0.9396     10025
         PER     0.9785    0.9797    0.9791     11128

   micro avg     0.9899    0.9899    0.9899    203621
   macro avg     0.9602    0.9571    0.9587    203621
weighted avg     0.9898    0.9899    0.9899    203621

F1-macro tok:  0.9586717304592206
F1-micro tok:  0.9898782542075719
**************************************************
dev_cost_sum: 84853.83278274536
dev_cost_avg: 26.10887162546011
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50787.0
dev_accuracy_tok: 0.9888049530781512
dev_label=0_precision_sent: 0.9904306220095693
dev_label=0_recall_sent: 0.9627906976744186
dev_label=0_f-score_sent: 0.9764150943396227
dev_label=1_precision_sent: 0.9908501715592832
dev_label=1_recall_sent: 0.9976967370441459
dev_label=1_f-score_sent: 0.9942616679418516
dev_precision_macro_sent: 0.9906403967844263
dev_recall_macro_sent: 0.9802437173592822
dev_f-score_macro_sent: 0.9853383811407371
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9962617695848228
dev_label=O_recall_tok: 0.9972403470614374
dev_label=O_f-score_tok: 0.9967508181393175
dev_label=LOC_precision_tok: 0.9712054660810151
dev_label=LOC_recall_tok: 0.9503342884431709
dev_label=LOC_f-score_tok: 0.9606565290852039
dev_label=MISC_precision_tok: 0.8925750394944708
dev_label=MISC_recall_tok: 0.8911671924290221
dev_label=MISC_f-score_tok: 0.8918705603788476
dev_label=ORG_precision_tok: 0.9433776464795667
dev_label=ORG_recall_tok: 0.9158699808795411
dev_label=ORG_f-score_tok: 0.9294203250060636
dev_label=PER_precision_tok: 0.9673405909797823
dev_label=PER_recall_tok: 0.9876151159098127
dev_label=PER_f-score_tok: 0.9773727215587681
dev_precision_macro_tok: 0.9541521025239316
dev_recall_macro_tok: 0.9484453849445968
dev_f-score_macro_tok: 0.9512141908336401
dev_precision_micro_tok: 0.9888049530781512
dev_recall_micro_tok: 0.9888049530781512
dev_f-score_micro_tok: 0.9888049530781512
dev_time: 13.46031403541565
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9904    0.9628    0.9764       645
           1     0.9909    0.9977    0.9943      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9906    0.9802    0.9853      3250
weighted avg     0.9908    0.9908    0.9907      3250

F1-macro sent:  0.9853383811407371
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9972    0.9968     42759
         LOC     0.9712    0.9503    0.9607      2094
        MISC     0.8926    0.8912    0.8919      1268
         ORG     0.9434    0.9159    0.9294      2092
         PER     0.9673    0.9876    0.9774      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9542    0.9484    0.9512     51362
weighted avg     0.9888    0.9888    0.9888     51362

F1-macro tok:  0.9512141908336401
F1-micro tok:  0.9888049530781512
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 310645.6463317871
train_cost_avg: 22.12418248926623
train_count_sent: 14041.0
train_total_correct_sent: 13808.0
train_accuracy_sent: 0.9834057403318852
train_count_tok: 203621.0
train_total_correct_tok: 201740.0
train_accuracy_tok: 0.9907622494732862
train_label=0_precision_sent: 0.9585332419465388
train_label=0_recall_sent: 0.9614987968374011
train_label=0_f-score_sent: 0.9600137291916938
train_label=1_precision_sent: 0.9899307740717432
train_label=1_recall_sent: 0.9891304347826086
train_label=1_f-score_sent: 0.9895304425971692
train_precision_macro_sent: 0.974232008009141
train_recall_macro_sent: 0.9753146158100049
train_f-score_macro_sent: 0.9747720858944315
train_precision_micro_sent: 0.9834057403318852
train_recall_micro_sent: 0.9834057403318852
train_f-score_micro_sent: 0.9834057403318852
train_label=O_precision_tok: 0.9970644062201578
train_label=O_recall_tok: 0.9974407057519253
train_label=O_f-score_tok: 0.9972525204881787
train_label=LOC_precision_tok: 0.9615570016871535
train_label=LOC_recall_tok: 0.9616728938170424
train_label=LOC_f-score_tok: 0.9616149442603195
train_label=MISC_precision_tok: 0.9305156007966364
train_label=MISC_recall_tok: 0.9155236229044198
train_label=MISC_f-score_tok: 0.9229587357330993
train_label=ORG_precision_tok: 0.9477626847782661
train_label=ORG_recall_tok: 0.9465336658354114
train_label=ORG_f-score_tok: 0.9471477766132654
train_label=PER_precision_tok: 0.9796412556053812
train_label=PER_recall_tok: 0.9815780014378145
train_label=PER_f-score_tok: 0.9806086722326959
train_precision_macro_tok: 0.963308189817519
train_recall_macro_tok: 0.9605497779493227
train_f-score_macro_tok: 0.9619165298655117
train_precision_micro_tok: 0.9907622494732862
train_recall_micro_tok: 0.9907622494732862
train_f-score_micro_tok: 0.9907622494732862
train_time: 155.57132411003113
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9585    0.9615    0.9600      2909
           1     0.9899    0.9891    0.9895     11132

   micro avg     0.9834    0.9834    0.9834     14041
   macro avg     0.9742    0.9753    0.9748     14041
weighted avg     0.9834    0.9834    0.9834     14041

F1-macro sent:  0.9747720858944315
F1-micro sent:  0.9834057403318852
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9974    0.9973    169578
         LOC     0.9616    0.9617    0.9616      8297
        MISC     0.9305    0.9155    0.9230      4593
         ORG     0.9478    0.9465    0.9471     10025
         PER     0.9796    0.9816    0.9806     11128

   micro avg     0.9908    0.9908    0.9908    203621
   macro avg     0.9633    0.9605    0.9619    203621
weighted avg     0.9907    0.9908    0.9907    203621

F1-macro tok:  0.9619165298655117
F1-micro tok:  0.9907622494732862
**************************************************
dev_cost_sum: 84535.21535491943
dev_cost_avg: 26.010835493821364
dev_count_sent: 3250.0
dev_total_correct_sent: 3199.0
dev_accuracy_sent: 0.9843076923076923
dev_count_tok: 51362.0
dev_total_correct_tok: 50777.0
dev_accuracy_tok: 0.9886102566099451
dev_label=0_precision_sent: 0.9393491124260355
dev_label=0_recall_sent: 0.9844961240310077
dev_label=0_f-score_sent: 0.9613928841786524
dev_label=1_precision_sent: 0.9961149961149961
dev_label=1_recall_sent: 0.9842610364683302
dev_label=1_f-score_sent: 0.9901525391002124
dev_precision_macro_sent: 0.9677320542705158
dev_recall_macro_sent: 0.984378580249669
dev_f-score_macro_sent: 0.9757727116394324
dev_precision_micro_sent: 0.9843076923076923
dev_recall_micro_sent: 0.9843076923076923
dev_f-score_micro_sent: 0.9843076923076923
dev_label=O_precision_tok: 0.9960280373831776
dev_label=O_recall_tok: 0.996983091279029
dev_label=O_f-score_tok: 0.9965053354994798
dev_label=LOC_precision_tok: 0.958969465648855
dev_label=LOC_recall_tok: 0.9598853868194842
dev_label=LOC_f-score_tok: 0.9594272076372315
dev_label=MISC_precision_tok: 0.8972332015810277
dev_label=MISC_recall_tok: 0.8951104100946372
dev_label=MISC_f-score_tok: 0.8961705487564152
dev_label=ORG_precision_tok: 0.9436758893280632
dev_label=ORG_recall_tok: 0.9130019120458891
dev_label=ORG_f-score_tok: 0.9280855199222545
dev_label=PER_precision_tok: 0.9732451998740951
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9775529560543789
dev_precision_macro_tok: 0.9538303587630438
dev_recall_macro_tok: 0.9493759631599069
dev_f-score_macro_tok: 0.9515483135739519
dev_precision_micro_tok: 0.9886102566099451
dev_recall_micro_tok: 0.9886102566099451
dev_f-score_micro_tok: 0.9886102566099451
dev_time: 14.665818691253662
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9393    0.9845    0.9614       645
           1     0.9961    0.9843    0.9902      2605

   micro avg     0.9843    0.9843    0.9843      3250
   macro avg     0.9677    0.9844    0.9758      3250
weighted avg     0.9848    0.9843    0.9844      3250

F1-macro sent:  0.9757727116394324
F1-micro sent:  0.9843076923076923
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9970    0.9965     42759
         LOC     0.9590    0.9599    0.9594      2094
        MISC     0.8972    0.8951    0.8962      1268
         ORG     0.9437    0.9130    0.9281      2092
         PER     0.9732    0.9819    0.9776      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9538    0.9494    0.9515     51362
weighted avg     0.9885    0.9886    0.9886     51362

F1-macro tok:  0.9515483135739519
F1-micro tok:  0.9886102566099451
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 308830.7264404297
train_cost_avg: 21.994923897188926
train_count_sent: 14041.0
train_total_correct_sent: 13826.0
train_accuracy_sent: 0.984687700306246
train_count_tok: 203621.0
train_total_correct_tok: 201802.0
train_accuracy_tok: 0.9910667367314766
train_label=0_precision_sent: 0.9619341563786008
train_label=0_recall_sent: 0.9642488827775868
train_label=0_f-score_sent: 0.9630901287553648
train_label=1_precision_sent: 0.9906516853932584
train_label=1_recall_sent: 0.9900287459575997
train_label=1_f-score_sent: 0.9903401177157749
train_precision_macro_sent: 0.9762929208859297
train_recall_macro_sent: 0.9771388143675932
train_f-score_macro_sent: 0.9767151232355699
train_precision_micro_sent: 0.984687700306246
train_recall_micro_sent: 0.984687700306246
train_f-score_micro_sent: 0.984687700306246
train_label=O_precision_tok: 0.9971113940765893
train_label=O_recall_tok: 0.9974289117692153
train_label=O_f-score_tok: 0.9972701276495387
train_label=LOC_precision_tok: 0.9628647214854111
train_label=LOC_recall_tok: 0.962516572255032
train_label=LOC_f-score_tok: 0.9626906153938883
train_label=MISC_precision_tok: 0.9349647266313933
train_label=MISC_recall_tok: 0.9233616372741128
train_label=MISC_f-score_tok: 0.9291269580457882
train_label=ORG_precision_tok: 0.9477358866945941
train_label=ORG_recall_tok: 0.9478304239401496
train_label=ORG_f-score_tok: 0.9477831529599521
train_label=PER_precision_tok: 0.9818557441839576
train_label=PER_recall_tok: 0.9822969086987778
train_label=PER_f-score_tok: 0.9820762768968152
train_precision_macro_tok: 0.9649064946143892
train_recall_macro_tok: 0.9626868907874574
train_f-score_macro_tok: 0.9637894261891965
train_precision_micro_tok: 0.9910667367314766
train_recall_micro_tok: 0.9910667367314766
train_f-score_micro_tok: 0.9910667367314766
train_time: 154.79915118217468
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9619    0.9642    0.9631      2909
           1     0.9907    0.9900    0.9903     11132

   micro avg     0.9847    0.9847    0.9847     14041
   macro avg     0.9763    0.9771    0.9767     14041
weighted avg     0.9847    0.9847    0.9847     14041

F1-macro sent:  0.9767151232355699
F1-micro sent:  0.984687700306246
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9971    0.9974    0.9973    169578
         LOC     0.9629    0.9625    0.9627      8297
        MISC     0.9350    0.9234    0.9291      4593
         ORG     0.9477    0.9478    0.9478     10025
         PER     0.9819    0.9823    0.9821     11128

   micro avg     0.9911    0.9911    0.9911    203621
   macro avg     0.9649    0.9627    0.9638    203621
weighted avg     0.9910    0.9911    0.9911    203621

F1-macro tok:  0.9637894261891965
F1-micro tok:  0.9910667367314766
**************************************************
dev_cost_sum: 84276.26731872559
dev_cost_avg: 25.931159174992487
dev_count_sent: 3250.0
dev_total_correct_sent: 3214.0
dev_accuracy_sent: 0.9889230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50796.0
dev_accuracy_tok: 0.9889801798995366
dev_label=0_precision_sent: 0.9872
dev_label=0_recall_sent: 0.9565891472868217
dev_label=0_f-score_sent: 0.9716535433070865
dev_label=1_precision_sent: 0.9893333333333333
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9931166347992351
dev_precision_macro_sent: 0.9882666666666666
dev_recall_macro_sent: 0.9767590650061748
dev_f-score_macro_sent: 0.9823850890531608
dev_precision_micro_sent: 0.9889230769230769
dev_recall_micro_sent: 0.9889230769230769
dev_f-score_micro_sent: 0.9889230769230769
dev_label=O_precision_tok: 0.9969826678829555
dev_label=O_recall_tok: 0.9968427699431699
dev_label=O_f-score_tok: 0.996912714005052
dev_label=LOC_precision_tok: 0.9647172547124214
dev_label=LOC_recall_tok: 0.9531996179560649
dev_label=LOC_f-score_tok: 0.9589238529906318
dev_label=MISC_precision_tok: 0.8975762314308053
dev_label=MISC_recall_tok: 0.9053627760252366
dev_label=MISC_f-score_tok: 0.9014526894385553
dev_label=ORG_precision_tok: 0.9317851959361393
dev_label=ORG_recall_tok: 0.9206500956022945
dev_label=ORG_f-score_tok: 0.9261841788891562
dev_label=PER_precision_tok: 0.971195992485911
dev_label=PER_recall_tok: 0.9850746268656716
dev_label=PER_f-score_tok: 0.9780860791423617
dev_precision_macro_tok: 0.9524514684896467
dev_recall_macro_tok: 0.9522259772784875
dev_f-score_macro_tok: 0.9523119028931513
dev_precision_micro_tok: 0.9889801798995366
dev_recall_micro_tok: 0.9889801798995366
dev_f-score_micro_tok: 0.9889801798995366
dev_time: 14.907282829284668
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9872    0.9566    0.9717       645
           1     0.9893    0.9969    0.9931      2605

   micro avg     0.9889    0.9889    0.9889      3250
   macro avg     0.9883    0.9768    0.9824      3250
weighted avg     0.9889    0.9889    0.9889      3250

F1-macro sent:  0.9823850890531608
F1-micro sent:  0.9889230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9968    0.9969     42759
         LOC     0.9647    0.9532    0.9589      2094
        MISC     0.8976    0.9054    0.9015      1268
         ORG     0.9318    0.9207    0.9262      2092
         PER     0.9712    0.9851    0.9781      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9525    0.9522    0.9523     51362
weighted avg     0.9890    0.9890    0.9890     51362

F1-macro tok:  0.9523119028931513
F1-micro tok:  0.9889801798995366
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 307338.40954589844
train_cost_avg: 21.888641090086065
train_count_sent: 14041.0
train_total_correct_sent: 13807.0
train_accuracy_sent: 0.9833345203333096
train_count_tok: 203621.0
train_total_correct_tok: 201888.0
train_accuracy_tok: 0.9914890900250957
train_label=0_precision_sent: 0.9604130808950087
train_label=0_recall_sent: 0.9590924716397388
train_label=0_f-score_sent: 0.9597523219814242
train_label=1_precision_sent: 0.9893139367816092
train_label=1_recall_sent: 0.9896694214876033
train_label=1_f-score_sent: 0.9894916472067541
train_precision_macro_sent: 0.9748635088383089
train_recall_macro_sent: 0.974380946563671
train_f-score_macro_sent: 0.9746219845940891
train_precision_micro_sent: 0.9833345203333096
train_recall_micro_sent: 0.9833345203333096
train_f-score_micro_sent: 0.9833345203333096
train_label=O_precision_tok: 0.99727064260745
train_label=O_recall_tok: 0.9976176154925757
train_label=O_f-score_tok: 0.9974440988753445
train_label=LOC_precision_tok: 0.9651891110575764
train_label=LOC_recall_tok: 0.9657707605158491
train_label=LOC_f-score_tok: 0.9654798481836255
train_label=MISC_precision_tok: 0.9382443758270842
train_label=MISC_recall_tok: 0.9261920313520575
train_label=MISC_f-score_tok: 0.9321792483839159
train_label=ORG_precision_tok: 0.9494707409626523
train_label=ORG_recall_tok: 0.948428927680798
train_label=ORG_f-score_tok: 0.9489495483806578
train_label=PER_precision_tok: 0.9824860786779235
train_label=PER_recall_tok: 0.9830158159597412
train_label=PER_f-score_tok: 0.9827508759320817
train_precision_macro_tok: 0.9665321898265372
train_recall_macro_tok: 0.9642050302002044
train_f-score_macro_tok: 0.965360723951125
train_precision_micro_tok: 0.9914890900250957
train_recall_micro_tok: 0.9914890900250957
train_f-score_micro_tok: 0.9914890900250957
train_time: 155.91356492042542
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9604    0.9591    0.9598      2909
           1     0.9893    0.9897    0.9895     11132

   micro avg     0.9833    0.9833    0.9833     14041
   macro avg     0.9749    0.9744    0.9746     14041
weighted avg     0.9833    0.9833    0.9833     14041

F1-macro sent:  0.9746219845940891
F1-micro sent:  0.9833345203333096
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9973    0.9976    0.9974    169578
         LOC     0.9652    0.9658    0.9655      8297
        MISC     0.9382    0.9262    0.9322      4593
         ORG     0.9495    0.9484    0.9489     10025
         PER     0.9825    0.9830    0.9828     11128

   micro avg     0.9915    0.9915    0.9915    203621
   macro avg     0.9665    0.9642    0.9654    203621
weighted avg     0.9915    0.9915    0.9915    203621

F1-macro tok:  0.965360723951125
F1-micro tok:  0.9914890900250957
**************************************************
dev_cost_sum: 84191.19426727295
dev_cost_avg: 25.9049828514686
dev_count_sent: 3250.0
dev_total_correct_sent: 3197.0
dev_accuracy_sent: 0.9836923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50779.0
dev_accuracy_tok: 0.9886491959035864
dev_label=0_precision_sent: 0.9444444444444444
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.9595728451563692
dev_label=1_precision_sent: 0.9938080495356038
dev_label=1_recall_sent: 0.9857965451055662
dev_label=1_f-score_sent: 0.9897860859510503
dev_precision_macro_sent: 0.9691262469900241
dev_recall_macro_sent: 0.9804951717775894
dev_f-score_macro_sent: 0.9746794655537098
dev_precision_micro_sent: 0.9836923076923076
dev_recall_micro_sent: 0.9836923076923076
dev_f-score_micro_sent: 0.9836923076923076
dev_label=O_precision_tok: 0.9959383753501401
dev_label=O_recall_tok: 0.9978250192941837
dev_label=O_f-score_tok: 0.9968808046822977
dev_label=LOC_precision_tok: 0.9484777517564403
dev_label=LOC_recall_tok: 0.9670487106017192
dev_label=LOC_f-score_tok: 0.9576732087964057
dev_label=MISC_precision_tok: 0.9301346801346801
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8998371335504887
dev_label=ORG_precision_tok: 0.9517521584560691
dev_label=ORG_recall_tok: 0.8957934990439771
dev_label=ORG_f-score_tok: 0.9229253878355086
dev_label=PER_precision_tok: 0.9625386996904025
dev_label=PER_recall_tok: 0.987297554779295
dev_label=PER_f-score_tok: 0.9747609343157234
dev_precision_macro_tok: 0.9577683330775464
dev_recall_macro_tok: 0.9438831775640242
dev_f-score_macro_tok: 0.9504154938360848
dev_precision_micro_tok: 0.9886491959035864
dev_recall_micro_tok: 0.9886491959035864
dev_f-score_micro_tok: 0.9886491959035864
dev_time: 14.95338749885559
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9444    0.9752    0.9596       645
           1     0.9938    0.9858    0.9898      2605

   micro avg     0.9837    0.9837    0.9837      3250
   macro avg     0.9691    0.9805    0.9747      3250
weighted avg     0.9840    0.9837    0.9838      3250

F1-macro sent:  0.9746794655537098
F1-micro sent:  0.9836923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9978    0.9969     42759
         LOC     0.9485    0.9670    0.9577      2094
        MISC     0.9301    0.8715    0.8998      1268
         ORG     0.9518    0.8958    0.9229      2092
         PER     0.9625    0.9873    0.9748      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9578    0.9439    0.9504     51362
weighted avg     0.9885    0.9886    0.9885     51362

F1-macro tok:  0.9504154938360848
F1-micro tok:  0.9886491959035864
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 305734.13946533203
train_cost_avg: 21.774384977233247
train_count_sent: 14041.0
train_total_correct_sent: 13846.0
train_accuracy_sent: 0.986112100277758
train_count_tok: 203621.0
train_total_correct_tok: 201906.0
train_accuracy_tok: 0.991577489551667
train_label=0_precision_sent: 0.9650445510623715
train_label=0_recall_sent: 0.968030250945342
train_label=0_f-score_sent: 0.9665350952462674
train_label=1_precision_sent: 0.9916389463274297
train_label=1_recall_sent: 0.9908372260150916
train_label=1_f-score_sent: 0.9912379240620085
train_precision_macro_sent: 0.9783417486949006
train_recall_macro_sent: 0.9794337384802168
train_f-score_macro_sent: 0.9788865096541379
train_precision_micro_sent: 0.986112100277758
train_recall_micro_sent: 0.986112100277758
train_f-score_micro_sent: 0.986112100277758
train_label=O_precision_tok: 0.9973062504420814
train_label=O_recall_tok: 0.997741452311031
train_label=O_f-score_tok: 0.9975238039088524
train_label=LOC_precision_tok: 0.9647370321338308
train_label=LOC_recall_tok: 0.9661323369892733
train_label=LOC_f-score_tok: 0.9654341804167168
train_label=MISC_precision_tok: 0.9333039841514418
train_label=MISC_recall_tok: 0.9231439146527324
train_label=MISC_f-score_tok: 0.9281961471103327
train_label=ORG_precision_tok: 0.9536144578313253
train_label=ORG_recall_tok: 0.947431421446384
train_label=ORG_f-score_tok: 0.9505128846634977
train_label=PER_precision_tok: 0.9820740342385946
train_label=PER_recall_tok: 0.9846333572969087
train_label=PER_f-score_tok: 0.9833520305137986
train_precision_macro_tok: 0.9662071517594548
train_recall_macro_tok: 0.9638164965392658
train_f-score_macro_tok: 0.9650038093226396
train_precision_micro_tok: 0.991577489551667
train_recall_micro_tok: 0.991577489551667
train_f-score_micro_tok: 0.991577489551667
train_time: 155.40233206748962
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9650    0.9680    0.9665      2909
           1     0.9916    0.9908    0.9912     11132

   micro avg     0.9861    0.9861    0.9861     14041
   macro avg     0.9783    0.9794    0.9789     14041
weighted avg     0.9861    0.9861    0.9861     14041

F1-macro sent:  0.9788865096541379
F1-micro sent:  0.986112100277758
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9973    0.9977    0.9975    169578
         LOC     0.9647    0.9661    0.9654      8297
        MISC     0.9333    0.9231    0.9282      4593
         ORG     0.9536    0.9474    0.9505     10025
         PER     0.9821    0.9846    0.9834     11128

   micro avg     0.9916    0.9916    0.9916    203621
   macro avg     0.9662    0.9638    0.9650    203621
weighted avg     0.9916    0.9916    0.9916    203621

F1-macro tok:  0.9650038093226396
F1-micro tok:  0.991577489551667
**************************************************
dev_cost_sum: 83843.87147140503
dev_cost_avg: 25.798114298893854
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50785.0
dev_accuracy_tok: 0.9887660137845099
dev_label=0_precision_sent: 0.9723076923076923
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9760617760617761
dev_label=1_precision_sent: 0.995
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9940441882804996
dev_precision_macro_sent: 0.9836538461538462
dev_recall_macro_sent: 0.9864675861863739
dev_f-score_macro_sent: 0.9850529821711378
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9960758665794637
dev_label=O_recall_tok: 0.9973105077293669
dev_label=O_f-score_tok: 0.9966928048053663
dev_label=LOC_precision_tok: 0.9612625538020086
dev_label=LOC_recall_tok: 0.9598853868194842
dev_label=LOC_f-score_tok: 0.9605734767025089
dev_label=MISC_precision_tok: 0.91701244813278
dev_label=MISC_recall_tok: 0.8714511041009464
dev_label=MISC_f-score_tok: 0.8936514355034372
dev_label=ORG_precision_tok: 0.9401373895976447
dev_label=ORG_recall_tok: 0.9158699808795411
dev_label=ORG_f-score_tok: 0.9278450363196126
dev_label=PER_precision_tok: 0.9670398009950248
dev_label=PER_recall_tok: 0.9876151159098127
dev_label=PER_f-score_tok: 0.9772191673212883
dev_precision_macro_tok: 0.9563056118213844
dev_recall_macro_tok: 0.9464264190878302
dev_f-score_macro_tok: 0.9511963841304427
dev_precision_micro_tok: 0.9887660137845099
dev_recall_micro_tok: 0.9887660137845099
dev_f-score_micro_tok: 0.9887660137845099
dev_time: 15.110545873641968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9723    0.9798    0.9761       645
           1     0.9950    0.9931    0.9940      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9837    0.9865    0.9851      3250
weighted avg     0.9905    0.9905    0.9905      3250

F1-macro sent:  0.9850529821711378
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9973    0.9967     42759
         LOC     0.9613    0.9599    0.9606      2094
        MISC     0.9170    0.8715    0.8937      1268
         ORG     0.9401    0.9159    0.9278      2092
         PER     0.9670    0.9876    0.9772      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9563    0.9464    0.9512     51362
weighted avg     0.9886    0.9888    0.9887     51362

F1-macro tok:  0.9511963841304427
F1-micro tok:  0.9887660137845099
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 304007.1298522949
train_cost_avg: 21.651387355052698
train_count_sent: 14041.0
train_total_correct_sent: 13859.0
train_accuracy_sent: 0.9870379602592408
train_count_tok: 203621.0
train_total_correct_tok: 202013.0
train_accuracy_tok: 0.9921029756262861
train_label=0_precision_sent: 0.9683957402954311
train_label=0_recall_sent: 0.9690615331729117
train_label=0_f-score_sent: 0.9687285223367696
train_label=1_precision_sent: 0.9919137466307277
train_label=1_recall_sent: 0.9917355371900827
train_label=1_f-score_sent: 0.9918246339053094
train_precision_macro_sent: 0.9801547434630794
train_recall_macro_sent: 0.9803985351814972
train_f-score_macro_sent: 0.9802765781210395
train_precision_micro_sent: 0.9870379602592408
train_recall_micro_sent: 0.9870379602592408
train_f-score_micro_sent: 0.9870379602592408
train_label=O_precision_tok: 0.9975123791558594
train_label=O_recall_tok: 0.9978770831121961
train_label=O_f-score_tok: 0.9976946978049513
train_label=LOC_precision_tok: 0.9667590027700831
train_label=LOC_recall_tok: 0.9674581173918284
train_label=LOC_f-score_tok: 0.9671084337349398
train_label=MISC_precision_tok: 0.9427816901408451
train_label=MISC_recall_tok: 0.9327237099934683
train_label=MISC_f-score_tok: 0.9377257305461311
train_label=ORG_precision_tok: 0.9551654964894684
train_label=ORG_recall_tok: 0.9499251870324189
train_label=ORG_f-score_tok: 0.9525381345336333
train_label=PER_precision_tok: 0.9818165532067359
train_label=PER_recall_tok: 0.9849928109273903
train_label=PER_f-score_tok: 0.9834021173515162
train_precision_macro_tok: 0.9688070243525984
train_recall_macro_tok: 0.9665953816914603
train_f-score_macro_tok: 0.9676938227942344
train_precision_micro_tok: 0.9921029756262861
train_recall_micro_tok: 0.9921029756262861
train_f-score_micro_tok: 0.9921029756262861
train_time: 140.78626036643982
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9684    0.9691    0.9687      2909
           1     0.9919    0.9917    0.9918     11132

   micro avg     0.9870    0.9870    0.9870     14041
   macro avg     0.9802    0.9804    0.9803     14041
weighted avg     0.9870    0.9870    0.9870     14041

F1-macro sent:  0.9802765781210395
F1-micro sent:  0.9870379602592408
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9975    0.9979    0.9977    169578
         LOC     0.9668    0.9675    0.9671      8297
        MISC     0.9428    0.9327    0.9377      4593
         ORG     0.9552    0.9499    0.9525     10025
         PER     0.9818    0.9850    0.9834     11128

   micro avg     0.9921    0.9921    0.9921    203621
   macro avg     0.9688    0.9666    0.9677    203621
weighted avg     0.9921    0.9921    0.9921    203621

F1-macro tok:  0.9676938227942344
F1-micro tok:  0.9921029756262861
**************************************************
dev_cost_sum: 83552.96668243408
dev_cost_avg: 25.70860513305664
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50787.0
dev_accuracy_tok: 0.9888049530781512
dev_label=0_precision_sent: 0.9708141321044547
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9753086419753086
dev_label=1_precision_sent: 0.9949980761831474
dev_label=1_recall_sent: 0.9927063339731286
dev_label=1_f-score_sent: 0.9938508839354343
dev_precision_macro_sent: 0.982906104143801
dev_recall_macro_sent: 0.9862756476067194
dev_f-score_macro_sent: 0.9845797629553714
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9962857409829938
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9968562646814777
dev_label=LOC_precision_tok: 0.9505183788878416
dev_label=LOC_recall_tok: 0.9632282712511939
dev_label=LOC_f-score_tok: 0.956831119544592
dev_label=MISC_precision_tok: 0.9283333333333333
dev_label=MISC_recall_tok: 0.8785488958990536
dev_label=MISC_f-score_tok: 0.9027552674230146
dev_label=ORG_precision_tok: 0.9479479479479479
dev_label=ORG_recall_tok: 0.9053537284894837
dev_label=ORG_f-score_tok: 0.9261613691931541
dev_label=PER_precision_tok: 0.9625850340136054
dev_label=PER_recall_tok: 0.9885677993013655
dev_label=PER_f-score_tok: 0.975403415321949
dev_precision_macro_tok: 0.9571340870331444
dev_recall_macro_tok: 0.9466252274234026
dev_f-score_macro_tok: 0.9516014872328376
dev_precision_micro_tok: 0.9888049530781512
dev_recall_micro_tok: 0.9888049530781512
dev_f-score_micro_tok: 0.9888049530781512
dev_time: 7.260977745056152
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9708    0.9798    0.9753       645
           1     0.9950    0.9927    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9829    0.9863    0.9846      3250
weighted avg     0.9902    0.9902    0.9902      3250

F1-macro sent:  0.9845797629553714
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9974    0.9969     42759
         LOC     0.9505    0.9632    0.9568      2094
        MISC     0.9283    0.8785    0.9028      1268
         ORG     0.9479    0.9054    0.9262      2092
         PER     0.9626    0.9886    0.9754      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9571    0.9466    0.9516     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9516014872328376
F1-micro tok:  0.9888049530781512
**************************************************
Best epoch: 16
**************************************************

EPOCH: 22
Learning rate: 0.810000
train_cost_sum: 302482.49938964844
train_cost_avg: 21.5428031756747
train_count_sent: 14041.0
train_total_correct_sent: 13882.0
train_accuracy_sent: 0.9886760202264796
train_count_tok: 203621.0
train_total_correct_tok: 202184.0
train_accuracy_tok: 0.9929427711287147
train_label=0_precision_sent: 0.9731589814177564
train_label=0_recall_sent: 0.9721553798556205
train_label=0_f-score_sent: 0.9726569217540842
train_label=1_precision_sent: 0.9927256398742703
train_label=1_recall_sent: 0.99299317283507
train_label=1_f-score_sent: 0.99285938833251
train_precision_macro_sent: 0.9829423106460133
train_recall_macro_sent: 0.9825742763453453
train_f-score_macro_sent: 0.9827581550432971
train_precision_micro_sent: 0.9886760202264796
train_recall_micro_sent: 0.9886760202264796
train_f-score_micro_sent: 0.9886760202264796
train_label=O_precision_tok: 0.9977713972395984
train_label=O_recall_tok: 0.9979773319652313
train_label=O_f-score_tok: 0.9978743539775524
train_label=LOC_precision_tok: 0.9718360933156049
train_label=LOC_recall_tok: 0.9690249487766662
train_label=LOC_f-score_tok: 0.9704284852142426
train_label=MISC_precision_tok: 0.9518657540295871
train_label=MISC_recall_tok: 0.9386022207707381
train_label=MISC_f-score_tok: 0.9451874588905942
train_label=ORG_precision_tok: 0.9596291866028708
train_label=ORG_recall_tok: 0.9602992518703242
train_label=ORG_f-score_tok: 0.9599641023084209
train_label=PER_precision_tok: 0.9818328262036872
train_label=PER_recall_tok: 0.9858914450035945
train_label=PER_f-score_tok: 0.9838579499596449
train_precision_macro_tok: 0.9725870514782697
train_recall_macro_tok: 0.9703590396773109
train_f-score_macro_tok: 0.9714624700700909
train_precision_micro_tok: 0.9929427711287147
train_recall_micro_tok: 0.9929427711287147
train_f-score_micro_tok: 0.9929427711287147
train_time: 88.7582483291626
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9732    0.9722    0.9727      2909
           1     0.9927    0.9930    0.9929     11132

   micro avg     0.9887    0.9887    0.9887     14041
   macro avg     0.9829    0.9826    0.9828     14041
weighted avg     0.9887    0.9887    0.9887     14041

F1-macro sent:  0.9827581550432971
F1-micro sent:  0.9886760202264796
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9978    0.9980    0.9979    169578
         LOC     0.9718    0.9690    0.9704      8297
        MISC     0.9519    0.9386    0.9452      4593
         ORG     0.9596    0.9603    0.9600     10025
         PER     0.9818    0.9859    0.9839     11128

   micro avg     0.9929    0.9929    0.9929    203621
   macro avg     0.9726    0.9704    0.9715    203621
weighted avg     0.9929    0.9929    0.9929    203621

F1-macro tok:  0.9714624700700909
F1-micro tok:  0.9929427711287147
**************************************************
dev_cost_sum: 83166.83178329468
dev_cost_avg: 25.5897943948599
dev_count_sent: 3250.0
dev_total_correct_sent: 3210.0
dev_accuracy_sent: 0.9876923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50807.0
dev_accuracy_tok: 0.9891943460145632
dev_label=0_precision_sent: 0.9562594268476622
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9694189602446484
dev_label=1_precision_sent: 0.9957479706223424
dev_label=1_recall_sent: 0.9888675623800384
dev_label=1_f-score_sent: 0.9922958397534669
dev_precision_macro_sent: 0.9760036987350023
dev_recall_macro_sent: 0.9859066494070734
dev_f-score_macro_sent: 0.9808573999990576
dev_precision_micro_sent: 0.9876923076923076
dev_recall_micro_sent: 0.9876923076923076
dev_f-score_micro_sent: 0.9876923076923076
dev_label=O_precision_tok: 0.9967272132220586
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.99693696221474
dev_label=LOC_precision_tok: 0.9581550166428912
dev_label=LOC_recall_tok: 0.9622731614135626
dev_label=LOC_f-score_tok: 0.960209673576364
dev_label=MISC_precision_tok: 0.8964980544747082
dev_label=MISC_recall_tok: 0.9085173501577287
dev_label=MISC_f-score_tok: 0.9024676850763808
dev_label=ORG_precision_tok: 0.9494747373686844
dev_label=ORG_recall_tok: 0.9072657743785851
dev_label=ORG_f-score_tok: 0.9278904913224152
dev_label=PER_precision_tok: 0.9709193245778611
dev_label=PER_recall_tok: 0.9860273102572246
dev_label=PER_f-score_tok: 0.9784149992122262
dev_precision_macro_tok: 0.9543548692572406
dev_recall_macro_tok: 0.9522460791422598
dev_f-score_macro_tok: 0.9531839622804252
dev_precision_micro_tok: 0.9891943460145632
dev_recall_micro_tok: 0.9891943460145632
dev_f-score_micro_tok: 0.9891943460145632
dev_time: 7.328612804412842
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9563    0.9829    0.9694       645
           1     0.9957    0.9889    0.9923      2605

   micro avg     0.9877    0.9877    0.9877      3250
   macro avg     0.9760    0.9859    0.9809      3250
weighted avg     0.9879    0.9877    0.9878      3250

F1-macro sent:  0.9808573999990576
F1-micro sent:  0.9876923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9971    0.9969     42759
         LOC     0.9582    0.9623    0.9602      2094
        MISC     0.8965    0.9085    0.9025      1268
         ORG     0.9495    0.9073    0.9279      2092
         PER     0.9709    0.9860    0.9784      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9544    0.9522    0.9532     51362
weighted avg     0.9892    0.9892    0.9892     51362

F1-macro tok:  0.9531839622804252
F1-micro tok:  0.9891943460145632
**************************************************
Best epoch: 16
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 301241.22076416016
train_cost_avg: 21.4543993137355
train_count_sent: 14041.0
train_total_correct_sent: 13883.0
train_accuracy_sent: 0.9887472402250552
train_count_tok: 203621.0
train_total_correct_tok: 202259.0
train_accuracy_tok: 0.9933111024894289
train_label=0_precision_sent: 0.9734939759036144
train_label=0_recall_sent: 0.9721553798556205
train_label=0_f-score_sent: 0.9728242174062607
train_label=1_precision_sent: 0.9927262931034483
train_label=1_recall_sent: 0.9930830039525692
train_label=1_f-score_sent: 0.9929046164900305
train_precision_macro_sent: 0.9831101345035314
train_recall_macro_sent: 0.9826191919040949
train_f-score_macro_sent: 0.9828644169481455
train_precision_micro_sent: 0.9887472402250552
train_recall_micro_sent: 0.9887472402250552
train_f-score_micro_sent: 0.9887472402250552
train_label=O_precision_tok: 0.9978717383358291
train_label=O_recall_tok: 0.9981306537404616
train_label=O_f-score_tok: 0.998001179245283
train_label=LOC_precision_tok: 0.9703089313619425
train_label=LOC_recall_tok: 0.9728817644931903
train_label=LOC_f-score_tok: 0.9715936446798267
train_label=MISC_precision_tok: 0.9513584574934268
train_label=MISC_recall_tok: 0.9453516220335293
train_label=MISC_f-score_tok: 0.9483455280113574
train_label=ORG_precision_tok: 0.9632706164931946
train_label=ORG_recall_tok: 0.9600997506234414
train_label=ORG_f-score_tok: 0.9616825698156567
train_label=PER_precision_tok: 0.9851672060409924
train_label=PER_recall_tok: 0.9848130841121495
train_label=PER_f-score_tok: 0.9849901132482473
train_precision_macro_tok: 0.973595389945077
train_recall_macro_tok: 0.9722553750005544
train_f-score_macro_tok: 0.9729226070000742
train_precision_micro_tok: 0.9933111024894289
train_recall_micro_tok: 0.9933111024894289
train_f-score_micro_tok: 0.9933111024894289
train_time: 87.89426469802856
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9735    0.9722    0.9728      2909
           1     0.9927    0.9931    0.9929     11132

   micro avg     0.9887    0.9887    0.9887     14041
   macro avg     0.9831    0.9826    0.9829     14041
weighted avg     0.9887    0.9887    0.9887     14041

F1-macro sent:  0.9828644169481455
F1-micro sent:  0.9887472402250552
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9979    0.9981    0.9980    169578
         LOC     0.9703    0.9729    0.9716      8297
        MISC     0.9514    0.9454    0.9483      4593
         ORG     0.9633    0.9601    0.9617     10025
         PER     0.9852    0.9848    0.9850     11128

   micro avg     0.9933    0.9933    0.9933    203621
   macro avg     0.9736    0.9723    0.9729    203621
weighted avg     0.9933    0.9933    0.9933    203621

F1-macro tok:  0.9729226070000742
F1-micro tok:  0.9933111024894289
**************************************************
dev_cost_sum: 83116.53687286377
dev_cost_avg: 25.574319037804237
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50805.0
dev_accuracy_tok: 0.9891554067209221
dev_label=0_precision_sent: 0.9782608695652174
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9775019394879751
dev_label=1_precision_sent: 0.9942440521872602
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9944348493571291
dev_precision_macro_sent: 0.9862524608762389
dev_recall_macro_sent: 0.9856849529080927
dev_f-score_macro_sent: 0.9859683944225521
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9966573946378064
dev_label=O_recall_tok: 0.9971701863935079
dev_label=O_f-score_tok: 0.9969137245732991
dev_label=LOC_precision_tok: 0.9538606403013182
dev_label=LOC_recall_tok: 0.9675262655205349
dev_label=LOC_f-score_tok: 0.9606448553816975
dev_label=MISC_precision_tok: 0.9101123595505618
dev_label=MISC_recall_tok: 0.8943217665615142
dev_label=MISC_f-score_tok: 0.9021479713603819
dev_label=ORG_precision_tok: 0.9481296758104738
dev_label=ORG_recall_tok: 0.9086998087954111
dev_label=ORG_f-score_tok: 0.9279960947034415
dev_label=PER_precision_tok: 0.9688084840923269
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9774980330448466
dev_precision_macro_tok: 0.9555137108784976
dev_recall_macro_tok: 0.9508125797317419
dev_f-score_macro_tok: 0.9530401358127332
dev_precision_micro_tok: 0.9891554067209221
dev_recall_micro_tok: 0.9891554067209221
dev_f-score_micro_tok: 0.9891554067209221
dev_time: 7.283057928085327
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9783    0.9767    0.9775       645
           1     0.9942    0.9946    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9863    0.9857    0.9860      3250
weighted avg     0.9911    0.9911    0.9911      3250

F1-macro sent:  0.9859683944225521
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9972    0.9969     42759
         LOC     0.9539    0.9675    0.9606      2094
        MISC     0.9101    0.8943    0.9021      1268
         ORG     0.9481    0.9087    0.9280      2092
         PER     0.9688    0.9863    0.9775      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9555    0.9508    0.9530     51362
weighted avg     0.9891    0.9892    0.9891     51362

F1-macro tok:  0.9530401358127332
F1-micro tok:  0.9891554067209221
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 0.729000
train_cost_sum: 300245.1262207031
train_cost_avg: 21.38345746176933
train_count_sent: 14041.0
train_total_correct_sent: 13898.0
train_accuracy_sent: 0.9898155402036892
train_count_tok: 203621.0
train_total_correct_tok: 202271.0
train_accuracy_tok: 0.9933700355071432
train_label=0_precision_sent: 0.9736301369863014
train_label=0_recall_sent: 0.9773117909934685
train_label=0_f-score_sent: 0.9754674901355292
train_label=1_precision_sent: 0.9940652818991098
train_label=1_recall_sent: 0.9930830039525692
train_label=1_f-score_sent: 0.9935739001482946
train_precision_macro_sent: 0.9838477094427056
train_recall_macro_sent: 0.9851973974730188
train_f-score_macro_sent: 0.9845206951419119
train_precision_micro_sent: 0.9898155402036892
train_recall_micro_sent: 0.9898155402036892
train_f-score_micro_sent: 0.9898155402036892
train_label=O_precision_tok: 0.997812783719093
train_label=O_recall_tok: 0.9980716838269115
train_label=O_f-score_tok: 0.9979422169811321
train_label=LOC_precision_tok: 0.9719074029418857
train_label=LOC_recall_tok: 0.9715559840906351
train_label=LOC_f-score_tok: 0.9717316617443191
train_label=MISC_precision_tok: 0.9523181718303669
train_label=MISC_recall_tok: 0.9436098410624864
train_label=MISC_f-score_tok: 0.9479440069991251
train_label=ORG_precision_tok: 0.9625224865080951
train_label=ORG_recall_tok: 0.9606982543640897
train_label=ORG_f-score_tok: 0.9616095052668363
train_label=PER_precision_tok: 0.9861858629350556
train_label=PER_recall_tok: 0.9879583033788641
train_label=PER_f-score_tok: 0.987071287484288
train_precision_macro_tok: 0.9741493415868993
train_recall_macro_tok: 0.9723788133445973
train_f-score_macro_tok: 0.9732597356951402
train_precision_micro_tok: 0.9933700355071432
train_recall_micro_tok: 0.9933700355071432
train_f-score_micro_tok: 0.9933700355071432
train_time: 88.79787564277649
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9736    0.9773    0.9755      2909
           1     0.9941    0.9931    0.9936     11132

   micro avg     0.9898    0.9898    0.9898     14041
   macro avg     0.9838    0.9852    0.9845     14041
weighted avg     0.9898    0.9898    0.9898     14041

F1-macro sent:  0.9845206951419119
F1-micro sent:  0.9898155402036892
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9978    0.9981    0.9979    169578
         LOC     0.9719    0.9716    0.9717      8297
        MISC     0.9523    0.9436    0.9479      4593
         ORG     0.9625    0.9607    0.9616     10025
         PER     0.9862    0.9880    0.9871     11128

   micro avg     0.9934    0.9934    0.9934    203621
   macro avg     0.9741    0.9724    0.9733    203621
weighted avg     0.9934    0.9934    0.9934    203621

F1-macro tok:  0.9732597356951402
F1-micro tok:  0.9933700355071432
**************************************************
dev_cost_sum: 82946.95259475708
dev_cost_avg: 25.522139259925254
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50792.0
dev_accuracy_tok: 0.9889023013122542
dev_label=0_precision_sent: 0.9813084112149533
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.979020979020979
dev_label=1_precision_sent: 0.9942484662576687
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9948206407059275
dev_precision_macro_sent: 0.987778438736311
dev_recall_macro_sent: 0.9860688300674016
dev_f-score_macro_sent: 0.9869208098634532
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9963553104995093
dev_label=O_recall_tok: 0.9973572815079866
dev_label=O_f-score_tok: 0.9968560442257571
dev_label=LOC_precision_tok: 0.9475164011246485
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.956480605487228
dev_label=MISC_precision_tok: 0.9156528791565288
dev_label=MISC_recall_tok: 0.8903785488958991
dev_label=MISC_f-score_tok: 0.9028388644542182
dev_label=ORG_precision_tok: 0.9436970602889886
dev_label=ORG_recall_tok: 0.9053537284894837
dev_label=ORG_f-score_tok: 0.924127836057575
dev_label=PER_precision_tok: 0.9733207784055242
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9790055248618785
dev_precision_macro_tok: 0.9553084858950399
dev_recall_macro_tok: 0.9486925340947592
dev_f-score_macro_tok: 0.9518617750173315
dev_precision_micro_tok: 0.9889023013122542
dev_recall_micro_tok: 0.9889023013122542
dev_f-score_micro_tok: 0.9889023013122542
dev_time: 7.314802169799805
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9813    0.9767    0.9790       645
           1     0.9942    0.9954    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9878    0.9861    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9869208098634532
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9974    0.9969     42759
         LOC     0.9475    0.9656    0.9565      2094
        MISC     0.9157    0.8904    0.9028      1268
         ORG     0.9437    0.9054    0.9241      2092
         PER     0.9733    0.9848    0.9790      3149

   micro avg     0.9889    0.9889    0.9889     51362
   macro avg     0.9553    0.9487    0.9519     51362
weighted avg     0.9888    0.9889    0.9888     51362

F1-macro tok:  0.9518617750173315
F1-micro tok:  0.9889023013122542
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 0.729000
train_cost_sum: 299025.4108886719
train_cost_avg: 21.296589337559425
train_count_sent: 14041.0
train_total_correct_sent: 13907.0
train_accuracy_sent: 0.9904565201908696
train_count_tok: 203621.0
train_total_correct_tok: 202379.0
train_accuracy_tok: 0.9939004326665717
train_label=0_precision_sent: 0.9750085587127696
train_label=0_recall_sent: 0.9790305947060846
train_label=0_f-score_sent: 0.9770154373927958
train_label=1_precision_sent: 0.9945143884892086
train_label=1_recall_sent: 0.9934423284225655
train_label=1_f-score_sent: 0.9939780693870214
train_precision_macro_sent: 0.9847614736009891
train_recall_macro_sent: 0.9862364615643251
train_f-score_macro_sent: 0.9854967533899086
train_precision_micro_sent: 0.9904565201908696
train_recall_micro_sent: 0.9904565201908696
train_f-score_micro_sent: 0.9904565201908696
train_label=O_precision_tok: 0.9979544436322478
train_label=O_recall_tok: 0.9982957694984019
train_label=O_f-score_tok: 0.9981250773847777
train_label=LOC_precision_tok: 0.9750271444082519
train_label=LOC_recall_tok: 0.9740870194046041
train_label=LOC_f-score_tok: 0.9745568551790667
train_label=MISC_precision_tok: 0.9552238805970149
train_label=MISC_recall_tok: 0.9475288482473329
train_label=MISC_f-score_tok: 0.9513608044595038
train_label=ORG_precision_tok: 0.9671328671328672
train_label=ORG_recall_tok: 0.9656857855361596
train_label=ORG_f-score_tok: 0.9664087846269029
train_label=PER_precision_tok: 0.9860736747529201
train_label=PER_recall_tok: 0.9862508986340762
train_label=PER_f-score_tok: 0.9861622787312427
train_precision_macro_tok: 0.9762824021046604
train_recall_macro_tok: 0.9743696642641151
train_f-score_macro_tok: 0.9753227600762987
train_precision_micro_tok: 0.9939004326665717
train_recall_micro_tok: 0.9939004326665717
train_f-score_micro_tok: 0.9939004326665717
train_time: 88.53415274620056
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9750    0.9790    0.9770      2909
           1     0.9945    0.9934    0.9940     11132

   micro avg     0.9905    0.9905    0.9905     14041
   macro avg     0.9848    0.9862    0.9855     14041
weighted avg     0.9905    0.9905    0.9905     14041

F1-macro sent:  0.9854967533899086
F1-micro sent:  0.9904565201908696
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9983    0.9981    169578
         LOC     0.9750    0.9741    0.9746      8297
        MISC     0.9552    0.9475    0.9514      4593
         ORG     0.9671    0.9657    0.9664     10025
         PER     0.9861    0.9863    0.9862     11128

   micro avg     0.9939    0.9939    0.9939    203621
   macro avg     0.9763    0.9744    0.9753    203621
weighted avg     0.9939    0.9939    0.9939    203621

F1-macro tok:  0.9753227600762987
F1-micro tok:  0.9939004326665717
**************************************************
dev_cost_sum: 82744.06059646606
dev_cost_avg: 25.45971095275879
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50809.0
dev_accuracy_tok: 0.9892332853082045
dev_label=0_precision_sent: 0.9709035222052067
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9768875192604006
dev_label=1_precision_sent: 0.9957643434732384
dev_label=1_recall_sent: 0.9927063339731286
dev_label=1_f-score_sent: 0.9942329873125721
dev_precision_macro_sent: 0.9833339328392225
dev_recall_macro_sent: 0.9878260352036186
dev_f-score_macro_sent: 0.9855602532864864
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9968207214157141
dev_label=O_recall_tok: 0.9972403470614374
dev_label=O_f-score_tok: 0.9970304900860458
dev_label=LOC_precision_tok: 0.9560283687943263
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.9607982893799003
dev_label=MISC_precision_tok: 0.9044233807266983
dev_label=MISC_recall_tok: 0.9029968454258676
dev_label=MISC_f-score_tok: 0.9037095501183898
dev_label=ORG_precision_tok: 0.9479739869934968
dev_label=ORG_recall_tok: 0.905831739961759
dev_label=ORG_f-score_tok: 0.9264238572476167
dev_label=PER_precision_tok: 0.9691107644305772
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9776518728360087
dev_precision_macro_tok: 0.9548714444721625
dev_recall_macro_tok: 0.9516059699364157
dev_f-score_macro_tok: 0.9531228119335923
dev_precision_micro_tok: 0.9892332853082045
dev_recall_micro_tok: 0.9892332853082045
dev_f-score_micro_tok: 0.9892332853082045
dev_time: 7.298922777175903
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9709    0.9829    0.9769       645
           1     0.9958    0.9927    0.9942      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9833    0.9878    0.9856      3250
weighted avg     0.9908    0.9908    0.9908      3250

F1-macro sent:  0.9855602532864864
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9968    0.9972    0.9970     42759
         LOC     0.9560    0.9656    0.9608      2094
        MISC     0.9044    0.9030    0.9037      1268
         ORG     0.9480    0.9058    0.9264      2092
         PER     0.9691    0.9863    0.9777      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9549    0.9516    0.9531     51362
weighted avg     0.9892    0.9892    0.9892     51362

F1-macro tok:  0.9531228119335923
F1-micro tok:  0.9892332853082045
**************************************************
Best epoch: 24
**************************************************

EPOCH: 26
Learning rate: 0.729000
train_cost_sum: 298196.1003112793
train_cost_avg: 21.237525839418794
train_count_sent: 14041.0
train_total_correct_sent: 13893.0
train_accuracy_sent: 0.9894594402108112
train_count_tok: 203621.0
train_total_correct_tok: 202382.0
train_accuracy_tok: 0.9939151659210003
train_label=0_precision_sent: 0.9748882008943929
train_label=0_recall_sent: 0.9742179443107597
train_label=0_f-score_sent: 0.9745529573590097
train_label=1_precision_sent: 0.9932638764145859
train_label=1_recall_sent: 0.9934423284225655
train_label=1_f-score_sent: 0.993353094404024
train_precision_macro_sent: 0.9840760386544893
train_recall_macro_sent: 0.9838301363666626
train_f-score_macro_sent: 0.9839530258815168
train_precision_micro_sent: 0.9894594402108112
train_recall_micro_sent: 0.9894594402108112
train_f-score_micro_sent: 0.9894594402108112
train_label=O_precision_tok: 0.9979717339905544
train_label=O_recall_tok: 0.9981188597577516
train_label=O_f-score_tok: 0.9980452914520566
train_label=LOC_precision_tok: 0.9724461556972687
train_label=LOC_recall_tok: 0.9740870194046041
train_label=LOC_f-score_tok: 0.9732658959537572
train_label=MISC_precision_tok: 0.9566739606126915
train_label=MISC_recall_tok: 0.9518833006749401
train_label=MISC_f-score_tok: 0.9542726181381644
train_label=ORG_precision_tok: 0.9685968596859686
train_label=ORG_recall_tok: 0.9660847880299251
train_label=ORG_f-score_tok: 0.967339192968438
train_label=PER_precision_tok: 0.9861734602262525
train_label=PER_recall_tok: 0.98705966930266
train_label=PER_f-score_tok: 0.9866163657594539
train_precision_macro_tok: 0.976372434042547
train_recall_macro_tok: 0.9754467274339762
train_f-score_macro_tok: 0.975907872854374
train_precision_micro_tok: 0.9939151659210003
train_recall_micro_tok: 0.9939151659210003
train_f-score_micro_tok: 0.9939151659210003
train_time: 133.89391493797302
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9749    0.9742    0.9746      2909
           1     0.9933    0.9934    0.9934     11132

   micro avg     0.9895    0.9895    0.9895     14041
   macro avg     0.9841    0.9838    0.9840     14041
weighted avg     0.9895    0.9895    0.9895     14041

F1-macro sent:  0.9839530258815168
F1-micro sent:  0.9894594402108112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9981    0.9980    169578
         LOC     0.9724    0.9741    0.9733      8297
        MISC     0.9567    0.9519    0.9543      4593
         ORG     0.9686    0.9661    0.9673     10025
         PER     0.9862    0.9871    0.9866     11128

   micro avg     0.9939    0.9939    0.9939    203621
   macro avg     0.9764    0.9754    0.9759    203621
weighted avg     0.9939    0.9939    0.9939    203621

F1-macro tok:  0.975907872854374
F1-micro tok:  0.9939151659210003
**************************************************
dev_cost_sum: 82620.93515396118
dev_cost_avg: 25.421826201218824
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50808.0
dev_accuracy_tok: 0.9892138156613839
dev_label=0_precision_sent: 0.9678407350689127
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9738058551617874
dev_label=1_precision_sent: 0.9949942241047363
dev_label=1_recall_sent: 0.9919385796545106
dev_label=1_f-score_sent: 0.9934640522875817
dev_precision_macro_sent: 0.9814174795868245
dev_recall_macro_sent: 0.9858917704474104
dev_f-score_macro_sent: 0.9836349537246846
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9962631664992877
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.9969383939422267
dev_label=LOC_precision_tok: 0.9649207111965401
dev_label=LOC_recall_tok: 0.958930276981853
dev_label=LOC_f-score_tok: 0.9619161676646707
dev_label=MISC_precision_tok: 0.8850837138508372
dev_label=MISC_recall_tok: 0.917192429022082
dev_label=MISC_f-score_tok: 0.9008520526723469
dev_label=ORG_precision_tok: 0.9585677749360614
dev_label=ORG_recall_tok: 0.8957934990439771
dev_label=ORG_f-score_tok: 0.926118112181863
dev_label=PER_precision_tok: 0.9721439749608763
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9791929382093316
dev_precision_macro_tok: 0.9553958682887206
dev_recall_macro_tok: 0.9511751227452099
dev_f-score_macro_tok: 0.9530035329340878
dev_precision_micro_tok: 0.9892138156613839
dev_recall_micro_tok: 0.9892138156613839
dev_f-score_micro_tok: 0.9892138156613839
dev_time: 14.896644830703735
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9678    0.9798    0.9738       645
           1     0.9950    0.9919    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9814    0.9859    0.9836      3250
weighted avg     0.9896    0.9895    0.9896      3250

F1-macro sent:  0.9836349537246846
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9976    0.9969     42759
         LOC     0.9649    0.9589    0.9619      2094
        MISC     0.8851    0.9172    0.9009      1268
         ORG     0.9586    0.8958    0.9261      2092
         PER     0.9721    0.9863    0.9792      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9554    0.9512    0.9530     51362
weighted avg     0.9892    0.9892    0.9892     51362

F1-macro tok:  0.9530035329340878
F1-micro tok:  0.9892138156613839
**************************************************
Best epoch: 24
**************************************************

EPOCH: 27
Learning rate: 0.729000
train_cost_sum: 297196.83685302734
train_cost_avg: 21.166358297345443
train_count_sent: 14041.0
train_total_correct_sent: 13902.0
train_accuracy_sent: 0.9901004201979916
train_count_tok: 203621.0
train_total_correct_tok: 202456.0
train_accuracy_tok: 0.994278586196905
train_label=0_precision_sent: 0.9766001376462491
train_label=0_recall_sent: 0.9755929872808525
train_label=0_f-score_sent: 0.9760963026655202
train_label=1_precision_sent: 0.9936237090255949
train_label=1_recall_sent: 0.9938914840100611
train_label=1_f-score_sent: 0.9937575784793641
train_precision_macro_sent: 0.985111923335922
train_recall_macro_sent: 0.9847422356454568
train_f-score_macro_sent: 0.9849269405724421
train_precision_micro_sent: 0.9901004201979916
train_recall_micro_sent: 0.9901004201979916
train_f-score_micro_sent: 0.9901004201979916
train_label=O_precision_tok: 0.9981251326557083
train_label=O_recall_tok: 0.998325254455177
train_label=O_f-score_tok: 0.9982251835254576
train_label=LOC_precision_tok: 0.9769740807715491
train_label=LOC_recall_tok: 0.9767385802097144
train_label=LOC_f-score_tok: 0.9768563162970108
train_label=MISC_precision_tok: 0.9533667465678797
train_label=MISC_recall_tok: 0.9525364685390812
train_label=MISC_f-score_tok: 0.9529514267044216
train_label=ORG_precision_tok: 0.9693601682186843
train_label=ORG_recall_tok: 0.9656857855361596
train_label=ORG_f-score_tok: 0.9675194883070158
train_label=PER_precision_tok: 0.9877895492907165
train_label=PER_recall_tok: 0.9886772106398275
train_label=PER_f-score_tok: 0.9882331806341507
train_precision_macro_tok: 0.9771231355009075
train_recall_macro_tok: 0.976392659875992
train_f-score_macro_tok: 0.9767571190936113
train_precision_micro_tok: 0.994278586196905
train_recall_micro_tok: 0.994278586196905
train_f-score_micro_tok: 0.994278586196905
train_time: 154.4734492301941
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9766    0.9756    0.9761      2909
           1     0.9936    0.9939    0.9938     11132

   micro avg     0.9901    0.9901    0.9901     14041
   macro avg     0.9851    0.9847    0.9849     14041
weighted avg     0.9901    0.9901    0.9901     14041

F1-macro sent:  0.9849269405724421
F1-micro sent:  0.9901004201979916
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9981    0.9983    0.9982    169578
         LOC     0.9770    0.9767    0.9769      8297
        MISC     0.9534    0.9525    0.9530      4593
         ORG     0.9694    0.9657    0.9675     10025
         PER     0.9878    0.9887    0.9882     11128

   micro avg     0.9943    0.9943    0.9943    203621
   macro avg     0.9771    0.9764    0.9768    203621
weighted avg     0.9943    0.9943    0.9943    203621

F1-macro tok:  0.9767571190936113
F1-micro tok:  0.994278586196905
**************************************************
dev_cost_sum: 82364.22184371948
dev_cost_avg: 25.342837490375224
dev_count_sent: 3250.0
dev_total_correct_sent: 3220.0
dev_accuracy_sent: 0.9907692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50826.0
dev_accuracy_tok: 0.9895642693041549
dev_label=0_precision_sent: 0.9709035222052067
dev_label=0_recall_sent: 0.9829457364341085
dev_label=0_f-score_sent: 0.9768875192604006
dev_label=1_precision_sent: 0.9957643434732384
dev_label=1_recall_sent: 0.9927063339731286
dev_label=1_f-score_sent: 0.9942329873125721
dev_precision_macro_sent: 0.9833339328392225
dev_recall_macro_sent: 0.9878260352036186
dev_f-score_macro_sent: 0.9855602532864864
dev_precision_micro_sent: 0.9907692307692307
dev_recall_micro_sent: 0.9907692307692307
dev_f-score_micro_sent: 0.9907692307692307
dev_label=O_precision_tok: 0.9965190982361873
dev_label=O_recall_tok: 0.9975911504010851
dev_label=O_f-score_tok: 0.9970548361460426
dev_label=LOC_precision_tok: 0.9555765595463138
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.9605700712589074
dev_label=MISC_precision_tok: 0.9196428571428571
dev_label=MISC_recall_tok: 0.8935331230283912
dev_label=MISC_f-score_tok: 0.9063999999999999
dev_label=ORG_precision_tok: 0.9452122408687068
dev_label=ORG_recall_tok: 0.9153919694072657
dev_label=ORG_f-score_tok: 0.9300631374453618
dev_label=PER_precision_tok: 0.9739239710964499
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9791535060012634
dev_precision_macro_tok: 0.9581749453781031
dev_recall_macro_tok: 0.9513143586573299
dev_f-score_macro_tok: 0.9546483101703152
dev_precision_micro_tok: 0.9895642693041549
dev_recall_micro_tok: 0.9895642693041549
dev_f-score_micro_tok: 0.9895642693041549
dev_time: 15.023770809173584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9709    0.9829    0.9769       645
           1     0.9958    0.9927    0.9942      2605

   micro avg     0.9908    0.9908    0.9908      3250
   macro avg     0.9833    0.9878    0.9856      3250
weighted avg     0.9908    0.9908    0.9908      3250

F1-macro sent:  0.9855602532864864
F1-micro sent:  0.9907692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9976    0.9971     42759
         LOC     0.9556    0.9656    0.9606      2094
        MISC     0.9196    0.8935    0.9064      1268
         ORG     0.9452    0.9154    0.9301      2092
         PER     0.9739    0.9844    0.9792      3149

   micro avg     0.9896    0.9896    0.9896     51362
   macro avg     0.9582    0.9513    0.9546     51362
weighted avg     0.9895    0.9896    0.9895     51362

F1-macro tok:  0.9546483101703152
F1-micro tok:  0.9895642693041549
**************************************************
Best epoch: 24
**************************************************

EPOCH: 28
Learning rate: 0.729000
train_cost_sum: 296300.5252380371
train_cost_avg: 21.102522985402544
train_count_sent: 14041.0
train_total_correct_sent: 13905.0
train_accuracy_sent: 0.9903140801937184
train_count_tok: 203621.0
train_total_correct_tok: 202494.0
train_accuracy_tok: 0.9944652074196669
train_label=0_precision_sent: 0.9756432246998284
train_label=0_recall_sent: 0.9776555517359917
train_label=0_f-score_sent: 0.9766483516483515
train_label=1_precision_sent: 0.9941578285097968
train_label=1_recall_sent: 0.9936219906575637
train_label=1_f-score_sent: 0.9938898373618474
train_precision_macro_sent: 0.9849005266048126
train_recall_macro_sent: 0.9856387711967778
train_f-score_macro_sent: 0.9852690945050995
train_precision_micro_sent: 0.9903140801937184
train_recall_micro_sent: 0.9903140801937184
train_f-score_micro_sent: 0.9903140801937184
train_label=O_precision_tok: 0.9981900612549301
train_label=O_recall_tok: 0.9984314002995671
train_label=O_f-score_tok: 0.9983107161914758
train_label=LOC_precision_tok: 0.9771849348140995
train_label=LOC_recall_tok: 0.975653850789442
train_label=LOC_f-score_tok: 0.9764187925939328
train_label=MISC_precision_tok: 0.9588351215239763
train_label=MISC_recall_tok: 0.9534073590246026
train_label=MISC_f-score_tok: 0.9561135371179039
train_label=ORG_precision_tok: 0.969224620303757
train_label=ORG_recall_tok: 0.9675810473815462
train_label=ORG_f-score_tok: 0.9684021364748165
train_label=PER_precision_tok: 0.9878847707080678
train_label=PER_recall_tok: 0.9892163910855499
train_label=PER_f-score_tok: 0.9885501324592518
train_precision_macro_tok: 0.9782639017209661
train_recall_macro_tok: 0.9768580097161417
train_f-score_macro_tok: 0.9775590629674762
train_precision_micro_tok: 0.9944652074196669
train_recall_micro_tok: 0.9944652074196669
train_f-score_micro_tok: 0.9944652074196669
train_time: 154.00840020179749
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9756    0.9777    0.9766      2909
           1     0.9942    0.9936    0.9939     11132

   micro avg     0.9903    0.9903    0.9903     14041
   macro avg     0.9849    0.9856    0.9853     14041
weighted avg     0.9903    0.9903    0.9903     14041

F1-macro sent:  0.9852690945050995
F1-micro sent:  0.9903140801937184
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9984    0.9983    169578
         LOC     0.9772    0.9757    0.9764      8297
        MISC     0.9588    0.9534    0.9561      4593
         ORG     0.9692    0.9676    0.9684     10025
         PER     0.9879    0.9892    0.9886     11128

   micro avg     0.9945    0.9945    0.9945    203621
   macro avg     0.9783    0.9769    0.9776    203621
weighted avg     0.9945    0.9945    0.9945    203621

F1-macro tok:  0.9775590629674762
F1-micro tok:  0.9944652074196669
**************************************************
dev_cost_sum: 82288.78522491455
dev_cost_avg: 25.31962622305063
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50812.0
dev_accuracy_tok: 0.9892916942486664
dev_label=0_precision_sent: 0.9858044164037855
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.977326035965598
dev_label=1_precision_sent: 0.9923547400611621
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9944455085232714
dev_precision_macro_sent: 0.9890795782324737
dev_recall_macro_sent: 0.9827686768141171
dev_f-score_macro_sent: 0.9858857722444347
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9961469303878757
dev_label=O_recall_tok: 0.9976379241797049
dev_label=O_f-score_tok: 0.9968918697857027
dev_label=LOC_precision_tok: 0.9654344695151225
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9628920277711276
dev_label=MISC_precision_tok: 0.8843797856049005
dev_label=MISC_recall_tok: 0.9108832807570978
dev_label=MISC_f-score_tok: 0.8974358974358975
dev_label=ORG_precision_tok: 0.959349593495935
dev_label=ORG_recall_tok: 0.9024856596558317
dev_label=ORG_f-score_tok: 0.9300492610837439
dev_label=PER_precision_tok: 0.9742300439974858
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9793081661664823
dev_precision_macro_tok: 0.9559081646002638
dev_recall_macro_tok: 0.9511618621871142
dev_f-score_macro_tok: 0.9533154444485907
dev_precision_micro_tok: 0.9892916942486664
dev_recall_micro_tok: 0.9892916942486664
dev_f-score_micro_tok: 0.9892916942486664
dev_time: 14.96107029914856
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9858    0.9690    0.9773       645
           1     0.9924    0.9965    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9891    0.9828    0.9859      3250
weighted avg     0.9911    0.9911    0.9910      3250

F1-macro sent:  0.9858857722444347
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9976    0.9969     42759
         LOC     0.9654    0.9604    0.9629      2094
        MISC     0.8844    0.9109    0.8974      1268
         ORG     0.9593    0.9025    0.9300      2092
         PER     0.9742    0.9844    0.9793      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9559    0.9512    0.9533     51362
weighted avg     0.9893    0.9893    0.9892     51362

F1-macro tok:  0.9533154444485907
F1-micro tok:  0.9892916942486664
**************************************************
Best epoch: 24
**************************************************

EPOCH: 29
Learning rate: 0.656100
train_cost_sum: 295562.38552856445
train_cost_avg: 21.049952676345306
train_count_sent: 14041.0
train_total_correct_sent: 13914.0
train_accuracy_sent: 0.9909550601808989
train_count_tok: 203621.0
train_total_correct_tok: 202535.0
train_accuracy_tok: 0.9946665618968574
train_label=0_precision_sent: 0.9786648313833448
train_label=0_recall_sent: 0.9776555517359917
train_label=0_f-score_sent: 0.9781599312123818
train_label=1_precision_sent: 0.9941625505163898
train_label=1_recall_sent: 0.9944304707150557
train_label=1_f-score_sent: 0.9942964925674767
train_precision_macro_sent: 0.9864136909498673
train_recall_macro_sent: 0.9860430112255237
train_f-score_macro_sent: 0.9862282118899293
train_precision_micro_sent: 0.9909550601808989
train_recall_micro_sent: 0.9909550601808989
train_f-score_micro_sent: 0.9909550601808989
train_label=O_precision_tok: 0.9981959674566678
train_label=O_recall_tok: 0.9984431942822772
train_label=O_f-score_tok: 0.9983195655634763
train_label=LOC_precision_tok: 0.9793328498912255
train_label=LOC_recall_tok: 0.976618054718573
train_label=LOC_f-score_tok: 0.9779735682819383
train_label=MISC_precision_tok: 0.9616480385711155
train_label=MISC_recall_tok: 0.9553668626170259
train_label=MISC_f-score_tok: 0.9584971603320227
train_label=ORG_precision_tok: 0.9694854407658556
train_label=ORG_recall_tok: 0.9697755610972568
train_label=ORG_f-score_tok: 0.9696304792300404
train_label=PER_precision_tok: 0.9885057471264368
train_label=PER_recall_tok: 0.9892163910855499
train_label=PER_f-score_tok: 0.9888609414301114
train_precision_macro_tok: 0.9794336087622602
train_recall_macro_tok: 0.9778840127601367
train_f-score_macro_tok: 0.9786563429675178
train_precision_micro_tok: 0.9946665618968574
train_recall_micro_tok: 0.9946665618968574
train_f-score_micro_tok: 0.9946665618968574
train_time: 153.75646138191223
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9787    0.9777    0.9782      2909
           1     0.9942    0.9944    0.9943     11132

   micro avg     0.9910    0.9910    0.9910     14041
   macro avg     0.9864    0.9860    0.9862     14041
weighted avg     0.9910    0.9910    0.9910     14041

F1-macro sent:  0.9862282118899293
F1-micro sent:  0.9909550601808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9984    0.9983    169578
         LOC     0.9793    0.9766    0.9780      8297
        MISC     0.9616    0.9554    0.9585      4593
         ORG     0.9695    0.9698    0.9696     10025
         PER     0.9885    0.9892    0.9889     11128

   micro avg     0.9947    0.9947    0.9947    203621
   macro avg     0.9794    0.9779    0.9787    203621
weighted avg     0.9947    0.9947    0.9947    203621

F1-macro tok:  0.9786563429675178
F1-micro tok:  0.9946665618968574
**************************************************
dev_cost_sum: 82230.08386230469
dev_cost_avg: 25.30156426532452
dev_count_sent: 3250.0
dev_total_correct_sent: 3221.0
dev_accuracy_sent: 0.9910769230769231
dev_count_tok: 51362.0
dev_total_correct_tok: 50831.0
dev_accuracy_tok: 0.9896616175382579
dev_label=0_precision_sent: 0.9873417721518988
dev_label=0_recall_sent: 0.9674418604651163
dev_label=0_f-score_sent: 0.9772905246671887
dev_label=1_precision_sent: 0.9919786096256684
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9944476354585488
dev_precision_macro_sent: 0.9896601908887837
dev_recall_macro_sent: 0.9821854215953221
dev_f-score_macro_sent: 0.9858690800628687
dev_precision_micro_sent: 0.9910769230769231
dev_recall_micro_sent: 0.9910769230769231
dev_f-score_micro_sent: 0.9910769230769231
dev_label=O_precision_tok: 0.9964027936745229
dev_label=O_recall_tok: 0.997614537290395
dev_label=O_f-score_tok: 0.9970082973004558
dev_label=LOC_precision_tok: 0.9552309142318567
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9615749525616698
dev_label=MISC_precision_tok: 0.912
dev_label=MISC_recall_tok: 0.8990536277602523
dev_label=MISC_f-score_tok: 0.9054805401111993
dev_label=ORG_precision_tok: 0.9529293940911367
dev_label=ORG_recall_tok: 0.9096558317399618
dev_label=ORG_f-score_tok: 0.9307899241868428
dev_label=PER_precision_tok: 0.9754871150219987
dev_label=PER_recall_tok: 0.9857097491267068
dev_label=PER_f-score_tok: 0.9805717896066971
dev_precision_macro_tok: 0.958410043403903
dev_recall_macro_tok: 0.9520075132713333
dev_f-score_macro_tok: 0.9550851007533729
dev_precision_micro_tok: 0.9896616175382579
dev_recall_micro_tok: 0.9896616175382579
dev_f-score_micro_tok: 0.9896616175382579
dev_time: 14.964852809906006
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9873    0.9674    0.9773       645
           1     0.9920    0.9969    0.9944      2605

   micro avg     0.9911    0.9911    0.9911      3250
   macro avg     0.9897    0.9822    0.9859      3250
weighted avg     0.9911    0.9911    0.9910      3250

F1-macro sent:  0.9858690800628687
F1-micro sent:  0.9910769230769231
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9976    0.9970     42759
         LOC     0.9552    0.9680    0.9616      2094
        MISC     0.9120    0.8991    0.9055      1268
         ORG     0.9529    0.9097    0.9308      2092
         PER     0.9755    0.9857    0.9806      3149

   micro avg     0.9897    0.9897    0.9897     51362
   macro avg     0.9584    0.9520    0.9551     51362
weighted avg     0.9896    0.9897    0.9896     51362

F1-macro tok:  0.9550851007533729
F1-micro tok:  0.9896616175382579
**************************************************
Best epoch: 24
**************************************************

EPOCH: 30
Learning rate: 0.590490
train_cost_sum: 294559.0126647949
train_cost_avg: 20.978492462416845
train_count_sent: 14041.0
train_total_correct_sent: 13921.0
train_accuracy_sent: 0.991453600170928
train_count_tok: 203621.0
train_total_correct_tok: 202553.0
train_accuracy_tok: 0.9947549614234288
train_label=0_precision_sent: 0.9787161002403021
train_label=0_recall_sent: 0.9800618769336542
train_label=0_f-score_sent: 0.9793885262796289
train_label=1_precision_sent: 0.9947879223580158
train_label=1_recall_sent: 0.9944304707150557
train_label=1_f-score_sent: 0.9946091644204852
train_precision_macro_sent: 0.986752011299159
train_recall_macro_sent: 0.987246173824355
train_f-score_macro_sent: 0.9869988453500571
train_precision_micro_sent: 0.991453600170928
train_recall_micro_sent: 0.991453600170928
train_f-score_micro_sent: 0.991453600170928
train_label=O_precision_tok: 0.9982903261939713
train_label=O_recall_tok: 0.9985552371180224
train_label=O_f-score_tok: 0.9984227640838323
train_label=LOC_precision_tok: 0.9781953981448018
train_label=LOC_recall_tok: 0.9786669880679764
train_label=LOC_f-score_tok: 0.9784311362814797
train_label=MISC_precision_tok: 0.9616059675296182
train_label=MISC_recall_tok: 0.9542782495101241
train_label=MISC_f-score_tok: 0.9579280952901322
train_label=ORG_precision_tok: 0.9716198660937344
train_label=ORG_recall_tok: 0.9698753117206983
train_label=ORG_f-score_tok: 0.9707468051118211
train_label=PER_precision_tok: 0.987603305785124
train_label=PER_recall_tok: 0.9879583033788641
train_label=PER_f-score_tok: 0.9877807726864332
train_precision_macro_tok: 0.97946297274945
train_recall_macro_tok: 0.9778668179591371
train_f-score_macro_tok: 0.9786619146907396
train_precision_micro_tok: 0.9947549614234288
train_recall_micro_tok: 0.9947549614234288
train_f-score_micro_tok: 0.9947549614234288
train_time: 154.6634111404419
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9787    0.9801    0.9794      2909
           1     0.9948    0.9944    0.9946     11132

   micro avg     0.9915    0.9915    0.9915     14041
   macro avg     0.9868    0.9872    0.9870     14041
weighted avg     0.9915    0.9915    0.9915     14041

F1-macro sent:  0.9869988453500571
F1-micro sent:  0.991453600170928
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9986    0.9984    169578
         LOC     0.9782    0.9787    0.9784      8297
        MISC     0.9616    0.9543    0.9579      4593
         ORG     0.9716    0.9699    0.9707     10025
         PER     0.9876    0.9880    0.9878     11128

   micro avg     0.9948    0.9948    0.9948    203621
   macro avg     0.9795    0.9779    0.9787    203621
weighted avg     0.9947    0.9948    0.9948    203621

F1-macro tok:  0.9786619146907396
F1-micro tok:  0.9947549614234288
**************************************************
dev_cost_sum: 82088.5227355957
dev_cost_avg: 25.258006995567907
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50815.0
dev_accuracy_tok: 0.9893501031891282
dev_label=0_precision_sent: 0.9843260188087775
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9789555728760718
dev_label=1_precision_sent: 0.9934915773353752
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9948246118458884
dev_precision_macro_sent: 0.9889087980720763
dev_recall_macro_sent: 0.9849023196298115
dev_f-score_macro_sent: 0.9868900923609801
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.996309359743991
dev_label=O_recall_tok: 0.9975209897331556
dev_label=O_f-score_tok: 0.996914806591095
dev_label=LOC_precision_tok: 0.9559867486985328
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.9603042548134062
dev_label=MISC_precision_tok: 0.9163961038961039
dev_label=MISC_recall_tok: 0.8903785488958991
dev_label=MISC_f-score_tok: 0.9032
dev_label=ORG_precision_tok: 0.9421000981354269
dev_label=ORG_recall_tok: 0.9177820267686424
dev_label=ORG_f-score_tok: 0.9297820823244551
dev_label=PER_precision_tok: 0.9763257575757576
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9792623080576223
dev_precision_macro_tok: 0.9574236136099625
dev_recall_macro_tok: 0.9505118156192702
dev_f-score_macro_tok: 0.9538926903573157
dev_precision_micro_tok: 0.9893501031891282
dev_recall_micro_tok: 0.9893501031891282
dev_f-score_micro_tok: 0.9893501031891282
dev_time: 14.39471960067749
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9843    0.9736    0.9790       645
           1     0.9935    0.9962    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9889    0.9849    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9868900923609801
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9975    0.9969     42759
         LOC     0.9560    0.9647    0.9603      2094
        MISC     0.9164    0.8904    0.9032      1268
         ORG     0.9421    0.9178    0.9298      2092
         PER     0.9763    0.9822    0.9793      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9574    0.9505    0.9539     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9538926903573157
F1-micro tok:  0.9893501031891282
**************************************************
Best epoch: 24
**************************************************

EPOCH: 31
Learning rate: 0.531441
train_cost_sum: 293896.1403198242
train_cost_avg: 20.931282694952227
train_count_sent: 14041.0
train_total_correct_sent: 13937.0
train_accuracy_sent: 0.9925931201481376
train_count_tok: 203621.0
train_total_correct_tok: 202595.0
train_accuracy_tok: 0.9949612269854288
train_label=0_precision_sent: 0.9824561403508771
train_label=0_recall_sent: 0.9817806806462702
train_label=0_f-score_sent: 0.9821182943603852
train_label=1_precision_sent: 0.9952398059996408
train_label=1_recall_sent: 0.9954186130075459
train_label=1_f-score_sent: 0.9953292014730981
train_precision_macro_sent: 0.988847973175259
train_recall_macro_sent: 0.988599646826908
train_f-score_macro_sent: 0.9887237479167417
train_precision_micro_sent: 0.9925931201481376
train_recall_micro_sent: 0.9925931201481376
train_f-score_micro_sent: 0.9925931201481376
train_label=O_precision_tok: 0.9984079719331348
train_label=O_recall_tok: 0.9985080611871823
train_label=O_f-score_tok: 0.998458014051826
train_label=LOC_precision_tok: 0.9798698167791707
train_label=LOC_recall_tok: 0.9797517174882487
train_label=LOC_f-score_tok: 0.9798107635750015
train_label=MISC_precision_tok: 0.961798733900895
train_label=MISC_recall_tok: 0.9592858698018724
train_label=MISC_f-score_tok: 0.960540658382385
train_label=ORG_precision_tok: 0.9704561333466414
train_label=ORG_recall_tok: 0.9698753117206983
train_label=ORG_f-score_tok: 0.9701656356016763
train_label=PER_precision_tok: 0.9893980233602875
train_label=PER_recall_tok: 0.9895758447160317
train_label=PER_f-score_tok: 0.9894869260490611
train_precision_macro_tok: 0.9799861358640258
train_recall_macro_tok: 0.9793993609828068
train_f-score_macro_tok: 0.97969239953199
train_precision_micro_tok: 0.9949612269854288
train_recall_micro_tok: 0.9949612269854288
train_f-score_micro_tok: 0.9949612269854288
train_time: 156.22788953781128
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9825    0.9818    0.9821      2909
           1     0.9952    0.9954    0.9953     11132

   micro avg     0.9926    0.9926    0.9926     14041
   macro avg     0.9888    0.9886    0.9887     14041
weighted avg     0.9926    0.9926    0.9926     14041

F1-macro sent:  0.9887237479167417
F1-micro sent:  0.9925931201481376
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9985    0.9985    169578
         LOC     0.9799    0.9798    0.9798      8297
        MISC     0.9618    0.9593    0.9605      4593
         ORG     0.9705    0.9699    0.9702     10025
         PER     0.9894    0.9896    0.9895     11128

   micro avg     0.9950    0.9950    0.9950    203621
   macro avg     0.9800    0.9794    0.9797    203621
weighted avg     0.9950    0.9950    0.9950    203621

F1-macro tok:  0.97969239953199
F1-micro tok:  0.9949612269854288
**************************************************
dev_cost_sum: 81935.78007888794
dev_cost_avg: 25.21100925504244
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50824.0
dev_accuracy_tok: 0.9895253300105136
dev_label=0_precision_sent: 0.9889064976228209
dev_label=0_recall_sent: 0.9674418604651163
dev_label=0_f-score_sent: 0.9780564263322883
dev_label=1_precision_sent: 0.9919816723940436
dev_label=1_recall_sent: 0.9973128598848369
dev_label=1_f-score_sent: 0.9946401225114855
dev_precision_macro_sent: 0.9904440850084322
dev_recall_macro_sent: 0.9823773601749766
dev_f-score_macro_sent: 0.9863482744218869
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.9969141574714794
dev_label=O_recall_tok: 0.9973105077293669
dev_label=O_f-score_tok: 0.9971122932133045
dev_label=LOC_precision_tok: 0.956953642384106
dev_label=LOC_recall_tok: 0.9660936007640879
dev_label=LOC_f-score_tok: 0.9615019011406843
dev_label=MISC_precision_tok: 0.9011673151750973
dev_label=MISC_recall_tok: 0.9132492113564669
dev_label=MISC_f-score_tok: 0.9071680376028203
dev_label=ORG_precision_tok: 0.9509018036072144
dev_label=ORG_recall_tok: 0.9072657743785851
dev_label=ORG_f-score_tok: 0.9285714285714286
dev_label=PER_precision_tok: 0.9717956753368849
dev_label=PER_recall_tok: 0.984757065735154
dev_label=PER_f-score_tok: 0.9782334384858044
dev_precision_macro_tok: 0.9555465187949566
dev_recall_macro_tok: 0.9537352319927322
dev_f-score_macro_tok: 0.9545174198028084
dev_precision_micro_tok: 0.9895253300105136
dev_recall_micro_tok: 0.9895253300105136
dev_f-score_micro_tok: 0.9895253300105136
dev_time: 11.991057872772217
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9889    0.9674    0.9781       645
           1     0.9920    0.9973    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9904    0.9824    0.9863      3250
weighted avg     0.9914    0.9914    0.9913      3250

F1-macro sent:  0.9863482744218869
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9969    0.9973    0.9971     42759
         LOC     0.9570    0.9661    0.9615      2094
        MISC     0.9012    0.9132    0.9072      1268
         ORG     0.9509    0.9073    0.9286      2092
         PER     0.9718    0.9848    0.9782      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9555    0.9537    0.9545     51362
weighted avg     0.9895    0.9895    0.9895     51362

F1-macro tok:  0.9545174198028084
F1-micro tok:  0.9895253300105136
**************************************************
Best epoch: 24
**************************************************

test0_cost_sum: 82946.95302963257
test0_cost_avg: 25.5221393937331
test0_count_sent: 3250.0
test0_total_correct_sent: 3223.0
test0_accuracy_sent: 0.9916923076923077
test0_count_tok: 51362.0
test0_total_correct_tok: 50792.0
test0_accuracy_tok: 0.9889023013122542
test0_label=0_precision_sent: 0.9813084112149533
test0_label=0_recall_sent: 0.9767441860465116
test0_label=0_f-score_sent: 0.979020979020979
test0_label=1_precision_sent: 0.9942484662576687
test0_label=1_recall_sent: 0.9953934740882917
test0_label=1_f-score_sent: 0.9948206407059275
test0_precision_macro_sent: 0.987778438736311
test0_recall_macro_sent: 0.9860688300674016
test0_f-score_macro_sent: 0.9869208098634532
test0_precision_micro_sent: 0.9916923076923077
test0_recall_micro_sent: 0.9916923076923077
test0_f-score_micro_sent: 0.9916923076923077
test0_label=O_precision_tok: 0.9963553104995093
test0_label=O_recall_tok: 0.9973572815079866
test0_label=O_f-score_tok: 0.9968560442257571
test0_label=LOC_precision_tok: 0.9475164011246485
test0_label=LOC_recall_tok: 0.9656160458452722
test0_label=LOC_f-score_tok: 0.956480605487228
test0_label=MISC_precision_tok: 0.9156528791565288
test0_label=MISC_recall_tok: 0.8903785488958991
test0_label=MISC_f-score_tok: 0.9028388644542182
test0_label=ORG_precision_tok: 0.9436970602889886
test0_label=ORG_recall_tok: 0.9053537284894837
test0_label=ORG_f-score_tok: 0.924127836057575
test0_label=PER_precision_tok: 0.9733207784055242
test0_label=PER_recall_tok: 0.984757065735154
test0_label=PER_f-score_tok: 0.9790055248618785
test0_precision_macro_tok: 0.9553084858950399
test0_recall_macro_tok: 0.9486925340947592
test0_f-score_macro_tok: 0.9518617750173315
test0_precision_micro_tok: 0.9889023013122542
test0_recall_micro_tok: 0.9889023013122542
test0_f-score_micro_tok: 0.9889023013122542
test0_time: 13.854099035263062
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9813    0.9767    0.9790       645
           1     0.9942    0.9954    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9878    0.9861    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9869208098634532
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9964    0.9974    0.9969     42759
         LOC     0.9475    0.9656    0.9565      2094
        MISC     0.9157    0.8904    0.9028      1268
         ORG     0.9437    0.9054    0.9241      2092
         PER     0.9733    0.9848    0.9790      3149

   micro avg     0.9889    0.9889    0.9889     51362
   macro avg     0.9553    0.9487    0.9519     51362
weighted avg     0.9888    0.9889    0.9888     51362

F1-macro tok:  0.9518617750173315
F1-micro tok:  0.9889023013122542
**************************************************
test1_cost_sum: 73581.7681427002
test1_cost_avg: 21.30951872073565
test1_count_sent: 3453.0
test1_total_correct_sent: 3343.0
test1_accuracy_sent: 0.968143643208804
test1_count_tok: 46435.0
test1_total_correct_tok: 45433.0
test1_accuracy_tok: 0.978421449337784
test1_label=0_precision_sent: 0.9564541213063764
test1_label=0_recall_sent: 0.8823529411764706
test1_label=0_f-score_sent: 0.917910447761194
test1_label=1_precision_sent: 0.9708185053380783
test1_label=1_recall_sent: 0.9898403483309144
test1_label=1_f-score_sent: 0.9802371541501976
test1_precision_macro_sent: 0.9636363133222274
test1_recall_macro_sent: 0.9360966447536925
test1_f-score_macro_sent: 0.9490738009556958
test1_precision_micro_sent: 0.968143643208804
test1_recall_micro_sent: 0.968143643208804
test1_f-score_micro_sent: 0.968143643208804
test1_label=O_precision_tok: 0.9944788968260199
test1_label=O_recall_tok: 0.9917282049943897
test1_label=O_f-score_tok: 0.9931016461980663
test1_label=LOC_precision_tok: 0.8857705563761694
test1_label=LOC_recall_tok: 0.9345454545454546
test1_label=LOC_f-score_tok: 0.9095045500505561
test1_label=MISC_precision_tok: 0.7852564102564102
test1_label=MISC_recall_tok: 0.8006535947712419
test1_label=MISC_f-score_tok: 0.7928802588996763
test1_label=ORG_precision_tok: 0.8828502415458938
test1_label=ORG_recall_tok: 0.8786057692307693
test1_label=ORG_f-score_tok: 0.880722891566265
test1_label=PER_precision_tok: 0.9757860498735093
test1_label=PER_recall_tok: 0.9736747205192932
test1_label=PER_f-score_tok: 0.9747292418772563
test1_precision_macro_tok: 0.9048284309756005
test1_recall_macro_tok: 0.9158415488122296
test1_f-score_macro_tok: 0.9101877177183638
test1_precision_micro_tok: 0.978421449337784
test1_recall_micro_tok: 0.978421449337784
test1_f-score_micro_tok: 0.978421449337784
test1_time: 14.911323547363281
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9565    0.8824    0.9179       697
           1     0.9708    0.9898    0.9802      2756

   micro avg     0.9681    0.9681    0.9681      3453
   macro avg     0.9636    0.9361    0.9491      3453
weighted avg     0.9679    0.9681    0.9677      3453

F1-macro sent:  0.9490738009556958
F1-micro sent:  0.968143643208804
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9945    0.9917    0.9931     38323
         LOC     0.8858    0.9345    0.9095      1925
        MISC     0.7853    0.8007    0.7929       918
         ORG     0.8829    0.8786    0.8807      2496
         PER     0.9758    0.9737    0.9747      2773

   micro avg     0.9784    0.9784    0.9784     46435
   macro avg     0.9048    0.9158    0.9102     46435
weighted avg     0.9787    0.9784    0.9785     46435

F1-macro tok:  0.9101877177183638
F1-micro tok:  0.978421449337784
**************************************************

