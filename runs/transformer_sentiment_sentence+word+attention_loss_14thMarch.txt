debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'O': 0, 'N': 1}
{'P': 2, 'O': 0, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 19:34:35.598819: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 19:34:35.684184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 10.48GiB
2019-03-14 19:34:35.684228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 19:34:36.052981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 19:34:36.053035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 19:34:36.053050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 19:34:36.053299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7835707.
Parameter count without word embeddings: 2035207.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 111857.29229736328
train_cost_avg: 13.091911551657688
train_count_sent: 8544.0
train_total_correct_sent: 4406.0
train_accuracy_sent: 0.5156835205992509
train_count_tok: 163566.0
train_total_correct_tok: 126695.0
train_accuracy_tok: 0.7745802917476737
train_label=O_precision_sent: 0.246875
train_label=O_recall_sent: 0.04864532019704434
train_label=O_f-score_sent: 0.08127572016460906
train_label=N_precision_sent: 0.5091439173071826
train_label=N_recall_sent: 0.5803625377643504
train_label=N_f-score_sent: 0.5424255259071015
train_label=P_precision_sent: 0.5405526847899349
train_label=P_recall_sent: 0.6664819944598338
train_label=P_f-score_sent: 0.5969482694454783
train_precision_macro_sent: 0.43219053403237245
train_recall_macro_sent: 0.4318299508070762
train_f-score_macro_sent: 0.4068831718390629
train_precision_micro_sent: 0.5156835205992509
train_recall_micro_sent: 0.5156835205992509
train_f-score_micro_sent: 0.5156835205992509
train_label=O_precision_tok: 0.7979542565854512
train_label=O_recall_tok: 0.9542248707246657
train_label=O_f-score_tok: 0.8691209539784506
train_label=N_precision_tok: 0.5303701080219586
train_label=N_recall_tok: 0.21088579073369948
train_label=N_f-score_tok: 0.3017784271247922
train_label=P_precision_tok: 0.547180043383948
train_label=P_recall_tok: 0.20166286924891075
train_label=P_f-score_tok: 0.2947104010281275
train_precision_macro_tok: 0.6251681359971193
train_recall_macro_tok: 0.45559117690242523
train_f-score_macro_tok: 0.48853659404379
train_precision_micro_tok: 0.7745802917476737
train_recall_micro_tok: 0.7745802917476737
train_f-score_micro_tok: 0.7745802917476737
train_time: 85.66802597045898
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2469    0.0486    0.0813      1624
           N     0.5091    0.5804    0.5424      3310
           P     0.5406    0.6665    0.5969      3610

   micro avg     0.5157    0.5157    0.5157      8544
   macro avg     0.4322    0.4318    0.4069      8544
weighted avg     0.4726    0.5157    0.4778      8544

F1-macro sent:  0.4068831718390629
F1-micro sent:  0.5156835205992509
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7980    0.9542    0.8691    124347
           N     0.5304    0.2109    0.3018     14202
           P     0.5472    0.2017    0.2947     25017

   micro avg     0.7746    0.7746    0.7746    163566
   macro avg     0.6252    0.4556    0.4885    163566
weighted avg     0.7364    0.7746    0.7320    163566

F1-macro tok:  0.48853659404379
F1-micro tok:  0.7745802917476737
**************************************************
dev_cost_sum: 11749.809020996094
dev_cost_avg: 10.671942798361576
dev_count_sent: 1101.0
dev_total_correct_sent: 657.0
dev_accuracy_sent: 0.5967302452316077
dev_count_tok: 21274.0
dev_total_correct_tok: 17477.0
dev_accuracy_tok: 0.8215192253454922
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6438679245283019
dev_label=N_recall_sent: 0.6378504672897196
dev_label=N_f-score_sent: 0.6408450704225352
dev_label=P_precision_sent: 0.5672082717872969
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.6851025869759143
dev_precision_macro_sent: 0.4036920654385329
dev_recall_macro_sent: 0.5009051107181949
dev_f-score_macro_sent: 0.44198255246614987
dev_precision_micro_sent: 0.5967302452316077
dev_recall_micro_sent: 0.5967302452316077
dev_f-score_micro_sent: 0.5967302452316077
dev_label=O_precision_tok: 0.8429001367989056
dev_label=O_recall_tok: 0.9505708114779389
dev_label=O_f-score_tok: 0.8935034802784223
dev_label=N_precision_tok: 0.6351156069364162
dev_label=N_recall_tok: 0.47334410339256866
dev_label=N_f-score_tok: 0.5424251774143782
dev_label=P_precision_tok: 0.7393188854489164
dev_label=P_recall_tok: 0.3717310087173101
dev_label=P_f-score_tok: 0.49471721566190174
dev_precision_macro_tok: 0.7391115430614127
dev_recall_macro_tok: 0.5985486411959392
dev_f-score_macro_tok: 0.6435486244515675
dev_precision_micro_tok: 0.8215192253454922
dev_recall_micro_tok: 0.8215192253454922
dev_f-score_micro_tok: 0.8215192253454922
dev_time: 4.623382329940796
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6439    0.6379    0.6408       428
           P     0.5672    0.8649    0.6851       444

   micro avg     0.5967    0.5967    0.5967      1101
   macro avg     0.4037    0.5009    0.4420      1101
weighted avg     0.4790    0.5967    0.5254      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.44198255246614987
F1-micro sent:  0.5967302452316077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8429    0.9506    0.8935     16205
           N     0.6351    0.4733    0.5424      1857
           P     0.7393    0.3717    0.4947      3212

   micro avg     0.8215    0.8215    0.8215     21274
   macro avg     0.7391    0.5985    0.6435     21274
weighted avg     0.8091    0.8215    0.8026     21274

F1-macro tok:  0.6435486244515675
F1-micro tok:  0.8215192253454922
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 92471.08114624023
train_cost_avg: 10.822926164119878
train_count_sent: 8544.0
train_total_correct_sent: 4976.0
train_accuracy_sent: 0.5823970037453183
train_count_tok: 163566.0
train_total_correct_tok: 132510.0
train_accuracy_tok: 0.8101316899600162
train_label=O_precision_sent: 0.29411764705882354
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012062726176115802
train_label=N_precision_sent: 0.5543062200956937
train_label=N_recall_sent: 0.7
train_label=N_f-score_sent: 0.6186915887850466
train_label=P_precision_sent: 0.6117782909930716
train_label=P_recall_sent: 0.7337950138504156
train_label=P_f-score_sent: 0.6672544080604533
train_precision_macro_sent: 0.48673405271586295
train_recall_macro_sent: 0.47998421643946526
train_f-score_macro_sent: 0.4326695743405386
train_precision_micro_sent: 0.5823970037453183
train_recall_micro_sent: 0.5823970037453183
train_f-score_micro_sent: 0.5823970037453183
train_label=O_precision_tok: 0.8344563303803106
train_label=O_recall_tok: 0.9491423194769476
train_label=O_f-score_tok: 0.88811215122054
train_label=N_precision_tok: 0.6344254937163375
train_label=N_recall_tok: 0.39811294183917756
train_label=N_f-score_tok: 0.48922730812494597
train_label=P_precision_tok: 0.6683059695846258
train_label=P_recall_tok: 0.3530799056641484
train_label=P_f-score_tok: 0.46204948475179153
train_precision_macro_tok: 0.7123959312270913
train_recall_macro_tok: 0.5667783889934245
train_f-score_macro_tok: 0.6131296480324259
train_precision_micro_tok: 0.8101316899600162
train_recall_micro_tok: 0.8101316899600162
train_f-score_micro_tok: 0.8101316899600162
train_time: 84.10640716552734
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2941    0.0062    0.0121      1624
           N     0.5543    0.7000    0.6187      3310
           P     0.6118    0.7338    0.6673      3610

   micro avg     0.5824    0.5824    0.5824      8544
   macro avg     0.4867    0.4800    0.4327      8544
weighted avg     0.5291    0.5824    0.5239      8544

F1-macro sent:  0.4326695743405386
F1-micro sent:  0.5823970037453183
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8345    0.9491    0.8881    124347
           N     0.6344    0.3981    0.4892     14202
           P     0.6683    0.3531    0.4620     25017

   micro avg     0.8101    0.8101    0.8101    163566
   macro avg     0.7124    0.5668    0.6131    163566
weighted avg     0.7917    0.8101    0.7883    163566

F1-macro tok:  0.6131296480324259
F1-micro tok:  0.8101316899600162
**************************************************
dev_cost_sum: 10567.453720092773
dev_cost_avg: 9.598050608621955
dev_count_sent: 1101.0
dev_total_correct_sent: 665.0
dev_accuracy_sent: 0.6039963669391463
dev_count_tok: 21274.0
dev_total_correct_tok: 17739.0
dev_accuracy_tok: 0.8338347278367961
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.554531490015361
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.6691380908248378
dev_label=P_precision_sent: 0.6755555555555556
dev_label=P_recall_sent: 0.6846846846846847
dev_label=P_f-score_sent: 0.680089485458613
dev_precision_macro_sent: 0.4100290151903055
dev_recall_macro_sent: 0.5093808762033061
dev_f-score_macro_sent: 0.4497425254278169
dev_precision_micro_sent: 0.6039963669391463
dev_recall_micro_sent: 0.6039963669391463
dev_f-score_micro_sent: 0.6039963669391463
dev_label=O_precision_tok: 0.8416965672361163
dev_label=O_recall_tok: 0.9698858377044122
dev_label=O_f-score_tok: 0.9012558059521761
dev_label=N_precision_tok: 0.7146619841966637
dev_label=N_recall_tok: 0.43834141087775985
dev_label=N_f-score_tok: 0.5433911882510013
dev_label=P_precision_tok: 0.826265389876881
dev_label=P_recall_tok: 0.37608966376089664
dev_label=P_f-score_tok: 0.5169020111253745
dev_precision_macro_tok: 0.7942079804365537
dev_recall_macro_tok: 0.5947723041143562
dev_f-score_macro_tok: 0.6538496684428506
dev_precision_micro_tok: 0.8338347278367961
dev_recall_micro_tok: 0.8338347278367961
dev_f-score_micro_tok: 0.833834727836796
dev_time: 4.356229782104492
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5545    0.8435    0.6691       428
           P     0.6756    0.6847    0.6801       444

   micro avg     0.6040    0.6040    0.6040      1101
   macro avg     0.4100    0.5094    0.4497      1101
weighted avg     0.4880    0.6040    0.5344      1101

F1-macro sent:  0.4497425254278169
F1-micro sent:  0.6039963669391463
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8417    0.9699    0.9013     16205
           N     0.7147    0.4383    0.5434      1857
           P     0.8263    0.3761    0.5169      3212

   micro avg     0.8338    0.8338    0.8338     21274
   macro avg     0.7942    0.5948    0.6538     21274
weighted avg     0.8283    0.8338    0.8120     21274

F1-macro tok:  0.6538496684428506
F1-micro tok:  0.833834727836796
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 86844.57173156738
train_cost_avg: 10.164392758844498
train_count_sent: 8544.0
train_total_correct_sent: 5133.0
train_accuracy_sent: 0.6007724719101124
train_count_tok: 163566.0
train_total_correct_tok: 135407.0
train_accuracy_tok: 0.8278431947959844
train_label=O_precision_sent: 0.3225806451612903
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012084592145015106
train_label=N_precision_sent: 0.5695181000691723
train_label=N_recall_sent: 0.7462235649546828
train_label=N_f-score_sent: 0.6460049692689943
train_label=P_precision_sent: 0.6352969348659003
train_label=P_recall_sent: 0.7349030470914127
train_label=P_f-score_sent: 0.6814795787310556
train_precision_macro_sent: 0.5091318933654543
train_recall_macro_sent: 0.49576141583802524
train_f-score_macro_sent: 0.44652304671502163
train_precision_micro_sent: 0.6007724719101124
train_recall_micro_sent: 0.6007724719101124
train_f-score_micro_sent: 0.6007724719101124
train_label=O_precision_tok: 0.8492594875912199
train_label=O_recall_tok: 0.9527370986031026
train_label=O_f-score_tok: 0.8980272508480357
train_label=N_precision_tok: 0.6732165741136267
train_label=N_recall_tok: 0.44388114350091534
train_label=N_f-score_tok: 0.5350080624628702
train_label=P_precision_tok: 0.7231365614798694
train_label=P_recall_tok: 0.4250309789343247
train_label=P_f-score_tok: 0.5353843055310793
train_precision_macro_tok: 0.7485375410615721
train_recall_macro_tok: 0.6072164070127809
train_f-score_macro_tok: 0.6561398729473283
train_precision_micro_tok: 0.8278431947959844
train_recall_micro_tok: 0.8278431947959844
train_f-score_micro_tok: 0.8278431947959844
train_time: 84.54165053367615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3226    0.0062    0.0121      1624
           N     0.5695    0.7462    0.6460      3310
           P     0.6353    0.7349    0.6815      3610

   micro avg     0.6008    0.6008    0.6008      8544
   macro avg     0.5091    0.4958    0.4465      8544
weighted avg     0.5504    0.6008    0.5405      8544

F1-macro sent:  0.44652304671502163
F1-micro sent:  0.6007724719101124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8493    0.9527    0.8980    124347
           N     0.6732    0.4439    0.5350     14202
           P     0.7231    0.4250    0.5354     25017

   micro avg     0.8278    0.8278    0.8278    163566
   macro avg     0.7485    0.6072    0.6561    163566
weighted avg     0.8147    0.8278    0.8110    163566

F1-macro tok:  0.6561398729473283
F1-micro tok:  0.8278431947959844
**************************************************
dev_cost_sum: 9995.975875854492
dev_cost_avg: 9.078997162447314
dev_count_sent: 1101.0
dev_total_correct_sent: 681.0
dev_accuracy_sent: 0.6185286103542235
dev_count_tok: 21274.0
dev_total_correct_tok: 18243.0
dev_accuracy_tok: 0.8575256181254113
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5700787401574803
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.6810912511759172
dev_label=P_precision_sent: 0.6845493562231759
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.701098901098901
dev_precision_macro_sent: 0.41820936546021875
dev_recall_macro_sent: 0.5214209536639444
dev_f-score_macro_sent: 0.4607300507582727
dev_precision_micro_sent: 0.6185286103542235
dev_recall_micro_sent: 0.6185286103542235
dev_f-score_micro_sent: 0.6185286103542235
dev_label=O_precision_tok: 0.8714565278166061
dev_label=O_recall_tok: 0.961801912989818
dev_label=O_f-score_tok: 0.91440305074802
dev_label=N_precision_tok: 0.7386759581881533
dev_label=N_recall_tok: 0.45665051157781367
dev_label=N_f-score_tok: 0.5643926788685524
dev_label=P_precision_tok: 0.8072289156626506
dev_label=P_recall_tok: 0.563200498132005
dev_label=P_f-score_tok: 0.6634879882633413
dev_precision_macro_tok: 0.8057871338891367
dev_recall_macro_tok: 0.6605509742332122
dev_f-score_macro_tok: 0.7140945726266379
dev_precision_micro_tok: 0.8575256181254113
dev_recall_micro_tok: 0.8575256181254113
dev_f-score_micro_tok: 0.8575256181254113
dev_time: 4.276352882385254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5701    0.8458    0.6811       428
           P     0.6845    0.7185    0.7011       444

   micro avg     0.6185    0.6185    0.6185      1101
   macro avg     0.4182    0.5214    0.4607      1101
weighted avg     0.4977    0.6185    0.5475      1101

F1-macro sent:  0.4607300507582727
F1-micro sent:  0.6185286103542235
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8715    0.9618    0.9144     16205
           N     0.7387    0.4567    0.5644      1857
           P     0.8072    0.5632    0.6635      3212

   micro avg     0.8575    0.8575    0.8575     21274
   macro avg     0.8058    0.6606    0.7141     21274
weighted avg     0.8502    0.8575    0.8460     21274

F1-macro tok:  0.7140945726266379
F1-micro tok:  0.8575256181254113
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 82375.53546142578
train_cost_avg: 9.641331397638785
train_count_sent: 8544.0
train_total_correct_sent: 5223.0
train_accuracy_sent: 0.6113061797752809
train_count_tok: 163566.0
train_total_correct_tok: 137550.0
train_accuracy_tok: 0.840944939657386
train_label=O_precision_sent: 0.39473684210526316
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.01805054151624549
train_label=N_precision_sent: 0.5802555168408827
train_label=N_recall_sent: 0.7546827794561933
train_label=N_f-score_sent: 0.6560735390676297
train_label=P_precision_sent: 0.6450845036895977
train_label=P_recall_sent: 0.7506925207756233
train_label=P_f-score_sent: 0.69389322749968
train_precision_macro_sent: 0.5400256208785812
train_recall_macro_sent: 0.504870584477929
train_f-score_macro_sent: 0.45600576936118503
train_precision_micro_sent: 0.6113061797752809
train_recall_micro_sent: 0.6113061797752809
train_f-score_micro_sent: 0.6113061797752809
train_label=O_precision_tok: 0.8609751321715293
train_label=O_recall_tok: 0.9547395594586118
train_label=O_f-score_tok: 0.9054363245321009
train_label=N_precision_tok: 0.6904687662405156
train_label=N_recall_tok: 0.4677510209829601
train_label=N_f-score_tok: 0.55769634386937
train_label=P_precision_tok: 0.7590931738913802
train_label=P_recall_tok: 0.48718871167606026
train_label=P_f-score_tok: 0.593479901638546
train_precision_macro_tok: 0.7701790241011417
train_recall_macro_tok: 0.6365597640392108
train_f-score_macro_tok: 0.6855375233466723
train_precision_micro_tok: 0.840944939657386
train_recall_micro_tok: 0.840944939657386
train_f-score_micro_tok: 0.840944939657386
train_time: 85.09686732292175
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3947    0.0092    0.0181      1624
           N     0.5803    0.7547    0.6561      3310
           P     0.6451    0.7507    0.6939      3610

   micro avg     0.6113    0.6113    0.6113      8544
   macro avg     0.5400    0.5049    0.4560      8544
weighted avg     0.5724    0.6113    0.5508      8544

F1-macro sent:  0.45600576936118503
F1-micro sent:  0.6113061797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8610    0.9547    0.9054    124347
           N     0.6905    0.4678    0.5577     14202
           P     0.7591    0.4872    0.5935     25017

   micro avg     0.8409    0.8409    0.8409    163566
   macro avg     0.7702    0.6366    0.6855    163566
weighted avg     0.8306    0.8409    0.8275    163566

F1-macro tok:  0.6855375233466723
F1-micro tok:  0.840944939657386
**************************************************
dev_cost_sum: 9678.956588745117
dev_cost_avg: 8.791059571975584
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 18384.0
dev_accuracy_tok: 0.8641534267180596
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6492374727668845
dev_label=N_recall_sent: 0.6962616822429907
dev_label=N_f-score_sent: 0.6719278466741826
dev_label=P_precision_sent: 0.5914826498422713
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.6957328385899815
dev_precision_macro_sent: 0.4135733742030519
dev_recall_macro_sent: 0.5136187589458617
dev_f-score_macro_sent: 0.45588689508805463
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.879527603548624
dev_label=O_recall_tok: 0.9605060166615242
dev_label=O_f-score_tok: 0.918234912394549
dev_label=N_precision_tok: 0.7605633802816901
dev_label=N_recall_tok: 0.46526655896607433
dev_label=N_f-score_tok: 0.577347143334447
dev_label=P_precision_tok: 0.8009012699713233
dev_label=P_recall_tok: 0.6086550435865504
dev_label=P_f-score_tok: 0.6916681408101893
dev_precision_macro_tok: 0.8136640846005458
dev_recall_macro_tok: 0.6781425397380496
dev_f-score_macro_tok: 0.7290833988463952
dev_precision_micro_tok: 0.8641534267180596
dev_recall_micro_tok: 0.8641534267180596
dev_f-score_micro_tok: 0.8641534267180596
dev_time: 4.313029766082764
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6492    0.6963    0.6719       428
           P     0.5915    0.8446    0.6957       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.4136    0.5136    0.4559      1101
weighted avg     0.4909    0.6113    0.5418      1101

F1-macro sent:  0.45588689508805463
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8795    0.9605    0.9182     16205
           N     0.7606    0.4653    0.5773      1857
           P     0.8009    0.6087    0.6917      3212

   micro avg     0.8642    0.8642    0.8642     21274
   macro avg     0.8137    0.6781    0.7291     21274
weighted avg     0.8573    0.8642    0.8543     21274

F1-macro tok:  0.7290833988463952
F1-micro tok:  0.8641534267180596
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 78877.38522338867
train_cost_avg: 9.231903701239311
train_count_sent: 8544.0
train_total_correct_sent: 5309.0
train_accuracy_sent: 0.6213717228464419
train_count_tok: 163566.0
train_total_correct_tok: 139338.0
train_accuracy_tok: 0.8518763068119292
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007294832826747719
train_label=N_precision_sent: 0.5828289621161175
train_label=N_recall_sent: 0.7854984894259819
train_label=N_f-score_sent: 0.6691545489640973
train_label=P_precision_sent: 0.6654357459379616
train_label=P_recall_sent: 0.7487534626038781
train_label=P_f-score_sent: 0.7046402502606882
train_precision_macro_sent: 0.5113263312561216
train_recall_macro_sent: 0.5126488444368827
train_f-score_macro_sent: 0.4603632106838444
train_precision_micro_sent: 0.6213717228464419
train_recall_micro_sent: 0.6213717228464419
train_f-score_micro_sent: 0.6213717228464419
train_label=O_precision_tok: 0.8695832968572179
train_label=O_recall_tok: 0.9585997249632078
train_label=O_f-score_tok: 0.9119243524862006
train_label=N_precision_tok: 0.7161648340355564
train_label=N_recall_tok: 0.4907055344317702
train_label=N_f-score_tok: 0.5823757991058371
train_label=P_precision_tok: 0.7858464108837043
train_label=P_recall_tok: 0.5264420194267898
train_label=P_f-score_tok: 0.6305055534278056
train_precision_macro_tok: 0.7905315139254929
train_recall_macro_tok: 0.6585824262739226
train_f-score_macro_tok: 0.7082685683399478
train_precision_micro_tok: 0.8518763068119292
train_recall_micro_tok: 0.8518763068119292
train_f-score_micro_tok: 0.8518763068119292
train_time: 85.03545069694519
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0037    0.0073      1624
           N     0.5828    0.7855    0.6692      3310
           P     0.6654    0.7488    0.7046      3610

   micro avg     0.6214    0.6214    0.6214      8544
   macro avg     0.5113    0.5126    0.4604      8544
weighted avg     0.5613    0.6214    0.5583      8544

F1-macro sent:  0.4603632106838444
F1-micro sent:  0.6213717228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8696    0.9586    0.9119    124347
           N     0.7162    0.4907    0.5824     14202
           P     0.7858    0.5264    0.6305     25017

   micro avg     0.8519    0.8519    0.8519    163566
   macro avg     0.7905    0.6586    0.7083    163566
weighted avg     0.8435    0.8519    0.8403    163566

F1-macro tok:  0.7082685683399478
F1-micro tok:  0.8518763068119292
**************************************************
dev_cost_sum: 9183.594970703125
dev_cost_avg: 8.341139846233538
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18540.0
dev_accuracy_tok: 0.8714863213312024
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.634765625
dev_label=N_recall_sent: 0.7593457943925234
dev_label=N_f-score_sent: 0.6914893617021276
dev_label=P_precision_sent: 0.6218057921635435
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7080504364694472
dev_precision_macro_sent: 0.41885713905451444
dev_recall_macro_sent: 0.5271392888215318
dev_f-score_macro_sent: 0.4665132660571916
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8810191940734089
dev_label=O_recall_tok: 0.9687133600740512
dev_label=O_f-score_tok: 0.9227875260852952
dev_label=N_precision_tok: 0.7402894135567403
dev_label=N_recall_tok: 0.5234248788368336
dev_label=N_f-score_tok: 0.6132492113564668
dev_label=P_precision_tok: 0.8726084927671488
dev_label=P_recall_tok: 0.5821917808219178
dev_label=P_f-score_tok: 0.6984126984126984
dev_precision_macro_tok: 0.8313057001324328
dev_recall_macro_tok: 0.6914433399109342
dev_f-score_macro_tok: 0.7448164786181536
dev_precision_micro_tok: 0.8714863213312024
dev_recall_micro_tok: 0.8714863213312024
dev_f-score_micro_tok: 0.8714863213312023
dev_time: 4.462694406509399
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6348    0.7593    0.6915       428
           P     0.6218    0.8221    0.7081       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4189    0.5271    0.4665      1101
weighted avg     0.4975    0.6267    0.5543      1101

F1-macro sent:  0.4665132660571916
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8810    0.9687    0.9228     16205
           N     0.7403    0.5234    0.6132      1857
           P     0.8726    0.5822    0.6984      3212

   micro avg     0.8715    0.8715    0.8715     21274
   macro avg     0.8313    0.6914    0.7448     21274
weighted avg     0.8675    0.8715    0.8619     21274

F1-macro tok:  0.7448164786181536
F1-micro tok:  0.8714863213312023
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 75980.32675170898
train_cost_avg: 8.892828505583918
train_count_sent: 8544.0
train_total_correct_sent: 5340.0
train_accuracy_sent: 0.625
train_count_tok: 163566.0
train_total_correct_tok: 140389.0
train_accuracy_tok: 0.8583018475722338
train_label=O_precision_sent: 0.38823529411764707
train_label=O_recall_sent: 0.020320197044334975
train_label=O_f-score_sent: 0.03861907548273844
train_label=N_precision_sent: 0.592341816483773
train_label=N_recall_sent: 0.766465256797583
train_label=N_f-score_sent: 0.6682470696694324
train_label=P_precision_sent: 0.6633141762452107
train_label=P_recall_sent: 0.7673130193905817
train_label=P_f-score_sent: 0.7115335217056256
train_precision_macro_sent: 0.5479637622822103
train_recall_macro_sent: 0.5180328244108332
train_f-score_macro_sent: 0.47279988895259883
train_precision_micro_sent: 0.625
train_recall_micro_sent: 0.625
train_f-score_micro_sent: 0.625
train_label=O_precision_tok: 0.8745964937964352
train_label=O_recall_tok: 0.9608836562200938
train_label=O_f-score_tok: 0.9157118660954467
train_label=N_precision_tok: 0.7247390290868552
train_label=N_recall_tok: 0.5035206308970568
train_label=N_f-score_tok: 0.5942083177531264
train_label=P_precision_tok: 0.805139311636619
train_label=P_recall_tok: 0.549826118239597
train_label=P_f-score_tok: 0.6534286596517898
train_precision_macro_tok: 0.8014916115066365
train_recall_macro_tok: 0.6714101351189159
train_f-score_macro_tok: 0.7211162811667876
train_precision_micro_tok: 0.8583018475722338
train_recall_micro_tok: 0.8583018475722338
train_f-score_micro_tok: 0.8583018475722338
train_time: 84.34552264213562
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3882    0.0203    0.0386      1624
           N     0.5923    0.7665    0.6682      3310
           P     0.6633    0.7673    0.7115      3610

   micro avg     0.6250    0.6250    0.6250      8544
   macro avg     0.5480    0.5180    0.4728      8544
weighted avg     0.5835    0.6250    0.5669      8544

F1-macro sent:  0.47279988895259883
F1-micro sent:  0.625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8746    0.9609    0.9157    124347
           N     0.7247    0.5035    0.5942     14202
           P     0.8051    0.5498    0.6534     25017

   micro avg     0.8583    0.8583    0.8583    163566
   macro avg     0.8015    0.6714    0.7211    163566
weighted avg     0.8510    0.8583    0.8477    163566

F1-macro tok:  0.7211162811667876
F1-micro tok:  0.8583018475722338
**************************************************
dev_cost_sum: 8925.555740356445
dev_cost_avg: 8.106771789606217
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18639.0
dev_accuracy_tok: 0.8761398890664661
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6730310262529833
dev_label=N_recall_sent: 0.6588785046728972
dev_label=N_f-score_sent: 0.665879574970484
dev_label=P_precision_sent: 0.5791788856304986
dev_label=P_recall_sent: 0.8896396396396397
dev_label=P_f-score_sent: 0.7015985790408525
dev_precision_macro_sent: 0.4174033039611606
dev_recall_macro_sent: 0.5161727147708456
dev_f-score_macro_sent: 0.4558260513371122
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.881709019826864
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.9256523013778951
dev_label=N_precision_tok: 0.7889072847682119
dev_label=N_recall_tok: 0.5131933225632741
dev_label=N_f-score_tok: 0.6218597063621534
dev_label=P_precision_tok: 0.8787598334104582
dev_label=P_recall_tok: 0.5912204234122043
dev_label=P_f-score_tok: 0.7068676716917924
dev_precision_macro_tok: 0.8497920460018448
dev_recall_macro_tok: 0.6928730793691787
dev_f-score_macro_tok: 0.7514598931439469
dev_precision_micro_tok: 0.8761398890664661
dev_recall_micro_tok: 0.8761398890664661
dev_f-score_micro_tok: 0.8761398890664661
dev_time: 4.324060678482056
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6730    0.6589    0.6659       428
           P     0.5792    0.8896    0.7016       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4174    0.5162    0.4558      1101
weighted avg     0.4952    0.6149    0.5418      1101

F1-macro sent:  0.4558260513371122
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8817    0.9742    0.9257     16205
           N     0.7889    0.5132    0.6219      1857
           P     0.8788    0.5912    0.7069      3212

   micro avg     0.8761    0.8761    0.8761     21274
   macro avg     0.8498    0.6929    0.7515     21274
weighted avg     0.8732    0.8761    0.8661     21274

F1-macro tok:  0.7514598931439469
F1-micro tok:  0.8761398890664661
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 74008.90673828125
train_cost_avg: 8.662091144461757
train_count_sent: 8544.0
train_total_correct_sent: 5342.0
train_accuracy_sent: 0.6252340823970037
train_count_tok: 163566.0
train_total_correct_tok: 141238.0
train_accuracy_tok: 0.863492412848636
train_label=O_precision_sent: 0.2727272727272727
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036697247706422016
train_label=N_precision_sent: 0.5926436781609196
train_label=N_recall_sent: 0.7788519637462236
train_label=N_f-score_sent: 0.6731070496083551
train_label=P_precision_sent: 0.6600525938321778
train_label=P_recall_sent: 0.7648199445983379
train_label=P_f-score_sent: 0.708584627229565
train_precision_macro_sent: 0.5084745149067901
train_recall_macro_sent: 0.5151730663283186
train_f-score_macro_sent: 0.46178713386952075
train_precision_micro_sent: 0.6252340823970037
train_recall_micro_sent: 0.6252340823970037
train_f-score_micro_sent: 0.6252340823970037
train_label=O_precision_tok: 0.87856535007923
train_label=O_recall_tok: 0.9631032513852364
train_label=O_f-score_tok: 0.9188940339677509
train_label=N_precision_tok: 0.7373868046571799
train_label=N_recall_tok: 0.5217574989438107
train_label=N_f-score_tok: 0.6111088202548349
train_label=P_precision_tok: 0.817727404824179
train_label=P_recall_tok: 0.5623775832433945
train_label=P_f-score_tok: 0.6664298233148596
train_precision_macro_tok: 0.8112265198535297
train_recall_macro_tok: 0.6824127778574806
train_f-score_macro_tok: 0.7321442258458152
train_precision_micro_tok: 0.863492412848636
train_recall_micro_tok: 0.863492412848636
train_f-score_micro_tok: 0.8634924128486361
train_time: 84.80494904518127
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2727    0.0018    0.0037      1624
           N     0.5926    0.7789    0.6731      3310
           P     0.6601    0.7648    0.7086      3610

   micro avg     0.6252    0.6252    0.6252      8544
   macro avg     0.5085    0.5152    0.4618      8544
weighted avg     0.5603    0.6252    0.5609      8544

F1-macro sent:  0.46178713386952075
F1-micro sent:  0.6252340823970037
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8786    0.9631    0.9189    124347
           N     0.7374    0.5218    0.6111     14202
           P     0.8177    0.5624    0.6664     25017

   micro avg     0.8635    0.8635    0.8635    163566
   macro avg     0.8112    0.6824    0.7321    163566
weighted avg     0.8570    0.8635    0.8536    163566

F1-macro tok:  0.7321442258458152
F1-micro tok:  0.8634924128486361
**************************************************
dev_cost_sum: 8829.694076538086
dev_cost_avg: 8.019703975057299
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18703.0
dev_accuracy_tok: 0.8791482560872427
dev_label=O_precision_sent: 0.4166666666666667
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04149377593360996
dev_label=N_precision_sent: 0.6417322834645669
dev_label=N_recall_sent: 0.7616822429906542
dev_label=N_f-score_sent: 0.6965811965811967
dev_label=P_precision_sent: 0.6316695352839932
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.71609756097561
dev_precision_macro_sent: 0.5633561618050756
dev_recall_macro_sent: 0.5366976269008673
dev_f-score_macro_sent: 0.4847241778301388
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8810567797080535
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9277073227748233
dev_label=N_precision_tok: 0.8375241779497099
dev_label=N_recall_tok: 0.4663435648896069
dev_label=N_f-score_tok: 0.5991006572120373
dev_label=P_precision_tok: 0.8830409356725146
dev_label=P_recall_tok: 0.611145703611457
dev_label=P_f-score_tok: 0.7223551057957682
dev_precision_macro_tok: 0.8672072977767593
dev_recall_macro_tok: 0.6856878246643987
dev_f-score_macro_tok: 0.7497210285942096
dev_precision_micro_tok: 0.8791482560872427
dev_recall_micro_tok: 0.8791482560872427
dev_f-score_micro_tok: 0.8791482560872427
dev_time: 4.320714712142944
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0218    0.0415       229
           N     0.6417    0.7617    0.6966       428
           P     0.6317    0.8266    0.7161       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.5634    0.5367    0.4847      1101
weighted avg     0.5909    0.6340    0.5682      1101

F1-macro sent:  0.4847241778301388
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8811    0.9796    0.9277     16205
           N     0.8375    0.4663    0.5991      1857
           P     0.8830    0.6111    0.7224      3212

   micro avg     0.8791    0.8791    0.8791     21274
   macro avg     0.8672    0.6857    0.7497     21274
weighted avg     0.8776    0.8791    0.8680     21274

F1-macro tok:  0.7497210285942096
F1-micro tok:  0.8791482560872427
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 72056.73617553711
train_cost_avg: 8.433606762118107
train_count_sent: 8544.0
train_total_correct_sent: 5402.0
train_accuracy_sent: 0.6322565543071161
train_count_tok: 163566.0
train_total_correct_tok: 141832.0
train_accuracy_tok: 0.8671239744201118
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.02361275088547816
train_label=N_precision_sent: 0.604967197750703
train_label=N_recall_sent: 0.7800604229607251
train_label=N_f-score_sent: 0.6814462918975983
train_label=P_precision_sent: 0.6657156443176415
train_label=P_recall_sent: 0.775623268698061
train_label=P_f-score_sent: 0.7164790174002046
train_precision_macro_sent: 0.5187990425942101
train_recall_macro_sent: 0.5226663208649156
train_f-score_macro_sent: 0.47384602006109366
train_precision_micro_sent: 0.6322565543071161
train_recall_micro_sent: 0.6322565543071161
train_f-score_micro_sent: 0.6322565543071161
train_label=O_precision_tok: 0.8811563326476638
train_label=O_recall_tok: 0.9645829814953316
train_label=O_f-score_tok: 0.9209842321676067
train_label=N_precision_tok: 0.7432445710916773
train_label=N_recall_tok: 0.5326010421067455
train_label=N_f-score_tok: 0.6205340662045202
train_label=P_precision_tok: 0.8295211071862876
train_label=P_recall_tok: 0.5726106247751529
train_label=P_f-score_tok: 0.677529205883744
train_precision_macro_tok: 0.8179740036418762
train_recall_macro_tok: 0.6899315494590766
train_f-score_macro_tok: 0.7396825014186237
train_precision_micro_tok: 0.8671239744201118
train_recall_micro_tok: 0.8671239744201118
train_f-score_micro_tok: 0.8671239744201118
train_time: 84.58443665504456
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0123    0.0236      1624
           N     0.6050    0.7801    0.6814      3310
           P     0.6657    0.7756    0.7165      3610

   micro avg     0.6323    0.6323    0.6323      8544
   macro avg     0.5188    0.5227    0.4738      8544
weighted avg     0.5700    0.6323    0.5712      8544

F1-macro sent:  0.47384602006109366
F1-micro sent:  0.6322565543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8812    0.9646    0.9210    124347
           N     0.7432    0.5326    0.6205     14202
           P     0.8295    0.5726    0.6775     25017

   micro avg     0.8671    0.8671    0.8671    163566
   macro avg     0.8180    0.6899    0.7397    163566
weighted avg     0.8613    0.8671    0.8577    163566

F1-macro tok:  0.7396825014186237
F1-micro tok:  0.8671239744201118
**************************************************
dev_cost_sum: 8546.739181518555
dev_cost_avg: 7.762705886937834
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18773.0
dev_accuracy_tok: 0.882438657516217
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5960912052117264
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7024952015355087
dev_label=P_precision_sent: 0.6878850102669405
dev_label=P_recall_sent: 0.7545045045045045
dev_label=P_f-score_sent: 0.719656283566058
dev_precision_macro_sent: 0.4279920718262223
dev_recall_macro_sent: 0.5365482304734641
dev_f-score_macro_sent: 0.4740504950338556
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8919684860851329
dev_label=O_recall_tok: 0.9711200246837396
dev_label=O_f-score_tok: 0.9298629165681872
dev_label=N_precision_tok: 0.7505376344086021
dev_label=N_recall_tok: 0.5638126009693053
dev_label=N_f-score_tok: 0.6439114391143911
dev_label=P_precision_tok: 0.8895348837209303
dev_label=P_recall_tok: 0.6192403486924035
dev_label=P_f-score_tok: 0.7301762114537445
dev_precision_macro_tok: 0.8440136680715552
dev_recall_macro_tok: 0.7180576581151494
dev_f-score_macro_tok: 0.7679835223787742
dev_precision_micro_tok: 0.882438657516217
dev_recall_micro_tok: 0.882438657516217
dev_f-score_micro_tok: 0.882438657516217
dev_time: 4.238021373748779
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5961    0.8551    0.7025       428
           P     0.6879    0.7545    0.7197       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4280    0.5365    0.4741      1101
weighted avg     0.5091    0.6367    0.5633      1101

F1-macro sent:  0.4740504950338556
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8920    0.9711    0.9299     16205
           N     0.7505    0.5638    0.6439      1857
           P     0.8895    0.6192    0.7302      3212

   micro avg     0.8824    0.8824    0.8824     21274
   macro avg     0.8440    0.7181    0.7680     21274
weighted avg     0.8793    0.8824    0.8748     21274

F1-macro tok:  0.7679835223787742
F1-micro tok:  0.882438657516217
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 70340.21522521973
train_cost_avg: 8.232703092839387
train_count_sent: 8544.0
train_total_correct_sent: 5426.0
train_accuracy_sent: 0.635065543071161
train_count_tok: 163566.0
train_total_correct_tok: 142403.0
train_accuracy_tok: 0.8706149199711432
train_label=O_precision_sent: 0.42857142857142855
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007326007326007325
train_label=N_precision_sent: 0.60266604303087
train_label=N_recall_sent: 0.7785498489425982
train_label=N_f-score_sent: 0.6794094384392302
train_label=P_precision_sent: 0.6683121767748001
train_label=P_recall_sent: 0.7875346260387812
train_label=P_f-score_sent: 0.7230417090539166
train_precision_macro_sent: 0.5665165494590328
train_recall_macro_sent: 0.5232596854207224
train_f-score_macro_sent: 0.46992571827305135
train_precision_micro_sent: 0.635065543071161
train_recall_micro_sent: 0.635065543071161
train_f-score_micro_sent: 0.635065543071161
train_label=O_precision_tok: 0.8839117508536442
train_label=O_recall_tok: 0.9659501234448761
train_label=O_f-score_tok: 0.9231118027936288
train_label=N_precision_tok: 0.7462150621118012
train_label=N_recall_tok: 0.5414026193493874
train_label=N_f-score_tok: 0.6275197910715743
train_label=P_precision_tok: 0.8403936917232646
train_label=P_recall_tok: 0.5836431226765799
train_label=P_f-score_tok: 0.6888726380599656
train_precision_macro_tok: 0.8235068348962367
train_recall_macro_tok: 0.6969986218236145
train_f-score_macro_tok: 0.7465014106417228
train_precision_micro_tok: 0.8706149199711432
train_recall_micro_tok: 0.8706149199711432
train_f-score_micro_tok: 0.8706149199711432
train_time: 84.99804949760437
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0037    0.0073      1624
           N     0.6027    0.7785    0.6794      3310
           P     0.6683    0.7875    0.7230      3610

   micro avg     0.6351    0.6351    0.6351      8544
   macro avg     0.5665    0.5233    0.4699      8544
weighted avg     0.5973    0.6351    0.5701      8544

F1-macro sent:  0.46992571827305135
F1-micro sent:  0.635065543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8839    0.9660    0.9231    124347
           N     0.7462    0.5414    0.6275     14202
           P     0.8404    0.5836    0.6889     25017

   micro avg     0.8706    0.8706    0.8706    163566
   macro avg     0.8235    0.6970    0.7465    163566
weighted avg     0.8653    0.8706    0.8616    163566

F1-macro tok:  0.7465014106417228
F1-micro tok:  0.8706149199711432
**************************************************
dev_cost_sum: 8410.05850982666
dev_cost_avg: 7.638563587490155
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18820.0
dev_accuracy_tok: 0.8846479270470997
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.6866666666666666
dev_label=N_recall_sent: 0.7219626168224299
dev_label=N_f-score_sent: 0.7038724373576309
dev_label=P_precision_sent: 0.6024653312788906
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.7154620311070449
dev_precision_macro_sent: 0.596377332648519
dev_recall_macro_sent: 0.5356533532267116
dev_f-score_macro_sent: 0.4759974923742282
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8884466618083974
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9310891787099048
dev_label=N_precision_tok: 0.792094861660079
dev_label=N_recall_tok: 0.5395799676898223
dev_label=N_f-score_tok: 0.6418962203715567
dev_label=P_precision_tok: 0.9073732718894009
dev_label=P_recall_tok: 0.613013698630137
dev_label=P_f-score_tok: 0.7316982534373839
dev_precision_macro_tok: 0.8626382651192924
dev_recall_macro_tok: 0.710208379362644
dev_f-score_macro_tok: 0.7682278841729485
dev_precision_micro_tok: 0.8846479270470997
dev_recall_micro_tok: 0.8846479270470997
dev_f-score_micro_tok: 0.8846479270470997
dev_time: 4.305377960205078
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6867    0.7220    0.7039       428
           P     0.6025    0.8806    0.7155       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.5964    0.5357    0.4760      1101
weighted avg     0.6139    0.6367    0.5639      1101

F1-macro sent:  0.4759974923742282
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8884    0.9780    0.9311     16205
           N     0.7921    0.5396    0.6419      1857
           P     0.9074    0.6130    0.7317      3212

   micro avg     0.8846    0.8846    0.8846     21274
   macro avg     0.8626    0.7102    0.7682     21274
weighted avg     0.8829    0.8846    0.8757     21274

F1-macro tok:  0.7682278841729485
F1-micro tok:  0.8846479270470997
**************************************************
Best epoch: 6
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 68589.08949279785
train_cost_avg: 8.027749238389262
train_count_sent: 8544.0
train_total_correct_sent: 5479.0
train_accuracy_sent: 0.6412687265917603
train_count_tok: 163566.0
train_total_correct_tok: 142994.0
train_accuracy_tok: 0.8742281403225609
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010962241169305725
train_label=N_precision_sent: 0.6039035591274398
train_label=N_recall_sent: 0.7945619335347432
train_label=N_f-score_sent: 0.6862361382909329
train_label=P_precision_sent: 0.6808918724526493
train_label=P_recall_sent: 0.7867036011080333
train_label=P_f-score_sent: 0.729983292635908
train_precision_macro_sent: 0.5949318105266963
train_recall_macro_sent: 0.5289358021879863
train_f-score_macro_sent: 0.4757272240320489
train_precision_micro_sent: 0.6412687265917603
train_recall_micro_sent: 0.6412687265917603
train_f-score_micro_sent: 0.6412687265917603
train_label=O_precision_tok: 0.886367654859433
train_label=O_recall_tok: 0.9675504837269898
train_label=O_f-score_tok: 0.9251815766505308
train_label=N_precision_tok: 0.7599884470973332
train_label=N_recall_tok: 0.5558372060273201
train_label=N_f-score_tok: 0.6420757249176461
train_label=P_precision_tok: 0.8477899443902999
train_label=P_recall_tok: 0.5911180397329816
train_label=P_f-score_tok: 0.6965614696184645
train_precision_macro_tok: 0.831382015449022
train_recall_macro_tok: 0.7048352431624304
train_f-score_macro_tok: 0.7546062570622137
train_precision_micro_tok: 0.8742281403225609
train_recall_micro_tok: 0.8742281403225609
train_f-score_micro_tok: 0.8742281403225609
train_time: 85.05583381652832
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0055    0.0110      1624
           N     0.6039    0.7946    0.6862      3310
           P     0.6809    0.7867    0.7300      3610

   micro avg     0.6413    0.6413    0.6413      8544
   macro avg     0.5949    0.5289    0.4757      8544
weighted avg     0.6167    0.6413    0.5764      8544

F1-macro sent:  0.4757272240320489
F1-micro sent:  0.6412687265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8864    0.9676    0.9252    124347
           N     0.7600    0.5558    0.6421     14202
           P     0.8478    0.5911    0.6966     25017

   micro avg     0.8742    0.8742    0.8742    163566
   macro avg     0.8314    0.7048    0.7546    163566
weighted avg     0.8695    0.8742    0.8656    163566

F1-macro tok:  0.7546062570622137
F1-micro tok:  0.8742281403225609
**************************************************
dev_cost_sum: 8312.549530029297
dev_cost_avg: 7.549999573141959
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18866.0
dev_accuracy_tok: 0.8868101908432828
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6167247386759582
dev_label=N_recall_sent: 0.8271028037383178
dev_label=N_f-score_sent: 0.7065868263473055
dev_label=P_precision_sent: 0.6641366223908919
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7209062821833163
dev_precision_macro_sent: 0.4269537870222833
dev_recall_macro_sent: 0.538463697342202
dev_f-score_macro_sent: 0.475831036176874
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8873577326489623
dev_label=O_recall_tok: 0.9814871953100894
dev_label=O_f-score_tok: 0.9320519206539892
dev_label=N_precision_tok: 0.8189438390611903
dev_label=N_recall_tok: 0.526117393645665
dev_label=N_f-score_tok: 0.6406557377049179
dev_label=P_precision_tok: 0.9197960129809921
dev_label=P_recall_tok: 0.6176836861768369
dev_label=P_f-score_tok: 0.7390575526168748
dev_precision_macro_tok: 0.875365861563715
dev_recall_macro_tok: 0.7084294250441973
dev_f-score_macro_tok: 0.770588403658594
dev_precision_micro_tok: 0.8868101908432828
dev_recall_micro_tok: 0.8868101908432828
dev_f-score_micro_tok: 0.8868101908432828
dev_time: 4.325909614562988
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6167    0.8271    0.7066       428
           P     0.6641    0.7883    0.7209       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.4270    0.5385    0.4758      1101
weighted avg     0.5076    0.6394    0.5654      1101

F1-macro sent:  0.475831036176874
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8874    0.9815    0.9321     16205
           N     0.8189    0.5261    0.6407      1857
           P     0.9198    0.6177    0.7391      3212

   micro avg     0.8868    0.8868    0.8868     21274
   macro avg     0.8754    0.7084    0.7706     21274
weighted avg     0.8863    0.8868    0.8775     21274

F1-macro tok:  0.770588403658594
F1-micro tok:  0.8868101908432828
**************************************************
Best epoch: 6
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 67275.79699707031
train_cost_avg: 7.874039910705795
train_count_sent: 8544.0
train_total_correct_sent: 5507.0
train_accuracy_sent: 0.6445458801498127
train_count_tok: 163566.0
train_total_correct_tok: 143384.0
train_accuracy_tok: 0.8766124989300955
train_label=O_precision_sent: 0.3888888888888889
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.016867469879518072
train_label=N_precision_sent: 0.5992915651981403
train_label=N_recall_sent: 0.8178247734138973
train_label=N_f-score_sent: 0.6917081896001022
train_label=P_precision_sent: 0.6980706589827111
train_label=P_recall_sent: 0.7717451523545706
train_label=P_f-score_sent: 0.7330614392843048
train_precision_macro_sent: 0.5620837043565801
train_recall_macro_sent: 0.5327302051412134
train_f-score_macro_sent: 0.48054569958797505
train_precision_micro_sent: 0.6445458801498127
train_recall_micro_sent: 0.6445458801498127
train_f-score_micro_sent: 0.6445458801498127
train_label=O_precision_tok: 0.888693675072344
train_label=O_recall_tok: 0.968145592575615
train_label=O_f-score_tok: 0.9267198078603293
train_label=N_precision_tok: 0.7636052806534334
train_label=N_recall_tok: 0.5661174482467258
train_label=N_f-score_tok: 0.650196110145162
train_label=P_precision_tok: 0.8511921698059524
train_label=P_recall_tok: 0.5979134188751649
train_label=P_f-score_tok: 0.7024184080770134
train_precision_macro_tok: 0.8344970418439098
train_recall_macro_tok: 0.7107254865658352
train_f-score_macro_tok: 0.7597781086941682
train_precision_micro_tok: 0.8766124989300955
train_recall_micro_tok: 0.8766124989300955
train_f-score_micro_tok: 0.8766124989300955
train_time: 84.77030658721924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3889    0.0086    0.0169      1624
           N     0.5993    0.8178    0.6917      3310
           P     0.6981    0.7717    0.7331      3610

   micro avg     0.6445    0.6445    0.6445      8544
   macro avg     0.5621    0.5327    0.4805      8544
weighted avg     0.6010    0.6445    0.5809      8544

F1-macro sent:  0.48054569958797505
F1-micro sent:  0.6445458801498127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8887    0.9681    0.9267    124347
           N     0.7636    0.5661    0.6502     14202
           P     0.8512    0.5979    0.7024     25017

   micro avg     0.8766    0.8766    0.8766    163566
   macro avg     0.8345    0.7107    0.7598    163566
weighted avg     0.8721    0.8766    0.8684    163566

F1-macro tok:  0.7597781086941682
F1-micro tok:  0.8766124989300955
**************************************************
dev_cost_sum: 8133.756782531738
dev_cost_avg: 7.3876083401741495
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18932.0
dev_accuracy_tok: 0.8899125693334586
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6198630136986302
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7154150197628459
dev_label=P_precision_sent: 0.6731141199226306
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7242455775234131
dev_precision_macro_sent: 0.4309923778737536
dev_recall_macro_sent: 0.5431927254357162
dev_f-score_macro_sent: 0.47988686576208633
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8948736788560447
dev_label=O_recall_tok: 0.977044122184511
dev_label=O_f-score_tok: 0.9341554073986666
dev_label=N_precision_tok: 0.7884476534296029
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6736582356570019
dev_label=P_precision_tok: 0.9139344262295082
dev_label=P_recall_tok: 0.6248443337484434
dev_label=P_f-score_tok: 0.742233727810651
dev_precision_macro_tok: 0.865751919505052
dev_recall_macro_tok: 0.7299778967272476
dev_f-score_macro_tok: 0.7833491236221065
dev_precision_micro_tok: 0.8899125693334586
dev_recall_micro_tok: 0.8899125693334586
dev_f-score_micro_tok: 0.8899125693334586
dev_time: 4.355350732803345
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6199    0.8458    0.7154       428
           P     0.6731    0.7838    0.7242       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.4310    0.5432    0.4799      1101
weighted avg     0.5124    0.6449    0.5702      1101

F1-macro sent:  0.47988686576208633
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9770    0.9342     16205
           N     0.7884    0.5880    0.6737      1857
           P     0.9139    0.6248    0.7422      3212

   micro avg     0.8899    0.8899    0.8899     21274
   macro avg     0.8658    0.7300    0.7833     21274
weighted avg     0.8885    0.8899    0.8824     21274

F1-macro tok:  0.7833491236221065
F1-micro tok:  0.8899125693334586
**************************************************
Best epoch: 6
**************************************************

EPOCH: 11
Learning rate: 0.900000
train_cost_sum: 65567.78257751465
train_cost_avg: 7.67413185598252
train_count_sent: 8544.0
train_total_correct_sent: 5545.0
train_accuracy_sent: 0.6489934456928839
train_count_tok: 163566.0
train_total_correct_tok: 143889.0
train_accuracy_tok: 0.8796999376398518
train_label=O_precision_sent: 0.36585365853658536
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.01801801801801802
train_label=N_precision_sent: 0.6104014598540146
train_label=N_recall_sent: 0.8084592145015106
train_label=N_f-score_sent: 0.6956069664673772
train_label=P_precision_sent: 0.6928866229667395
train_label=P_recall_sent: 0.7905817174515235
train_label=P_f-score_sent: 0.7385172726096519
train_precision_macro_sent: 0.5563805804524465
train_recall_macro_sent: 0.5360924617183348
train_f-score_macro_sent: 0.4840474190316824
train_precision_micro_sent: 0.6489934456928839
train_recall_micro_sent: 0.6489934456928839
train_f-score_micro_sent: 0.6489934456928839
train_label=O_precision_tok: 0.8913728565299087
train_label=O_recall_tok: 0.9690141298141491
train_label=O_f-score_tok: 0.9285733551680956
train_label=N_precision_tok: 0.7688111361926261
train_label=N_recall_tok: 0.5755527390508379
train_label=N_f-score_tok: 0.6582910525891923
train_label=P_precision_tok: 0.8572313584140572
train_label=P_recall_tok: 0.6084262701363073
train_label=P_f-score_tok: 0.7117106585930377
train_precision_macro_tok: 0.839138450378864
train_recall_macro_tok: 0.7176643796670982
train_f-score_macro_tok: 0.7661916887834419
train_precision_micro_tok: 0.8796999376398518
train_recall_micro_tok: 0.8796999376398518
train_f-score_micro_tok: 0.8796999376398518
train_time: 85.09861254692078
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3659    0.0092    0.0180      1624
           N     0.6104    0.8085    0.6956      3310
           P     0.6929    0.7906    0.7385      3610

   micro avg     0.6490    0.6490    0.6490      8544
   macro avg     0.5564    0.5361    0.4840      8544
weighted avg     0.5988    0.6490    0.5849      8544

F1-macro sent:  0.4840474190316824
F1-micro sent:  0.6489934456928839
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8914    0.9690    0.9286    124347
           N     0.7688    0.5756    0.6583     14202
           P     0.8572    0.6084    0.7117     25017

   micro avg     0.8797    0.8797    0.8797    163566
   macro avg     0.8391    0.7177    0.7662    163566
weighted avg     0.8755    0.8797    0.8719    163566

F1-macro tok:  0.7661916887834419
F1-micro tok:  0.8796999376398518
**************************************************
dev_cost_sum: 8081.699333190918
dev_cost_avg: 7.340326369837346
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18914.0
dev_accuracy_tok: 0.8890664661088653
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.559774964838256
dev_label=N_recall_sent: 0.9299065420560748
dev_label=N_f-score_sent: 0.6988586479367866
dev_label=P_precision_sent: 0.7480719794344473
dev_label=P_recall_sent: 0.6554054054054054
dev_label=P_f-score_sent: 0.6986794717887155
dev_precision_macro_sent: 0.7692823147575677
dev_recall_macro_sent: 0.5298929198961848
dev_f-score_macro_sent: 0.4687445906331384
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8884180003345787
dev_label=O_recall_tok: 0.9831533477321814
dev_label=O_f-score_tok: 0.9333880133575488
dev_label=N_precision_tok: 0.8174474959612278
dev_label=N_recall_tok: 0.5449649973074852
dev_label=N_f-score_tok: 0.6539579967689821
dev_label=P_precision_tok: 0.936757013789824
dev_label=P_recall_tok: 0.6133250311332503
dev_label=P_f-score_tok: 0.7412982126058325
dev_precision_macro_tok: 0.8808741700285435
dev_recall_macro_tok: 0.7138144587243057
dev_f-score_macro_tok: 0.7762147409107878
dev_precision_micro_tok: 0.8890664661088653
dev_recall_micro_tok: 0.8890664661088653
dev_f-score_micro_tok: 0.8890664661088653
dev_time: 4.385086536407471
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.5598    0.9299    0.6989       428
           P     0.7481    0.6554    0.6987       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.7693    0.5299    0.4687      1101
weighted avg     0.7273    0.6267    0.5552      1101

F1-macro sent:  0.4687445906331384
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8884    0.9832    0.9334     16205
           N     0.8174    0.5450    0.6540      1857
           P     0.9368    0.6133    0.7413      3212

   micro avg     0.8891    0.8891    0.8891     21274
   macro avg     0.8809    0.7138    0.7762     21274
weighted avg     0.8895    0.8891    0.8800     21274

F1-macro tok:  0.7762147409107878
F1-micro tok:  0.8890664661088653
**************************************************
Best epoch: 6
**************************************************

EPOCH: 12
Learning rate: 0.810000
train_cost_sum: 64462.87803649902
train_cost_avg: 7.544812504271889
train_count_sent: 8544.0
train_total_correct_sent: 5564.0
train_accuracy_sent: 0.6512172284644194
train_count_tok: 163566.0
train_total_correct_tok: 144361.0
train_accuracy_tok: 0.8825856229289706
train_label=O_precision_sent: 0.38095238095238093
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009726443768996961
train_label=N_precision_sent: 0.6139398053858339
train_label=N_recall_sent: 0.8196374622356496
train_label=N_f-score_sent: 0.7020313106482081
train_label=P_precision_sent: 0.692738791423002
train_label=P_recall_sent: 0.7875346260387812
train_label=P_f-score_sent: 0.7371013741249676
train_precision_macro_sent: 0.562543659253739
train_recall_macro_sent: 0.537366065549605
train_f-score_macro_sent: 0.4829530428473909
train_precision_micro_sent: 0.6512172284644194
train_recall_micro_sent: 0.6512172284644194
train_f-score_micro_sent: 0.6512172284644194
train_label=O_precision_tok: 0.893424053069565
train_label=O_recall_tok: 0.9704536498669047
train_label=O_f-score_tok: 0.9303471271900238
train_label=N_precision_tok: 0.7760314341846758
train_label=N_recall_tok: 0.5840726658217152
train_label=N_f-score_tok: 0.6665059660118116
train_label=P_precision_tok: 0.8643382559380088
train_label=P_recall_tok: 0.6153015949154574
train_label=P_f-score_tok: 0.7188623733246159
train_precision_macro_tok: 0.8445979143974164
train_recall_macro_tok: 0.723275970201359
train_f-score_macro_tok: 0.7719051555088171
train_precision_micro_tok: 0.8825856229289706
train_recall_micro_tok: 0.8825856229289706
train_f-score_micro_tok: 0.8825856229289706
train_time: 84.19737577438354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3810    0.0049    0.0097      1624
           N     0.6139    0.8196    0.7020      3310
           P     0.6927    0.7875    0.7371      3610

   micro avg     0.6512    0.6512    0.6512      8544
   macro avg     0.5625    0.5374    0.4830      8544
weighted avg     0.6029    0.6512    0.5853      8544

F1-macro sent:  0.4829530428473909
F1-micro sent:  0.6512172284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9705    0.9303    124347
           N     0.7760    0.5841    0.6665     14202
           P     0.8643    0.6153    0.7189     25017

   micro avg     0.8826    0.8826    0.8826    163566
   macro avg     0.8446    0.7233    0.7719    163566
weighted avg     0.8788    0.8826    0.8751    163566

F1-macro tok:  0.7719051555088171
F1-micro tok:  0.8825856229289706
**************************************************
dev_cost_sum: 7982.0256423950195
dev_cost_avg: 7.249796223792025
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18969.0
dev_accuracy_tok: 0.8916517815173451
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6501901140684411
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7169811320754716
dev_label=P_precision_sent: 0.6504347826086957
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7340529931305201
dev_precision_macro_sent: 0.43354163222571224
dev_recall_macro_sent: 0.5471359209676967
dev_f-score_macro_sent: 0.4836780417353306
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8928110443908188
dev_label=O_recall_tok: 0.9817340327059549
dev_label=O_f-score_tok: 0.9351634140606631
dev_label=N_precision_tok: 0.844044558697515
dev_label=N_recall_tok: 0.5304254173397954
dev_label=N_f-score_tok: 0.6514550264550265
dev_label=P_precision_tok: 0.9069055944055944
dev_label=P_recall_tok: 0.6460149439601495
dev_label=P_f-score_tok: 0.7545454545454545
dev_precision_macro_tok: 0.8812537324979761
dev_recall_macro_tok: 0.7193914646686332
dev_f-score_macro_tok: 0.7803879650203814
dev_precision_micro_tok: 0.8916517815173451
dev_recall_micro_tok: 0.8916517815173451
dev_f-score_micro_tok: 0.8916517815173451
dev_time: 4.326767206192017
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6502    0.7991    0.7170       428
           P     0.6504    0.8423    0.7341       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.4335    0.5471    0.4837      1101
weighted avg     0.5151    0.6503    0.5747      1101

F1-macro sent:  0.4836780417353306
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8928    0.9817    0.9352     16205
           N     0.8440    0.5304    0.6515      1857
           P     0.9069    0.6460    0.7545      3212

   micro avg     0.8917    0.8917    0.8917     21274
   macro avg     0.8813    0.7194    0.7804     21274
weighted avg     0.8907    0.8917    0.8831     21274

F1-macro tok:  0.7803879650203814
F1-micro tok:  0.8916517815173451
**************************************************
Best epoch: 6
**************************************************

EPOCH: 13
Learning rate: 0.729000
train_cost_sum: 63276.0924987793
train_cost_avg: 7.405909702572483
train_count_sent: 8544.0
train_total_correct_sent: 5609.0
train_accuracy_sent: 0.6564840823970037
train_count_tok: 163566.0
train_total_correct_tok: 144738.0
train_accuracy_tok: 0.884890502916254
train_label=O_precision_sent: 0.35
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.016826923076923076
train_label=N_precision_sent: 0.6179341657207719
train_label=N_recall_sent: 0.8223564954682779
train_label=N_f-score_sent: 0.7056383668178873
train_label=P_precision_sent: 0.7009026591851671
train_label=P_recall_sent: 0.7958448753462604
train_label=P_f-score_sent: 0.7453625632377741
train_precision_macro_sent: 0.556278941635313
train_recall_macro_sent: 0.5422740201565702
train_f-score_macro_sent: 0.4892759510441948
train_precision_micro_sent: 0.6564840823970037
train_recall_micro_sent: 0.6564840823970037
train_f-score_micro_sent: 0.6564840823970037
train_label=O_precision_tok: 0.8953671160148893
train_label=O_recall_tok: 0.9710809267614016
train_label=O_f-score_tok: 0.9316883287231539
train_label=N_precision_tok: 0.7814187302178365
train_label=N_recall_tok: 0.5910435149978877
train_label=N_f-score_tok: 0.6730275817831943
train_label=P_precision_tok: 0.8681104554058569
train_label=P_recall_tok: 0.6232961586121437
train_label=P_f-score_tok: 0.7256101817166524
train_precision_macro_tok: 0.8482987672128609
train_recall_macro_tok: 0.7284735334571444
train_f-score_macro_tok: 0.7767753640743336
train_precision_micro_tok: 0.884890502916254
train_recall_micro_tok: 0.884890502916254
train_f-score_micro_tok: 0.884890502916254
train_time: 84.63270926475525
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3500    0.0086    0.0168      1624
           N     0.6179    0.8224    0.7056      3310
           P     0.7009    0.7958    0.7454      3610

   micro avg     0.6565    0.6565    0.6565      8544
   macro avg     0.5563    0.5423    0.4893      8544
weighted avg     0.6021    0.6565    0.5915      8544

F1-macro sent:  0.4892759510441948
F1-micro sent:  0.6564840823970037
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8954    0.9711    0.9317    124347
           N     0.7814    0.5910    0.6730     14202
           P     0.8681    0.6233    0.7256     25017

   micro avg     0.8849    0.8849    0.8849    163566
   macro avg     0.8483    0.7285    0.7768    163566
weighted avg     0.8813    0.8849    0.8777    163566

F1-macro tok:  0.7767753640743336
F1-micro tok:  0.884890502916254
**************************************************
dev_cost_sum: 7942.356140136719
dev_cost_avg: 7.213765794856239
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19013.0
dev_accuracy_tok: 0.893720033844129
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6549707602339181
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7141339001062698
dev_label=P_precision_sent: 0.6354344122657581
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.72356935014549
dev_precision_macro_sent: 0.43013505749989206
dev_recall_macro_sent: 0.5417122730206843
dev_f-score_macro_sent: 0.4792344167505866
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8972110652259999
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.9361903075379256
dev_label=N_precision_tok: 0.8244514106583072
dev_label=N_recall_tok: 0.5665051157781368
dev_label=N_f-score_tok: 0.6715608043408874
dev_label=P_precision_tok: 0.9052132701421801
dev_label=P_recall_tok: 0.6541095890410958
dev_label=P_f-score_tok: 0.7594433399602386
dev_precision_macro_tok: 0.8756252486754957
dev_recall_macro_tok: 0.7331083264752785
dev_f-score_macro_tok: 0.7890648172796838
dev_precision_micro_tok: 0.893720033844129
dev_recall_micro_tok: 0.893720033844129
dev_f-score_micro_tok: 0.893720033844129
dev_time: 4.310882568359375
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6550    0.7850    0.7141       428
           P     0.6354    0.8401    0.7236       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.4301    0.5417    0.4792      1101
weighted avg     0.5109    0.6440    0.5694      1101

F1-macro sent:  0.4792344167505866
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9787    0.9362     16205
           N     0.8245    0.5665    0.6716      1857
           P     0.9052    0.6541    0.7594      3212

   micro avg     0.8937    0.8937    0.8937     21274
   macro avg     0.8756    0.7331    0.7891     21274
weighted avg     0.8921    0.8937    0.8864     21274

F1-macro tok:  0.7890648172796838
F1-micro tok:  0.893720033844129
**************************************************
Best epoch: 6
**************************************************

test0_cost_sum: 8829.694076538086
test0_cost_avg: 8.019703975057299
test0_count_sent: 1101.0
test0_total_correct_sent: 698.0
test0_accuracy_sent: 0.633969118982743
test0_count_tok: 21274.0
test0_total_correct_tok: 18703.0
test0_accuracy_tok: 0.8791482560872427
test0_label=O_precision_sent: 0.4166666666666667
test0_label=O_recall_sent: 0.021834061135371178
test0_label=O_f-score_sent: 0.04149377593360996
test0_label=N_precision_sent: 0.6417322834645669
test0_label=N_recall_sent: 0.7616822429906542
test0_label=N_f-score_sent: 0.6965811965811967
test0_label=P_precision_sent: 0.6316695352839932
test0_label=P_recall_sent: 0.8265765765765766
test0_label=P_f-score_sent: 0.71609756097561
test0_precision_macro_sent: 0.5633561618050756
test0_recall_macro_sent: 0.5366976269008673
test0_f-score_macro_sent: 0.4847241778301388
test0_precision_micro_sent: 0.633969118982743
test0_recall_micro_sent: 0.633969118982743
test0_f-score_micro_sent: 0.633969118982743
test0_label=O_precision_tok: 0.8810567797080535
test0_label=O_recall_tok: 0.979574205492132
test0_label=O_f-score_tok: 0.9277073227748233
test0_label=N_precision_tok: 0.8375241779497099
test0_label=N_recall_tok: 0.4663435648896069
test0_label=N_f-score_tok: 0.5991006572120373
test0_label=P_precision_tok: 0.8830409356725146
test0_label=P_recall_tok: 0.611145703611457
test0_label=P_f-score_tok: 0.7223551057957682
test0_precision_macro_tok: 0.8672072977767593
test0_recall_macro_tok: 0.6856878246643987
test0_f-score_macro_tok: 0.7497210285942096
test0_precision_micro_tok: 0.8791482560872427
test0_recall_micro_tok: 0.8791482560872427
test0_f-score_micro_tok: 0.8791482560872427
test0_time: 4.272462606430054
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0218    0.0415       229
           N     0.6417    0.7617    0.6966       428
           P     0.6317    0.8266    0.7161       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.5634    0.5367    0.4847      1101
weighted avg     0.5909    0.6340    0.5682      1101

F1-macro sent:  0.4847241778301388
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8811    0.9796    0.9277     16205
           N     0.8375    0.4663    0.5991      1857
           P     0.8830    0.6111    0.7224      3212

   micro avg     0.8791    0.8791    0.8791     21274
   macro avg     0.8672    0.6857    0.7497     21274
weighted avg     0.8776    0.8791    0.8680     21274

F1-macro tok:  0.7497210285942096
F1-micro tok:  0.8791482560872427
**************************************************
test1_cost_sum: 18394.560052871704
test1_cost_avg: 8.32333034066593
test1_count_sent: 2210.0
test1_total_correct_sent: 1466.0
test1_accuracy_sent: 0.6633484162895927
test1_count_tok: 42405.0
test1_total_correct_tok: 36906.0
test1_accuracy_tok: 0.8703218960028298
test1_label=O_precision_sent: 0.42857142857142855
test1_label=O_recall_sent: 0.02313624678663239
test1_label=O_f-score_sent: 0.04390243902439025
test1_label=N_precision_sent: 0.6682554814108675
test1_label=N_recall_sent: 0.768640350877193
test1_label=N_f-score_sent: 0.7149413564507905
test1_label=P_precision_sent: 0.6631578947368421
test1_label=P_recall_sent: 0.8316831683168316
test1_label=P_f-score_sent: 0.7379209370424596
test1_precision_macro_sent: 0.586661601573046
test1_recall_macro_sent: 0.5411532553268857
test1_f-score_macro_sent: 0.4989215775058802
test1_precision_micro_sent: 0.6633484162895927
test1_recall_micro_sent: 0.6633484162895927
test1_f-score_micro_sent: 0.6633484162895927
test1_label=O_precision_tok: 0.8715881927844794
test1_label=O_recall_tok: 0.9799987499218701
test1_label=O_f-score_tok: 0.9226197481464046
test1_label=N_precision_tok: 0.826251180358829
test1_label=N_recall_tok: 0.4654255319148936
test1_label=N_f-score_tok: 0.5954406260632868
test1_label=P_precision_tok: 0.8814110002320724
test1_label=P_recall_tok: 0.5713855874830751
test1_label=P_f-score_tok: 0.6933187294633079
test1_precision_macro_tok: 0.8597501244584603
test1_recall_macro_tok: 0.6722699564399462
test1_f-score_macro_tok: 0.7371263678909997
test1_precision_micro_tok: 0.8703218960028298
test1_recall_micro_tok: 0.8703218960028298
test1_f-score_micro_tok: 0.8703218960028298
test1_time: 8.746045112609863
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0231    0.0439       389
           N     0.6683    0.7686    0.7149       912
           P     0.6632    0.8317    0.7379       909

   micro avg     0.6633    0.6633    0.6633      2210
   macro avg     0.5867    0.5412    0.4989      2210
weighted avg     0.6240    0.6633    0.6063      2210

F1-macro sent:  0.4989215775058802
F1-micro sent:  0.6633484162895927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8716    0.9800    0.9226     31998
           N     0.8263    0.4654    0.5954      3760
           P     0.8814    0.5714    0.6933      6647

   micro avg     0.8703    0.8703    0.8703     42405
   macro avg     0.8598    0.6723    0.7371     42405
weighted avg     0.8691    0.8703    0.8577     42405

F1-macro tok:  0.7371263678909997
F1-micro tok:  0.8703218960028298
**************************************************
