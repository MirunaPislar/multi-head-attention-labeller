to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.5_+attention_loss=0.5_model_selector_tok+sent_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:dev_f-score_macro_tok:high
model_selector_ratio: 1:1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.5
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.5
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428214.9442138672
train_cost_avg: 50.11879028720356
train_count_sent: 8544.0
train_total_correct_sent: 4372.0
train_accuracy_sent: 0.5117041198501873
train_count_tok: 163566.0
train_total_correct_tok: 126147.0
train_accuracy_tok: 0.7712299622170867
train_label=O_precision_sent: 0.23484848484848486
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.09207920792079208
train_label=N_precision_sent: 0.5046397379912664
train_label=N_recall_sent: 0.5586102719033232
train_label=N_f-score_sent: 0.5302552337252653
train_label=P_precision_sent: 0.5419268510258698
train_label=P_recall_sent: 0.6731301939058172
train_label=P_f-score_sent: 0.6004447739065975
train_precision_macro_sent: 0.42713835795520705
train_recall_macro_sent: 0.42966882522045236
train_f-score_macro_sent: 0.40759307185088495
train_precision_micro_sent: 0.5117041198501873
train_recall_micro_sent: 0.5117041198501873
train_f-score_micro_sent: 0.5117041198501873
train_label=O_precision_tok: 0.7974548523206751
train_label=O_recall_tok: 0.9499465206237384
train_label=O_f-score_tok: 0.8670468892216447
train_label=N_precision_tok: 0.5118189438390612
train_label=N_recall_tok: 0.21496972257428532
train_label=N_f-score_tok: 0.302771855010661
train_label=P_precision_tok: 0.5245884339383706
train_label=P_recall_tok: 0.19870488068113681
train_label=P_f-score_tok: 0.2882323949786913
train_precision_macro_tok: 0.6112874100327024
train_recall_macro_tok: 0.4545403746263869
train_f-score_macro_tok: 0.4860170464036657
train_precision_micro_tok: 0.7712299622170867
train_recall_micro_tok: 0.7712299622170867
train_f-score_micro_tok: 0.7712299622170868
train_time: 122.73705291748047
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2348    0.0573    0.0921      1624
           N     0.5046    0.5586    0.5303      3310
           P     0.5419    0.6731    0.6004      3610

   micro avg     0.5117    0.5117    0.5117      8544
   macro avg     0.4271    0.4297    0.4076      8544
weighted avg     0.4691    0.5117    0.4766      8544

F1-macro sent:  0.40759307185088495
F1-micro sent:  0.5117041198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7975    0.9499    0.8670    124347
           N     0.5118    0.2150    0.3028     14202
           P     0.5246    0.1987    0.2882     25017

   micro avg     0.7712    0.7712    0.7712    163566
   macro avg     0.6113    0.4545    0.4860    163566
weighted avg     0.7309    0.7712    0.7295    163566

F1-macro tok:  0.4860170464036657
F1-micro tok:  0.7712299622170868
**************************************************
dev_cost_sum: 50712.698974609375
dev_cost_avg: 46.060580358409965
dev_count_sent: 1101.0
dev_total_correct_sent: 658.0
dev_accuracy_sent: 0.59763851044505
dev_count_tok: 21274.0
dev_total_correct_tok: 17492.0
dev_accuracy_tok: 0.8222243113659866
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5995934959349594
dev_label=N_recall_sent: 0.6892523364485982
dev_label=N_f-score_sent: 0.641304347826087
dev_label=P_precision_sent: 0.5960591133004927
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.6894586894586895
dev_precision_macro_sent: 0.3985508697451507
dev_recall_macro_sent: 0.5022733013387218
dev_f-score_macro_sent: 0.4435876790949255
dev_precision_micro_sent: 0.59763851044505
dev_recall_micro_sent: 0.59763851044505
dev_f-score_micro_sent: 0.59763851044505
dev_label=O_precision_tok: 0.8460816777041943
dev_label=O_recall_tok: 0.946066029003394
dev_label=O_f-score_tok: 0.8932847778587034
dev_label=N_precision_tok: 0.65402124430956
dev_label=N_recall_tok: 0.4641895530425417
dev_label=N_f-score_tok: 0.5429921259842521
dev_label=P_precision_tok: 0.7075163398692811
dev_label=P_recall_tok: 0.4044209215442092
dev_label=P_f-score_tok: 0.5146592709984152
dev_precision_macro_tok: 0.7358730872943452
dev_recall_macro_tok: 0.6048921678633816
dev_f-score_macro_tok: 0.6503120582804569
dev_precision_micro_tok: 0.8222243113659866
dev_recall_micro_tok: 0.8222243113659866
dev_f-score_micro_tok: 0.8222243113659866
dev_time: 5.632135629653931
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5996    0.6893    0.6413       428
           P     0.5961    0.8176    0.6895       444

   micro avg     0.5976    0.5976    0.5976      1101
   macro avg     0.3986    0.5023    0.4436      1101
weighted avg     0.4735    0.5976    0.5273      1101

F1-macro sent:  0.4435876790949255
F1-micro sent:  0.59763851044505
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8461    0.9461    0.8933     16205
           N     0.6540    0.4642    0.5430      1857
           P     0.7075    0.4044    0.5147      3212

   micro avg     0.8222    0.8222    0.8222     21274
   macro avg     0.7359    0.6049    0.6503     21274
weighted avg     0.8084    0.8222    0.8055     21274

F1-macro tok:  0.6503120582804569
F1-micro tok:  0.8222243113659866
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379376.4598388672
train_cost_avg: 44.402675542938574
train_count_sent: 8544.0
train_total_correct_sent: 4918.0
train_accuracy_sent: 0.5756086142322098
train_count_tok: 163566.0
train_total_correct_tok: 132329.0
train_accuracy_tok: 0.8090251030165193
train_label=O_precision_sent: 0.14634146341463414
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.0072072072072072065
train_label=N_precision_sent: 0.5415816904600045
train_label=N_recall_sent: 0.7220543806646526
train_label=N_f-score_sent: 0.6189304674349346
train_label=P_precision_sent: 0.6166259168704157
train_label=P_recall_sent: 0.6986149584487534
train_label=P_f-score_sent: 0.6550649350649351
train_precision_macro_sent: 0.43484969024835146
train_recall_macro_sent: 0.4747879734647314
train_f-score_macro_sent: 0.4270675365690257
train_precision_micro_sent: 0.5756086142322098
train_recall_micro_sent: 0.5756086142322098
train_f-score_micro_sent: 0.5756086142322098
train_label=O_precision_tok: 0.8317682725245662
train_label=O_recall_tok: 0.9509678560801628
train_label=O_f-score_tok: 0.8873830267828331
train_label=N_precision_tok: 0.6357159542163046
train_label=N_recall_tok: 0.38325587945359807
train_label=N_f-score_tok: 0.47821121068353545
train_label=P_precision_tok: 0.6727428526914389
train_label=P_recall_tok: 0.34520526042291244
train_label=P_f-score_tok: 0.45627938923231365
train_precision_macro_tok: 0.7134090264774365
train_recall_macro_tok: 0.5598096653188911
train_f-score_macro_tok: 0.6072912088995607
train_precision_micro_tok: 0.8090251030165193
train_recall_micro_tok: 0.8090251030165193
train_f-score_micro_tok: 0.8090251030165193
train_time: 96.96768307685852
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1463    0.0037    0.0072      1624
           N     0.5416    0.7221    0.6189      3310
           P     0.6166    0.6986    0.6551      3610

   micro avg     0.5756    0.5756    0.5756      8544
   macro avg     0.4348    0.4748    0.4271      8544
weighted avg     0.4982    0.5756    0.5179      8544

F1-macro sent:  0.4270675365690257
F1-micro sent:  0.5756086142322098
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8318    0.9510    0.8874    124347
           N     0.6357    0.3833    0.4782     14202
           P     0.6727    0.3452    0.4563     25017

   micro avg     0.8090    0.8090    0.8090    163566
   macro avg     0.7134    0.5598    0.6073    163566
weighted avg     0.7904    0.8090    0.7859    163566

F1-macro tok:  0.6072912088995607
F1-micro tok:  0.8090251030165193
**************************************************
dev_cost_sum: 49225.85876464844
dev_cost_avg: 44.710135117755165
dev_count_sent: 1101.0
dev_total_correct_sent: 603.0
dev_accuracy_sent: 0.547683923705722
dev_count_tok: 21274.0
dev_total_correct_tok: 17818.0
dev_accuracy_tok: 0.8375481808780671
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.46763392857142855
dev_label=N_recall_sent: 0.9789719626168224
dev_label=N_f-score_sent: 0.6329305135951662
dev_label=P_precision_sent: 0.8975609756097561
dev_label=P_recall_sent: 0.4144144144144144
dev_label=P_f-score_sent: 0.5670261941448381
dev_precision_macro_sent: 0.45506496806039487
dev_recall_macro_sent: 0.46446212567707895
dev_f-score_macro_sent: 0.39998556924666806
dev_precision_micro_sent: 0.547683923705722
dev_recall_micro_sent: 0.547683923705722
dev_f-score_micro_sent: 0.547683923705722
dev_label=O_precision_tok: 0.8471478778048122
dev_label=O_recall_tok: 0.9668620796050602
dev_label=O_f-score_tok: 0.9030547550432279
dev_label=N_precision_tok: 0.7001582278481012
dev_label=N_recall_tok: 0.4765751211631664
dev_label=N_f-score_tok: 0.5671259211791092
dev_label=P_precision_tok: 0.834983498349835
dev_label=P_recall_tok: 0.3938356164383562
dev_label=P_f-score_tok: 0.5352231859530359
dev_precision_macro_tok: 0.7940965346675828
dev_recall_macro_tok: 0.6124242724021943
dev_f-score_macro_tok: 0.6684679540584577
dev_precision_micro_tok: 0.8375481808780671
dev_recall_micro_tok: 0.8375481808780671
dev_f-score_micro_tok: 0.8375481808780673
dev_time: 5.2440314292907715
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4676    0.9790    0.6329       428
           P     0.8976    0.4144    0.5670       444

   micro avg     0.5477    0.5477    0.5477      1101
   macro avg     0.4551    0.4645    0.4000      1101
weighted avg     0.5437    0.5477    0.4747      1101

F1-macro sent:  0.39998556924666806
F1-micro sent:  0.547683923705722
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8471    0.9669    0.9031     16205
           N     0.7002    0.4766    0.5671      1857
           P     0.8350    0.3938    0.5352      3212

   micro avg     0.8375    0.8375    0.8375     21274
   macro avg     0.7941    0.6124    0.6685     21274
weighted avg     0.8325    0.8375    0.8182     21274

F1-macro tok:  0.6684679540584577
F1-micro tok:  0.8375481808780673
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369546.8054199219
train_cost_avg: 43.25220100888599
train_count_sent: 8544.0
train_total_correct_sent: 5001.0
train_accuracy_sent: 0.5853230337078652
train_count_tok: 163566.0
train_total_correct_tok: 135470.0
train_accuracy_tok: 0.8282283604172016
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014405762304921967
train_label=N_precision_sent: 0.5561308543186633
train_label=N_recall_sent: 0.7138972809667674
train_label=N_f-score_sent: 0.6252149755258632
train_label=P_precision_sent: 0.6174465083470492
train_label=P_recall_sent: 0.7274238227146814
train_label=P_f-score_sent: 0.6679384458857942
train_precision_macro_sent: 0.48643054945999936
train_recall_macro_sent: 0.4829034220810084
train_f-score_macro_sent: 0.4358530612388598
train_precision_micro_sent: 0.5853230337078652
train_recall_micro_sent: 0.5853230337078652
train_f-score_micro_sent: 0.5853230337078652
train_label=O_precision_tok: 0.8484523324105272
train_label=O_recall_tok: 0.9538308121627381
train_label=O_f-score_tok: 0.8980608621251013
train_label=N_precision_tok: 0.6739516307965387
train_label=N_recall_tok: 0.42775665399239543
train_label=N_f-score_tok: 0.5233459682977257
train_label=P_precision_tok: 0.7309125398008265
train_label=P_recall_tok: 0.43126673861773995
train_label=P_f-score_tok: 0.5424606566443763
train_precision_macro_tok: 0.7511055010026307
train_recall_macro_tok: 0.6042847349242911
train_f-score_macro_tok: 0.6546224956890678
train_precision_micro_tok: 0.8282283604172016
train_recall_micro_tok: 0.8282283604172016
train_f-score_micro_tok: 0.8282283604172016
train_time: 96.16236448287964
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0074    0.0144      1624
           N     0.5561    0.7139    0.6252      3310
           P     0.6174    0.7274    0.6679      3610

   micro avg     0.5853    0.5853    0.5853      8544
   macro avg     0.4864    0.4829    0.4359      8544
weighted avg     0.5306    0.5853    0.5272      8544

F1-macro sent:  0.4358530612388598
F1-micro sent:  0.5853230337078652
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8485    0.9538    0.8981    124347
           N     0.6740    0.4278    0.5233     14202
           P     0.7309    0.4313    0.5425     25017

   micro avg     0.8282    0.8282    0.8282    163566
   macro avg     0.7511    0.6043    0.6546    163566
weighted avg     0.8153    0.8282    0.8111    163566

F1-macro tok:  0.6546224956890678
F1-micro tok:  0.8282283604172016
**************************************************
dev_cost_sum: 48253.33044433594
dev_cost_avg: 43.826821475327826
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 18267.0
dev_accuracy_tok: 0.8586537557582025
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6255144032921811
dev_label=N_recall_sent: 0.7102803738317757
dev_label=N_f-score_sent: 0.6652078774617068
dev_label=P_precision_sent: 0.5993485342019544
dev_label=P_recall_sent: 0.8288288288288288
dev_label=P_f-score_sent: 0.6956521739130436
dev_precision_macro_sent: 0.7416209791647118
dev_recall_macro_sent: 0.5144920049625595
dev_f-score_macro_sent: 0.45651856784955447
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.8681251730822487
dev_label=O_recall_tok: 0.9672323356988584
dev_label=O_f-score_tok: 0.9150029188558085
dev_label=N_precision_tok: 0.7495621716287215
dev_label=N_recall_tok: 0.46095853527194397
dev_label=N_f-score_tok: 0.5708569523174392
dev_label=P_precision_tok: 0.8363023591718826
dev_label=P_recall_tok: 0.5407845579078456
dev_label=P_f-score_tok: 0.6568349404424277
dev_precision_macro_tok: 0.8179965679609508
dev_recall_macro_tok: 0.6563251429595494
dev_f-score_macro_tok: 0.7142316038718919
dev_precision_micro_tok: 0.8586537557582025
dev_recall_micro_tok: 0.8586537557582025
dev_f-score_micro_tok: 0.8586537557582025
dev_time: 5.181172847747803
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6255    0.7103    0.6652       428
           P     0.5993    0.8288    0.6957       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.7416    0.5145    0.4565      1101
weighted avg     0.6929    0.6113    0.5409      1101

F1-macro sent:  0.45651856784955447
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8681    0.9672    0.9150     16205
           N     0.7496    0.4610    0.5709      1857
           P     0.8363    0.5408    0.6568      3212

   micro avg     0.8587    0.8587    0.8587     21274
   macro avg     0.8180    0.6563    0.7142     21274
weighted avg     0.8530    0.8587    0.8460     21274

F1-macro tok:  0.7142316038718919
F1-micro tok:  0.8586537557582025
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362728.0549316406
train_cost_avg: 42.45412627945232
train_count_sent: 8544.0
train_total_correct_sent: 5165.0
train_accuracy_sent: 0.6045177902621723
train_count_tok: 163566.0
train_total_correct_tok: 137851.0
train_accuracy_tok: 0.8427851754032012
train_label=O_precision_sent: 0.38095238095238093
train_label=O_recall_sent: 0.014778325123152709
train_label=O_f-score_sent: 0.02845287492590397
train_label=N_precision_sent: 0.5679378853619548
train_label=N_recall_sent: 0.7513595166163142
train_label=N_f-score_sent: 0.6468981662114709
train_label=P_precision_sent: 0.6470014627011214
train_label=P_recall_sent: 0.7351800554016621
train_label=P_f-score_sent: 0.6882780082987552
train_precision_macro_sent: 0.5319639096718191
train_recall_macro_sent: 0.500439299047043
train_f-score_macro_sent: 0.45454301647871004
train_precision_micro_sent: 0.6045177902621723
train_recall_micro_sent: 0.6045177902621723
train_f-score_micro_sent: 0.6045177902621723
train_label=O_precision_tok: 0.8602949144950257
train_label=O_recall_tok: 0.9576105575526551
train_label=O_f-score_tok: 0.906347998173238
train_label=N_precision_tok: 0.6981333333333334
train_label=N_recall_tok: 0.4608505844247289
train_label=N_f-score_tok: 0.5552021037451754
train_label=P_precision_tok: 0.7751299277474966
train_label=P_recall_tok: 0.4888675700523644
train_label=P_f-score_tok: 0.5995832822649836
train_precision_macro_tok: 0.7778527251919519
train_recall_macro_tok: 0.6357762373432495
train_f-score_macro_tok: 0.6870444613944656
train_precision_micro_tok: 0.8427851754032012
train_recall_micro_tok: 0.8427851754032012
train_f-score_micro_tok: 0.8427851754032011
train_time: 97.34329771995544
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3810    0.0148    0.0285      1624
           N     0.5679    0.7514    0.6469      3310
           P     0.6470    0.7352    0.6883      3610

   micro avg     0.6045    0.6045    0.6045      8544
   macro avg     0.5320    0.5004    0.4545      8544
weighted avg     0.5658    0.6045    0.5468      8544

F1-macro sent:  0.45454301647871004
F1-micro sent:  0.6045177902621723
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8603    0.9576    0.9063    124347
           N     0.6981    0.4609    0.5552     14202
           P     0.7751    0.4889    0.5996     25017

   micro avg     0.8428    0.8428    0.8428    163566
   macro avg     0.7779    0.6358    0.6870    163566
weighted avg     0.8332    0.8428    0.8289    163566

F1-macro tok:  0.6870444613944656
F1-micro tok:  0.8427851754032011
**************************************************
dev_cost_sum: 47594.77526855469
dev_cost_avg: 43.22867871803332
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18381.0
dev_accuracy_tok: 0.8640124095139607
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6334661354581673
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.6838709677419355
dev_label=P_precision_sent: 0.622895622895623
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7129094412331406
dev_precision_macro_sent: 0.6187872527845967
dev_recall_macro_sent: 0.5298081414067212
dev_f-score_macro_sent: 0.47414047820536726
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8730317698770378
dev_label=O_recall_tok: 0.9682813946312866
dev_label=O_f-score_tok: 0.9181929896424601
dev_label=N_precision_tok: 0.7713248638838476
dev_label=N_recall_tok: 0.45772751750134627
dev_label=N_f-score_tok: 0.5745184183845894
dev_label=P_precision_tok: 0.836743974533879
dev_label=P_recall_tok: 0.572851805728518
dev_label=P_f-score_tok: 0.6800961005359453
dev_precision_macro_tok: 0.8270335360982548
dev_recall_macro_tok: 0.666286905953717
dev_f-score_macro_tok: 0.7242691695209982
dev_precision_micro_tok: 0.8640124095139607
dev_recall_micro_tok: 0.8640124095139607
dev_f-score_micro_tok: 0.8640124095139607
dev_time: 5.23440957069397
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6335    0.7430    0.6839       428
           P     0.6229    0.8333    0.7129       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.6188    0.5298    0.4741      1101
weighted avg     0.6222    0.6276    0.5587      1101

F1-macro sent:  0.47414047820536726
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8730    0.9683    0.9182     16205
           N     0.7713    0.4577    0.5745      1857
           P     0.8367    0.5729    0.6801      3212

   micro avg     0.8640    0.8640    0.8640     21274
   macro avg     0.8270    0.6663    0.7243     21274
weighted avg     0.8587    0.8640    0.8522     21274

F1-macro tok:  0.7242691695209982
F1-micro tok:  0.8640124095139607
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 357080.2307128906
train_cost_avg: 41.793098163961915
train_count_sent: 8544.0
train_total_correct_sent: 5200.0
train_accuracy_sent: 0.6086142322097379
train_count_tok: 163566.0
train_total_correct_tok: 139264.0
train_accuracy_tok: 0.8514238900504995
train_label=O_precision_sent: 0.32967032967032966
train_label=O_recall_sent: 0.01847290640394089
train_label=O_f-score_sent: 0.03498542274052478
train_label=N_precision_sent: 0.5711066035609647
train_label=N_recall_sent: 0.7655589123867069
train_label=N_f-score_sent: 0.6541887182135019
train_label=P_precision_sent: 0.6563745019920318
train_label=P_recall_sent: 0.7301939058171745
train_label=P_f-score_sent: 0.6913191712562285
train_precision_macro_sent: 0.5190504784077753
train_recall_macro_sent: 0.5047419082026074
train_f-score_macro_sent: 0.4601644374034184
train_precision_micro_sent: 0.6086142322097379
train_recall_micro_sent: 0.6086142322097379
train_f-score_micro_sent: 0.6086142322097379
train_label=O_precision_tok: 0.8674694417394591
train_label=O_recall_tok: 0.9599668669127522
train_label=O_f-score_tok: 0.9113772317934896
train_label=N_precision_tok: 0.7113766233766233
train_label=N_recall_tok: 0.4821151950429517
train_label=N_f-score_tok: 0.5747261510051622
train_label=P_precision_tok: 0.7987756351392715
train_label=P_recall_tok: 0.5215653355718112
train_label=P_f-score_tok: 0.6310698394273554
train_precision_macro_tok: 0.7925405667517845
train_recall_macro_tok: 0.6545491325091718
train_f-score_macro_tok: 0.705724407408669
train_precision_micro_tok: 0.8514238900504995
train_recall_micro_tok: 0.8514238900504995
train_f-score_micro_tok: 0.8514238900504995
train_time: 96.41433238983154
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3297    0.0185    0.0350      1624
           N     0.5711    0.7656    0.6542      3310
           P     0.6564    0.7302    0.6913      3610

   micro avg     0.6086    0.6086    0.6086      8544
   macro avg     0.5191    0.5047    0.4602      8544
weighted avg     0.5612    0.6086    0.5522      8544

F1-macro sent:  0.4601644374034184
F1-micro sent:  0.6086142322097379
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8675    0.9600    0.9114    124347
           N     0.7114    0.4821    0.5747     14202
           P     0.7988    0.5216    0.6311     25017

   micro avg     0.8514    0.8514    0.8514    163566
   macro avg     0.7925    0.6545    0.7057    163566
weighted avg     0.8434    0.8514    0.8393    163566

F1-macro tok:  0.705724407408669
F1-micro tok:  0.8514238900504995
**************************************************
dev_cost_sum: 46909.82458496094
dev_cost_avg: 42.606561839201575
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18557.0
dev_accuracy_tok: 0.8722854188210962
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6583143507972665
dev_label=N_recall_sent: 0.6752336448598131
dev_label=N_f-score_sent: 0.6666666666666666
dev_label=P_precision_sent: 0.5861027190332326
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.701627486437613
dev_precision_macro_sent: 0.4148056899434997
dev_recall_macro_sent: 0.516369172911229
dev_f-score_macro_sent: 0.45609805103475987
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8809350299904704
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.9232170132769357
dev_label=N_precision_tok: 0.7552123552123552
dev_label=N_recall_tok: 0.5266558966074314
dev_label=N_f-score_tok: 0.6205583756345178
dev_label=P_precision_tok: 0.8710280373831776
dev_label=P_recall_tok: 0.5803237858032378
dev_label=P_f-score_tok: 0.6965620328849028
dev_precision_macro_tok: 0.8357251408620009
dev_recall_macro_tok: 0.6922473671390496
dev_f-score_macro_tok: 0.7467791405987855
dev_precision_micro_tok: 0.8722854188210962
dev_recall_micro_tok: 0.8722854188210962
dev_f-score_micro_tok: 0.8722854188210962
dev_time: 5.159150123596191
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6583    0.6752    0.6667       428
           P     0.5861    0.8739    0.7016       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4148    0.5164    0.4561      1101
weighted avg     0.4923    0.6149    0.5421      1101

F1-macro sent:  0.45609805103475987
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8809    0.9698    0.9232     16205
           N     0.7552    0.5267    0.6206      1857
           P     0.8710    0.5803    0.6966      3212

   micro avg     0.8723    0.8723    0.8723     21274
   macro avg     0.8357    0.6922    0.7468     21274
weighted avg     0.8685    0.8723    0.8626     21274

F1-macro tok:  0.7467791405987855
F1-micro tok:  0.8722854188210962
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 352422.37634277344
train_cost_avg: 41.247937306036214
train_count_sent: 8544.0
train_total_correct_sent: 5285.0
train_accuracy_sent: 0.618562734082397
train_count_tok: 163566.0
train_total_correct_tok: 140302.0
train_accuracy_tok: 0.8577699521905531
train_label=O_precision_sent: 0.3111111111111111
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.016776512881965248
train_label=N_precision_sent: 0.5888429752066116
train_label=N_recall_sent: 0.7749244712990937
train_label=N_f-score_sent: 0.6691886250978346
train_label=P_precision_sent: 0.6531498913830558
train_label=P_recall_sent: 0.749584487534626
train_label=P_f-score_sent: 0.6980523668257449
train_precision_macro_sent: 0.5177013259002595
train_recall_macro_sent: 0.511043216162964
train_f-score_macro_sent: 0.4613391682685149
train_precision_micro_sent: 0.618562734082397
train_recall_micro_sent: 0.618562734082397
train_f-score_micro_sent: 0.618562734082397
train_label=O_precision_tok: 0.8727561718943669
train_label=O_recall_tok: 0.9626448567315657
train_label=O_f-score_tok: 0.9154993671152309
train_label=N_precision_tok: 0.7183943089430894
train_label=N_recall_tok: 0.4977467962258837
train_label=N_f-score_tok: 0.5880542384161052
train_label=P_precision_tok: 0.8164977069756215
train_label=P_recall_tok: 0.5408722068993085
train_label=P_f-score_tok: 0.6507009064896968
train_precision_macro_tok: 0.8025493959376927
train_recall_macro_tok: 0.667087953285586
train_f-score_macro_tok: 0.7180848373403443
train_precision_micro_tok: 0.8577699521905531
train_recall_micro_tok: 0.8577699521905531
train_f-score_micro_tok: 0.8577699521905531
train_time: 96.78694987297058
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3111    0.0086    0.0168      1624
           N     0.5888    0.7749    0.6692      3310
           P     0.6531    0.7496    0.6981      3610

   micro avg     0.6186    0.6186    0.6186      8544
   macro avg     0.5177    0.5110    0.4613      8544
weighted avg     0.5632    0.6186    0.5574      8544

F1-macro sent:  0.4613391682685149
F1-micro sent:  0.618562734082397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8728    0.9626    0.9155    124347
           N     0.7184    0.4977    0.5881     14202
           P     0.8165    0.5409    0.6507     25017

   micro avg     0.8578    0.8578    0.8578    163566
   macro avg     0.8025    0.6671    0.7181    163566
weighted avg     0.8507    0.8578    0.8466    163566

F1-macro tok:  0.7180848373403443
F1-micro tok:  0.8577699521905531
**************************************************
dev_cost_sum: 46553.82849121094
dev_cost_avg: 42.2832229711271
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18565.0
dev_accuracy_tok: 0.8726614646986932
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6079136690647482
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.6869918699186992
dev_label=P_precision_sent: 0.6403669724770642
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.705763397371082
dev_precision_macro_sent: 0.41609354718060415
dev_recall_macro_sent: 0.5252518874014201
dev_f-score_macro_sent: 0.4642517557632604
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8720070133143389
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9237868586022755
dev_label=N_precision_tok: 0.8053333333333333
dev_label=N_recall_tok: 0.4878836833602585
dev_label=N_f-score_tok: 0.607645875251509
dev_label=P_precision_tok: 0.9188619599578504
dev_label=P_recall_tok: 0.5429638854296388
dev_label=P_f-score_tok: 0.6825831702544032
dev_precision_macro_tok: 0.8654007688685076
dev_recall_macro_tok: 0.6709839525298835
dev_f-score_macro_tok: 0.7380053013693959
dev_precision_micro_tok: 0.8726614646986932
dev_recall_micro_tok: 0.8726614646986932
dev_f-score_micro_tok: 0.8726614646986931
dev_time: 5.036447763442993
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6079    0.7897    0.6870       428
           P     0.6404    0.7860    0.7058       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4161    0.5253    0.4643      1101
weighted avg     0.4946    0.6240    0.5517      1101

F1-macro sent:  0.4642517557632604
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8720    0.9821    0.9238     16205
           N     0.8053    0.4879    0.6076      1857
           P     0.9189    0.5430    0.6826      3212

   micro avg     0.8727    0.8727    0.8727     21274
   macro avg     0.8654    0.6710    0.7380     21274
weighted avg     0.8733    0.8727    0.8598     21274

F1-macro tok:  0.7380053013693959
F1-micro tok:  0.8726614646986931
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 348214.5142211914
train_cost_avg: 40.75544408019562
train_count_sent: 8544.0
train_total_correct_sent: 5343.0
train_accuracy_sent: 0.6253511235955056
train_count_tok: 163566.0
train_total_correct_tok: 141139.0
train_accuracy_tok: 0.8628871525867234
train_label=O_precision_sent: 0.39622641509433965
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.025044722719141325
train_label=N_precision_sent: 0.6005740253527864
train_label=N_recall_sent: 0.7586102719033233
train_label=N_f-score_sent: 0.670404485382459
train_label=P_precision_sent: 0.6522041763341068
train_label=P_recall_sent: 0.7786703601108034
train_label=P_f-score_sent: 0.7098484848484851
train_precision_macro_sent: 0.5496682055937443
train_recall_macro_sent: 0.5167372221656285
train_f-score_macro_sent: 0.4684325643166951
train_precision_micro_sent: 0.6253511235955056
train_recall_micro_sent: 0.6253511235955056
train_f-score_micro_sent: 0.6253511235955056
train_label=O_precision_tok: 0.8764424306646691
train_label=O_recall_tok: 0.964462351323313
train_label=O_f-score_tok: 0.9183481250622173
train_label=N_precision_tok: 0.7322779769016328
train_label=N_recall_tok: 0.5178848049570483
train_label=N_f-score_tok: 0.6066980120432236
train_label=P_precision_tok: 0.8303469766884402
train_label=P_recall_tok: 0.5538633729064236
train_label=P_f-score_tok: 0.6644926146173029
train_precision_macro_tok: 0.8130224614182474
train_recall_macro_tok: 0.6787368430622617
train_f-score_macro_tok: 0.7298462505742479
train_precision_micro_tok: 0.8628871525867234
train_recall_micro_tok: 0.8628871525867234
train_f-score_micro_tok: 0.8628871525867234
train_time: 96.35543775558472
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3962    0.0129    0.0250      1624
           N     0.6006    0.7586    0.6704      3310
           P     0.6522    0.7787    0.7098      3610

   micro avg     0.6254    0.6254    0.6254      8544
   macro avg     0.5497    0.5167    0.4684      8544
weighted avg     0.5835    0.6254    0.5644      8544

F1-macro sent:  0.4684325643166951
F1-micro sent:  0.6253511235955056
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8764    0.9645    0.9183    124347
           N     0.7323    0.5179    0.6067     14202
           P     0.8303    0.5539    0.6645     25017

   micro avg     0.8629    0.8629    0.8629    163566
   macro avg     0.8130    0.6787    0.7298    163566
weighted avg     0.8569    0.8629    0.8525    163566

F1-macro tok:  0.7298462505742479
F1-micro tok:  0.8628871525867234
**************************************************
dev_cost_sum: 46105.29699707031
dev_cost_avg: 41.87583741786586
dev_count_sent: 1101.0
dev_total_correct_sent: 667.0
dev_accuracy_sent: 0.6058128973660308
dev_count_tok: 21274.0
dev_total_correct_tok: 18709.0
dev_accuracy_tok: 0.8794302904954404
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6735218508997429
dev_label=N_recall_sent: 0.6121495327102804
dev_label=N_f-score_sent: 0.6413708690330477
dev_label=P_precision_sent: 0.5676056338028169
dev_label=P_recall_sent: 0.9076576576576577
dev_label=P_f-score_sent: 0.6984402079722704
dev_precision_macro_sent: 0.7470424949008533
dev_recall_macro_sent: 0.5095136049406955
dev_f-score_macro_sent: 0.4523756981071118
dev_precision_micro_sent: 0.6058128973660308
dev_recall_micro_sent: 0.6058128973660308
dev_f-score_micro_sent: 0.6058128973660308
dev_label=O_precision_tok: 0.8816857555876793
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.9276125296130561
dev_label=N_precision_tok: 0.8341143392689785
dev_label=N_recall_tok: 0.47926763597199784
dev_label=N_f-score_tok: 0.6087551299589604
dev_label=P_precision_tok: 0.8829356145880234
dev_label=P_recall_tok: 0.6105230386052304
dev_label=P_f-score_tok: 0.7218847782072519
dev_precision_macro_tok: 0.8662452364815604
dev_recall_macro_tok: 0.6894591768286328
dev_f-score_macro_tok: 0.7527508125930895
dev_precision_micro_tok: 0.8794302904954404
dev_recall_micro_tok: 0.8794302904954404
dev_f-score_micro_tok: 0.8794302904954404
dev_time: 5.181339502334595
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6735    0.6121    0.6414       428
           P     0.5676    0.9077    0.6984       444

   micro avg     0.6058    0.6058    0.6058      1101
   macro avg     0.7470    0.5095    0.4524      1101
weighted avg     0.6987    0.6058    0.5346      1101

F1-macro sent:  0.4523756981071118
F1-micro sent:  0.6058128973660308
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8817    0.9786    0.9276     16205
           N     0.8341    0.4793    0.6088      1857
           P     0.8829    0.6105    0.7219      3212

   micro avg     0.8794    0.8794    0.8794     21274
   macro avg     0.8662    0.6895    0.7528     21274
weighted avg     0.8777    0.8794    0.8687     21274

F1-macro tok:  0.7527508125930895
F1-micro tok:  0.8794302904954404
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 344222.28564453125
train_cost_avg: 40.288188862889896
train_count_sent: 8544.0
train_total_correct_sent: 5408.0
train_accuracy_sent: 0.6329588014981273
train_count_tok: 163566.0
train_total_correct_tok: 141916.0
train_accuracy_tok: 0.8676375285817346
train_label=O_precision_sent: 0.4339622641509434
train_label=O_recall_sent: 0.01416256157635468
train_label=O_f-score_sent: 0.027429934406678593
train_label=N_precision_sent: 0.6042065009560229
train_label=N_recall_sent: 0.7637462235649547
train_label=N_f-score_sent: 0.6746730717907659
train_label=P_precision_sent: 0.6633387508706756
train_label=P_recall_sent: 0.7914127423822714
train_label=P_f-score_sent: 0.7217380320828597
train_precision_macro_sent: 0.5671691719925473
train_recall_macro_sent: 0.5231071758411936
train_f-score_macro_sent: 0.4746136794267681
train_precision_micro_sent: 0.6329588014981273
train_recall_micro_sent: 0.6329588014981273
train_f-score_micro_sent: 0.6329588014981273
train_label=O_precision_tok: 0.8803969423129072
train_label=O_recall_tok: 0.9660385855710231
train_label=O_f-score_tok: 0.9212316423175735
train_label=N_precision_tok: 0.7418726883394977
train_label=N_recall_tok: 0.5366849739473314
train_label=N_f-score_tok: 0.6228141853243995
train_label=P_precision_tok: 0.8409994658436702
train_label=P_recall_tok: 0.5664148379102211
train_label=P_f-score_tok: 0.6769216070319591
train_precision_macro_tok: 0.821089698832025
train_recall_macro_tok: 0.6897127991428585
train_f-score_macro_tok: 0.7403224782246439
train_precision_micro_tok: 0.8676375285817346
train_recall_micro_tok: 0.8676375285817346
train_f-score_micro_tok: 0.8676375285817346
train_time: 79.18289160728455
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4340    0.0142    0.0274      1624
           N     0.6042    0.7637    0.6747      3310
           P     0.6633    0.7914    0.7217      3610

   micro avg     0.6330    0.6330    0.6330      8544
   macro avg     0.5672    0.5231    0.4746      8544
weighted avg     0.5968    0.6330    0.5715      8544

F1-macro sent:  0.4746136794267681
F1-micro sent:  0.6329588014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9660    0.9212    124347
           N     0.7419    0.5367    0.6228     14202
           P     0.8410    0.5664    0.6769     25017

   micro avg     0.8676    0.8676    0.8676    163566
   macro avg     0.8211    0.6897    0.7403    163566
weighted avg     0.8623    0.8676    0.8580    163566

F1-macro tok:  0.7403224782246439
F1-micro tok:  0.8676375285817346
**************************************************
dev_cost_sum: 45628.946228027344
dev_cost_avg: 41.44318458494763
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 18782.0
dev_accuracy_tok: 0.8828617091285137
dev_label=O_precision_sent: 0.3333333333333333
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008620689655172414
dev_label=N_precision_sent: 0.5828220858895705
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.7037037037037036
dev_label=P_precision_sent: 0.7085201793721974
dev_label=P_recall_sent: 0.7117117117117117
dev_label=P_f-score_sent: 0.7101123595505617
dev_precision_macro_sent: 0.5415585328650337
dev_recall_macro_sent: 0.5346429970761685
dev_f-score_macro_sent: 0.4741455843031459
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8918444733714415
dev_label=O_recall_tok: 0.9724159210120333
dev_label=O_f-score_tok: 0.9303890889767963
dev_label=N_precision_tok: 0.7308724832214765
dev_label=N_recall_tok: 0.5864297253634895
dev_label=N_f-score_tok: 0.6507319988049
dev_label=P_precision_tok: 0.9148936170212766
dev_label=P_recall_tok: 0.6024283935242839
dev_label=P_f-score_tok: 0.7264877041486766
dev_precision_macro_tok: 0.8458701912047314
dev_recall_macro_tok: 0.7204246799666022
dev_f-score_macro_tok: 0.7692029306434577
dev_precision_micro_tok: 0.8828617091285137
dev_recall_micro_tok: 0.8828617091285137
dev_f-score_micro_tok: 0.8828617091285137
dev_time: 2.4555463790893555
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0044    0.0086       229
           N     0.5828    0.8879    0.7037       428
           P     0.7085    0.7117    0.7101       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.5416    0.5346    0.4741      1101
weighted avg     0.5816    0.6331    0.5617      1101

F1-macro sent:  0.4741455843031459
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9724    0.9304     16205
           N     0.7309    0.5864    0.6507      1857
           P     0.9149    0.6024    0.7265      3212

   micro avg     0.8829    0.8829    0.8829     21274
   macro avg     0.8459    0.7204    0.7692     21274
weighted avg     0.8813    0.8829    0.8752     21274

F1-macro tok:  0.7692029306434577
F1-micro tok:  0.8828617091285137
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 340984.1165161133
train_cost_avg: 39.90918966714809
train_count_sent: 8544.0
train_total_correct_sent: 5399.0
train_accuracy_sent: 0.6319054307116105
train_count_tok: 163566.0
train_total_correct_tok: 142446.0
train_accuracy_tok: 0.8708778107919739
train_label=O_precision_sent: 0.3047619047619048
train_label=O_recall_sent: 0.019704433497536946
train_label=O_f-score_sent: 0.03701561596298439
train_label=N_precision_sent: 0.6036141750762731
train_label=N_recall_sent: 0.7770392749244713
train_label=N_f-score_sent: 0.6794346849821689
train_label=P_precision_sent: 0.6689803733843944
train_label=P_recall_sent: 0.7742382271468145
train_label=P_f-score_sent: 0.7177709296353365
train_precision_macro_sent: 0.5257854844075242
train_recall_macro_sent: 0.5236606451896075
train_f-score_macro_sent: 0.4780737435268299
train_precision_micro_sent: 0.6319054307116105
train_recall_micro_sent: 0.6319054307116105
train_f-score_micro_sent: 0.6319054307116105
train_label=O_precision_tok: 0.8826817281596127
train_label=O_recall_tok: 0.9677434920022195
train_label=O_f-score_tok: 0.9232575179244811
train_label=N_precision_tok: 0.7450790264714439
train_label=N_recall_tok: 0.5410505562596817
train_label=N_f-score_tok: 0.6268815011217622
train_label=P_precision_tok: 0.8524493293151333
train_label=P_recall_tok: 0.5766478794419795
train_label=P_f-score_tok: 0.6879351454458751
train_precision_macro_tok: 0.82673669464873
train_recall_macro_tok: 0.6951473092346269
train_f-score_macro_tok: 0.7460247214973729
train_precision_micro_tok: 0.8708778107919739
train_recall_micro_tok: 0.8708778107919739
train_f-score_micro_tok: 0.8708778107919738
train_time: 51.483901500701904
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3048    0.0197    0.0370      1624
           N     0.6036    0.7770    0.6794      3310
           P     0.6690    0.7742    0.7178      3610

   micro avg     0.6319    0.6319    0.6319      8544
   macro avg     0.5258    0.5237    0.4781      8544
weighted avg     0.5744    0.6319    0.5735      8544

F1-macro sent:  0.4780737435268299
F1-micro sent:  0.6319054307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8827    0.9677    0.9233    124347
           N     0.7451    0.5411    0.6269     14202
           P     0.8524    0.5766    0.6879     25017

   micro avg     0.8709    0.8709    0.8709    163566
   macro avg     0.8267    0.6951    0.7460    163566
weighted avg     0.8661    0.8709    0.8615    163566

F1-macro tok:  0.7460247214973729
F1-micro tok:  0.8708778107919738
**************************************************
dev_cost_sum: 45334.82043457031
dev_cost_avg: 41.176040358374486
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 18764.0
dev_accuracy_tok: 0.8820156059039203
dev_label=O_precision_sent: 0.6470588235294118
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08943089430894309
dev_label=N_precision_sent: 0.6494252873563219
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7136842105263158
dev_label=P_precision_sent: 0.6512455516014235
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.727634194831014
dev_precision_macro_sent: 0.6492432208290524
dev_recall_macro_sent: 0.5548051111961653
dev_f-score_macro_sent: 0.5102497665554243
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.8861283643892339
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9294518135931448
dev_label=N_precision_tok: 0.7454545454545455
dev_label=N_recall_tok: 0.5740441572428648
dev_label=N_f-score_tok: 0.6486157590508063
dev_label=P_precision_tok: 0.9437404967055246
dev_label=P_recall_tok: 0.5797011207970112
dev_label=P_f-score_tok: 0.7182256509161041
dev_precision_macro_tok: 0.8584411355164346
dev_recall_macro_tok: 0.7103248427570953
dev_f-score_macro_tok: 0.7654310745200185
dev_precision_micro_tok: 0.8820156059039203
dev_recall_micro_tok: 0.8820156059039203
dev_f-score_micro_tok: 0.8820156059039203
dev_time: 2.491166353225708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6471    0.0480    0.0894       229
           N     0.6494    0.7921    0.7137       428
           P     0.6512    0.8243    0.7276       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6492    0.5548    0.5102      1101
weighted avg     0.6497    0.6503    0.5895      1101

F1-macro sent:  0.5102497665554243
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8861    0.9772    0.9295     16205
           N     0.7455    0.5740    0.6486      1857
           P     0.9437    0.5797    0.7182      3212

   micro avg     0.8820    0.8820    0.8820     21274
   macro avg     0.8584    0.7103    0.7654     21274
weighted avg     0.8825    0.8820    0.8730     21274

F1-macro tok:  0.7654310745200185
F1-micro tok:  0.8820156059039203
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 337692.90118408203
train_cost_avg: 39.52398188015941
train_count_sent: 8544.0
train_total_correct_sent: 5392.0
train_accuracy_sent: 0.6310861423220974
train_count_tok: 163566.0
train_total_correct_tok: 142974.0
train_accuracy_tok: 0.8741058655221745
train_label=O_precision_sent: 0.37857142857142856
train_label=O_recall_sent: 0.03263546798029557
train_label=O_f-score_sent: 0.060090702947845805
train_label=N_precision_sent: 0.6067739610857554
train_label=N_recall_sent: 0.7631419939577039
train_label=N_f-score_sent: 0.6760337213970293
train_label=P_precision_sent: 0.6632869606224947
train_label=P_recall_sent: 0.779224376731302
train_label=P_f-score_sent: 0.7165966118965736
train_precision_macro_sent: 0.5495441167598929
train_recall_macro_sent: 0.5250006128897672
train_f-score_macro_sent: 0.4842403454138163
train_precision_micro_sent: 0.6310861423220974
train_recall_micro_sent: 0.6310861423220974
train_f-score_micro_sent: 0.6310861423220974
train_label=O_precision_tok: 0.8856348348083247
train_label=O_recall_tok: 0.9681536345870829
train_label=O_f-score_tok: 0.9250576302443523
train_label=N_precision_tok: 0.7519054878048781
train_label=N_recall_tok: 0.5556963807914378
train_label=N_f-score_tok: 0.6390800874564743
train_label=P_precision_tok: 0.8575013129485908
train_label=P_recall_tok: 0.5874005676140225
train_label=P_f-score_tok: 0.6972054846515159
train_precision_macro_tok: 0.8316805451872645
train_recall_macro_tok: 0.7037501943308477
train_f-score_macro_tok: 0.7537810674507807
train_precision_micro_tok: 0.8741058655221745
train_recall_micro_tok: 0.8741058655221745
train_f-score_micro_tok: 0.8741058655221745
train_time: 51.46785616874695
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3786    0.0326    0.0601      1624
           N     0.6068    0.7631    0.6760      3310
           P     0.6633    0.7792    0.7166      3610

   micro avg     0.6311    0.6311    0.6311      8544
   macro avg     0.5495    0.5250    0.4842      8544
weighted avg     0.5873    0.6311    0.5761      8544

F1-macro sent:  0.4842403454138163
F1-micro sent:  0.6310861423220974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8856    0.9682    0.9251    124347
           N     0.7519    0.5557    0.6391     14202
           P     0.8575    0.5874    0.6972     25017

   micro avg     0.8741    0.8741    0.8741    163566
   macro avg     0.8317    0.7038    0.7538    163566
weighted avg     0.8697    0.8741    0.8654    163566

F1-macro tok:  0.7537810674507807
F1-micro tok:  0.8741058655221745
**************************************************
dev_cost_sum: 45063.67492675781
dev_cost_avg: 40.92976832584724
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18849.0
dev_accuracy_tok: 0.8860110933533891
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6586345381526104
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7084233261339092
dev_label=P_precision_sent: 0.6301824212271974
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7258834765998091
dev_precision_macro_sent: 0.4296056531266026
dev_recall_macro_sent: 0.540736998680924
dev_f-score_macro_sent: 0.47810226757790614
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8829316825116074
dev_label=O_recall_tok: 0.9857451403887689
dev_label=O_f-score_tok: 0.9315100446103157
dev_label=N_precision_tok: 0.8655705996131529
dev_label=N_recall_tok: 0.4819601507808293
dev_label=N_f-score_tok: 0.6191629194050502
dev_label=P_precision_tok: 0.9217877094972067
dev_label=P_recall_tok: 0.6164383561643836
dev_label=P_f-score_tok: 0.7388059701492538
dev_precision_macro_tok: 0.890096663873989
dev_recall_macro_tok: 0.6947145491113274
dev_f-score_macro_tok: 0.7631596447215397
dev_precision_micro_tok: 0.8860110933533891
dev_recall_micro_tok: 0.8860110933533891
dev_f-score_micro_tok: 0.8860110933533891
dev_time: 2.491410493850708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6586    0.7664    0.7084       428
           P     0.6302    0.8559    0.7259       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.4296    0.5407    0.4781      1101
weighted avg     0.5102    0.6431    0.5681      1101

F1-macro sent:  0.47810226757790614
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8829    0.9857    0.9315     16205
           N     0.8656    0.4820    0.6192      1857
           P     0.9218    0.6164    0.7388      3212

   micro avg     0.8860    0.8860    0.8860     21274
   macro avg     0.8901    0.6947    0.7632     21274
weighted avg     0.8873    0.8860    0.8752     21274

F1-macro tok:  0.7631596447215397
F1-micro tok:  0.8860110933533891
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 335135.0833129883
train_cost_avg: 39.224611810977095
train_count_sent: 8544.0
train_total_correct_sent: 5519.0
train_accuracy_sent: 0.6459503745318352
train_count_tok: 163566.0
train_total_correct_tok: 143315.0
train_accuracy_tok: 0.8761906508687625
train_label=O_precision_sent: 0.4148148148148148
train_label=O_recall_sent: 0.034482758620689655
train_label=O_f-score_sent: 0.06367254121660035
train_label=N_precision_sent: 0.6197991391678622
train_label=N_recall_sent: 0.7830815709969788
train_label=N_f-score_sent: 0.6919380672717566
train_label=P_precision_sent: 0.6792051100070973
train_label=P_recall_sent: 0.7952908587257618
train_label=P_f-score_sent: 0.7326783207860151
train_precision_macro_sent: 0.5712730213299247
train_recall_macro_sent: 0.5376183961144768
train_f-score_macro_sent: 0.49609630975812397
train_precision_micro_sent: 0.6459503745318352
train_recall_micro_sent: 0.6459503745318352
train_f-score_micro_sent: 0.6459503745318352
train_label=O_precision_tok: 0.8875815934106414
train_label=O_recall_tok: 0.9688613315962589
train_label=O_f-score_tok: 0.926442146869629
train_label=N_precision_tok: 0.7570846365273434
train_label=N_recall_tok: 0.5624559921137868
train_label=N_f-score_tok: 0.6454167171655961
train_label=P_precision_tok: 0.8594410045714947
train_label=P_recall_tok: 0.5936763001159212
train_label=P_f-score_tok: 0.7022554257884535
train_precision_macro_tok: 0.8347024115031597
train_recall_macro_tok: 0.7083312079419889
train_f-score_macro_tok: 0.7580380966078929
train_precision_micro_tok: 0.8761906508687625
train_recall_micro_tok: 0.8761906508687625
train_f-score_micro_tok: 0.8761906508687625
train_time: 51.26009964942932
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4148    0.0345    0.0637      1624
           N     0.6198    0.7831    0.6919      3310
           P     0.6792    0.7953    0.7327      3610

   micro avg     0.6460    0.6460    0.6460      8544
   macro avg     0.5713    0.5376    0.4961      8544
weighted avg     0.6059    0.6460    0.5897      8544

F1-macro sent:  0.49609630975812397
F1-micro sent:  0.6459503745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8876    0.9689    0.9264    124347
           N     0.7571    0.5625    0.6454     14202
           P     0.8594    0.5937    0.7023     25017

   micro avg     0.8762    0.8762    0.8762    163566
   macro avg     0.8347    0.7083    0.7580    163566
weighted avg     0.8719    0.8762    0.8678    163566

F1-macro tok:  0.7580380966078929
F1-micro tok:  0.8761906508687625
**************************************************
dev_cost_sum: 44592.08923339844
dev_cost_avg: 40.501443445411844
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18920.0
dev_accuracy_tok: 0.889348500517063
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.059322033898305086
dev_label=N_precision_sent: 0.6113989637305699
dev_label=N_recall_sent: 0.8271028037383178
dev_label=N_f-score_sent: 0.7030784508440914
dev_label=P_precision_sent: 0.6660194174757281
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7153284671532847
dev_precision_macro_sent: 0.7591394604020993
dev_recall_macro_sent: 0.5433976706167867
dev_f-score_macro_sent: 0.4925763172985604
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8928671958565557
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.9338200659444182
dev_label=N_precision_tok: 0.7943854324734446
dev_label=N_recall_tok: 0.5638126009693053
dev_label=N_f-score_tok: 0.6595275590551181
dev_label=P_precision_tok: 0.9179206566347469
dev_label=P_recall_tok: 0.6267123287671232
dev_label=P_f-score_tok: 0.7448658649398704
dev_precision_macro_tok: 0.8683910949882492
dev_recall_macro_tok: 0.7230784014476771
dev_f-score_macro_tok: 0.7794044966464688
dev_precision_micro_tok: 0.889348500517063
dev_recall_micro_tok: 0.889348500517063
dev_f-score_micro_tok: 0.889348500517063
dev_time: 2.4547712802886963
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0306    0.0593       229
           N     0.6114    0.8271    0.7031       428
           P     0.6660    0.7725    0.7153       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7591    0.5434    0.4926      1101
weighted avg     0.7143    0.6394    0.5741      1101

F1-macro sent:  0.4925763172985604
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8929    0.9787    0.9338     16205
           N     0.7944    0.5638    0.6595      1857
           P     0.9179    0.6267    0.7449      3212

   micro avg     0.8893    0.8893    0.8893     21274
   macro avg     0.8684    0.7231    0.7794     21274
weighted avg     0.8881    0.8893    0.8813     21274

F1-macro tok:  0.7794044966464688
F1-micro tok:  0.889348500517063
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 332519.76654052734
train_cost_avg: 38.91851200146621
train_count_sent: 8544.0
train_total_correct_sent: 5514.0
train_accuracy_sent: 0.6453651685393258
train_count_tok: 163566.0
train_total_correct_tok: 143683.0
train_accuracy_tok: 0.878440507195872
train_label=O_precision_sent: 0.371900826446281
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.05157593123209169
train_label=N_precision_sent: 0.6129106894956039
train_label=N_recall_sent: 0.8003021148036253
train_label=N_f-score_sent: 0.694182389937107
train_label=P_precision_sent: 0.6876371616678859
train_label=P_recall_sent: 0.7811634349030471
train_label=P_f-score_sent: 0.7314226429775645
train_precision_macro_sent: 0.5574828925365902
train_recall_macro_sent: 0.536391636437528
train_f-score_macro_sent: 0.49239365471558777
train_precision_micro_sent: 0.6453651685393258
train_recall_micro_sent: 0.6453651685393258
train_f-score_micro_sent: 0.6453651685393258
train_label=O_precision_tok: 0.8899872920176138
train_label=O_recall_tok: 0.9687246174013044
train_label=O_f-score_tok: 0.9276882496775063
train_label=N_precision_tok: 0.7567819520835275
train_label=N_recall_tok: 0.5716096324461344
train_label=N_f-score_tok: 0.651289662641903
train_label=P_precision_tok: 0.8637013321136584
train_label=P_recall_tok: 0.6038693688291962
train_label=P_f-score_tok: 0.7107838524513033
train_precision_macro_tok: 0.8368235254049333
train_recall_macro_tok: 0.7147345395588783
train_f-score_macro_tok: 0.7632539215902376
train_precision_micro_tok: 0.878440507195872
train_recall_micro_tok: 0.878440507195872
train_f-score_micro_tok: 0.878440507195872
train_time: 51.450058937072754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3719    0.0277    0.0516      1624
           N     0.6129    0.8003    0.6942      3310
           P     0.6876    0.7812    0.7314      3610

   micro avg     0.6454    0.6454    0.6454      8544
   macro avg     0.5575    0.5364    0.4924      8544
weighted avg     0.5987    0.6454    0.5878      8544

F1-macro sent:  0.49239365471558777
F1-micro sent:  0.6453651685393258
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8900    0.9687    0.9277    124347
           N     0.7568    0.5716    0.6513     14202
           P     0.8637    0.6039    0.7108     25017

   micro avg     0.8784    0.8784    0.8784    163566
   macro avg     0.8368    0.7147    0.7633    163566
weighted avg     0.8744    0.8784    0.8705    163566

F1-macro tok:  0.7632539215902376
F1-micro tok:  0.878440507195872
**************************************************
dev_cost_sum: 44356.546142578125
dev_cost_avg: 40.28750784975306
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18941.0
dev_accuracy_tok: 0.8903356209457554
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5890625
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7059925093632958
dev_label=P_precision_sent: 0.7167755991285403
dev_label=P_recall_sent: 0.740990990990991
dev_label=P_f-score_sent: 0.7286821705426356
dev_precision_macro_sent: 0.7686126997095135
dev_recall_macro_sent: 0.5435219123134889
dev_f-score_macro_sent: 0.4839968990739829
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8927125506072875
dev_label=O_recall_tok: 0.9796976241900648
dev_label=O_f-score_tok: 0.9341845891317779
dev_label=N_precision_tok: 0.7920059215396003
dev_label=N_recall_tok: 0.57619816908993
dev_label=N_f-score_tok: 0.6670822942643392
dev_label=P_precision_tok: 0.9326788218793829
dev_label=P_recall_tok: 0.6211083437110835
dev_label=P_f-score_tok: 0.7456550177536908
dev_precision_macro_tok: 0.8724657646754235
dev_recall_macro_tok: 0.7256680456636927
dev_f-score_macro_tok: 0.7823073003832692
dev_precision_micro_tok: 0.8903356209457554
dev_recall_micro_tok: 0.8903356209457554
dev_f-score_micro_tok: 0.8903356209457554
dev_time: 2.4833502769470215
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5891    0.8808    0.7060       428
           P     0.7168    0.7410    0.7287       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.7686    0.5435    0.4840      1101
weighted avg     0.7260    0.6431    0.5719      1101

F1-macro sent:  0.4839968990739829
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8927    0.9797    0.9342     16205
           N     0.7920    0.5762    0.6671      1857
           P     0.9327    0.6211    0.7457      3212

   micro avg     0.8903    0.8903    0.8903     21274
   macro avg     0.8725    0.7257    0.7823     21274
weighted avg     0.8900    0.8903    0.8824     21274

F1-macro tok:  0.7823073003832692
F1-micro tok:  0.8903356209457554
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 330171.04412841797
train_cost_avg: 38.64361471540472
train_count_sent: 8544.0
train_total_correct_sent: 5494.0
train_accuracy_sent: 0.6430243445692884
train_count_tok: 163566.0
train_total_correct_tok: 143951.0
train_accuracy_tok: 0.8800789895210496
train_label=O_precision_sent: 0.30718954248366015
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.05289814293753517
train_label=N_precision_sent: 0.6102941176470589
train_label=N_recall_sent: 0.802416918429003
train_label=N_f-score_sent: 0.6932915687809972
train_label=P_precision_sent: 0.6910126268878435
train_label=P_recall_sent: 0.7731301939058172
train_label=P_f-score_sent: 0.7297685972022486
train_precision_macro_sent: 0.5361654290061875
train_recall_macro_sent: 0.5348293330114425
train_f-score_macro_sent: 0.49198610297359363
train_precision_micro_sent: 0.6430243445692884
train_recall_micro_sent: 0.6430243445692884
train_f-score_micro_sent: 0.6430243445692884
train_label=O_precision_tok: 0.8912460177252803
train_label=O_recall_tok: 0.9696574907315818
train_label=O_f-score_tok: 0.9287997719867198
train_label=N_precision_tok: 0.763900530874546
train_label=N_recall_tok: 0.5775242923531897
train_label=N_f-score_tok: 0.6577649464693853
train_label=P_precision_tok: 0.8650666970698894
train_label=P_recall_tok: 0.6065875204860695
train_label=P_f-score_tok: 0.7131276580746727
train_precision_macro_tok: 0.8400710818899052
train_recall_macro_tok: 0.7179231011902804
train_f-score_macro_tok: 0.7665641255102593
train_precision_micro_tok: 0.8800789895210496
train_recall_micro_tok: 0.8800789895210496
train_f-score_micro_tok: 0.8800789895210496
train_time: 51.396247148513794
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3072    0.0289    0.0529      1624
           N     0.6103    0.8024    0.6933      3310
           P     0.6910    0.7731    0.7298      3610

   micro avg     0.6430    0.6430    0.6430      8544
   macro avg     0.5362    0.5348    0.4920      8544
weighted avg     0.5868    0.6430    0.5870      8544

F1-macro sent:  0.49198610297359363
F1-micro sent:  0.6430243445692884
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8912    0.9697    0.9288    124347
           N     0.7639    0.5775    0.6578     14202
           P     0.8651    0.6066    0.7131     25017

   micro avg     0.8801    0.8801    0.8801    163566
   macro avg     0.8401    0.7179    0.7666    163566
weighted avg     0.8762    0.8801    0.8723    163566

F1-macro tok:  0.7665641255102593
F1-micro tok:  0.8800789895210496
**************************************************
dev_cost_sum: 44093.31750488281
dev_cost_avg: 40.0484264349526
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18965.0
dev_accuracy_tok: 0.8914637585785465
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6025641025641025
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.714828897338403
dev_label=P_precision_sent: 0.701271186440678
dev_label=P_recall_sent: 0.7454954954954955
dev_label=P_f-score_sent: 0.7227074235807861
dev_precision_macro_sent: 0.6346117630015935
dev_recall_macro_sent: 0.5457002016913048
dev_f-score_macro_sent: 0.48772578218673823
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8949091319562027
dev_label=O_recall_tok: 0.9784634372107375
dev_label=O_f-score_tok: 0.9348229814580079
dev_label=N_precision_tok: 0.8100470957613815
dev_label=N_recall_tok: 0.555735056542811
dev_label=N_f-score_tok: 0.6592143085276269
dev_label=P_precision_tok: 0.9101665205959685
dev_label=P_recall_tok: 0.6466376089663761
dev_label=P_f-score_tok: 0.7560975609756099
dev_precision_macro_tok: 0.8717075827711841
dev_recall_macro_tok: 0.7269453675733081
dev_f-score_macro_tok: 0.7833782836537483
dev_precision_micro_tok: 0.8914637585785465
dev_recall_micro_tok: 0.8914637585785465
dev_f-score_micro_tok: 0.8914637585785465
dev_time: 2.4580349922180176
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6026    0.8785    0.7148       428
           P     0.7013    0.7455    0.7227       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.6346    0.5457    0.4877      1101
weighted avg     0.6418    0.6449    0.5747      1101

F1-macro sent:  0.48772578218673823
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9785    0.9348     16205
           N     0.8100    0.5557    0.6592      1857
           P     0.9102    0.6466    0.7561      3212

   micro avg     0.8915    0.8915    0.8915     21274
   macro avg     0.8717    0.7269    0.7834     21274
weighted avg     0.8898    0.8915    0.8838     21274

F1-macro tok:  0.7833782836537483
F1-micro tok:  0.8914637585785465
**************************************************
Best epoch: 8
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 327589.5415649414
train_cost_avg: 38.34147256143977
train_count_sent: 8544.0
train_total_correct_sent: 5576.0
train_accuracy_sent: 0.6526217228464419
train_count_tok: 163566.0
train_total_correct_tok: 144356.0
train_accuracy_tok: 0.8825550542288739
train_label=O_precision_sent: 0.40789473684210525
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.06981981981981983
train_label=N_precision_sent: 0.6135449262405007
train_label=N_recall_sent: 0.8293051359516617
train_label=N_f-score_sent: 0.7052929085303187
train_label=P_precision_sent: 0.7067381316998469
train_label=P_recall_sent: 0.7670360110803324
train_label=P_f-score_sent: 0.7356535600425079
train_precision_macro_sent: 0.5760592649274843
train_recall_macro_sent: 0.5448394956444906
train_f-score_macro_sent: 0.5035887627975488
train_precision_micro_sent: 0.6526217228464419
train_recall_micro_sent: 0.6526217228464419
train_f-score_micro_sent: 0.6526217228464419
train_label=O_precision_tok: 0.8934536109197828
train_label=O_recall_tok: 0.9701480534311242
train_label=O_f-score_tok: 0.9302226951667129
train_label=N_precision_tok: 0.7670260805455719
train_label=N_recall_tok: 0.586044219124067
train_label=N_f-score_tok: 0.6644314054205086
train_label=P_precision_tok: 0.8702384989261897
train_label=P_recall_tok: 0.6155014590078747
train_label=P_f-score_tok: 0.7210320526328112
train_precision_macro_tok: 0.8435727301305148
train_recall_macro_tok: 0.7238979105210218
train_f-score_macro_tok: 0.7718953844066775
train_precision_micro_tok: 0.8825550542288739
train_recall_micro_tok: 0.8825550542288739
train_f-score_micro_tok: 0.8825550542288739
train_time: 51.32642412185669
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4079    0.0382    0.0698      1624
           N     0.6135    0.8293    0.7053      3310
           P     0.7067    0.7670    0.7357      3610

   micro avg     0.6526    0.6526    0.6526      8544
   macro avg     0.5761    0.5448    0.5036      8544
weighted avg     0.6138    0.6526    0.5973      8544

F1-macro sent:  0.5035887627975488
F1-micro sent:  0.6526217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9701    0.9302    124347
           N     0.7670    0.5860    0.6644     14202
           P     0.8702    0.6155    0.7210     25017

   micro avg     0.8826    0.8826    0.8826    163566
   macro avg     0.8436    0.7239    0.7719    163566
weighted avg     0.8789    0.8826    0.8751    163566

F1-macro tok:  0.7718953844066775
F1-micro tok:  0.8825550542288739
**************************************************
dev_cost_sum: 43963.12829589844
dev_cost_avg: 39.93018010526652
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 18989.0
dev_accuracy_tok: 0.8925918962113378
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6112
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.7255460588793922
dev_label=P_precision_sent: 0.7103594080338267
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7328244274809161
dev_precision_macro_sent: 0.7738531360112756
dev_recall_macro_sent: 0.5541268526413203
dev_f-score_macro_sent: 0.4947441851086085
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.8946982928615697
dev_label=O_recall_tok: 0.9799444615859303
dev_label=O_f-score_tok: 0.9353831654591506
dev_label=N_precision_tok: 0.8073739653875094
dev_label=N_recall_tok: 0.5778136779752289
dev_label=N_f-score_tok: 0.6735718769617074
dev_label=P_precision_tok: 0.9271402550091075
dev_label=P_recall_tok: 0.6338729763387297
dev_label=P_f-score_tok: 0.7529585798816567
dev_precision_macro_tok: 0.8764041710860622
dev_recall_macro_tok: 0.7305437052999629
dev_f-score_macro_tok: 0.7873045407675049
dev_precision_micro_tok: 0.8925918962113378
dev_recall_micro_tok: 0.8925918962113378
dev_f-score_micro_tok: 0.8925918962113378
dev_time: 2.4694173336029053
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6112    0.8925    0.7255       428
           P     0.7104    0.7568    0.7328       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.7739    0.5541    0.4947      1101
weighted avg     0.7321    0.6549    0.5830      1101

F1-macro sent:  0.4947441851086085
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8947    0.9799    0.9354     16205
           N     0.8074    0.5778    0.6736      1857
           P     0.9271    0.6339    0.7530      3212

   micro avg     0.8926    0.8926    0.8926     21274
   macro avg     0.8764    0.7305    0.7873     21274
weighted avg     0.8920    0.8926    0.8850     21274

F1-macro tok:  0.7873045407675049
F1-micro tok:  0.8925918962113378
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 325480.30560302734
train_cost_avg: 38.0946050565341
train_count_sent: 8544.0
train_total_correct_sent: 5557.0
train_accuracy_sent: 0.6503979400749064
train_count_tok: 163566.0
train_total_correct_tok: 144744.0
train_accuracy_tok: 0.8849271853563699
train_label=O_precision_sent: 0.3665594855305466
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.11782945736434108
train_label=N_precision_sent: 0.620217288615966
train_label=N_recall_sent: 0.7933534743202417
train_label=N_f-score_sent: 0.6961823966065749
train_label=P_precision_sent: 0.7044261065266316
train_label=P_recall_sent: 0.7803324099722991
train_label=P_f-score_sent: 0.7404389538704166
train_precision_macro_sent: 0.5637342935577148
train_recall_macro_sent: 0.5479609762091721
train_f-score_macro_sent: 0.5181502692804442
train_precision_micro_sent: 0.6503979400749064
train_recall_micro_sent: 0.6503979400749064
train_f-score_micro_sent: 0.6503979400749064
train_label=O_precision_tok: 0.8952840753183379
train_label=O_recall_tok: 0.9708396664173643
train_label=O_f-score_tok: 0.9315323240273469
train_label=N_precision_tok: 0.7767238234221088
train_label=N_recall_tok: 0.5996338543867061
train_label=N_f-score_tok: 0.6767861400301995
train_label=P_precision_tok: 0.8730927312651314
train_label=P_recall_tok: 0.6198584962225686
train_label=P_f-score_tok: 0.724998831174903
train_precision_macro_tok: 0.8483668766685261
train_recall_macro_tok: 0.7301106723422129
train_f-score_macro_tok: 0.7777724317441498
train_precision_micro_tok: 0.8849271853563699
train_recall_micro_tok: 0.8849271853563699
train_f-score_micro_tok: 0.8849271853563699
train_time: 51.027082681655884
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3666    0.0702    0.1178      1624
           N     0.6202    0.7934    0.6962      3310
           P     0.7044    0.7803    0.7404      3610

   micro avg     0.6504    0.6504    0.6504      8544
   macro avg     0.5637    0.5480    0.5182      8544
weighted avg     0.6076    0.6504    0.6050      8544

F1-macro sent:  0.5181502692804442
F1-micro sent:  0.6503979400749064
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8953    0.9708    0.9315    124347
           N     0.7767    0.5996    0.6768     14202
           P     0.8731    0.6199    0.7250     25017

   micro avg     0.8849    0.8849    0.8849    163566
   macro avg     0.8484    0.7301    0.7778    163566
weighted avg     0.8816    0.8849    0.8778    163566

F1-macro tok:  0.7777724317441498
F1-micro tok:  0.8849271853563699
**************************************************
dev_cost_sum: 43747.95129394531
dev_cost_avg: 39.73474231965969
dev_count_sent: 1101.0
dev_total_correct_sent: 685.0
dev_accuracy_sent: 0.6221616712079927
dev_count_tok: 21274.0
dev_total_correct_tok: 18999.0
dev_accuracy_tok: 0.8930619535583341
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09795918367346937
dev_label=N_precision_sent: 0.5341935483870968
dev_label=N_recall_sent: 0.9672897196261683
dev_label=N_f-score_sent: 0.688279301745636
dev_label=P_precision_sent: 0.8354838709677419
dev_label=P_recall_sent: 0.5833333333333334
dev_label=P_f-score_sent: 0.6870026525198939
dev_precision_macro_sent: 0.7065591397849462
dev_recall_macro_sent: 0.5343415998947975
dev_f-score_macro_sent: 0.4910803793129997
dev_precision_micro_sent: 0.6221616712079927
dev_recall_micro_sent: 0.6221616712079927
dev_f-score_micro_sent: 0.6221616712079927
dev_label=O_precision_tok: 0.8968186698310449
dev_label=O_recall_tok: 0.979389077445233
dev_label=O_f-score_tok: 0.9362869447230253
dev_label=N_precision_tok: 0.7783216783216783
dev_label=N_recall_tok: 0.5993537964458805
dev_label=N_f-score_tok: 0.6772132643748099
dev_label=P_precision_tok: 0.9385188635305077
dev_label=P_recall_tok: 0.6273349937733499
dev_label=P_f-score_tok: 0.7520059712632954
dev_precision_macro_tok: 0.8712197372277437
dev_recall_macro_tok: 0.7353592892214879
dev_f-score_macro_tok: 0.7885020601203768
dev_precision_micro_tok: 0.8930619535583341
dev_recall_micro_tok: 0.8930619535583341
dev_f-score_micro_tok: 0.8930619535583341
dev_time: 2.4419877529144287
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0524    0.0980       229
           N     0.5342    0.9673    0.6883       428
           P     0.8355    0.5833    0.6870       444

   micro avg     0.6222    0.6222    0.6222      1101
   macro avg     0.7066    0.5343    0.4911      1101
weighted avg     0.7006    0.6222    0.5650      1101

F1-macro sent:  0.4910803793129997
F1-micro sent:  0.6221616712079927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8968    0.9794    0.9363     16205
           N     0.7783    0.5994    0.6772      1857
           P     0.9385    0.6273    0.7520      3212

   micro avg     0.8931    0.8931    0.8931     21274
   macro avg     0.8712    0.7354    0.7885     21274
weighted avg     0.8928    0.8931    0.8858     21274

F1-macro tok:  0.7885020601203768
F1-micro tok:  0.8930619535583341
**************************************************
Best epoch: 13
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 323559.51708984375
train_cost_avg: 37.86979366688246
train_count_sent: 8544.0
train_total_correct_sent: 5675.0
train_accuracy_sent: 0.6642088014981273
train_count_tok: 163566.0
train_total_correct_tok: 144981.0
train_accuracy_tok: 0.8863761417409486
train_label=O_precision_sent: 0.45751633986928103
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07878446820483963
train_label=N_precision_sent: 0.6318361647661159
train_label=N_recall_sent: 0.8202416918429003
train_label=N_f-score_sent: 0.7138162219008808
train_label=P_precision_sent: 0.7059110893991206
train_label=P_recall_sent: 0.8005540166204986
train_label=P_f-score_sent: 0.7502596053997923
train_precision_macro_sent: 0.5984211980115058
train_recall_macro_sent: 0.5546330522464203
train_f-score_macro_sent: 0.5142867651685042
train_precision_micro_sent: 0.6642088014981273
train_recall_micro_sent: 0.6642088014981273
train_f-score_micro_sent: 0.6642088014981273
train_label=O_precision_tok: 0.896572718362983
train_label=O_recall_tok: 0.9711050527958053
train_label=O_f-score_tok: 0.9323517262412606
train_label=N_precision_tok: 0.7795138888888888
train_label=N_recall_tok: 0.6006900436558231
train_label=N_f-score_tok: 0.6785174580450171
train_label=P_precision_tok: 0.8750139368937451
train_label=P_recall_tok: 0.6274133589159372
train_label=P_f-score_tok: 0.7308113141659877
train_precision_macro_tok: 0.850366848048539
train_recall_macro_tok: 0.7330694851225218
train_f-score_macro_tok: 0.7805601661507552
train_precision_micro_tok: 0.8863761417409486
train_recall_micro_tok: 0.8863761417409486
train_f-score_micro_tok: 0.8863761417409486
train_time: 51.2812237739563
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4575    0.0431    0.0788      1624
           N     0.6318    0.8202    0.7138      3310
           P     0.7059    0.8006    0.7503      3610

   micro avg     0.6642    0.6642    0.6642      8544
   macro avg     0.5984    0.5546    0.5143      8544
weighted avg     0.6300    0.6642    0.6085      8544

F1-macro sent:  0.5142867651685042
F1-micro sent:  0.6642088014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9711    0.9324    124347
           N     0.7795    0.6007    0.6785     14202
           P     0.8750    0.6274    0.7308     25017

   micro avg     0.8864    0.8864    0.8864    163566
   macro avg     0.8504    0.7331    0.7806    163566
weighted avg     0.8831    0.8864    0.8795    163566

F1-macro tok:  0.7805601661507552
F1-micro tok:  0.8863761417409486
**************************************************
dev_cost_sum: 43649.40002441406
dev_cost_avg: 39.645231629803874
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 18995.0
dev_accuracy_tok: 0.8928739306195356
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.631858407079646
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7190332326283989
dev_label=P_precision_sent: 0.6805293005671077
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7399794450154162
dev_precision_macro_sent: 0.6755578073108226
dev_recall_macro_sent: 0.5555856738262975
dev_f-score_macro_sent: 0.5004618529999157
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.8992375967228038
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.9357331044078033
dev_label=N_precision_tok: 0.7751561415683553
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.6773802304426926
dev_label=P_precision_tok: 0.9184758529020824
dev_label=P_recall_tok: 0.6453922789539228
dev_label=P_f-score_tok: 0.7580910586944597
dev_precision_macro_tok: 0.8642898637310804
dev_recall_macro_tok: 0.7407387825534403
dev_f-score_macro_tok: 0.7904014645149853
dev_precision_micro_tok: 0.8928739306195356
dev_recall_micro_tok: 0.8928739306195356
dev_f-score_micro_tok: 0.8928739306195356
dev_time: 2.441168785095215
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6319    0.8341    0.7190       428
           P     0.6805    0.8108    0.7400       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6756    0.5556    0.5005      1101
weighted avg     0.6686    0.6558    0.5867      1101

F1-macro sent:  0.5004618529999157
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9753    0.9357     16205
           N     0.7752    0.6015    0.6774      1857
           P     0.9185    0.6454    0.7581      3212

   micro avg     0.8929    0.8929    0.8929     21274
   macro avg     0.8643    0.7407    0.7904     21274
weighted avg     0.8913    0.8929    0.8864     21274

F1-macro tok:  0.7904014645149853
F1-micro tok:  0.8928739306195356
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 321707.84478759766
train_cost_avg: 37.65307172139486
train_count_sent: 8544.0
train_total_correct_sent: 5688.0
train_accuracy_sent: 0.6657303370786517
train_count_tok: 163566.0
train_total_correct_tok: 145297.0
train_accuracy_tok: 0.8883080835870536
train_label=O_precision_sent: 0.5087719298245614
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.0969359331476323
train_label=N_precision_sent: 0.6366210476639924
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.7148913619501855
train_label=P_precision_sent: 0.702055622732769
train_label=P_recall_sent: 0.8041551246537396
train_label=P_f-score_sent: 0.7496449322143318
train_precision_macro_sent: 0.6158162000737742
train_recall_macro_sent: 0.5576107644688123
train_f-score_macro_sent: 0.5204907424373832
train_precision_micro_sent: 0.6657303370786517
train_recall_micro_sent: 0.6657303370786517
train_f-score_micro_sent: 0.6657303370786517
train_label=O_precision_tok: 0.8992396428332055
train_label=O_recall_tok: 0.9710648427384657
train_label=O_f-score_tok: 0.9337730931924864
train_label=N_precision_tok: 0.7773105484477051
train_label=N_recall_tok: 0.6117448246725813
train_label=N_f-score_tok: 0.6846605461208085
train_label=P_precision_tok: 0.8757592490336831
train_label=P_recall_tok: 0.6339689011472199
train_label=P_f-score_tok: 0.7355021216407356
train_precision_macro_tok: 0.8507698134381978
train_recall_macro_tok: 0.7389261895194222
train_f-score_macro_tok: 0.7846452536513434
train_precision_micro_tok: 0.8883080835870536
train_recall_micro_tok: 0.8883080835870536
train_f-score_micro_tok: 0.8883080835870536
train_time: 51.37448573112488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5088    0.0536    0.0969      1624
           N     0.6366    0.8151    0.7149      3310
           P     0.7021    0.8042    0.7496      3610

   micro avg     0.6657    0.6657    0.6657      8544
   macro avg     0.6158    0.5576    0.5205      8544
weighted avg     0.6400    0.6657    0.6121      8544

F1-macro sent:  0.5204907424373832
F1-micro sent:  0.6657303370786517
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9711    0.9338    124347
           N     0.7773    0.6117    0.6847     14202
           P     0.8758    0.6340    0.7355     25017

   micro avg     0.8883    0.8883    0.8883    163566
   macro avg     0.8508    0.7389    0.7846    163566
weighted avg     0.8851    0.8883    0.8818    163566

F1-macro tok:  0.7846452536513434
F1-micro tok:  0.8883080835870536
**************************************************
dev_cost_sum: 43412.359130859375
dev_cost_avg: 39.429935632024865
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 19035.0
dev_accuracy_tok: 0.894754160007521
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.569164265129683
dev_label=N_recall_sent: 0.9228971962616822
dev_label=N_f-score_sent: 0.7040998217468806
dev_label=P_precision_sent: 0.7437185929648241
dev_label=P_recall_sent: 0.6666666666666666
dev_label=P_f-score_sent: 0.7030878859857482
dev_precision_macro_sent: 0.6968868786240949
dev_recall_macro_sent: 0.5400438495059562
dev_f-score_macro_sent: 0.48867041238146447
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8980538583389908
dev_label=O_recall_tok: 0.979574205492132
dev_label=O_f-score_tok: 0.9370443611463652
dev_label=N_precision_tok: 0.7989766081871345
dev_label=N_recall_tok: 0.5885837372105547
dev_label=N_f-score_tok: 0.677829457364341
dev_label=P_precision_tok: 0.9273542600896861
dev_label=P_recall_tok: 0.6438356164383562
dev_label=P_f-score_tok: 0.7600147004777655
dev_precision_macro_tok: 0.874794908871937
dev_recall_macro_tok: 0.7373311863803477
dev_f-score_macro_tok: 0.7916295063294906
dev_precision_micro_tok: 0.894754160007521
dev_recall_micro_tok: 0.894754160007521
dev_f-score_micro_tok: 0.894754160007521
dev_time: 2.490600109100342
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.5692    0.9229    0.7041       428
           P     0.7437    0.6667    0.7031       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.6969    0.5400    0.4887      1101
weighted avg     0.6829    0.6340    0.5695      1101

F1-macro sent:  0.48867041238146447
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8981    0.9796    0.9370     16205
           N     0.7990    0.5886    0.6778      1857
           P     0.9274    0.6438    0.7600      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8748    0.7373    0.7916     21274
weighted avg     0.8938    0.8948    0.8877     21274

F1-macro tok:  0.7916295063294906
F1-micro tok:  0.894754160007521
**************************************************
Best epoch: 15
**************************************************

EPOCH: 17
Learning rate: 0.900000
train_cost_sum: 319935.27447509766
train_cost_avg: 37.445607967591016
train_count_sent: 8544.0
train_total_correct_sent: 5650.0
train_accuracy_sent: 0.6612827715355806
train_count_tok: 163566.0
train_total_correct_tok: 145513.0
train_accuracy_tok: 0.8896286514312265
train_label=O_precision_sent: 0.41040462427745666
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.07902058987200891
train_label=N_precision_sent: 0.626486360456983
train_label=N_recall_sent: 0.8117824773413898
train_label=N_f-score_sent: 0.7071983155678379
train_label=P_precision_sent: 0.7084762371386575
train_label=P_recall_sent: 0.8011080332409972
train_label=P_f-score_sent: 0.7519500780031201
train_precision_macro_sent: 0.5817890739576991
train_recall_macro_sent: 0.5522032408016824
train_f-score_macro_sent: 0.5127229944809889
train_precision_micro_sent: 0.6612827715355806
train_recall_micro_sent: 0.6612827715355806
train_f-score_micro_sent: 0.6612827715355806
train_label=O_precision_tok: 0.900050660070924
train_label=O_recall_tok: 0.971571489460944
train_label=O_f-score_tok: 0.9344445518708304
train_label=N_precision_tok: 0.7840796912860092
train_label=N_recall_tok: 0.6151950429516969
train_label=N_f-score_tok: 0.6894456500295916
train_label=P_precision_tok: 0.8773838966749107
train_label=P_recall_tok: 0.6381260742694967
train_label=P_f-score_tok: 0.7388688327316487
train_precision_macro_tok: 0.8538380826772812
train_recall_macro_tok: 0.741630868894046
train_f-score_macro_tok: 0.7875863448773569
train_precision_micro_tok: 0.8896286514312265
train_recall_micro_tok: 0.8896286514312265
train_f-score_micro_tok: 0.8896286514312265
train_time: 51.472609996795654
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4104    0.0437    0.0790      1624
           N     0.6265    0.8118    0.7072      3310
           P     0.7085    0.8011    0.7520      3610

   micro avg     0.6613    0.6613    0.6613      8544
   macro avg     0.5818    0.5522    0.5127      8544
weighted avg     0.6201    0.6613    0.6067      8544

F1-macro sent:  0.5127229944809889
F1-micro sent:  0.6612827715355806
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9001    0.9716    0.9344    124347
           N     0.7841    0.6152    0.6894     14202
           P     0.8774    0.6381    0.7389     25017

   micro avg     0.8896    0.8896    0.8896    163566
   macro avg     0.8538    0.7416    0.7876    163566
weighted avg     0.8865    0.8896    0.8833    163566

F1-macro tok:  0.7875863448773569
F1-micro tok:  0.8896286514312265
**************************************************
dev_cost_sum: 43370.886291503906
dev_cost_avg: 39.39226729473561
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19017.0
dev_accuracy_tok: 0.8939080567829275
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6237113402061856
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7188118811881187
dev_label=P_precision_sent: 0.6861598440545809
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.735632183908046
dev_precision_macro_sent: 0.6588459503091443
dev_recall_macro_sent: 0.5527969609408617
dev_f-score_macro_sent: 0.49616220609588463
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.8947753219728924
dev_label=O_recall_tok: 0.9817957420549214
dev_label=O_f-score_tok: 0.936267875007356
dev_label=N_precision_tok: 0.8213438735177866
dev_label=N_recall_tok: 0.559504577275175
dev_label=N_f-score_tok: 0.6655989750160154
dev_label=P_precision_tok: 0.9281867145421903
dev_label=P_recall_tok: 0.6438356164383562
dev_label=P_f-score_tok: 0.7602941176470588
dev_precision_macro_tok: 0.8814353033442899
dev_recall_macro_tok: 0.7283786452561508
dev_f-score_macro_tok: 0.7873869892234767
dev_precision_micro_tok: 0.8939080567829275
dev_recall_micro_tok: 0.8939080567829275
dev_f-score_micro_tok: 0.8939080567829275
dev_time: 2.4587197303771973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6237    0.8481    0.7188       428
           P     0.6862    0.7928    0.7356       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.6588    0.5528    0.4962      1101
weighted avg     0.6578    0.6530    0.5832      1101

F1-macro sent:  0.49616220609588463
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9818    0.9363     16205
           N     0.8213    0.5595    0.6656      1857
           P     0.9282    0.6438    0.7603      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8814    0.7284    0.7874     21274
weighted avg     0.8934    0.8939    0.8861     21274

F1-macro tok:  0.7873869892234767
F1-micro tok:  0.8939080567829275
**************************************************
Best epoch: 15
**************************************************

EPOCH: 18
Learning rate: 0.900000
train_cost_sum: 318113.3203125
train_cost_avg: 37.23236426878511
train_count_sent: 8544.0
train_total_correct_sent: 5701.0
train_accuracy_sent: 0.6672518726591761
train_count_tok: 163566.0
train_total_correct_tok: 145700.0
train_accuracy_tok: 0.8907719208148392
train_label=O_precision_sent: 0.3895131086142322
train_label=O_recall_sent: 0.06403940886699508
train_label=O_f-score_sent: 0.10999471179270229
train_label=N_precision_sent: 0.648681640625
train_label=N_recall_sent: 0.8027190332326284
train_label=N_f-score_sent: 0.7175263300027005
train_label=P_precision_sent: 0.7031810571633581
train_label=P_recall_sent: 0.814404432132964
train_label=P_f-score_sent: 0.7547169811320755
train_precision_macro_sent: 0.5804586021341968
train_recall_macro_sent: 0.5603876247441958
train_f-score_macro_sent: 0.5274126743091595
train_precision_micro_sent: 0.6672518726591761
train_recall_micro_sent: 0.6672518726591761
train_f-score_micro_sent: 0.6672518726591761
train_label=O_precision_tok: 0.9016972439386812
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9351299028148836
train_label=N_precision_tok: 0.7831314570716067
train_label=N_recall_tok: 0.6191381495564005
train_label=N_f-score_tok: 0.6915454187966968
train_label=P_precision_tok: 0.8769481401031768
train_label=P_recall_tok: 0.6455210456889315
train_label=P_f-score_tok: 0.7436452385337999
train_precision_macro_tok: 0.8539256137044883
train_recall_macro_tok: 0.745265472029003
train_f-score_macro_tok: 0.7901068533817934
train_precision_micro_tok: 0.8907719208148392
train_recall_micro_tok: 0.8907719208148392
train_f-score_micro_tok: 0.8907719208148392
train_time: 51.53905987739563
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3895    0.0640    0.1100      1624
           N     0.6487    0.8027    0.7175      3310
           P     0.7032    0.8144    0.7547      3610

   micro avg     0.6673    0.6673    0.6673      8544
   macro avg     0.5805    0.5604    0.5274      8544
weighted avg     0.6224    0.6673    0.6178      8544

F1-macro sent:  0.5274126743091595
F1-micro sent:  0.6672518726591761
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9017    0.9711    0.9351    124347
           N     0.7831    0.6191    0.6915     14202
           P     0.8769    0.6455    0.7436     25017

   micro avg     0.8908    0.8908    0.8908    163566
   macro avg     0.8539    0.7453    0.7901    163566
weighted avg     0.8876    0.8908    0.8847    163566

F1-macro tok:  0.7901068533817934
F1-micro tok:  0.8907719208148392
**************************************************
dev_cost_sum: 43119.565673828125
dev_cost_avg: 39.16400152027986
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19069.0
dev_accuracy_tok: 0.8963523549873085
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6412078152753108
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7285570131180626
dev_label=P_precision_sent: 0.6791744840525328
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.7410440122824974
dev_precision_macro_sent: 0.6401274331092811
dev_recall_macro_sent: 0.5572912319739239
dev_f-score_macro_sent: 0.49841401701386195
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9001930282729647
dev_label=O_recall_tok: 0.9784634372107375
dev_label=O_f-score_tok: 0.9376977438717881
dev_label=N_precision_tok: 0.8061002178649237
dev_label=N_recall_tok: 0.5977382875605816
dev_label=N_f-score_tok: 0.6864564007421149
dev_label=P_precision_tok: 0.9211563731931669
dev_label=P_recall_tok: 0.6547322540473225
dev_label=P_f-score_tok: 0.7654231119199273
dev_precision_macro_tok: 0.8758165397770185
dev_recall_macro_tok: 0.7436446596062138
dev_f-score_macro_tok: 0.7965257521779434
dev_precision_micro_tok: 0.8963523549873085
dev_recall_micro_tok: 0.8963523549873085
dev_f-score_micro_tok: 0.8963523549873085
dev_time: 2.472273111343384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6412    0.8435    0.7286       428
           P     0.6792    0.8153    0.7410       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.6401    0.5573    0.4984      1101
weighted avg     0.6479    0.6594    0.5874      1101

F1-macro sent:  0.49841401701386195
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9002    0.9785    0.9377     16205
           N     0.8061    0.5977    0.6865      1857
           P     0.9212    0.6547    0.7654      3212

   micro avg     0.8964    0.8964    0.8964     21274
   macro avg     0.8758    0.7436    0.7965     21274
weighted avg     0.8951    0.8964    0.8898     21274

F1-macro tok:  0.7965257521779434
F1-micro tok:  0.8963523549873085
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 316455.4651489258
train_cost_avg: 37.03832691349787
train_count_sent: 8544.0
train_total_correct_sent: 5716.0
train_accuracy_sent: 0.6690074906367042
train_count_tok: 163566.0
train_total_correct_tok: 145878.0
train_accuracy_tok: 0.8918601665382782
train_label=O_precision_sent: 0.4691358024691358
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.12212104981253345
train_label=N_precision_sent: 0.6476259339599904
train_label=N_recall_sent: 0.8117824773413898
train_label=N_f-score_sent: 0.7204719131250839
train_label=P_precision_sent: 0.7020712909441233
train_label=P_recall_sent: 0.8074792243767313
train_label=P_f-score_sent: 0.7510950785879927
train_precision_macro_sent: 0.6062776757910832
train_recall_macro_sent: 0.5631529153510321
train_f-score_macro_sent: 0.5312293471752033
train_precision_micro_sent: 0.6690074906367042
train_recall_micro_sent: 0.6690074906367042
train_f-score_micro_sent: 0.6690074906367042
train_label=O_precision_tok: 0.902722746370419
train_label=O_recall_tok: 0.9710728847499337
train_label=O_f-score_tok: 0.9356512171214487
train_label=N_precision_tok: 0.7873390936342797
train_label=N_recall_tok: 0.628784678214336
train_label=N_f-score_tok: 0.6991857187597871
train_label=P_precision_tok: 0.877369732423356
train_label=P_recall_tok: 0.6474797137946197
train_label=P_f-score_tok: 0.7450953333793325
train_precision_macro_tok: 0.8558105241426849
train_recall_macro_tok: 0.7491124255862965
train_f-score_macro_tok: 0.7933107564201894
train_precision_micro_tok: 0.8918601665382782
train_recall_micro_tok: 0.8918601665382782
train_f-score_micro_tok: 0.8918601665382782
train_time: 51.13470983505249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4691    0.0702    0.1221      1624
           N     0.6476    0.8118    0.7205      3310
           P     0.7021    0.8075    0.7511      3610

   micro avg     0.6690    0.6690    0.6690      8544
   macro avg     0.6063    0.5632    0.5312      8544
weighted avg     0.6367    0.6690    0.6197      8544

F1-macro sent:  0.5312293471752033
F1-micro sent:  0.6690074906367042
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9027    0.9711    0.9357    124347
           N     0.7873    0.6288    0.6992     14202
           P     0.8774    0.6475    0.7451     25017

   micro avg     0.8919    0.8919    0.8919    163566
   macro avg     0.8558    0.7491    0.7933    163566
weighted avg     0.8888    0.8919    0.8860    163566

F1-macro tok:  0.7933107564201894
F1-micro tok:  0.8918601665382782
**************************************************
dev_cost_sum: 43023.96435546875
dev_cost_avg: 39.07717016845481
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19043.0
dev_accuracy_tok: 0.8951302058851179
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6179401993355482
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7223300970873786
dev_label=P_precision_sent: 0.705050505050505
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7433439829605964
dev_precision_macro_sent: 0.6909969014620178
dev_recall_macro_sent: 0.5560984504073105
dev_f-score_macro_sent: 0.49714171766978277
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9067512983266013
dev_label=O_recall_tok: 0.9697007096575131
dev_label=O_f-score_tok: 0.9371701207693456
dev_label=N_precision_tok: 0.7696440564137005
dev_label=N_recall_tok: 0.617124394184168
dev_label=N_f-score_tok: 0.6849970113568441
dev_label=P_precision_tok: 0.8892057026476579
dev_label=P_recall_tok: 0.6796388542963886
dev_label=P_f-score_tok: 0.7704252691018176
dev_precision_macro_tok: 0.8552003524626532
dev_recall_macro_tok: 0.7554879860460232
dev_f-score_macro_tok: 0.7975308004093358
dev_precision_micro_tok: 0.8951302058851179
dev_recall_micro_tok: 0.8951302058851179
dev_f-score_micro_tok: 0.8951302058851179
dev_time: 2.5008561611175537
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6179    0.8692    0.7223       428
           P     0.7051    0.7860    0.7433       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6910    0.5561    0.4971      1101
weighted avg     0.6805    0.6576    0.5859      1101

F1-macro sent:  0.49714171766978277
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9068    0.9697    0.9372     16205
           N     0.7696    0.6171    0.6850      1857
           P     0.8892    0.6796    0.7704      3212

   micro avg     0.8951    0.8951    0.8951     21274
   macro avg     0.8552    0.7555    0.7975     21274
weighted avg     0.8921    0.8951    0.8900     21274

F1-macro tok:  0.7975308004093358
F1-micro tok:  0.8951302058851179
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 0.900000
train_cost_sum: 314926.3825683594
train_cost_avg: 36.85936125566004
train_count_sent: 8544.0
train_total_correct_sent: 5703.0
train_accuracy_sent: 0.6674859550561798
train_count_tok: 163566.0
train_total_correct_tok: 146218.0
train_accuracy_tok: 0.8939388381448468
train_label=O_precision_sent: 0.4076655052264808
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.12244897959183672
train_label=N_precision_sent: 0.6515301085883515
train_label=N_recall_sent: 0.797583081570997
train_label=N_f-score_sent: 0.71719641401793
train_label=P_precision_sent: 0.7005945303210463
train_label=P_recall_sent: 0.8160664819944599
train_label=P_f-score_sent: 0.7539347408829176
train_precision_macro_sent: 0.5865967147119595
train_recall_macro_sent: 0.5618979661802754
train_f-score_macro_sent: 0.5311933781642281
train_precision_micro_sent: 0.6674859550561798
train_recall_micro_sent: 0.6674859550561798
train_f-score_micro_sent: 0.6674859550561798
train_label=O_precision_tok: 0.9052647356390752
train_label=O_recall_tok: 0.9714267332545217
train_label=O_f-score_tok: 0.9371794772327005
train_label=N_precision_tok: 0.7867203219315896
train_label=N_recall_tok: 0.6332206731446275
train_label=N_f-score_tok: 0.7016736238442633
train_label=P_precision_tok: 0.8786631016042781
train_label=P_recall_tok: 0.6567933805012591
train_label=P_f-score_tok: 0.7516984239540682
train_precision_macro_tok: 0.856882719724981
train_recall_macro_tok: 0.7538135956334694
train_f-score_macro_tok: 0.7968505083436773
train_precision_micro_tok: 0.8939388381448468
train_recall_micro_tok: 0.8939388381448468
train_f-score_micro_tok: 0.8939388381448468
train_time: 51.47943687438965
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4077    0.0720    0.1224      1624
           N     0.6515    0.7976    0.7172      3310
           P     0.7006    0.8161    0.7539      3610

   micro avg     0.6675    0.6675    0.6675      8544
   macro avg     0.5866    0.5619    0.5312      8544
weighted avg     0.6259    0.6675    0.6197      8544

F1-macro sent:  0.5311933781642281
F1-micro sent:  0.6674859550561798
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9053    0.9714    0.9372    124347
           N     0.7867    0.6332    0.7017     14202
           P     0.8787    0.6568    0.7517     25017

   micro avg     0.8939    0.8939    0.8939    163566
   macro avg     0.8569    0.7538    0.7969    163566
weighted avg     0.8909    0.8939    0.8884    163566

F1-macro tok:  0.7968505083436773
F1-micro tok:  0.8939388381448468
**************************************************
dev_cost_sum: 42880.7392578125
dev_cost_avg: 38.94708379456176
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19079.0
dev_accuracy_tok: 0.8968224123343048
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08032128514056225
dev_label=N_precision_sent: 0.670020120724346
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.72
dev_label=P_precision_sent: 0.6558219178082192
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.745136186770428
dev_precision_macro_sent: 0.6086140128441885
dev_recall_macro_sent: 0.561439372686975
dev_f-score_macro_sent: 0.5151524906369968
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9063631660631143
dev_label=O_recall_tok: 0.973033014501697
dev_label=O_f-score_tok: 0.9385155645497291
dev_label=N_precision_tok: 0.7722705961152043
dev_label=N_recall_tok: 0.620893914916532
dev_label=N_f-score_tok: 0.6883582089552238
dev_label=P_precision_tok: 0.9052013422818792
dev_label=P_recall_tok: 0.6718555417185554
dev_label=P_f-score_tok: 0.7712651894210151
dev_precision_macro_tok: 0.8612783681533993
dev_recall_macro_tok: 0.7552608237122614
dev_f-score_macro_tok: 0.7993796543086559
dev_precision_micro_tok: 0.8968224123343048
dev_recall_micro_tok: 0.8968224123343048
dev_f-score_micro_tok: 0.8968224123343048
dev_time: 2.4589765071868896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0437    0.0803       229
           N     0.6700    0.7780    0.7200       428
           P     0.6558    0.8626    0.7451       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.6086    0.5614    0.5152      1101
weighted avg     0.6289    0.6594    0.5971      1101

F1-macro sent:  0.5151524906369968
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9064    0.9730    0.9385     16205
           N     0.7723    0.6209    0.6884      1857
           P     0.9052    0.6719    0.7713      3212

   micro avg     0.8968    0.8968    0.8968     21274
   macro avg     0.8613    0.7553    0.7994     21274
weighted avg     0.8945    0.8968    0.8914     21274

F1-macro tok:  0.7993796543086559
F1-micro tok:  0.8968224123343048
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 313536.0219116211
train_cost_avg: 36.69663177804554
train_count_sent: 8544.0
train_total_correct_sent: 5774.0
train_accuracy_sent: 0.6757958801498127
train_count_tok: 163566.0
train_total_correct_tok: 146419.0
train_accuracy_tok: 0.8951676998887299
train_label=O_precision_sent: 0.4412811387900356
train_label=O_recall_sent: 0.07635467980295567
train_label=O_f-score_sent: 0.13018372703412073
train_label=N_precision_sent: 0.6530266343825666
train_label=N_recall_sent: 0.8148036253776435
train_label=N_f-score_sent: 0.7250000000000001
train_label=P_precision_sent: 0.7144931042826035
train_label=P_recall_sent: 0.818005540166205
train_label=P_f-score_sent: 0.7627534547333076
train_precision_macro_sent: 0.6029336258184018
train_recall_macro_sent: 0.569721281782268
train_f-score_macro_sent: 0.5393123939224761
train_precision_micro_sent: 0.6757958801498127
train_recall_micro_sent: 0.6757958801498127
train_f-score_micro_sent: 0.6757958801498127
train_label=O_precision_tok: 0.9062279688601557
train_label=O_recall_tok: 0.9717242876788342
train_label=O_f-score_tok: 0.9378339885362134
train_label=N_precision_tok: 0.7921907756813418
train_label=N_recall_tok: 0.6385720321081538
train_label=N_f-score_tok: 0.7071345029239766
train_label=P_precision_tok: 0.8794186541737649
train_label=P_recall_tok: 0.6603109885278011
train_label=P_f-score_tok: 0.7542750165521335
train_precision_macro_tok: 0.8592791329050874
train_recall_macro_tok: 0.7568691027715962
train_f-score_macro_tok: 0.7997478360041077
train_precision_micro_tok: 0.8951676998887299
train_recall_micro_tok: 0.8951676998887299
train_f-score_micro_tok: 0.89516769988873
train_time: 51.36684441566467
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4413    0.0764    0.1302      1624
           N     0.6530    0.8148    0.7250      3310
           P     0.7145    0.8180    0.7628      3610

   micro avg     0.6758    0.6758    0.6758      8544
   macro avg     0.6029    0.5697    0.5393      8544
weighted avg     0.6387    0.6758    0.6279      8544

F1-macro sent:  0.5393123939224761
F1-micro sent:  0.6757958801498127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9062    0.9717    0.9378    124347
           N     0.7922    0.6386    0.7071     14202
           P     0.8794    0.6603    0.7543     25017

   micro avg     0.8952    0.8952    0.8952    163566
   macro avg     0.8593    0.7569    0.7997    163566
weighted avg     0.8922    0.8952    0.8897    163566

F1-macro tok:  0.7997478360041077
F1-micro tok:  0.89516769988873
**************************************************
dev_cost_sum: 42787.626220703125
dev_cost_avg: 38.86251246203735
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19118.0
dev_accuracy_tok: 0.8986556359875905
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.625
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7295719844357976
dev_label=P_precision_sent: 0.709349593495935
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7457264957264957
dev_precision_macro_sent: 0.7040424570912376
dev_recall_macro_sent: 0.564257315308207
dev_f-score_macro_sent: 0.5113740031913526
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.903485254691689
dev_label=O_recall_tok: 0.9774143782783091
dev_label=O_f-score_tok: 0.9389969172397439
dev_label=N_precision_tok: 0.7917251051893408
dev_label=N_recall_tok: 0.6079698438341411
dev_label=N_f-score_tok: 0.6877855619859885
dev_label=P_precision_tok: 0.927924039706517
dev_label=P_recall_tok: 0.6693648816936488
dev_label=P_f-score_tok: 0.7777174896002894
dev_precision_macro_tok: 0.874378133195849
dev_recall_macro_tok: 0.751583034602033
dev_f-score_macro_tok: 0.8014999896086739
dev_precision_micro_tok: 0.8986556359875905
dev_recall_micro_tok: 0.8986556359875905
dev_f-score_micro_tok: 0.8986556359875905
dev_time: 2.4472763538360596
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6250    0.8762    0.7296       428
           P     0.7093    0.7860    0.7457       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.7040    0.5643    0.5114      1101
weighted avg     0.6908    0.6639    0.5966      1101

F1-macro sent:  0.5113740031913526
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9035    0.9774    0.9390     16205
           N     0.7917    0.6080    0.6878      1857
           P     0.9279    0.6694    0.7777      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8744    0.7516    0.8015     21274
weighted avg     0.8974    0.8987    0.8927     21274

F1-macro tok:  0.8014999896086739
F1-micro tok:  0.8986556359875905
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 311814.36376953125
train_cost_avg: 36.49512684568484
train_count_sent: 8544.0
train_total_correct_sent: 5769.0
train_accuracy_sent: 0.6752106741573034
train_count_tok: 163566.0
train_total_correct_tok: 146661.0
train_accuracy_tok: 0.8966472249734052
train_label=O_precision_sent: 0.4297872340425532
train_label=O_recall_sent: 0.062192118226600986
train_label=O_f-score_sent: 0.10866057019903175
train_label=N_precision_sent: 0.654656862745098
train_label=N_recall_sent: 0.8069486404833837
train_label=N_f-score_sent: 0.7228687415426253
train_label=P_precision_sent: 0.7086781745093402
train_label=P_recall_sent: 0.8301939058171746
train_label=P_f-score_sent: 0.764638346727899
train_precision_macro_sent: 0.5977074237656638
train_recall_macro_sent: 0.5664448881757197
train_f-score_macro_sent: 0.5320558861565187
train_precision_micro_sent: 0.6752106741573034
train_recall_micro_sent: 0.6752106741573034
train_f-score_micro_sent: 0.6752106741573034
train_label=O_precision_tok: 0.9077273205245685
train_label=O_recall_tok: 0.9719012119311282
train_label=O_f-score_tok: 0.9387187603161349
train_label=N_precision_tok: 0.7941941074523396
train_label=N_recall_tok: 0.6453316434305028
train_label=N_f-score_tok: 0.7120658845466553
train_label=P_precision_tok: 0.8811414654807285
train_label=P_recall_tok: 0.6652676180197465
train_label=P_f-score_tok: 0.7581368864594009
train_precision_macro_tok: 0.861020964485879
train_recall_macro_tok: 0.7608334911271258
train_f-score_macro_tok: 0.8029738437740637
train_precision_micro_tok: 0.8966472249734052
train_recall_micro_tok: 0.8966472249734052
train_f-score_micro_tok: 0.8966472249734051
train_time: 51.06163740158081
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4298    0.0622    0.1087      1624
           N     0.6547    0.8069    0.7229      3310
           P     0.7087    0.8302    0.7646      3610

   micro avg     0.6752    0.6752    0.6752      8544
   macro avg     0.5977    0.5664    0.5321      8544
weighted avg     0.6347    0.6752    0.6238      8544

F1-macro sent:  0.5320558861565187
F1-micro sent:  0.6752106741573034
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9077    0.9719    0.9387    124347
           N     0.7942    0.6453    0.7121     14202
           P     0.8811    0.6653    0.7581     25017

   micro avg     0.8966    0.8966    0.8966    163566
   macro avg     0.8610    0.7608    0.8030    163566
weighted avg     0.8938    0.8966    0.8914    163566

F1-macro tok:  0.8029738437740637
F1-micro tok:  0.8966472249734051
**************************************************
dev_cost_sum: 42689.56982421875
dev_cost_avg: 38.773451248155084
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.48936170212765956
dev_label=O_recall_sent: 0.10043668122270742
dev_label=O_f-score_sent: 0.16666666666666669
dev_label=N_precision_sent: 0.6919831223628692
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7272727272727273
dev_label=P_precision_sent: 0.656896551724138
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.744140625
dev_precision_macro_sent: 0.6127471254048888
dev_recall_macro_sent: 0.5749666431725772
dev_f-score_macro_sent: 0.546026672979798
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9039913083257091
dev_label=O_recall_tok: 0.9755630978093182
dev_label=O_f-score_tok: 0.9384145074644586
dev_label=N_precision_tok: 0.8131462333825702
dev_label=N_recall_tok: 0.592891760904685
dev_label=N_f-score_tok: 0.6857676736219247
dev_label=P_precision_tok: 0.8980263157894737
dev_label=P_recall_tok: 0.6799501867995019
dev_label=P_f-score_tok: 0.7739192062367115
dev_precision_macro_tok: 0.8717212858325842
dev_recall_macro_tok: 0.7494683485045016
dev_f-score_macro_tok: 0.7993671291076984
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 2.4646692276000977
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4894    0.1004    0.1667       229
           N     0.6920    0.7664    0.7273       428
           P     0.6569    0.8581    0.7441       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6127    0.5750    0.5460      1101
weighted avg     0.6357    0.6649    0.6175      1101

F1-macro sent:  0.546026672979798
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9040    0.9756    0.9384     16205
           N     0.8131    0.5929    0.6858      1857
           P     0.8980    0.6800    0.7739      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8717    0.7495    0.7994     21274
weighted avg     0.8952    0.8975    0.8915     21274

F1-macro tok:  0.7993671291076984
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 310133.8801269531
train_cost_avg: 36.2984410260947
train_count_sent: 8544.0
train_total_correct_sent: 5792.0
train_accuracy_sent: 0.6779026217228464
train_count_tok: 163566.0
train_total_correct_tok: 146941.0
train_accuracy_tok: 0.8983590721788147
train_label=O_precision_sent: 0.4418604651162791
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.12114771519659935
train_label=N_precision_sent: 0.6569200779727096
train_label=N_recall_sent: 0.8145015105740181
train_label=N_f-score_sent: 0.7272727272727273
train_label=P_precision_sent: 0.7130559540889526
train_label=P_recall_sent: 0.8260387811634349
train_label=P_f-score_sent: 0.7654004106776181
train_precision_macro_sent: 0.6039454990593137
train_recall_macro_sent: 0.5702457786908094
train_f-score_macro_sent: 0.5379402843823149
train_precision_micro_sent: 0.6779026217228464
train_recall_micro_sent: 0.6779026217228464
train_f-score_micro_sent: 0.6779026217228464
train_label=O_precision_tok: 0.9093645359118101
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.9395821833137669
train_label=N_precision_tok: 0.7970138948821955
train_label=N_recall_tok: 0.6502605266863822
train_label=N_f-score_tok: 0.7161968281050061
train_label=P_precision_tok: 0.8832529867952211
train_label=P_recall_tok: 0.6737818283567174
train_label=P_f-score_tok: 0.7644271104963606
train_precision_macro_tok: 0.8632104725297424
train_recall_macro_tok: 0.7653064803132748
train_f-score_macro_tok: 0.8067353739717111
train_precision_micro_tok: 0.8983590721788147
train_recall_micro_tok: 0.8983590721788147
train_f-score_micro_tok: 0.8983590721788147
train_time: 51.52661681175232
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4419    0.0702    0.1211      1624
           N     0.6569    0.8145    0.7273      3310
           P     0.7131    0.8260    0.7654      3610

   micro avg     0.6779    0.6779    0.6779      8544
   macro avg     0.6039    0.5702    0.5379      8544
weighted avg     0.6398    0.6779    0.6282      8544

F1-macro sent:  0.5379402843823149
F1-micro sent:  0.6779026217228464
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9094    0.9719    0.9396    124347
           N     0.7970    0.6503    0.7162     14202
           P     0.8833    0.6738    0.7644     25017

   micro avg     0.8984    0.8984    0.8984    163566
   macro avg     0.8632    0.7653    0.8067    163566
weighted avg     0.8956    0.8984    0.8934    163566

F1-macro tok:  0.8067353739717111
F1-micro tok:  0.8983590721788147
**************************************************
dev_cost_sum: 42766.31396484375
dev_cost_avg: 38.8431552814203
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 19087.0
dev_accuracy_tok: 0.8971984582119018
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.725130890052356
dev_label=N_recall_sent: 0.647196261682243
dev_label=N_f-score_sent: 0.6839506172839506
dev_label=P_precision_sent: 0.5734265734265734
dev_label=P_recall_sent: 0.9234234234234234
dev_label=P_f-score_sent: 0.7075064710957721
dev_precision_macro_sent: 0.7661858211596431
dev_recall_macro_sent: 0.5293623113379878
dev_f-score_macro_sent: 0.4752639507760736
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.9046800710316778
dev_label=O_recall_tok: 0.9745757482258562
dev_label=O_f-score_tok: 0.9383280850811004
dev_label=N_precision_tok: 0.7902439024390244
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6889428918590523
dev_label=P_precision_tok: 0.906801007556675
dev_label=P_recall_tok: 0.6724782067247821
dev_label=P_f-score_tok: 0.7722559885591705
dev_precision_macro_tok: 0.8672416603424592
dev_recall_macro_tok: 0.7525721045312036
dev_f-score_macro_tok: 0.7998423218331078
dev_precision_micro_tok: 0.8971984582119018
dev_recall_micro_tok: 0.8971984582119018
dev_f-score_micro_tok: 0.8971984582119018
dev_time: 2.5121519565582275
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.7251    0.6472    0.6840       428
           P     0.5734    0.9234    0.7075       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.7662    0.5294    0.4753      1101
weighted avg     0.7211    0.6276    0.5583      1101

F1-macro sent:  0.4752639507760736
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9047    0.9746    0.9383     16205
           N     0.7902    0.6107    0.6889      1857
           P     0.9068    0.6725    0.7723      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8672    0.7526    0.7998     21274
weighted avg     0.8950    0.8972    0.8915     21274

F1-macro tok:  0.7998423218331078
F1-micro tok:  0.8971984582119018
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 308954.21661376953
train_cost_avg: 36.16037179468276
train_count_sent: 8544.0
train_total_correct_sent: 5843.0
train_accuracy_sent: 0.6838717228464419
train_count_tok: 163566.0
train_total_correct_tok: 147115.0
train_accuracy_tok: 0.8994228629421762
train_label=O_precision_sent: 0.5342465753424658
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.12696690179055886
train_label=N_precision_sent: 0.6486169714017815
train_label=N_recall_sent: 0.83595166163142
train_label=N_f-score_sent: 0.7304646251319958
train_label=P_precision_sent: 0.7289972899728997
train_label=P_recall_sent: 0.8196675900277008
train_label=P_f-score_sent: 0.7716781849002479
train_precision_macro_sent: 0.6372869455723823
train_recall_macro_sent: 0.5758878622114968
train_f-score_macro_sent: 0.5430365706076009
train_precision_micro_sent: 0.6838717228464419
train_recall_micro_sent: 0.6838717228464419
train_f-score_micro_sent: 0.6838717228464419
train_label=O_precision_tok: 0.9106810457220803
train_label=O_recall_tok: 0.9718047077935134
train_label=O_f-score_tok: 0.9402505446623094
train_label=N_precision_tok: 0.7939668432746539
train_label=N_recall_tok: 0.6542036332910858
train_label=N_f-score_tok: 0.7173409512044472
train_label=P_precision_tok: 0.8858692817276094
train_label=P_recall_tok: 0.6788583763041132
train_label=P_f-score_tok: 0.7686702272110075
train_precision_macro_tok: 0.8635057235747813
train_recall_macro_tok: 0.7682889057962375
train_f-score_macro_tok: 0.808753907692588
train_precision_micro_tok: 0.8994228629421762
train_recall_micro_tok: 0.8994228629421762
train_f-score_micro_tok: 0.8994228629421762
train_time: 51.21699833869934
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5342    0.0720    0.1270      1624
           N     0.6486    0.8360    0.7305      3310
           P     0.7290    0.8197    0.7717      3610

   micro avg     0.6839    0.6839    0.6839      8544
   macro avg     0.6373    0.5759    0.5430      8544
weighted avg     0.6608    0.6839    0.6332      8544

F1-macro sent:  0.5430365706076009
F1-micro sent:  0.6838717228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9107    0.9718    0.9403    124347
           N     0.7940    0.6542    0.7173     14202
           P     0.8859    0.6789    0.7687     25017

   micro avg     0.8994    0.8994    0.8994    163566
   macro avg     0.8635    0.7683    0.8088    163566
weighted avg     0.8968    0.8994    0.8947    163566

F1-macro tok:  0.808753907692588
F1-micro tok:  0.8994228629421762
**************************************************
dev_cost_sum: 42563.62158203125
dev_cost_avg: 38.65905684108197
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19127.0
dev_accuracy_tok: 0.8990786875998872
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11336032388663966
dev_label=N_precision_sent: 0.627287853577371
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7327502429543246
dev_label=P_precision_sent: 0.7178423236514523
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7473002159827214
dev_precision_macro_sent: 0.7076359850022004
dev_recall_macro_sent: 0.5737519239845486
dev_f-score_macro_sent: 0.5311369276078952
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9105013314808382
dev_label=O_recall_tok: 0.9705646405430423
dev_label=O_f-score_tok: 0.9395740613518923
dev_label=N_precision_tok: 0.7738172391445236
dev_label=N_recall_tok: 0.6429725363489499
dev_label=N_f-score_tok: 0.7023529411764706
dev_label=P_precision_tok: 0.8974358974358975
dev_label=P_recall_tok: 0.6864881693648817
dev_label=P_f-score_tok: 0.7779149761862761
dev_precision_macro_tok: 0.8605848226870864
dev_recall_macro_tok: 0.7666751154189578
dev_f-score_macro_tok: 0.8066139929048797
dev_precision_micro_tok: 0.8990786875998872
dev_recall_micro_tok: 0.8990786875998872
dev_f-score_micro_tok: 0.8990786875998872
dev_time: 2.451671600341797
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0611    0.1134       229
           N     0.6273    0.8808    0.7328       428
           P     0.7178    0.7793    0.7473       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.7076    0.5738    0.5311      1101
weighted avg     0.6951    0.6694    0.6098      1101

F1-macro sent:  0.5311369276078952
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9706    0.9396     16205
           N     0.7738    0.6430    0.7024      1857
           P     0.8974    0.6865    0.7779      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8606    0.7667    0.8066     21274
weighted avg     0.8966    0.8991    0.8945     21274

F1-macro tok:  0.8066139929048797
F1-micro tok:  0.8990786875998872
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.900000
train_cost_sum: 307698.36584472656
train_cost_avg: 36.01338551553447
train_count_sent: 8544.0
train_total_correct_sent: 5807.0
train_accuracy_sent: 0.6796582397003745
train_count_tok: 163566.0
train_total_correct_tok: 147280.0
train_accuracy_tok: 0.900431630045364
train_label=O_precision_sent: 0.4388059701492537
train_label=O_recall_sent: 0.09051724137931035
train_label=O_f-score_sent: 0.15007656967840732
train_label=N_precision_sent: 0.6571776155717761
train_label=N_recall_sent: 0.816012084592145
train_label=N_f-score_sent: 0.7280323450134771
train_label=P_precision_sent: 0.7218833861917541
train_label=P_recall_sent: 0.8196675900277008
train_label=P_f-score_sent: 0.7676741471007912
train_precision_macro_sent: 0.6059556573042614
train_recall_macro_sent: 0.5753989719997188
train_f-score_macro_sent: 0.5485943539308918
train_precision_micro_sent: 0.6796582397003745
train_recall_micro_sent: 0.6796582397003745
train_f-score_micro_sent: 0.6796582397003745
train_label=O_precision_tok: 0.9123168861388756
train_label=O_recall_tok: 0.971129178830209
train_label=O_f-score_tok: 0.9408047991897472
train_label=N_precision_tok: 0.7976716519374575
train_label=N_recall_tok: 0.6609632446134347
train_label=N_f-score_tok: 0.722911051212938
train_label=P_precision_tok: 0.881708258296887
train_label=P_recall_tok: 0.6849742175320782
train_label=P_f-score_tok: 0.7709889318815801
train_precision_macro_tok: 0.8638989321244067
train_recall_macro_tok: 0.7723555469919073
train_f-score_macro_tok: 0.8115682607614217
train_precision_micro_tok: 0.900431630045364
train_recall_micro_tok: 0.900431630045364
train_f-score_micro_tok: 0.900431630045364
train_time: 51.32178258895874
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4388    0.0905    0.1501      1624
           N     0.6572    0.8160    0.7280      3310
           P     0.7219    0.8197    0.7677      3610

   micro avg     0.6797    0.6797    0.6797      8544
   macro avg     0.6060    0.5754    0.5486      8544
weighted avg     0.6430    0.6797    0.6349      8544

F1-macro sent:  0.5485943539308918
F1-micro sent:  0.6796582397003745
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9711    0.9408    124347
           N     0.7977    0.6610    0.7229     14202
           P     0.8817    0.6850    0.7710     25017

   micro avg     0.9004    0.9004    0.9004    163566
   macro avg     0.8639    0.7724    0.8116    163566
weighted avg     0.8977    0.9004    0.8959    163566

F1-macro tok:  0.8115682607614217
F1-micro tok:  0.900431630045364
**************************************************
dev_cost_sum: 42416.59606933594
dev_cost_avg: 38.5255186824123
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19176.0
dev_accuracy_tok: 0.9013819686001692
dev_label=O_precision_sent: 0.46153846153846156
dev_label=O_recall_sent: 0.10480349344978165
dev_label=O_f-score_sent: 0.17081850533807827
dev_label=N_precision_sent: 0.7096069868995634
dev_label=N_recall_sent: 0.7593457943925234
dev_label=N_f-score_sent: 0.7336343115124153
dev_label=P_precision_sent: 0.6565143824027073
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7497584541062802
dev_precision_macro_sent: 0.6092199436135775
dev_recall_macro_sent: 0.5793410539053929
dev_f-score_macro_sent: 0.5514037569855913
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9055558727802204
dev_label=O_recall_tok: 0.9786485652576365
dev_label=O_f-score_tok: 0.9406845008600747
dev_label=N_precision_tok: 0.8057302585604472
dev_label=N_recall_tok: 0.620893914916532
dev_label=N_f-score_tok: 0.7013381995133818
dev_label=P_precision_tok: 0.9287553648068669
dev_label=P_recall_tok: 0.6737235367372354
dev_label=P_f-score_tok: 0.7809455070371707
dev_precision_macro_tok: 0.8800138320491783
dev_recall_macro_tok: 0.757755338970468
dev_f-score_macro_tok: 0.8076560691368758
dev_precision_micro_tok: 0.9013819686001692
dev_recall_micro_tok: 0.9013819686001692
dev_f-score_micro_tok: 0.9013819686001692
dev_time: 2.470396041870117
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.1048    0.1708       229
           N     0.7096    0.7593    0.7336       428
           P     0.6565    0.8739    0.7498       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6092    0.5793    0.5514      1101
weighted avg     0.6366    0.6694    0.6231      1101

F1-macro sent:  0.5514037569855913
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9786    0.9407     16205
           N     0.8057    0.6209    0.7013      1857
           P     0.9288    0.6737    0.7809      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8800    0.7578    0.8077     21274
weighted avg     0.9003    0.9014    0.8957     21274

F1-macro tok:  0.8076560691368758
F1-micro tok:  0.9013819686001692
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 0.900000
train_cost_sum: 306226.05291748047
train_cost_avg: 35.84106424595979
train_count_sent: 8544.0
train_total_correct_sent: 5880.0
train_accuracy_sent: 0.6882022471910112
train_count_tok: 163566.0
train_total_correct_tok: 147571.0
train_accuracy_tok: 0.9022107283909859
train_label=O_precision_sent: 0.45483870967741935
train_label=O_recall_sent: 0.08682266009852217
train_label=O_f-score_sent: 0.14581178903826267
train_label=N_precision_sent: 0.6555763823805061
train_label=N_recall_sent: 0.8453172205438066
train_label=N_f-score_sent: 0.7384534177883346
train_label=P_precision_sent: 0.7415532022188603
train_label=P_recall_sent: 0.8146814404432133
train_label=P_f-score_sent: 0.7763991552270327
train_precision_macro_sent: 0.6173227647589287
train_recall_macro_sent: 0.5822737736951807
train_f-score_macro_sent: 0.55355478735121
train_precision_micro_sent: 0.6882022471910112
train_recall_micro_sent: 0.6882022471910112
train_f-score_micro_sent: 0.6882022471910112
train_label=O_precision_tok: 0.9140091503762241
train_label=O_recall_tok: 0.9719896740572752
train_label=O_f-score_tok: 0.9421081759437528
train_label=N_precision_tok: 0.8035307036067235
train_label=N_recall_tok: 0.6698352344740177
train_label=N_f-score_tok: 0.7306171037978572
train_label=P_precision_tok: 0.882105479170942
train_label=P_recall_tok: 0.6872926410041172
train_label=P_f-score_tok: 0.7726077871891077
train_precision_macro_tok: 0.8665484443846299
train_recall_macro_tok: 0.7763725165118034
train_f-score_macro_tok: 0.8151110223102392
train_precision_micro_tok: 0.9022107283909859
train_recall_micro_tok: 0.9022107283909859
train_f-score_micro_tok: 0.9022107283909858
train_time: 51.481701612472534
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4548    0.0868    0.1458      1624
           N     0.6556    0.8453    0.7385      3310
           P     0.7416    0.8147    0.7764      3610

   micro avg     0.6882    0.6882    0.6882      8544
   macro avg     0.6173    0.5823    0.5536      8544
weighted avg     0.6537    0.6882    0.6418      8544

F1-macro sent:  0.55355478735121
F1-micro sent:  0.6882022471910112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9140    0.9720    0.9421    124347
           N     0.8035    0.6698    0.7306     14202
           P     0.8821    0.6873    0.7726     25017

   micro avg     0.9022    0.9022    0.9022    163566
   macro avg     0.8665    0.7764    0.8151    163566
weighted avg     0.8995    0.9022    0.8978    163566

F1-macro tok:  0.8151110223102392
F1-micro tok:  0.9022107283909858
**************************************************
dev_cost_sum: 42355.896423339844
dev_cost_avg: 38.47038730548578
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19137.0
dev_accuracy_tok: 0.8995487449468835
dev_label=O_precision_sent: 0.4166666666666667
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.07905138339920947
dev_label=N_precision_sent: 0.6256323777403036
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7267384916748285
dev_label=P_precision_sent: 0.71900826446281
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.75
dev_precision_macro_sent: 0.5871024362899268
dev_recall_macro_sent: 0.5647581119870227
dev_f-score_macro_sent: 0.5185966250246793
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9070181484034
dev_label=O_recall_tok: 0.9745757482258562
dev_label=O_f-score_tok: 0.9395841389773031
dev_label=N_precision_tok: 0.8058321479374111
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6944529574011645
dev_label=P_precision_tok: 0.9002442996742671
dev_label=P_recall_tok: 0.6883561643835616
dev_label=P_f-score_tok: 0.7801693719124911
dev_precision_macro_tok: 0.871031532005026
dev_recall_macro_tok: 0.7576852560968748
dev_f-score_macro_tok: 0.8047354894303197
dev_precision_micro_tok: 0.8995487449468835
dev_recall_micro_tok: 0.8995487449468835
dev_f-score_micro_tok: 0.8995487449468835
dev_time: 2.5143747329711914
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0437    0.0791       229
           N     0.6256    0.8668    0.7267       428
           P     0.7190    0.7838    0.7500       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5871    0.5648    0.5186      1101
weighted avg     0.6198    0.6621    0.6014      1101

F1-macro sent:  0.5185966250246793
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9070    0.9746    0.9396     16205
           N     0.8058    0.6101    0.6945      1857
           P     0.9002    0.6884    0.7802      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8710    0.7577    0.8047     21274
weighted avg     0.8972    0.8995    0.8941     21274

F1-macro tok:  0.8047354894303197
F1-micro tok:  0.8995487449468835
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 0.900000
train_cost_sum: 304665.6103515625
train_cost_avg: 35.65842817785142
train_count_sent: 8544.0
train_total_correct_sent: 5894.0
train_accuracy_sent: 0.6898408239700374
train_count_tok: 163566.0
train_total_correct_tok: 147802.0
train_accuracy_tok: 0.9036230023354487
train_label=O_precision_sent: 0.49554896142433236
train_label=O_recall_sent: 0.10283251231527094
train_label=O_f-score_sent: 0.17032126466088732
train_label=N_precision_sent: 0.663926499032882
train_label=N_recall_sent: 0.829607250755287
train_label=N_f-score_sent: 0.7375772226698898
train_label=P_precision_sent: 0.7322525178088921
train_label=P_recall_sent: 0.8257617728531856
train_label=P_f-score_sent: 0.7762010154927743
train_precision_macro_sent: 0.6305759927553688
train_recall_macro_sent: 0.5860671786412478
train_f-score_macro_sent: 0.5613665009411838
train_precision_micro_sent: 0.6898408239700374
train_recall_micro_sent: 0.6898408239700374
train_f-score_micro_sent: 0.6898408239700374
train_label=O_precision_tok: 0.9159706576242386
train_label=O_recall_tok: 0.971040716704062
train_label=O_f-score_tok: 0.9427021118788305
train_label=N_precision_tok: 0.8049395161290323
train_label=N_recall_tok: 0.674693705111956
train_label=N_f-score_tok: 0.7340841185934267
train_label=P_precision_tok: 0.8807903624174606
train_label=P_recall_tok: 0.6984850301794779
train_label=P_f-score_tok: 0.7791153914749421
train_precision_macro_tok: 0.8672335120569105
train_recall_macro_tok: 0.7814064839984987
train_f-score_macro_tok: 0.8186338739823998
train_precision_micro_tok: 0.9036230023354487
train_recall_micro_tok: 0.9036230023354487
train_f-score_micro_tok: 0.9036230023354488
train_time: 51.33329367637634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4955    0.1028    0.1703      1624
           N     0.6639    0.8296    0.7376      3310
           P     0.7323    0.8258    0.7762      3610

   micro avg     0.6898    0.6898    0.6898      8544
   macro avg     0.6306    0.5861    0.5614      8544
weighted avg     0.6608    0.6898    0.6461      8544

F1-macro sent:  0.5613665009411838
F1-micro sent:  0.6898408239700374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9160    0.9710    0.9427    124347
           N     0.8049    0.6747    0.7341     14202
           P     0.8808    0.6985    0.7791     25017

   micro avg     0.9036    0.9036    0.9036    163566
   macro avg     0.8672    0.7814    0.8186    163566
weighted avg     0.9009    0.9036    0.8996    163566

F1-macro tok:  0.8186338739823998
F1-micro tok:  0.9036230023354488
**************************************************
dev_cost_sum: 42352.116638183594
dev_cost_avg: 38.46695425811407
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19141.0
dev_accuracy_tok: 0.899736767885682
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.0502092050209205
dev_label=N_precision_sent: 0.6166134185303515
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.7324478178368122
dev_label=P_precision_sent: 0.7397849462365591
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7568756875687569
dev_precision_macro_sent: 0.6521327882556368
dev_recall_macro_sent: 0.5676149356719082
dev_f-score_macro_sent: 0.5131775701421631
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9059726278417225
dev_label=O_recall_tok: 0.9763036099969146
dev_label=O_f-score_tok: 0.9398241653795889
dev_label=N_precision_tok: 0.7797179314976495
dev_label=N_recall_tok: 0.6252019386106623
dev_label=N_f-score_tok: 0.6939629408248655
dev_label=P_precision_tok: 0.929801894918174
dev_label=P_recall_tok: 0.6721668742216688
dev_label=P_f-score_tok: 0.7802674376581135
dev_precision_macro_tok: 0.8718308180858486
dev_recall_macro_tok: 0.7578908076097486
dev_f-score_macro_tok: 0.8046848479541894
dev_precision_micro_tok: 0.899736767885682
dev_recall_micro_tok: 0.899736767885682
dev_f-score_micro_tok: 0.899736767885682
dev_time: 2.43890643119812
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0262    0.0502       229
           N     0.6166    0.9019    0.7324       428
           P     0.7398    0.7748    0.7569       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6521    0.5676    0.5132      1101
weighted avg     0.6628    0.6685    0.6004      1101

F1-macro sent:  0.5131775701421631
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9060    0.9763    0.9398     16205
           N     0.7797    0.6252    0.6940      1857
           P     0.9298    0.6722    0.7803      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8718    0.7579    0.8047     21274
weighted avg     0.8985    0.8997    0.8943     21274

F1-macro tok:  0.8046848479541894
F1-micro tok:  0.899736767885682
**************************************************
Best epoch: 25
**************************************************

EPOCH: 28
Learning rate: 0.900000
train_cost_sum: 303007.40911865234
train_cost_avg: 35.46435031819433
train_count_sent: 8544.0
train_total_correct_sent: 5855.0
train_accuracy_sent: 0.6852762172284644
train_count_tok: 163566.0
train_total_correct_tok: 148299.0
train_accuracy_tok: 0.9066615311250504
train_label=O_precision_sent: 0.40294117647058825
train_label=O_recall_sent: 0.08435960591133004
train_label=O_f-score_sent: 0.1395112016293279
train_label=N_precision_sent: 0.6666666666666666
train_label=N_recall_sent: 0.8265861027190332
train_label=N_f-score_sent: 0.7380631238198004
train_label=P_precision_sent: 0.7273170731707317
train_label=P_recall_sent: 0.8260387811634349
train_label=P_f-score_sent: 0.7735408560311283
train_precision_macro_sent: 0.5989749721026622
train_recall_macro_sent: 0.578994829931266
train_f-score_macro_sent: 0.5503717271600855
train_precision_micro_sent: 0.6852762172284644
train_recall_micro_sent: 0.6852762172284644
train_f-score_micro_sent: 0.6852762172284644
train_label=O_precision_tok: 0.9183440941891379
train_label=O_recall_tok: 0.9722791864701199
train_label=O_f-score_tok: 0.9445423188552992
train_label=N_precision_tok: 0.8131904921325744
train_label=N_recall_tok: 0.6841289959160681
train_label=N_f-score_tok: 0.7430975143403442
train_label=P_precision_tok: 0.885566907051282
train_label=P_recall_tok: 0.7068393492425151
train_label=P_f-score_tok: 0.7861731688340557
train_precision_macro_tok: 0.8723671644576648
train_recall_macro_tok: 0.7877491772095677
train_f-score_macro_tok: 0.8246043340098997
train_precision_micro_tok: 0.9066615311250504
train_recall_micro_tok: 0.9066615311250504
train_f-score_micro_tok: 0.9066615311250504
train_time: 51.17823052406311
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4029    0.0844    0.1395      1624
           N     0.6667    0.8266    0.7381      3310
           P     0.7273    0.8260    0.7735      3610

   micro avg     0.6853    0.6853    0.6853      8544
   macro avg     0.5990    0.5790    0.5504      8544
weighted avg     0.6422    0.6853    0.6393      8544

F1-macro sent:  0.5503717271600855
F1-micro sent:  0.6852762172284644
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9183    0.9723    0.9445    124347
           N     0.8132    0.6841    0.7431     14202
           P     0.8856    0.7068    0.7862     25017

   micro avg     0.9067    0.9067    0.9067    163566
   macro avg     0.8724    0.7877    0.8246    163566
weighted avg     0.9042    0.9067    0.9028    163566

F1-macro tok:  0.8246043340098997
F1-micro tok:  0.9066615311250504
**************************************************
dev_cost_sum: 42297.04815673828
dev_cost_avg: 38.4169374720602
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19187.0
dev_accuracy_tok: 0.9018990316818651
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.12927756653992395
dev_label=N_precision_sent: 0.6415770609318996
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7261663286004056
dev_label=P_precision_sent: 0.7053045186640472
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7534102833158447
dev_precision_macro_sent: 0.6156271931986489
dev_recall_macro_sent: 0.5730809881832206
dev_f-score_macro_sent: 0.5362847261520581
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9097822329761494
dev_label=O_recall_tok: 0.9745140388768898
dev_label=O_f-score_tok: 0.9410362601674463
dev_label=N_precision_tok: 0.7901815736381977
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.7027511961722488
dev_label=P_precision_tok: 0.9139563606422396
dev_label=P_recall_tok: 0.6911581569115816
dev_label=P_f-score_tok: 0.7870944867931219
dev_precision_macro_tok: 0.8713067224188622
dev_recall_macro_tok: 0.7661377252879539
dev_f-score_macro_tok: 0.8102939810442723
dev_precision_micro_tok: 0.9018990316818651
dev_recall_micro_tok: 0.9018990316818651
dev_f-score_micro_tok: 0.9018990316818651
dev_time: 2.4545748233795166
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0742    0.1293       229
           N     0.6416    0.8364    0.7262       428
           P     0.7053    0.8086    0.7534       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6156    0.5731    0.5363      1101
weighted avg     0.6378    0.6667    0.6130      1101

F1-macro sent:  0.5362847261520581
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9098    0.9745    0.9410     16205
           N     0.7902    0.6327    0.7028      1857
           P     0.9140    0.6912    0.7871      3212

   micro avg     0.9019    0.9019    0.9019     21274
   macro avg     0.8713    0.7661    0.8103     21274
weighted avg     0.9000    0.9019    0.8970     21274

F1-macro tok:  0.8102939810442723
F1-micro tok:  0.9018990316818651
**************************************************
Best epoch: 25
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 301866.56787109375
train_cost_avg: 35.3308248912797
train_count_sent: 8544.0
train_total_correct_sent: 5934.0
train_accuracy_sent: 0.6945224719101124
train_count_tok: 163566.0
train_total_correct_tok: 148343.0
train_accuracy_tok: 0.9069305356859005
train_label=O_precision_sent: 0.4742857142857143
train_label=O_recall_sent: 0.1022167487684729
train_label=O_f-score_sent: 0.16818642350557245
train_label=N_precision_sent: 0.6744753538311371
train_label=N_recall_sent: 0.8350453172205438
train_label=N_f-score_sent: 0.7462203023758099
train_label=P_precision_sent: 0.7333984375
train_label=P_recall_sent: 0.8321329639889197
train_label=P_f-score_sent: 0.7796522190500909
train_precision_macro_sent: 0.6273865018722838
train_recall_macro_sent: 0.5897983433259788
train_f-score_macro_sent: 0.5646863149771577
train_precision_micro_sent: 0.6945224719101124
train_recall_micro_sent: 0.6945224719101124
train_f-score_micro_sent: 0.6945224719101124
train_label=O_precision_tok: 0.919129058762667
train_label=O_recall_tok: 0.9715875734838798
train_label=O_f-score_tok: 0.9446305773072547
train_label=N_precision_tok: 0.8120069750062276
train_label=N_recall_tok: 0.6885649908463597
train_label=N_f-score_tok: 0.7452086111640313
train_label=P_precision_tok: 0.8840081677374372
train_label=P_recall_tok: 0.709517528080905
train_label=P_f-score_tok: 0.7872095086038673
train_precision_macro_tok: 0.8717147338354438
train_recall_macro_tok: 0.7898900308037149
train_f-score_macro_tok: 0.825682899025051
train_precision_micro_tok: 0.9069305356859005
train_recall_micro_tok: 0.9069305356859005
train_f-score_micro_tok: 0.9069305356859005
train_time: 51.283478021621704
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4743    0.1022    0.1682      1624
           N     0.6745    0.8350    0.7462      3310
           P     0.7334    0.8321    0.7797      3610

   micro avg     0.6945    0.6945    0.6945      8544
   macro avg     0.6274    0.5898    0.5647      8544
weighted avg     0.6613    0.6945    0.6505      8544

F1-macro sent:  0.5646863149771577
F1-micro sent:  0.6945224719101124
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9191    0.9716    0.9446    124347
           N     0.8120    0.6886    0.7452     14202
           P     0.8840    0.7095    0.7872     25017

   micro avg     0.9069    0.9069    0.9069    163566
   macro avg     0.8717    0.7899    0.8257    163566
weighted avg     0.9045    0.9069    0.9032    163566

F1-macro tok:  0.825682899025051
F1-micro tok:  0.9069305356859005
**************************************************
dev_cost_sum: 42348.219299316406
dev_cost_avg: 38.46341444079601
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19047.0
dev_accuracy_tok: 0.8953182288239165
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.7180616740088106
dev_label=N_recall_sent: 0.7616822429906542
dev_label=N_f-score_sent: 0.7392290249433108
dev_label=P_precision_sent: 0.6343402225755167
dev_label=P_recall_sent: 0.8986486486486487
dev_label=P_f-score_sent: 0.7437092264678472
dev_precision_macro_sent: 0.6545043358984795
dev_recall_macro_sent: 0.5694552753790398
dev_f-score_macro_sent: 0.524002359107363
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9144937749588913
dev_label=O_recall_tok: 0.9609379821042888
dev_label=O_f-score_tok: 0.9371407937893059
dev_label=N_precision_tok: 0.7870307167235495
dev_label=N_recall_tok: 0.620893914916532
dev_label=N_f-score_tok: 0.6941601444912703
dev_label=P_precision_tok: 0.8349514563106796
dev_label=P_recall_tok: 0.7229140722291407
dev_label=P_f-score_tok: 0.7749040547305188
dev_precision_macro_tok: 0.8454919826643734
dev_recall_macro_tok: 0.7682486564166539
dev_f-score_macro_tok: 0.8020683310036985
dev_precision_micro_tok: 0.8953182288239165
dev_recall_micro_tok: 0.8953182288239165
dev_f-score_micro_tok: 0.8953182288239167
dev_time: 2.472395181655884
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.7181    0.7617    0.7392       428
           P     0.6343    0.8986    0.7437       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6545    0.5695    0.5240      1101
weighted avg     0.6621    0.6685    0.6058      1101

F1-macro sent:  0.524002359107363
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9145    0.9609    0.9371     16205
           N     0.7870    0.6209    0.6942      1857
           P     0.8350    0.7229    0.7749      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8455    0.7682    0.8021     21274
weighted avg     0.8914    0.8953    0.8914     21274

F1-macro tok:  0.8020683310036985
F1-micro tok:  0.8953182288239167
**************************************************
Best epoch: 25
**************************************************

EPOCH: 30
Learning rate: 0.810000
train_cost_sum: 300308.2844238281
train_cost_avg: 35.1484415290061
train_count_sent: 8544.0
train_total_correct_sent: 5959.0
train_accuracy_sent: 0.6974485018726592
train_count_tok: 163566.0
train_total_correct_tok: 148705.0
train_accuracy_tok: 0.9091437095728941
train_label=O_precision_sent: 0.4827586206896552
train_label=O_recall_sent: 0.11206896551724138
train_label=O_f-score_sent: 0.1819090454772614
train_label=N_precision_sent: 0.6709134615384615
train_label=N_recall_sent: 0.843202416918429
train_label=N_f-score_sent: 0.747255689424364
train_label=P_precision_sent: 0.7451959071624656
train_label=P_recall_sent: 0.8271468144044322
train_label=P_f-score_sent: 0.7840357095969542
train_precision_macro_sent: 0.6329559964635275
train_recall_macro_sent: 0.5941393989467009
train_f-score_macro_sent: 0.5710668148328599
train_precision_micro_sent: 0.6974485018726592
train_recall_micro_sent: 0.6974485018726592
train_f-score_micro_sent: 0.6974485018726592
train_label=O_precision_tok: 0.9216220132549324
train_label=O_recall_tok: 0.9718288338279171
train_label=O_f-score_tok: 0.9460597804813128
train_label=N_precision_tok: 0.8131002216202906
train_label=N_recall_tok: 0.6975073933248839
train_label=N_f-score_tok: 0.7508811824900512
train_label=P_precision_tok: 0.8861415457506663
train_label=P_recall_tok: 0.7177119558700084
train_label=P_f-score_tok: 0.7930828861061419
train_precision_macro_tok: 0.8736212602086297
train_recall_macro_tok: 0.7956827276742698
train_f-score_macro_tok: 0.830007949692502
train_precision_micro_tok: 0.9091437095728941
train_recall_micro_tok: 0.9091437095728941
train_f-score_micro_tok: 0.9091437095728941
train_time: 51.30996012687683
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4828    0.1121    0.1819      1624
           N     0.6709    0.8432    0.7473      3310
           P     0.7452    0.8271    0.7840      3610

   micro avg     0.6974    0.6974    0.6974      8544
   macro avg     0.6330    0.5941    0.5711      8544
weighted avg     0.6665    0.6974    0.6553      8544

F1-macro sent:  0.5710668148328599
F1-micro sent:  0.6974485018726592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9216    0.9718    0.9461    124347
           N     0.8131    0.6975    0.7509     14202
           P     0.8861    0.7177    0.7931     25017

   micro avg     0.9091    0.9091    0.9091    163566
   macro avg     0.8736    0.7957    0.8300    163566
weighted avg     0.9068    0.9091    0.9057    163566

F1-macro tok:  0.830007949692502
F1-micro tok:  0.9091437095728941
**************************************************
dev_cost_sum: 42238.76721191406
dev_cost_avg: 38.364002917269815
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19177.0
dev_accuracy_tok: 0.9014289743348689
dev_label=O_precision_sent: 0.5294117647058824
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07317073170731707
dev_label=N_precision_sent: 0.616504854368932
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.72848948374761
dev_label=P_precision_sent: 0.7274678111587983
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.7450549450549451
dev_precision_macro_sent: 0.6244614767445374
dev_recall_macro_sent: 0.564333913148344
dev_f-score_macro_sent: 0.5155717201699573
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9094522204942111
dev_label=O_recall_tok: 0.9743289108299907
dev_label=O_f-score_tok: 0.940773401656438
dev_label=N_precision_tok: 0.8065433854907539
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6950658902850138
dev_label=P_precision_tok: 0.8990825688073395
dev_label=P_recall_tok: 0.7017434620174346
dev_label=P_f-score_tok: 0.788249694002448
dev_precision_macro_tok: 0.8716927249307682
dev_recall_macro_tok: 0.7622449104967993
dev_f-score_macro_tok: 0.8080296619812999
dev_precision_micro_tok: 0.9014289743348689
dev_recall_micro_tok: 0.9014289743348689
dev_f-score_micro_tok: 0.9014289743348689
dev_time: 2.431293487548828
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0393    0.0732       229
           N     0.6165    0.8902    0.7285       428
           P     0.7275    0.7635    0.7451       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6245    0.5643    0.5156      1101
weighted avg     0.6431    0.6621    0.5989      1101

F1-macro sent:  0.5155717201699573
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9095    0.9743    0.9408     16205
           N     0.8065    0.6107    0.6951      1857
           P     0.8991    0.7017    0.7882      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8717    0.7622    0.8080     21274
weighted avg     0.8989    0.9014    0.8963     21274

F1-macro tok:  0.8080296619812999
F1-micro tok:  0.9014289743348689
**************************************************
Best epoch: 25
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 298521.8362426758
train_cost_avg: 34.93935349282254
train_count_sent: 8544.0
train_total_correct_sent: 5986.0
train_accuracy_sent: 0.7006086142322098
train_count_tok: 163566.0
train_total_correct_tok: 149117.0
train_accuracy_tok: 0.9116625704608537
train_label=O_precision_sent: 0.453125
train_label=O_recall_sent: 0.10714285714285714
train_label=O_f-score_sent: 0.17330677290836652
train_label=N_precision_sent: 0.6806948862246146
train_label=N_recall_sent: 0.8404833836858006
train_label=N_f-score_sent: 0.7521968365553602
train_label=P_precision_sent: 0.743923397986742
train_label=P_recall_sent: 0.8393351800554016
train_label=P_f-score_sent: 0.7887543928153066
train_precision_macro_sent: 0.6259144280704522
train_recall_macro_sent: 0.5956538069613532
train_f-score_macro_sent: 0.571419334093011
train_precision_micro_sent: 0.7006086142322098
train_recall_micro_sent: 0.7006086142322098
train_f-score_micro_sent: 0.7006086142322098
train_label=O_precision_tok: 0.9243308128110832
train_label=O_recall_tok: 0.9722470184242483
train_label=O_f-score_tok: 0.9476836246766482
train_label=N_precision_tok: 0.8179597818122608
train_label=N_recall_tok: 0.7074355724545839
train_label=N_f-score_tok: 0.7586936001510288
train_label=P_precision_tok: 0.8869692532942899
train_label=P_recall_tok: 0.7264660031178798
train_label=P_f-score_tok: 0.7987342606631946
train_precision_macro_tok: 0.8764199493058781
train_recall_macro_tok: 0.8020495313322374
train_f-score_macro_tok: 0.8350371618302906
train_precision_micro_tok: 0.9116625704608537
train_recall_micro_tok: 0.9116625704608537
train_f-score_micro_tok: 0.9116625704608539
train_time: 51.39177966117859
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4531    0.1071    0.1733      1624
           N     0.6807    0.8405    0.7522      3310
           P     0.7439    0.8393    0.7888      3610

   micro avg     0.7006    0.7006    0.7006      8544
   macro avg     0.6259    0.5957    0.5714      8544
weighted avg     0.6642    0.7006    0.6576      8544

F1-macro sent:  0.571419334093011
F1-micro sent:  0.7006086142322098
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9243    0.9722    0.9477    124347
           N     0.8180    0.7074    0.7587     14202
           P     0.8870    0.7265    0.7987     25017

   micro avg     0.9117    0.9117    0.9117    163566
   macro avg     0.8764    0.8020    0.8350    163566
weighted avg     0.9094    0.9117    0.9085    163566

F1-macro tok:  0.8350371618302906
F1-micro tok:  0.9116625704608539
**************************************************
dev_cost_sum: 42215.74279785156
dev_cost_avg: 38.34309064291695
dev_count_sent: 1101.0
dev_total_correct_sent: 745.0
dev_accuracy_sent: 0.6766575840145322
dev_count_tok: 21274.0
dev_total_correct_tok: 19169.0
dev_accuracy_tok: 0.9010529284572718
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09716599190283401
dev_label=N_precision_sent: 0.6473684210526316
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7394789579158316
dev_label=P_precision_sent: 0.7095516569200779
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7607105538140021
dev_precision_macro_sent: 0.6745289148797919
dev_recall_macro_sent: 0.5781236997516637
dev_f-score_macro_sent: 0.5324518345442226
dev_precision_micro_sent: 0.6766575840145322
dev_recall_micro_sent: 0.6766575840145322
dev_f-score_micro_sent: 0.6766575840145322
dev_label=O_precision_tok: 0.9091223021582734
dev_label=O_recall_tok: 0.9747608762727553
dev_label=O_f-score_tok: 0.9407980941036332
dev_label=N_precision_tok: 0.7973537604456824
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.6954145156392348
dev_label=P_precision_tok: 0.9045879009338206
dev_label=P_recall_tok: 0.6936488169364882
dev_label=P_f-score_tok: 0.7851982378854626
dev_precision_macro_tok: 0.8703546545125921
dev_recall_macro_tok: 0.7616651948105484
dev_f-score_macro_tok: 0.8071369492094437
dev_precision_micro_tok: 0.9010529284572718
dev_recall_micro_tok: 0.9010529284572718
dev_f-score_micro_tok: 0.9010529284572718
dev_time: 2.4767608642578125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0524    0.0972       229
           N     0.6474    0.8621    0.7395       428
           P     0.7096    0.8198    0.7607       444

   micro avg     0.6767    0.6767    0.6767      1101
   macro avg     0.6745    0.5781    0.5325      1101
weighted avg     0.6765    0.6767    0.6144      1101

F1-macro sent:  0.5324518345442226
F1-micro sent:  0.6766575840145322
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9091    0.9748    0.9408     16205
           N     0.7974    0.6166    0.6954      1857
           P     0.9046    0.6936    0.7852      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8704    0.7617    0.8071     21274
weighted avg     0.8987    0.9011    0.8959     21274

F1-macro tok:  0.8071369492094437
F1-micro tok:  0.9010529284572718
**************************************************
Best epoch: 25
**************************************************

EPOCH: 32
Learning rate: 0.656100
train_cost_sum: 297666.7327270508
train_cost_avg: 34.83927115251063
train_count_sent: 8544.0
train_total_correct_sent: 6024.0
train_accuracy_sent: 0.7050561797752809
train_count_tok: 163566.0
train_total_correct_tok: 149192.0
train_accuracy_tok: 0.9121211009623027
train_label=O_precision_sent: 0.4823529411764706
train_label=O_recall_sent: 0.12623152709359606
train_label=O_f-score_sent: 0.2000976085895559
train_label=N_precision_sent: 0.6829268292682927
train_label=N_recall_sent: 0.8459214501510574
train_label=N_f-score_sent: 0.7557354925775978
train_label=P_precision_sent: 0.7511818860413038
train_label=P_recall_sent: 0.8362880886426592
train_label=P_f-score_sent: 0.7914536636518548
train_precision_macro_sent: 0.6388205521620224
train_recall_macro_sent: 0.6028136886291042
train_f-score_macro_sent: 0.5824289216063362
train_precision_micro_sent: 0.7050561797752809
train_recall_micro_sent: 0.7050561797752809
train_f-score_micro_sent: 0.7050561797752809
train_label=O_precision_tok: 0.9247146485510572
train_label=O_recall_tok: 0.9720781361834222
train_label=O_f-score_tok: 0.9478050520851712
train_label=N_precision_tok: 0.8187418936446174
train_label=N_recall_tok: 0.711167441205464
train_label=N_f-score_tok: 0.7611726580752128
train_label=P_precision_tok: 0.8880276884079166
train_label=P_recall_tok: 0.7281848343126673
train_label=P_f-score_tok: 0.8002020601348532
train_precision_macro_tok: 0.8771614102011971
train_recall_macro_tok: 0.8038101372338513
train_f-score_macro_tok: 0.836393256765079
train_precision_micro_tok: 0.9121211009623027
train_recall_micro_tok: 0.9121211009623027
train_f-score_micro_tok: 0.9121211009623028
train_time: 51.314210176467896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4824    0.1262    0.2001      1624
           N     0.6829    0.8459    0.7557      3310
           P     0.7512    0.8363    0.7915      3610

   micro avg     0.7051    0.7051    0.7051      8544
   macro avg     0.6388    0.6028    0.5824      8544
weighted avg     0.6736    0.7051    0.6652      8544

F1-macro sent:  0.5824289216063362
F1-micro sent:  0.7050561797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9247    0.9721    0.9478    124347
           N     0.8187    0.7112    0.7612     14202
           P     0.8880    0.7282    0.8002     25017

   micro avg     0.9121    0.9121    0.9121    163566
   macro avg     0.8772    0.8038    0.8364    163566
weighted avg     0.9099    0.9121    0.9090    163566

F1-macro tok:  0.836393256765079
F1-micro tok:  0.9121211009623028
**************************************************
dev_cost_sum: 42259.935791015625
dev_cost_avg: 38.38322960128576
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.34375
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.0842911877394636
dev_label=N_precision_sent: 0.6628131021194605
dev_label=N_recall_sent: 0.8037383177570093
dev_label=N_f-score_sent: 0.7265047518479408
dev_label=P_precision_sent: 0.6854545454545454
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7585513078470825
dev_precision_macro_sent: 0.5640058825246687
dev_recall_macro_sent: 0.5669574504513083
dev_f-score_macro_sent: 0.523115749144829
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9109975018881078
dev_label=O_recall_tok: 0.9676643011416229
dev_label=O_f-score_tok: 0.9384762702735052
dev_label=N_precision_tok: 0.7877325982081324
dev_label=N_recall_tok: 0.6155088852988692
dev_label=N_f-score_tok: 0.6910519951632407
dev_label=P_precision_tok: 0.8693486590038314
dev_label=P_recall_tok: 0.7064134495641345
dev_label=P_f-score_tok: 0.7794572311920304
dev_precision_macro_tok: 0.8560262530333572
dev_recall_macro_tok: 0.7631955453348755
dev_f-score_macro_tok: 0.8029951655429254
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 2.4690892696380615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3438    0.0480    0.0843       229
           N     0.6628    0.8037    0.7265       428
           P     0.6855    0.8491    0.7586       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.5640    0.5670    0.5231      1101
weighted avg     0.6056    0.6649    0.6059      1101

F1-macro sent:  0.523115749144829
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9110    0.9677    0.9385     16205
           N     0.7877    0.6155    0.6911      1857
           P     0.8693    0.7064    0.7795      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8560    0.7632    0.8030     21274
weighted avg     0.8939    0.8975    0.8929     21274

F1-macro tok:  0.8029951655429254
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 25
**************************************************

test0_cost_sum: 42416.595947265625
test0_cost_avg: 38.525518571540076
test0_count_sent: 1101.0
test0_total_correct_sent: 737.0
test0_accuracy_sent: 0.6693914623069936
test0_count_tok: 21274.0
test0_total_correct_tok: 19176.0
test0_accuracy_tok: 0.9013819686001692
test0_label=O_precision_sent: 0.46153846153846156
test0_label=O_recall_sent: 0.10480349344978165
test0_label=O_f-score_sent: 0.17081850533807827
test0_label=N_precision_sent: 0.7096069868995634
test0_label=N_recall_sent: 0.7593457943925234
test0_label=N_f-score_sent: 0.7336343115124153
test0_label=P_precision_sent: 0.6565143824027073
test0_label=P_recall_sent: 0.8738738738738738
test0_label=P_f-score_sent: 0.7497584541062802
test0_precision_macro_sent: 0.6092199436135775
test0_recall_macro_sent: 0.5793410539053929
test0_f-score_macro_sent: 0.5514037569855913
test0_precision_micro_sent: 0.6693914623069936
test0_recall_micro_sent: 0.6693914623069936
test0_f-score_micro_sent: 0.6693914623069936
test0_label=O_precision_tok: 0.9055558727802204
test0_label=O_recall_tok: 0.9786485652576365
test0_label=O_f-score_tok: 0.9406845008600747
test0_label=N_precision_tok: 0.8057302585604472
test0_label=N_recall_tok: 0.620893914916532
test0_label=N_f-score_tok: 0.7013381995133818
test0_label=P_precision_tok: 0.9287553648068669
test0_label=P_recall_tok: 0.6737235367372354
test0_label=P_f-score_tok: 0.7809455070371707
test0_precision_macro_tok: 0.8800138320491783
test0_recall_macro_tok: 0.757755338970468
test0_f-score_macro_tok: 0.8076560691368758
test0_precision_micro_tok: 0.9013819686001692
test0_recall_micro_tok: 0.9013819686001692
test0_f-score_micro_tok: 0.9013819686001692
test0_time: 2.4581220149993896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.1048    0.1708       229
           N     0.7096    0.7593    0.7336       428
           P     0.6565    0.8739    0.7498       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6092    0.5793    0.5514      1101
weighted avg     0.6366    0.6694    0.6231      1101

F1-macro sent:  0.5514037569855913
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9786    0.9407     16205
           N     0.8057    0.6209    0.7013      1857
           P     0.9288    0.6737    0.7809      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8800    0.7578    0.8077     21274
weighted avg     0.9003    0.9014    0.8957     21274

F1-macro tok:  0.8076560691368758
F1-micro tok:  0.9013819686001692
**************************************************
test1_cost_sum: 82188.7001914978
test1_cost_avg: 37.18945710022525
test1_count_sent: 2210.0
test1_total_correct_sent: 1509.0
test1_accuracy_sent: 0.6828054298642534
test1_count_tok: 42405.0
test1_total_correct_tok: 37902.0
test1_accuracy_tok: 0.893809692253272
test1_label=O_precision_sent: 0.3524590163934426
test1_label=O_recall_sent: 0.11053984575835475
test1_label=O_f-score_sent: 0.16829745596868884
test1_label=N_precision_sent: 0.7252985884907709
test1_label=N_recall_sent: 0.7324561403508771
test1_label=N_f-score_sent: 0.72885979268958
test1_label=P_precision_sent: 0.6838046272493573
test1_label=P_recall_sent: 0.8778877887788779
test1_label=P_f-score_sent: 0.76878612716763
test1_precision_macro_sent: 0.5871874107111902
test1_recall_macro_sent: 0.5736279249627033
test1_f-score_macro_sent: 0.5553144586086329
test1_precision_micro_sent: 0.6828054298642534
test1_recall_micro_sent: 0.6828054298642534
test1_f-score_micro_sent: 0.6828054298642534
test1_label=O_precision_tok: 0.8969207875457875
test1_label=O_recall_tok: 0.9794987186699169
test1_label=O_f-score_tok: 0.9363926981566132
test1_label=N_precision_tok: 0.8078004216444132
test1_label=N_recall_tok: 0.611436170212766
test1_label=N_f-score_tok: 0.6960339085679685
test1_label=P_precision_tok: 0.9232936078006501
test1_label=P_recall_tok: 0.6410410711599218
test1_label=P_f-score_tok: 0.7567039602202096
test1_precision_macro_tok: 0.8760049389969503
test1_recall_macro_tok: 0.7439919866808683
test1_f-score_macro_tok: 0.7963768556482638
test1_precision_micro_tok: 0.893809692253272
test1_recall_micro_tok: 0.893809692253272
test1_f-score_micro_tok: 0.893809692253272
test1_time: 5.063082695007324
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3525    0.1105    0.1683       389
           N     0.7253    0.7325    0.7289       912
           P     0.6838    0.8779    0.7688       909

   micro avg     0.6828    0.6828    0.6828      2210
   macro avg     0.5872    0.5736    0.5553      2210
weighted avg     0.6426    0.6828    0.6466      2210

F1-macro sent:  0.5553144586086329
F1-micro sent:  0.6828054298642534
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8969    0.9795    0.9364     31998
           N     0.8078    0.6114    0.6960      3760
           P     0.9233    0.6410    0.7567      6647

   micro avg     0.8938    0.8938    0.8938     42405
   macro avg     0.8760    0.7440    0.7964     42405
weighted avg     0.8932    0.8938    0.8869     42405

F1-macro tok:  0.7963768556482638
F1-micro tok:  0.893809692253272
**************************************************
