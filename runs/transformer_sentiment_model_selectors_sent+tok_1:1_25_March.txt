to_write_filename: runs/transformer_sentiment_model_selectors_sent+tok_1:1_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:dev_f-score_macro_tok:high
model_selector_ratio: 1:1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 427948.1922607422
train_cost_avg: 50.08756931890709
train_count_sent: 8544.0
train_total_correct_sent: 4244.0
train_accuracy_sent: 0.4967228464419476
train_count_tok: 163566.0
train_total_correct_tok: 126311.0
train_accuracy_tok: 0.772232615580255
train_label=O_precision_sent: 0.16759776536312848
train_label=O_recall_sent: 0.01847290640394089
train_label=O_f-score_sent: 0.03327787021630616
train_label=N_precision_sent: 0.4882802212272847
train_label=N_recall_sent: 0.5601208459214502
train_label=N_f-score_sent: 0.5217391304347826
train_label=P_precision_sent: 0.5166374781085814
train_label=P_recall_sent: 0.6537396121883656
train_label=P_f-score_sent: 0.5771582293959403
train_precision_macro_sent: 0.3908384882329982
train_recall_macro_sent: 0.4107777881712522
train_f-score_macro_sent: 0.3773917433490097
train_precision_micro_sent: 0.4967228464419476
train_recall_micro_sent: 0.4967228464419476
train_f-score_micro_sent: 0.4967228464419476
train_label=O_precision_tok: 0.7988382943618734
train_label=O_recall_tok: 0.9500591087842891
train_label=O_f-score_tok: 0.8679109439340565
train_label=N_precision_tok: 0.5042875989445911
train_label=N_recall_tok: 0.215321785663991
train_label=N_f-score_tok: 0.3017862429685187
train_label=P_precision_tok: 0.5320299500831946
train_label=P_recall_tok: 0.20450093936123437
train_label=P_f-score_tok: 0.2954407645886871
train_precision_macro_tok: 0.6117186144632197
train_recall_macro_tok: 0.45662727793650487
train_f-score_macro_tok: 0.4883793171637541
train_precision_micro_tok: 0.772232615580255
train_recall_micro_tok: 0.772232615580255
train_f-score_micro_tok: 0.772232615580255
train_time: 57.957419633865356
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1676    0.0185    0.0333      1624
           N     0.4883    0.5601    0.5217      3310
           P     0.5166    0.6537    0.5772      3610

   micro avg     0.4967    0.4967    0.4967      8544
   macro avg     0.3908    0.4108    0.3774      8544
weighted avg     0.4393    0.4967    0.4523      8544

F1-macro sent:  0.3773917433490097
F1-micro sent:  0.4967228464419476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7988    0.9501    0.8679    124347
           N     0.5043    0.2153    0.3018     14202
           P     0.5320    0.2045    0.2954     25017

   micro avg     0.7722    0.7722    0.7722    163566
   macro avg     0.6117    0.4566    0.4884    163566
weighted avg     0.7325    0.7722    0.7312    163566

F1-macro tok:  0.4883793171637541
F1-micro tok:  0.772232615580255
**************************************************
dev_cost_sum: 50618.975830078125
dev_cost_avg: 45.975454886537804
dev_count_sent: 1101.0
dev_total_correct_sent: 661.0
dev_accuracy_sent: 0.6003633060853769
dev_count_tok: 21274.0
dev_total_correct_tok: 17527.0
dev_accuracy_tok: 0.8238695120804738
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.582089552238806
dev_label=N_recall_sent: 0.7289719626168224
dev_label=N_f-score_sent: 0.6473029045643154
dev_label=P_precision_sent: 0.6176991150442478
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.6917740336967294
dev_precision_macro_sent: 0.3999295557610179
dev_recall_macro_sent: 0.5050026662176195
dev_f-score_macro_sent: 0.44635897942034825
dev_precision_micro_sent: 0.6003633060853769
dev_recall_micro_sent: 0.6003633060853769
dev_f-score_micro_sent: 0.6003633060853769
dev_label=O_precision_tok: 0.8449939686369119
dev_label=O_recall_tok: 0.9510027769207035
dev_label=O_f-score_tok: 0.8948697848619458
dev_label=N_precision_tok: 0.6592135697764071
dev_label=N_recall_tok: 0.4604200323101777
dev_label=N_f-score_tok: 0.5421686746987951
dev_label=P_precision_tok: 0.7251293847038528
dev_label=P_recall_tok: 0.3925902864259029
dev_label=P_f-score_tok: 0.5093920420117148
dev_precision_macro_tok: 0.7431123077057239
dev_recall_macro_tok: 0.6013376985522614
dev_f-score_macro_tok: 0.6488101671908185
dev_precision_micro_tok: 0.8238695120804738
dev_recall_micro_tok: 0.8238695120804738
dev_f-score_micro_tok: 0.8238695120804738
dev_time: 2.878992795944214
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5821    0.7290    0.6473       428
           P     0.6177    0.7860    0.6918       444

   micro avg     0.6004    0.6004    0.6004      1101
   macro avg     0.3999    0.5050    0.4464      1101
weighted avg     0.4754    0.6004    0.5306      1101

F1-macro sent:  0.44635897942034825
F1-micro sent:  0.6003633060853769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8450    0.9510    0.8949     16205
           N     0.6592    0.4604    0.5422      1857
           P     0.7251    0.3926    0.5094      3212

   micro avg     0.8239    0.8239    0.8239     21274
   macro avg     0.7431    0.6013    0.6488     21274
weighted avg     0.8107    0.8239    0.8059     21274

F1-macro tok:  0.6488101671908185
F1-micro tok:  0.8238695120804738
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378008.0760498047
train_cost_avg: 44.24251826425617
train_count_sent: 8544.0
train_total_correct_sent: 4878.0
train_accuracy_sent: 0.5709269662921348
train_count_tok: 163566.0
train_total_correct_tok: 132444.0
train_accuracy_tok: 0.8097281831187411
train_label=O_precision_sent: 0.17391304347826086
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004857316332726169
train_label=N_precision_sent: 0.5481427174975562
train_label=N_recall_sent: 0.6776435045317221
train_label=N_f-score_sent: 0.6060524182653336
train_label=P_precision_sent: 0.5940392865206593
train_label=P_recall_sent: 0.728808864265928
train_label=P_f-score_sent: 0.6545590247543226
train_precision_macro_sent: 0.4386983491654921
train_recall_macro_sent: 0.4696384743282807
train_f-score_macro_sent: 0.42182291978412745
train_precision_micro_sent: 0.5709269662921348
train_recall_micro_sent: 0.5709269662921348
train_f-score_micro_sent: 0.5709269662921348
train_label=O_precision_tok: 0.8324393952191909
train_label=O_recall_tok: 0.9510724022292456
train_label=O_f-score_tok: 0.8878103710376668
train_label=N_precision_tok: 0.63933845245127
train_label=N_recall_tok: 0.3810730882974229
train_label=N_f-score_tok: 0.47752238937662683
train_label=P_precision_tok: 0.6728305071740965
train_label=P_recall_tok: 0.35052164528120877
train_label=P_f-score_tok: 0.4609198423127464
train_precision_macro_tok: 0.7148694516148524
train_recall_macro_tok: 0.5608890452692924
train_f-score_macro_tok: 0.60875086757568
train_precision_micro_tok: 0.8097281831187411
train_recall_micro_tok: 0.8097281831187411
train_f-score_micro_tok: 0.8097281831187412
train_time: 82.14955019950867
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1739    0.0025    0.0049      1624
           N     0.5481    0.6776    0.6061      3310
           P     0.5940    0.7288    0.6546      3610

   micro avg     0.5709    0.5709    0.5709      8544
   macro avg     0.4387    0.4696    0.4218      8544
weighted avg     0.4964    0.5709    0.5123      8544

F1-macro sent:  0.42182291978412745
F1-micro sent:  0.5709269662921348
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8324    0.9511    0.8878    124347
           N     0.6393    0.3811    0.4775     14202
           P     0.6728    0.3505    0.4609     25017

   micro avg     0.8097    0.8097    0.8097    163566
   macro avg     0.7149    0.5609    0.6088    163566
weighted avg     0.7913    0.8097    0.7869    163566

F1-macro tok:  0.60875086757568
F1-micro tok:  0.8097281831187412
**************************************************
dev_cost_sum: 49029.134521484375
dev_cost_avg: 44.53145733104848
dev_count_sent: 1101.0
dev_total_correct_sent: 603.0
dev_accuracy_sent: 0.547683923705722
dev_count_tok: 21274.0
dev_total_correct_tok: 17805.0
dev_accuracy_tok: 0.8369371063269719
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4738636363636364
dev_label=N_recall_sent: 0.9742990654205608
dev_label=N_f-score_sent: 0.6376146788990825
dev_label=P_precision_sent: 0.8416289592760181
dev_label=P_recall_sent: 0.4189189189189189
dev_label=P_f-score_sent: 0.5593984962406015
dev_precision_macro_sent: 0.43849753187988477
dev_recall_macro_sent: 0.4644059947798265
dev_f-score_macro_sent: 0.399004391713228
dev_precision_micro_sent: 0.547683923705722
dev_recall_micro_sent: 0.547683923705722
dev_f-score_micro_sent: 0.547683923705722
dev_label=O_precision_tok: 0.8469316031359827
dev_label=O_recall_tok: 0.9666152422091947
dev_label=O_f-score_tok: 0.9028242074927952
dev_label=N_precision_tok: 0.7025117739403454
dev_label=N_recall_tok: 0.4819601507808293
dev_label=N_f-score_tok: 0.571702331523475
dev_label=P_precision_tok: 0.827906976744186
dev_label=P_recall_tok: 0.387920298879203
dev_label=P_f-score_tok: 0.5283018867924528
dev_precision_macro_tok: 0.7924501179401714
dev_recall_macro_tok: 0.6121652306230757
dev_f-score_macro_tok: 0.6676094752695744
dev_precision_micro_tok: 0.8369371063269719
dev_recall_micro_tok: 0.8369371063269719
dev_f-score_micro_tok: 0.8369371063269719
dev_time: 5.238949775695801
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4739    0.9743    0.6376       428
           P     0.8416    0.4189    0.5594       444

   micro avg     0.5477    0.5477    0.5477      1101
   macro avg     0.4385    0.4644    0.3990      1101
weighted avg     0.5236    0.5477    0.4735      1101

F1-macro sent:  0.399004391713228
F1-micro sent:  0.547683923705722
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8469    0.9666    0.9028     16205
           N     0.7025    0.4820    0.5717      1857
           P     0.8279    0.3879    0.5283      3212

   micro avg     0.8369    0.8369    0.8369     21274
   macro avg     0.7925    0.6122    0.6676     21274
weighted avg     0.8315    0.8369    0.8174     21274

F1-macro tok:  0.6676094752695744
F1-micro tok:  0.8369371063269719
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368260.31103515625
train_cost_avg: 43.10162816422709
train_count_sent: 8544.0
train_total_correct_sent: 5009.0
train_accuracy_sent: 0.5862593632958801
train_count_tok: 163566.0
train_total_correct_tok: 135545.0
train_accuracy_tok: 0.8286868909186506
train_label=O_precision_sent: 0.14285714285714285
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.001226241569589209
train_label=N_precision_sent: 0.5562074630368458
train_label=N_recall_sent: 0.716012084592145
train_label=N_f-score_sent: 0.6260731739532427
train_label=P_precision_sent: 0.616931711880262
train_label=P_recall_sent: 0.7307479224376732
train_label=P_f-score_sent: 0.6690337306619325
train_precision_macro_sent: 0.43866543925808354
train_recall_macro_sent: 0.48245859019220544
train_f-score_macro_sent: 0.43211104872825484
train_precision_micro_sent: 0.5862593632958801
train_recall_micro_sent: 0.5862593632958801
train_f-score_micro_sent: 0.5862593632958801
train_label=O_precision_tok: 0.8488953775468578
train_label=O_recall_tok: 0.9539192742888851
train_label=O_f-score_tok: 0.8983482153000251
train_label=N_precision_tok: 0.6752400927254664
train_label=N_recall_tok: 0.4307139839459231
train_label=N_f-score_tok: 0.5259447143287047
train_label=P_precision_tok: 0.7316594477531132
train_label=P_recall_tok: 0.43214614062437545
train_label=P_f-score_tok: 0.5433618978212249
train_precision_macro_tok: 0.7519316393418124
train_recall_macro_tok: 0.6055931329530612
train_f-score_macro_tok: 0.6558849424833183
train_precision_micro_tok: 0.8286868909186506
train_recall_micro_tok: 0.8286868909186506
train_f-score_micro_tok: 0.8286868909186506
train_time: 94.19191122055054
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1429    0.0006    0.0012      1624
           N     0.5562    0.7160    0.6261      3310
           P     0.6169    0.7307    0.6690      3610

   micro avg     0.5863    0.5863    0.5863      8544
   macro avg     0.4387    0.4825    0.4321      8544
weighted avg     0.5033    0.5863    0.5255      8544

F1-macro sent:  0.43211104872825484
F1-micro sent:  0.5862593632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8489    0.9539    0.8983    124347
           N     0.6752    0.4307    0.5259     14202
           P     0.7317    0.4321    0.5434     25017

   micro avg     0.8287    0.8287    0.8287    163566
   macro avg     0.7519    0.6056    0.6559    163566
weighted avg     0.8159    0.8287    0.8117    163566

F1-macro tok:  0.6558849424833183
F1-micro tok:  0.8286868909186506
**************************************************
dev_cost_sum: 48058.08923339844
dev_cost_avg: 43.64949067520294
dev_count_sent: 1101.0
dev_total_correct_sent: 675.0
dev_accuracy_sent: 0.6130790190735694
dev_count_tok: 21274.0
dev_total_correct_tok: 18241.0
dev_accuracy_tok: 0.857431606656012
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6011029411764706
dev_label=N_recall_sent: 0.764018691588785
dev_label=N_f-score_sent: 0.6728395061728395
dev_label=P_precision_sent: 0.6247755834829444
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.6953046953046953
dev_precision_macro_sent: 0.4086261748864716
dev_recall_macro_sent: 0.5159341584575229
dev_f-score_macro_sent: 0.4560480671591782
dev_precision_micro_sent: 0.6130790190735694
dev_recall_micro_sent: 0.6130790190735694
dev_f-score_micro_sent: 0.6130790190735694
dev_label=O_precision_tok: 0.8676054776293175
dev_label=O_recall_tok: 0.9656896019746992
dev_label=O_f-score_tok: 0.9140237135681327
dev_label=N_precision_tok: 0.7344434706397897
dev_label=N_recall_tok: 0.45126548196015076
dev_label=N_f-score_tok: 0.5590393595730486
dev_label=P_precision_tok: 0.8368320610687023
dev_label=P_recall_tok: 0.5460772104607721
dev_label=P_f-score_tok: 0.6608892238131123
dev_precision_macro_tok: 0.8129603364459365
dev_recall_macro_tok: 0.654344098131874
dev_f-score_macro_tok: 0.711317432318098
dev_precision_micro_tok: 0.857431606656012
dev_recall_micro_tok: 0.857431606656012
dev_f-score_micro_tok: 0.857431606656012
dev_time: 5.134106159210205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6011    0.7640    0.6728       428
           P     0.6248    0.7838    0.6953       444

   micro avg     0.6131    0.6131    0.6131      1101
   macro avg     0.4086    0.5159    0.4560      1101
weighted avg     0.4856    0.6131    0.5420      1101

F1-macro sent:  0.4560480671591782
F1-micro sent:  0.6130790190735694
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8676    0.9657    0.9140     16205
           N     0.7344    0.4513    0.5590      1857
           P     0.8368    0.5461    0.6609      3212

   micro avg     0.8574    0.8574    0.8574     21274
   macro avg     0.8130    0.6543    0.7113     21274
weighted avg     0.8513    0.8574    0.8448     21274

F1-macro tok:  0.711317432318098
F1-micro tok:  0.857431606656012
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361268.7833251953
train_cost_avg: 42.28333138169421
train_count_sent: 8544.0
train_total_correct_sent: 5110.0
train_accuracy_sent: 0.5980805243445693
train_count_tok: 163566.0
train_total_correct_tok: 137874.0
train_accuracy_tok: 0.8429257914236455
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.0024554941682013508
train_label=N_precision_sent: 0.5720348974298515
train_label=N_recall_sent: 0.7329305135951661
train_label=N_f-score_sent: 0.6425638988213481
train_label=P_precision_sent: 0.6240111679851094
train_label=P_recall_sent: 0.7429362880886426
train_label=P_f-score_sent: 0.6783004552352049
train_precision_macro_sent: 0.5320153551383203
train_recall_macro_sent: 0.4923661095924683
train_f-score_macro_sent: 0.44110661607491813
train_precision_micro_sent: 0.5980805243445693
train_recall_micro_sent: 0.5980805243445693
train_f-score_micro_sent: 0.5980805243445693
train_label=O_precision_tok: 0.8609363474638781
train_label=O_recall_tok: 0.9574175492774253
train_label=O_f-score_tok: 0.9066173194887083
train_label=N_precision_tok: 0.6958199356913183
train_label=N_recall_tok: 0.45711871567384876
train_label=N_f-score_tok: 0.5517593064762877
train_label=P_precision_tok: 0.7728469349379467
train_label=P_recall_tok: 0.4928648519007075
train_label=P_f-score_tok: 0.6018891410998023
train_precision_macro_tok: 0.7765344060310477
train_recall_macro_tok: 0.6358003722839939
train_f-score_macro_tok: 0.686755255688266
train_precision_micro_tok: 0.8429257914236455
train_recall_micro_tok: 0.8429257914236455
train_f-score_micro_tok: 0.8429257914236455
train_time: 94.77504706382751
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0012    0.0025      1624
           N     0.5720    0.7329    0.6426      3310
           P     0.6240    0.7429    0.6783      3610

   micro avg     0.5981    0.5981    0.5981      8544
   macro avg     0.5320    0.4924    0.4411      8544
weighted avg     0.5613    0.5981    0.5360      8544

F1-macro sent:  0.44110661607491813
F1-micro sent:  0.5980805243445693
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8609    0.9574    0.9066    124347
           N     0.6958    0.4571    0.5518     14202
           P     0.7728    0.4929    0.6019     25017

   micro avg     0.8429    0.8429    0.8429    163566
   macro avg     0.7765    0.6358    0.6868    163566
weighted avg     0.8331    0.8429    0.8292    163566

F1-macro tok:  0.686755255688266
F1-micro tok:  0.8429257914236455
**************************************************
dev_cost_sum: 47390.153259277344
dev_cost_avg: 43.04282766510204
dev_count_sent: 1101.0
dev_total_correct_sent: 652.0
dev_accuracy_sent: 0.592188919164396
dev_count_tok: 21274.0
dev_total_correct_tok: 18386.0
dev_accuracy_tok: 0.8642474381874589
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6615384615384615
dev_label=N_recall_sent: 0.602803738317757
dev_label=N_f-score_sent: 0.6308068459657702
dev_label=P_precision_sent: 0.5541490857946554
dev_label=P_recall_sent: 0.8873873873873874
dev_label=P_f-score_sent: 0.6822510822510822
dev_precision_macro_sent: 0.40522918244437234
dev_recall_macro_sent: 0.4967303752350481
dev_f-score_macro_sent: 0.43768597607228416
dev_precision_micro_sent: 0.592188919164396
dev_recall_micro_sent: 0.592188919164396
dev_f-score_micro_sent: 0.592188919164396
dev_label=O_precision_tok: 0.8710176991150442
dev_label=O_recall_tok: 0.9717988275223697
dev_label=O_f-score_tok: 0.9186524719264985
dev_label=N_precision_tok: 0.7824427480916031
dev_label=N_recall_tok: 0.44157242864835755
dev_label=N_f-score_tok: 0.5645438898450947
dev_label=P_precision_tok: 0.8471575023299162
dev_label=P_recall_tok: 0.566002490660025
dev_label=P_f-score_tok: 0.6786114221724524
dev_precision_macro_tok: 0.8335393165121877
dev_recall_macro_tok: 0.6597912489435841
dev_f-score_macro_tok: 0.7206025946480151
dev_precision_micro_tok: 0.8642474381874589
dev_recall_micro_tok: 0.8642474381874589
dev_f-score_micro_tok: 0.8642474381874589
dev_time: 5.332194089889526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6615    0.6028    0.6308       428
           P     0.5541    0.8874    0.6823       444

   micro avg     0.5922    0.5922    0.5922      1101
   macro avg     0.4052    0.4967    0.4377      1101
weighted avg     0.4806    0.5922    0.5203      1101

F1-macro sent:  0.43768597607228416
F1-micro sent:  0.592188919164396
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8710    0.9718    0.9187     16205
           N     0.7824    0.4416    0.5645      1857
           P     0.8472    0.5660    0.6786      3212

   micro avg     0.8642    0.8642    0.8642     21274
   macro avg     0.8335    0.6598    0.7206     21274
weighted avg     0.8597    0.8642    0.8515     21274

F1-macro tok:  0.7206025946480151
F1-micro tok:  0.8642474381874589
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355486.6424560547
train_cost_avg: 41.606582684463326
train_count_sent: 8544.0
train_total_correct_sent: 5225.0
train_accuracy_sent: 0.6115402621722846
train_count_tok: 163566.0
train_total_correct_tok: 139252.0
train_accuracy_tok: 0.8513505251702677
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002452483139178418
train_label=N_precision_sent: 0.5841420118343196
train_label=N_recall_sent: 0.7456193353474321
train_label=N_f-score_sent: 0.6550763105507631
train_label=P_precision_sent: 0.6389146567717996
train_label=P_recall_sent: 0.7631578947368421
train_label=P_f-score_sent: 0.6955314314567028
train_precision_macro_sent: 0.502923651440135
train_recall_macro_sent: 0.5033362523926234
train_f-score_macro_sent: 0.4510200750488815
train_precision_micro_sent: 0.6115402621722846
train_recall_micro_sent: 0.6115402621722846
train_f-score_micro_sent: 0.6115402621722846
train_label=O_precision_tok: 0.8674073267254838
train_label=O_recall_tok: 0.9606584798989923
train_label=O_f-score_tok: 0.9116544939747083
train_label=N_precision_tok: 0.7065710368104631
train_label=N_recall_tok: 0.4716941275876637
train_label=N_f-score_tok: 0.5657222480260102
train_label=P_precision_tok: 0.800122174709835
train_label=P_recall_tok: 0.5235639764959827
train_label=P_f-score_tok: 0.6329523763500616
train_precision_macro_tok: 0.7913668460819273
train_recall_macro_tok: 0.6519721946608795
train_f-score_macro_tok: 0.7034430394502601
train_precision_micro_tok: 0.8513505251702677
train_recall_micro_tok: 0.8513505251702677
train_f-score_micro_tok: 0.8513505251702677
train_time: 94.15485835075378
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0012    0.0025      1624
           N     0.5841    0.7456    0.6551      3310
           P     0.6389    0.7632    0.6955      3610

   micro avg     0.6115    0.6115    0.6115      8544
   macro avg     0.5029    0.5033    0.4510      8544
weighted avg     0.5506    0.6115    0.5481      8544

F1-macro sent:  0.4510200750488815
F1-micro sent:  0.6115402621722846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8674    0.9607    0.9117    124347
           N     0.7066    0.4717    0.5657     14202
           P     0.8001    0.5236    0.6330     25017

   micro avg     0.8514    0.8514    0.8514    163566
   macro avg     0.7914    0.6520    0.7034    163566
weighted avg     0.8432    0.8514    0.8390    163566

F1-macro tok:  0.7034430394502601
F1-micro tok:  0.8513505251702677
**************************************************
dev_cost_sum: 46726.52331542969
dev_cost_avg: 42.44007567250653
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18505.0
dev_accuracy_tok: 0.8698411206167153
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5831987075928917
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.6895893027698184
dev_label=P_precision_sent: 0.6763485477178424
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7041036717062635
dev_precision_macro_sent: 0.41984908510357805
dev_recall_macro_sent: 0.5258973927198226
dev_f-score_macro_sent: 0.46456432482536064
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8781782620843811
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.9217008797653959
dev_label=N_precision_tok: 0.7392290249433107
dev_label=N_recall_tok: 0.5266558966074314
dev_label=N_f-score_tok: 0.6150943396226415
dev_label=P_precision_tok: 0.8813229571984436
dev_label=P_recall_tok: 0.564134495641345
dev_label=P_f-score_tok: 0.6879271070615034
dev_precision_macro_tok: 0.8329100814087118
dev_recall_macro_tok: 0.6868509370850853
dev_f-score_macro_tok: 0.7415741088165136
dev_precision_micro_tok: 0.8698411206167153
dev_recall_micro_tok: 0.8698411206167153
dev_f-score_micro_tok: 0.8698411206167153
dev_time: 5.009511470794678
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5832    0.8435    0.6896       428
           P     0.6763    0.7342    0.7041       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4198    0.5259    0.4646      1101
weighted avg     0.4995    0.6240    0.5520      1101

F1-macro sent:  0.46456432482536064
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8782    0.9698    0.9217     16205
           N     0.7392    0.5267    0.6151      1857
           P     0.8813    0.5641    0.6879      3212

   micro avg     0.8698    0.8698    0.8698     21274
   macro avg     0.8329    0.6869    0.7416     21274
weighted avg     0.8665    0.8698    0.8596     21274

F1-macro tok:  0.7415741088165136
F1-micro tok:  0.8698411206167153
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350945.42138671875
train_cost_avg: 41.0750727278463
train_count_sent: 8544.0
train_total_correct_sent: 5331.0
train_accuracy_sent: 0.6239466292134831
train_count_tok: 163566.0
train_total_correct_tok: 140291.0
train_accuracy_tok: 0.8577027010503405
train_label=O_precision_sent: 0.46153846153846156
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007330482590103848
train_label=N_precision_sent: 0.5998554565165021
train_label=N_recall_sent: 0.7522658610271903
train_label=N_f-score_sent: 0.667470848411741
train_label=P_precision_sent: 0.6472602739726028
train_label=P_recall_sent: 0.7853185595567868
train_label=P_f-score_sent: 0.7096370463078849
train_precision_macro_sent: 0.5695513973425221
train_recall_macro_sent: 0.5137596672882551
train_f-score_macro_sent: 0.46147945910324323
train_precision_micro_sent: 0.6239466292134831
train_recall_micro_sent: 0.6239466292134831
train_f-score_micro_sent: 0.6239466292134831
train_label=O_precision_tok: 0.8719572559981364
train_label=O_recall_tok: 0.96332038569487
train_label=O_f-score_tok: 0.9153647176595102
train_label=N_precision_tok: 0.7206917978458989
train_label=N_recall_tok: 0.4900014082523588
train_label=N_f-score_tok: 0.583368262218124
train_label=P_precision_tok: 0.8192814805854602
train_label=P_recall_tok: 0.54147179917656
train_label=P_f-score_tok: 0.6520180019734785
train_precision_macro_tok: 0.8039768448098318
train_recall_macro_tok: 0.6649311977079296
train_f-score_macro_tok: 0.7169169939503709
train_precision_micro_tok: 0.8577027010503405
train_recall_micro_tok: 0.8577027010503405
train_f-score_micro_tok: 0.8577027010503405
train_time: 95.43559861183167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4615    0.0037    0.0073      1624
           N     0.5999    0.7523    0.6675      3310
           P     0.6473    0.7853    0.7096      3610

   micro avg     0.6239    0.6239    0.6239      8544
   macro avg     0.5696    0.5138    0.4615      8544
weighted avg     0.5936    0.6239    0.5598      8544

F1-macro sent:  0.46147945910324323
F1-micro sent:  0.6239466292134831
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8720    0.9633    0.9154    124347
           N     0.7207    0.4900    0.5834     14202
           P     0.8193    0.5415    0.6520     25017

   micro avg     0.8577    0.8577    0.8577    163566
   macro avg     0.8040    0.6649    0.7169    163566
weighted avg     0.8508    0.8577    0.8463    163566

F1-macro tok:  0.7169169939503709
F1-micro tok:  0.8577027010503405
**************************************************
dev_cost_sum: 46310.65930175781
dev_cost_avg: 42.06236085536586
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 18609.0
dev_accuracy_tok: 0.8747297170254771
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6405622489959839
dev_label=N_recall_sent: 0.7453271028037384
dev_label=N_f-score_sent: 0.6889848812095032
dev_label=P_precision_sent: 0.6185737976782753
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7125119388729704
dev_precision_macro_sent: 0.4197120155580864
dev_recall_macro_sent: 0.5284723976312762
dev_f-score_macro_sent: 0.46716560669415785
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.8753099344316492
dev_label=O_recall_tok: 0.9803147176797284
dev_label=O_f-score_tok: 0.9248413576293881
dev_label=N_precision_tok: 0.8145161290322581
dev_label=N_recall_tok: 0.4894991922455573
dev_label=N_f-score_tok: 0.6115035317860746
dev_label=P_precision_tok: 0.9029367844698856
dev_label=P_recall_tok: 0.5647571606475716
dev_label=P_f-score_tok: 0.6948860371576325
dev_precision_macro_tok: 0.8642542826445977
dev_recall_macro_tok: 0.6781903568576192
dev_f-score_macro_tok: 0.7437436421910317
dev_precision_micro_tok: 0.8747297170254771
dev_recall_micro_tok: 0.8747297170254771
dev_f-score_micro_tok: 0.8747297170254771
dev_time: 5.068422794342041
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6406    0.7453    0.6890       428
           P     0.6186    0.8401    0.7125       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.4197    0.5285    0.4672      1101
weighted avg     0.4985    0.6285    0.5552      1101

F1-macro sent:  0.46716560669415785
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8753    0.9803    0.9248     16205
           N     0.8145    0.4895    0.6115      1857
           P     0.9029    0.5648    0.6949      3212

   micro avg     0.8747    0.8747    0.8747     21274
   macro avg     0.8643    0.6782    0.7437     21274
weighted avg     0.8742    0.8747    0.8628     21274

F1-macro tok:  0.7437436421910317
F1-micro tok:  0.8747297170254771
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346830.87548828125
train_cost_avg: 40.59350134460221
train_count_sent: 8544.0
train_total_correct_sent: 5315.0
train_accuracy_sent: 0.6220739700374532
train_count_tok: 163566.0
train_total_correct_tok: 141138.0
train_accuracy_tok: 0.8628810388467041
train_label=O_precision_sent: 0.2692307692307692
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008484848484848486
train_label=N_precision_sent: 0.5930394431554524
train_label=N_recall_sent: 0.7722054380664652
train_label=N_f-score_sent: 0.6708661417322834
train_label=P_precision_sent: 0.6539923954372624
train_label=P_recall_sent: 0.7623268698060942
train_label=P_f-score_sent: 0.7040163724737785
train_precision_macro_sent: 0.5054208692744947
train_recall_macro_sent: 0.5129475509000486
train_f-score_macro_sent: 0.46112245423030346
train_precision_micro_sent: 0.6220739700374532
train_recall_micro_sent: 0.6220739700374532
train_f-score_micro_sent: 0.6220739700374532
train_label=O_precision_tok: 0.8758328285887341
train_label=O_recall_tok: 0.9651861323554247
train_label=O_f-score_tok: 0.9183411125564312
train_label=N_precision_tok: 0.7325255357500501
train_label=N_recall_tok: 0.5150683002394029
train_label=N_f-score_tok: 0.6048453778733256
train_label=P_precision_tok: 0.8342902036622952
train_label=P_recall_tok: 0.5518247591637686
train_label=P_f-score_tok: 0.664276777980945
train_precision_macro_tok: 0.8142161893336931
train_recall_macro_tok: 0.6773597305861987
train_f-score_macro_tok: 0.7291544228035672
train_precision_micro_tok: 0.8628810388467041
train_recall_micro_tok: 0.8628810388467041
train_f-score_micro_tok: 0.8628810388467041
train_time: 94.51562738418579
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2692    0.0043    0.0085      1624
           N     0.5930    0.7722    0.6709      3310
           P     0.6540    0.7623    0.7040      3610

   micro avg     0.6221    0.6221    0.6221      8544
   macro avg     0.5054    0.5129    0.4611      8544
weighted avg     0.5572    0.6221    0.5590      8544

F1-macro sent:  0.46112245423030346
F1-micro sent:  0.6220739700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8758    0.9652    0.9183    124347
           N     0.7325    0.5151    0.6048     14202
           P     0.8343    0.5518    0.6643     25017

   micro avg     0.8629    0.8629    0.8629    163566
   macro avg     0.8142    0.6774    0.7292    163566
weighted avg     0.8570    0.8629    0.8523    163566

F1-macro tok:  0.7291544228035672
F1-micro tok:  0.8628810388467041
**************************************************
dev_cost_sum: 45891.03137207031
dev_cost_avg: 41.68122740424188
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18691.0
dev_accuracy_tok: 0.8785841872708471
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6342857142857142
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.6988457502623295
dev_label=P_precision_sent: 0.6381118881118881
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7185039370078741
dev_precision_macro_sent: 0.6741325341325343
dev_recall_macro_sent: 0.5377366306436216
dev_f-score_macro_sent: 0.48103358674385904
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8805572514847089
dev_label=O_recall_tok: 0.9790188213514347
dev_label=O_f-score_tok: 0.9271813453334113
dev_label=N_precision_tok: 0.8347826086956521
dev_label=N_recall_tok: 0.46526655896607433
dev_label=N_f-score_tok: 0.5975103734439834
dev_label=P_precision_tok: 0.882988298829883
dev_label=P_recall_tok: 0.6108343711083437
dev_label=P_f-score_tok: 0.72211998527788
dev_precision_macro_tok: 0.8661093863367478
dev_recall_macro_tok: 0.6850399171419509
dev_f-score_macro_tok: 0.7489372346850915
dev_precision_micro_tok: 0.8785841872708471
dev_recall_micro_tok: 0.8785841872708471
dev_f-score_micro_tok: 0.8785841872708472
dev_time: 5.024611234664917
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6343    0.7780    0.6988       428
           P     0.6381    0.8221    0.7185       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.6741    0.5377    0.4810      1101
weighted avg     0.6599    0.6367    0.5668      1101

F1-macro sent:  0.48103358674385904
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9790    0.9272     16205
           N     0.8348    0.4653    0.5975      1857
           P     0.8830    0.6108    0.7221      3212

   micro avg     0.8786    0.8786    0.8786     21274
   macro avg     0.8661    0.6850    0.7489     21274
weighted avg     0.8769    0.8786    0.8674     21274

F1-macro tok:  0.7489372346850915
F1-micro tok:  0.8785841872708472
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342893.64080810547
train_cost_avg: 40.132682678851296
train_count_sent: 8544.0
train_total_correct_sent: 5403.0
train_accuracy_sent: 0.632373595505618
train_count_tok: 163566.0
train_total_correct_tok: 141771.0
train_accuracy_tok: 0.8667510362789332
train_label=O_precision_sent: 0.5217391304347826
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014571948998178505
train_label=N_precision_sent: 0.5995845834294946
train_label=N_recall_sent: 0.7848942598187311
train_label=N_f-score_sent: 0.6798377600418685
train_label=P_precision_sent: 0.6669054441260746
train_label=P_recall_sent: 0.7736842105263158
train_label=P_f-score_sent: 0.7163375224416518
train_precision_macro_sent: 0.5960763859967839
train_recall_macro_sent: 0.5219892109688744
train_f-score_macro_sent: 0.4702490771605663
train_precision_micro_sent: 0.632373595505618
train_recall_micro_sent: 0.632373595505618
train_f-score_micro_sent: 0.632373595505618
train_label=O_precision_tok: 0.8793397379145844
train_label=O_recall_tok: 0.9665050222361617
train_label=O_f-score_tok: 0.9208643015860853
train_label=N_precision_tok: 0.7395408923780185
train_label=N_recall_tok: 0.524010702717927
train_label=N_f-score_tok: 0.6133937770451267
train_label=P_precision_tok: 0.84058229352347
train_label=P_recall_tok: 0.5654954630851021
train_label=P_f-score_tok: 0.6761297106124693
train_precision_macro_tok: 0.8198209746053576
train_recall_macro_tok: 0.6853370626797304
train_f-score_macro_tok: 0.7367959297478938
train_precision_micro_tok: 0.8667510362789332
train_recall_micro_tok: 0.8667510362789332
train_f-score_micro_tok: 0.8667510362789332
train_time: 95.05854964256287
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5217    0.0074    0.0146      1624
           N     0.5996    0.7849    0.6798      3310
           P     0.6669    0.7737    0.7163      3610

   micro avg     0.6324    0.6324    0.6324      8544
   macro avg     0.5961    0.5220    0.4702      8544
weighted avg     0.6132    0.6324    0.5688      8544

F1-macro sent:  0.4702490771605663
F1-micro sent:  0.632373595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8793    0.9665    0.9209    124347
           N     0.7395    0.5240    0.6134     14202
           P     0.8406    0.5655    0.6761     25017

   micro avg     0.8668    0.8668    0.8668    163566
   macro avg     0.8198    0.6853    0.7368    163566
weighted avg     0.8613    0.8668    0.8567    163566

F1-macro tok:  0.7367959297478938
F1-micro tok:  0.8667510362789332
**************************************************
dev_cost_sum: 45390.337890625
dev_cost_avg: 41.226464932447776
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18773.0
dev_accuracy_tok: 0.882438657516217
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5705794947994056
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.6975476839237058
dev_label=P_precision_sent: 0.7206572769953051
dev_label=P_recall_sent: 0.6914414414414415
dev_label=P_f-score_sent: 0.7057471264367816
dev_precision_macro_sent: 0.763745590598237
dev_recall_macro_sent: 0.532457109192611
dev_f-score_macro_sent: 0.4735369425588349
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8935722411831627
dev_label=O_recall_tok: 0.9693921629126813
dev_label=O_f-score_tok: 0.9299393221844013
dev_label=N_precision_tok: 0.7257636122177955
dev_label=N_recall_tok: 0.5885837372105547
dev_label=N_f-score_tok: 0.6500148676776687
dev_label=P_precision_tok: 0.9008226691042047
dev_label=P_recall_tok: 0.6136363636363636
dev_label=P_f-score_tok: 0.73
dev_precision_macro_tok: 0.8400528408350544
dev_recall_macro_tok: 0.7238707545865332
dev_f-score_macro_tok: 0.7699847299540233
dev_precision_micro_tok: 0.882438657516217
dev_recall_micro_tok: 0.882438657516217
dev_f-score_micro_tok: 0.882438657516217
dev_time: 5.303014039993286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5706    0.8972    0.6975       428
           P     0.7207    0.6914    0.7057       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.7637    0.5325    0.4735      1101
weighted avg     0.7204    0.6294    0.5594      1101

F1-macro sent:  0.4735369425588349
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8936    0.9694    0.9299     16205
           N     0.7258    0.5886    0.6500      1857
           P     0.9008    0.6136    0.7300      3212

   micro avg     0.8824    0.8824    0.8824     21274
   macro avg     0.8401    0.7239    0.7700     21274
weighted avg     0.8800    0.8824    0.8753     21274

F1-macro tok:  0.7699847299540233
F1-micro tok:  0.882438657516217
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339361.06787109375
train_cost_avg: 39.71922610850817
train_count_sent: 8544.0
train_total_correct_sent: 5371.0
train_accuracy_sent: 0.6286282771535581
train_count_tok: 163566.0
train_total_correct_tok: 142518.0
train_accuracy_tok: 0.8713180000733649
train_label=O_precision_sent: 0.3611111111111111
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.01566265060240964
train_label=N_precision_sent: 0.5856857079350967
train_label=N_recall_sent: 0.7960725075528701
train_label=N_f-score_sent: 0.6748623383275708
train_label=P_precision_sent: 0.6792217510601147
train_label=P_recall_sent: 0.7542936288088643
train_label=P_f-score_sent: 0.7147919674497965
train_precision_macro_sent: 0.5420061900354408
train_recall_macro_sent: 0.5194570208233696
train_f-score_macro_sent: 0.4684389854599256
train_precision_micro_sent: 0.6286282771535581
train_recall_micro_sent: 0.6286282771535581
train_f-score_micro_sent: 0.6286282771535581
train_label=O_precision_tok: 0.8825055515247455
train_label=O_recall_tok: 0.9683948949311202
train_label=O_f-score_tok: 0.9234574149910274
train_label=N_precision_tok: 0.7513050329951738
train_label=N_recall_tok: 0.5371074496549781
train_label=N_f-score_tok: 0.6264011496612605
train_label=P_precision_tok: 0.8531596321622259
train_label=P_recall_tok: 0.5785266019107007
train_label=P_f-score_tok: 0.6895023939401157
train_precision_macro_tok: 0.8289900722273819
train_recall_macro_tok: 0.694676315498933
train_f-score_macro_tok: 0.7464536528641346
train_precision_micro_tok: 0.8713180000733649
train_recall_micro_tok: 0.8713180000733649
train_f-score_micro_tok: 0.8713180000733649
train_time: 140.62315249443054
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3611    0.0080    0.0157      1624
           N     0.5857    0.7961    0.6749      3310
           P     0.6792    0.7543    0.7148      3610

   micro avg     0.6286    0.6286    0.6286      8544
   macro avg     0.5420    0.5195    0.4684      8544
weighted avg     0.5825    0.6286    0.5664      8544

F1-macro sent:  0.4684389854599256
F1-micro sent:  0.6286282771535581
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8825    0.9684    0.9235    124347
           N     0.7513    0.5371    0.6264     14202
           P     0.8532    0.5785    0.6895     25017

   micro avg     0.8713    0.8713    0.8713    163566
   macro avg     0.8290    0.6947    0.7465    163566
weighted avg     0.8666    0.8713    0.8619    163566

F1-macro tok:  0.7464536528641346
F1-micro tok:  0.8713180000733649
**************************************************
dev_cost_sum: 45051.963623046875
dev_cost_avg: 40.91913135608254
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18832.0
dev_accuracy_tok: 0.8852119958634953
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6223021582733813
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7032520325203253
dev_label=P_precision_sent: 0.6549815498154982
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.7200811359026369
dev_precision_macro_sent: 0.6479834582518488
dev_recall_macro_sent: 0.5388981296523231
dev_f-score_macro_sent: 0.4801915159111023
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8884033613445378
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.9313169872265453
dev_label=N_precision_tok: 0.7817490494296578
dev_label=N_recall_tok: 0.5535810446957459
dev_label=N_f-score_tok: 0.648171500630517
dev_label=P_precision_tok: 0.9227121858700806
dev_label=P_recall_tok: 0.6058530510585305
dev_label=P_f-score_tok: 0.7314414583724863
dev_precision_macro_tok: 0.8642881988814254
dev_recall_macro_tok: 0.7126736505543155
dev_f-score_macro_tok: 0.7703099820765162
dev_precision_micro_tok: 0.8852119958634953
dev_recall_micro_tok: 0.8852119958634953
dev_f-score_micro_tok: 0.8852119958634953
dev_time: 8.274188995361328
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6223    0.8084    0.7033       428
           P     0.6550    0.7995    0.7201       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.6480    0.5389    0.4802      1101
weighted avg     0.6447    0.6385    0.5674      1101

F1-macro sent:  0.4801915159111023
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8884    0.9786    0.9313     16205
           N     0.7817    0.5536    0.6482      1857
           P     0.9227    0.6059    0.7314      3212

   micro avg     0.8852    0.8852    0.8852     21274
   macro avg     0.8643    0.7127    0.7703     21274
weighted avg     0.8843    0.8852    0.8764     21274

F1-macro tok:  0.7703099820765162
F1-micro tok:  0.8852119958634953
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 335905.6773071289
train_cost_avg: 39.31480305560966
train_count_sent: 8544.0
train_total_correct_sent: 5417.0
train_accuracy_sent: 0.6340121722846442
train_count_tok: 163566.0
train_total_correct_tok: 143047.0
train_accuracy_tok: 0.8745521685435849
train_label=O_precision_sent: 0.38235294117647056
train_label=O_recall_sent: 0.01600985221674877
train_label=O_f-score_sent: 0.030732860520094562
train_label=N_precision_sent: 0.5950561797752809
train_label=N_recall_sent: 0.8
train_label=N_f-score_sent: 0.6824742268041237
train_label=P_precision_sent: 0.6813214108296075
train_label=P_recall_sent: 0.7598337950138504
train_label=P_f-score_sent: 0.718438973284442
train_precision_macro_sent: 0.552910177260453
train_recall_macro_sent: 0.525281215743533
train_f-score_macro_sent: 0.4772153535362201
train_precision_micro_sent: 0.6340121722846442
train_recall_micro_sent: 0.6340121722846442
train_f-score_micro_sent: 0.6340121722846442
train_label=O_precision_tok: 0.8857894891627209
train_label=O_recall_tok: 0.9688854576306626
train_label=O_f-score_tok: 0.9254759774004355
train_label=N_precision_tok: 0.7564497497112053
train_label=N_recall_tok: 0.5533023517814393
train_label=N_f-score_tok: 0.639121594143961
train_label=P_precision_tok: 0.8569847372713504
train_label=P_recall_tok: 0.5880401327097574
train_label=P_f-score_tok: 0.6974847687457034
train_precision_macro_tok: 0.8330746587150921
train_recall_macro_tok: 0.7034093140406198
train_f-score_macro_tok: 0.7540274467633666
train_precision_micro_tok: 0.8745521685435849
train_recall_micro_tok: 0.8745521685435849
train_f-score_micro_tok: 0.8745521685435849
train_time: 144.78428769111633
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3824    0.0160    0.0307      1624
           N     0.5951    0.8000    0.6825      3310
           P     0.6813    0.7598    0.7184      3610

   micro avg     0.6340    0.6340    0.6340      8544
   macro avg     0.5529    0.5253    0.4772      8544
weighted avg     0.5911    0.6340    0.5738      8544

F1-macro sent:  0.4772153535362201
F1-micro sent:  0.6340121722846442
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8858    0.9689    0.9255    124347
           N     0.7564    0.5533    0.6391     14202
           P     0.8570    0.5880    0.6975     25017

   micro avg     0.8746    0.8746    0.8746    163566
   macro avg     0.8331    0.7034    0.7540    163566
weighted avg     0.8702    0.8746    0.8657    163566

F1-macro tok:  0.7540274467633666
F1-micro tok:  0.8745521685435849
**************************************************
dev_cost_sum: 44779.96923828125
dev_cost_avg: 40.672088318148276
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18816.0
dev_accuracy_tok: 0.8844599041083012
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5662824207492796
dev_label=N_recall_sent: 0.9182242990654206
dev_label=N_f-score_sent: 0.7005347593582888
dev_label=P_precision_sent: 0.7376237623762376
dev_label=P_recall_sent: 0.6711711711711712
dev_label=P_f-score_sent: 0.7028301886792453
dev_precision_macro_sent: 0.6568576165973946
dev_recall_macro_sent: 0.5327096982302467
dev_f-score_macro_sent: 0.47353544244929296
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8801341617638972
dev_label=O_recall_tok: 0.9877815489046591
dev_label=O_f-score_tok: 0.9308560130262851
dev_label=N_precision_tok: 0.8448275862068966
dev_label=N_recall_tok: 0.5013462574044157
dev_label=N_f-score_tok: 0.6292666441365327
dev_label=P_precision_tok: 0.9460957178841309
dev_label=P_recall_tok: 0.5846824408468244
dev_label=P_f-score_tok: 0.722724648835867
dev_precision_macro_tok: 0.8903524886183082
dev_recall_macro_tok: 0.6912700823852997
dev_f-score_macro_tok: 0.7609491019995615
dev_precision_micro_tok: 0.8844599041083012
dev_recall_micro_tok: 0.8844599041083012
dev_f-score_micro_tok: 0.8844599041083013
dev_time: 8.43703317642212
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5663    0.9182    0.7005       428
           P     0.7376    0.6712    0.7028       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.6569    0.5327    0.4735      1101
weighted avg     0.6563    0.6294    0.5593      1101

F1-macro sent:  0.47353544244929296
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8801    0.9878    0.9309     16205
           N     0.8448    0.5013    0.6293      1857
           P     0.9461    0.5847    0.7227      3212

   micro avg     0.8845    0.8845    0.8845     21274
   macro avg     0.8904    0.6913    0.7609     21274
weighted avg     0.8870    0.8845    0.8731     21274

F1-macro tok:  0.7609491019995615
F1-micro tok:  0.8844599041083013
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 332905.87200927734
train_cost_avg: 38.963702248276846
train_count_sent: 8544.0
train_total_correct_sent: 5471.0
train_accuracy_sent: 0.6403323970037453
train_count_tok: 163566.0
train_total_correct_tok: 143354.0
train_accuracy_tok: 0.8764290867295159
train_label=O_precision_sent: 0.3387096774193548
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.02491103202846975
train_label=N_precision_sent: 0.6021650879566982
train_label=N_recall_sent: 0.8066465256797583
train_label=N_f-score_sent: 0.6895661157024793
train_label=P_precision_sent: 0.6867588932806324
train_label=P_recall_sent: 0.7700831024930748
train_label=P_f-score_sent: 0.7260381300600678
train_precision_macro_sent: 0.5425445528855618
train_recall_macro_sent: 0.5298868875518639
train_f-score_macro_sent: 0.4801717592636723
train_precision_micro_sent: 0.6403323970037453
train_recall_micro_sent: 0.6403323970037453
train_f-score_micro_sent: 0.6403323970037453
train_label=O_precision_tok: 0.8874401825811676
train_label=O_recall_tok: 0.9693921043531408
train_label=O_f-score_tok: 0.9266076555575627
train_label=N_precision_tok: 0.7595249406175772
train_label=N_recall_tok: 0.5628784678214336
train_label=N_f-score_tok: 0.646580660816112
train_label=P_precision_tok: 0.8610191156818314
train_label=P_recall_tok: 0.5923571971059679
train_label=P_f-score_tok: 0.7018565880458465
train_precision_macro_tok: 0.8359947462935254
train_recall_macro_tok: 0.7082092564268474
train_f-score_macro_tok: 0.7583483014731738
train_precision_micro_tok: 0.8764290867295159
train_recall_micro_tok: 0.8764290867295159
train_f-score_micro_tok: 0.8764290867295159
train_time: 144.09634685516357
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3387    0.0129    0.0249      1624
           N     0.6022    0.8066    0.6896      3310
           P     0.6868    0.7701    0.7260      3610

   micro avg     0.6403    0.6403    0.6403      8544
   macro avg     0.5425    0.5299    0.4802      8544
weighted avg     0.5878    0.6403    0.5786      8544

F1-macro sent:  0.4801717592636723
F1-micro sent:  0.6403323970037453
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8874    0.9694    0.9266    124347
           N     0.7595    0.5629    0.6466     14202
           P     0.8610    0.5924    0.7019     25017

   micro avg     0.8764    0.8764    0.8764    163566
   macro avg     0.8360    0.7082    0.7583    163566
weighted avg     0.8723    0.8764    0.8679    163566

F1-macro tok:  0.7583483014731738
F1-micro tok:  0.8764290867295159
**************************************************
dev_cost_sum: 44344.829833984375
dev_cost_avg: 40.27686633422741
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18918.0
dev_accuracy_tok: 0.8892544890476638
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6328413284132841
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7072164948453609
dev_label=P_precision_sent: 0.64568345323741
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.718
dev_precision_macro_sent: 0.6483971494391202
dev_recall_macro_sent: 0.5395646840571952
dev_f-score_macro_sent: 0.4808192913852352
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8957896526321755
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.9339477726574501
dev_label=N_precision_tok: 0.7840409956076134
dev_label=N_recall_tok: 0.5767366720516963
dev_label=N_f-score_tok: 0.6645982004343779
dev_label=P_precision_tok: 0.901813356921716
dev_label=P_recall_tok: 0.6348069738480697
dev_label=P_f-score_tok: 0.7451123698154576
dev_precision_macro_tok: 0.8605480017205016
dev_recall_macro_tok: 0.7290150114533726
dev_f-score_macro_tok: 0.7812194476357619
dev_precision_micro_tok: 0.8892544890476638
dev_recall_micro_tok: 0.8892544890476638
dev_f-score_micro_tok: 0.8892544890476638
dev_time: 8.452873229980469
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6328    0.8014    0.7072       428
           P     0.6457    0.8086    0.7180       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6484    0.5396    0.4808      1101
weighted avg     0.6451    0.6394    0.5681      1101

F1-macro sent:  0.4808192913852352
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8958    0.9755    0.9339     16205
           N     0.7840    0.5767    0.6646      1857
           P     0.9018    0.6348    0.7451      3212

   micro avg     0.8893    0.8893    0.8893     21274
   macro avg     0.8605    0.7290    0.7812     21274
weighted avg     0.8869    0.8893    0.8819     21274

F1-macro tok:  0.7812194476357619
F1-micro tok:  0.8892544890476638
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330340.0923461914
train_cost_avg: 38.663400321417534
train_count_sent: 8544.0
train_total_correct_sent: 5472.0
train_accuracy_sent: 0.6404494382022472
train_count_tok: 163566.0
train_total_correct_tok: 143871.0
train_accuracy_tok: 0.8795898903195041
train_label=O_precision_sent: 0.422680412371134
train_label=O_recall_sent: 0.025246305418719212
train_label=O_f-score_sent: 0.04764671702498547
train_label=N_precision_sent: 0.6054642278305163
train_label=N_recall_sent: 0.7900302114803626
train_label=N_f-score_sent: 0.6855420107484598
train_label=P_precision_sent: 0.6821705426356589
train_label=P_recall_sent: 0.7800554016620499
train_label=P_f-score_sent: 0.7278366502972344
train_precision_macro_sent: 0.5701050609457697
train_recall_macro_sent: 0.5317773061870439
train_f-score_macro_sent: 0.48700845935689324
train_precision_micro_sent: 0.6404494382022472
train_recall_micro_sent: 0.6404494382022472
train_f-score_micro_sent: 0.6404494382022472
train_label=O_precision_tok: 0.8898709915223001
train_label=O_recall_tok: 0.9707592463026852
train_label=O_f-score_tok: 0.928556867963861
train_label=N_precision_tok: 0.7671817233861029
train_label=N_recall_tok: 0.569849316997606
train_label=N_f-score_tok: 0.653953375621187
train_label=P_precision_tok: 0.8675649219784649
train_label=P_recall_tok: 0.6022704560898589
train_label=P_f-score_tok: 0.7109758399395999
train_precision_macro_tok: 0.8415392122956226
train_recall_macro_tok: 0.7142930064633832
train_f-score_macro_tok: 0.7644953611748827
train_precision_micro_tok: 0.8795898903195041
train_recall_micro_tok: 0.8795898903195041
train_f-score_micro_tok: 0.8795898903195041
train_time: 144.37456583976746
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4227    0.0252    0.0476      1624
           N     0.6055    0.7900    0.6855      3310
           P     0.6822    0.7801    0.7278      3610

   micro avg     0.6404    0.6404    0.6404      8544
   macro avg     0.5701    0.5318    0.4870      8544
weighted avg     0.6031    0.6404    0.5822      8544

F1-macro sent:  0.48700845935689324
F1-micro sent:  0.6404494382022472
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8899    0.9708    0.9286    124347
           N     0.7672    0.5698    0.6540     14202
           P     0.8676    0.6023    0.7110     25017

   micro avg     0.8796    0.8796    0.8796    163566
   macro avg     0.8415    0.7143    0.7645    163566
weighted avg     0.8758    0.8796    0.8714    163566

F1-macro tok:  0.7644953611748827
F1-micro tok:  0.8795898903195041
**************************************************
dev_cost_sum: 44057.893310546875
dev_cost_avg: 40.016251871523046
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 18935.0
dev_accuracy_tok: 0.8900535865375576
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6494252873563219
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7136842105263158
dev_label=P_precision_sent: 0.6510416666666666
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7352941176470588
dev_precision_macro_sent: 0.7668223180076628
dev_recall_macro_sent: 0.5499170353473909
dev_f-score_macro_sent: 0.491613465712964
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8941103463838429
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9341899737702986
dev_label=N_precision_tok: 0.7800711743772242
dev_label=N_recall_tok: 0.5901992460958535
dev_label=N_f-score_tok: 0.6719803801348865
dev_label=P_precision_tok: 0.9286047596826879
dev_label=P_recall_tok: 0.6195516811955168
dev_label=P_f-score_tok: 0.7432306255835668
dev_precision_macro_tok: 0.867595426814585
dev_recall_macro_tok: 0.7292607996864477
dev_f-score_macro_tok: 0.7831336598295838
dev_precision_micro_tok: 0.8900535865375576
dev_recall_micro_tok: 0.8900535865375576
dev_f-score_micro_tok: 0.8900535865375576
dev_time: 8.387014150619507
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6494    0.7921    0.7137       428
           P     0.6510    0.8446    0.7353       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.7668    0.5499    0.4916      1101
weighted avg     0.7230    0.6512    0.5793      1101

F1-macro sent:  0.491613465712964
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8941    0.9780    0.9342     16205
           N     0.7801    0.5902    0.6720      1857
           P     0.9286    0.6196    0.7432      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8676    0.7293    0.7831     21274
weighted avg     0.8894    0.8901    0.8825     21274

F1-macro tok:  0.7831336598295838
F1-micro tok:  0.8900535865375576
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 327808.8610839844
train_cost_avg: 38.36714198080342
train_count_sent: 8544.0
train_total_correct_sent: 5510.0
train_accuracy_sent: 0.6448970037453183
train_count_tok: 163566.0
train_total_correct_tok: 144096.0
train_accuracy_tok: 0.8809654818238509
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.011083743842364532
train_label=O_f-score_sent: 0.021686746987951807
train_label=N_precision_sent: 0.6049631120053656
train_label=N_recall_sent: 0.817522658610272
train_label=N_f-score_sent: 0.6953616857252988
train_label=P_precision_sent: 0.6904584882280049
train_label=P_recall_sent: 0.7717451523545706
train_label=P_f-score_sent: 0.7288423806409418
train_precision_macro_sent: 0.5984738667444568
train_recall_macro_sent: 0.5334505182690691
train_f-score_macro_sent: 0.48196360445139746
train_precision_micro_sent: 0.6448970037453183
train_recall_micro_sent: 0.6448970037453183
train_f-score_micro_sent: 0.6448970037453183
train_label=O_precision_tok: 0.8911878469351601
train_label=O_recall_tok: 0.9709200865320434
train_label=O_f-score_tok: 0.9293469684665094
train_label=N_precision_tok: 0.7706042665163049
train_label=N_recall_tok: 0.5773834671173074
train_label=N_f-score_tok: 0.66014571509077
train_label=P_precision_tok: 0.8689050593021257
train_label=P_recall_tok: 0.6061877923012352
train_label=P_f-score_tok: 0.7141511655286085
train_precision_macro_tok: 0.8435657242511968
train_recall_macro_tok: 0.7181637819835287
train_f-score_macro_tok: 0.7678812830286293
train_precision_micro_tok: 0.8809654818238509
train_recall_micro_tok: 0.8809654818238509
train_f-score_micro_tok: 0.8809654818238509
train_time: 144.1097059249878
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0111    0.0217      1624
           N     0.6050    0.8175    0.6954      3310
           P     0.6905    0.7717    0.7288      3610

   micro avg     0.6449    0.6449    0.6449      8544
   macro avg     0.5985    0.5335    0.4820      8544
weighted avg     0.6211    0.6449    0.5815      8544

F1-macro sent:  0.48196360445139746
F1-micro sent:  0.6448970037453183
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8912    0.9709    0.9293    124347
           N     0.7706    0.5774    0.6601     14202
           P     0.8689    0.6062    0.7142     25017

   micro avg     0.8810    0.8810    0.8810    163566
   macro avg     0.8436    0.7182    0.7679    163566
weighted avg     0.8773    0.8810    0.8731    163566

F1-macro tok:  0.7678812830286293
F1-micro tok:  0.8809654818238509
**************************************************
dev_cost_sum: 43800.23449707031
dev_cost_avg: 39.78222933430546
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 18965.0
dev_accuracy_tok: 0.8914637585785465
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6330275229357798
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.709146968139774
dev_label=P_precision_sent: 0.6648451730418944
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7351460221550856
dev_precision_macro_sent: 0.6707194700877962
dev_recall_macro_sent: 0.5499936331875278
dev_f-score_macro_sent: 0.495555290550264
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8950812274368231
dev_label=O_recall_tok: 0.9792039493983339
dev_label=O_f-score_tok: 0.9352547667462353
dev_label=N_precision_tok: 0.8227344992050875
dev_label=N_recall_tok: 0.5573505654281099
dev_label=N_f-score_tok: 0.6645264847512039
dev_label=P_precision_tok: 0.9012237762237763
dev_label=P_recall_tok: 0.6419676214196762
dev_label=P_f-score_tok: 0.7498181818181818
dev_precision_macro_tok: 0.8730131676218956
dev_recall_macro_tok: 0.7261740454153734
dev_f-score_macro_tok: 0.7831998111052071
dev_precision_micro_tok: 0.8914637585785465
dev_recall_micro_tok: 0.8914637585785465
dev_f-score_micro_tok: 0.8914637585785465
dev_time: 8.262253522872925
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6330    0.8061    0.7091       428
           P     0.6648    0.8221    0.7351       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.6707    0.5500    0.4956      1101
weighted avg     0.6628    0.6494    0.5809      1101

F1-macro sent:  0.495555290550264
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8951    0.9792    0.9353     16205
           N     0.8227    0.5574    0.6645      1857
           P     0.9012    0.6420    0.7498      3212

   micro avg     0.8915    0.8915    0.8915     21274
   macro avg     0.8730    0.7262    0.7832     21274
weighted avg     0.8897    0.8915    0.8836     21274

F1-macro tok:  0.7831998111052071
F1-micro tok:  0.8914637585785465
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325481.1368408203
train_cost_avg: 38.094702345601625
train_count_sent: 8544.0
train_total_correct_sent: 5536.0
train_accuracy_sent: 0.6479400749063671
train_count_tok: 163566.0
train_total_correct_tok: 144496.0
train_accuracy_tok: 0.8834109778315787
train_label=O_precision_sent: 0.4462809917355372
train_label=O_recall_sent: 0.0332512315270936
train_label=O_f-score_sent: 0.06189111747851003
train_label=N_precision_sent: 0.6128211062254107
train_label=N_recall_sent: 0.8
train_label=N_f-score_sent: 0.6940112698204691
train_label=P_precision_sent: 0.6908824963432472
train_label=P_recall_sent: 0.7850415512465374
train_label=P_f-score_sent: 0.7349585062240664
train_precision_macro_sent: 0.5833281981013984
train_recall_macro_sent: 0.5394309275912104
train_f-score_macro_sent: 0.49695363117434854
train_precision_micro_sent: 0.6479400749063671
train_recall_micro_sent: 0.6479400749063671
train_f-score_micro_sent: 0.6479400749063671
train_label=O_precision_tok: 0.8938017721912546
train_label=O_recall_tok: 0.9710005066467224
train_label=O_f-score_tok: 0.9308032100649876
train_label=N_precision_tok: 0.7742446848190974
train_label=N_recall_tok: 0.5846359667652443
train_label=N_f-score_tok: 0.6662119874829495
train_label=P_precision_tok: 0.870290059138271
train_label=P_recall_tok: 0.6176599912059799
train_label=P_f-score_tok: 0.7225287571308332
train_precision_macro_tok: 0.8461121720495409
train_recall_macro_tok: 0.7244321548726488
train_f-score_macro_tok: 0.7731813182262567
train_precision_micro_tok: 0.8834109778315787
train_recall_micro_tok: 0.8834109778315787
train_f-score_micro_tok: 0.8834109778315787
train_time: 145.17169427871704
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4463    0.0333    0.0619      1624
           N     0.6128    0.8000    0.6940      3310
           P     0.6909    0.7850    0.7350      3610

   micro avg     0.6479    0.6479    0.6479      8544
   macro avg     0.5833    0.5394    0.4970      8544
weighted avg     0.6141    0.6479    0.5912      8544

F1-macro sent:  0.49695363117434854
F1-micro sent:  0.6479400749063671
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8938    0.9710    0.9308    124347
           N     0.7742    0.5846    0.6662     14202
           P     0.8703    0.6177    0.7225     25017

   micro avg     0.8834    0.8834    0.8834    163566
   macro avg     0.8461    0.7244    0.7732    163566
weighted avg     0.8798    0.8834    0.8760    163566

F1-macro tok:  0.7731813182262567
F1-micro tok:  0.8834109778315787
**************************************************
dev_cost_sum: 43613.044189453125
dev_cost_avg: 39.612210889603205
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 18999.0
dev_accuracy_tok: 0.8930619535583341
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.5893939393939394
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.7150735294117646
dev_label=P_precision_sent: 0.7319347319347319
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7193585337915235
dev_precision_macro_sent: 0.7182206682206682
dev_recall_macro_sent: 0.5532512780502823
dev_f-score_macro_sent: 0.5058065383568361
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.8991075996134826
dev_label=O_recall_tok: 0.9761184819500154
dev_label=O_f-score_tok: 0.9360317178531273
dev_label=N_precision_tok: 0.8053293856402665
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.6783042394014962
dev_label=P_precision_tok: 0.8982832618025751
dev_label=P_recall_tok: 0.6516189290161893
dev_label=P_f-score_tok: 0.7553229880909419
dev_precision_macro_tok: 0.8675734156854414
dev_recall_macro_tok: 0.7378762111226426
dev_f-score_macro_tok: 0.7898863151151886
dev_precision_micro_tok: 0.8930619535583341
dev_recall_micro_tok: 0.8930619535583341
dev_f-score_micro_tok: 0.8930619535583341
dev_time: 8.523642539978027
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.5894    0.9089    0.7151       428
           P     0.7319    0.7072    0.7194       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7182    0.5533    0.5058      1101
weighted avg     0.6976    0.6476    0.5853      1101

F1-macro sent:  0.5058065383568361
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9761    0.9360     16205
           N     0.8053    0.5859    0.6783      1857
           P     0.8983    0.6516    0.7553      3212

   micro avg     0.8931    0.8931    0.8931     21274
   macro avg     0.8676    0.7379    0.7899     21274
weighted avg     0.8908    0.8931    0.8863     21274

F1-macro tok:  0.7898863151151886
F1-micro tok:  0.8930619535583341
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323211.52264404297
train_cost_avg: 37.82906397987394
train_count_sent: 8544.0
train_total_correct_sent: 5589.0
train_accuracy_sent: 0.6541432584269663
train_count_tok: 163566.0
train_total_correct_tok: 144754.0
train_accuracy_tok: 0.8849883227565631
train_label=O_precision_sent: 0.43529411764705883
train_label=O_recall_sent: 0.022783251231527094
train_label=O_f-score_sent: 0.0433001755412522
train_label=N_precision_sent: 0.6127506195088984
train_label=N_recall_sent: 0.8217522658610272
train_label=N_f-score_sent: 0.7020260678797265
train_label=P_precision_sent: 0.7044776119402985
train_label=P_recall_sent: 0.7844875346260388
train_label=P_f-score_sent: 0.7423328964613368
train_precision_macro_sent: 0.5841741163654185
train_recall_macro_sent: 0.5430076839061977
train_f-score_macro_sent: 0.49588637996077184
train_precision_micro_sent: 0.6541432584269663
train_recall_micro_sent: 0.6541432584269663
train_f-score_micro_sent: 0.6541432584269663
train_label=O_precision_tok: 0.8946745124162688
train_label=O_recall_tok: 0.9720781361834222
train_label=O_f-score_tok: 0.9317715800995945
train_label=N_precision_tok: 0.7793064980942642
train_label=N_recall_tok: 0.5902689762005351
train_label=N_f-score_tok: 0.6717416563163588
train_label=P_precision_tok: 0.8752824220515137
train_label=P_recall_tok: 0.6194187952192509
train_label=P_f-score_tok: 0.725451183258819
train_precision_macro_tok: 0.8497544775206823
train_recall_macro_tok: 0.7272553025344027
train_f-score_macro_tok: 0.7763214732249241
train_precision_micro_tok: 0.8849883227565631
train_recall_micro_tok: 0.8849883227565631
train_f-score_micro_tok: 0.8849883227565631
train_time: 143.93206071853638
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4353    0.0228    0.0433      1624
           N     0.6128    0.8218    0.7020      3310
           P     0.7045    0.7845    0.7423      3610

   micro avg     0.6541    0.6541    0.6541      8544
   macro avg     0.5842    0.5430    0.4959      8544
weighted avg     0.6178    0.6541    0.5938      8544

F1-macro sent:  0.49588637996077184
F1-micro sent:  0.6541432584269663
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8947    0.9721    0.9318    124347
           N     0.7793    0.5903    0.6717     14202
           P     0.8753    0.6194    0.7255     25017

   micro avg     0.8850    0.8850    0.8850    163566
   macro avg     0.8498    0.7273    0.7763    163566
weighted avg     0.8817    0.8850    0.8776    163566

F1-macro tok:  0.7763214732249241
F1-micro tok:  0.8849883227565631
**************************************************
dev_cost_sum: 43395.916748046875
dev_cost_avg: 39.41500158769017
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 18998.0
dev_accuracy_tok: 0.8930149478236344
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11857707509881421
dev_label=N_precision_sent: 0.6338028169014085
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7228915662650603
dev_label=P_precision_sent: 0.6856581532416502
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7324239244491081
dev_precision_macro_sent: 0.6481536567143529
dev_recall_macro_sent: 0.5642199049230842
dev_f-score_macro_sent: 0.5246308552709942
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9007468217319423
dev_label=O_recall_tok: 0.9750077136686208
dev_label=O_f-score_tok: 0.9364072778996029
dev_label=N_precision_tok: 0.7599206349206349
dev_label=N_recall_tok: 0.6187399030694669
dev_label=N_f-score_tok: 0.6821015138023152
dev_label=P_precision_tok: 0.9225574065736155
dev_label=P_recall_tok: 0.637920298879203
dev_label=P_f-score_tok: 0.7542794036443953
dev_precision_macro_tok: 0.8610749544087309
dev_recall_macro_tok: 0.7438893052057636
dev_f-score_macro_tok: 0.7909293984487711
dev_precision_micro_tok: 0.8930149478236344
dev_recall_micro_tok: 0.8930149478236344
dev_f-score_micro_tok: 0.8930149478236343
dev_time: 8.49392032623291
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0655    0.1186       229
           N     0.6338    0.8411    0.7229       428
           P     0.6857    0.7860    0.7324       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6482    0.5642    0.5246      1101
weighted avg     0.6529    0.6576    0.6010      1101

F1-macro sent:  0.5246308552709942
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9007    0.9750    0.9364     16205
           N     0.7599    0.6187    0.6821      1857
           P     0.9226    0.6379    0.7543      3212

   micro avg     0.8930    0.8930    0.8930     21274
   macro avg     0.8611    0.7439    0.7909     21274
weighted avg     0.8917    0.8930    0.8867     21274

F1-macro tok:  0.7909293984487711
F1-micro tok:  0.8930149478236343
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321050.88397216797
train_cost_avg: 37.5761802401882
train_count_sent: 8544.0
train_total_correct_sent: 5623.0
train_accuracy_sent: 0.65812265917603
train_count_tok: 163566.0
train_total_correct_tok: 145184.0
train_accuracy_tok: 0.8876172309648704
train_label=O_precision_sent: 0.5391304347826087
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.07130534790109258
train_label=N_precision_sent: 0.6337279536119835
train_label=N_recall_sent: 0.7924471299093656
train_label=N_f-score_sent: 0.7042556047791649
train_label=P_precision_sent: 0.6848484848484848
train_label=P_recall_sent: 0.8138504155124654
train_label=P_f-score_sent: 0.7437974683544304
train_precision_macro_sent: 0.619235624414359
train_recall_macro_sent: 0.5481582951077696
train_f-score_macro_sent: 0.5064528070115627
train_precision_micro_sent: 0.65812265917603
train_recall_micro_sent: 0.65812265917603
train_f-score_micro_sent: 0.65812265917603
train_label=O_precision_tok: 0.8970167188357637
train_label=O_recall_tok: 0.9725526148600288
train_label=O_f-score_tok: 0.9332587347828603
train_label=N_precision_tok: 0.7897658924770982
train_label=N_recall_tok: 0.6009716941275877
train_label=N_f-score_tok: 0.6825542804590348
train_label=P_precision_tok: 0.8759266484588373
train_label=P_recall_tok: 0.6281728424671223
train_label=P_f-score_tok: 0.7316448624237628
train_precision_macro_tok: 0.8542364199238998
train_recall_macro_tok: 0.7338990504849129
train_f-score_macro_tok: 0.7824859592218859
train_precision_micro_tok: 0.8876172309648704
train_recall_micro_tok: 0.8876172309648704
train_f-score_micro_tok: 0.8876172309648704
train_time: 144.71821308135986
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5391    0.0382    0.0713      1624
           N     0.6337    0.7924    0.7043      3310
           P     0.6848    0.8139    0.7438      3610

   micro avg     0.6581    0.6581    0.6581      8544
   macro avg     0.6192    0.5482    0.5065      8544
weighted avg     0.6373    0.6581    0.6007      8544

F1-macro sent:  0.5064528070115627
F1-micro sent:  0.65812265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9726    0.9333    124347
           N     0.7898    0.6010    0.6826     14202
           P     0.8759    0.6282    0.7316     25017

   micro avg     0.8876    0.8876    0.8876    163566
   macro avg     0.8542    0.7339    0.7825    163566
weighted avg     0.8845    0.8876    0.8807    163566

F1-macro tok:  0.7824859592218859
F1-micro tok:  0.8876172309648704
**************************************************
dev_cost_sum: 43268.34167480469
dev_cost_avg: 39.29912958656193
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 19013.0
dev_accuracy_tok: 0.893720033844129
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042735042735042736
dev_label=N_precision_sent: 0.6764705882352942
dev_label=N_recall_sent: 0.7523364485981309
dev_label=N_f-score_sent: 0.7123893805309734
dev_label=P_precision_sent: 0.6306451612903226
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.7349624060150375
dev_precision_macro_sent: 0.7690385831752056
dev_recall_macro_sent: 0.5516003801213776
dev_f-score_macro_sent: 0.4966956097603512
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.8981696605655353
dev_label=O_recall_tok: 0.9780931811169392
dev_label=O_f-score_tok: 0.9364291622356139
dev_label=N_precision_tok: 0.8085908063300679
dev_label=N_recall_tok: 0.5778136779752289
dev_label=N_f-score_tok: 0.6739949748743719
dev_label=P_precision_tok: 0.908695652173913
dev_label=P_recall_tok: 0.6506849315068494
dev_label=P_f-score_tok: 0.7583454281567489
dev_precision_macro_tok: 0.8718187063565054
dev_recall_macro_tok: 0.7355305968663391
dev_f-score_macro_tok: 0.7895898550889116
dev_precision_micro_tok: 0.893720033844129
dev_recall_micro_tok: 0.893720033844129
dev_f-score_micro_tok: 0.893720033844129
dev_time: 8.351490259170532
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0218    0.0427       229
           N     0.6765    0.7523    0.7124       428
           P     0.6306    0.8806    0.7350       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.7690    0.5516    0.4967      1101
weighted avg     0.7253    0.6521    0.5822      1101

F1-macro sent:  0.4966956097603512
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8982    0.9781    0.9364     16205
           N     0.8086    0.5778    0.6740      1857
           P     0.9087    0.6507    0.7583      3212

   micro avg     0.8937    0.8937    0.8937     21274
   macro avg     0.8718    0.7355    0.7896     21274
weighted avg     0.8919    0.8937    0.8866     21274

F1-macro tok:  0.7895898550889116
F1-micro tok:  0.893720033844129
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319240.1569213867
train_cost_avg: 37.364250576005
train_count_sent: 8544.0
train_total_correct_sent: 5614.0
train_accuracy_sent: 0.6570692883895131
train_count_tok: 163566.0
train_total_correct_tok: 145200.0
train_accuracy_tok: 0.8877150508051795
train_label=O_precision_sent: 0.47191011235955055
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.04903677758318739
train_label=N_precision_sent: 0.6303059046715674
train_label=N_recall_sent: 0.8030211480362538
train_label=N_f-score_sent: 0.7062574730968514
train_label=P_precision_sent: 0.6875884851344974
train_label=P_recall_sent: 0.807202216066482
train_label=P_f-score_sent: 0.7426095820591234
train_precision_macro_sent: 0.5966015007218718
train_recall_macro_sent: 0.545361811022751
train_f-score_macro_sent: 0.4993012775797207
train_precision_micro_sent: 0.6570692883895131
train_recall_micro_sent: 0.6570692883895131
train_f-score_micro_sent: 0.6570692883895131
train_label=O_precision_tok: 0.8979964923753753
train_label=O_recall_tok: 0.9717805817591096
train_label=O_f-score_tok: 0.9334327239862348
train_label=N_precision_tok: 0.7804456571168713
train_label=N_recall_tok: 0.6042106745528799
train_label=N_f-score_tok: 0.6811128308925666
train_label=P_precision_tok: 0.8763814072305215
train_label=P_recall_tok: 0.6308110484870288
train_label=P_f-score_tok: 0.7335905541093344
train_precision_macro_tok: 0.8516078522409227
train_recall_macro_tok: 0.7356007682663396
train_f-score_macro_tok: 0.7827120363293786
train_precision_micro_tok: 0.8877150508051795
train_recall_micro_tok: 0.8877150508051795
train_f-score_micro_tok: 0.8877150508051795
train_time: 145.32896065711975
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4719    0.0259    0.0490      1624
           N     0.6303    0.8030    0.7063      3310
           P     0.6876    0.8072    0.7426      3610

   micro avg     0.6571    0.6571    0.6571      8544
   macro avg     0.5966    0.5454    0.4993      8544
weighted avg     0.6244    0.6571    0.5967      8544

F1-macro sent:  0.4993012775797207
F1-micro sent:  0.6570692883895131
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8980    0.9718    0.9334    124347
           N     0.7804    0.6042    0.6811     14202
           P     0.8764    0.6308    0.7336     25017

   micro avg     0.8877    0.8877    0.8877    163566
   macro avg     0.8516    0.7356    0.7827    163566
weighted avg     0.8845    0.8877    0.8810    163566

F1-macro tok:  0.7827120363293786
F1-micro tok:  0.8877150508051795
**************************************************
dev_cost_sum: 43000.11071777344
dev_cost_avg: 39.05550473912211
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19025.0
dev_accuracy_tok: 0.8942841026605246
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6512059369202227
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7259565667011375
dev_label=P_precision_sent: 0.6654676258992805
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.74
dev_precision_macro_sent: 0.6611134098287232
dev_recall_macro_sent: 0.5569646800618518
dev_f-score_macro_sent: 0.4999997066308756
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.8955484270358489
dev_label=O_recall_tok: 0.9819808701018204
dev_label=O_f-score_tok: 0.9367751810207806
dev_label=N_precision_tok: 0.8242710795902285
dev_label=N_recall_tok: 0.563274098007539
dev_label=N_f-score_tok: 0.6692258477287268
dev_label=P_precision_tok: 0.9239713774597496
dev_label=P_recall_tok: 0.6432129514321295
dev_label=P_f-score_tok: 0.7584434654919235
dev_precision_macro_tok: 0.8812636280286089
dev_recall_macro_tok: 0.7294893065138296
dev_f-score_macro_tok: 0.7881481647471437
dev_precision_micro_tok: 0.8942841026605246
dev_recall_micro_tok: 0.8942841026605246
dev_f-score_micro_tok: 0.8942841026605246
dev_time: 8.517345666885376
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6512    0.8201    0.7260       428
           P     0.6655    0.8333    0.7400       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6611    0.5570    0.5000      1101
weighted avg     0.6602    0.6585    0.5877      1101

F1-macro sent:  0.4999997066308756
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8955    0.9820    0.9368     16205
           N     0.8243    0.5633    0.6692      1857
           P     0.9240    0.6432    0.7584      3212

   micro avg     0.8943    0.8943    0.8943     21274
   macro avg     0.8813    0.7295    0.7881     21274
weighted avg     0.8936    0.8943    0.8865     21274

F1-macro tok:  0.7881481647471437
F1-micro tok:  0.8942841026605246
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317117.1301879883
train_cost_avg: 37.11576898267653
train_count_sent: 8544.0
train_total_correct_sent: 5637.0
train_accuracy_sent: 0.6597612359550562
train_count_tok: 163566.0
train_total_correct_tok: 145633.0
train_accuracy_tok: 0.8903623002335449
train_label=O_precision_sent: 0.48484848484848486
train_label=O_recall_sent: 0.03940886699507389
train_label=O_f-score_sent: 0.07289293849658315
train_label=N_precision_sent: 0.6306263396046677
train_label=N_recall_sent: 0.8
train_label=N_f-score_sent: 0.7052869889465975
train_label=P_precision_sent: 0.6942796107286969
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.7477949635689634
train_precision_macro_sent: 0.6032514783939499
train_recall_macro_sent: 0.5498860581580994
train_f-score_macro_sent: 0.508658297004048
train_precision_micro_sent: 0.6597612359550562
train_recall_micro_sent: 0.6597612359550562
train_f-score_micro_sent: 0.6597612359550562
train_label=O_precision_tok: 0.9000573185347298
train_label=O_recall_tok: 0.9723676485962669
train_label=O_f-score_tok: 0.9348162236551159
train_label=N_precision_tok: 0.7891823214447772
train_label=N_recall_tok: 0.6123081256161104
train_label=N_f-score_tok: 0.689584076761429
train_label=P_precision_tok: 0.8800658978583196
train_label=P_recall_tok: 0.6406043890154695
train_label=P_f-score_tok: 0.7414810188076895
train_precision_macro_tok: 0.8564351792792756
train_recall_macro_tok: 0.7417600544092822
train_f-score_macro_tok: 0.7886271064080782
train_precision_micro_tok: 0.8903623002335449
train_recall_micro_tok: 0.8903623002335449
train_f-score_micro_tok: 0.890362300233545
train_time: 144.9684054851532
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4848    0.0394    0.0729      1624
           N     0.6306    0.8000    0.7053      3310
           P     0.6943    0.8102    0.7478      3610

   micro avg     0.6598    0.6598    0.6598      8544
   macro avg     0.6033    0.5499    0.5087      8544
weighted avg     0.6298    0.6598    0.6030      8544

F1-macro sent:  0.508658297004048
F1-micro sent:  0.6597612359550562
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9001    0.9724    0.9348    124347
           N     0.7892    0.6123    0.6896     14202
           P     0.8801    0.6406    0.7415     25017

   micro avg     0.8904    0.8904    0.8904    163566
   macro avg     0.8564    0.7418    0.7886    163566
weighted avg     0.8874    0.8904    0.8840    163566

F1-macro tok:  0.7886271064080782
F1-micro tok:  0.890362300233545
**************************************************
dev_cost_sum: 42941.95635986328
dev_cost_avg: 39.00268515882224
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19036.0
dev_accuracy_tok: 0.8948011657422206
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6089030206677265
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7246925260170292
dev_label=P_precision_sent: 0.7136752136752137
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7324561403508772
dev_precision_macro_sent: 0.6908594114476467
dev_recall_macro_sent: 0.5534041673391957
dev_f-score_macro_sent: 0.4942999131097599
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.8955626792643834
dev_label=O_recall_tok: 0.9826596729404504
dev_label=O_f-score_tok: 0.9370917436591537
dev_label=N_precision_tok: 0.8308181096108023
dev_label=N_recall_tok: 0.563274098007539
dev_label=N_f-score_tok: 0.6713735558408216
dev_label=P_precision_tok: 0.9247985675917636
dev_label=P_recall_tok: 0.6432129514321295
dev_label=P_f-score_tok: 0.758721997796548
dev_precision_macro_tok: 0.8837264521556497
dev_recall_macro_tok: 0.7297155741267063
dev_f-score_macro_tok: 0.7890624324321744
dev_precision_micro_tok: 0.8948011657422206
dev_recall_micro_tok: 0.8948011657422206
dev_f-score_micro_tok: 0.8948011657422205
dev_time: 8.122215509414673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6089    0.8949    0.7247       428
           P     0.7137    0.7523    0.7325       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6909    0.5534    0.4943      1101
weighted avg     0.6805    0.6540    0.5824      1101

F1-macro sent:  0.4942999131097599
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8956    0.9827    0.9371     16205
           N     0.8308    0.5633    0.6714      1857
           P     0.9248    0.6432    0.7587      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8837    0.7297    0.7891     21274
weighted avg     0.8943    0.8948    0.8870     21274

F1-macro tok:  0.7890624324321744
F1-micro tok:  0.8948011657422205
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315201.9235229492
train_cost_avg: 36.89161089922158
train_count_sent: 8544.0
train_total_correct_sent: 5677.0
train_accuracy_sent: 0.6644428838951311
train_count_tok: 163566.0
train_total_correct_tok: 145944.0
train_accuracy_tok: 0.8922636733795533
train_label=O_precision_sent: 0.47560975609756095
train_label=O_recall_sent: 0.0480295566502463
train_label=O_f-score_sent: 0.08724832214765099
train_label=N_precision_sent: 0.6391158097068717
train_label=N_recall_sent: 0.8036253776435045
train_label=N_f-score_sent: 0.7119914346895075
train_label=P_precision_sent: 0.6967757230915126
train_label=P_recall_sent: 0.8141274238227146
train_label=P_f-score_sent: 0.7508942258559018
train_precision_macro_sent: 0.6038337629653151
train_recall_macro_sent: 0.5552607860388218
train_f-score_macro_sent: 0.5167113275643535
train_precision_micro_sent: 0.6644428838951311
train_recall_micro_sent: 0.6644428838951311
train_f-score_micro_sent: 0.6644428838951311
train_label=O_precision_tok: 0.9025269411027195
train_label=O_recall_tok: 0.9725606568714967
train_label=O_f-score_tok: 0.9362359343972936
train_label=N_precision_tok: 0.7898790864308106
train_label=N_recall_tok: 0.62096887762287
train_label=N_f-score_tok: 0.6953128079788702
train_label=P_precision_tok: 0.8796522684053246
train_label=P_recall_tok: 0.6471599312467522
train_label=P_f-score_tok: 0.7457049421952007
train_precision_macro_tok: 0.8573527653129517
train_recall_macro_tok: 0.746896488580373
train_f-score_macro_tok: 0.7924178948571216
train_precision_micro_tok: 0.8922636733795533
train_recall_micro_tok: 0.8922636733795533
train_f-score_micro_tok: 0.8922636733795533
train_time: 145.79976272583008
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4756    0.0480    0.0872      1624
           N     0.6391    0.8036    0.7120      3310
           P     0.6968    0.8141    0.7509      3610

   micro avg     0.6644    0.6644    0.6644      8544
   macro avg     0.6038    0.5553    0.5167      8544
weighted avg     0.6324    0.6644    0.6097      8544

F1-macro sent:  0.5167113275643535
F1-micro sent:  0.6644428838951311
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9726    0.9362    124347
           N     0.7899    0.6210    0.6953     14202
           P     0.8797    0.6472    0.7457     25017

   micro avg     0.8923    0.8923    0.8923    163566
   macro avg     0.8574    0.7469    0.7924    163566
weighted avg     0.8892    0.8923    0.8862    163566

F1-macro tok:  0.7924178948571216
F1-micro tok:  0.8922636733795533
**************************************************
dev_cost_sum: 42713.12414550781
dev_cost_avg: 38.79484481880819
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19062.0
dev_accuracy_tok: 0.896023314844411
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.6641509433962264
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7348643006263048
dev_label=P_precision_sent: 0.670863309352518
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.746
dev_precision_macro_sent: 0.6894491953606926
dev_recall_macro_sent: 0.5701849770433208
dev_f-score_macro_sent: 0.5236760783508448
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9018279141278971
dev_label=O_recall_tok: 0.9772909595803764
dev_label=O_f-score_tok: 0.9380441864597525
dev_label=N_precision_tok: 0.7991391678622669
dev_label=N_recall_tok: 0.5998922994076468
dev_label=N_f-score_tok: 0.6853275915103045
dev_label=P_precision_tok: 0.9103061664510564
dev_label=P_recall_tok: 0.6572229140722291
dev_label=P_f-score_tok: 0.7633339359971071
dev_precision_macro_tok: 0.8704244161470734
dev_recall_macro_tok: 0.7448020576867508
dev_f-score_macro_tok: 0.795568571322388
dev_precision_micro_tok: 0.896023314844411
dev_recall_micro_tok: 0.896023314844411
dev_f-score_micro_tok: 0.896023314844411
dev_time: 8.264688491821289
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.6642    0.8224    0.7349       428
           P     0.6709    0.8401    0.7460       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6894    0.5702    0.5237      1101
weighted avg     0.6812    0.6685    0.6053      1101

F1-macro sent:  0.5236760783508448
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9773    0.9380     16205
           N     0.7991    0.5999    0.6853      1857
           P     0.9103    0.6572    0.7633      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8704    0.7448    0.7956     21274
weighted avg     0.8941    0.8960    0.8896     21274

F1-macro tok:  0.795568571322388
F1-micro tok:  0.896023314844411
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313509.47216796875
train_cost_avg: 36.69352436422855
train_count_sent: 8544.0
train_total_correct_sent: 5748.0
train_accuracy_sent: 0.672752808988764
train_count_tok: 163566.0
train_total_correct_tok: 146107.0
train_accuracy_tok: 0.8932602130027023
train_label=O_precision_sent: 0.450199203187251
train_label=O_recall_sent: 0.06958128078817734
train_label=O_f-score_sent: 0.12053333333333333
train_label=N_precision_sent: 0.6499879139473048
train_label=N_recall_sent: 0.8123867069486405
train_label=N_f-score_sent: 0.7221700013428225
train_label=P_precision_sent: 0.7088546679499519
train_label=P_recall_sent: 0.8160664819944599
train_label=P_f-score_sent: 0.7586917331959825
train_precision_macro_sent: 0.6030139283615026
train_recall_macro_sent: 0.5660114899104259
train_f-score_macro_sent: 0.5337983559573795
train_precision_micro_sent: 0.672752808988764
train_recall_micro_sent: 0.672752808988764
train_f-score_micro_sent: 0.672752808988764
train_label=O_precision_tok: 0.9030854105544482
train_label=O_recall_tok: 0.9728501692843414
train_label=O_f-score_tok: 0.9366705381339528
train_label=N_precision_tok: 0.7891393809268206
train_label=N_recall_tok: 0.6211097028587523
train_label=N_f-score_tok: 0.6951142631993695
train_label=P_precision_tok: 0.8850013561160835
train_label=P_recall_tok: 0.6521565335571811
train_label=P_f-score_tok: 0.7509435699162293
train_precision_macro_tok: 0.8590753825324509
train_recall_macro_tok: 0.7487054685667583
train_f-score_macro_tok: 0.7942427904165172
train_precision_micro_tok: 0.8932602130027023
train_recall_micro_tok: 0.8932602130027023
train_f-score_micro_tok: 0.8932602130027023
train_time: 144.65559601783752
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4502    0.0696    0.1205      1624
           N     0.6500    0.8124    0.7222      3310
           P     0.7089    0.8161    0.7587      3610

   micro avg     0.6728    0.6728    0.6728      8544
   macro avg     0.6030    0.5660    0.5338      8544
weighted avg     0.6369    0.6728    0.6232      8544

F1-macro sent:  0.5337983559573795
F1-micro sent:  0.672752808988764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9729    0.9367    124347
           N     0.7891    0.6211    0.6951     14202
           P     0.8850    0.6522    0.7509     25017

   micro avg     0.8933    0.8933    0.8933    163566
   macro avg     0.8591    0.7487    0.7942    163566
weighted avg     0.8904    0.8933    0.8873    163566

F1-macro tok:  0.7942427904165172
F1-micro tok:  0.8932602130027023
**************************************************
dev_cost_sum: 42657.5947265625
dev_cost_avg: 38.74440937925749
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19078.0
dev_accuracy_tok: 0.8967754065996052
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6499068901303539
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7233160621761658
dev_label=P_precision_sent: 0.6589698046181173
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.736842105263158
dev_precision_macro_sent: 0.7696255649161571
dev_recall_macro_sent: 0.5517909861867745
dev_f-score_macro_sent: 0.48961793987107893
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.903882440391103
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.9383272986288359
dev_label=N_precision_tok: 0.7985714285714286
dev_label=N_recall_tok: 0.6020463112547119
dev_label=N_f-score_tok: 0.6865213386552043
dev_label=P_precision_tok: 0.9023060796645702
dev_label=P_recall_tok: 0.6699875466998755
dev_label=P_f-score_tok: 0.7689833839556904
dev_precision_macro_tok: 0.8682533162090339
dev_recall_macro_tok: 0.7491784154716464
dev_f-score_macro_tok: 0.7979440070799102
dev_precision_micro_tok: 0.8967754065996052
dev_recall_micro_tok: 0.8967754065996052
dev_f-score_micro_tok: 0.8967754065996052
dev_time: 8.384216547012329
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6499    0.8154    0.7233       428
           P     0.6590    0.8356    0.7368       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.7696    0.5518    0.4896      1101
weighted avg     0.7264    0.6549    0.5801      1101

F1-macro sent:  0.48961793987107893
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9039    0.9755    0.9383     16205
           N     0.7986    0.6020    0.6865      1857
           P     0.9023    0.6700    0.7690      3212

   micro avg     0.8968    0.8968    0.8968     21274
   macro avg     0.8683    0.7492    0.7979     21274
weighted avg     0.8945    0.8968    0.8908     21274

F1-macro tok:  0.7979440070799102
F1-micro tok:  0.8967754065996052
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 311758.08990478516
train_cost_avg: 36.48854048511062
train_count_sent: 8544.0
train_total_correct_sent: 5737.0
train_accuracy_sent: 0.6714653558052435
train_count_tok: 163566.0
train_total_correct_tok: 146503.0
train_accuracy_tok: 0.8956812540503528
train_label=O_precision_sent: 0.4215686274509804
train_label=O_recall_sent: 0.05295566502463054
train_label=O_f-score_sent: 0.09409190371991247
train_label=N_precision_sent: 0.6445238095238095
train_label=N_recall_sent: 0.8178247734138973
train_label=N_f-score_sent: 0.7209054593874834
train_label=P_precision_sent: 0.7111111111111111
train_label=P_recall_sent: 0.8155124653739613
train_label=P_f-score_sent: 0.7597419354838709
train_precision_macro_sent: 0.5924011826953004
train_recall_macro_sent: 0.5620976346041631
train_f-score_macro_sent: 0.5249130995304223
train_precision_micro_sent: 0.6714653558052435
train_recall_micro_sent: 0.6714653558052435
train_f-score_micro_sent: 0.6714653558052435
train_label=O_precision_tok: 0.9053003956412154
train_label=O_recall_tok: 0.9734452781329667
train_label=O_f-score_tok: 0.9381369790818975
train_label=N_precision_tok: 0.798124162572577
train_label=N_recall_tok: 0.6291367413040417
train_label=N_f-score_tok: 0.7036264125684135
train_label=P_precision_tok: 0.8852871838834119
train_label=P_recall_tok: 0.6604708798017348
train_label=P_f-score_tok: 0.7565302992147616
train_precision_macro_tok: 0.8629039140324015
train_recall_macro_tok: 0.7543509664129143
train_f-score_macro_tok: 0.7994312302883575
train_precision_micro_tok: 0.8956812540503528
train_recall_micro_tok: 0.8956812540503528
train_f-score_micro_tok: 0.8956812540503528
train_time: 144.62488341331482
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4216    0.0530    0.0941      1624
           N     0.6445    0.8178    0.7209      3310
           P     0.7111    0.8155    0.7597      3610

   micro avg     0.6715    0.6715    0.6715      8544
   macro avg     0.5924    0.5621    0.5249      8544
weighted avg     0.6303    0.6715    0.6182      8544

F1-macro sent:  0.5249130995304223
F1-micro sent:  0.6714653558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9053    0.9734    0.9381    124347
           N     0.7981    0.6291    0.7036     14202
           P     0.8853    0.6605    0.7565     25017

   micro avg     0.8957    0.8957    0.8957    163566
   macro avg     0.8629    0.7544    0.7994    163566
weighted avg     0.8929    0.8957    0.8900    163566

F1-macro tok:  0.7994312302883575
F1-micro tok:  0.8956812540503528
**************************************************
dev_cost_sum: 42543.94909667969
dev_cost_avg: 38.641189006975196
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19091.0
dev_accuracy_tok: 0.8973864811507004
dev_label=O_precision_sent: 0.9
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07531380753138077
dev_label=N_precision_sent: 0.7294117647058823
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.7268464243845252
dev_label=P_precision_sent: 0.6141141141141141
dev_label=P_recall_sent: 0.9211711711711712
dev_label=P_f-score_sent: 0.7369369369369371
dev_precision_macro_sent: 0.7478419596066654
dev_recall_macro_sent: 0.5615905155451334
dev_f-score_macro_sent: 0.5130323896176143
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9035573573916519
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.9386084583901774
dev_label=N_precision_tok: 0.7998575498575499
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.6887457835019932
dev_label=P_precision_tok: 0.9096308867204073
dev_label=P_recall_tok: 0.6674968866749689
dev_label=P_f-score_tok: 0.7699766564912911
dev_precision_macro_tok: 0.8710152646565362
dev_recall_macro_tok: 0.749574816927442
dev_f-score_macro_tok: 0.799110299461154
dev_precision_micro_tok: 0.8973864811507004
dev_recall_micro_tok: 0.8973864811507004
dev_f-score_micro_tok: 0.8973864811507004
dev_time: 8.217933177947998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9000    0.0393    0.0753       229
           N     0.7294    0.7243    0.7268       428
           P     0.6141    0.9212    0.7369       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.7478    0.5616    0.5130      1101
weighted avg     0.7184    0.6612    0.5954      1101

F1-macro sent:  0.5130323896176143
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9036    0.9765    0.9386     16205
           N     0.7999    0.6047    0.6887      1857
           P     0.9096    0.6675    0.7700      3212

   micro avg     0.8974    0.8974    0.8974     21274
   macro avg     0.8710    0.7496    0.7991     21274
weighted avg     0.8954    0.8974    0.8913     21274

F1-macro tok:  0.799110299461154
F1-micro tok:  0.8973864811507004
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 309957.5948486328
train_cost_avg: 36.27780838584186
train_count_sent: 8544.0
train_total_correct_sent: 5797.0
train_accuracy_sent: 0.6784878277153558
train_count_tok: 163566.0
train_total_correct_tok: 146723.0
train_accuracy_tok: 0.897026276854603
train_label=O_precision_sent: 0.4426229508196721
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11563169164882227
train_label=N_precision_sent: 0.6441660867548132
train_label=N_recall_sent: 0.8389728096676737
train_label=N_f-score_sent: 0.7287757512137515
train_label=P_precision_sent: 0.7300075206818751
train_label=P_recall_sent: 0.8066481994459834
train_label=P_f-score_sent: 0.7664166337676009
train_precision_macro_sent: 0.6055988527521201
train_recall_macro_sent: 0.5707078240559481
train_f-score_macro_sent: 0.5369413588767249
train_precision_micro_sent: 0.6784878277153558
train_recall_micro_sent: 0.6784878277153558
train_f-score_micro_sent: 0.6784878277153558
train_label=O_precision_tok: 0.9074467207273437
train_label=O_recall_tok: 0.9728340852614056
train_label=O_f-score_tok: 0.9390034697695359
train_label=N_precision_tok: 0.7962669484064095
train_label=N_recall_tok: 0.6368117166596254
train_label=N_f-score_tok: 0.7076682316118936
train_label=P_precision_tok: 0.884080207396434
train_label=P_recall_tok: 0.6679457968581365
train_label=P_f-score_tok: 0.7609636140079238
train_precision_macro_tok: 0.8625979588433959
train_recall_macro_tok: 0.7591971995930558
train_f-score_macro_tok: 0.8025451051297844
train_precision_micro_tok: 0.897026276854603
train_recall_micro_tok: 0.897026276854603
train_f-score_micro_tok: 0.897026276854603
train_time: 145.86027574539185
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4426    0.0665    0.1156      1624
           N     0.6442    0.8390    0.7288      3310
           P     0.7300    0.8066    0.7664      3610

   micro avg     0.6785    0.6785    0.6785      8544
   macro avg     0.6056    0.5707    0.5369      8544
weighted avg     0.6421    0.6785    0.6281      8544

F1-macro sent:  0.5369413588767249
F1-micro sent:  0.6784878277153558
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9728    0.9390    124347
           N     0.7963    0.6368    0.7077     14202
           P     0.8841    0.6679    0.7610     25017

   micro avg     0.8970    0.8970    0.8970    163566
   macro avg     0.8626    0.7592    0.8025    163566
weighted avg     0.8942    0.8970    0.8917    163566

F1-macro tok:  0.8025451051297844
F1-micro tok:  0.897026276854603
**************************************************
dev_cost_sum: 42457.23986816406
dev_cost_avg: 38.56243403103003
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19104.0
dev_accuracy_tok: 0.8979975557017956
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11155378486055777
dev_label=N_precision_sent: 0.7213114754098361
dev_label=N_recall_sent: 0.719626168224299
dev_label=N_f-score_sent: 0.7204678362573099
dev_label=P_precision_sent: 0.6165644171779141
dev_label=P_recall_sent: 0.9054054054054054
dev_label=P_f-score_sent: 0.7335766423357662
dev_precision_macro_sent: 0.6580798429837955
dev_recall_macro_sent: 0.5620556482695812
dev_f-score_macro_sent: 0.521866087817878
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9024695573005577
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.9390449687675776
dev_label=N_precision_tok: 0.8137472283813747
dev_label=N_recall_tok: 0.592891760904685
dev_label=N_f-score_tok: 0.6859813084112149
dev_label=P_precision_tok: 0.9130805283340434
dev_label=P_recall_tok: 0.6671855541718555
dev_label=P_f-score_tok: 0.7710019787731607
dev_precision_macro_tok: 0.8764324380053252
dev_recall_macro_tok: 0.7462625298943811
dev_f-score_macro_tok: 0.7986760853173177
dev_precision_micro_tok: 0.8979975557017956
dev_recall_micro_tok: 0.8979975557017956
dev_f-score_micro_tok: 0.8979975557017955
dev_time: 8.264089584350586
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0611    0.1116       229
           N     0.7213    0.7196    0.7205       428
           P     0.6166    0.9054    0.7336       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6581    0.5621    0.5219      1101
weighted avg     0.6614    0.6576    0.5991      1101

F1-macro sent:  0.521866087817878
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9787    0.9390     16205
           N     0.8137    0.5929    0.6860      1857
           P     0.9131    0.6672    0.7710      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8764    0.7463    0.7987     21274
weighted avg     0.8963    0.8980    0.8916     21274

F1-macro tok:  0.7986760853173177
F1-micro tok:  0.8979975557017955
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 308260.9375
train_cost_avg: 36.07922957631086
train_count_sent: 8544.0
train_total_correct_sent: 5796.0
train_accuracy_sent: 0.6783707865168539
train_count_tok: 163566.0
train_total_correct_tok: 147006.0
train_accuracy_tok: 0.8987564652800705
train_label=O_precision_sent: 0.49528301886792453
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11437908496732027
train_label=N_precision_sent: 0.6368869445084043
train_label=N_recall_sent: 0.8356495468277946
train_label=N_f-score_sent: 0.7228537828302627
train_label=P_precision_sent: 0.7332664828277764
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.7698381365969206
train_precision_macro_sent: 0.6218121487347018
train_recall_macro_sent: 0.5701846755736041
train_f-score_macro_sent: 0.5356903347981679
train_precision_micro_sent: 0.6783707865168539
train_recall_micro_sent: 0.6783707865168539
train_f-score_micro_sent: 0.6783707865168539
train_label=O_precision_tok: 0.9093251985483617
train_label=O_recall_tok: 0.9732683538806727
train_label=O_f-score_tok: 0.9402108468835214
train_label=N_precision_tok: 0.7962333246141774
train_label=N_recall_tok: 0.6430080270384453
train_label=N_f-score_tok: 0.711464298235363
train_label=P_precision_tok: 0.8866147532358203
train_label=P_recall_tok: 0.6735819642643003
train_label=P_f-score_tok: 0.7655543693069532
train_precision_macro_tok: 0.864057758799453
train_recall_macro_tok: 0.7632861150611395
train_f-score_macro_tok: 0.8057431714752793
train_precision_micro_tok: 0.8987564652800705
train_recall_micro_tok: 0.8987564652800705
train_f-score_micro_tok: 0.8987564652800705
train_time: 144.36656546592712
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4953    0.0647    0.1144      1624
           N     0.6369    0.8356    0.7229      3310
           P     0.7333    0.8102    0.7698      3610

   micro avg     0.6784    0.6784    0.6784      8544
   macro avg     0.6218    0.5702    0.5357      8544
weighted avg     0.6507    0.6784    0.6270      8544

F1-macro sent:  0.5356903347981679
F1-micro sent:  0.6783707865168539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9093    0.9733    0.9402    124347
           N     0.7962    0.6430    0.7115     14202
           P     0.8866    0.6736    0.7656     25017

   micro avg     0.8988    0.8988    0.8988    163566
   macro avg     0.8641    0.7633    0.8057    163566
weighted avg     0.8960    0.8988    0.8936    163566

F1-macro tok:  0.8057431714752793
F1-micro tok:  0.8987564652800705
**************************************************
dev_cost_sum: 42335.616760253906
dev_cost_avg: 38.45196799296449
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09795918367346937
dev_label=N_precision_sent: 0.6443661971830986
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.7349397590361446
dev_label=P_precision_sent: 0.7059961315280464
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7596253902185224
dev_precision_macro_sent: 0.7001207762370484
dev_recall_macro_sent: 0.5765380019042836
dev_f-score_macro_sent: 0.5308414443093787
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.89970584907795
dev_label=O_recall_tok: 0.9814871953100894
dev_label=O_f-score_tok: 0.9388188767228404
dev_label=N_precision_tok: 0.8283294842186297
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6818757921419518
dev_label=P_precision_tok: 0.9198955158902917
dev_label=P_recall_tok: 0.6578455790784558
dev_label=P_f-score_tok: 0.7671083681248865
dev_precision_macro_tok: 0.8826436163956238
dev_recall_macro_tok: 0.7395873204163577
dev_f-score_macro_tok: 0.7959343456632263
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 8.191058874130249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0524    0.0980       229
           N     0.6444    0.8551    0.7349       428
           P     0.7060    0.8221    0.7596       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.7001    0.5765    0.5308      1101
weighted avg     0.6912    0.6748    0.6124      1101

F1-macro sent:  0.5308414443093787
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8997    0.9815    0.9388     16205
           N     0.8283    0.5794    0.6819      1857
           P     0.9199    0.6578    0.7671      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8826    0.7396    0.7959     21274
weighted avg     0.8965    0.8975    0.8905     21274

F1-macro tok:  0.7959343456632263
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 306739.6362915039
train_cost_avg: 35.90117465958613
train_count_sent: 8544.0
train_total_correct_sent: 5798.0
train_accuracy_sent: 0.6786048689138576
train_count_tok: 163566.0
train_total_correct_tok: 147137.0
train_accuracy_tok: 0.8995573652226013
train_label=O_precision_sent: 0.37037037037037035
train_label=O_recall_sent: 0.08620689655172414
train_label=O_f-score_sent: 0.13986013986013987
train_label=N_precision_sent: 0.6542527630946661
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7288543897216274
train_label=P_precision_sent: 0.733016983016983
train_label=P_recall_sent: 0.8130193905817175
train_label=P_f-score_sent: 0.7709482532177567
train_precision_macro_sent: 0.5858800388273399
train_recall_macro_sent: 0.5739616324684483
train_f-score_macro_sent: 0.5465542609331747
train_precision_micro_sent: 0.6786048689138576
train_recall_micro_sent: 0.6786048689138576
train_f-score_micro_sent: 0.6786048689138576
train_label=O_precision_tok: 0.9103733128695888
train_label=O_recall_tok: 0.9731235976742503
train_label=O_f-score_tok: 0.9407031659961518
train_label=N_precision_tok: 0.8045957002350074
train_label=N_recall_tok: 0.6508942402478524
train_label=N_f-score_tok: 0.7196294422171188
train_label=P_precision_tok: 0.881465629730153
train_label=P_recall_tok: 0.6750609585481873
train_label=P_f-score_tok: 0.7645780514306412
train_precision_macro_tok: 0.8654782142782497
train_recall_macro_tok: 0.76635959882343
train_f-score_macro_tok: 0.8083035532146372
train_precision_micro_tok: 0.8995573652226013
train_recall_micro_tok: 0.8995573652226013
train_f-score_micro_tok: 0.8995573652226013
train_time: 144.77157878875732
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3704    0.0862    0.1399      1624
           N     0.6543    0.8227    0.7289      3310
           P     0.7330    0.8130    0.7709      3610

   micro avg     0.6786    0.6786    0.6786      8544
   macro avg     0.5859    0.5740    0.5466      8544
weighted avg     0.6336    0.6786    0.6347      8544

F1-macro sent:  0.5465542609331747
F1-micro sent:  0.6786048689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9104    0.9731    0.9407    124347
           N     0.8046    0.6509    0.7196     14202
           P     0.8815    0.6751    0.7646     25017

   micro avg     0.8996    0.8996    0.8996    163566
   macro avg     0.8655    0.7664    0.8083    163566
weighted avg     0.8968    0.8996    0.8946    163566

F1-macro tok:  0.8083035532146372
F1-micro tok:  0.8995573652226013
**************************************************
dev_cost_sum: 42261.123779296875
dev_cost_avg: 38.384308609715596
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19096.0
dev_accuracy_tok: 0.8976215098241985
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6698841698841699
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.733615221987315
dev_label=P_precision_sent: 0.6689895470383276
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7544204322200393
dev_precision_macro_sent: 0.7055504982334252
dev_recall_macro_sent: 0.5687267380019287
dev_f-score_macro_sent: 0.5156197278730397
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.902355752816661
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.9389265519997632
dev_label=N_precision_tok: 0.811529933481153
dev_label=N_recall_tok: 0.5912762520193862
dev_label=N_f-score_tok: 0.6841121495327104
dev_label=P_precision_tok: 0.911802300809544
dev_label=P_recall_tok: 0.6662515566625156
dev_label=P_f-score_tok: 0.7699226479582657
dev_precision_macro_tok: 0.8752293290357861
dev_recall_macro_tok: 0.7453715548635239
dev_f-score_macro_tok: 0.7976537831635797
dev_precision_micro_tok: 0.8976215098241985
dev_recall_micro_tok: 0.8976215098241985
dev_f-score_micro_tok: 0.8976215098241985
dev_time: 8.461658954620361
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6699    0.8107    0.7336       428
           P     0.6690    0.8649    0.7544       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.7056    0.5687    0.5156      1101
weighted avg     0.6920    0.6703    0.6017      1101

F1-macro sent:  0.5156197278730397
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9786    0.9389     16205
           N     0.8115    0.5913    0.6841      1857
           P     0.9118    0.6663    0.7699      3212

   micro avg     0.8976    0.8976    0.8976     21274
   macro avg     0.8752    0.7454    0.7977     21274
weighted avg     0.8959    0.8976    0.8912     21274

F1-macro tok:  0.7976537831635797
F1-micro tok:  0.8976215098241985
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 305075.50677490234
train_cost_avg: 35.706402946500745
train_count_sent: 8544.0
train_total_correct_sent: 5824.0
train_accuracy_sent: 0.6816479400749064
train_count_tok: 163566.0
train_total_correct_tok: 147498.0
train_accuracy_tok: 0.9017644253695756
train_label=O_precision_sent: 0.441025641025641
train_label=O_recall_sent: 0.05295566502463054
train_label=O_f-score_sent: 0.09455744914788344
train_label=N_precision_sent: 0.6556434219985622
train_label=N_recall_sent: 0.8265861027190332
train_label=N_f-score_sent: 0.7312575170386209
train_label=P_precision_sent: 0.7188697318007663
train_label=P_recall_sent: 0.8315789473684211
train_label=P_f-score_sent: 0.7711276650398151
train_precision_macro_sent: 0.6051795982749898
train_recall_macro_sent: 0.5703735717040282
train_f-score_macro_sent: 0.5323142104087731
train_precision_micro_sent: 0.6816479400749064
train_recall_micro_sent: 0.6816479400749064
train_f-score_micro_sent: 0.6816479400749064
train_label=O_precision_tok: 0.9127215920668342
train_label=O_recall_tok: 0.972616950951772
train_label=O_f-score_tok: 0.9417178630661777
train_label=N_precision_tok: 0.8054988083077971
train_label=N_recall_tok: 0.666314603576961
train_label=N_f-score_tok: 0.7293256262042389
train_label=P_precision_tok: 0.8851431826420175
train_label=P_recall_tok: 0.6832553863372907
train_label=P_f-score_tok: 0.7712055585634362
train_precision_macro_tok: 0.8677878610055497
train_recall_macro_tok: 0.7740623136220078
train_f-score_macro_tok: 0.8140830159446176
train_precision_micro_tok: 0.9017644253695756
train_recall_micro_tok: 0.9017644253695756
train_f-score_micro_tok: 0.9017644253695756
train_time: 144.8591628074646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4410    0.0530    0.0946      1624
           N     0.6556    0.8266    0.7313      3310
           P     0.7189    0.8316    0.7711      3610

   micro avg     0.6816    0.6816    0.6816      8544
   macro avg     0.6052    0.5704    0.5323      8544
weighted avg     0.6416    0.6816    0.6271      8544

F1-macro sent:  0.5323142104087731
F1-micro sent:  0.6816479400749064
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9127    0.9726    0.9417    124347
           N     0.8055    0.6663    0.7293     14202
           P     0.8851    0.6833    0.7712     25017

   micro avg     0.9018    0.9018    0.9018    163566
   macro avg     0.8678    0.7741    0.8141    163566
weighted avg     0.8992    0.9018    0.8972    163566

F1-macro tok:  0.8140830159446176
F1-micro tok:  0.9017644253695756
**************************************************
dev_cost_sum: 42247.69812011719
dev_cost_avg: 38.37211455051516
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19098.0
dev_accuracy_tok: 0.8977155212935978
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.667953667953668
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7315010570824525
dev_label=P_precision_sent: 0.6754850088183422
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7576656775469832
dev_precision_macro_sent: 0.65614622559067
dev_recall_macro_sent: 0.5715639832788754
dev_f-score_macro_sent: 0.5235997958968867
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9107670899286833
dev_label=O_recall_tok: 0.9693304535637149
dev_label=O_f-score_tok: 0.9391366734425445
dev_label=N_precision_tok: 0.8004231311706629
dev_label=N_recall_tok: 0.6112008616047389
dev_label=N_f-score_tok: 0.6931297709923664
dev_label=P_precision_tok: 0.8643158298198543
dev_label=P_recall_tok: 0.702054794520548
dev_label=P_f-score_tok: 0.7747809654698505
dev_precision_macro_tok: 0.8585020169730667
dev_recall_macro_tok: 0.7608620365630006
dev_f-score_macro_tok: 0.8023491366349204
dev_precision_micro_tok: 0.8977155212935978
dev_recall_micro_tok: 0.8977155212935978
dev_f-score_micro_tok: 0.8977155212935977
dev_time: 8.672128915786743
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6680    0.8084    0.7315       428
           P     0.6755    0.8626    0.7577       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6561    0.5716    0.5236      1101
weighted avg     0.6621    0.6712    0.6069      1101

F1-macro sent:  0.5235997958968867
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9108    0.9693    0.9391     16205
           N     0.8004    0.6112    0.6931      1857
           P     0.8643    0.7021    0.7748      3212

   micro avg     0.8977    0.8977    0.8977     21274
   macro avg     0.8585    0.7609    0.8023     21274
weighted avg     0.8941    0.8977    0.8928     21274

F1-macro tok:  0.8023491366349204
F1-micro tok:  0.8977155212935977
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 303579.5079345703
train_cost_avg: 35.53130944927087
train_count_sent: 8544.0
train_total_correct_sent: 5837.0
train_accuracy_sent: 0.6831694756554307
train_count_tok: 163566.0
train_total_correct_tok: 147733.0
train_accuracy_tok: 0.9032011542741156
train_label=O_precision_sent: 0.5384615384615384
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11544804837822979
train_label=N_precision_sent: 0.6551889048302247
train_label=N_recall_sent: 0.8277945619335347
train_label=N_f-score_sent: 0.7314468766684462
train_label=P_precision_sent: 0.7180225581953443
train_label=P_recall_sent: 0.8288088642659279
train_label=P_f-score_sent: 0.7694483734087695
train_precision_macro_sent: 0.6372243338290359
train_recall_macro_sent: 0.5737528662044186
train_f-score_macro_sent: 0.5387810994851484
train_precision_micro_sent: 0.6831694756554307
train_recall_micro_sent: 0.6831694756554307
train_f-score_micro_sent: 0.6831694756554307
train_label=O_precision_tok: 0.9144786083117237
train_label=O_recall_tok: 0.9727536651467265
train_label=O_f-score_tok: 0.9427164111636752
train_label=N_precision_tok: 0.8101158038147139
train_label=N_recall_tok: 0.6699056470919589
train_label=N_f-score_tok: 0.7333693054806136
train_label=P_precision_tok: 0.8828192931307861
train_label=P_recall_tok: 0.6899308470240236
train_label=P_f-score_tok: 0.77454676000718
train_precision_macro_tok: 0.8691379017524078
train_recall_macro_tok: 0.7775300530875696
train_f-score_macro_tok: 0.8168774922171563
train_precision_micro_tok: 0.9032011542741156
train_recall_micro_tok: 0.9032011542741156
train_f-score_micro_tok: 0.9032011542741156
train_time: 145.4300720691681
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5385    0.0647    0.1154      1624
           N     0.6552    0.8278    0.7314      3310
           P     0.7180    0.8288    0.7694      3610

   micro avg     0.6832    0.6832    0.6832      8544
   macro avg     0.6372    0.5738    0.5388      8544
weighted avg     0.6596    0.6832    0.6304      8544

F1-macro sent:  0.5387810994851484
F1-micro sent:  0.6831694756554307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9145    0.9728    0.9427    124347
           N     0.8101    0.6699    0.7334     14202
           P     0.8828    0.6899    0.7745     25017

   micro avg     0.9032    0.9032    0.9032    163566
   macro avg     0.8691    0.7775    0.8169    163566
weighted avg     0.9006    0.9032    0.8988    163566

F1-macro tok:  0.8168774922171563
F1-micro tok:  0.9032011542741156
**************************************************
dev_cost_sum: 42156.30743408203
dev_cost_avg: 38.2891075695568
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19155.0
dev_accuracy_tok: 0.900394848171477
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06751054852320675
dev_label=N_precision_sent: 0.7108695652173913
dev_label=N_recall_sent: 0.764018691588785
dev_label=N_f-score_sent: 0.7364864864864864
dev_label=P_precision_sent: 0.627172195892575
dev_label=P_recall_sent: 0.8941441441441441
dev_label=P_f-score_sent: 0.7372330547818013
dev_precision_macro_sent: 0.779347253703322
dev_recall_macro_sent: 0.564365777849841
dev_f-score_macro_sent: 0.5137433632638314
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9056409670229182
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9403596225743278
dev_label=N_precision_tok: 0.8229700073152889
dev_label=N_recall_tok: 0.6058158319870759
dev_label=N_f-score_tok: 0.6978908188585607
dev_label=P_precision_tok: 0.9062240663900415
dev_label=P_recall_tok: 0.6799501867995019
dev_label=P_f-score_tok: 0.7769477054429029
dev_precision_macro_tok: 0.8782783469094162
dev_recall_macro_tok: 0.7545374541692172
dev_f-score_macro_tok: 0.8050660489585972
dev_precision_micro_tok: 0.900394848171477
dev_recall_micro_tok: 0.900394848171477
dev_f-score_micro_tok: 0.900394848171477
dev_time: 8.715335607528687
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0349    0.0675       229
           N     0.7109    0.7640    0.7365       428
           P     0.6272    0.8941    0.7372       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7793    0.5644    0.5137      1101
weighted avg     0.7373    0.6649    0.5976      1101

F1-macro sent:  0.5137433632638314
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9778    0.9404     16205
           N     0.8230    0.6058    0.6979      1857
           P     0.9062    0.6800    0.7769      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8783    0.7545    0.8051     21274
weighted avg     0.8985    0.9004    0.8945     21274

F1-macro tok:  0.8050660489585972
F1-micro tok:  0.900394848171477
**************************************************
Best epoch: 22
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 301986.79803466797
train_cost_avg: 35.3448967737205
train_count_sent: 8544.0
train_total_correct_sent: 5875.0
train_accuracy_sent: 0.6876170411985019
train_count_tok: 163566.0
train_total_correct_tok: 147971.0
train_accuracy_tok: 0.9046562243987136
train_label=O_precision_sent: 0.4664429530201342
train_label=O_recall_sent: 0.08559113300492611
train_label=O_f-score_sent: 0.1446409989594173
train_label=N_precision_sent: 0.6690295771205085
train_label=N_recall_sent: 0.8268882175226586
train_label=N_f-score_sent: 0.739629779759492
train_label=P_precision_sent: 0.7217809867629362
train_label=P_recall_sent: 0.8307479224376731
train_label=P_f-score_sent: 0.7724404378622022
train_precision_macro_sent: 0.6190845056345263
train_recall_macro_sent: 0.581075757655086
train_f-score_macro_sent: 0.5522370721937038
train_precision_micro_sent: 0.6876170411985019
train_recall_micro_sent: 0.6876170411985019
train_f-score_micro_sent: 0.6876170411985019
train_label=O_precision_tok: 0.9159951529839443
train_label=O_recall_tok: 0.9726652030205795
train_label=O_f-score_tok: 0.9434799736336085
train_label=N_precision_tok: 0.8106730115567641
train_label=N_recall_tok: 0.6717363751584284
train_label=N_f-score_tok: 0.7346938775510204
train_label=P_precision_tok: 0.8848567668792388
train_label=P_recall_tok: 0.6988447855458289
train_label=P_f-score_tok: 0.780926856504746
train_precision_macro_tok: 0.8705083104733157
train_recall_macro_tok: 0.7810821212416122
train_f-score_macro_tok: 0.8197002358964584
train_precision_micro_tok: 0.9046562243987136
train_recall_micro_tok: 0.9046562243987136
train_f-score_micro_tok: 0.9046562243987136
train_time: 145.17630529403687
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4664    0.0856    0.1446      1624
           N     0.6690    0.8269    0.7396      3310
           P     0.7218    0.8307    0.7724      3610

   micro avg     0.6876    0.6876    0.6876      8544
   macro avg     0.6191    0.5811    0.5522      8544
weighted avg     0.6528    0.6876    0.6404      8544

F1-macro sent:  0.5522370721937038
F1-micro sent:  0.6876170411985019
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9160    0.9727    0.9435    124347
           N     0.8107    0.6717    0.7347     14202
           P     0.8849    0.6988    0.7809     25017

   micro avg     0.9047    0.9047    0.9047    163566
   macro avg     0.8705    0.7811    0.8197    163566
weighted avg     0.9021    0.9047    0.9005    163566

F1-macro tok:  0.8197002358964584
F1-micro tok:  0.9046562243987136
**************************************************
dev_cost_sum: 42043.937438964844
dev_cost_avg: 38.18704581195717
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19103.0
dev_accuracy_tok: 0.897950549967096
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05042016806722689
dev_label=N_precision_sent: 0.617363344051447
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7314285714285714
dev_label=P_precision_sent: 0.7319148936170212
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7527352297592999
dev_precision_macro_sent: 0.6719816347783784
dev_recall_macro_sent: 0.5660573032731544
dev_f-score_macro_sent: 0.5115279897516994
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9055695622278249
dev_label=O_recall_tok: 0.9752545510644862
dev_label=O_f-score_tok: 0.9391211337908905
dev_label=N_precision_tok: 0.7863542384562371
dev_label=N_recall_tok: 0.6144318793753366
dev_label=N_f-score_tok: 0.6898428053204353
dev_label=P_precision_tok: 0.9101644875579924
dev_label=P_recall_tok: 0.6718555417185554
dev_label=P_f-score_tok: 0.7730610782733298
dev_precision_macro_tok: 0.8673627627473515
dev_recall_macro_tok: 0.7538473240527926
dev_f-score_macro_tok: 0.8006750057948852
dev_precision_micro_tok: 0.897950549967096
dev_recall_micro_tok: 0.897950549967096
dev_f-score_micro_tok: 0.8979505499670959
dev_time: 8.439995527267456
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0262    0.0504       229
           N     0.6174    0.8972    0.7314       428
           P     0.7319    0.7748    0.7527       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6720    0.5661    0.5115      1101
weighted avg     0.6738    0.6667    0.5984      1101

F1-macro sent:  0.5115279897516994
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9753    0.9391     16205
           N     0.7864    0.6144    0.6898      1857
           P     0.9102    0.6719    0.7731      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8674    0.7538    0.8007     21274
weighted avg     0.8959    0.8980    0.8923     21274

F1-macro tok:  0.8006750057948852
F1-micro tok:  0.8979505499670959
**************************************************
Best epoch: 22
**************************************************

EPOCH: 27
Learning rate: 0.900000
train_cost_sum: 300077.2908935547
train_cost_avg: 35.12140576937672
train_count_sent: 8544.0
train_total_correct_sent: 5891.0
train_accuracy_sent: 0.6894897003745318
train_count_tok: 163566.0
train_total_correct_tok: 148311.0
train_accuracy_tok: 0.9067348960052822
train_label=O_precision_sent: 0.521551724137931
train_label=O_recall_sent: 0.07450738916256158
train_label=O_f-score_sent: 0.13038793103448276
train_label=N_precision_sent: 0.6612517916865743
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.7385272145144077
train_label=P_precision_sent: 0.7275811924381969
train_label=P_recall_sent: 0.8315789473684211
train_label=P_f-score_sent: 0.7761116856256464
train_precision_macro_sent: 0.6367949027542341
train_recall_macro_sent: 0.5807800376553427
train_f-score_macro_sent: 0.548342277058179
train_precision_micro_sent: 0.6894897003745318
train_recall_micro_sent: 0.6894897003745318
train_f-score_micro_sent: 0.6894897003745318
train_label=O_precision_tok: 0.9191512976843897
train_label=O_recall_tok: 0.9723354805503953
train_label=O_f-score_tok: 0.9449956817213714
train_label=N_precision_tok: 0.8106420184861354
train_label=N_recall_tok: 0.6854668356569498
train_label=N_f-score_tok: 0.7428179008813093
train_label=P_precision_tok: 0.8827879090681988
train_label=P_recall_tok: 0.7062797297837471
train_label=P_f-score_tok: 0.7847308580564931
train_precision_macro_tok: 0.870860408412908
train_recall_macro_tok: 0.7880273486636974
train_f-score_macro_tok: 0.8241814802197246
train_precision_micro_tok: 0.9067348960052822
train_recall_micro_tok: 0.9067348960052822
train_f-score_micro_tok: 0.9067348960052822
train_time: 145.34281706809998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5216    0.0745    0.1304      1624
           N     0.6613    0.8363    0.7385      3310
           P     0.7276    0.8316    0.7761      3610

   micro avg     0.6895    0.6895    0.6895      8544
   macro avg     0.6368    0.5808    0.5483      8544
weighted avg     0.6627    0.6895    0.6388      8544

F1-macro sent:  0.548342277058179
F1-micro sent:  0.6894897003745318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9192    0.9723    0.9450    124347
           N     0.8106    0.6855    0.7428     14202
           P     0.8828    0.7063    0.7847     25017

   micro avg     0.9067    0.9067    0.9067    163566
   macro avg     0.8709    0.7880    0.8242    163566
weighted avg     0.9042    0.9067    0.9029    163566

F1-macro tok:  0.8241814802197246
F1-micro tok:  0.9067348960052822
**************************************************
dev_cost_sum: 42032.47186279297
dev_cost_avg: 38.17663202796818
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19157.0
dev_accuracy_tok: 0.9004888596408762
dev_label=O_precision_sent: 0.6923076923076923
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0743801652892562
dev_label=N_precision_sent: 0.6323777403035413
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7345739471106758
dev_label=P_precision_sent: 0.7151515151515152
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.7539936102236422
dev_precision_macro_sent: 0.6799456492542496
dev_recall_macro_sent: 0.5709222772133437
dev_f-score_macro_sent: 0.5209825742078581
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9075263882514915
dev_label=O_recall_tok: 0.9762419006479481
dev_label=O_f-score_tok: 0.9406308529298094
dev_label=N_precision_tok: 0.7993079584775087
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.6995760145366444
dev_label=P_precision_tok: 0.9103045473508552
dev_label=P_recall_tok: 0.6793275217932753
dev_label=P_f-score_tok: 0.7780353004100553
dev_precision_macro_tok: 0.8723796313599518
dev_recall_macro_tok: 0.759180114427096
dev_f-score_macro_tok: 0.8060807226255031
dev_precision_micro_tok: 0.9004888596408762
dev_recall_micro_tok: 0.9004888596408762
dev_f-score_micro_tok: 0.9004888596408761
dev_time: 8.349987268447876
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6923    0.0393    0.0744       229
           N     0.6324    0.8762    0.7346       428
           P     0.7152    0.7973    0.7540       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6799    0.5709    0.5210      1101
weighted avg     0.6782    0.6703    0.6051      1101

F1-macro sent:  0.5209825742078581
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9075    0.9762    0.9406     16205
           N     0.7993    0.6220    0.6996      1857
           P     0.9103    0.6793    0.7780      3212

   micro avg     0.9005    0.9005    0.9005     21274
   macro avg     0.8724    0.7592    0.8061     21274
weighted avg     0.8985    0.9005    0.8950     21274

F1-macro tok:  0.8060807226255031
F1-micro tok:  0.9004888596408761
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 0.900000
train_cost_sum: 299172.6181640625
train_cost_avg: 35.015521788864994
train_count_sent: 8544.0
train_total_correct_sent: 5879.0
train_accuracy_sent: 0.6880852059925093
train_count_tok: 163566.0
train_total_correct_tok: 148561.0
train_accuracy_tok: 0.9082633310101121
train_label=O_precision_sent: 0.4784172661870504
train_label=O_recall_sent: 0.08189655172413793
train_label=O_f-score_sent: 0.1398527865404837
train_label=N_precision_sent: 0.6581583969465649
train_label=N_recall_sent: 0.8335347432024169
train_label=N_f-score_sent: 0.7355371900826445
train_label=P_precision_sent: 0.7331860579283259
train_label=P_recall_sent: 0.8274238227146814
train_label=P_f-score_sent: 0.7774596564289432
train_precision_macro_sent: 0.6232539070206471
train_recall_macro_sent: 0.5809517058804121
train_f-score_macro_sent: 0.5509498776840238
train_precision_micro_sent: 0.6880852059925093
train_recall_micro_sent: 0.6880852059925093
train_f-score_micro_sent: 0.6880852059925093
train_label=O_precision_tok: 0.920028287037389
train_label=O_recall_tok: 0.9730190515251674
train_label=O_f-score_tok: 0.9457820023763368
train_label=N_precision_tok: 0.8131622516556292
train_label=N_recall_tok: 0.6916631460357696
train_label=N_f-score_tok: 0.7475078000152195
train_label=P_precision_tok: 0.8883215698052761
train_label=P_recall_tok: 0.7093576368069713
train_label=P_f-score_tok: 0.7888162866159933
train_precision_macro_tok: 0.8738373694994315
train_recall_macro_tok: 0.7913466114559694
train_f-score_macro_tok: 0.8273686963358499
train_precision_micro_tok: 0.9082633310101121
train_recall_micro_tok: 0.9082633310101121
train_f-score_micro_tok: 0.9082633310101121
train_time: 144.56296682357788
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4784    0.0819    0.1399      1624
           N     0.6582    0.8335    0.7355      3310
           P     0.7332    0.8274    0.7775      3610

   micro avg     0.6881    0.6881    0.6881      8544
   macro avg     0.6233    0.5810    0.5509      8544
weighted avg     0.6557    0.6881    0.6400      8544

F1-macro sent:  0.5509498776840238
F1-micro sent:  0.6880852059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9200    0.9730    0.9458    124347
           N     0.8132    0.6917    0.7475     14202
           P     0.8883    0.7094    0.7888     25017

   micro avg     0.9083    0.9083    0.9083    163566
   macro avg     0.8738    0.7913    0.8274    163566
weighted avg     0.9059    0.9083    0.9046    163566

F1-macro tok:  0.8273686963358499
F1-micro tok:  0.9082633310101121
**************************************************
dev_cost_sum: 41943.46856689453
dev_cost_avg: 38.09579343042192
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.43243243243243246
dev_label=O_recall_sent: 0.13973799126637554
dev_label=O_f-score_sent: 0.21122112211221122
dev_label=N_precision_sent: 0.6598890942698706
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.736842105263158
dev_label=P_precision_sent: 0.7242798353909465
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7569892473118279
dev_precision_macro_sent: 0.6055337873644165
dev_recall_macro_sent: 0.5888809778639595
dev_f-score_macro_sent: 0.5683508248957324
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.910188286935428
dev_label=O_recall_tok: 0.9724776303609997
dev_label=O_f-score_tok: 0.9403025149914974
dev_label=N_precision_tok: 0.7908232118758435
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.7020065887990417
dev_label=P_precision_tok: 0.8950766747376917
dev_label=P_recall_tok: 0.6905354919053549
dev_label=P_f-score_tok: 0.7796133567662565
dev_precision_macro_tok: 0.865362724516321
dev_recall_macro_tok: 0.764712864485482
dev_f-score_macro_tok: 0.8073074868522653
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 8.541415214538574
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4324    0.1397    0.2112       229
           N     0.6599    0.8341    0.7368       428
           P     0.7243    0.7928    0.7570       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6055    0.5889    0.5684      1101
weighted avg     0.6385    0.6730    0.6356      1101

F1-macro sent:  0.5683508248957324
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9725    0.9403     16205
           N     0.7908    0.6311    0.7020      1857
           P     0.8951    0.6905    0.7796      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8654    0.7647    0.8073     21274
weighted avg     0.8975    0.9001    0.8952     21274

F1-macro tok:  0.8073074868522653
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 297666.26525878906
train_cost_avg: 34.83921643946501
train_count_sent: 8544.0
train_total_correct_sent: 5900.0
train_accuracy_sent: 0.6905430711610487
train_count_tok: 163566.0
train_total_correct_tok: 148854.0
train_accuracy_tok: 0.9100546568357727
train_label=O_precision_sent: 0.46408839779005523
train_label=O_recall_sent: 0.10344827586206896
train_label=O_f-score_sent: 0.16918429003021146
train_label=N_precision_sent: 0.6643440653531956
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7400963597430408
train_label=P_precision_sent: 0.7380597014925373
train_label=P_recall_sent: 0.8218836565096953
train_label=P_f-score_sent: 0.7777195281782437
train_precision_macro_sent: 0.622164054878596
train_recall_macro_sent: 0.5868931214653111
train_f-score_macro_sent: 0.5623333926504986
train_precision_micro_sent: 0.6905430711610487
train_recall_micro_sent: 0.6905430711610487
train_f-score_micro_sent: 0.6905430711610487
train_label=O_precision_tok: 0.9225002478588806
train_label=O_recall_tok: 0.9727697491696623
train_label=O_f-score_tok: 0.9469683328766587
train_label=N_precision_tok: 0.8164457980080665
train_label=N_recall_tok: 0.6984227573581185
train_label=N_f-score_tok: 0.7528367044893932
train_label=P_precision_tok: 0.8856804966985315
train_label=P_recall_tok: 0.7184714394211936
train_label=P_f-score_tok: 0.7933614354130344
train_precision_macro_tok: 0.8748755141884929
train_recall_macro_tok: 0.7965546486496581
train_f-score_macro_tok: 0.8310554909263622
train_precision_micro_tok: 0.9100546568357727
train_recall_micro_tok: 0.9100546568357727
train_f-score_micro_tok: 0.9100546568357727
train_time: 145.213397026062
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4641    0.1034    0.1692      1624
           N     0.6643    0.8353    0.7401      3310
           P     0.7381    0.8219    0.7777      3610

   micro avg     0.6905    0.6905    0.6905      8544
   macro avg     0.6222    0.5869    0.5623      8544
weighted avg     0.6574    0.6905    0.6475      8544

F1-macro sent:  0.5623333926504986
F1-micro sent:  0.6905430711610487
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9225    0.9728    0.9470    124347
           N     0.8164    0.6984    0.7528     14202
           P     0.8857    0.7185    0.7934     25017

   micro avg     0.9101    0.9101    0.9101    163566
   macro avg     0.8749    0.7966    0.8311    163566
weighted avg     0.9077    0.9101    0.9066    163566

F1-macro tok:  0.8310554909263622
F1-micro tok:  0.9100546568357727
**************************************************
dev_cost_sum: 41886.895568847656
dev_cost_avg: 38.0444101442758
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19078.0
dev_accuracy_tok: 0.8967754065996052
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09599999999999999
dev_label=N_precision_sent: 0.6610800744878957
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7357512953367876
dev_label=P_precision_sent: 0.6795580110497238
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7477203647416413
dev_precision_macro_sent: 0.6373555523220636
dev_recall_macro_sent: 0.5709740267141402
dev_f-score_macro_sent: 0.5264905533594763
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9130815480707489
dev_label=O_recall_tok: 0.9652576365319346
dev_label=O_f-score_tok: 0.9384449244060475
dev_label=N_precision_tok: 0.7690288713910761
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6932860100561965
dev_label=P_precision_tok: 0.8644520809469263
dev_label=P_recall_tok: 0.7048567870485679
dev_label=P_f-score_tok: 0.776539187103413
dev_precision_macro_tok: 0.8488541668029171
dev_recall_macro_tok: 0.7670799649235315
dev_f-score_macro_tok: 0.8027567071885523
dev_precision_micro_tok: 0.8967754065996052
dev_recall_micro_tok: 0.8967754065996052
dev_f-score_micro_tok: 0.8967754065996052
dev_time: 8.190780878067017
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0524    0.0960       229
           N     0.6611    0.8294    0.7358       428
           P     0.6796    0.8311    0.7477       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6374    0.5710    0.5265      1101
weighted avg     0.6499    0.6685    0.6075      1101

F1-macro sent:  0.5264905533594763
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9131    0.9653    0.9384     16205
           N     0.7690    0.6311    0.6933      1857
           P     0.8645    0.7049    0.7765      3212

   micro avg     0.8968    0.8968    0.8968     21274
   macro avg     0.8489    0.7671    0.8028     21274
weighted avg     0.8932    0.8968    0.8926     21274

F1-macro tok:  0.8027567071885523
F1-micro tok:  0.8967754065996052
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.900000
train_cost_sum: 296168.8522338867
train_cost_avg: 34.663957424378125
train_count_sent: 8544.0
train_total_correct_sent: 5977.0
train_accuracy_sent: 0.6995552434456929
train_count_tok: 163566.0
train_total_correct_tok: 149058.0
train_accuracy_tok: 0.9113018597997139
train_label=O_precision_sent: 0.4835164835164835
train_label=O_recall_sent: 0.0812807881773399
train_label=O_f-score_sent: 0.13916710595677384
train_label=N_precision_sent: 0.6608173631955668
train_label=N_recall_sent: 0.8646525679758308
train_label=N_f-score_sent: 0.7491166077738517
train_label=P_precision_sent: 0.7571065989847716
train_label=P_recall_sent: 0.8263157894736842
train_label=P_f-score_sent: 0.7901986754966889
train_precision_macro_sent: 0.6338134818989406
train_recall_macro_sent: 0.5907497152089517
train_f-score_macro_sent: 0.5594941297424382
train_precision_micro_sent: 0.6995552434456929
train_recall_micro_sent: 0.6995552434456929
train_f-score_micro_sent: 0.6995552434456929
train_label=O_precision_tok: 0.9236561931965723
train_label=O_recall_tok: 0.9725847829059004
train_label=O_f-score_tok: 0.9474892373502142
train_label=N_precision_tok: 0.8207207207207208
train_label=N_recall_tok: 0.7056048443881143
train_label=N_f-score_tok: 0.7588217476904436
train_label=P_precision_tok: 0.8862501224170013
train_label=P_recall_tok: 0.7234680417316225
train_label=P_f-score_tok: 0.7966284469288496
train_precision_macro_tok: 0.8768756787780981
train_recall_macro_tok: 0.800552556341879
train_f-score_macro_tok: 0.8343131439898358
train_precision_micro_tok: 0.9113018597997139
train_recall_micro_tok: 0.9113018597997139
train_f-score_micro_tok: 0.9113018597997139
train_time: 113.77669286727905
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4835    0.0813    0.1392      1624
           N     0.6608    0.8647    0.7491      3310
           P     0.7571    0.8263    0.7902      3610

   micro avg     0.6996    0.6996    0.6996      8544
   macro avg     0.6338    0.5907    0.5595      8544
weighted avg     0.6678    0.6996    0.6505      8544

F1-macro sent:  0.5594941297424382
F1-micro sent:  0.6995552434456929
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9237    0.9726    0.9475    124347
           N     0.8207    0.7056    0.7588     14202
           P     0.8863    0.7235    0.7966     25017

   micro avg     0.9113    0.9113    0.9113    163566
   macro avg     0.8769    0.8006    0.8343    163566
weighted avg     0.9090    0.9113    0.9080    163566

F1-macro tok:  0.8343131439898358
F1-micro tok:  0.9113018597997139
**************************************************
dev_cost_sum: 41971.15606689453
dev_cost_avg: 38.1209410235191
dev_count_sent: 1101.0
dev_total_correct_sent: 748.0
dev_accuracy_sent: 0.6793823796548593
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.7619047619047619
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.128
dev_label=N_precision_sent: 0.6432246998284734
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7418397626112759
dev_label=P_precision_sent: 0.7183098591549296
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7587672688629119
dev_precision_macro_sent: 0.7078131069627216
dev_recall_macro_sent: 0.5833637579954357
dev_f-score_macro_sent: 0.5428690104913959
dev_precision_micro_sent: 0.6793823796548593
dev_recall_micro_sent: 0.6793823796548593
dev_f-score_micro_sent: 0.6793823796548593
dev_label=O_precision_tok: 0.9101512876775609
dev_label=O_recall_tok: 0.9726627584078988
dev_label=O_f-score_tok: 0.9403692986904514
dev_label=N_precision_tok: 0.8040873854827343
dev_label=N_recall_tok: 0.6144318793753366
dev_label=N_f-score_tok: 0.6965811965811967
dev_label=P_precision_tok: 0.8856917619235317
dev_label=P_recall_tok: 0.6995641344956414
dev_label=P_f-score_tok: 0.7817011654200731
dev_precision_macro_tok: 0.8666434783612756
dev_recall_macro_tok: 0.7622195907596256
dev_f-score_macro_tok: 0.8062172202305736
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 5.176340579986572
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7619    0.0699    0.1280       229
           N     0.6432    0.8762    0.7418       428
           P     0.7183    0.8041    0.7588       444

   micro avg     0.6794    0.6794    0.6794      1101
   macro avg     0.7078    0.5834    0.5429      1101
weighted avg     0.6982    0.6794    0.6210      1101

F1-macro sent:  0.5428690104913959
F1-micro sent:  0.6793823796548593
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9727    0.9404     16205
           N     0.8041    0.6144    0.6966      1857
           P     0.8857    0.6996    0.7817      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8666    0.7622    0.8062     21274
weighted avg     0.8972    0.9002    0.8951     21274

F1-macro tok:  0.8062172202305736
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.900000
train_cost_sum: 294942.3792114258
train_cost_avg: 34.520409551899085
train_count_sent: 8544.0
train_total_correct_sent: 6006.0
train_accuracy_sent: 0.7029494382022472
train_count_tok: 163566.0
train_total_correct_tok: 149287.0
train_accuracy_tok: 0.912701906264138
train_label=O_precision_sent: 0.5177865612648221
train_label=O_recall_sent: 0.08066502463054187
train_label=O_f-score_sent: 0.1395844432605221
train_label=N_precision_sent: 0.6862453531598512
train_label=N_recall_sent: 0.8365558912386707
train_label=N_f-score_sent: 0.7539823008849558
train_label=P_precision_sent: 0.7297932330827067
train_label=P_recall_sent: 0.8603878116343491
train_label=P_f-score_sent: 0.7897279430460208
train_precision_macro_sent: 0.6446083825024601
train_recall_macro_sent: 0.5925362425011872
train_f-score_macro_sent: 0.5610982290638329
train_precision_micro_sent: 0.7029494382022472
train_recall_micro_sent: 0.7029494382022472
train_f-score_micro_sent: 0.7029494382022472
train_label=O_precision_tok: 0.9256776941165656
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.948214986269125
train_label=N_precision_tok: 0.8208614933637326
train_label=N_recall_tok: 0.7098296014645824
train_label=N_f-score_tok: 0.7613185817316769
train_label=P_precision_tok: 0.8853945591356357
train_label=P_recall_tok: 0.7337410560818644
train_label=P_f-score_tok: 0.8024656276639927
train_precision_macro_tok: 0.877311248871978
train_recall_macro_tok: 0.8051492478143905
train_f-score_macro_tok: 0.8373330652215981
train_precision_micro_tok: 0.912701906264138
train_recall_micro_tok: 0.912701906264138
train_f-score_micro_tok: 0.9127019062641379
train_time: 95.26433086395264
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5178    0.0807    0.1396      1624
           N     0.6862    0.8366    0.7540      3310
           P     0.7298    0.8604    0.7897      3610

   micro avg     0.7029    0.7029    0.7029      8544
   macro avg     0.6446    0.5925    0.5611      8544
weighted avg     0.6726    0.7029    0.6523      8544

F1-macro sent:  0.5610982290638329
F1-micro sent:  0.7029494382022472
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9257    0.9719    0.9482    124347
           N     0.8209    0.7098    0.7613     14202
           P     0.8854    0.7337    0.8025     25017

   micro avg     0.9127    0.9127    0.9127    163566
   macro avg     0.8773    0.8051    0.8373    163566
weighted avg     0.9104    0.9127    0.9097    163566

F1-macro tok:  0.8373330652215981
F1-micro tok:  0.9127019062641379
**************************************************
dev_cost_sum: 41906.6591796875
dev_cost_avg: 38.062360744493645
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19178.0
dev_accuracy_tok: 0.9014759800695685
dev_label=O_precision_sent: 0.6842105263157895
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10483870967741936
dev_label=N_precision_sent: 0.6603415559772297
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7287958115183247
dev_label=P_precision_sent: 0.6756756756756757
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7507507507507508
dev_precision_macro_sent: 0.6734092526562317
dev_recall_macro_sent: 0.5714824218986975
dev_f-score_macro_sent: 0.528128423982165
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9089236430542779
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.9410364020597077
dev_label=N_precision_tok: 0.8089171974522293
dev_label=N_recall_tok: 0.6155088852988692
dev_label=N_f-score_tok: 0.6990825688073395
dev_label=P_precision_tok: 0.9019846091535034
dev_label=P_recall_tok: 0.6933374844333748
dev_label=P_f-score_tok: 0.7840168984333745
dev_precision_macro_tok: 0.8732751498866702
dev_recall_macro_tok: 0.7614492527308653
dev_f-score_macro_tok: 0.8080452897668073
dev_precision_micro_tok: 0.9014759800695685
dev_recall_micro_tok: 0.9014759800695685
dev_f-score_micro_tok: 0.9014759800695685
dev_time: 5.169453382492065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6842    0.0568    0.1048       229
           N     0.6603    0.8131    0.7288       428
           P     0.6757    0.8446    0.7508       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6734    0.5715    0.5281      1101
weighted avg     0.6715    0.6685    0.6079      1101

F1-macro sent:  0.528128423982165
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9089    0.9755    0.9410     16205
           N     0.8089    0.6155    0.6991      1857
           P     0.9020    0.6933    0.7840      3212

   micro avg     0.9015    0.9015    0.9015     21274
   macro avg     0.8733    0.7614    0.8080     21274
weighted avg     0.8991    0.9015    0.8962     21274

F1-macro tok:  0.8080452897668073
F1-micro tok:  0.9014759800695685
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.900000
train_cost_sum: 293792.1123046875
train_cost_avg: 34.385780934537394
train_count_sent: 8544.0
train_total_correct_sent: 6012.0
train_accuracy_sent: 0.7036516853932584
train_count_tok: 163566.0
train_total_correct_tok: 149596.0
train_accuracy_tok: 0.9145910519301077
train_label=O_precision_sent: 0.5021097046413502
train_label=O_recall_sent: 0.07327586206896551
train_label=O_f-score_sent: 0.12788823213326167
train_label=N_precision_sent: 0.6789650215620507
train_label=N_recall_sent: 0.8561933534743202
train_label=N_f-score_sent: 0.7573490112239445
train_label=P_precision_sent: 0.740140333897895
train_label=P_recall_sent: 0.8473684210526315
train_label=P_f-score_sent: 0.7901330233759524
train_precision_macro_sent: 0.6404050200337653
train_recall_macro_sent: 0.5922792121986391
train_f-score_macro_sent: 0.5584567555777196
train_precision_micro_sent: 0.7036516853932584
train_recall_micro_sent: 0.7036516853932584
train_f-score_micro_sent: 0.7036516853932584
train_label=O_precision_tok: 0.9272383054718818
train_label=O_recall_tok: 0.9728742953187451
train_label=O_f-score_tok: 0.9495082687764409
train_label=N_precision_tok: 0.8219067591547023
train_label=N_recall_tok: 0.7175045768201662
train_label=N_f-score_tok: 0.7661654135338346
train_label=P_precision_tok: 0.8903917685135984
train_label=P_recall_tok: 0.7367789902866051
train_label=P_f-score_tok: 0.8063344853230674
train_precision_macro_tok: 0.8798456110467274
train_recall_macro_tok: 0.8090526208085054
train_f-score_macro_tok: 0.8406693892111144
train_precision_micro_tok: 0.9145910519301077
train_recall_micro_tok: 0.9145910519301077
train_f-score_micro_tok: 0.9145910519301077
train_time: 61.689006328582764
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5021    0.0733    0.1279      1624
           N     0.6790    0.8562    0.7573      3310
           P     0.7401    0.8474    0.7901      3610

   micro avg     0.7037    0.7037    0.7037      8544
   macro avg     0.6404    0.5923    0.5585      8544
weighted avg     0.6712    0.7037    0.6516      8544

F1-macro sent:  0.5584567555777196
F1-micro sent:  0.7036516853932584
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9272    0.9729    0.9495    124347
           N     0.8219    0.7175    0.7662     14202
           P     0.8904    0.7368    0.8063     25017

   micro avg     0.9146    0.9146    0.9146    163566
   macro avg     0.8798    0.8091    0.8407    163566
weighted avg     0.9125    0.9146    0.9117    163566

F1-macro tok:  0.8406693892111144
F1-micro tok:  0.9145910519301077
**************************************************
dev_cost_sum: 41945.23486328125
dev_cost_avg: 38.0973976959866
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19106.0
dev_accuracy_tok: 0.8980915671711949
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08032128514056225
dev_label=N_precision_sent: 0.6635160680529301
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7335423197492162
dev_label=P_precision_sent: 0.6793478260869565
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.753012048192771
dev_precision_macro_sent: 0.6142879647132955
dev_recall_macro_sent: 0.5694520582697541
dev_f-score_macro_sent: 0.5222918843608498
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9127168976359613
dev_label=O_recall_tok: 0.9672940450478248
dev_label=O_f-score_tok: 0.9392132778094011
dev_label=N_precision_tok: 0.7788141239173884
dev_label=N_recall_tok: 0.6295099623047927
dev_label=N_f-score_tok: 0.696247766527695
dev_label=P_precision_tok: 0.8703347441323586
dev_label=P_recall_tok: 0.7042341220423413
dev_label=P_f-score_tok: 0.7785234899328859
dev_precision_macro_tok: 0.8539552552285694
dev_recall_macro_tok: 0.7670127097983196
dev_f-score_macro_tok: 0.8046615114233274
dev_precision_micro_tok: 0.8980915671711949
dev_recall_micro_tok: 0.8980915671711949
dev_f-score_micro_tok: 0.8980915671711949
dev_time: 2.4855055809020996
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0437    0.0803       229
           N     0.6635    0.8201    0.7335       428
           P     0.6793    0.8446    0.7530       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6143    0.5695    0.5223      1101
weighted avg     0.6359    0.6685    0.6055      1101

F1-macro sent:  0.5222918843608498
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9127    0.9673    0.9392     16205
           N     0.7788    0.6295    0.6962      1857
           P     0.8703    0.7042    0.7785      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8540    0.7670    0.8047     21274
weighted avg     0.8946    0.8981    0.8937     21274

F1-macro tok:  0.8046615114233274
F1-micro tok:  0.8980915671711949
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.810000
train_cost_sum: 292002.1180419922
train_cost_avg: 34.176277860720056
train_count_sent: 8544.0
train_total_correct_sent: 6026.0
train_accuracy_sent: 0.7052902621722846
train_count_tok: 163566.0
train_total_correct_tok: 149977.0
train_accuracy_tok: 0.9169203868774685
train_label=O_precision_sent: 0.5530973451327433
train_label=O_recall_sent: 0.0769704433497537
train_label=O_f-score_sent: 0.13513513513513514
train_label=N_precision_sent: 0.6803357314148681
train_label=N_recall_sent: 0.8570996978851964
train_label=N_f-score_sent: 0.7585561497326203
train_label=P_precision_sent: 0.7386692381870781
train_label=P_recall_sent: 0.8487534626038781
train_label=P_f-score_sent: 0.7898943026553236
train_precision_macro_sent: 0.6573674382448965
train_recall_macro_sent: 0.5942745346129427
train_f-score_macro_sent: 0.5611951958410263
train_precision_micro_sent: 0.7052902621722846
train_recall_micro_sent: 0.7052902621722846
train_f-score_micro_sent: 0.7052902621722846
train_label=O_precision_tok: 0.9296334145235772
train_label=O_recall_tok: 0.9729949254907637
train_label=O_f-score_tok: 0.9508200586261365
train_label=N_precision_tok: 0.8305755105335378
train_label=N_recall_tok: 0.7245458386142797
train_label=N_f-score_tok: 0.7739460719792411
train_label=P_precision_tok: 0.8891107941036615
train_label=P_recall_tok: 0.7474117600031979
train_label=P_f-score_tok: 0.8121267400699286
train_precision_macro_tok: 0.8831065730535922
train_recall_macro_tok: 0.814984174702747
train_f-score_macro_tok: 0.8456309568917687
train_precision_micro_tok: 0.9169203868774685
train_recall_micro_tok: 0.9169203868774685
train_f-score_micro_tok: 0.9169203868774685
train_time: 50.95437169075012
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5531    0.0770    0.1351      1624
           N     0.6803    0.8571    0.7586      3310
           P     0.7387    0.8488    0.7899      3610

   micro avg     0.7053    0.7053    0.7053      8544
   macro avg     0.6574    0.5943    0.5612      8544
weighted avg     0.6808    0.7053    0.6533      8544

F1-macro sent:  0.5611951958410263
F1-micro sent:  0.7052902621722846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9296    0.9730    0.9508    124347
           N     0.8306    0.7245    0.7739     14202
           P     0.8891    0.7474    0.8121     25017

   micro avg     0.9169    0.9169    0.9169    163566
   macro avg     0.8831    0.8150    0.8456    163566
weighted avg     0.9148    0.9169    0.9142    163566

F1-macro tok:  0.8456309568917687
F1-micro tok:  0.9169203868774685
**************************************************
dev_cost_sum: 41962.745849609375
dev_cost_avg: 38.113302315721505
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.7058823529411765
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0975609756097561
dev_label=N_precision_sent: 0.7191011235955056
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.7331042382588774
dev_label=P_precision_sent: 0.6306729264475743
dev_label=P_recall_sent: 0.9076576576576577
dev_label=P_f-score_sent: 0.7442289935364729
dev_precision_macro_sent: 0.6852188009947522
dev_recall_macro_sent: 0.5692409852614726
dev_f-score_macro_sent: 0.5249647358017021
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9123152709359605
dev_label=O_recall_tok: 0.9714285714285714
dev_label=O_f-score_tok: 0.9409444112372983
dev_label=N_precision_tok: 0.7940974605353466
dev_label=N_recall_tok: 0.6230479267635972
dev_label=N_f-score_tok: 0.6982498491249246
dev_label=P_precision_tok: 0.8836846213895394
dev_label=P_recall_tok: 0.7048567870485679
dev_label=P_f-score_tok: 0.7842050571527537
dev_precision_macro_tok: 0.8633657842869488
dev_recall_macro_tok: 0.7664444284135788
dev_f-score_macro_tok: 0.8077997725049922
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 2.4729089736938477
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7059    0.0524    0.0976       229
           N     0.7191    0.7477    0.7331       428
           P     0.6307    0.9077    0.7442       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6852    0.5692    0.5250      1101
weighted avg     0.6807    0.6676    0.6054      1101

F1-macro sent:  0.5249647358017021
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9714    0.9409     16205
           N     0.7941    0.6230    0.6982      1857
           P     0.8837    0.7049    0.7842      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8634    0.7664    0.8078     21274
weighted avg     0.8977    0.9008    0.8961     21274

F1-macro tok:  0.8077997725049922
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.729000
train_cost_sum: 290779.4147949219
train_cost_avg: 34.03317120727082
train_count_sent: 8544.0
train_total_correct_sent: 5959.0
train_accuracy_sent: 0.6974485018726592
train_count_tok: 163566.0
train_total_correct_tok: 150372.0
train_accuracy_tok: 0.9193353141850996
train_label=O_precision_sent: 0.42359249329758714
train_label=O_recall_sent: 0.09729064039408868
train_label=O_f-score_sent: 0.15823735603405106
train_label=N_precision_sent: 0.6743961352657005
train_label=N_recall_sent: 0.8435045317220544
train_label=N_f-score_sent: 0.749530201342282
train_label=P_precision_sent: 0.7464648970478789
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7875932469572047
train_precision_macro_sent: 0.6148178418703888
train_recall_macro_sent: 0.5914377258854364
train_f-score_macro_sent: 0.5651202681111792
train_precision_micro_sent: 0.6974485018726592
train_recall_micro_sent: 0.6974485018726592
train_f-score_micro_sent: 0.6974485018726592
train_label=O_precision_tok: 0.9323549803559048
train_label=O_recall_tok: 0.9733166059494801
train_label=O_f-score_tok: 0.9523955665199069
train_label=N_precision_tok: 0.8346588197868617
train_label=N_recall_tok: 0.7389804252922124
train_label=N_f-score_tok: 0.7839109650433225
train_label=P_precision_tok: 0.8898121046171278
train_label=P_recall_tok: 0.7534076827757125
train_label=P_f-score_tok: 0.8159483971514535
train_precision_macro_tok: 0.8856086349199649
train_recall_macro_tok: 0.821901571339135
train_f-score_macro_tok: 0.8507516429048944
train_precision_micro_tok: 0.9193353141850996
train_recall_micro_tok: 0.9193353141850996
train_f-score_micro_tok: 0.9193353141850996
train_time: 50.76669764518738
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4236    0.0973    0.1582      1624
           N     0.6744    0.8435    0.7495      3310
           P     0.7465    0.8335    0.7876      3610

   micro avg     0.6974    0.6974    0.6974      8544
   macro avg     0.6148    0.5914    0.5651      8544
weighted avg     0.6572    0.6974    0.6532      8544

F1-macro sent:  0.5651202681111792
F1-micro sent:  0.6974485018726592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9324    0.9733    0.9524    124347
           N     0.8347    0.7390    0.7839     14202
           P     0.8898    0.7534    0.8159     25017

   micro avg     0.9193    0.9193    0.9193    163566
   macro avg     0.8856    0.8219    0.8508    163566
weighted avg     0.9174    0.9193    0.9169    163566

F1-macro tok:  0.8507516429048944
F1-micro tok:  0.9193353141850996
**************************************************
dev_cost_sum: 42014.52899169922
dev_cost_avg: 38.16033514232445
dev_count_sent: 1101.0
dev_total_correct_sent: 751.0
dev_accuracy_sent: 0.6821071752951862
dev_count_tok: 21274.0
dev_total_correct_tok: 19092.0
dev_accuracy_tok: 0.8974334868854
dev_label=O_precision_sent: 0.4805194805194805
dev_label=O_recall_sent: 0.1615720524017467
dev_label=O_f-score_sent: 0.2418300653594771
dev_label=N_precision_sent: 0.6830708661417323
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7414529914529915
dev_label=P_precision_sent: 0.7112403100775194
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7645833333333334
dev_precision_macro_sent: 0.624943552246244
dev_recall_macro_sent: 0.5996320975099083
dev_f-score_macro_sent: 0.5826221300486006
dev_precision_micro_sent: 0.6821071752951862
dev_recall_micro_sent: 0.6821071752951862
dev_f-score_micro_sent: 0.6821071752951862
dev_label=O_precision_tok: 0.912481062813192
dev_label=O_recall_tok: 0.9663684048133292
dev_label=O_f-score_tok: 0.9386519615188659
dev_label=N_precision_tok: 0.778
dev_label=N_recall_tok: 0.6284329563812601
dev_label=N_f-score_tok: 0.6952636282394995
dev_label=P_precision_tok: 0.8671516079632465
dev_label=P_recall_tok: 0.7051681195516812
dev_label=P_f-score_tok: 0.7778159340659341
dev_precision_macro_tok: 0.8525442235921462
dev_recall_macro_tok: 0.7666564935820901
dev_f-score_macro_tok: 0.803910507941433
dev_precision_micro_tok: 0.8974334868854
dev_recall_micro_tok: 0.8974334868854
dev_f-score_micro_tok: 0.8974334868854
dev_time: 2.4800453186035156
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4805    0.1616    0.2418       229
           N     0.6831    0.8107    0.7415       428
           P     0.7112    0.8266    0.7646       444

   micro avg     0.6821    0.6821    0.6821      1101
   macro avg     0.6249    0.5996    0.5826      1101
weighted avg     0.6523    0.6821    0.6469      1101

F1-macro sent:  0.5826221300486006
F1-micro sent:  0.6821071752951862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9664    0.9387     16205
           N     0.7780    0.6284    0.6953      1857
           P     0.8672    0.7052    0.7778      3212

   micro avg     0.8974    0.8974    0.8974     21274
   macro avg     0.8525    0.7667    0.8039     21274
weighted avg     0.8939    0.8974    0.8931     21274

F1-macro tok:  0.803910507941433
F1-micro tok:  0.8974334868854
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 0.729000
train_cost_sum: 289840.9419555664
train_cost_avg: 33.9233312213912
train_count_sent: 8544.0
train_total_correct_sent: 6063.0
train_accuracy_sent: 0.7096207865168539
train_count_tok: 163566.0
train_total_correct_tok: 150448.0
train_accuracy_tok: 0.9197999584265679
train_label=O_precision_sent: 0.45305164319248825
train_label=O_recall_sent: 0.1188423645320197
train_label=O_f-score_sent: 0.18829268292682927
train_label=N_precision_sent: 0.6906581217648509
train_label=N_recall_sent: 0.8465256797583082
train_label=N_f-score_sent: 0.7606895615583005
train_label=P_precision_sent: 0.755478946072396
train_label=P_recall_sent: 0.8498614958448754
train_label=P_f-score_sent: 0.799895711119802
train_precision_macro_sent: 0.6330629036765784
train_recall_macro_sent: 0.6050765133784011
train_f-score_macro_sent: 0.5829593185349772
train_precision_micro_sent: 0.7096207865168539
train_recall_micro_sent: 0.7096207865168539
train_f-score_micro_sent: 0.7096207865168539
train_label=O_precision_tok: 0.9334758978476361
train_label=O_recall_tok: 0.9723998166421385
train_label=O_f-score_tok: 0.952540383410995
train_label=N_precision_tok: 0.8336888678201786
train_label=N_recall_tok: 0.742993944514857
train_label=N_f-score_tok: 0.7857329014483041
train_label=P_precision_tok: 0.8879169200542639
train_label=P_recall_tok: 0.7587240676340089
train_label=P_f-score_tok: 0.8182523602189938
train_precision_macro_tok: 0.8850272285740263
train_recall_macro_tok: 0.8247059429303348
train_f-score_macro_tok: 0.8521752150260977
train_precision_micro_tok: 0.9197999584265679
train_recall_micro_tok: 0.9197999584265679
train_f-score_micro_tok: 0.9197999584265679
train_time: 50.60538172721863
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4531    0.1188    0.1883      1624
           N     0.6907    0.8465    0.7607      3310
           P     0.7555    0.8499    0.7999      3610

   micro avg     0.7096    0.7096    0.7096      8544
   macro avg     0.6331    0.6051    0.5830      8544
weighted avg     0.6729    0.7096    0.6685      8544

F1-macro sent:  0.5829593185349772
F1-micro sent:  0.7096207865168539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9335    0.9724    0.9525    124347
           N     0.8337    0.7430    0.7857     14202
           P     0.8879    0.7587    0.8183     25017

   micro avg     0.9198    0.9198    0.9198    163566
   macro avg     0.8850    0.8247    0.8522    163566
weighted avg     0.9178    0.9198    0.9175    163566

F1-macro tok:  0.8521752150260977
F1-micro tok:  0.9197999584265679
**************************************************
dev_cost_sum: 42100.35681152344
dev_cost_avg: 38.23828956541638
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19129.0
dev_accuracy_tok: 0.8991726990692864
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10894941634241244
dev_label=N_precision_sent: 0.6857142857142857
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7320261437908497
dev_label=P_precision_sent: 0.660377358490566
dev_label=P_recall_sent: 0.8671171171171171
dev_label=P_f-score_sent: 0.7497565725413826
dev_precision_macro_sent: 0.6153638814016172
dev_recall_macro_sent: 0.5710997390893731
dev_f-score_macro_sent: 0.5302440442248816
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9137860682016905
dev_label=O_recall_tok: 0.9673557543967911
dev_label=O_f-score_tok: 0.9398081534772181
dev_label=N_precision_tok: 0.7991746905089409
dev_label=N_recall_tok: 0.6257404415724287
dev_label=N_f-score_tok: 0.7019027484143764
dev_label=P_precision_tok: 0.8596622889305816
dev_label=P_recall_tok: 0.7132627646326276
dev_label=P_f-score_tok: 0.7796494810277352
dev_precision_macro_tok: 0.8575410158804043
dev_recall_macro_tok: 0.7687863202006158
dev_f-score_macro_tok: 0.8071201276397767
dev_precision_micro_tok: 0.8991726990692864
dev_recall_micro_tok: 0.8991726990692864
dev_f-score_micro_tok: 0.8991726990692864
dev_time: 2.455979824066162
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0611    0.1089       229
           N     0.6857    0.7850    0.7320       428
           P     0.6604    0.8671    0.7498       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6154    0.5711    0.5302      1101
weighted avg     0.6369    0.6676    0.6096      1101

F1-macro sent:  0.5302440442248816
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9138    0.9674    0.9398     16205
           N     0.7992    0.6257    0.7019      1857
           P     0.8597    0.7133    0.7796      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8575    0.7688    0.8071     21274
weighted avg     0.8956    0.8992    0.8949     21274

F1-macro tok:  0.8071201276397767
F1-micro tok:  0.8991726990692864
**************************************************
Best epoch: 34
**************************************************

EPOCH: 36
Learning rate: 0.729000
train_cost_sum: 288399.2828979492
train_cost_avg: 33.754597717456605
train_count_sent: 8544.0
train_total_correct_sent: 6089.0
train_accuracy_sent: 0.7126638576779026
train_count_tok: 163566.0
train_total_correct_tok: 150786.0
train_accuracy_tok: 0.9218664025530978
train_label=O_precision_sent: 0.4463276836158192
train_label=O_recall_sent: 0.09729064039408868
train_label=O_f-score_sent: 0.1597573306370071
train_label=N_precision_sent: 0.6895131993218697
train_label=N_recall_sent: 0.8601208459214501
train_label=N_f-score_sent: 0.7654254604113455
train_label=P_precision_sent: 0.7594188623491751
train_label=P_recall_sent: 0.8542936288088643
train_label=P_f-score_sent: 0.8040672663277277
train_precision_macro_sent: 0.6317532484289546
train_recall_macro_sent: 0.6039017050414677
train_f-score_macro_sent: 0.5764166857920268
train_precision_micro_sent: 0.7126638576779026
train_recall_micro_sent: 0.7126638576779026
train_f-score_micro_sent: 0.7126638576779026
train_label=O_precision_tok: 0.9353252676742299
train_label=O_recall_tok: 0.9729949254907637
train_label=O_f-score_tok: 0.9537883028119605
train_label=N_precision_tok: 0.8355873565025947
train_label=N_recall_tok: 0.7482748908604422
train_label=N_f-score_tok: 0.789524517087667
train_label=P_precision_tok: 0.8919182989810636
train_label=P_recall_tok: 0.7662789303273774
train_label=P_f-score_tok: 0.824338851859815
train_precision_macro_tok: 0.8876103077192959
train_recall_macro_tok: 0.8291829155595277
train_f-score_macro_tok: 0.8558838905864808
train_precision_micro_tok: 0.9218664025530978
train_recall_micro_tok: 0.9218664025530978
train_f-score_micro_tok: 0.9218664025530978
train_time: 66.41747832298279
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4463    0.0973    0.1598      1624
           N     0.6895    0.8601    0.7654      3310
           P     0.7594    0.8543    0.8041      3610

   micro avg     0.7127    0.7127    0.7127      8544
   macro avg     0.6318    0.6039    0.5764      8544
weighted avg     0.6728    0.7127    0.6666      8544

F1-macro sent:  0.5764166857920268
F1-micro sent:  0.7126638576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9353    0.9730    0.9538    124347
           N     0.8356    0.7483    0.7895     14202
           P     0.8919    0.7663    0.8243     25017

   micro avg     0.9219    0.9219    0.9219    163566
   macro avg     0.8876    0.8292    0.8559    163566
weighted avg     0.9200    0.9219    0.9197    163566

F1-macro tok:  0.8558838905864808
F1-micro tok:  0.9218664025530978
**************************************************
dev_cost_sum: 42173.06805419922
dev_cost_avg: 38.30433065776496
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19153.0
dev_accuracy_tok: 0.9003008367020776
dev_label=O_precision_sent: 0.7058823529411765
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0975609756097561
dev_label=N_precision_sent: 0.6557377049180327
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7369498464687819
dev_label=P_precision_sent: 0.6934579439252336
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7579162410623085
dev_precision_macro_sent: 0.6850260005948142
dev_recall_macro_sent: 0.5763696092125264
dev_f-score_macro_sent: 0.5308090210469488
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9083438685208597
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9406968786264767
dev_label=N_precision_tok: 0.8075284090909091
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6964777947932619
dev_label=P_precision_tok: 0.8965097402597403
dev_label=P_recall_tok: 0.687733499377335
dev_label=P_f-score_tok: 0.7783650458069062
dev_precision_macro_tok: 0.8707940059571696
dev_recall_macro_tok: 0.7584836820056639
dev_f-score_macro_tok: 0.8051799064088816
dev_precision_micro_tok: 0.9003008367020776
dev_recall_micro_tok: 0.9003008367020776
dev_f-score_micro_tok: 0.9003008367020775
dev_time: 4.933985471725464
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7059    0.0524    0.0976       229
           N     0.6557    0.8411    0.7369       428
           P     0.6935    0.8356    0.7579       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6850    0.5764    0.5308      1101
weighted avg     0.6814    0.6748    0.6124      1101

F1-macro sent:  0.5308090210469488
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9754    0.9407     16205
           N     0.8075    0.6123    0.6965      1857
           P     0.8965    0.6877    0.7784      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8708    0.7585    0.8052     21274
weighted avg     0.8978    0.9003    0.8949     21274

F1-macro tok:  0.8051799064088816
F1-micro tok:  0.9003008367020775
**************************************************
Best epoch: 34
**************************************************

EPOCH: 37
Learning rate: 0.729000
train_cost_sum: 287568.4401855469
train_cost_avg: 33.65735489063049
train_count_sent: 8544.0
train_total_correct_sent: 6075.0
train_accuracy_sent: 0.7110252808988764
train_count_tok: 163566.0
train_total_correct_tok: 151007.0
train_accuracy_tok: 0.9232175390973675
train_label=O_precision_sent: 0.4813753581661891
train_label=O_recall_sent: 0.10344827586206896
train_label=O_f-score_sent: 0.17029903699949314
train_label=N_precision_sent: 0.6794566253574833
train_label=N_recall_sent: 0.8613293051359516
train_label=N_f-score_sent: 0.7596589395150547
train_label=P_precision_sent: 0.7641910477619405
train_label=P_recall_sent: 0.8465373961218836
train_label=P_f-score_sent: 0.8032592981995006
train_precision_macro_sent: 0.6416743437618709
train_recall_macro_sent: 0.6037716590399681
train_f-score_macro_sent: 0.5777390915713495
train_precision_micro_sent: 0.7110252808988764
train_recall_micro_sent: 0.7110252808988764
train_f-score_micro_sent: 0.7110252808988763
train_label=O_precision_tok: 0.9366406957221444
train_label=O_recall_tok: 0.9735498242820494
train_label=O_f-score_tok: 0.9547386767825736
train_label=N_precision_tok: 0.8383656183828719
train_label=N_recall_tok: 0.7527108857907338
train_label=N_f-score_tok: 0.7932326642674284
train_label=P_precision_tok: 0.8929432492581603
train_label=P_recall_tok: 0.7698365111724028
train_label=P_f-score_tok: 0.8268326714607707
train_precision_macro_tok: 0.8893165211210589
train_recall_macro_tok: 0.8320324070817287
train_f-score_macro_tok: 0.8582680041702576
train_precision_micro_tok: 0.9232175390973675
train_recall_micro_tok: 0.9232175390973675
train_f-score_micro_tok: 0.9232175390973675
train_time: 94.05045104026794
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4814    0.1034    0.1703      1624
           N     0.6795    0.8613    0.7597      3310
           P     0.7642    0.8465    0.8033      3610

   micro avg     0.7110    0.7110    0.7110      8544
   macro avg     0.6417    0.6038    0.5777      8544
weighted avg     0.6776    0.7110    0.6661      8544

F1-macro sent:  0.5777390915713495
F1-micro sent:  0.7110252808988763
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9366    0.9735    0.9547    124347
           N     0.8384    0.7527    0.7932     14202
           P     0.8929    0.7698    0.8268     25017

   micro avg     0.9232    0.9232    0.9232    163566
   macro avg     0.8893    0.8320    0.8583    163566
weighted avg     0.9214    0.9232    0.9212    163566

F1-macro tok:  0.8582680041702576
F1-micro tok:  0.9232175390973675
**************************************************
dev_cost_sum: 41926.56915283203
dev_cost_avg: 38.08044428050139
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19123.0
dev_accuracy_tok: 0.8988906646610887
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06611570247933884
dev_label=N_precision_sent: 0.6524822695035462
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7419354838709677
dev_label=P_precision_sent: 0.700381679389313
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7582644628099174
dev_precision_macro_sent: 0.6560828547591582
dev_recall_macro_sent: 0.5737747195017734
dev_f-score_macro_sent: 0.5221052163867413
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9157240813456016
dev_label=O_recall_tok: 0.9642085775995063
dev_label=O_f-score_tok: 0.9393411085728026
dev_label=N_precision_tok: 0.7690339091490723
dev_label=N_recall_tok: 0.6472805600430802
dev_label=N_f-score_tok: 0.7029239766081871
dev_label=P_precision_tok: 0.8670694864048338
dev_label=P_recall_tok: 0.7148194271481942
dev_label=P_f-score_tok: 0.7836177474402731
dev_precision_macro_tok: 0.8506091589665026
dev_recall_macro_tok: 0.7754361882635935
dev_f-score_macro_tok: 0.8086276108737542
dev_precision_micro_tok: 0.8988906646610887
dev_recall_micro_tok: 0.8988906646610887
dev_f-score_micro_tok: 0.8988906646610887
dev_time: 5.039408206939697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0349    0.0661       229
           N     0.6525    0.8598    0.7419       428
           P     0.7004    0.8266    0.7583       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6561    0.5738    0.5221      1101
weighted avg     0.6641    0.6748    0.6080      1101

F1-macro sent:  0.5221052163867413
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9642    0.9393     16205
           N     0.7690    0.6473    0.7029      1857
           P     0.8671    0.7148    0.7836      3212

   micro avg     0.8989    0.8989    0.8989     21274
   macro avg     0.8506    0.7754    0.8086     21274
weighted avg     0.8956    0.8989    0.8952     21274

F1-macro tok:  0.8086276108737542
F1-micro tok:  0.8988906646610887
**************************************************
Best epoch: 34
**************************************************

EPOCH: 38
Learning rate: 0.729000
train_cost_sum: 286838.21502685547
train_cost_avg: 33.57188846288103
train_count_sent: 8544.0
train_total_correct_sent: 6083.0
train_accuracy_sent: 0.7119616104868914
train_count_tok: 163566.0
train_total_correct_tok: 151186.0
train_accuracy_tok: 0.9243118985608256
train_label=O_precision_sent: 0.5133531157270029
train_label=O_recall_sent: 0.10652709359605911
train_label=O_f-score_sent: 0.17644059153493116
train_label=N_precision_sent: 0.6844401357246728
train_label=N_recall_sent: 0.8531722054380665
train_label=N_f-score_sent: 0.7595481441635289
train_label=P_precision_sent: 0.7561872090173977
train_label=P_recall_sent: 0.8548476454293629
train_label=P_f-score_sent: 0.8024964243921466
train_precision_macro_sent: 0.6513268201563579
train_recall_macro_sent: 0.6048489814878294
train_f-score_macro_sent: 0.5794950533635356
train_precision_micro_sent: 0.7119616104868914
train_recall_micro_sent: 0.7119616104868914
train_f-score_micro_sent: 0.7119616104868914
train_label=O_precision_tok: 0.9380572137374991
train_label=O_recall_tok: 0.9730833876169107
train_label=O_f-score_tok: 0.9552493319175643
train_label=N_precision_tok: 0.8393875478478244
train_label=N_recall_tok: 0.7565835797774961
train_label=N_f-score_tok: 0.7958374995370885
train_label=P_precision_tok: 0.8928128587830081
train_label=P_recall_tok: 0.7771115641363873
train_label=P_f-score_tok: 0.8309540092323474
train_precision_macro_tok: 0.8900858734561106
train_recall_macro_tok: 0.8355928438435981
train_f-score_macro_tok: 0.860680280229
train_precision_micro_tok: 0.9243118985608256
train_recall_micro_tok: 0.9243118985608256
train_f-score_micro_tok: 0.9243118985608256
train_time: 94.4466392993927
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5134    0.1065    0.1764      1624
           N     0.6844    0.8532    0.7595      3310
           P     0.7562    0.8548    0.8025      3610

   micro avg     0.7120    0.7120    0.7120      8544
   macro avg     0.6513    0.6048    0.5795      8544
weighted avg     0.6822    0.7120    0.6669      8544

F1-macro sent:  0.5794950533635356
F1-micro sent:  0.7119616104868914
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9381    0.9731    0.9552    124347
           N     0.8394    0.7566    0.7958     14202
           P     0.8928    0.7771    0.8310     25017

   micro avg     0.9243    0.9243    0.9243    163566
   macro avg     0.8901    0.8356    0.8607    163566
weighted avg     0.9226    0.9243    0.9224    163566

F1-macro tok:  0.860680280229
F1-micro tok:  0.9243118985608256
**************************************************
dev_cost_sum: 41932.1005859375
dev_cost_avg: 38.08546828877157
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19087.0
dev_accuracy_tok: 0.8971984582119018
dev_label=O_precision_sent: 0.5666666666666667
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.1312741312741313
dev_label=N_precision_sent: 0.6474694589877836
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7412587412587411
dev_label=P_precision_sent: 0.7108433734939759
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.751592356687898
dev_precision_macro_sent: 0.6416598330494754
dev_recall_macro_sent: 0.5794518450213672
dev_f-score_macro_sent: 0.5413750764069235
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9195075757575758
dev_label=O_recall_tok: 0.9587164455414995
dev_label=O_f-score_tok: 0.9387027582248271
dev_label=N_precision_tok: 0.7400482509047045
dev_label=N_recall_tok: 0.6607431340872375
dev_label=N_f-score_tok: 0.6981507823613087
dev_label=P_precision_tok: 0.8544117647058823
dev_label=P_recall_tok: 0.7235367372353674
dev_label=P_f-score_tok: 0.7835468644639245
dev_precision_macro_tok: 0.8379891971227208
dev_recall_macro_tok: 0.7809987722880347
dev_f-score_macro_tok: 0.8068001350166867
dev_precision_micro_tok: 0.8971984582119018
dev_recall_micro_tok: 0.8971984582119018
dev_f-score_micro_tok: 0.8971984582119018
dev_time: 5.243995189666748
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5667    0.0742    0.1313       229
           N     0.6475    0.8668    0.7413       428
           P     0.7108    0.7973    0.7516       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6417    0.5795    0.5414      1101
weighted avg     0.6562    0.6739    0.6186      1101

F1-macro sent:  0.5413750764069235
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9195    0.9587    0.9387     16205
           N     0.7400    0.6607    0.6982      1857
           P     0.8544    0.7235    0.7835      3212

   micro avg     0.8972    0.8972    0.8972     21274
   macro avg     0.8380    0.7810    0.8068     21274
weighted avg     0.8940    0.8972    0.8943     21274

F1-macro tok:  0.8068001350166867
F1-micro tok:  0.8971984582119018
**************************************************
Best epoch: 34
**************************************************

EPOCH: 39
Learning rate: 0.656100
train_cost_sum: 285692.4876098633
train_cost_avg: 33.4377911528398
train_count_sent: 8544.0
train_total_correct_sent: 6106.0
train_accuracy_sent: 0.7146535580524345
train_count_tok: 163566.0
train_total_correct_tok: 151480.0
train_accuracy_tok: 0.9261093381265055
train_label=O_precision_sent: 0.4945054945054945
train_label=O_recall_sent: 0.11083743842364532
train_label=O_f-score_sent: 0.18108651911468812
train_label=N_precision_sent: 0.6872299567930868
train_label=N_recall_sent: 0.8649546827794562
train_label=N_f-score_sent: 0.7659176029962547
train_label=P_precision_sent: 0.7630792227204783
train_label=P_recall_sent: 0.8484764542936288
train_label=P_f-score_sent: 0.8035152151101785
train_precision_macro_sent: 0.6482715580063533
train_recall_macro_sent: 0.6080895251655768
train_f-score_macro_sent: 0.5835064457403738
train_precision_micro_sent: 0.7146535580524345
train_recall_micro_sent: 0.7146535580524345
train_f-score_micro_sent: 0.7146535580524345
train_label=O_precision_tok: 0.9396149697764465
train_label=O_recall_tok: 0.9738152106604904
train_label=O_f-score_tok: 0.9564094463312534
train_label=N_precision_tok: 0.8469101123595506
train_label=N_recall_tok: 0.7642585551330798
train_label=N_f-score_tok: 0.8034643570952699
train_label=P_precision_tok: 0.8929469305663482
train_label=P_recall_tok: 0.7808690090738298
train_label=P_f-score_tok: 0.8331556275856187
train_precision_macro_tok: 0.8931573375674485
train_recall_macro_tok: 0.8396475916224667
train_f-score_macro_tok: 0.864343143670714
train_precision_micro_tok: 0.9261093381265055
train_recall_micro_tok: 0.9261093381265055
train_f-score_micro_tok: 0.9261093381265056
train_time: 137.75881505012512
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4945    0.1108    0.1811      1624
           N     0.6872    0.8650    0.7659      3310
           P     0.7631    0.8485    0.8035      3610

   micro avg     0.7147    0.7147    0.7147      8544
   macro avg     0.6483    0.6081    0.5835      8544
weighted avg     0.6826    0.7147    0.6706      8544

F1-macro sent:  0.5835064457403738
F1-micro sent:  0.7146535580524345
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9396    0.9738    0.9564    124347
           N     0.8469    0.7643    0.8035     14202
           P     0.8929    0.7809    0.8332     25017

   micro avg     0.9261    0.9261    0.9261    163566
   macro avg     0.8932    0.8396    0.8643    163566
weighted avg     0.9244    0.9261    0.9243    163566

F1-macro tok:  0.864343143670714
F1-micro tok:  0.9261093381265056
**************************************************
dev_cost_sum: 42138.1767578125
dev_cost_avg: 38.272640107004996
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19034.0
dev_accuracy_tok: 0.8947071542728213
dev_label=O_precision_sent: 0.5365853658536586
dev_label=O_recall_sent: 0.09606986899563319
dev_label=O_f-score_sent: 0.16296296296296295
dev_label=N_precision_sent: 0.6951983298538622
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7342888643880925
dev_label=P_precision_sent: 0.6609294320137694
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7492682926829268
dev_precision_macro_sent: 0.6309043759070967
dev_recall_macro_sent: 0.5796573723460227
dev_f-score_macro_sent: 0.5488400400113275
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9181317705558515
dev_label=O_recall_tok: 0.9571120024683739
dev_label=O_f-score_tok: 0.9372167502568132
dev_label=N_precision_tok: 0.7309976247030879
dev_label=N_recall_tok: 0.6628971459343026
dev_label=N_f-score_tok: 0.6952838181304717
dev_label=P_precision_tok: 0.8502039302929181
dev_label=P_recall_tok: 0.7138854296388543
dev_label=P_f-score_tok: 0.7761042477576577
dev_precision_macro_tok: 0.8331111085172859
dev_recall_macro_tok: 0.7779648593471769
dev_f-score_macro_tok: 0.8028682720483142
dev_precision_micro_tok: 0.8947071542728213
dev_recall_micro_tok: 0.8947071542728213
dev_f-score_micro_tok: 0.8947071542728212
dev_time: 8.314096450805664
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5366    0.0961    0.1630       229
           N     0.6952    0.7780    0.7343       428
           P     0.6609    0.8649    0.7493       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6309    0.5797    0.5488      1101
weighted avg     0.6484    0.6712    0.6215      1101

F1-macro sent:  0.5488400400113275
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9181    0.9571    0.9372     16205
           N     0.7310    0.6629    0.6953      1857
           P     0.8502    0.7139    0.7761      3212

   micro avg     0.8947    0.8947    0.8947     21274
   macro avg     0.8331    0.7780    0.8029     21274
weighted avg     0.8915    0.8947    0.8918     21274

F1-macro tok:  0.8028682720483142
F1-micro tok:  0.8947071542728212
**************************************************
Best epoch: 34
**************************************************

EPOCH: 40
Learning rate: 0.590490
train_cost_sum: 284361.3427734375
train_cost_avg: 33.28199236580495
train_count_sent: 8544.0
train_total_correct_sent: 6142.0
train_accuracy_sent: 0.7188670411985019
train_count_tok: 163566.0
train_total_correct_tok: 151879.0
train_accuracy_tok: 0.928548720394214
train_label=O_precision_sent: 0.5306666666666666
train_label=O_recall_sent: 0.12253694581280788
train_label=O_f-score_sent: 0.19909954977488747
train_label=N_precision_sent: 0.7001245330012453
train_label=N_recall_sent: 0.8492447129909365
train_label=N_f-score_sent: 0.7675085324232082
train_label=P_precision_sent: 0.7539720751083293
train_label=P_recall_sent: 0.867590027700831
train_label=P_f-score_sent: 0.8068006182380216
train_precision_macro_sent: 0.6615877582587472
train_recall_macro_sent: 0.6131238955015251
train_f-score_macro_sent: 0.5911362334787057
train_precision_micro_sent: 0.7188670411985019
train_recall_micro_sent: 0.7188670411985019
train_f-score_micro_sent: 0.7188670411985019
train_label=O_precision_tok: 0.9421311424392369
train_label=O_recall_tok: 0.9738393366948941
train_label=O_f-score_tok: 0.9577228635038891
train_label=N_precision_tok: 0.850139189607176
train_label=N_recall_tok: 0.7741163216448388
train_label=N_f-score_tok: 0.8103486400825534
train_label=P_precision_tok: 0.8954393267577595
train_label=P_recall_tok: 0.7911020506055882
train_label=P_f-score_tok: 0.840043294636983
train_precision_macro_tok: 0.8959032196013909
train_recall_macro_tok: 0.8463525696484404
train_f-score_macro_tok: 0.8693715994078085
train_precision_micro_tok: 0.928548720394214
train_recall_micro_tok: 0.928548720394214
train_f-score_micro_tok: 0.928548720394214
train_time: 143.33550930023193
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5307    0.1225    0.1991      1624
           N     0.7001    0.8492    0.7675      3310
           P     0.7540    0.8676    0.8068      3610

   micro avg     0.7189    0.7189    0.7189      8544
   macro avg     0.6616    0.6131    0.5911      8544
weighted avg     0.6907    0.7189    0.6761      8544

F1-macro sent:  0.5911362334787057
F1-micro sent:  0.7188670411985019
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9421    0.9738    0.9577    124347
           N     0.8501    0.7741    0.8103     14202
           P     0.8954    0.7911    0.8400     25017

   micro avg     0.9285    0.9285    0.9285    163566
   macro avg     0.8959    0.8464    0.8694    163566
weighted avg     0.9270    0.9285    0.9269    163566

F1-macro tok:  0.8693715994078085
F1-micro tok:  0.928548720394214
**************************************************
dev_cost_sum: 42052.5244140625
dev_cost_avg: 38.19484506272707
dev_count_sent: 1101.0
dev_total_correct_sent: 751.0
dev_accuracy_sent: 0.6821071752951862
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.10480349344978165
dev_label=O_f-score_sent: 0.17712177121771217
dev_label=N_precision_sent: 0.6509598603839442
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7452547452547452
dev_label=P_precision_sent: 0.7283950617283951
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.7612903225806451
dev_precision_macro_sent: 0.6502611645136369
dev_recall_macro_sent: 0.5911987059499609
dev_f-score_macro_sent: 0.5612222796843674
dev_precision_micro_sent: 0.6821071752951862
dev_recall_micro_sent: 0.6821071752951862
dev_f-score_micro_sent: 0.6821071752951862
dev_label=O_precision_tok: 0.9168773146787373
dev_label=O_recall_tok: 0.962480715828448
dev_label=O_f-score_tok: 0.9391257225433527
dev_label=N_precision_tok: 0.7467732022126613
dev_label=N_recall_tok: 0.654281098546042
dev_label=N_f-score_tok: 0.6974741676234213
dev_label=P_precision_tok: 0.8657056145675266
dev_label=P_recall_tok: 0.7104607721046077
dev_label=P_f-score_tok: 0.780437756497948
dev_precision_macro_tok: 0.8431187104863085
dev_recall_macro_tok: 0.7757408621596992
dev_f-score_macro_tok: 0.8056792155549073
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 8.475207567214966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.1048    0.1771       229
           N     0.6510    0.8715    0.7453       428
           P     0.7284    0.7973    0.7613       444

   micro avg     0.6821    0.6821    0.6821      1101
   macro avg     0.6503    0.5912    0.5612      1101
weighted avg     0.6656    0.6821    0.6336      1101

F1-macro sent:  0.5612222796843674
F1-micro sent:  0.6821071752951862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9169    0.9625    0.9391     16205
           N     0.7468    0.6543    0.6975      1857
           P     0.8657    0.7105    0.7804      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8431    0.7757    0.8057     21274
weighted avg     0.8943    0.8975    0.8941     21274

F1-macro tok:  0.8056792155549073
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 34
**************************************************

EPOCH: 41
Learning rate: 0.531441
train_cost_sum: 283095.0608520508
train_cost_avg: 33.1337852120846
train_count_sent: 8544.0
train_total_correct_sent: 6155.0
train_accuracy_sent: 0.7203885767790262
train_count_tok: 163566.0
train_total_correct_tok: 152077.0
train_accuracy_tok: 0.9297592409180392
train_label=O_precision_sent: 0.516042780748663
train_label=O_recall_sent: 0.1188423645320197
train_label=O_f-score_sent: 0.19319319319319317
train_label=N_precision_sent: 0.6982421875
train_label=N_recall_sent: 0.8640483383685801
train_label=N_f-score_sent: 0.7723467458817175
train_label=P_precision_sent: 0.7614138438880707
train_label=P_recall_sent: 0.8592797783933518
train_label=P_f-score_sent: 0.8073919833420092
train_precision_macro_sent: 0.6585662707122446
train_recall_macro_sent: 0.6140568270979839
train_f-score_macro_sent: 0.5909773074723067
train_precision_micro_sent: 0.7203885767790262
train_recall_micro_sent: 0.7203885767790262
train_f-score_micro_sent: 0.7203885767790262
train_label=O_precision_tok: 0.9435903030491939
train_label=O_recall_tok: 0.9738071686490225
train_label=O_f-score_tok: 0.9584606373379349
train_label=N_precision_tok: 0.849075500770416
train_label=N_recall_tok: 0.7760174623292494
train_label=N_f-score_tok: 0.8109042748877934
train_label=P_precision_tok: 0.8970660915666981
train_label=P_recall_tok: 0.7980972938401887
train_label=P_f-score_tok: 0.8446926428903838
train_precision_macro_tok: 0.8965772984621028
train_recall_macro_tok: 0.8493073082728202
train_f-score_macro_tok: 0.8713525183720373
train_precision_micro_tok: 0.9297592409180392
train_recall_micro_tok: 0.9297592409180392
train_f-score_micro_tok: 0.9297592409180392
train_time: 143.55257296562195
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5160    0.1188    0.1932      1624
           N     0.6982    0.8640    0.7723      3310
           P     0.7614    0.8593    0.8074      3610

   micro avg     0.7204    0.7204    0.7204      8544
   macro avg     0.6586    0.6141    0.5910      8544
weighted avg     0.6903    0.7204    0.6771      8544

F1-macro sent:  0.5909773074723067
F1-micro sent:  0.7203885767790262
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9436    0.9738    0.9585    124347
           N     0.8491    0.7760    0.8109     14202
           P     0.8971    0.7981    0.8447     25017

   micro avg     0.9298    0.9298    0.9298    163566
   macro avg     0.8966    0.8493    0.8714    163566
weighted avg     0.9283    0.9298    0.9282    163566

F1-macro tok:  0.8713525183720373
F1-micro tok:  0.9297592409180392
**************************************************
dev_cost_sum: 42242.92614746094
dev_cost_avg: 38.36778033375199
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19075.0
dev_accuracy_tok: 0.8966343893955062
dev_label=O_precision_sent: 0.4444444444444444
dev_label=O_recall_sent: 0.1222707423580786
dev_label=O_f-score_sent: 0.1917808219178082
dev_label=N_precision_sent: 0.6843177189409368
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7312295973884657
dev_label=P_precision_sent: 0.6855575868372943
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.756811301715439
dev_precision_macro_sent: 0.6047732500742252
dev_recall_macro_sent: 0.5839706886415453
dev_f-score_macro_sent: 0.5599405736739044
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9193863649825268
dev_label=O_recall_tok: 0.9578525146559704
dev_label=O_f-score_tok: 0.9382253384912959
dev_label=N_precision_tok: 0.750920245398773
dev_label=N_recall_tok: 0.6591276252019386
dev_label=N_f-score_tok: 0.7020361342127903
dev_label=P_precision_tok: 0.8435349511046722
dev_label=P_recall_tok: 0.725093399750934
dev_label=P_f-score_tok: 0.7798426251464926
dev_precision_macro_tok: 0.8379471871619907
dev_recall_macro_tok: 0.7806911798696143
dev_f-score_macro_tok: 0.806701365950193
dev_precision_micro_tok: 0.8966343893955062
dev_recall_micro_tok: 0.8966343893955062
dev_f-score_micro_tok: 0.8966343893955062
dev_time: 8.460888385772705
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.1223    0.1918       229
           N     0.6843    0.7850    0.7312       428
           P     0.6856    0.8446    0.7568       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6048    0.5840    0.5599      1101
weighted avg     0.6349    0.6712    0.6293      1101

F1-macro sent:  0.5599405736739044
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9194    0.9579    0.9382     16205
           N     0.7509    0.6591    0.7020      1857
           P     0.8435    0.7251    0.7798      3212

   micro avg     0.8966    0.8966    0.8966     21274
   macro avg     0.8379    0.7807    0.8067     21274
weighted avg     0.8932    0.8966    0.8937     21274

F1-macro tok:  0.806701365950193
F1-micro tok:  0.8966343893955062
**************************************************
Best epoch: 34
**************************************************

test0_cost_sum: 42014.529235839844
test0_cost_avg: 38.160335364068885
test0_count_sent: 1101.0
test0_total_correct_sent: 751.0
test0_accuracy_sent: 0.6821071752951862
test0_count_tok: 21274.0
test0_total_correct_tok: 19092.0
test0_accuracy_tok: 0.8974334868854
test0_label=O_precision_sent: 0.4805194805194805
test0_label=O_recall_sent: 0.1615720524017467
test0_label=O_f-score_sent: 0.2418300653594771
test0_label=N_precision_sent: 0.6830708661417323
test0_label=N_recall_sent: 0.8107476635514018
test0_label=N_f-score_sent: 0.7414529914529915
test0_label=P_precision_sent: 0.7112403100775194
test0_label=P_recall_sent: 0.8265765765765766
test0_label=P_f-score_sent: 0.7645833333333334
test0_precision_macro_sent: 0.624943552246244
test0_recall_macro_sent: 0.5996320975099083
test0_f-score_macro_sent: 0.5826221300486006
test0_precision_micro_sent: 0.6821071752951862
test0_recall_micro_sent: 0.6821071752951862
test0_f-score_micro_sent: 0.6821071752951862
test0_label=O_precision_tok: 0.912481062813192
test0_label=O_recall_tok: 0.9663684048133292
test0_label=O_f-score_tok: 0.9386519615188659
test0_label=N_precision_tok: 0.778
test0_label=N_recall_tok: 0.6284329563812601
test0_label=N_f-score_tok: 0.6952636282394995
test0_label=P_precision_tok: 0.8671516079632465
test0_label=P_recall_tok: 0.7051681195516812
test0_label=P_f-score_tok: 0.7778159340659341
test0_precision_macro_tok: 0.8525442235921462
test0_recall_macro_tok: 0.7666564935820901
test0_f-score_macro_tok: 0.803910507941433
test0_precision_micro_tok: 0.8974334868854
test0_recall_micro_tok: 0.8974334868854
test0_f-score_micro_tok: 0.8974334868854
test0_time: 8.123836517333984
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4805    0.1616    0.2418       229
           N     0.6831    0.8107    0.7415       428
           P     0.7112    0.8266    0.7646       444

   micro avg     0.6821    0.6821    0.6821      1101
   macro avg     0.6249    0.5996    0.5826      1101
weighted avg     0.6523    0.6821    0.6469      1101

F1-macro sent:  0.5826221300486006
F1-micro sent:  0.6821071752951862
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9664    0.9387     16205
           N     0.7780    0.6284    0.6953      1857
           P     0.8672    0.7052    0.7778      3212

   micro avg     0.8974    0.8974    0.8974     21274
   macro avg     0.8525    0.7667    0.8039     21274
weighted avg     0.8939    0.8974    0.8931     21274

F1-macro tok:  0.803910507941433
F1-micro tok:  0.8974334868854
**************************************************
test1_cost_sum: 81035.00317001343
test1_cost_avg: 36.66742224887486
test1_count_sent: 2210.0
test1_total_correct_sent: 1516.0
test1_accuracy_sent: 0.685972850678733
test1_count_tok: 42405.0
test1_total_correct_tok: 37891.0
test1_accuracy_tok: 0.8935502888810282
test1_label=O_precision_sent: 0.3236994219653179
test1_label=O_recall_sent: 0.14395886889460155
test1_label=O_f-score_sent: 0.199288256227758
test1_label=N_precision_sent: 0.6973811833171678
test1_label=N_recall_sent: 0.7883771929824561
test1_label=N_f-score_sent: 0.7400926402470407
test1_label=P_precision_sent: 0.7365805168986084
test1_label=P_recall_sent: 0.8151815181518152
test1_label=P_f-score_sent: 0.7738903394255875
test1_precision_macro_sent: 0.5858870407270313
test1_recall_macro_sent: 0.5825058600096242
test1_f-score_macro_sent: 0.5710904119667953
test1_precision_micro_sent: 0.685972850678733
test1_recall_micro_sent: 0.685972850678733
test1_f-score_micro_sent: 0.685972850678733
test1_label=O_precision_tok: 0.9054054054054054
test1_label=O_recall_tok: 0.9694668416776049
test1_label=O_f-score_tok: 0.9363416842740717
test1_label=N_precision_tok: 0.7857142857142857
test1_label=N_recall_tok: 0.6319148936170212
test1_label=N_f-score_tok: 0.7004716981132075
test1_label=P_precision_tok: 0.8779058409845673
test1_label=P_recall_tok: 0.676094478712201
test1_label=P_f-score_tok: 0.7638959714431411
test1_precision_macro_tok: 0.8563418440347528
test1_recall_macro_tok: 0.7591587380022756
test1_f-score_macro_tok: 0.8002364512768069
test1_precision_micro_tok: 0.8935502888810282
test1_recall_micro_tok: 0.8935502888810282
test1_f-score_micro_tok: 0.8935502888810282
test1_time: 15.105224847793579
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3237    0.1440    0.1993       389
           N     0.6974    0.7884    0.7401       912
           P     0.7366    0.8152    0.7739       909

   micro avg     0.6860    0.6860    0.6860      2210
   macro avg     0.5859    0.5825    0.5711      2210
weighted avg     0.6477    0.6860    0.6588      2210

F1-macro sent:  0.5710904119667953
F1-micro sent:  0.685972850678733
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9054    0.9695    0.9363     31998
           N     0.7857    0.6319    0.7005      3760
           P     0.8779    0.6761    0.7639      6647

   micro avg     0.8936    0.8936    0.8936     42405
   macro avg     0.8563    0.7592    0.8002     42405
weighted avg     0.8905    0.8936    0.8884     42405

F1-macro tok:  0.8002364512768069
F1-micro tok:  0.8935502888810282
**************************************************
