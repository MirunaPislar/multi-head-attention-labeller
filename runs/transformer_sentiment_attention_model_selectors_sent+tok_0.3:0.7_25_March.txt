to_write_filename: runs/transformer_sentiment_attention_model_selectors_sent+tok_0.3:0.7_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:dev_f-score_macro_tok:high
model_selector_ratio: 0.3:0.7
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 427968.30798339844
train_cost_avg: 50.08992368719551
train_count_sent: 8544.0
train_total_correct_sent: 4215.0
train_accuracy_sent: 0.49332865168539325
train_count_tok: 163566.0
train_total_correct_tok: 126098.0
train_accuracy_tok: 0.7709303889561401
train_label=O_precision_sent: 0.21755725190839695
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.060445387062566275
train_label=N_precision_sent: 0.47960224375318716
train_label=N_recall_sent: 0.5682779456193353
train_label=N_f-score_sent: 0.5201880530973452
train_label=P_precision_sent: 0.5222477064220183
train_label=P_recall_sent: 0.6307479224376731
train_label=P_f-score_sent: 0.5713927227101632
train_precision_macro_sent: 0.4064690673612008
train_recall_macro_sent: 0.4113747967414987
train_f-score_macro_sent: 0.38400872095669153
train_precision_micro_sent: 0.49332865168539325
train_recall_micro_sent: 0.49332865168539325
train_f-score_micro_sent: 0.49332865168539325
train_label=O_precision_tok: 0.7984626211227196
train_label=O_recall_tok: 0.9489573532131856
train_label=O_f-score_tok: 0.8672293858472574
train_label=N_precision_tok: 0.5075257906308135
train_label=N_recall_tok: 0.2113082664413463
train_label=N_f-score_tok: 0.29838429033059904
train_label=P_precision_tok: 0.5164657006788935
train_label=P_recall_tok: 0.20374145581004915
train_label=P_f-score_tok: 0.2922089090179441
train_precision_macro_tok: 0.6074847041441422
train_recall_macro_tok: 0.4546690251548604
train_f-score_macro_tok: 0.48594086173193346
train_precision_micro_tok: 0.7709303889561401
train_recall_micro_tok: 0.7709303889561401
train_f-score_micro_tok: 0.7709303889561401
train_time: 146.0494384765625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2176    0.0351    0.0604      1624
           N     0.4796    0.5683    0.5202      3310
           P     0.5222    0.6307    0.5714      3610

   micro avg     0.4933    0.4933    0.4933      8544
   macro avg     0.4065    0.4114    0.3840      8544
weighted avg     0.4478    0.4933    0.4544      8544

F1-macro sent:  0.38400872095669153
F1-micro sent:  0.49332865168539325
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7985    0.9490    0.8672    124347
           N     0.5075    0.2113    0.2984     14202
           P     0.5165    0.2037    0.2922     25017

   micro avg     0.7709    0.7709    0.7709    163566
   macro avg     0.6075    0.4547    0.4859    163566
weighted avg     0.7301    0.7709    0.7299    163566

F1-macro tok:  0.48594086173193346
F1-micro tok:  0.7709303889561401
**************************************************
dev_cost_sum: 50471.395751953125
dev_cost_avg: 45.841413035379766
dev_count_sent: 1101.0
dev_total_correct_sent: 633.0
dev_accuracy_sent: 0.5749318801089919
dev_count_tok: 21274.0
dev_total_correct_tok: 17492.0
dev_accuracy_tok: 0.8222243113659866
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5731225296442688
dev_label=N_recall_sent: 0.677570093457944
dev_label=N_f-score_sent: 0.620985010706638
dev_label=P_precision_sent: 0.5764705882352941
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.6602502406159768
dev_precision_macro_sent: 0.3831977059598543
dev_recall_macro_sent: 0.4833642053268221
dev_f-score_macro_sent: 0.4270784171075383
dev_precision_micro_sent: 0.5749318801089919
dev_recall_micro_sent: 0.5749318801089919
dev_f-score_micro_sent: 0.5749318801089919
dev_label=O_precision_tok: 0.8364418167159365
dev_label=O_recall_tok: 0.9603208886146252
dev_label=O_f-score_tok: 0.8941108876759551
dev_label=N_precision_tok: 0.7027027027027027
dev_label=N_recall_tok: 0.3920301561658589
dev_label=N_f-score_tok: 0.5032837884548911
dev_label=P_precision_tok: 0.736068585425597
dev_label=P_recall_tok: 0.3742216687422167
dev_label=P_f-score_tok: 0.4961816305469556
dev_precision_macro_tok: 0.7584043682814121
dev_recall_macro_tok: 0.5755242378409002
dev_f-score_macro_tok: 0.6311921022259339
dev_precision_micro_tok: 0.8222243113659866
dev_recall_micro_tok: 0.8222243113659866
dev_f-score_micro_tok: 0.8222243113659866
dev_time: 8.791359663009644
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5731    0.6776    0.6210       428
           P     0.5765    0.7725    0.6603       444

   micro avg     0.5749    0.5749    0.5749      1101
   macro avg     0.3832    0.4834    0.4271      1101
weighted avg     0.4553    0.5749    0.5077      1101

F1-macro sent:  0.4270784171075383
F1-micro sent:  0.5749318801089919
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8364    0.9603    0.8941     16205
           N     0.7027    0.3920    0.5033      1857
           P     0.7361    0.3742    0.4962      3212

   micro avg     0.8222    0.8222    0.8222     21274
   macro avg     0.7584    0.5755    0.6312     21274
weighted avg     0.8096    0.8222    0.7999     21274

F1-macro tok:  0.6311921022259339
F1-micro tok:  0.8222243113659866
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378444.984375
train_cost_avg: 44.29365453827247
train_count_sent: 8544.0
train_total_correct_sent: 4887.0
train_accuracy_sent: 0.5719803370786517
train_count_tok: 163566.0
train_total_correct_tok: 132437.0
train_accuracy_tok: 0.8096853869386058
train_label=O_precision_sent: 0.15789473684210525
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036518563603164934
train_label=N_precision_sent: 0.5430772822787766
train_label=N_recall_sent: 0.7027190332326284
train_label=N_f-score_sent: 0.6126695640721719
train_label=P_precision_sent: 0.603017444601603
train_label=P_recall_sent: 0.7085872576177286
train_label=P_f-score_sent: 0.651553744268976
train_precision_macro_sent: 0.43466315457416166
train_recall_macro_sent: 0.47105119383025035
train_f-score_macro_sent: 0.4226250549004882
train_precision_micro_sent: 0.5719803370786517
train_recall_micro_sent: 0.5719803370786517
train_f-score_micro_sent: 0.5719803370786517
train_label=O_precision_tok: 0.8334156634158045
train_label=O_recall_tok: 0.9497615543599766
train_label=O_f-score_tok: 0.8877930337188454
train_label=N_precision_tok: 0.6347856075410967
train_label=N_recall_tok: 0.38881847627094773
train_label=N_f-score_tok: 0.482249683419938
train_label=P_precision_tok: 0.6697819314641744
train_label=P_recall_tok: 0.3523603949314466
train_label=P_f-score_tok: 0.46178427366546176
train_precision_macro_tok: 0.7126610674736918
train_recall_macro_tok: 0.5636468085207903
train_f-score_macro_tok: 0.6106089969347485
train_precision_micro_tok: 0.8096853869386058
train_recall_micro_tok: 0.8096853869386058
train_f-score_micro_tok: 0.8096853869386058
train_time: 145.92112612724304
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1579    0.0018    0.0037      1624
           N     0.5431    0.7027    0.6127      3310
           P     0.6030    0.7086    0.6516      3610

   micro avg     0.5720    0.5720    0.5720      8544
   macro avg     0.4347    0.4711    0.4226      8544
weighted avg     0.4952    0.5720    0.5133      8544

F1-macro sent:  0.4226250549004882
F1-micro sent:  0.5719803370786517
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8334    0.9498    0.8878    124347
           N     0.6348    0.3888    0.4822     14202
           P     0.6698    0.3524    0.4618     25017

   micro avg     0.8097    0.8097    0.8097    163566
   macro avg     0.7127    0.5636    0.6106    163566
weighted avg     0.7911    0.8097    0.7874    163566

F1-macro tok:  0.6106089969347485
F1-micro tok:  0.8096853869386058
**************************************************
dev_cost_sum: 49262.551330566406
dev_cost_avg: 44.7434616989704
dev_count_sent: 1101.0
dev_total_correct_sent: 558.0
dev_accuracy_sent: 0.5068119891008175
dev_count_tok: 21274.0
dev_total_correct_tok: 17672.0
dev_accuracy_tok: 0.8306853436119207
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.44306418219461696
dev_label=N_recall_sent: 1.0
dev_label=N_f-score_sent: 0.6140602582496414
dev_label=P_precision_sent: 0.9629629629629629
dev_label=P_recall_sent: 0.2927927927927928
dev_label=P_f-score_sent: 0.4490500863557858
dev_precision_macro_sent: 0.46867571505252664
dev_recall_macro_sent: 0.4309309309309309
dev_f-score_macro_sent: 0.35437011486847575
dev_precision_micro_sent: 0.5068119891008175
dev_recall_micro_sent: 0.5068119891008175
dev_f-score_micro_sent: 0.5068119891008175
dev_label=O_precision_tok: 0.8350956963096119
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.8995130840855378
dev_label=N_precision_tok: 0.739049394221808
dev_label=N_recall_tok: 0.42703284868066776
dev_label=N_f-score_tok: 0.5412969283276451
dev_label=P_precision_tok: 0.8422688422688422
dev_label=P_recall_tok: 0.33748443337484435
dev_label=P_f-score_tok: 0.48188486330295616
dev_precision_macro_tok: 0.8054713109334207
dev_recall_macro_tok: 0.5797388163264338
dev_f-score_macro_tok: 0.6408982919053797
dev_precision_micro_tok: 0.8306853436119207
dev_recall_micro_tok: 0.8306853436119207
dev_f-score_micro_tok: 0.8306853436119207
dev_time: 8.45328950881958
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4431    1.0000    0.6141       428
           P     0.9630    0.2928    0.4491       444

   micro avg     0.5068    0.5068    0.5068      1101
   macro avg     0.4687    0.4309    0.3544      1101
weighted avg     0.5606    0.5068    0.4198      1101

F1-macro sent:  0.35437011486847575
F1-micro sent:  0.5068119891008175
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8351    0.9747    0.8995     16205
           N     0.7390    0.4270    0.5413      1857
           P     0.8423    0.3375    0.4819      3212

   micro avg     0.8307    0.8307    0.8307     21274
   macro avg     0.8055    0.5797    0.6409     21274
weighted avg     0.8278    0.8307    0.8052     21274

F1-macro tok:  0.6408982919053797
F1-micro tok:  0.8306853436119207
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368966.8479003906
train_cost_avg: 43.18432208571988
train_count_sent: 8544.0
train_total_correct_sent: 5021.0
train_accuracy_sent: 0.5876638576779026
train_count_tok: 163566.0
train_total_correct_tok: 135384.0
train_accuracy_tok: 0.8277025787755401
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012300123001230013
train_label=N_precision_sent: 0.5507925876311677
train_label=N_recall_sent: 0.7453172205438067
train_label=N_f-score_sent: 0.6334574399794581
train_label=P_precision_sent: 0.6283534334235786
train_label=P_recall_sent: 0.707202216066482
train_label=P_f-score_sent: 0.6654502802033103
train_precision_macro_sent: 0.5597153403515821
train_recall_macro_sent: 0.48437840005236227
train_f-score_macro_sent: 0.43337924416096385
train_precision_micro_sent: 0.5876638576779026
train_recall_micro_sent: 0.5876638576779026
train_f-score_micro_sent: 0.5876638576779026
train_label=O_precision_tok: 0.848710548366074
train_label=O_recall_tok: 0.9530426950388832
train_label=O_f-score_tok: 0.8978558981741042
train_label=N_precision_tok: 0.671003717472119
train_label=N_recall_tok: 0.43212223630474583
train_label=N_f-score_tok: 0.5256981326023642
train_label=P_precision_tok: 0.7262460269155339
train_label=P_recall_tok: 0.4292680976935684
train_label=P_f-score_tok: 0.5395940106521957
train_precision_macro_tok: 0.7486534309179089
train_recall_macro_tok: 0.6048110096790658
train_f-score_macro_tok: 0.6543826804762213
train_precision_micro_tok: 0.8277025787755401
train_recall_micro_tok: 0.8277025787755401
train_f-score_micro_tok: 0.8277025787755401
train_time: 142.39668440818787
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0006    0.0012      1624
           N     0.5508    0.7453    0.6335      3310
           P     0.6284    0.7072    0.6655      3610

   micro avg     0.5877    0.5877    0.5877      8544
   macro avg     0.5597    0.4844    0.4334      8544
weighted avg     0.5739    0.5877    0.5268      8544

F1-macro sent:  0.43337924416096385
F1-micro sent:  0.5876638576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8487    0.9530    0.8979    124347
           N     0.6710    0.4321    0.5257     14202
           P     0.7262    0.4293    0.5396     25017

   micro avg     0.8277    0.8277    0.8277    163566
   macro avg     0.7487    0.6048    0.6544    163566
weighted avg     0.8146    0.8277    0.8107    163566

F1-macro tok:  0.6543826804762213
F1-micro tok:  0.8277025787755401
**************************************************
dev_cost_sum: 48103.74353027344
dev_cost_avg: 43.690956884898675
dev_count_sent: 1101.0
dev_total_correct_sent: 695.0
dev_accuracy_sent: 0.631244323342416
dev_count_tok: 21274.0
dev_total_correct_tok: 18228.0
dev_accuracy_tok: 0.8568205321049168
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5965811965811966
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.6890424481737414
dev_label=P_precision_sent: 0.6705653021442495
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7189132706374085
dev_precision_macro_sent: 0.6446043884640376
dev_recall_macro_sent: 0.5329763199921956
dev_f-score_macro_sent: 0.4750656993738316
dev_precision_micro_sent: 0.631244323342416
dev_recall_micro_sent: 0.631244323342416
dev_f-score_micro_sent: 0.631244323342416
dev_label=O_precision_tok: 0.8727609635577517
dev_label=O_recall_tok: 0.9591484109842641
dev_label=O_f-score_tok: 0.9139177985535368
dev_label=N_precision_tok: 0.749554367201426
dev_label=N_recall_tok: 0.45288099084544964
dev_label=N_f-score_tok: 0.5646189996643168
dev_label=P_precision_tok: 0.7870251813913786
dev_label=P_recall_tok: 0.5740971357409713
dev_label=P_f-score_tok: 0.6639063906390639
dev_precision_macro_tok: 0.8031135040501854
dev_recall_macro_tok: 0.6620421791902283
dev_f-score_macro_tok: 0.7141477296189725
dev_precision_micro_tok: 0.8568205321049168
dev_recall_micro_tok: 0.8568205321049168
dev_f-score_micro_tok: 0.8568205321049168
dev_time: 7.086244821548462
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5966    0.8154    0.6890       428
           P     0.6706    0.7748    0.7189       444

   micro avg     0.6312    0.6312    0.6312      1101
   macro avg     0.6446    0.5330    0.4751      1101
weighted avg     0.6410    0.6312    0.5614      1101

F1-macro sent:  0.4750656993738316
F1-micro sent:  0.631244323342416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8728    0.9591    0.9139     16205
           N     0.7496    0.4529    0.5646      1857
           P     0.7870    0.5741    0.6639      3212

   micro avg     0.8568    0.8568    0.8568     21274
   macro avg     0.8031    0.6620    0.7141     21274
weighted avg     0.8491    0.8568    0.8457     21274

F1-macro tok:  0.7141477296189725
F1-micro tok:  0.8568205321049168
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361758.5773925781
train_cost_avg: 42.3406574663598
train_count_sent: 8544.0
train_total_correct_sent: 5102.0
train_accuracy_sent: 0.5971441947565543
train_count_tok: 163566.0
train_total_correct_tok: 137677.0
train_accuracy_tok: 0.8417213846398396
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003667481662591687
train_label=N_precision_sent: 0.5590270029011382
train_label=N_recall_sent: 0.756797583081571
train_label=N_f-score_sent: 0.6430496726992684
train_label=P_precision_sent: 0.6403357195754135
train_label=P_recall_sent: 0.7185595567867036
train_label=P_f-score_sent: 0.6771961884871426
train_precision_macro_sent: 0.4831209074921839
train_recall_macro_sent: 0.4924014768362229
train_f-score_macro_sent: 0.4413044476163342
train_precision_micro_sent: 0.5971441947565543
train_recall_micro_sent: 0.5971441947565543
train_f-score_micro_sent: 0.5971441947565543
train_label=O_precision_tok: 0.8609027732486938
train_label=O_recall_tok: 0.9554070464104482
train_label=O_f-score_tok: 0.9056963376330314
train_label=N_precision_tok: 0.695021186440678
train_label=N_recall_tok: 0.4619771863117871
train_label=N_f-score_tok: 0.5550291853481093
train_label=P_precision_tok: 0.7634695269390539
train_label=P_recall_tok: 0.49222528680497263
train_label=P_f-score_tok: 0.5985514995382297
train_precision_macro_tok: 0.7731311622094753
train_recall_macro_tok: 0.6365365065090692
train_f-score_macro_tok: 0.6864256741731234
train_precision_micro_tok: 0.8417213846398396
train_recall_micro_tok: 0.8417213846398396
train_f-score_micro_tok: 0.8417213846398396
train_time: 96.13957095146179
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0018    0.0037      1624
           N     0.5590    0.7568    0.6430      3310
           P     0.6403    0.7186    0.6772      3610

   micro avg     0.5971    0.5971    0.5971      8544
   macro avg     0.4831    0.4924    0.4413      8544
weighted avg     0.5346    0.5971    0.5359      8544

F1-macro sent:  0.4413044476163342
F1-micro sent:  0.5971441947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8609    0.9554    0.9057    124347
           N     0.6950    0.4620    0.5550     14202
           P     0.7635    0.4922    0.5986     25017

   micro avg     0.8417    0.8417    0.8417    163566
   macro avg     0.7731    0.6365    0.6864    163566
weighted avg     0.8316    0.8417    0.8283    163566

F1-macro tok:  0.6864256741731234
F1-micro tok:  0.8417213846398396
**************************************************
dev_cost_sum: 47414.73046875
dev_cost_avg: 43.06515028950954
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18401.0
dev_accuracy_tok: 0.8649525242079533
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6405622489959839
dev_label=N_recall_sent: 0.7453271028037384
dev_label=N_f-score_sent: 0.6889848812095032
dev_label=P_precision_sent: 0.6156405990016639
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.708133971291866
dev_precision_macro_sent: 0.4187342826658826
dev_recall_macro_sent: 0.526220145379024
dev_f-score_macro_sent: 0.46570628416712306
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.874665327978581
dev_label=O_recall_tok: 0.9676643011416229
dev_label=O_f-score_tok: 0.9188175665777987
dev_label=N_precision_tok: 0.7684117125110914
dev_label=N_recall_tok: 0.4663435648896069
dev_label=N_f-score_tok: 0.5804289544235925
dev_label=P_precision_tok: 0.8355114916629113
dev_label=P_recall_tok: 0.5772104607721046
dev_label=P_f-score_tok: 0.6827471920456638
dev_precision_macro_tok: 0.8261961773841945
dev_recall_macro_tok: 0.6704061089344449
dev_f-score_macro_tok: 0.7273312376823516
dev_precision_micro_tok: 0.8649525242079533
dev_recall_micro_tok: 0.8649525242079533
dev_f-score_micro_tok: 0.8649525242079533
dev_time: 5.0615150928497314
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6406    0.7453    0.6890       428
           P     0.6156    0.8333    0.7081       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.4187    0.5262    0.4657      1101
weighted avg     0.4973    0.6258    0.5534      1101

F1-macro sent:  0.46570628416712306
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8747    0.9677    0.9188     16205
           N     0.7684    0.4663    0.5804      1857
           P     0.8355    0.5772    0.6827      3212

   micro avg     0.8650    0.8650    0.8650     21274
   macro avg     0.8262    0.6704    0.7273     21274
weighted avg     0.8595    0.8650    0.8536     21274

F1-macro tok:  0.7273312376823516
F1-micro tok:  0.8649525242079533
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355795.1711425781
train_cost_avg: 41.64269325170624
train_count_sent: 8544.0
train_total_correct_sent: 5223.0
train_accuracy_sent: 0.6113061797752809
train_count_tok: 163566.0
train_total_correct_tok: 139163.0
train_accuracy_tok: 0.8508064023085482
train_label=O_precision_sent: 0.375
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007317073170731707
train_label=N_precision_sent: 0.574966231427285
train_label=N_recall_sent: 0.7716012084592145
train_label=N_f-score_sent: 0.6589267285861713
train_label=P_precision_sent: 0.6517376407244249
train_label=P_recall_sent: 0.7376731301939058
train_label=P_f-score_sent: 0.6920478170478169
train_precision_macro_sent: 0.5339012907172366
train_recall_macro_sent: 0.5043229733113028
train_f-score_macro_sent: 0.4527638729349066
train_precision_micro_sent: 0.6113061797752809
train_recall_micro_sent: 0.6113061797752809
train_f-score_micro_sent: 0.6113061797752809
train_label=O_precision_tok: 0.8685040919392805
train_label=O_recall_tok: 0.9584228007109138
train_label=O_f-score_tok: 0.9112506116956202
train_label=N_precision_tok: 0.7069145602673909
train_label=N_recall_tok: 0.47655259822560203
train_label=N_f-score_tok: 0.5693135935397039
train_label=P_precision_tok: 0.7881462047582136
train_label=P_recall_tok: 0.5283607147139945
train_label=P_f-score_tok: 0.6326218053029578
train_precision_macro_tok: 0.7878549523216284
train_recall_macro_tok: 0.6544453712168368
train_f-score_macro_tok: 0.704395336846094
train_precision_micro_tok: 0.8508064023085482
train_recall_micro_tok: 0.8508064023085482
train_f-score_micro_tok: 0.8508064023085481
train_time: 95.71299028396606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3750    0.0037    0.0073      1624
           N     0.5750    0.7716    0.6589      3310
           P     0.6517    0.7377    0.6920      3610

   micro avg     0.6113    0.6113    0.6113      8544
   macro avg     0.5339    0.5043    0.4528      8544
weighted avg     0.5694    0.6113    0.5491      8544

F1-macro sent:  0.4527638729349066
F1-micro sent:  0.6113061797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8685    0.9584    0.9113    124347
           N     0.7069    0.4766    0.5693     14202
           P     0.7881    0.5284    0.6326     25017

   micro avg     0.8508    0.8508    0.8508    163566
   macro avg     0.7879    0.6544    0.7044    163566
weighted avg     0.8422    0.8508    0.8389    163566

F1-macro tok:  0.704395336846094
F1-micro tok:  0.8508064023085481
**************************************************
dev_cost_sum: 46788.57275390625
dev_cost_avg: 42.49643301898842
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18509.0
dev_accuracy_tok: 0.8700291435555138
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6101398601398601
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.698
dev_label=P_precision_sent: 0.6597353497164461
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7173689619732785
dev_precision_macro_sent: 0.42329173661876873
dev_recall_macro_sent: 0.5338188655945665
dev_f-score_macro_sent: 0.4717896539910928
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.880604562310372
dev_label=O_recall_tok: 0.967170626349892
dev_label=O_f-score_tok: 0.9218598358968326
dev_label=N_precision_tok: 0.7425057647963106
dev_label=N_recall_tok: 0.5201938610662359
dev_label=N_f-score_tok: 0.6117796073464218
dev_label=P_precision_tok: 0.8597701149425288
dev_label=P_recall_tok: 0.5821917808219178
dev_label=P_f-score_tok: 0.6942639688138109
dev_precision_macro_tok: 0.8276268140164037
dev_recall_macro_tok: 0.6898520894126818
dev_f-score_macro_tok: 0.7426344706856884
dev_precision_micro_tok: 0.8700291435555138
dev_recall_micro_tok: 0.8700291435555138
dev_f-score_micro_tok: 0.8700291435555138
dev_time: 5.130859136581421
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6101    0.8154    0.6980       428
           P     0.6597    0.7860    0.7174       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.4233    0.5338    0.4718      1101
weighted avg     0.5032    0.6340    0.5606      1101

F1-macro sent:  0.4717896539910928
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9672    0.9219     16205
           N     0.7425    0.5202    0.6118      1857
           P     0.8598    0.5822    0.6943      3212

   micro avg     0.8700    0.8700    0.8700     21274
   macro avg     0.8276    0.6899    0.7426     21274
weighted avg     0.8654    0.8700    0.8604     21274

F1-macro tok:  0.7426344706856884
F1-micro tok:  0.8700291435555138
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351050.78466796875
train_cost_avg: 41.08740457256189
train_count_sent: 8544.0
train_total_correct_sent: 5281.0
train_accuracy_sent: 0.6180945692883895
train_count_tok: 163566.0
train_total_correct_tok: 140198.0
train_accuracy_tok: 0.8571341232285439
train_label=O_precision_sent: 0.38461538461538464
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006108735491753207
train_label=N_precision_sent: 0.5792931581332125
train_label=N_recall_sent: 0.7725075528700907
train_label=N_f-score_sent: 0.6620921802175038
train_label=P_precision_sent: 0.6604323536555744
train_label=P_recall_sent: 0.753185595567867
train_label=P_f-score_sent: 0.7037660152711271
train_precision_macro_sent: 0.5414469654680572
train_recall_macro_sent: 0.5095906553906492
train_f-score_macro_sent: 0.4573223103267947
train_precision_micro_sent: 0.6180945692883895
train_recall_micro_sent: 0.6180945692883895
train_f-score_micro_sent: 0.6180945692883895
train_label=O_precision_tok: 0.8731676646268799
train_label=O_recall_tok: 0.9604654716237625
train_label=O_f-score_tok: 0.9147384787420632
train_label=N_precision_tok: 0.7214022140221402
train_label=N_recall_tok: 0.4955640050697085
train_label=N_f-score_tok: 0.5875281743050338
train_label=P_precision_tok: 0.8061182549468616
train_label=P_recall_tok: 0.5487868249590279
train_label=P_f-score_tok: 0.653015601217656
train_precision_macro_tok: 0.8002293778652939
train_recall_macro_tok: 0.668272100550833
train_f-score_macro_tok: 0.718427418088251
train_precision_micro_tok: 0.8571341232285439
train_recall_micro_tok: 0.8571341232285439
train_f-score_micro_tok: 0.857134123228544
train_time: 95.3693675994873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.0031    0.0061      1624
           N     0.5793    0.7725    0.6621      3310
           P     0.6604    0.7532    0.7038      3610

   micro avg     0.6181    0.6181    0.6181      8544
   macro avg     0.5414    0.5096    0.4573      8544
weighted avg     0.5766    0.6181    0.5550      8544

F1-macro sent:  0.4573223103267947
F1-micro sent:  0.6180945692883895
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8732    0.9605    0.9147    124347
           N     0.7214    0.4956    0.5875     14202
           P     0.8061    0.5488    0.6530     25017

   micro avg     0.8571    0.8571    0.8571    163566
   macro avg     0.8002    0.6683    0.7184    163566
weighted avg     0.8497    0.8571    0.8463    163566

F1-macro tok:  0.718427418088251
F1-micro tok:  0.857134123228544
**************************************************
dev_cost_sum: 46325.00830078125
dev_cost_avg: 42.07539355202657
dev_count_sent: 1101.0
dev_total_correct_sent: 666.0
dev_accuracy_sent: 0.6049046321525886
dev_count_tok: 21274.0
dev_total_correct_tok: 18624.0
dev_accuracy_tok: 0.8754348030459717
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6829896907216495
dev_label=N_recall_sent: 0.6191588785046729
dev_label=N_f-score_sent: 0.6495098039215687
dev_label=P_precision_sent: 0.5624123422159888
dev_label=P_recall_sent: 0.9031531531531531
dev_label=P_f-score_sent: 0.693171996542783
dev_precision_macro_sent: 0.41513401097921276
dev_recall_macro_sent: 0.507437343885942
dev_f-score_macro_sent: 0.4475606001547839
dev_precision_micro_sent: 0.6049046321525886
dev_recall_micro_sent: 0.6049046321525886
dev_f-score_micro_sent: 0.6049046321525886
dev_label=O_precision_tok: 0.8769409294358181
dev_label=O_recall_tok: 0.9793273680962666
dev_label=O_f-score_tok: 0.9253104775231766
dev_label=N_precision_tok: 0.8114387846291331
dev_label=N_recall_tok: 0.48896068928379105
dev_label=N_f-score_tok: 0.6102150537634409
dev_label=P_precision_tok: 0.8969873663751214
dev_label=P_recall_tok: 0.574719800747198
dev_label=P_f-score_tok: 0.7005692599620493
dev_precision_macro_tok: 0.8617890268133576
dev_recall_macro_tok: 0.6810026193757519
dev_f-score_macro_tok: 0.7453649304162223
dev_precision_micro_tok: 0.8754348030459717
dev_recall_micro_tok: 0.8754348030459717
dev_f-score_micro_tok: 0.8754348030459717
dev_time: 5.2450270652771
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6830    0.6192    0.6495       428
           P     0.5624    0.9032    0.6932       444

   micro avg     0.6049    0.6049    0.6049      1101
   macro avg     0.4151    0.5074    0.4476      1101
weighted avg     0.4923    0.6049    0.5320      1101

F1-macro sent:  0.4475606001547839
F1-micro sent:  0.6049046321525886
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8769    0.9793    0.9253     16205
           N     0.8114    0.4890    0.6102      1857
           P     0.8970    0.5747    0.7006      3212

   micro avg     0.8754    0.8754    0.8754     21274
   macro avg     0.8618    0.6810    0.7454     21274
weighted avg     0.8742    0.8754    0.8639     21274

F1-macro tok:  0.7453649304162223
F1-micro tok:  0.8754348030459717
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346948.39489746094
train_cost_avg: 40.60725595709983
train_count_sent: 8544.0
train_total_correct_sent: 5317.0
train_accuracy_sent: 0.622308052434457
train_count_tok: 163566.0
train_total_correct_tok: 141237.0
train_accuracy_tok: 0.8634862991086167
train_label=O_precision_sent: 0.2
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012277470841006754
train_label=N_precision_sent: 0.5909514925373134
train_label=N_recall_sent: 0.7655589123867069
train_label=N_f-score_sent: 0.6670176362200579
train_label=P_precision_sent: 0.654434250764526
train_label=P_recall_sent: 0.7706371191135734
train_label=P_f-score_sent: 0.7077979900775984
train_precision_macro_sent: 0.4817952477672798
train_recall_macro_sent: 0.5122705983490261
train_f-score_macro_sent: 0.4586811244605857
train_precision_micro_sent: 0.622308052434457
train_recall_micro_sent: 0.622308052434457
train_f-score_micro_sent: 0.622308052434457
train_label=O_precision_tok: 0.877976931983058
train_label=O_recall_tok: 0.9635455620159714
train_label=O_f-score_tok: 0.9187732206600131
train_label=N_precision_tok: 0.7374335306511488
train_label=N_recall_tok: 0.5175327418673427
train_label=N_f-score_tok: 0.6082171376556746
train_label=P_precision_tok: 0.8213973034494835
train_label=P_recall_tok: 0.5625374745173282
train_label=P_f-score_tok: 0.6677580071174377
train_precision_macro_tok: 0.8122692553612301
train_recall_macro_tok: 0.6812052594668808
train_f-score_macro_tok: 0.7315827884777085
train_precision_micro_tok: 0.8634862991086167
train_recall_micro_tok: 0.8634862991086167
train_f-score_micro_tok: 0.8634862991086167
train_time: 95.477712392807
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2000    0.0006    0.0012      1624
           N     0.5910    0.7656    0.6670      3310
           P     0.6544    0.7706    0.7078      3610

   micro avg     0.6223    0.6223    0.6223      8544
   macro avg     0.4818    0.5123    0.4587      8544
weighted avg     0.5435    0.6223    0.5577      8544

F1-macro sent:  0.4586811244605857
F1-micro sent:  0.622308052434457
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8780    0.9635    0.9188    124347
           N     0.7374    0.5175    0.6082     14202
           P     0.8214    0.5625    0.6678     25017

   micro avg     0.8635    0.8635    0.8635    163566
   macro avg     0.8123    0.6812    0.7316    163566
weighted avg     0.8571    0.8635    0.8534    163566

F1-macro tok:  0.7315827884777085
F1-micro tok:  0.8634862991086167
**************************************************
dev_cost_sum: 45989.23474121094
dev_cost_avg: 41.77042210827515
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18654.0
dev_accuracy_tok: 0.8768449750869606
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.638095238095238
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7030430220356768
dev_label=P_precision_sent: 0.6354166666666666
dev_label=P_recall_sent: 0.8243243243243243
dev_label=P_f-score_sent: 0.7176470588235293
dev_precision_macro_sent: 0.4245039682539682
dev_recall_macro_sent: 0.5356782015660521
dev_f-score_macro_sent: 0.473563360286402
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8809961557746949
dev_label=O_recall_tok: 0.9758099352051836
dev_label=O_f-score_tok: 0.9259823153949757
dev_label=N_precision_tok: 0.8543983822042467
dev_label=N_recall_tok: 0.4550350026925148
dev_label=N_f-score_tok: 0.5938158819395642
dev_label=P_precision_tok: 0.8544520547945206
dev_label=P_recall_tok: 0.6214196762141968
dev_label=P_f-score_tok: 0.7195385724585437
dev_precision_macro_tok: 0.8632821975911541
dev_recall_macro_tok: 0.684088204703965
dev_f-score_macro_tok: 0.7464455899310279
dev_precision_micro_tok: 0.8768449750869606
dev_recall_micro_tok: 0.8768449750869606
dev_f-score_micro_tok: 0.8768449750869606
dev_time: 5.137283563613892
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6381    0.7827    0.7030       428
           P     0.6354    0.8243    0.7176       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4245    0.5357    0.4736      1101
weighted avg     0.5043    0.6367    0.5627      1101

F1-macro sent:  0.473563360286402
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8810    0.9758    0.9260     16205
           N     0.8544    0.4550    0.5938      1857
           P     0.8545    0.6214    0.7195      3212

   micro avg     0.8768    0.8768    0.8768     21274
   macro avg     0.8633    0.6841    0.7464     21274
weighted avg     0.8747    0.8768    0.8658     21274

F1-macro tok:  0.7464455899310279
F1-micro tok:  0.8768449750869606
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 343119.5319213867
train_cost_avg: 40.159121245480655
train_count_sent: 8544.0
train_total_correct_sent: 5419.0
train_accuracy_sent: 0.634246254681648
train_count_tok: 163566.0
train_total_correct_tok: 141702.0
train_accuracy_tok: 0.8663291882176002
train_label=O_precision_sent: 0.16666666666666666
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012269938650306747
train_label=N_precision_sent: 0.6094156612254554
train_label=N_recall_sent: 0.7782477341389729
train_label=N_f-score_sent: 0.6835610985803371
train_label=P_precision_sent: 0.6592437949431686
train_label=P_recall_sent: 0.7872576177285319
train_label=P_f-score_sent: 0.7175861633632117
train_precision_macro_sent: 0.4784420409450969
train_recall_macro_sent: 0.5220403718047676
train_f-score_macro_sent: 0.4674580852695265
train_precision_micro_sent: 0.634246254681648
train_recall_micro_sent: 0.634246254681648
train_f-score_micro_sent: 0.634246254681648
train_label=O_precision_tok: 0.8804338248252365
train_label=O_recall_tok: 0.9642452170136795
train_label=O_f-score_tok: 0.9204355719664838
train_label=N_precision_tok: 0.7410086198355296
train_label=N_recall_tok: 0.526615969581749
train_label=N_f-score_tok: 0.6156822391438568
train_label=P_precision_tok: 0.8283879923650876
train_label=P_recall_tok: 0.5724907063197026
train_label=P_f-score_tok: 0.6770670826833074
train_precision_macro_tok: 0.8166101456752846
train_recall_macro_tok: 0.6877839643050437
train_f-score_macro_tok: 0.737728297931216
train_precision_micro_tok: 0.8663291882176002
train_recall_micro_tok: 0.8663291882176002
train_f-score_micro_tok: 0.8663291882176002
train_time: 96.18030953407288
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1667    0.0006    0.0012      1624
           N     0.6094    0.7782    0.6836      3310
           P     0.6592    0.7873    0.7176      3610

   micro avg     0.6342    0.6342    0.6342      8544
   macro avg     0.4784    0.5220    0.4675      8544
weighted avg     0.5463    0.6342    0.5682      8544

F1-macro sent:  0.4674580852695265
F1-micro sent:  0.634246254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9642    0.9204    124347
           N     0.7410    0.5266    0.6157     14202
           P     0.8284    0.5725    0.6771     25017

   micro avg     0.8663    0.8663    0.8663    163566
   macro avg     0.8166    0.6878    0.7377    163566
weighted avg     0.8604    0.8663    0.8568    163566

F1-macro tok:  0.737728297931216
F1-micro tok:  0.8663291882176002
**************************************************
dev_cost_sum: 45384.18035888672
dev_cost_avg: 41.22087226056923
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18764.0
dev_accuracy_tok: 0.8820156059039203
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5763473053892215
dev_label=N_recall_sent: 0.8995327102803738
dev_label=N_f-score_sent: 0.7025547445255474
dev_label=P_precision_sent: 0.7251732101616628
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7160775370581528
dev_precision_macro_sent: 0.4338401718502947
dev_recall_macro_sent: 0.5355799724958604
dev_f-score_macro_sent: 0.47287742719456677
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8917631041524847
dev_label=O_recall_tok: 0.9700709657513114
dev_label=O_f-score_tok: 0.9292702391156563
dev_label=N_precision_tok: 0.7370892018779343
dev_label=N_recall_tok: 0.5918147549811524
dev_label=N_f-score_tok: 0.6565113500597372
dev_label=P_precision_tok: 0.9025522041763341
dev_label=P_recall_tok: 0.6055417185554172
dev_label=P_f-score_tok: 0.7247997018818707
dev_precision_macro_tok: 0.843801503402251
dev_recall_macro_tok: 0.7224758130959602
dev_f-score_macro_tok: 0.7701937636857547
dev_precision_micro_tok: 0.8820156059039203
dev_recall_micro_tok: 0.8820156059039203
dev_f-score_micro_tok: 0.8820156059039203
dev_time: 5.319248676300049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5763    0.8995    0.7026       428
           P     0.7252    0.7072    0.7161       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.4338    0.5356    0.4729      1101
weighted avg     0.5165    0.6349    0.5619      1101

F1-macro sent:  0.47287742719456677
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9701    0.9293     16205
           N     0.7371    0.5918    0.6565      1857
           P     0.9026    0.6055    0.7248      3212

   micro avg     0.8820    0.8820    0.8820     21274
   macro avg     0.8438    0.7225    0.7702     21274
weighted avg     0.8799    0.8820    0.8746     21274

F1-macro tok:  0.7701937636857547
F1-micro tok:  0.8820156059039203
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339279.9356689453
train_cost_avg: 39.709730298331614
train_count_sent: 8544.0
train_total_correct_sent: 5433.0
train_accuracy_sent: 0.6358848314606742
train_count_tok: 163566.0
train_total_correct_tok: 142345.0
train_accuracy_tok: 0.8702603230500227
train_label=O_precision_sent: 0.2903225806451613
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010876132930513595
train_label=N_precision_sent: 0.5985003408316292
train_label=N_recall_sent: 0.7957703927492447
train_label=N_f-score_sent: 0.6831798729088314
train_label=P_precision_sent: 0.6785019455252919
train_label=P_recall_sent: 0.7728531855955678
train_label=P_f-score_sent: 0.7226107226107227
train_precision_macro_sent: 0.5224416223340275
train_recall_macro_sent: 0.5247218167553316
train_f-score_macro_sent: 0.4722222428166892
train_precision_micro_sent: 0.6358848314606742
train_recall_micro_sent: 0.6358848314606742
train_f-score_micro_sent: 0.6358848314606742
train_label=O_precision_tok: 0.8839106268634741
train_label=O_recall_tok: 0.9655721489058844
train_label=O_f-score_tok: 0.9229385583937398
train_label=N_precision_tok: 0.744282945736434
train_label=N_recall_tok: 0.5408393184058583
train_label=N_f-score_tok: 0.6264578745616182
train_label=P_precision_tok: 0.8384354718281546
train_label=P_recall_tok: 0.5835232042211296
train_label=P_f-score_tok: 0.6881304798717827
train_precision_macro_tok: 0.8222096814760209
train_recall_macro_tok: 0.6966448905109575
train_f-score_macro_tok: 0.7458423042757136
train_precision_micro_tok: 0.8702603230500227
train_recall_micro_tok: 0.8702603230500227
train_f-score_micro_tok: 0.8702603230500227
train_time: 96.2965931892395
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2903    0.0055    0.0109      1624
           N     0.5985    0.7958    0.6832      3310
           P     0.6785    0.7729    0.7226      3610

   micro avg     0.6359    0.6359    0.6359      8544
   macro avg     0.5224    0.5247    0.4722      8544
weighted avg     0.5737    0.6359    0.5721      8544

F1-macro sent:  0.4722222428166892
F1-micro sent:  0.6358848314606742
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8839    0.9656    0.9229    124347
           N     0.7443    0.5408    0.6265     14202
           P     0.8384    0.5835    0.6881     25017

   micro avg     0.8703    0.8703    0.8703    163566
   macro avg     0.8222    0.6966    0.7458    163566
weighted avg     0.8648    0.8703    0.8613    163566

F1-macro tok:  0.7458423042757136
F1-micro tok:  0.8702603230500227
**************************************************
dev_cost_sum: 44996.157653808594
dev_cost_avg: 40.868444735520974
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 18834.0
dev_accuracy_tok: 0.8853060073328947
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.5755287009063444
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.6990825688073394
dev_label=P_precision_sent: 0.716589861751152
dev_label=P_recall_sent: 0.7004504504504504
dev_label=P_f-score_sent: 0.7084282460136673
dev_precision_macro_sent: 0.6973728542191656
dev_recall_macro_sent: 0.536034871748866
dev_f-score_macro_sent: 0.4805662830030137
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.8896629213483146
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9313924422878989
dev_label=N_precision_tok: 0.7871362940275651
dev_label=N_recall_tok: 0.5535810446957459
dev_label=N_f-score_tok: 0.6500158077774266
dev_label=P_precision_tok: 0.9086715867158671
dev_label=P_recall_tok: 0.6133250311332503
dev_label=P_f-score_tok: 0.7323420074349443
dev_precision_macro_tok: 0.861823600697249
dev_recall_macro_tok: 0.7147117753534687
dev_f-score_macro_tok: 0.7712500858334232
dev_precision_micro_tok: 0.8853060073328947
dev_recall_micro_tok: 0.8853060073328947
dev_f-score_micro_tok: 0.8853060073328947
dev_time: 5.171269655227661
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.5755    0.8902    0.6991       428
           P     0.7166    0.7005    0.7084       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.6974    0.5360    0.4806      1101
weighted avg     0.6791    0.6322    0.5646      1101

F1-macro sent:  0.4805662830030137
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8897    0.9772    0.9314     16205
           N     0.7871    0.5536    0.6500      1857
           P     0.9087    0.6133    0.7323      3212

   micro avg     0.8853    0.8853    0.8853     21274
   macro avg     0.8618    0.7147    0.7713     21274
weighted avg     0.8836    0.8853    0.8768     21274

F1-macro tok:  0.7712500858334232
F1-micro tok:  0.8853060073328947
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336145.96954345703
train_cost_avg: 39.3429271469402
train_count_sent: 8544.0
train_total_correct_sent: 5404.0
train_accuracy_sent: 0.6324906367041199
train_count_tok: 163566.0
train_total_correct_tok: 142917.0
train_accuracy_tok: 0.8737573823410734
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013365735115431349
train_label=N_precision_sent: 0.5982309124767226
train_label=N_recall_sent: 0.7764350453172205
train_label=N_f-score_sent: 0.6757822771496188
train_label=P_precision_sent: 0.6680075721722669
train_label=P_recall_sent: 0.781994459833795
train_label=P_f-score_sent: 0.72052067381317
train_precision_macro_sent: 0.5887461615496632
train_recall_macro_sent: 0.521734301388598
train_f-score_macro_sent: 0.4698895620260734
train_precision_micro_sent: 0.6324906367041199
train_recall_micro_sent: 0.6324906367041199
train_f-score_micro_sent: 0.6324906367041199
train_label=O_precision_tok: 0.8862512436894278
train_label=O_recall_tok: 0.9670599210274474
train_label=O_f-score_tok: 0.9248938592173271
train_label=N_precision_tok: 0.7513242800731966
train_label=N_recall_tok: 0.5492888325587946
train_label=N_f-score_tok: 0.6346146023998374
train_label=P_precision_tok: 0.8495256600754372
train_label=P_recall_tok: 0.5941959467562058
train_label=P_f-score_tok: 0.6992826061390098
train_precision_macro_tok: 0.8290337279460206
train_recall_macro_tok: 0.7035149001141493
train_f-score_macro_tok: 0.7529303559187248
train_precision_micro_tok: 0.8737573823410734
train_recall_micro_tok: 0.8737573823410734
train_f-score_micro_tok: 0.8737573823410734
train_time: 96.40828800201416
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0068    0.0134      1624
           N     0.5982    0.7764    0.6758      3310
           P     0.6680    0.7820    0.7205      3610

   micro avg     0.6325    0.6325    0.6325      8544
   macro avg     0.5887    0.5217    0.4699      8544
weighted avg     0.6090    0.6325    0.5688      8544

F1-macro sent:  0.4698895620260734
F1-micro sent:  0.6324906367041199
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8863    0.9671    0.9249    124347
           N     0.7513    0.5493    0.6346     14202
           P     0.8495    0.5942    0.6993     25017

   micro avg     0.8738    0.8738    0.8738    163566
   macro avg     0.8290    0.7035    0.7529    163566
weighted avg     0.8689    0.8738    0.8652    163566

F1-macro tok:  0.7529303559187248
F1-micro tok:  0.8737573823410734
**************************************************
dev_cost_sum: 44735.61639404297
dev_cost_avg: 40.63180417260942
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 18835.0
dev_accuracy_tok: 0.8853530130675943
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6164383561643836
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7114624505928853
dev_label=P_precision_sent: 0.6731141199226306
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7242455775234131
dev_precision_macro_sent: 0.4298508253623381
dev_recall_macro_sent: 0.5416350930369621
dev_f-score_macro_sent: 0.4785693427054328
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8848932859048466
dev_label=O_recall_tok: 0.9824745448935513
dev_label=O_f-score_tok: 0.9311343100271954
dev_label=N_precision_tok: 0.8212435233160622
dev_label=N_recall_tok: 0.5121163166397416
dev_label=N_f-score_tok: 0.6308457711442786
dev_label=P_precision_tok: 0.9241996233521658
dev_label=P_recall_tok: 0.611145703611457
dev_label=P_f-score_tok: 0.7357571214392804
dev_precision_macro_tok: 0.8767788108576915
dev_recall_macro_tok: 0.7019121883815833
dev_f-score_macro_tok: 0.7659124008702515
dev_precision_micro_tok: 0.8853530130675943
dev_recall_micro_tok: 0.8853530130675943
dev_f-score_micro_tok: 0.8853530130675943
dev_time: 5.118445634841919
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6164    0.8411    0.7115       428
           P     0.6731    0.7838    0.7242       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.4299    0.5416    0.4786      1101
weighted avg     0.5111    0.6431    0.5686      1101

F1-macro sent:  0.4785693427054328
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8849    0.9825    0.9311     16205
           N     0.8212    0.5121    0.6308      1857
           P     0.9242    0.6111    0.7358      3212

   micro avg     0.8854    0.8854    0.8854     21274
   macro avg     0.8768    0.7019    0.7659     21274
weighted avg     0.8853    0.8854    0.8754     21274

F1-macro tok:  0.7659124008702515
F1-micro tok:  0.8853530130675943
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333153.95642089844
train_cost_avg: 38.992738345142605
train_count_sent: 8544.0
train_total_correct_sent: 5510.0
train_accuracy_sent: 0.6448970037453183
train_count_tok: 163566.0
train_total_correct_tok: 143325.0
train_accuracy_tok: 0.8762517882689557
train_label=O_precision_sent: 0.7142857142857143
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006131207847946046
train_label=N_precision_sent: 0.6077665441176471
train_label=N_recall_sent: 0.7990936555891238
train_label=N_f-score_sent: 0.690420255807883
train_label=P_precision_sent: 0.6833930704898447
train_label=P_recall_sent: 0.7922437673130194
train_label=P_f-score_sent: 0.7338037203335471
train_precision_macro_sent: 0.6684817762977353
train_recall_macro_sent: 0.5314720802120444
train_f-score_macro_sent: 0.4767850613297921
train_precision_micro_sent: 0.6448970037453183
train_recall_micro_sent: 0.6448970037453183
train_f-score_micro_sent: 0.6448970037453183
train_label=O_precision_tok: 0.8881731854704827
train_label=O_recall_tok: 0.9680571304494681
train_label=O_f-score_tok: 0.9263962320781289
train_label=N_precision_tok: 0.7532736693358455
train_label=N_recall_tok: 0.5630192930573159
train_label=N_f-score_tok: 0.6443969859370593
train_label=P_precision_tok: 0.8584385763490241
train_label=P_recall_tok: 0.5977535276012311
train_label=P_f-score_tok: 0.7047623536065226
train_precision_macro_tok: 0.8332951437184507
train_recall_macro_tok: 0.7096099837026717
train_f-score_macro_tok: 0.7585185238739035
train_precision_micro_tok: 0.8762517882689557
train_recall_micro_tok: 0.8762517882689557
train_f-score_micro_tok: 0.8762517882689557
train_time: 94.77871370315552
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0031    0.0061      1624
           N     0.6078    0.7991    0.6904      3310
           P     0.6834    0.7922    0.7338      3610

   micro avg     0.6449    0.6449    0.6449      8544
   macro avg     0.6685    0.5315    0.4768      8544
weighted avg     0.6600    0.6449    0.5787      8544

F1-macro sent:  0.4767850613297921
F1-micro sent:  0.6448970037453183
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8882    0.9681    0.9264    124347
           N     0.7533    0.5630    0.6444     14202
           P     0.8584    0.5978    0.7048     25017

   micro avg     0.8763    0.8763    0.8763    163566
   macro avg     0.8333    0.7096    0.7585    163566
weighted avg     0.8719    0.8763    0.8680    163566

F1-macro tok:  0.7585185238739035
F1-micro tok:  0.8762517882689557
**************************************************
dev_cost_sum: 44364.85595703125
dev_cost_avg: 40.295055365151
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18899.0
dev_accuracy_tok: 0.8883613800883707
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6219081272084805
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7082494969818913
dev_label=P_precision_sent: 0.6579439252336449
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7191011235955056
dev_precision_macro_sent: 0.4266173508140418
dev_recall_macro_sent: 0.5384075664449496
dev_f-score_macro_sent: 0.47578354019246566
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8969776310546986
dev_label=O_recall_tok: 0.9724776303609997
dev_label=O_f-score_tok: 0.9332030556049032
dev_label=N_precision_tok: 0.7750177430801988
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.6687078995713411
dev_label=P_precision_tok: 0.89198606271777
dev_label=P_recall_tok: 0.6376089663760897
dev_label=P_f-score_tok: 0.7436456063907043
dev_precision_macro_tok: 0.8546604789508891
dev_recall_macro_tok: 0.7327106103286258
dev_f-score_macro_tok: 0.7818521871889829
dev_precision_micro_tok: 0.8883613800883707
dev_recall_micro_tok: 0.8883613800883707
dev_f-score_micro_tok: 0.8883613800883707
dev_time: 5.239607095718384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6219    0.8224    0.7082       428
           P     0.6579    0.7928    0.7191       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.4266    0.5384    0.4758      1101
weighted avg     0.5071    0.6394    0.5653      1101

F1-macro sent:  0.47578354019246566
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9725    0.9332     16205
           N     0.7750    0.5880    0.6687      1857
           P     0.8920    0.6376    0.7436      3212

   micro avg     0.8884    0.8884    0.8884     21274
   macro avg     0.8547    0.7327    0.7819     21274
weighted avg     0.8856    0.8884    0.8815     21274

F1-macro tok:  0.7818521871889829
F1-micro tok:  0.8883613800883707
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330482.2388305664
train_cost_avg: 38.68003731631161
train_count_sent: 8544.0
train_total_correct_sent: 5523.0
train_accuracy_sent: 0.6464185393258427
train_count_tok: 163566.0
train_total_correct_tok: 143829.0
train_accuracy_tok: 0.8793331132386927
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.01327700663850332
train_label=N_precision_sent: 0.6144578313253012
train_label=N_recall_sent: 0.8012084592145015
train_label=N_f-score_sent: 0.6955153422501966
train_label=P_precision_sent: 0.6817640047675805
train_label=P_recall_sent: 0.7922437673130194
train_label=P_f-score_sent: 0.7328635490070468
train_precision_macro_sent: 0.543185056475405
train_recall_macro_sent: 0.5334085418474331
train_f-score_macro_sent: 0.48055196596524885
train_precision_micro_sent: 0.6464185393258427
train_recall_micro_sent: 0.6464185393258427
train_f-score_micro_sent: 0.6464185393258427
train_label=O_precision_tok: 0.8908885224810902
train_label=O_recall_tok: 0.9689819617682774
train_label=O_f-score_tok: 0.9282957233218025
train_label=N_precision_tok: 0.7645337863344658
train_label=N_recall_tok: 0.5704126179411351
train_label=N_f-score_tok: 0.6533591418662795
train_label=P_precision_tok: 0.8597867178242962
train_label=P_recall_tok: 0.6091058080505256
train_label=P_f-score_tok: 0.7130556855404773
train_precision_macro_tok: 0.8384030088799507
train_recall_macro_tok: 0.7161667959199794
train_f-score_macro_tok: 0.7649035169095196
train_precision_micro_tok: 0.8793331132386927
train_recall_micro_tok: 0.8793331132386927
train_f-score_micro_tok: 0.8793331132386927
train_time: 137.06998372077942
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0068    0.0133      1624
           N     0.6145    0.8012    0.6955      3310
           P     0.6818    0.7922    0.7329      3610

   micro avg     0.6464    0.6464    0.6464      8544
   macro avg     0.5432    0.5334    0.4806      8544
weighted avg     0.5895    0.6464    0.5816      8544

F1-macro sent:  0.48055196596524885
F1-micro sent:  0.6464185393258427
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8909    0.9690    0.9283    124347
           N     0.7645    0.5704    0.6534     14202
           P     0.8598    0.6091    0.7131     25017

   micro avg     0.8793    0.8793    0.8793    163566
   macro avg     0.8384    0.7162    0.7649    163566
weighted avg     0.8752    0.8793    0.8715    163566

F1-macro tok:  0.7649035169095196
F1-micro tok:  0.8793331132386927
**************************************************
dev_cost_sum: 44161.65576171875
dev_cost_avg: 40.11049569638397
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18950.0
dev_accuracy_tok: 0.8907586725580521
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7052896725440806
dev_label=N_recall_sent: 0.6542056074766355
dev_label=N_f-score_sent: 0.6787878787878787
dev_label=P_precision_sent: 0.5838068181818182
dev_label=P_recall_sent: 0.9256756756756757
dev_label=P_f-score_sent: 0.71602787456446
dev_precision_macro_sent: 0.42969883024196626
dev_recall_macro_sent: 0.5266270943841037
dev_f-score_macro_sent: 0.46493858445077957
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8909904868494684
dev_label=O_recall_tok: 0.9825362542425178
dev_label=O_f-score_tok: 0.9345267791636097
dev_label=N_precision_tok: 0.8110236220472441
dev_label=N_recall_tok: 0.5546580506192784
dev_label=N_f-score_tok: 0.6587783818356253
dev_label=P_precision_tok: 0.936269915651359
dev_label=P_recall_tok: 0.6220423412204235
dev_label=P_f-score_tok: 0.7474747474747475
dev_precision_macro_tok: 0.8794280081826905
dev_recall_macro_tok: 0.7197455486940733
dev_f-score_macro_tok: 0.7802599694913276
dev_precision_micro_tok: 0.8907586725580521
dev_recall_micro_tok: 0.8907586725580521
dev_f-score_micro_tok: 0.8907586725580521
dev_time: 8.381488561630249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7053    0.6542    0.6788       428
           P     0.5838    0.9257    0.7160       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.4297    0.5266    0.4649      1101
weighted avg     0.5096    0.6276    0.5526      1101

F1-macro sent:  0.46493858445077957
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8910    0.9825    0.9345     16205
           N     0.8110    0.5547    0.6588      1857
           P     0.9363    0.6220    0.7475      3212

   micro avg     0.8908    0.8908    0.8908     21274
   macro avg     0.8794    0.7197    0.7803     21274
weighted avg     0.8908    0.8908    0.8822     21274

F1-macro tok:  0.7802599694913276
F1-micro tok:  0.8907586725580521
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328625.9235839844
train_cost_avg: 38.46277195505435
train_count_sent: 8544.0
train_total_correct_sent: 5494.0
train_accuracy_sent: 0.6430243445692884
train_count_tok: 163566.0
train_total_correct_tok: 143911.0
train_accuracy_tok: 0.8798344399202769
train_label=O_precision_sent: 0.3076923076923077
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009696969696969699
train_label=N_precision_sent: 0.6144349477682811
train_label=N_recall_sent: 0.7818731117824773
train_label=N_f-score_sent: 0.6881148630683329
train_label=P_precision_sent: 0.6730143985137018
train_label=P_recall_sent: 0.8027700831024931
train_label=P_f-score_sent: 0.732187973724103
train_precision_macro_sent: 0.5317138846580969
train_recall_macro_sent: 0.5298564344197848
train_f-score_macro_sent: 0.47666660216313517
train_precision_micro_sent: 0.6430243445692884
train_recall_micro_sent: 0.6430243445692884
train_f-score_micro_sent: 0.6430243445692884
train_label=O_precision_tok: 0.8916759830306441
train_label=O_recall_tok: 0.9685476931490105
train_label=O_f-score_tok: 0.9285235183914516
train_label=N_precision_tok: 0.7629574586661713
train_label=N_recall_tok: 0.5783692437684833
train_label=N_f-score_tok: 0.6579621916052548
train_label=P_precision_tok: 0.8605988834376586
train_label=P_recall_tok: 0.6100251828756446
train_label=P_f-score_tok: 0.7139649122807017
train_precision_macro_tok: 0.8384107750448248
train_recall_macro_tok: 0.7189807065977128
train_f-score_macro_tok: 0.7668168740924693
train_precision_micro_tok: 0.8798344399202769
train_recall_micro_tok: 0.8798344399202769
train_f-score_micro_tok: 0.8798344399202769
train_time: 144.9289572238922
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3077    0.0049    0.0097      1624
           N     0.6144    0.7819    0.6881      3310
           P     0.6730    0.8028    0.7322      3610

   micro avg     0.6430    0.6430    0.6430      8544
   macro avg     0.5317    0.5299    0.4767      8544
weighted avg     0.5809    0.6430    0.5778      8544

F1-macro sent:  0.47666660216313517
F1-micro sent:  0.6430243445692884
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8917    0.9685    0.9285    124347
           N     0.7630    0.5784    0.6580     14202
           P     0.8606    0.6100    0.7140     25017

   micro avg     0.8798    0.8798    0.8798    163566
   macro avg     0.8384    0.7190    0.7668    163566
weighted avg     0.8757    0.8798    0.8722    163566

F1-macro tok:  0.7668168740924693
F1-micro tok:  0.8798344399202769
**************************************************
dev_cost_sum: 43952.67858886719
dev_cost_avg: 39.920688999879374
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18945.0
dev_accuracy_tok: 0.890523643884554
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.6256781193490054
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7054026503567788
dev_label=P_precision_sent: 0.6556169429097606
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7213779128672747
dev_precision_macro_sent: 0.5604316874195887
dev_recall_macro_sent: 0.5396488804030738
dev_f-score_macro_sent: 0.4812915267726902
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.888295505117935
dev_label=O_recall_tok: 0.9853748842949707
dev_label=O_f-score_tok: 0.9343202363886369
dev_label=N_precision_tok: 0.8613406795224977
dev_label=N_recall_tok: 0.5051157781367798
dev_label=N_f-score_tok: 0.636795655125594
dev_label=P_precision_tok: 0.9230421004979629
dev_label=P_recall_tok: 0.6348069738480697
dev_label=P_f-score_tok: 0.7522597306769969
dev_precision_macro_tok: 0.8908927617127985
dev_recall_macro_tok: 0.7084325454266067
dev_f-score_macro_tok: 0.7744585407304093
dev_precision_micro_tok: 0.890523643884554
dev_recall_micro_tok: 0.890523643884554
dev_f-score_micro_tok: 0.890523643884554
dev_time: 8.31520676612854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.6257    0.8084    0.7054       428
           P     0.6556    0.8018    0.7214       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.5604    0.5396    0.4813      1101
weighted avg     0.5908    0.6394    0.5687      1101

F1-macro sent:  0.4812915267726902
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8883    0.9854    0.9343     16205
           N     0.8613    0.5051    0.6368      1857
           P     0.9230    0.6348    0.7523      3212

   micro avg     0.8905    0.8905    0.8905     21274
   macro avg     0.8909    0.7084    0.7745     21274
weighted avg     0.8912    0.8905    0.8809     21274

F1-macro tok:  0.7744585407304093
F1-micro tok:  0.890523643884554
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325897.29943847656
train_cost_avg: 38.143410514802966
train_count_sent: 8544.0
train_total_correct_sent: 5558.0
train_accuracy_sent: 0.6505149812734082
train_count_tok: 163566.0
train_total_correct_tok: 144481.0
train_accuracy_tok: 0.8833192717312889
train_label=O_precision_sent: 0.37037037037037035
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012113870381586915
train_label=N_precision_sent: 0.6167623421354764
train_label=N_recall_sent: 0.8114803625377643
train_label=N_f-score_sent: 0.7008480104370516
train_label=P_precision_sent: 0.687650168188371
train_label=P_recall_sent: 0.792797783933518
train_label=P_f-score_sent: 0.7364899639732373
train_precision_macro_sent: 0.5582609602314059
train_recall_macro_sent: 0.5368119273130875
train_f-score_macro_sent: 0.4831506149306253
train_precision_micro_sent: 0.6505149812734082
train_recall_micro_sent: 0.6505149812734082
train_f-score_micro_sent: 0.6505149812734082
train_label=O_precision_tok: 0.8943654141246414
train_label=O_recall_tok: 0.9702606415916749
train_label=O_f-score_tok: 0.9307684593012042
train_label=N_precision_tok: 0.7717614165890028
train_label=N_recall_tok: 0.5830868891705394
train_label=N_f-score_tok: 0.664286860259907
train_label=P_precision_tok: 0.8669788704911635
train_label=P_recall_tok: 0.6216173002358396
train_label=P_f-score_tok: 0.7240769194952741
train_precision_macro_tok: 0.8443685670682693
train_recall_macro_tok: 0.7249882769993512
train_f-score_macro_tok: 0.7730440796854617
train_precision_micro_tok: 0.8833192717312889
train_recall_micro_tok: 0.8833192717312889
train_f-score_micro_tok: 0.8833192717312889
train_time: 145.10997080802917
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3704    0.0062    0.0121      1624
           N     0.6168    0.8115    0.7008      3310
           P     0.6877    0.7928    0.7365      3610

   micro avg     0.6505    0.6505    0.6505      8544
   macro avg     0.5583    0.5368    0.4832      8544
weighted avg     0.5999    0.6505    0.5850      8544

F1-macro sent:  0.4831506149306253
F1-micro sent:  0.6505149812734082
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9703    0.9308    124347
           N     0.7718    0.5831    0.6643     14202
           P     0.8670    0.6216    0.7241     25017

   micro avg     0.8833    0.8833    0.8833    163566
   macro avg     0.8444    0.7250    0.7730    163566
weighted avg     0.8795    0.8833    0.8760    163566

F1-macro tok:  0.7730440796854617
F1-micro tok:  0.8833192717312889
**************************************************
dev_cost_sum: 43692.12072753906
dev_cost_avg: 39.684033358346106
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19003.0
dev_accuracy_tok: 0.8932499764971327
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6047619047619047
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.720226843100189
dev_label=P_precision_sent: 0.7036247334754797
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7228915662650601
dev_precision_macro_sent: 0.7694622127457947
dev_recall_macro_sent: 0.5473879278617474
dev_f-score_macro_sent: 0.4868114755604222
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.89890896692806
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.9359524302576695
dev_label=N_precision_tok: 0.7942652329749104
dev_label=N_recall_tok: 0.596661281637049
dev_label=N_f-score_tok: 0.6814268142681427
dev_label=P_precision_tok: 0.9101271372205173
dev_label=P_recall_tok: 0.6463262764632628
dev_label=P_f-score_tok: 0.7558711086837795
dev_precision_macro_tok: 0.8677671123744958
dev_recall_macro_tok: 0.7397225831330978
dev_f-score_macro_tok: 0.791083451069864
dev_precision_micro_tok: 0.8932499764971327
dev_recall_micro_tok: 0.8932499764971327
dev_f-score_micro_tok: 0.8932499764971327
dev_time: 8.477049827575684
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6048    0.8902    0.7202       428
           P     0.7036    0.7432    0.7229       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.7695    0.5474    0.4868      1101
weighted avg     0.7268    0.6476    0.5751      1101

F1-macro sent:  0.4868114755604222
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9762    0.9360     16205
           N     0.7943    0.5967    0.6814      1857
           P     0.9101    0.6463    0.7559      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8678    0.7397    0.7911     21274
weighted avg     0.8915    0.8932    0.8865     21274

F1-macro tok:  0.791083451069864
F1-micro tok:  0.8932499764971327
**************************************************
Best epoch: 13
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323436.98431396484
train_cost_avg: 37.85545228393783
train_count_sent: 8544.0
train_total_correct_sent: 5643.0
train_accuracy_sent: 0.6604634831460674
train_count_tok: 163566.0
train_total_correct_tok: 144821.0
train_accuracy_tok: 0.8853979433378575
train_label=O_precision_sent: 0.43859649122807015
train_label=O_recall_sent: 0.01539408866995074
train_label=O_f-score_sent: 0.0297441998810232
train_label=N_precision_sent: 0.632186616399623
train_label=N_recall_sent: 0.8105740181268882
train_label=N_f-score_sent: 0.7103521313211545
train_label=P_precision_sent: 0.6917275512609004
train_label=P_recall_sent: 0.8130193905817175
train_label=P_f-score_sent: 0.7474850375652617
train_precision_macro_sent: 0.5875035529628646
train_recall_macro_sent: 0.5463291657928521
train_f-score_macro_sent: 0.4958604562558131
train_precision_micro_sent: 0.6604634831460674
train_recall_micro_sent: 0.6604634831460674
train_f-score_micro_sent: 0.6604634831460674
train_label=O_precision_tok: 0.8961398559869349
train_label=O_recall_tok: 0.9708235823944285
train_label=O_f-score_tok: 0.9319879408778763
train_label=N_precision_tok: 0.7733677134174417
train_label=N_recall_tok: 0.5913251654696522
train_label=N_f-score_tok: 0.670204700530705
train_label=P_precision_tok: 0.8725898760904596
train_label=P_recall_tok: 0.6277331414638047
train_label=P_f-score_tok: 0.7301808713442136
train_precision_macro_tok: 0.8473658151649454
train_recall_macro_tok: 0.7299606297759618
train_f-score_macro_tok: 0.777457837584265
train_precision_micro_tok: 0.8853979433378575
train_recall_micro_tok: 0.8853979433378575
train_f-score_micro_tok: 0.8853979433378575
train_time: 144.46872878074646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4386    0.0154    0.0297      1624
           N     0.6322    0.8106    0.7104      3310
           P     0.6917    0.8130    0.7475      3610

   micro avg     0.6605    0.6605    0.6605      8544
   macro avg     0.5875    0.5463    0.4959      8544
weighted avg     0.6205    0.6605    0.5967      8544

F1-macro sent:  0.4958604562558131
F1-micro sent:  0.6604634831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9708    0.9320    124347
           N     0.7734    0.5913    0.6702     14202
           P     0.8726    0.6277    0.7302     25017

   micro avg     0.8854    0.8854    0.8854    163566
   macro avg     0.8474    0.7300    0.7775    163566
weighted avg     0.8819    0.8854    0.8784    163566

F1-macro tok:  0.777457837584265
F1-micro tok:  0.8853979433378575
**************************************************
dev_cost_sum: 43452.98400878906
dev_cost_avg: 39.46683379544874
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 19056.0
dev_accuracy_tok: 0.8957412804362133
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.5818713450292398
dev_label=N_recall_sent: 0.9299065420560748
dev_label=N_f-score_sent: 0.7158273381294965
dev_label=P_precision_sent: 0.7475728155339806
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.719626168224299
dev_precision_macro_sent: 0.7098147201877402
dev_recall_macro_sent: 0.5470224948860218
dev_f-score_macro_sent: 0.48988051351394324
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.9015151515151515
dev_label=O_recall_tok: 0.9766738660907127
dev_label=O_f-score_tok: 0.9375907111756169
dev_label=N_precision_tok: 0.7786885245901639
dev_label=N_recall_tok: 0.6138933764135702
dev_label=N_f-score_tok: 0.6865401987353206
dev_label=P_precision_tok: 0.9267968056787933
dev_label=P_recall_tok: 0.650373599003736
dev_label=P_f-score_tok: 0.7643615075009148
dev_precision_macro_tok: 0.869000160594703
dev_recall_macro_tok: 0.746980280502673
dev_f-score_macro_tok: 0.796164139137284
dev_precision_micro_tok: 0.8957412804362133
dev_recall_micro_tok: 0.8957412804362133
dev_f-score_micro_tok: 0.8957412804362133
dev_time: 8.244088649749756
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.5819    0.9299    0.7158       428
           P     0.7476    0.6937    0.7196       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.7098    0.5470    0.4899      1101
weighted avg     0.6941    0.6449    0.5756      1101

F1-macro sent:  0.48988051351394324
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9015    0.9767    0.9376     16205
           N     0.7787    0.6139    0.6865      1857
           P     0.9268    0.6504    0.7644      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8690    0.7470    0.7962     21274
weighted avg     0.8946    0.8957    0.8895     21274

F1-macro tok:  0.796164139137284
F1-micro tok:  0.8957412804362133
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321552.9973754883
train_cost_avg: 37.63494819469666
train_count_sent: 8544.0
train_total_correct_sent: 5616.0
train_accuracy_sent: 0.6573033707865169
train_count_tok: 163566.0
train_total_correct_tok: 145056.0
train_accuracy_tok: 0.8868346722423975
train_label=O_precision_sent: 0.5147058823529411
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.041371158392434985
train_label=N_precision_sent: 0.6177597475771918
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7076287595198142
train_label=P_precision_sent: 0.703144342659074
train_label=P_recall_sent: 0.7867036011080333
train_label=P_f-score_sent: 0.7425807295071252
train_precision_macro_sent: 0.6118699908630689
train_recall_macro_sent: 0.5454506673277081
train_f-score_macro_sent: 0.49719354913979147
train_precision_micro_sent: 0.6573033707865169
train_recall_micro_sent: 0.6573033707865169
train_f-score_micro_sent: 0.6573033707865169
train_label=O_precision_tok: 0.8977702079552554
train_label=O_recall_tok: 0.9707270782568136
train_label=O_f-score_tok: 0.9328243153953454
train_label=N_precision_tok: 0.7779704325606862
train_label=N_recall_tok: 0.6002675679481763
train_label=N_f-score_tok: 0.6776629570747218
train_label=P_precision_tok: 0.8715576118087685
train_label=P_recall_tok: 0.6325298796818164
train_label=P_f-score_tok: 0.733050749310912
train_precision_macro_tok: 0.84909941744157
train_recall_macro_tok: 0.734508175295602
train_f-score_macro_tok: 0.7811793405936598
train_precision_micro_tok: 0.8868346722423975
train_recall_micro_tok: 0.8868346722423975
train_f-score_micro_tok: 0.8868346722423974
train_time: 145.12080645561218
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5147    0.0216    0.0414      1624
           N     0.6178    0.8281    0.7076      3310
           P     0.7031    0.7867    0.7426      3610

   micro avg     0.6573    0.6573    0.6573      8544
   macro avg     0.6119    0.5455    0.4972      8544
weighted avg     0.6342    0.6573    0.5958      8544

F1-macro sent:  0.49719354913979147
F1-micro sent:  0.6573033707865169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8978    0.9707    0.9328    124347
           N     0.7780    0.6003    0.6777     14202
           P     0.8716    0.6325    0.7331     25017

   micro avg     0.8868    0.8868    0.8868    163566
   macro avg     0.8491    0.7345    0.7812    163566
weighted avg     0.8834    0.8868    0.8801    163566

F1-macro tok:  0.7811793405936598
F1-micro tok:  0.8868346722423974
**************************************************
dev_cost_sum: 43321.31018066406
dev_cost_avg: 39.347239037842016
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19061.0
dev_accuracy_tok: 0.8959763091097114
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05042016806722689
dev_label=N_precision_sent: 0.6602316602316602
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7230443974630021
dev_label=P_precision_sent: 0.6463414634146342
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7288801571709235
dev_precision_macro_sent: 0.6577465967709871
dev_recall_macro_sent: 0.553617293169593
dev_f-score_macro_sent: 0.5007815742337175
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.8987320276236839
dev_label=O_recall_tok: 0.9797593335390312
dev_label=O_f-score_tok: 0.9374981547636622
dev_label=N_precision_tok: 0.8149812734082397
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.681704260651629
dev_label=P_precision_tok: 0.9221293444786626
dev_label=P_recall_tok: 0.6525529265255293
dev_label=P_f-score_tok: 0.7642661804922516
dev_precision_macro_tok: 0.8786142151701953
dev_recall_macro_tok: 0.7394011608220946
dev_f-score_macro_tok: 0.7944895319691808
dev_precision_micro_tok: 0.8959763091097114
dev_recall_micro_tok: 0.8959763091097114
dev_f-score_micro_tok: 0.8959763091097114
dev_time: 8.244566917419434
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0262    0.0504       229
           N     0.6602    0.7991    0.7230       428
           P     0.6463    0.8356    0.7289       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.6577    0.5536    0.5008      1101
weighted avg     0.6560    0.6530    0.5855      1101

F1-macro sent:  0.5007815742337175
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8987    0.9798    0.9375     16205
           N     0.8150    0.5859    0.6817      1857
           P     0.9221    0.6526    0.7643      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8786    0.7394    0.7945     21274
weighted avg     0.8950    0.8960    0.8890     21274

F1-macro tok:  0.7944895319691808
F1-micro tok:  0.8959763091097114
**************************************************
Best epoch: 15
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319768.5208129883
train_cost_avg: 37.42609091912316
train_count_sent: 8544.0
train_total_correct_sent: 5658.0
train_accuracy_sent: 0.6622191011235955
train_count_tok: 163566.0
train_total_correct_tok: 145259.0
train_accuracy_tok: 0.8880757614663194
train_label=O_precision_sent: 0.4305555555555556
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.036556603773584904
train_label=N_precision_sent: 0.6245429616087751
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.7111631537861046
train_label=P_precision_sent: 0.70654296875
train_label=P_recall_sent: 0.8016620498614958
train_label=P_f-score_sent: 0.7511030365948612
train_precision_macro_sent: 0.5872138286381102
train_recall_macro_sent: 0.5488101593734639
train_f-score_macro_sent: 0.4996075980515169
train_precision_micro_sent: 0.6622191011235955
train_recall_micro_sent: 0.6622191011235955
train_f-score_micro_sent: 0.6622191011235955
train_label=O_precision_tok: 0.8989895981474725
train_label=O_recall_tok: 0.9709683386008509
train_label=O_f-score_tok: 0.9335936593852697
train_label=N_precision_tok: 0.782660116448326
train_label=N_recall_tok: 0.6057597521475848
train_label=N_f-score_tok: 0.682940382630785
train_label=P_precision_tok: 0.8712714137157244
train_label=P_recall_tok: 0.6363272974377423
train_label=P_f-score_tok: 0.7354925152467197
train_precision_macro_tok: 0.8509737094371742
train_recall_macro_tok: 0.7376851293953927
train_f-score_macro_tok: 0.7840088524209249
train_precision_micro_tok: 0.8880757614663194
train_recall_micro_tok: 0.8880757614663194
train_f-score_micro_tok: 0.8880757614663194
train_time: 145.8127579689026
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4306    0.0191    0.0366      1624
           N     0.6245    0.8257    0.7112      3310
           P     0.7065    0.8017    0.7511      3610

   micro avg     0.6622    0.6622    0.6622      8544
   macro avg     0.5872    0.5488    0.4996      8544
weighted avg     0.6223    0.6622    0.5998      8544

F1-macro sent:  0.4996075980515169
F1-micro sent:  0.6622191011235955
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9710    0.9336    124347
           N     0.7827    0.6058    0.6829     14202
           P     0.8713    0.6363    0.7355     25017

   micro avg     0.8881    0.8881    0.8881    163566
   macro avg     0.8510    0.7377    0.7840    163566
weighted avg     0.8846    0.8881    0.8815    163566

F1-macro tok:  0.7840088524209249
F1-micro tok:  0.8880757614663194
**************************************************
dev_cost_sum: 43139.97448730469
dev_cost_avg: 39.182538135608254
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19046.0
dev_accuracy_tok: 0.8952712230892169
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.03375527426160337
dev_label=N_precision_sent: 0.6140939597315436
dev_label=N_recall_sent: 0.8551401869158879
dev_label=N_f-score_sent: 0.71484375
dev_label=P_precision_sent: 0.6901408450704225
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7290116896918172
dev_precision_macro_sent: 0.6014116016006553
dev_recall_macro_sent: 0.5483766527822358
dev_f-score_macro_sent: 0.49253690465114025
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.8940345368916798
dev_label=O_recall_tok: 0.9840172786177106
dev_label=O_f-score_tok: 0.9368702447049148
dev_label=N_precision_tok: 0.840032154340836
dev_label=N_recall_tok: 0.5627355950457728
dev_label=N_f-score_tok: 0.6739761367300872
dev_label=P_precision_tok: 0.9366453965360073
dev_label=P_recall_tok: 0.6397882938978829
dev_label=P_f-score_tok: 0.7602663706992231
dev_precision_macro_tok: 0.8902373625895077
dev_recall_macro_tok: 0.7288470558537888
dev_f-score_macro_tok: 0.790370917378075
dev_precision_micro_tok: 0.8952712230892169
dev_recall_micro_tok: 0.8952712230892169
dev_f-score_micro_tok: 0.8952712230892169
dev_time: 8.51837420463562
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0175    0.0338       229
           N     0.6141    0.8551    0.7148       428
           P     0.6901    0.7725    0.7290       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.6014    0.5484    0.4925      1101
weighted avg     0.6210    0.6476    0.5789      1101

F1-macro sent:  0.49253690465114025
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8940    0.9840    0.9369     16205
           N     0.8400    0.5627    0.6740      1857
           P     0.9366    0.6398    0.7603      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8902    0.7288    0.7904     21274
weighted avg     0.8958    0.8953    0.8873     21274

F1-macro tok:  0.790370917378075
F1-micro tok:  0.8952712230892169
**************************************************
Best epoch: 15
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317395.1112060547
train_cost_avg: 37.148304214191796
train_count_sent: 8544.0
train_total_correct_sent: 5675.0
train_accuracy_sent: 0.6642088014981273
train_count_tok: 163566.0
train_total_correct_tok: 145654.0
train_accuracy_tok: 0.8904906887739505
train_label=O_precision_sent: 0.38513513513513514
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.06433408577878104
train_label=N_precision_sent: 0.6358068315665489
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.7144937127729981
train_label=P_precision_sent: 0.7032040472175379
train_label=P_recall_sent: 0.8085872576177285
train_label=P_f-score_sent: 0.7522226517201391
train_precision_macro_sent: 0.574715337973074
train_recall_macro_sent: 0.5530312115900368
train_f-score_macro_sent: 0.5103501500906394
train_precision_micro_sent: 0.6642088014981273
train_recall_micro_sent: 0.6642088014981273
train_f-score_micro_sent: 0.6642088014981273
train_label=O_precision_tok: 0.9013468641569974
train_label=O_recall_tok: 0.9714267332545217
train_label=O_f-score_tok: 0.9350755916117697
train_label=N_precision_tok: 0.785611251352326
train_label=N_recall_tok: 0.6135755527390508
train_label=N_f-score_tok: 0.6890171582193406
train_label=P_precision_tok: 0.8746952705997074
train_label=P_recall_tok: 0.6454011272334812
train_label=P_f-score_tok: 0.7427546232404084
train_precision_macro_tok: 0.8538844620363436
train_recall_macro_tok: 0.7434678044090179
train_f-score_macro_tok: 0.7889491243571728
train_precision_micro_tok: 0.8904906887739505
train_recall_micro_tok: 0.8904906887739505
train_f-score_micro_tok: 0.8904906887739505
train_time: 128.76676845550537
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3851    0.0351    0.0643      1624
           N     0.6358    0.8154    0.7145      3310
           P     0.7032    0.8086    0.7522      3610

   micro avg     0.6642    0.6642    0.6642      8544
   macro avg     0.5747    0.5530    0.5104      8544
weighted avg     0.6166    0.6642    0.6069      8544

F1-macro sent:  0.5103501500906394
F1-micro sent:  0.6642088014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9013    0.9714    0.9351    124347
           N     0.7856    0.6136    0.6890     14202
           P     0.8747    0.6454    0.7428     25017

   micro avg     0.8905    0.8905    0.8905    163566
   macro avg     0.8539    0.7435    0.7889    163566
weighted avg     0.8872    0.8905    0.8843    163566

F1-macro tok:  0.7889491243571728
F1-micro tok:  0.8904906887739505
**************************************************
dev_cost_sum: 43024.09265136719
dev_cost_avg: 39.07728669515639
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19098.0
dev_accuracy_tok: 0.8977155212935978
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6483931947069943
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7168234064785788
dev_label=P_precision_sent: 0.6514886164623468
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7330049261083744
dev_precision_macro_sent: 0.43329393705644703
dev_recall_macro_sent: 0.5464132356655721
dev_f-score_macro_sent: 0.48327611086231775
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.8999830095712749
dev_label=O_recall_tok: 0.9806232644245603
dev_label=O_f-score_tok: 0.9385742129821039
dev_label=N_precision_tok: 0.8148967551622419
dev_label=N_recall_tok: 0.5950457727517501
dev_label=N_f-score_tok: 0.6878306878306878
dev_label=P_precision_tok: 0.9296771340114993
dev_label=P_recall_tok: 0.6544209215442092
dev_label=P_f-score_tok: 0.768134478348255
dev_precision_macro_tok: 0.8815189662483386
dev_recall_macro_tok: 0.7433633195735064
dev_f-score_macro_tok: 0.7981797930536821
dev_precision_micro_tok: 0.8977155212935978
dev_recall_micro_tok: 0.8977155212935978
dev_f-score_micro_tok: 0.8977155212935977
dev_time: 5.098537445068359
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6484    0.8014    0.7168       428
           P     0.6515    0.8378    0.7330       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.4333    0.5464    0.4833      1101
weighted avg     0.5148    0.6494    0.5743      1101

F1-macro sent:  0.48327611086231775
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9000    0.9806    0.9386     16205
           N     0.8149    0.5950    0.6878      1857
           P     0.9297    0.6544    0.7681      3212

   micro avg     0.8977    0.8977    0.8977     21274
   macro avg     0.8815    0.7434    0.7982     21274
weighted avg     0.8970    0.8977    0.8910     21274

F1-macro tok:  0.7981797930536821
F1-micro tok:  0.8977155212935977
**************************************************
Best epoch: 15
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315710.4378051758
train_cost_avg: 36.9511280202687
train_count_sent: 8544.0
train_total_correct_sent: 5672.0
train_accuracy_sent: 0.6638576779026217
train_count_tok: 163566.0
train_total_correct_tok: 145936.0
train_accuracy_tok: 0.8922147634593987
train_label=O_precision_sent: 0.4069767441860465
train_label=O_recall_sent: 0.021551724137931036
train_label=O_f-score_sent: 0.04093567251461989
train_label=N_precision_sent: 0.642822851656265
train_label=N_recall_sent: 0.8090634441087613
train_label=N_f-score_sent: 0.7164258962011771
train_label=P_precision_sent: 0.6894221808014911
train_label=P_recall_sent: 0.8196675900277008
train_label=P_f-score_sent: 0.7489243229562136
train_precision_macro_sent: 0.5797405922146008
train_recall_macro_sent: 0.5500942527581311
train_f-score_macro_sent: 0.5020952972240035
train_precision_micro_sent: 0.6638576779026217
train_recall_micro_sent: 0.6638576779026217
train_f-score_micro_sent: 0.6638576779026217
train_label=O_precision_tok: 0.9028337056322981
train_label=O_recall_tok: 0.9718529598623208
train_label=O_f-score_tok: 0.9360728117738187
train_label=N_precision_tok: 0.7892565689175859
train_label=N_recall_tok: 0.6197014504999296
train_label=N_f-score_tok: 0.6942768114227114
train_label=P_precision_tok: 0.8774916496067234
train_label=P_recall_tok: 0.6510772674581284
train_label=P_f-score_tok: 0.7475160054154524
train_precision_macro_tok: 0.8565273080522026
train_recall_macro_tok: 0.7475438926067929
train_f-score_macro_tok: 0.7926218762039943
train_precision_micro_tok: 0.8922147634593987
train_recall_micro_tok: 0.8922147634593987
train_f-score_micro_tok: 0.8922147634593987
train_time: 96.11406326293945
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4070    0.0216    0.0409      1624
           N     0.6428    0.8091    0.7164      3310
           P     0.6894    0.8197    0.7489      3610

   micro avg     0.6639    0.6639    0.6639      8544
   macro avg     0.5797    0.5501    0.5021      8544
weighted avg     0.6177    0.6639    0.6018      8544

F1-macro sent:  0.5020952972240035
F1-micro sent:  0.6638576779026217
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9028    0.9719    0.9361    124347
           N     0.7893    0.6197    0.6943     14202
           P     0.8775    0.6511    0.7475     25017

   micro avg     0.8922    0.8922    0.8922    163566
   macro avg     0.8565    0.7475    0.7926    163566
weighted avg     0.8891    0.8922    0.8862    163566

F1-macro tok:  0.7926218762039943
F1-micro tok:  0.8922147634593987
**************************************************
dev_cost_sum: 42762.09619140625
dev_cost_avg: 38.83932442452884
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19136.0
dev_accuracy_tok: 0.8995017392121839
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6324786324786325
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7305034550839092
dev_label=P_precision_sent: 0.682261208576998
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7314524555903866
dev_precision_macro_sent: 0.7715799470185435
dev_recall_macro_sent: 0.5552915687593075
dev_f-score_macro_sent: 0.49593932654660433
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9068886337543054
dev_label=O_recall_tok: 0.9748842949706881
dev_label=O_f-score_tok: 0.9396579925650557
dev_label=N_precision_tok: 0.7948369565217391
dev_label=N_recall_tok: 0.630048465266559
dev_label=N_f-score_tok: 0.7029137879243015
dev_label=P_precision_tok: 0.910159529806885
dev_label=P_recall_tok: 0.6749688667496887
dev_label=P_f-score_tok: 0.7751161959242046
dev_precision_macro_tok: 0.8706283733609764
dev_recall_macro_tok: 0.7599672089956453
dev_f-score_macro_tok: 0.8058959921378538
dev_precision_micro_tok: 0.8995017392121839
dev_recall_micro_tok: 0.8995017392121839
dev_f-score_micro_tok: 0.8995017392121839
dev_time: 5.215274333953857
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6325    0.8645    0.7305       428
           P     0.6823    0.7883    0.7315       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.7716    0.5553    0.4959      1101
weighted avg     0.7290    0.6567    0.5843      1101

F1-macro sent:  0.49593932654660433
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9069    0.9749    0.9397     16205
           N     0.7948    0.6300    0.7029      1857
           P     0.9102    0.6750    0.7751      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8706    0.7600    0.8059     21274
weighted avg     0.8976    0.8995    0.8941     21274

F1-macro tok:  0.8058959921378538
F1-micro tok:  0.8995017392121839
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313797.8229980469
train_cost_avg: 36.727273290969904
train_count_sent: 8544.0
train_total_correct_sent: 5706.0
train_accuracy_sent: 0.6678370786516854
train_count_tok: 163566.0
train_total_correct_tok: 146263.0
train_accuracy_tok: 0.8942139564457161
train_label=O_precision_sent: 0.44696969696969696
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06719817767653757
train_label=N_precision_sent: 0.6328143155937718
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7153553132799159
train_label=P_precision_sent: 0.7116086639084935
train_label=P_recall_sent: 0.8099722991689751
train_label=P_f-score_sent: 0.7576110895193678
train_precision_macro_sent: 0.5971308921573207
train_recall_macro_sent: 0.5563203195673206
train_f-score_macro_sent: 0.5133881934919404
train_precision_micro_sent: 0.6678370786516854
train_recall_micro_sent: 0.6678370786516854
train_f-score_micro_sent: 0.6678370786516854
train_label=O_precision_tok: 0.9050703529253188
train_label=O_recall_tok: 0.9719896740572752
train_label=O_f-score_tok: 0.9373371386028042
train_label=N_precision_tok: 0.7899510893730547
train_label=N_recall_tok: 0.6254752851711026
train_label=N_f-score_tok: 0.6981569536684088
train_label=P_precision_tok: 0.8794462193823216
train_label=P_recall_tok: 0.6601910700723508
train_label=P_f-score_tok: 0.7542069091490285
train_precision_macro_tok: 0.8581558872268985
train_recall_macro_tok: 0.7525520097669096
train_f-score_macro_tok: 0.7965670004734138
train_precision_micro_tok: 0.8942139564457161
train_recall_micro_tok: 0.8942139564457161
train_f-score_micro_tok: 0.8942139564457161
train_time: 94.50973200798035
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4470    0.0363    0.0672      1624
           N     0.6328    0.8227    0.7154      3310
           P     0.7116    0.8100    0.7576      3610

   micro avg     0.6678    0.6678    0.6678      8544
   macro avg     0.5971    0.5563    0.5134      8544
weighted avg     0.6308    0.6678    0.6100      8544

F1-macro sent:  0.5133881934919404
F1-micro sent:  0.6678370786516854
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9051    0.9720    0.9373    124347
           N     0.7900    0.6255    0.6982     14202
           P     0.8794    0.6602    0.7542     25017

   micro avg     0.8942    0.8942    0.8942    163566
   macro avg     0.8582    0.7526    0.7966    163566
weighted avg     0.8912    0.8942    0.8886    163566

F1-macro tok:  0.7965670004734138
F1-micro tok:  0.8942139564457161
**************************************************
dev_cost_sum: 42675.10095214844
dev_cost_avg: 38.76030967497587
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 19100.0
dev_accuracy_tok: 0.8978095327629971
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.649812734082397
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7214137214137214
dev_label=P_precision_sent: 0.6554770318021201
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7346534653465346
dev_precision_macro_sent: 0.4350965886281724
dev_recall_macro_sent: 0.5487777497123291
dev_f-score_macro_sent: 0.4853557289200854
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.9070195627157652
dev_label=O_recall_tok: 0.9727861771058315
dev_label=O_f-score_tok: 0.9387524192347775
dev_label=N_precision_tok: 0.7959750173490632
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.695573074590661
dev_label=P_precision_tok: 0.8923766816143498
dev_label=P_recall_tok: 0.6815068493150684
dev_label=P_f-score_tok: 0.7728155339805826
dev_precision_macro_tok: 0.8651237538930595
dev_recall_macro_tok: 0.7573186411889447
dev_f-score_macro_tok: 0.802380342602007
dev_precision_micro_tok: 0.8978095327629971
dev_recall_micro_tok: 0.8978095327629971
dev_f-score_micro_tok: 0.8978095327629971
dev_time: 5.154250383377075
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6498    0.8107    0.7214       428
           P     0.6555    0.8356    0.7347       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.4351    0.5488    0.4854      1101
weighted avg     0.5169    0.6521    0.5767      1101

F1-macro sent:  0.4853557289200854
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9070    0.9728    0.9388     16205
           N     0.7960    0.6177    0.6956      1857
           P     0.8924    0.6815    0.7728      3212

   micro avg     0.8978    0.8978    0.8978     21274
   macro avg     0.8651    0.7573    0.8024     21274
weighted avg     0.8951    0.8978    0.8925     21274

F1-macro tok:  0.802380342602007
F1-micro tok:  0.8978095327629971
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 311960.2404785156
train_cost_avg: 36.51220043053788
train_count_sent: 8544.0
train_total_correct_sent: 5814.0
train_accuracy_sent: 0.6804775280898876
train_count_tok: 163566.0
train_total_correct_tok: 146440.0
train_accuracy_tok: 0.8952960884291357
train_label=O_precision_sent: 0.4585635359116022
train_label=O_recall_sent: 0.05110837438423645
train_label=O_f-score_sent: 0.09196675900277007
train_label=N_precision_sent: 0.6525602057516952
train_label=N_recall_sent: 0.843202416918429
train_label=N_f-score_sent: 0.7357321734545934
train_label=P_precision_sent: 0.7195301027900147
train_label=P_recall_sent: 0.814404432132964
train_label=P_f-score_sent: 0.7640332640332641
train_precision_macro_sent: 0.610217948151104
train_recall_macro_sent: 0.5695717411452098
train_f-score_macro_sent: 0.5305773988302093
train_precision_micro_sent: 0.6804775280898876
train_recall_micro_sent: 0.6804775280898876
train_f-score_micro_sent: 0.6804775280898876
train_label=O_precision_tok: 0.9062558594775408
train_label=O_recall_tok: 0.9717323296903021
train_label=O_f-score_tok: 0.9378526688347473
train_label=N_precision_tok: 0.7941436659589526
train_label=N_recall_tok: 0.6320940712575693
train_label=N_f-score_tok: 0.7039128048302359
train_label=P_precision_tok: 0.8785061539274206
train_label=P_recall_tok: 0.6647879441979454
train_label=P_f-score_tok: 0.7568490033676163
train_precision_macro_tok: 0.8596352264546381
train_recall_macro_tok: 0.7562047817152724
train_f-score_macro_tok: 0.7995381590108664
train_precision_micro_tok: 0.8952960884291357
train_recall_micro_tok: 0.8952960884291357
train_f-score_micro_tok: 0.8952960884291357
train_time: 95.82705402374268
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4586    0.0511    0.0920      1624
           N     0.6526    0.8432    0.7357      3310
           P     0.7195    0.8144    0.7640      3610

   micro avg     0.6805    0.6805    0.6805      8544
   macro avg     0.6102    0.5696    0.5306      8544
weighted avg     0.6440    0.6805    0.6253      8544

F1-macro sent:  0.5305773988302093
F1-micro sent:  0.6804775280898876
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9717    0.9379    124347
           N     0.7941    0.6321    0.7039     14202
           P     0.8785    0.6648    0.7568     25017

   micro avg     0.8953    0.8953    0.8953    163566
   macro avg     0.8596    0.7562    0.7995    163566
weighted avg     0.8923    0.8953    0.8899    163566

F1-macro tok:  0.7995381590108664
F1-micro tok:  0.8952960884291357
**************************************************
dev_cost_sum: 42577.55676269531
dev_cost_avg: 38.671713680922174
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.049792531120331954
dev_label=N_precision_sent: 0.693304535637149
dev_label=N_recall_sent: 0.75
dev_label=N_f-score_sent: 0.7205387205387205
dev_label=P_precision_sent: 0.6214057507987221
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.7271028037383178
dev_precision_macro_sent: 0.604903428811957
dev_recall_macro_sent: 0.5507756664961905
dev_f-score_macro_sent: 0.4991446851324568
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9042407660738714
dev_label=O_recall_tok: 0.9789571120024684
dev_label=O_f-score_tok: 0.9401167441998282
dev_label=N_precision_tok: 0.8031767955801105
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.7037821482602118
dev_label=P_precision_tok: 0.92988606485539
dev_label=P_recall_tok: 0.6606475716064757
dev_label=P_f-score_tok: 0.7724790680742628
dev_precision_macro_tok: 0.8791012088364574
dev_recall_macro_tok: 0.7552945427143797
dev_f-score_macro_tok: 0.8054593201781008
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 5.047865152359009
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0262    0.0498       229
           N     0.6933    0.7500    0.7205       428
           P     0.6214    0.8761    0.7271       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6049    0.5508    0.4991      1101
weighted avg     0.6241    0.6503    0.5837      1101

F1-macro sent:  0.4991446851324568
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9790    0.9401     16205
           N     0.8032    0.6263    0.7038      1857
           P     0.9299    0.6606    0.7725      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8791    0.7553    0.8055     21274
weighted avg     0.8993    0.9001    0.8942     21274

F1-macro tok:  0.8054593201781008
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 310338.60009765625
train_cost_avg: 36.322401696823064
train_count_sent: 8544.0
train_total_correct_sent: 5722.0
train_accuracy_sent: 0.6697097378277154
train_count_tok: 163566.0
train_total_correct_tok: 146766.0
train_accuracy_tok: 0.8972891676754338
train_label=O_precision_sent: 0.3401360544217687
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.0564652738565782
train_label=N_precision_sent: 0.6391254315304948
train_label=N_recall_sent: 0.8389728096676737
train_label=N_f-score_sent: 0.7255388634879163
train_label=P_precision_sent: 0.7144619940769991
train_label=P_recall_sent: 0.8019390581717452
train_label=P_f-score_sent: 0.7556773688332029
train_precision_macro_sent: 0.5645744933430875
train_recall_macro_sent: 0.5572333483931068
train_f-score_macro_sent: 0.5125605020592324
train_precision_micro_sent: 0.6697097378277154
train_recall_micro_sent: 0.6697097378277154
train_f-score_micro_sent: 0.6697097378277154
train_label=O_precision_tok: 0.907998678400865
train_label=O_recall_tok: 0.972440026699478
train_label=O_f-score_tok: 0.9391151720843899
train_label=N_precision_tok: 0.7992617331692741
train_label=N_recall_tok: 0.6403323475566821
train_label=N_f-score_tok: 0.7110242376856919
train_label=P_precision_tok: 0.8809423643247791
train_label=P_recall_tok: 0.6696246552344406
train_label=P_f-score_tok: 0.7608838825426385
train_precision_macro_tok: 0.8627342586316393
train_recall_macro_tok: 0.7607990098302002
train_f-score_macro_tok: 0.8036744307709066
train_precision_micro_tok: 0.8972891676754338
train_recall_micro_tok: 0.8972891676754338
train_f-score_micro_tok: 0.8972891676754338
train_time: 95.39257788658142
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3401    0.0308    0.0565      1624
           N     0.6391    0.8390    0.7255      3310
           P     0.7145    0.8019    0.7557      3610

   micro avg     0.6697    0.6697    0.6697      8544
   macro avg     0.5646    0.5572    0.5126      8544
weighted avg     0.6141    0.6697    0.6111      8544

F1-macro sent:  0.5125605020592324
F1-micro sent:  0.6697097378277154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9724    0.9391    124347
           N     0.7993    0.6403    0.7110     14202
           P     0.8809    0.6696    0.7609     25017

   micro avg     0.8973    0.8973    0.8973    163566
   macro avg     0.8627    0.7608    0.8037    163566
weighted avg     0.8944    0.8973    0.8921    163566

F1-macro tok:  0.8036744307709066
F1-micro tok:  0.8972891676754338
**************************************************
dev_cost_sum: 42504.25604248047
dev_cost_avg: 38.60513718663076
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19152.0
dev_accuracy_tok: 0.900253830967378
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.5836972343522562
dev_label=N_recall_sent: 0.9369158878504673
dev_label=N_f-score_sent: 0.7192825112107624
dev_label=P_precision_sent: 0.7603911980440098
dev_label=P_recall_sent: 0.7004504504504504
dev_label=P_f-score_sent: 0.7291910902696366
dev_precision_macro_sent: 0.648029477465422
dev_recall_macro_sent: 0.5501555916607135
dev_f-score_macro_sent: 0.49137154237380826
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.9031395745648959
dev_label=O_recall_tok: 0.9798827522369639
dev_label=O_f-score_tok: 0.9399473170154201
dev_label=N_precision_tok: 0.8363914373088684
dev_label=N_recall_tok: 0.589122240172321
dev_label=N_f-score_tok: 0.6913112164296998
dev_label=P_precision_tok: 0.9140100671140939
dev_label=P_recall_tok: 0.6783935242839353
dev_label=P_f-score_tok: 0.778770550393138
dev_precision_macro_tok: 0.8845136929959527
dev_recall_macro_tok: 0.7491328388977401
dev_f-score_macro_tok: 0.8033430279460859
dev_precision_micro_tok: 0.900253830967378
dev_recall_micro_tok: 0.900253830967378
dev_f-score_micro_tok: 0.900253830967378
dev_time: 4.924452066421509
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.5837    0.9369    0.7193       428
           P     0.7604    0.7005    0.7292       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.6480    0.5502    0.4914      1101
weighted avg     0.6583    0.6494    0.5790      1101

F1-macro sent:  0.49137154237380826
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9799    0.9399     16205
           N     0.8364    0.5891    0.6913      1857
           P     0.9140    0.6784    0.7788      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8845    0.7491    0.8033     21274
weighted avg     0.8990    0.9003    0.8939     21274

F1-macro tok:  0.8033430279460859
F1-micro tok:  0.900253830967378
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 308591.79010009766
train_cost_avg: 36.117952961153755
train_count_sent: 8544.0
train_total_correct_sent: 5766.0
train_accuracy_sent: 0.6748595505617978
train_count_tok: 163566.0
train_total_correct_tok: 146977.0
train_accuracy_tok: 0.8985791668195102
train_label=O_precision_sent: 0.4948453608247423
train_label=O_recall_sent: 0.029556650246305417
train_label=O_f-score_sent: 0.0557815223707147
train_label=N_precision_sent: 0.6415745856353591
train_label=N_recall_sent: 0.8419939577039275
train_label=N_f-score_sent: 0.7282466684086751
train_label=P_precision_sent: 0.7143553497440897
train_label=P_recall_sent: 0.8119113573407202
train_label=P_f-score_sent: 0.7600155581485802
train_precision_macro_sent: 0.6169250987347303
train_recall_macro_sent: 0.5611539884303177
train_f-score_macro_sent: 0.5146812496426567
train_precision_micro_sent: 0.6748595505617978
train_recall_micro_sent: 0.6748595505617978
train_f-score_micro_sent: 0.6748595505617978
train_label=O_precision_tok: 0.9093479944945434
train_label=O_recall_tok: 0.9723274385389273
train_label=O_f-score_tok: 0.93978375941486
train_label=N_precision_tok: 0.801268682655544
train_label=N_recall_tok: 0.6492747500352063
train_label=N_f-score_tok: 0.7173084402956048
train_label=P_precision_tok: 0.8822451437248023
train_label=P_recall_tok: 0.6735419914458168
train_label=P_f-score_tok: 0.7638951854202557
train_precision_macro_tok: 0.8642872736249633
train_recall_macro_tok: 0.7650480600066502
train_f-score_macro_tok: 0.8069957950435734
train_precision_micro_tok: 0.8985791668195102
train_recall_micro_tok: 0.8985791668195102
train_f-score_micro_tok: 0.8985791668195102
train_time: 95.23329758644104
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4948    0.0296    0.0558      1624
           N     0.6416    0.8420    0.7282      3310
           P     0.7144    0.8119    0.7600      3610

   micro avg     0.6749    0.6749    0.6749      8544
   macro avg     0.6169    0.5612    0.5147      8544
weighted avg     0.6444    0.6749    0.6139      8544

F1-macro sent:  0.5146812496426567
F1-micro sent:  0.6748595505617978
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9093    0.9723    0.9398    124347
           N     0.8013    0.6493    0.7173     14202
           P     0.8822    0.6735    0.7639     25017

   micro avg     0.8986    0.8986    0.8986    163566
   macro avg     0.8643    0.7650    0.8070    163566
weighted avg     0.8958    0.8986    0.8936    163566

F1-macro tok:  0.8069957950435734
F1-micro tok:  0.8985791668195102
**************************************************
dev_cost_sum: 42360.73065185547
dev_cost_avg: 38.47477806708035
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19127.0
dev_accuracy_tok: 0.8990786875998872
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6802325581395349
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7436440677966101
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7546432062561094
dev_precision_macro_sent: 0.6711886304909561
dev_recall_macro_sent: 0.5689766920738638
dev_f-score_macro_sent: 0.510776609081403
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.8990577216046944
dev_label=O_recall_tok: 0.9832767664301142
dev_label=O_f-score_tok: 0.9392831879273755
dev_label=N_precision_tok: 0.8617021276595744
dev_label=N_recall_tok: 0.567043618739903
dev_label=N_f-score_tok: 0.6839883078921727
dev_label=P_precision_tok: 0.9188492915414341
dev_label=P_recall_tok: 0.6662515566625156
dev_label=P_f-score_tok: 0.772423750225591
dev_precision_macro_tok: 0.8932030469352344
dev_recall_macro_tok: 0.7388573139441776
dev_f-score_macro_tok: 0.7985650820150464
dev_precision_micro_tok: 0.8990786875998872
dev_recall_micro_tok: 0.8990786875998872
dev_f-score_micro_tok: 0.8990786875998872
dev_time: 5.078032732009888
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6802    0.8201    0.7436       428
           P     0.6667    0.8694    0.7546       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6712    0.5690    0.5108      1101
weighted avg     0.6719    0.6730    0.6005      1101

F1-macro sent:  0.510776609081403
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9833    0.9393     16205
           N     0.8617    0.5670    0.6840      1857
           P     0.9188    0.6663    0.7724      3212

   micro avg     0.8991    0.8991    0.8991     21274
   macro avg     0.8932    0.7389    0.7986     21274
weighted avg     0.8988    0.8991    0.8918     21274

F1-macro tok:  0.7985650820150464
F1-micro tok:  0.8990786875998872
**************************************************
Best epoch: 20
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 306814.43548583984
train_cost_avg: 35.909929246938184
train_count_sent: 8544.0
train_total_correct_sent: 5795.0
train_accuracy_sent: 0.678253745318352
train_count_tok: 163566.0
train_total_correct_tok: 147351.0
train_accuracy_tok: 0.9008657055867356
train_label=O_precision_sent: 0.4296875
train_label=O_recall_sent: 0.033866995073891626
train_label=O_f-score_sent: 0.06278538812785388
train_label=N_precision_sent: 0.647444913267698
train_label=N_recall_sent: 0.834441087613293
train_label=N_f-score_sent: 0.7291446673706441
train_label=P_precision_sent: 0.7175903614457831
train_label=P_recall_sent: 0.8249307479224377
train_label=P_f-score_sent: 0.7675257731958762
train_precision_macro_sent: 0.5982409249044937
train_recall_macro_sent: 0.5644129435365408
train_f-score_macro_sent: 0.5198186095647914
train_precision_micro_sent: 0.678253745318352
train_recall_micro_sent: 0.678253745318352
train_f-score_micro_sent: 0.678253745318352
train_label=O_precision_tok: 0.911559857084709
train_label=O_recall_tok: 0.9725445728485609
train_label=O_f-score_tok: 0.9410652379451623
train_label=N_precision_tok: 0.8048359240069085
train_label=N_recall_tok: 0.6562455992113787
train_label=N_f-score_tok: 0.7229850283143279
train_label=P_precision_tok: 0.8849896480331263
train_label=P_recall_tok: 0.6834552504297078
train_label=P_f-score_tok: 0.7712745562397094
train_precision_macro_tok: 0.8671284763749146
train_recall_macro_tok: 0.7707484741632159
train_f-score_macro_tok: 0.8117749408330664
train_precision_micro_tok: 0.9008657055867356
train_recall_micro_tok: 0.9008657055867356
train_f-score_micro_tok: 0.9008657055867356
train_time: 95.26690173149109
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4297    0.0339    0.0628      1624
           N     0.6474    0.8344    0.7291      3310
           P     0.7176    0.8249    0.7675      3610

   micro avg     0.6783    0.6783    0.6783      8544
   macro avg     0.5982    0.5644    0.5198      8544
weighted avg     0.6357    0.6783    0.6187      8544

F1-macro sent:  0.5198186095647914
F1-micro sent:  0.678253745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9116    0.9725    0.9411    124347
           N     0.8048    0.6562    0.7230     14202
           P     0.8850    0.6835    0.7713     25017

   micro avg     0.9009    0.9009    0.9009    163566
   macro avg     0.8671    0.7707    0.8118    163566
weighted avg     0.8982    0.9009    0.8962    163566

F1-macro tok:  0.8117749408330664
F1-micro tok:  0.9008657055867356
**************************************************
dev_cost_sum: 42342.351013183594
dev_cost_avg: 38.45808448063905
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19137.0
dev_accuracy_tok: 0.8995487449468835
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6393728222996515
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7325349301397205
dev_label=P_precision_sent: 0.6946564885496184
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7520661157024794
dev_precision_macro_sent: 0.6668986591719789
dev_recall_macro_sent: 0.5620100265959956
dev_f-score_macro_sent: 0.5006141417175148
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9111510374405934
dev_label=O_recall_tok: 0.9701326751002777
dev_label=O_f-score_tok: 0.9397172659075287
dev_label=N_precision_tok: 0.8035350101971448
dev_label=N_recall_tok: 0.6365105008077544
dev_label=N_f-score_tok: 0.7103365384615383
dev_label=P_precision_tok: 0.8764221263240487
dev_label=P_recall_tok: 0.6955168119551681
dev_label=P_f-score_tok: 0.7755597986460684
dev_precision_macro_tok: 0.8637027246539289
dev_recall_macro_tok: 0.7673866626210667
dev_f-score_macro_tok: 0.8085378676717118
dev_precision_micro_tok: 0.8995487449468835
dev_recall_micro_tok: 0.8995487449468835
dev_f-score_micro_tok: 0.8995487449468835
dev_time: 5.047955513000488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6394    0.8575    0.7325       428
           P     0.6947    0.8198    0.7521       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6669    0.5620    0.5006      1101
weighted avg     0.6673    0.6658    0.5916      1101

F1-macro sent:  0.5006141417175148
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9112    0.9701    0.9397     16205
           N     0.8035    0.6365    0.7103      1857
           P     0.8764    0.6955    0.7756      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8637    0.7674    0.8085     21274
weighted avg     0.8965    0.8995    0.8949     21274

F1-macro tok:  0.8085378676717118
F1-micro tok:  0.8995487449468835
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 305397.65350341797
train_cost_avg: 35.74410738569967
train_count_sent: 8544.0
train_total_correct_sent: 5813.0
train_accuracy_sent: 0.6803604868913857
train_count_tok: 163566.0
train_total_correct_tok: 147666.0
train_accuracy_tok: 0.9027915336928213
train_label=O_precision_sent: 0.41836734693877553
train_label=O_recall_sent: 0.025246305418719212
train_label=O_f-score_sent: 0.04761904761904762
train_label=N_precision_sent: 0.648331415420023
train_label=N_recall_sent: 0.8510574018126889
train_label=N_f-score_sent: 0.7359895493141738
train_label=P_precision_sent: 0.7205559619604974
train_label=P_recall_sent: 0.8185595567867036
train_label=P_f-score_sent: 0.7664375567371287
train_precision_macro_sent: 0.5957515747730987
train_recall_macro_sent: 0.5649544213393706
train_f-score_macro_sent: 0.5166820512234501
train_precision_micro_sent: 0.6803604868913857
train_recall_micro_sent: 0.6803604868913857
train_f-score_micro_sent: 0.6803604868913857
train_label=O_precision_tok: 0.9136260300148791
train_label=O_recall_tok: 0.972801917215534
train_label=O_f-score_tok: 0.9422858211164254
train_label=N_precision_tok: 0.8099640472521829
train_label=N_recall_tok: 0.6662441909590199
train_label=N_f-score_tok: 0.7311080203987018
train_label=P_precision_tok: 0.8848226659138736
train_label=P_recall_tok: 0.6890914178358716
train_label=P_f-score_tok: 0.7747865168539325
train_precision_macro_tok: 0.8694709143936451
train_recall_macro_tok: 0.7760458420034752
train_f-score_macro_tok: 0.8160601194563532
train_precision_micro_tok: 0.9027915336928213
train_recall_micro_tok: 0.9027915336928213
train_f-score_micro_tok: 0.9027915336928214
train_time: 95.49158096313477
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4184    0.0252    0.0476      1624
           N     0.6483    0.8511    0.7360      3310
           P     0.7206    0.8186    0.7664      3610

   micro avg     0.6804    0.6804    0.6804      8544
   macro avg     0.5958    0.5650    0.5167      8544
weighted avg     0.6351    0.6804    0.6180      8544

F1-macro sent:  0.5166820512234501
F1-micro sent:  0.6803604868913857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9728    0.9423    124347
           N     0.8100    0.6662    0.7311     14202
           P     0.8848    0.6891    0.7748     25017

   micro avg     0.9028    0.9028    0.9028    163566
   macro avg     0.8695    0.7760    0.8161    163566
weighted avg     0.9002    0.9028    0.8983    163566

F1-macro tok:  0.8160601194563532
F1-micro tok:  0.9027915336928214
**************************************************
dev_cost_sum: 42249.904296875
dev_cost_avg: 38.37411834411898
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19158.0
dev_accuracy_tok: 0.9005358653755758
dev_label=O_precision_sent: 0.5135135135135135
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14285714285714288
dev_label=N_precision_sent: 0.628099173553719
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.7357212003872217
dev_label=P_precision_sent: 0.7298474945533769
dev_label=P_recall_sent: 0.7545045045045045
dev_label=P_f-score_sent: 0.7419712070874861
dev_precision_macro_sent: 0.6238200605402032
dev_recall_macro_sent: 0.5751081347028782
dev_f-score_macro_sent: 0.5401831834439502
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9144456756283899
dev_label=O_recall_tok: 0.9676025917926566
dev_label=O_f-score_tok: 0.940273446869753
dev_label=N_precision_tok: 0.7870370370370371
dev_label=N_recall_tok: 0.6408185245018848
dev_label=N_f-score_tok: 0.7064410804392997
dev_label=P_precision_tok: 0.8749521988527724
dev_label=P_recall_tok: 0.7123287671232876
dev_label=P_f-score_tok: 0.7853097648875922
dev_precision_macro_tok: 0.8588116371727331
dev_recall_macro_tok: 0.7735832944726097
dev_f-score_macro_tok: 0.8106747640655483
dev_precision_micro_tok: 0.9005358653755758
dev_recall_micro_tok: 0.9005358653755758
dev_f-score_micro_tok: 0.9005358653755758
dev_time: 5.1090264320373535
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5135    0.0830    0.1429       229
           N     0.6281    0.8879    0.7357       428
           P     0.7298    0.7545    0.7420       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6238    0.5751    0.5402      1101
weighted avg     0.6453    0.6667    0.6149      1101

F1-macro sent:  0.5401831834439502
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9144    0.9676    0.9403     16205
           N     0.7870    0.6408    0.7064      1857
           P     0.8750    0.7123    0.7853      3212

   micro avg     0.9005    0.9005    0.9005     21274
   macro avg     0.8588    0.7736    0.8107     21274
weighted avg     0.8974    0.9005    0.8965     21274

F1-macro tok:  0.8106747640655483
F1-micro tok:  0.9005358653755758
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 303940.8102416992
train_cost_avg: 35.57359670431873
train_count_sent: 8544.0
train_total_correct_sent: 5817.0
train_accuracy_sent: 0.6808286516853933
train_count_tok: 163566.0
train_total_correct_tok: 147802.0
train_accuracy_tok: 0.9036230023354487
train_label=O_precision_sent: 0.40625
train_label=O_recall_sent: 0.03201970443349754
train_label=O_f-score_sent: 0.05936073059360731
train_label=N_precision_sent: 0.6528768426058013
train_label=N_recall_sent: 0.829607250755287
train_label=N_f-score_sent: 0.7307078233102715
train_label=P_precision_sent: 0.7171021377672209
train_label=P_recall_sent: 0.8362880886426592
train_label=P_f-score_sent: 0.7721227621483375
train_precision_macro_sent: 0.5920763267910073
train_recall_macro_sent: 0.5659716812771479
train_f-score_macro_sent: 0.5207304386840721
train_precision_micro_sent: 0.6808286516853933
train_recall_micro_sent: 0.6808286516853933
train_f-score_micro_sent: 0.6808286516853933
train_label=O_precision_tok: 0.915128620527806
train_label=O_recall_tok: 0.9721424722751655
train_label=O_f-score_tok: 0.9427743613540737
train_label=N_precision_tok: 0.8089020771513353
train_label=N_recall_tok: 0.6718067877763695
train_label=N_f-score_tok: 0.7340077701273223
train_label=P_precision_tok: 0.8831630838034253
train_label=P_recall_tok: 0.6946476396050686
train_label=P_f-score_tok: 0.7776435315702331
train_precision_macro_tok: 0.8690645938275222
train_recall_macro_tok: 0.7795322998855346
train_f-score_macro_tok: 0.8181418876838764
train_precision_micro_tok: 0.9036230023354487
train_recall_micro_tok: 0.9036230023354487
train_f-score_micro_tok: 0.9036230023354488
train_time: 95.90806102752686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4062    0.0320    0.0594      1624
           N     0.6529    0.8296    0.7307      3310
           P     0.7171    0.8363    0.7721      3610

   micro avg     0.6808    0.6808    0.6808      8544
   macro avg     0.5921    0.5660    0.5207      8544
weighted avg     0.6331    0.6808    0.6206      8544

F1-macro sent:  0.5207304386840721
F1-micro sent:  0.6808286516853933
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9151    0.9721    0.9428    124347
           N     0.8089    0.6718    0.7340     14202
           P     0.8832    0.6946    0.7776     25017

   micro avg     0.9036    0.9036    0.9036    163566
   macro avg     0.8691    0.7795    0.8181    163566
weighted avg     0.9010    0.9036    0.8994    163566

F1-macro tok:  0.8181418876838764
F1-micro tok:  0.9036230023354488
**************************************************
dev_cost_sum: 42111.889587402344
dev_cost_avg: 38.24876438456162
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19219.0
dev_accuracy_tok: 0.9034032151922534
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06639004149377593
dev_label=N_precision_sent: 0.6789883268482491
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7409766454352441
dev_label=P_precision_sent: 0.6643478260869565
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7497546614327772
dev_precision_macro_sent: 0.6700009398672907
dev_recall_macro_sent: 0.5702384729748725
dev_f-score_macro_sent: 0.5190404494539324
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.909833237492812
dev_label=O_recall_tok: 0.9763653193458809
dev_label=O_f-score_tok: 0.941925881827653
dev_label=N_precision_tok: 0.800135043889264
dev_label=N_recall_tok: 0.6381260096930533
dev_label=N_f-score_tok: 0.7100059916117435
dev_label=P_precision_tok: 0.9205160216396171
dev_label=P_recall_tok: 0.688667496886675
dev_label=P_f-score_tok: 0.7878895814781836
dev_precision_macro_tok: 0.8768281010072311
dev_recall_macro_tok: 0.7677196086418697
dev_f-score_macro_tok: 0.8132738183058601
dev_precision_micro_tok: 0.9034032151922534
dev_recall_micro_tok: 0.9034032151922534
dev_f-score_micro_tok: 0.9034032151922534
dev_time: 5.0266804695129395
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0349    0.0664       229
           N     0.6790    0.8154    0.7410       428
           P     0.6643    0.8604    0.7498       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6700    0.5702    0.5190      1101
weighted avg     0.6705    0.6712    0.6042      1101

F1-macro sent:  0.5190404494539324
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9098    0.9764    0.9419     16205
           N     0.8001    0.6381    0.7100      1857
           P     0.9205    0.6887    0.7879      3212

   micro avg     0.9034    0.9034    0.9034     21274
   macro avg     0.8768    0.7677    0.8133     21274
weighted avg     0.9019    0.9034    0.8984     21274

F1-macro tok:  0.8132738183058601
F1-micro tok:  0.9034032151922534
**************************************************
Best epoch: 24
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 302318.7203979492
train_cost_avg: 35.383745364928515
train_count_sent: 8544.0
train_total_correct_sent: 5879.0
train_accuracy_sent: 0.6880852059925093
train_count_tok: 163566.0
train_total_correct_tok: 148119.0
train_accuracy_tok: 0.9055610579215729
train_label=O_precision_sent: 0.4883720930232558
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07187678265830005
train_label=N_precision_sent: 0.6515920627595755
train_label=N_recall_sent: 0.8531722054380665
train_label=N_f-score_sent: 0.738880167451596
train_label=P_precision_sent: 0.7331536388140162
train_label=P_recall_sent: 0.8288088642659279
train_label=P_f-score_sent: 0.7780522688857106
train_precision_macro_sent: 0.6243725981989492
train_recall_macro_sent: 0.5735913910507567
train_f-score_macro_sent: 0.5296030729985356
train_precision_micro_sent: 0.6880852059925093
train_recall_micro_sent: 0.6880852059925093
train_f-score_micro_sent: 0.6880852059925093
train_label=O_precision_tok: 0.9168390660877077
train_label=O_recall_tok: 0.972978841467828
train_label=O_f-score_tok: 0.9440750971487429
train_label=N_precision_tok: 0.8119463426980511
train_label=N_recall_tok: 0.6776510350654837
train_label=N_f-score_tok: 0.7387449625791593
train_label=P_precision_tok: 0.8863912515188336
train_label=P_recall_tok: 0.6998441060079146
train_label=P_f-score_tok: 0.7821483615894927
train_precision_macro_tok: 0.8717255534348641
train_recall_macro_tok: 0.7834913275137421
train_f-score_macro_tok: 0.8216561404391317
train_precision_micro_tok: 0.9055610579215729
train_recall_micro_tok: 0.9055610579215729
train_f-score_micro_tok: 0.9055610579215729
train_time: 95.93922924995422
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4884    0.0388    0.0719      1624
           N     0.6516    0.8532    0.7389      3310
           P     0.7332    0.8288    0.7781      3610

   micro avg     0.6881    0.6881    0.6881      8544
   macro avg     0.6244    0.5736    0.5296      8544
weighted avg     0.6550    0.6881    0.6287      8544

F1-macro sent:  0.5296030729985356
F1-micro sent:  0.6880852059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9168    0.9730    0.9441    124347
           N     0.8119    0.6777    0.7387     14202
           P     0.8864    0.6998    0.7821     25017

   micro avg     0.9056    0.9056    0.9056    163566
   macro avg     0.8717    0.7835    0.8217    163566
weighted avg     0.9031    0.9056    0.9015    163566

F1-macro tok:  0.8216561404391317
F1-micro tok:  0.9055610579215729
**************************************************
dev_cost_sum: 42088.56298828125
dev_cost_avg: 38.22757764603202
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19183.0
dev_accuracy_tok: 0.9017110087430666
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04184100418410041
dev_label=N_precision_sent: 0.5978428351309707
dev_label=N_recall_sent: 0.9065420560747663
dev_label=N_f-score_sent: 0.7205199628597957
dev_label=P_precision_sent: 0.746606334841629
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7449209932279909
dev_precision_macro_sent: 0.6148163899908665
dev_recall_macro_sent: 0.5572064534844602
dev_f-score_macro_sent: 0.502427320090629
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9096978417266187
dev_label=O_recall_tok: 0.975377969762419
dev_label=O_f-score_tok: 0.9413936867182847
dev_label=N_precision_tok: 0.7922343324250681
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.6995488721804513
dev_label=P_precision_tok: 0.9107363225010284
dev_label=P_recall_tok: 0.6892901618929016
dev_label=P_f-score_tok: 0.784688995215311
dev_precision_macro_tok: 0.8708894988842384
dev_recall_macro_tok: 0.7636490253965053
dev_f-score_macro_tok: 0.8085438513713491
dev_precision_micro_tok: 0.9017110087430666
dev_recall_micro_tok: 0.9017110087430666
dev_f-score_micro_tok: 0.9017110087430666
dev_time: 5.061305999755859
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0218    0.0418       229
           N     0.5978    0.9065    0.7205       428
           P     0.7466    0.7432    0.7449       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6148    0.5572    0.5024      1101
weighted avg     0.6375    0.6567    0.5892      1101

F1-macro sent:  0.502427320090629
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9097    0.9754    0.9414     16205
           N     0.7922    0.6263    0.6995      1857
           P     0.9107    0.6893    0.7847      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8709    0.7636    0.8085     21274
weighted avg     0.8996    0.9017    0.8966     21274

F1-macro tok:  0.8085438513713491
F1-micro tok:  0.9017110087430666
**************************************************
Best epoch: 24
**************************************************

EPOCH: 27
Learning rate: 1.000000
train_cost_sum: 301014.0934448242
train_cost_avg: 35.231050262736915
train_count_sent: 8544.0
train_total_correct_sent: 5875.0
train_accuracy_sent: 0.6876170411985019
train_count_tok: 163566.0
train_total_correct_tok: 148347.0
train_accuracy_tok: 0.9069549906459777
train_label=O_precision_sent: 0.457286432160804
train_label=O_recall_sent: 0.05603448275862069
train_label=O_f-score_sent: 0.09983543609434997
train_label=N_precision_sent: 0.6519619224518226
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7372981488775108
train_label=P_precision_sent: 0.736998514115899
train_label=P_recall_sent: 0.824376731301939
train_label=P_f-score_sent: 0.7782426778242678
train_precision_macro_sent: 0.6154156229095086
train_recall_macro_sent: 0.5762498608802067
train_f-score_macro_sent: 0.5384587542653761
train_precision_micro_sent: 0.6876170411985019
train_recall_micro_sent: 0.6876170411985019
train_f-score_micro_sent: 0.6876170411985019
train_label=O_precision_tok: 0.9189511685350561
train_label=O_recall_tok: 0.9723676485962669
train_label=O_f-score_tok: 0.944905088269082
train_label=N_precision_tok: 0.817907444668008
train_label=N_recall_tok: 0.6869455006337135
train_label=N_f-score_tok: 0.746727898966705
train_label=P_precision_tok: 0.8812241439465683
train_label=P_recall_tok: 0.7067194307870648
train_label=P_f-score_tok: 0.7843833185448092
train_precision_macro_tok: 0.8726942523832109
train_recall_macro_tok: 0.7886775266723484
train_f-score_macro_tok: 0.8253387685935322
train_precision_micro_tok: 0.9069549906459777
train_recall_micro_tok: 0.9069549906459777
train_f-score_micro_tok: 0.9069549906459777
train_time: 122.46592831611633
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4573    0.0560    0.0998      1624
           N     0.6520    0.8483    0.7373      3310
           P     0.7370    0.8244    0.7782      3610

   micro avg     0.6876    0.6876    0.6876      8544
   macro avg     0.6154    0.5762    0.5385      8544
weighted avg     0.6509    0.6876    0.6334      8544

F1-macro sent:  0.5384587542653761
F1-micro sent:  0.6876170411985019
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9190    0.9724    0.9449    124347
           N     0.8179    0.6869    0.7467     14202
           P     0.8812    0.7067    0.7844     25017

   micro avg     0.9070    0.9070    0.9070    163566
   macro avg     0.8727    0.7887    0.8253    163566
weighted avg     0.9044    0.9070    0.9031    163566

F1-macro tok:  0.8253387685935322
F1-micro tok:  0.9069549906459777
**************************************************
dev_cost_sum: 42062.69494628906
dev_cost_avg: 38.20408260335065
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19207.0
dev_accuracy_tok: 0.9028391463758578
dev_label=O_precision_sent: 0.6190476190476191
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.104
dev_label=N_precision_sent: 0.6563636363636364
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.738241308793456
dev_label=P_precision_sent: 0.6867924528301886
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7474332648870636
dev_precision_macro_sent: 0.654067902747148
dev_recall_macro_sent: 0.5733487742323394
dev_f-score_macro_sent: 0.5298915245601732
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9080183276059565
dev_label=O_recall_tok: 0.9783400185128047
dev_label=O_f-score_tok: 0.9418684093271945
dev_label=N_precision_tok: 0.805980528511822
dev_label=N_recall_tok: 0.6241249326871298
dev_label=N_f-score_tok: 0.7034901365705616
dev_label=P_precision_tok: 0.9234006734006734
dev_label=P_recall_tok: 0.6830635118306351
dev_label=P_f-score_tok: 0.7852541159627774
dev_precision_macro_tok: 0.8791331765061506
dev_recall_macro_tok: 0.7618428210101899
dev_f-score_macro_tok: 0.8102042206201778
dev_precision_micro_tok: 0.9028391463758578
dev_recall_micro_tok: 0.9028391463758578
dev_f-score_micro_tok: 0.9028391463758577
dev_time: 8.444257020950317
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6190    0.0568    0.1040       229
           N     0.6564    0.8435    0.7382       428
           P     0.6868    0.8198    0.7474       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6541    0.5733    0.5299      1101
weighted avg     0.6609    0.6703    0.6100      1101

F1-macro sent:  0.5298915245601732
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9783    0.9419     16205
           N     0.8060    0.6241    0.7035      1857
           P     0.9234    0.6831    0.7853      3212

   micro avg     0.9028    0.9028    0.9028     21274
   macro avg     0.8791    0.7618    0.8102     21274
weighted avg     0.9014    0.9028    0.8974     21274

F1-macro tok:  0.8102042206201778
F1-micro tok:  0.9028391463758577
**************************************************
Best epoch: 24
**************************************************

EPOCH: 28
Learning rate: 1.000000
train_cost_sum: 299223.51055908203
train_cost_avg: 35.02147829577271
train_count_sent: 8544.0
train_total_correct_sent: 5884.0
train_accuracy_sent: 0.6886704119850188
train_count_tok: 163566.0
train_total_correct_tok: 148647.0
train_accuracy_tok: 0.9087891126517736
train_label=O_precision_sent: 0.4881516587677725
train_label=O_recall_sent: 0.06342364532019705
train_label=O_f-score_sent: 0.11226158038147141
train_label=N_precision_sent: 0.6719667318982387
train_label=N_recall_sent: 0.8299093655589124
train_label=N_f-score_sent: 0.7426331440929981
train_label=P_precision_sent: 0.7147232037691401
train_label=P_recall_sent: 0.8404432132963989
train_label=P_f-score_sent: 0.7725015913430935
train_precision_macro_sent: 0.6249471981450504
train_recall_macro_sent: 0.5779254080585028
train_f-score_macro_sent: 0.5424654386058543
train_precision_micro_sent: 0.6886704119850188
train_recall_micro_sent: 0.6886704119850188
train_f-score_micro_sent: 0.6886704119850188
train_label=O_precision_tok: 0.9210590439060049
train_label=O_recall_tok: 0.9727536651467265
train_label=O_f-score_tok: 0.9462008111924216
train_label=N_precision_tok: 0.8174173674132046
train_label=N_recall_tok: 0.6913110829460639
train_label=N_f-score_tok: 0.7490939610117118
train_label=P_precision_tok: 0.8833852390132978
train_label=P_recall_tok: 0.7143142662989167
train_label=P_f-score_tok: 0.7899040799186668
train_precision_macro_tok: 0.8739538834441691
train_recall_macro_tok: 0.7927930047972357
train_f-score_macro_tok: 0.8283996173742668
train_precision_micro_tok: 0.9087891126517736
train_recall_micro_tok: 0.9087891126517736
train_f-score_micro_tok: 0.9087891126517738
train_time: 149.07789278030396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4882    0.0634    0.1123      1624
           N     0.6720    0.8299    0.7426      3310
           P     0.7147    0.8404    0.7725      3610

   micro avg     0.6887    0.6887    0.6887      8544
   macro avg     0.6249    0.5779    0.5425      8544
weighted avg     0.6551    0.6887    0.6354      8544

F1-macro sent:  0.5424654386058543
F1-micro sent:  0.6886704119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9211    0.9728    0.9462    124347
           N     0.8174    0.6913    0.7491     14202
           P     0.8834    0.7143    0.7899     25017

   micro avg     0.9088    0.9088    0.9088    163566
   macro avg     0.8740    0.7928    0.8284    163566
weighted avg     0.9063    0.9088    0.9052    163566

F1-macro tok:  0.8283996173742668
F1-micro tok:  0.9087891126517738
**************************************************
dev_cost_sum: 42038.99432373047
dev_cost_avg: 38.18255615234375
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19236.0
dev_accuracy_tok: 0.9042023126821472
dev_label=O_precision_sent: 0.38571428571428573
dev_label=O_recall_sent: 0.11790393013100436
dev_label=O_f-score_sent: 0.1806020066889632
dev_label=N_precision_sent: 0.684931506849315
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7454739084132055
dev_label=P_precision_sent: 0.6942307692307692
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7489626556016598
dev_precision_macro_sent: 0.58829218726479
dev_recall_macro_sent: 0.5829080008466206
dev_f-score_macro_sent: 0.5583461902346095
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.907579825212772
dev_label=O_recall_tok: 0.9804998457266276
dev_label=O_f-score_tok: 0.9426317038443285
dev_label=N_precision_tok: 0.8229390681003584
dev_label=N_recall_tok: 0.6182014001077006
dev_label=N_f-score_tok: 0.7060270602706027
dev_label=P_precision_tok: 0.9270657672849916
dev_label=P_recall_tok: 0.6846201743462017
dev_label=P_f-score_tok: 0.7876074498567335
dev_precision_macro_tok: 0.8858615535327073
dev_recall_macro_tok: 0.7611071400601767
dev_f-score_macro_tok: 0.8120887379905549
dev_precision_micro_tok: 0.9042023126821472
dev_recall_micro_tok: 0.9042023126821472
dev_f-score_micro_tok: 0.9042023126821472
dev_time: 11.751928091049194
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3857    0.1179    0.1806       229
           N     0.6849    0.8178    0.7455       428
           P     0.6942    0.8131    0.7490       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.5883    0.5829    0.5583      1101
weighted avg     0.6264    0.6703    0.6294      1101

F1-macro sent:  0.5583461902346095
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9076    0.9805    0.9426     16205
           N     0.8229    0.6182    0.7060      1857
           P     0.9271    0.6846    0.7876      3212

   micro avg     0.9042    0.9042    0.9042     21274
   macro avg     0.8859    0.7611    0.8121     21274
weighted avg     0.9031    0.9042    0.8986     21274

F1-macro tok:  0.8120887379905549
F1-micro tok:  0.9042023126821472
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 1.000000
train_cost_sum: 298203.5473022461
train_cost_avg: 34.902100573764756
train_count_sent: 8544.0
train_total_correct_sent: 5879.0
train_accuracy_sent: 0.6880852059925093
train_count_tok: 163566.0
train_total_correct_tok: 148811.0
train_accuracy_tok: 0.9097917660149419
train_label=O_precision_sent: 0.42758620689655175
train_label=O_recall_sent: 0.07635467980295567
train_label=O_f-score_sent: 0.12957157784743992
train_label=N_precision_sent: 0.6596758817921831
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.7375432986943778
train_label=P_precision_sent: 0.7360768851651059
train_label=P_recall_sent: 0.8274238227146814
train_label=P_f-score_sent: 0.7790818988002086
train_precision_macro_sent: 0.6077796579512803
train_recall_macro_sent: 0.5800107596508941
train_f-score_macro_sent: 0.5487322584473421
train_precision_micro_sent: 0.6880852059925093
train_recall_micro_sent: 0.6880852059925093
train_f-score_micro_sent: 0.6880852059925093
train_label=O_precision_tok: 0.9218141495126245
train_label=O_recall_tok: 0.972713455089387
train_label=O_f-score_tok: 0.9465800594772265
train_label=N_precision_tok: 0.8192381110465599
train_label=N_recall_tok: 0.6950429516969441
train_label=N_f-score_tok: 0.7520475410460554
train_label=P_precision_tok: 0.8858353033884949
train_label=P_recall_tok: 0.7189511132429948
train_label=P_f-score_tok: 0.7937159374241523
train_precision_macro_tok: 0.8756291879825597
train_recall_macro_tok: 0.7955691733431086
train_f-score_macro_tok: 0.8307811793158114
train_precision_micro_tok: 0.9097917660149419
train_recall_micro_tok: 0.9097917660149419
train_f-score_micro_tok: 0.9097917660149419
train_time: 197.45879244804382
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4276    0.0764    0.1296      1624
           N     0.6597    0.8363    0.7375      3310
           P     0.7361    0.8274    0.7791      3610

   micro avg     0.6881    0.6881    0.6881      8544
   macro avg     0.6078    0.5800    0.5487      8544
weighted avg     0.6478    0.6881    0.6395      8544

F1-macro sent:  0.5487322584473421
F1-micro sent:  0.6880852059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9218    0.9727    0.9466    124347
           N     0.8192    0.6950    0.7520     14202
           P     0.8858    0.7190    0.7937     25017

   micro avg     0.9098    0.9098    0.9098    163566
   macro avg     0.8756    0.7956    0.8308    163566
weighted avg     0.9074    0.9098    0.9063    163566

F1-macro tok:  0.8307811793158114
F1-micro tok:  0.9097917660149419
**************************************************
dev_cost_sum: 41920.93634033203
dev_cost_avg: 38.075328192853796
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19182.0
dev_accuracy_tok: 0.901664003008367
dev_label=O_precision_sent: 0.4857142857142857
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.1287878787878788
dev_label=N_precision_sent: 0.7224770642201835
dev_label=N_recall_sent: 0.735981308411215
dev_label=N_f-score_sent: 0.7291666666666669
dev_label=P_precision_sent: 0.638095238095238
dev_label=P_recall_sent: 0.9054054054054054
dev_label=P_f-score_sent: 0.7486033519553073
dev_precision_macro_sent: 0.615428862676569
dev_recall_macro_sent: 0.5718741738922941
dev_f-score_macro_sent: 0.5355192991366177
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.91554389034704
dev_label=O_recall_tok: 0.9686516507250849
dev_label=O_f-score_tok: 0.9413493253373313
dev_label=N_precision_tok: 0.783203125
dev_label=N_recall_tok: 0.6478190630048465
dev_label=N_f-score_tok: 0.7091069849690539
dev_label=P_precision_tok: 0.8800617045892788
dev_label=P_recall_tok: 0.7104607721046077
dev_label=P_f-score_tok: 0.7862187769164513
dev_precision_macro_tok: 0.8596029066454397
dev_recall_macro_tok: 0.7756438286115129
dev_f-score_macro_tok: 0.8122250290742787
dev_precision_micro_tok: 0.901664003008367
dev_recall_micro_tok: 0.901664003008367
dev_f-score_micro_tok: 0.901664003008367
dev_time: 11.79220461845398
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4857    0.0742    0.1288       229
           N     0.7225    0.7360    0.7292       428
           P     0.6381    0.9054    0.7486       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6154    0.5719    0.5355      1101
weighted avg     0.6392    0.6667    0.6121      1101

F1-macro sent:  0.5355192991366177
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9155    0.9687    0.9413     16205
           N     0.7832    0.6478    0.7091      1857
           P     0.8801    0.7105    0.7862      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8596    0.7756    0.8122     21274
weighted avg     0.8986    0.9017    0.8977     21274

F1-macro tok:  0.8122250290742787
F1-micro tok:  0.901664003008367
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 1.000000
train_cost_sum: 296512.81451416016
train_cost_avg: 34.704215181900764
train_count_sent: 8544.0
train_total_correct_sent: 5942.0
train_accuracy_sent: 0.6954588014981273
train_count_tok: 163566.0
train_total_correct_tok: 149210.0
train_accuracy_tok: 0.9122311482826504
train_label=O_precision_sent: 0.40585774058577406
train_label=O_recall_sent: 0.11945812807881774
train_label=O_f-score_sent: 0.18458610846812562
train_label=N_precision_sent: 0.6827430293896006
train_label=N_recall_sent: 0.8211480362537764
train_label=N_f-score_sent: 0.7455767384446578
train_label=P_precision_sent: 0.7417380660954712
train_label=P_recall_sent: 0.8393351800554016
train_label=P_f-score_sent: 0.7875243664717348
train_precision_macro_sent: 0.6101129453569486
train_recall_macro_sent: 0.5933137814626653
train_f-score_macro_sent: 0.5725624044615061
train_precision_micro_sent: 0.6954588014981273
train_recall_micro_sent: 0.6954588014981273
train_f-score_micro_sent: 0.6954588014981273
train_label=O_precision_tok: 0.9244877840018952
train_label=O_recall_tok: 0.9728582112958093
train_label=O_f-score_tok: 0.9480564263322884
train_label=N_precision_tok: 0.8218268284683503
train_label=N_recall_tok: 0.7057456696239967
train_label=N_f-score_tok: 0.759375710281082
train_label=P_precision_tok: 0.8878003606765121
train_label=P_recall_tok: 0.7281048886757006
train_label=P_f-score_tok: 0.8000614925110906
train_precision_macro_tok: 0.8780383243822526
train_recall_macro_tok: 0.8022362565318355
train_f-score_macro_tok: 0.8358312097081536
train_precision_micro_tok: 0.9122311482826504
train_recall_micro_tok: 0.9122311482826504
train_f-score_micro_tok: 0.9122311482826504
train_time: 198.1456799507141
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4059    0.1195    0.1846      1624
           N     0.6827    0.8211    0.7456      3310
           P     0.7417    0.8393    0.7875      3610

   micro avg     0.6955    0.6955    0.6955      8544
   macro avg     0.6101    0.5933    0.5726      8544
weighted avg     0.6550    0.6955    0.6567      8544

F1-macro sent:  0.5725624044615061
F1-micro sent:  0.6954588014981273
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9245    0.9729    0.9481    124347
           N     0.8218    0.7057    0.7594     14202
           P     0.8878    0.7281    0.8001     25017

   micro avg     0.9122    0.9122    0.9122    163566
   macro avg     0.8780    0.8022    0.8358    163566
weighted avg     0.9100    0.9122    0.9090    163566

F1-macro tok:  0.8358312097081536
F1-micro tok:  0.9122311482826504
**************************************************
dev_cost_sum: 42110.561584472656
dev_cost_avg: 38.24755820569724
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19192.0
dev_accuracy_tok: 0.9021340603553634
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.10894941634241244
dev_label=N_precision_sent: 0.6691729323308271
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7416666666666667
dev_label=P_precision_sent: 0.6876155268022182
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7553299492385787
dev_precision_macro_sent: 0.6189294863776817
dev_recall_macro_sent: 0.5769163033171522
dev_f-score_macro_sent: 0.5353153440825525
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9101123595505618
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.9412991656734208
dev_label=N_precision_tok: 0.8321060382916053
dev_label=N_recall_tok: 0.6085083467959074
dev_label=N_f-score_tok: 0.7029548989113531
dev_label=P_precision_tok: 0.8852010933229207
dev_label=P_recall_tok: 0.7057907845579079
dev_label=P_f-score_tok: 0.7853802182574051
dev_precision_macro_tok: 0.8758064970550293
dev_recall_macro_tok: 0.7629994327592015
dev_f-score_macro_tok: 0.8098780942807263
dev_precision_micro_tok: 0.9021340603553634
dev_recall_micro_tok: 0.9021340603553634
dev_f-score_micro_tok: 0.9021340603553635
dev_time: 11.495977878570557
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0611    0.1089       229
           N     0.6692    0.8318    0.7417       428
           P     0.6876    0.8378    0.7553       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6189    0.5769    0.5353      1101
weighted avg     0.6414    0.6739    0.6156      1101

F1-macro sent:  0.5353153440825525
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9101    0.9747    0.9413     16205
           N     0.8321    0.6085    0.7030      1857
           P     0.8852    0.7058    0.7854      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8758    0.7630    0.8099     21274
weighted avg     0.8995    0.9021    0.8970     21274

F1-macro tok:  0.8098780942807263
F1-micro tok:  0.9021340603553635
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 1.000000
train_cost_sum: 295065.9613647461
train_cost_avg: 34.534873755237136
train_count_sent: 8544.0
train_total_correct_sent: 5944.0
train_accuracy_sent: 0.6956928838951311
train_count_tok: 163566.0
train_total_correct_tok: 149390.0
train_accuracy_tok: 0.9133316214861279
train_label=O_precision_sent: 0.4233983286908078
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15330307614725164
train_label=N_precision_sent: 0.6798915722030557
train_label=N_recall_sent: 0.8335347432024169
train_label=N_f-score_sent: 0.748914223669924
train_label=P_precision_sent: 0.7349164041676762
train_label=P_recall_sent: 0.8401662049861496
train_label=P_f-score_sent: 0.7840248158200853
train_precision_macro_sent: 0.6127354350205132
train_recall_macro_sent: 0.5890990024339556
train_f-score_macro_sent: 0.5620807052124203
train_precision_micro_sent: 0.6956928838951311
train_recall_micro_sent: 0.6956928838951311
train_f-score_micro_sent: 0.6956928838951311
train_label=O_precision_tok: 0.9262661161203337
train_label=O_recall_tok: 0.9723756906077348
train_label=O_f-score_tok: 0.9487610050061989
train_label=N_precision_tok: 0.8213326824505736
train_label=N_recall_tok: 0.7108153781157583
train_label=N_f-score_tok: 0.7620880987430643
train_label=P_precision_tok: 0.8864403510463883
train_label=P_recall_tok: 0.734820322180917
train_label=P_f-score_tok: 0.8035405966561031
train_precision_macro_tok: 0.8780130498724318
train_recall_macro_tok: 0.8060037969681367
train_f-score_macro_tok: 0.838129900135122
train_precision_micro_tok: 0.9133316214861279
train_recall_micro_tok: 0.9133316214861279
train_f-score_micro_tok: 0.9133316214861279
train_time: 165.33438372612
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4234    0.0936    0.1533      1624
           N     0.6799    0.8335    0.7489      3310
           P     0.7349    0.8402    0.7840      3610

   micro avg     0.6957    0.6957    0.6957      8544
   macro avg     0.6127    0.5891    0.5621      8544
weighted avg     0.6544    0.6957    0.6505      8544

F1-macro sent:  0.5620807052124203
F1-micro sent:  0.6956928838951311
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9263    0.9724    0.9488    124347
           N     0.8213    0.7108    0.7621     14202
           P     0.8864    0.7348    0.8035     25017

   micro avg     0.9133    0.9133    0.9133    163566
   macro avg     0.8780    0.8060    0.8381    163566
weighted avg     0.9111    0.9133    0.9103    163566

F1-macro tok:  0.838129900135122
F1-micro tok:  0.9133316214861279
**************************************************
dev_cost_sum: 41917.36749267578
dev_cost_avg: 38.07208673267555
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19156.0
dev_accuracy_tok: 0.9004418539061766
dev_label=O_precision_sent: 0.4666666666666667
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05737704918032786
dev_label=N_precision_sent: 0.6660482374768089
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7425025853154084
dev_label=P_precision_sent: 0.6855575868372943
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.756811301715439
dev_precision_macro_sent: 0.6060908303269233
dev_recall_macro_sent: 0.5713157756376953
dev_f-score_macro_sent: 0.5188969787370584
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9097779059705797
dev_label=O_recall_tok: 0.9732181425485961
dev_label=O_f-score_tok: 0.9404293381037567
dev_label=N_precision_tok: 0.8035087719298246
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.6977452772699574
dev_label=P_precision_tok: 0.8910103420843277
dev_label=P_recall_tok: 0.6973848069738481
dev_label=P_f-score_tok: 0.78239608801956
dev_precision_macro_tok: 0.8680990066615774
dev_recall_macro_tok: 0.7623962802482819
dev_f-score_macro_tok: 0.8068569011310913
dev_precision_micro_tok: 0.9004418539061766
dev_recall_micro_tok: 0.9004418539061766
dev_f-score_micro_tok: 0.9004418539061767
dev_time: 8.427714824676514
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0306    0.0574       229
           N     0.6660    0.8388    0.7425       428
           P     0.6856    0.8446    0.7568       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6061    0.5713    0.5189      1101
weighted avg     0.6324    0.6730    0.6058      1101

F1-macro sent:  0.5188969787370584
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9098    0.9732    0.9404     16205
           N     0.8035    0.6166    0.6977      1857
           P     0.8910    0.6974    0.7824      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8681    0.7624    0.8069     21274
weighted avg     0.8977    0.9004    0.8954     21274

F1-macro tok:  0.8068569011310913
F1-micro tok:  0.9004418539061767
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 1.000000
train_cost_sum: 293594.88983154297
train_cost_avg: 34.362697779909055
train_count_sent: 8544.0
train_total_correct_sent: 5950.0
train_accuracy_sent: 0.6963951310861424
train_count_tok: 163566.0
train_total_correct_tok: 149804.0
train_accuracy_tok: 0.9158627098541262
train_label=O_precision_sent: 0.38977635782747605
train_label=O_recall_sent: 0.07512315270935961
train_label=O_f-score_sent: 0.12596799173980383
train_label=N_precision_sent: 0.6934914228052472
train_label=N_recall_sent: 0.8305135951661632
train_label=N_f-score_sent: 0.7558427275226836
train_label=P_precision_sent: 0.7215842512303726
train_label=P_recall_sent: 0.8529085872576178
train_label=P_f-score_sent: 0.7817697092801827
train_precision_macro_sent: 0.6016173439543654
train_recall_macro_sent: 0.5861817783777136
train_f-score_macro_sent: 0.5545268095142234
train_precision_micro_sent: 0.6963951310861424
train_recall_micro_sent: 0.6963951310861424
train_f-score_micro_sent: 0.6963951310861424
train_label=O_precision_tok: 0.9284963277334787
train_label=O_recall_tok: 0.9729547154334242
train_label=O_f-score_tok: 0.9502057742452327
train_label=N_precision_tok: 0.8316550267987657
train_label=N_recall_tok: 0.7210956203351641
train_label=N_f-score_tok: 0.772439281942978
train_label=P_precision_tok: 0.886783447090831
train_label=P_recall_tok: 0.7426549946036695
train_label=P_f-score_tok: 0.808344935607379
train_precision_macro_tok: 0.8823116005410251
train_recall_macro_tok: 0.812235110124086
train_f-score_macro_tok: 0.8436633305985298
train_precision_micro_tok: 0.9158627098541262
train_recall_micro_tok: 0.9158627098541262
train_f-score_micro_tok: 0.9158627098541262
train_time: 152.3840081691742
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3898    0.0751    0.1260      1624
           N     0.6935    0.8305    0.7558      3310
           P     0.7216    0.8529    0.7818      3610

   micro avg     0.6964    0.6964    0.6964      8544
   macro avg     0.6016    0.5862    0.5545      8544
weighted avg     0.6476    0.6964    0.6471      8544

F1-macro sent:  0.5545268095142234
F1-micro sent:  0.6963951310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9285    0.9730    0.9502    124347
           N     0.8317    0.7211    0.7724     14202
           P     0.8868    0.7427    0.8083     25017

   micro avg     0.9159    0.9159    0.9159    163566
   macro avg     0.8823    0.8122    0.8437    163566
weighted avg     0.9137    0.9159    0.9131    163566

F1-macro tok:  0.8436633305985298
F1-micro tok:  0.9158627098541262
**************************************************
dev_cost_sum: 41892.09356689453
dev_cost_avg: 38.04913130508132
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19196.0
dev_accuracy_tok: 0.9023220832941619
dev_label=O_precision_sent: 0.35135135135135137
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.09774436090225563
dev_label=N_precision_sent: 0.6845360824742268
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7272727272727273
dev_label=P_precision_sent: 0.6683937823834197
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.7565982404692082
dev_precision_macro_sent: 0.5680937387363326
dev_recall_macro_sent: 0.5680303717176752
dev_f-score_macro_sent: 0.5272051095480638
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9119278779472955
dev_label=O_recall_tok: 0.9737735266892934
dev_label=O_f-score_tok: 0.941836521531529
dev_label=N_precision_tok: 0.8168210976478973
dev_label=N_recall_tok: 0.617124394184168
dev_label=N_f-score_tok: 0.7030674846625767
dev_label=P_precision_tok: 0.8843007401636152
dev_label=P_recall_tok: 0.7067247820672479
dev_label=P_f-score_tok: 0.7856030455096038
dev_precision_macro_tok: 0.8710165719196027
dev_recall_macro_tok: 0.7658742343135697
dev_f-score_macro_tok: 0.8101690172345698
dev_precision_micro_tok: 0.9023220832941619
dev_recall_micro_tok: 0.9023220832941619
dev_f-score_micro_tok: 0.9023220832941619
dev_time: 11.884185075759888
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3514    0.0568    0.0977       229
           N     0.6845    0.7757    0.7273       428
           P     0.6684    0.8716    0.7566       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.5681    0.5680    0.5272      1101
weighted avg     0.6087    0.6649    0.6082      1101

F1-macro sent:  0.5272051095480638
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9738    0.9418     16205
           N     0.8168    0.6171    0.7031      1857
           P     0.8843    0.7067    0.7856      3212

   micro avg     0.9023    0.9023    0.9023     21274
   macro avg     0.8710    0.7659    0.8102     21274
weighted avg     0.8995    0.9023    0.8974     21274

F1-macro tok:  0.8101690172345698
F1-micro tok:  0.9023220832941619
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.900000
train_cost_sum: 291720.5919189453
train_cost_avg: 34.14332770586907
train_count_sent: 8544.0
train_total_correct_sent: 5967.0
train_accuracy_sent: 0.6983848314606742
train_count_tok: 163566.0
train_total_correct_tok: 150230.0
train_accuracy_tok: 0.9184671631023562
train_label=O_precision_sent: 0.43506493506493504
train_label=O_recall_sent: 0.12376847290640394
train_label=O_f-score_sent: 0.19271332694151486
train_label=N_precision_sent: 0.688396677573622
train_label=N_recall_sent: 0.8262839879154078
train_label=N_f-score_sent: 0.751064121927777
train_label=P_precision_sent: 0.737649063032368
train_label=P_recall_sent: 0.839612188365651
train_label=P_f-score_sent: 0.7853348879388523
train_precision_macro_sent: 0.6203702252236417
train_recall_macro_sent: 0.5965548830624875
train_f-score_macro_sent: 0.576370778936048
train_precision_micro_sent: 0.6983848314606742
train_recall_micro_sent: 0.6983848314606742
train_f-score_micro_sent: 0.6983848314606742
train_label=O_precision_tok: 0.9304634489330147
train_label=O_recall_tok: 0.9737589165802151
train_label=O_f-score_tok: 0.9516189877397045
train_label=N_precision_tok: 0.8358088472715531
train_label=N_recall_tok: 0.7290522461625123
train_label=N_f-score_tok: 0.7787890184279804
train_label=P_precision_tok: 0.8929436920883821
train_label=P_recall_tok: 0.7511692049406403
train_label=P_f-score_tok: 0.8159437280187574
train_precision_macro_tok: 0.8864053294309833
train_recall_macro_tok: 0.8179934558944559
train_f-score_macro_tok: 0.8487839113954808
train_precision_micro_tok: 0.9184671631023562
train_recall_micro_tok: 0.9184671631023562
train_f-score_micro_tok: 0.9184671631023562
train_time: 197.19068455696106
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4351    0.1238    0.1927      1624
           N     0.6884    0.8263    0.7511      3310
           P     0.7376    0.8396    0.7853      3610

   micro avg     0.6984    0.6984    0.6984      8544
   macro avg     0.6204    0.5966    0.5764      8544
weighted avg     0.6611    0.6984    0.6594      8544

F1-macro sent:  0.576370778936048
F1-micro sent:  0.6983848314606742
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9305    0.9738    0.9516    124347
           N     0.8358    0.7291    0.7788     14202
           P     0.8929    0.7512    0.8159     25017

   micro avg     0.9185    0.9185    0.9185    163566
   macro avg     0.8864    0.8180    0.8488    163566
weighted avg     0.9165    0.9185    0.9159    163566

F1-macro tok:  0.8487839113954808
F1-micro tok:  0.9184671631023562
**************************************************
dev_cost_sum: 41972.943115234375
dev_cost_avg: 38.122564137360925
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19221.0
dev_accuracy_tok: 0.9034972266616528
dev_label=O_precision_sent: 0.4107142857142857
dev_label=O_recall_sent: 0.10043668122270742
dev_label=O_f-score_sent: 0.16140350877192983
dev_label=N_precision_sent: 0.7084233261339092
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7362514029180695
dev_label=P_precision_sent: 0.6597938144329897
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.7485380116959065
dev_precision_macro_sent: 0.5929771420937282
dev_recall_macro_sent: 0.5772188954248294
dev_f-score_macro_sent: 0.5487309744619685
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9114237933221844
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.94228820127586
dev_label=N_precision_tok: 0.8075342465753425
dev_label=N_recall_tok: 0.6348949919224556
dev_label=N_f-score_tok: 0.7108833283087126
dev_label=P_precision_tok: 0.9045693489688638
dev_label=P_recall_tok: 0.6964508094645081
dev_label=P_f-score_tok: 0.7869832893579596
dev_precision_macro_tok: 0.8745091296221302
dev_recall_macro_tok: 0.7688873539334722
dev_f-score_macro_tok: 0.8133849396475107
dev_precision_micro_tok: 0.9034972266616528
dev_recall_micro_tok: 0.9034972266616528
dev_f-score_micro_tok: 0.9034972266616528
dev_time: 11.72816777229309
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4107    0.1004    0.1614       229
           N     0.7084    0.7664    0.7363       428
           P     0.6598    0.8649    0.7485       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.5930    0.5772    0.5487      1101
weighted avg     0.6269    0.6676    0.6216      1101

F1-macro sent:  0.5487309744619685
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9753    0.9423     16205
           N     0.8075    0.6349    0.7109      1857
           P     0.9046    0.6965    0.7870      3212

   micro avg     0.9035    0.9035    0.9035     21274
   macro avg     0.8745    0.7689    0.8134     21274
weighted avg     0.9013    0.9035    0.8986     21274

F1-macro tok:  0.8133849396475107
F1-micro tok:  0.9034972266616528
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.810000
train_cost_sum: 290426.939453125
train_cost_avg: 33.991917070824556
train_count_sent: 8544.0
train_total_correct_sent: 6023.0
train_accuracy_sent: 0.704939138576779
train_count_tok: 163566.0
train_total_correct_tok: 150539.0
train_accuracy_tok: 0.920356308768326
train_label=O_precision_sent: 0.44370860927152317
train_label=O_recall_sent: 0.08251231527093596
train_label=O_f-score_sent: 0.13914849428868117
train_label=N_precision_sent: 0.6851941747572815
train_label=N_recall_sent: 0.8528700906344411
train_label=N_f-score_sent: 0.7598923283983848
train_label=P_precision_sent: 0.7438136826783115
train_label=P_recall_sent: 0.8493074792243768
train_label=P_f-score_sent: 0.7930677703052251
train_precision_macro_sent: 0.6242388222357054
train_recall_macro_sent: 0.5948966283765845
train_f-score_macro_sent: 0.564036197664097
train_precision_micro_sent: 0.704939138576779
train_recall_micro_sent: 0.704939138576779
train_f-score_micro_sent: 0.704939138576779
train_label=O_precision_tok: 0.9332767991365686
train_label=O_recall_tok: 0.9735659083049852
train_label=O_f-score_tok: 0.9529957254528422
train_label=N_precision_tok: 0.8359368741488424
train_label=N_recall_tok: 0.7347556682157442
train_label=N_f-score_tok: 0.7820873149709574
train_label=P_precision_tok: 0.8912392362411082
train_label=P_recall_tok: 0.7612423551984651
train_label=P_f-score_tok: 0.8211275196723079
train_precision_macro_tok: 0.8868176365088397
train_recall_macro_tok: 0.8231879772397316
train_f-score_macro_tok: 0.8520701866987025
train_precision_micro_tok: 0.920356308768326
train_recall_micro_tok: 0.920356308768326
train_f-score_micro_tok: 0.920356308768326
train_time: 197.46372318267822
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4437    0.0825    0.1391      1624
           N     0.6852    0.8529    0.7599      3310
           P     0.7438    0.8493    0.7931      3610

   micro avg     0.7049    0.7049    0.7049      8544
   macro avg     0.6242    0.5949    0.5640      8544
weighted avg     0.6641    0.7049    0.6559      8544

F1-macro sent:  0.564036197664097
F1-micro sent:  0.704939138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9333    0.9736    0.9530    124347
           N     0.8359    0.7348    0.7821     14202
           P     0.8912    0.7612    0.8211     25017

   micro avg     0.9204    0.9204    0.9204    163566
   macro avg     0.8868    0.8232    0.8521    163566
weighted avg     0.9184    0.9204    0.9180    163566

F1-macro tok:  0.8520701866987025
F1-micro tok:  0.920356308768326
**************************************************
dev_cost_sum: 41902.994384765625
dev_cost_avg: 38.059032138751704
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19121.0
dev_accuracy_tok: 0.8987966531916893
dev_label=O_precision_sent: 0.6060606060606061
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.15267175572519084
dev_label=N_precision_sent: 0.6563636363636364
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.738241308793456
dev_label=P_precision_sent: 0.7046332046332047
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7588357588357589
dev_precision_macro_sent: 0.6556858156858157
dev_recall_macro_sent: 0.5842887535129302
dev_f-score_macro_sent: 0.5499162744514686
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9179324149299423
dev_label=O_recall_tok: 0.9621721690836161
dev_label=O_f-score_tok: 0.9395318007893705
dev_label=N_precision_tok: 0.7743785850860421
dev_label=N_recall_tok: 0.654281098546042
dev_label=N_f-score_tok: 0.7092819614711033
dev_label=P_precision_tok: 0.8510481794777491
dev_label=P_recall_tok: 0.7204234122042341
dev_label=P_f-score_tok: 0.7803068622491992
dev_precision_macro_tok: 0.8477863931645778
dev_recall_macro_tok: 0.7789588932779642
dev_f-score_macro_tok: 0.8097068748365577
dev_precision_micro_tok: 0.8987966531916893
dev_recall_micro_tok: 0.8987966531916893
dev_f-score_micro_tok: 0.8987966531916893
dev_time: 11.825384378433228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6061    0.0873    0.1527       229
           N     0.6564    0.8435    0.7382       428
           P     0.7046    0.8221    0.7588       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6557    0.5843    0.5499      1101
weighted avg     0.6654    0.6776    0.6248      1101

F1-macro sent:  0.5499162744514686
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9179    0.9622    0.9395     16205
           N     0.7744    0.6543    0.7093      1857
           P     0.8510    0.7204    0.7803      3212

   micro avg     0.8988    0.8988    0.8988     21274
   macro avg     0.8478    0.7790    0.8097     21274
weighted avg     0.8953    0.8988    0.8954     21274

F1-macro tok:  0.8097068748365577
F1-micro tok:  0.8987966531916893
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.729000
train_cost_sum: 289208.5563964844
train_cost_avg: 33.84931605764096
train_count_sent: 8544.0
train_total_correct_sent: 5972.0
train_accuracy_sent: 0.6989700374531835
train_count_tok: 163566.0
train_total_correct_tok: 150792.0
train_accuracy_tok: 0.9219030849932137
train_label=O_precision_sent: 0.42790697674418604
train_label=O_recall_sent: 0.11330049261083744
train_label=O_f-score_sent: 0.17916260954235635
train_label=N_precision_sent: 0.6857998502620414
train_label=N_recall_sent: 0.8302114803625378
train_label=N_f-score_sent: 0.7511275112751128
train_label=P_precision_sent: 0.740199659118578
train_label=P_recall_sent: 0.8421052631578947
train_label=P_f-score_sent: 0.787870934300894
train_precision_macro_sent: 0.6179688287082684
train_recall_macro_sent: 0.5952057453770899
train_f-score_macro_sent: 0.5727203517061211
train_precision_micro_sent: 0.6989700374531835
train_recall_micro_sent: 0.6989700374531835
train_f-score_micro_sent: 0.6989700374531835
train_label=O_precision_tok: 0.9349995365936544
train_label=O_recall_tok: 0.9735659083049852
train_label=O_f-score_tok: 0.953893067216131
train_label=N_precision_tok: 0.837089350896683
train_label=N_recall_tok: 0.7427827066610336
train_label=N_f-score_tok: 0.7871213251753468
train_label=P_precision_tok: 0.8927308265078183
train_label=P_recall_tok: 0.766798576967662
train_label=P_f-score_tok: 0.8249865605848834
train_precision_macro_tok: 0.8882732379993853
train_recall_macro_tok: 0.8277157306445604
train_f-score_macro_tok: 0.8553336509921204
train_precision_micro_tok: 0.9219030849932137
train_recall_micro_tok: 0.9219030849932137
train_f-score_micro_tok: 0.9219030849932137
train_time: 197.3637011051178
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4279    0.1133    0.1792      1624
           N     0.6858    0.8302    0.7511      3310
           P     0.7402    0.8421    0.7879      3610

   micro avg     0.6990    0.6990    0.6990      8544
   macro avg     0.6180    0.5952    0.5727      8544
weighted avg     0.6598    0.6990    0.6579      8544

F1-macro sent:  0.5727203517061211
F1-micro sent:  0.6989700374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9350    0.9736    0.9539    124347
           N     0.8371    0.7428    0.7871     14202
           P     0.8927    0.7668    0.8250     25017

   micro avg     0.9219    0.9219    0.9219    163566
   macro avg     0.8883    0.8277    0.8553    163566
weighted avg     0.9200    0.9219    0.9197    163566

F1-macro tok:  0.8553336509921204
F1-micro tok:  0.9219030849932137
**************************************************
dev_cost_sum: 41957.45861816406
dev_cost_avg: 38.10850010732431
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19191.0
dev_accuracy_tok: 0.9020870546206637
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.694331983805668
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7440347071583514
dev_label=P_precision_sent: 0.6570458404074703
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.749273959341723
dev_precision_macro_sent: 0.6541629784414166
dev_recall_macro_sent: 0.5736861417594389
dev_f-score_macro_sent: 0.5274591641370018
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9155791190864601
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.9418921753723516
dev_label=N_precision_tok: 0.7877984084880637
dev_label=N_recall_tok: 0.6397415185783522
dev_label=N_f-score_tok: 0.7060921248142643
dev_label=P_precision_tok: 0.8793235972328978
dev_label=P_recall_tok: 0.7123287671232876
dev_label=P_f-score_tok: 0.7870657034743722
dev_precision_macro_tok: 0.8609003749358072
dev_recall_macro_tok: 0.7739442349027064
dev_f-score_macro_tok: 0.8116833345536628
dev_precision_micro_tok: 0.9020870546206637
dev_recall_micro_tok: 0.9020870546206637
dev_f-score_micro_tok: 0.9020870546206639
dev_time: 11.99156928062439
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.6943    0.8014    0.7440       428
           P     0.6570    0.8716    0.7493       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6542    0.5737    0.5275      1101
weighted avg     0.6620    0.6730    0.6099      1101

F1-macro sent:  0.5274591641370018
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9156    0.9698    0.9419     16205
           N     0.7878    0.6397    0.7061      1857
           P     0.8793    0.7123    0.7871      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8609    0.7739    0.8117     21274
weighted avg     0.8990    0.9021    0.8979     21274

F1-macro tok:  0.8116833345536628
F1-micro tok:  0.9020870546206639
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42038.99432373047
test0_cost_avg: 38.18255615234375
test0_count_sent: 1101.0
test0_total_correct_sent: 738.0
test0_accuracy_sent: 0.670299727520436
test0_count_tok: 21274.0
test0_total_correct_tok: 19236.0
test0_accuracy_tok: 0.9042023126821472
test0_label=O_precision_sent: 0.38571428571428573
test0_label=O_recall_sent: 0.11790393013100436
test0_label=O_f-score_sent: 0.1806020066889632
test0_label=N_precision_sent: 0.684931506849315
test0_label=N_recall_sent: 0.8177570093457944
test0_label=N_f-score_sent: 0.7454739084132055
test0_label=P_precision_sent: 0.6942307692307692
test0_label=P_recall_sent: 0.8130630630630631
test0_label=P_f-score_sent: 0.7489626556016598
test0_precision_macro_sent: 0.58829218726479
test0_recall_macro_sent: 0.5829080008466206
test0_f-score_macro_sent: 0.5583461902346095
test0_precision_micro_sent: 0.670299727520436
test0_recall_micro_sent: 0.670299727520436
test0_f-score_micro_sent: 0.670299727520436
test0_label=O_precision_tok: 0.907579825212772
test0_label=O_recall_tok: 0.9804998457266276
test0_label=O_f-score_tok: 0.9426317038443285
test0_label=N_precision_tok: 0.8229390681003584
test0_label=N_recall_tok: 0.6182014001077006
test0_label=N_f-score_tok: 0.7060270602706027
test0_label=P_precision_tok: 0.9270657672849916
test0_label=P_recall_tok: 0.6846201743462017
test0_label=P_f-score_tok: 0.7876074498567335
test0_precision_macro_tok: 0.8858615535327073
test0_recall_macro_tok: 0.7611071400601767
test0_f-score_macro_tok: 0.8120887379905549
test0_precision_micro_tok: 0.9042023126821472
test0_recall_micro_tok: 0.9042023126821472
test0_f-score_micro_tok: 0.9042023126821472
test0_time: 11.954869508743286
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3857    0.1179    0.1806       229
           N     0.6849    0.8178    0.7455       428
           P     0.6942    0.8131    0.7490       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.5883    0.5829    0.5583      1101
weighted avg     0.6264    0.6703    0.6294      1101

F1-macro sent:  0.5583461902346095
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9076    0.9805    0.9426     16205
           N     0.8229    0.6182    0.7060      1857
           P     0.9271    0.6846    0.7876      3212

   micro avg     0.9042    0.9042    0.9042     21274
   macro avg     0.8859    0.7611    0.8121     21274
weighted avg     0.9031    0.9042    0.8986     21274

F1-macro tok:  0.8120887379905549
F1-micro tok:  0.9042023126821472
**************************************************
test1_cost_sum: 81236.42724609375
test1_cost_avg: 36.7585643647483
test1_count_sent: 2210.0
test1_total_correct_sent: 1512.0
test1_accuracy_sent: 0.6841628959276018
test1_count_tok: 42405.0
test1_total_correct_tok: 37982.0
test1_accuracy_tok: 0.8956962622332272
test1_label=O_precision_sent: 0.2980132450331126
test1_label=O_recall_sent: 0.11568123393316196
test1_label=O_f-score_sent: 0.1666666666666667
test1_label=N_precision_sent: 0.6991321118611379
test1_label=N_recall_sent: 0.7949561403508771
test1_label=N_f-score_sent: 0.7439712673165726
test1_label=P_precision_sent: 0.726027397260274
test1_label=P_recall_sent: 0.8162816281628162
test1_label=P_f-score_sent: 0.7685137234593475
test1_precision_macro_sent: 0.5743909180515082
test1_recall_macro_sent: 0.5756396674822851
test1_f-score_macro_sent: 0.5597172191475289
test1_precision_micro_sent: 0.6841628959276018
test1_recall_micro_sent: 0.6841628959276018
test1_f-score_micro_sent: 0.6841628959276018
test1_label=O_precision_tok: 0.8980882605460477
test1_label=O_recall_tok: 0.9807175448465529
test1_label=O_f-score_tok: 0.9375858978189423
test1_label=N_precision_tok: 0.8170818505338078
test1_label=N_recall_tok: 0.6106382978723405
test1_label=N_f-score_tok: 0.6989345509893455
test1_label=P_precision_tok: 0.9252095422308189
test1_label=P_recall_tok: 0.6476605987663607
test1_label=P_f-score_tok: 0.7619469026548672
test1_precision_macro_tok: 0.8801265511035581
test1_recall_macro_tok: 0.746338813828418
test1_f-score_macro_tok: 0.7994891171543851
test1_precision_micro_tok: 0.8956962622332272
test1_recall_micro_tok: 0.8956962622332272
test1_f-score_micro_tok: 0.8956962622332272
test1_time: 23.929729461669922
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2980    0.1157    0.1667       389
           N     0.6991    0.7950    0.7440       912
           P     0.7260    0.8163    0.7685       909

   micro avg     0.6842    0.6842    0.6842      2210
   macro avg     0.5744    0.5756    0.5597      2210
weighted avg     0.6396    0.6842    0.6524      2210

F1-macro sent:  0.5597172191475289
F1-micro sent:  0.6841628959276018
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8981    0.9807    0.9376     31998
           N     0.8171    0.6106    0.6989      3760
           P     0.9252    0.6477    0.7619      6647

   micro avg     0.8957    0.8957    0.8957     42405
   macro avg     0.8801    0.7463    0.7995     42405
weighted avg     0.8952    0.8957    0.8889     42405

F1-macro tok:  0.7994891171543851
F1-micro tok:  0.8956962622332272
**************************************************
