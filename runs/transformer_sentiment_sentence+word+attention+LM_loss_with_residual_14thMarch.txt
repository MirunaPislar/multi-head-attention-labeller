default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.1
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'O': 0, 'P': 2}
{'N': 1, 'O': 0, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 21:21:50.808887: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 21:21:50.898723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 9.98GiB
2019-03-14 21:21:50.898767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 21:21:51.282934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 21:21:51.282986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 21:21:51.283001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 21:21:51.283239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033759.
Parameter count without word embeddings: 3233259.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 432460.4415283203
train_cost_avg: 50.61568838112363
train_count_sent: 8544.0
train_total_correct_sent: 3651.0
train_accuracy_sent: 0.4273174157303371
train_count_tok: 163566.0
train_total_correct_tok: 125285.0
train_accuracy_tok: 0.7659599183204333
train_label=O_precision_sent: 0.16412213740458015
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.04559915164369034
train_label=N_precision_sent: 0.4153605015673981
train_label=N_recall_sent: 0.48036253776435045
train_label=N_f-score_sent: 0.4455029420005604
train_label=P_precision_sent: 0.4530758868432869
train_label=P_recall_sent: 0.5590027700831025
train_label=P_f-score_sent: 0.5004960317460316
train_precision_macro_sent: 0.34418617527175505
train_recall_macro_sent: 0.35528104678658945
train_f-score_macro_sent: 0.33053270846342747
train_precision_micro_sent: 0.4273174157303371
train_recall_micro_sent: 0.4273174157303371
train_f-score_micro_sent: 0.4273174157303371
train_label=O_precision_tok: 0.792293384005995
train_label=O_recall_tok: 0.9522787039494318
train_label=O_f-score_tok: 0.8649503475126278
train_label=N_precision_tok: 0.47059965068891907
train_label=N_recall_tok: 0.1707505985072525
train_label=N_f-score_tok: 0.2505812451562904
train_label=P_precision_tok: 0.49648319749916264
train_label=P_recall_tok: 0.17775912379581885
train_label=P_f-score_tok: 0.2617884264437511
train_precision_macro_tok: 0.5864587440646922
train_recall_macro_tok: 0.4335961420841678
train_f-score_macro_tok: 0.4591066730375564
train_precision_micro_tok: 0.7659599183204333
train_recall_micro_tok: 0.7659599183204333
train_f-score_micro_tok: 0.7659599183204333
train_time: 99.25392365455627
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1641    0.0265    0.0456      1624
           N     0.4154    0.4804    0.4455      3310
           P     0.4531    0.5590    0.5005      3610

   micro avg     0.4273    0.4273    0.4273      8544
   macro avg     0.3442    0.3553    0.3305      8544
weighted avg     0.3835    0.4273    0.3927      8544

F1-macro sent:  0.33053270846342747
F1-micro sent:  0.4273174157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7923    0.9523    0.8650    124347
           N     0.4706    0.1708    0.2506     14202
           P     0.4965    0.1778    0.2618     25017

   micro avg     0.7660    0.7660    0.7660    163566
   macro avg     0.5865    0.4336    0.4591    163566
weighted avg     0.7191    0.7660    0.7194    163566

F1-macro tok:  0.4591066730375564
F1-micro tok:  0.7659599183204333
**************************************************
dev_cost_sum: 51495.19812011719
dev_cost_avg: 46.77129711182306
dev_count_sent: 1101.0
dev_total_correct_sent: 539.0
dev_accuracy_sent: 0.4895549500454133
dev_count_tok: 21274.0
dev_total_correct_tok: 17374.0
dev_accuracy_tok: 0.81667763467143
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4834307992202729
dev_label=N_recall_sent: 0.5794392523364486
dev_label=N_f-score_sent: 0.5270988310308183
dev_label=P_precision_sent: 0.49489795918367346
dev_label=P_recall_sent: 0.6554054054054054
dev_label=P_f-score_sent: 0.563953488372093
dev_precision_macro_sent: 0.3261095861346488
dev_recall_macro_sent: 0.4116148859139513
dev_f-score_macro_sent: 0.3636841064676371
dev_precision_micro_sent: 0.4895549500454133
dev_recall_micro_sent: 0.4895549500454133
dev_f-score_micro_sent: 0.4895549500454133
dev_label=O_precision_tok: 0.8439677098308084
dev_label=O_recall_tok: 0.9419315026226474
dev_label=O_f-score_tok: 0.8902627511591963
dev_label=N_precision_tok: 0.6197916666666666
dev_label=N_recall_tok: 0.44857296715131934
dev_label=N_f-score_tok: 0.5204623555139019
dev_label=P_precision_tok: 0.6925162689804772
dev_label=P_recall_tok: 0.39757160647571604
dev_label=P_f-score_tok: 0.5051424050632911
dev_precision_macro_tok: 0.7187585484926508
dev_recall_macro_tok: 0.5960253587498943
dev_f-score_macro_tok: 0.6386225039121297
dev_precision_micro_tok: 0.81667763467143
dev_recall_micro_tok: 0.81667763467143
dev_f-score_micro_tok: 0.81667763467143
dev_time: 5.5337817668914795
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4834    0.5794    0.5271       428
           P     0.4949    0.6554    0.5640       444

   micro avg     0.4896    0.4896    0.4896      1101
   macro avg     0.3261    0.4116    0.3637      1101
weighted avg     0.3875    0.4896    0.4323      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.3636841064676371
F1-micro sent:  0.4895549500454133
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8440    0.9419    0.8903     16205
           N     0.6198    0.4486    0.5205      1857
           P     0.6925    0.3976    0.5051      3212

   micro avg     0.8167    0.8167    0.8167     21274
   macro avg     0.7188    0.5960    0.6386     21274
weighted avg     0.8015    0.8167    0.7998     21274

F1-macro tok:  0.6386225039121297
F1-micro tok:  0.81667763467143
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 383337.73486328125
train_cost_avg: 44.86630791939153
train_count_sent: 8544.0
train_total_correct_sent: 4107.0
train_accuracy_sent: 0.480688202247191
train_count_tok: 163566.0
train_total_correct_tok: 131504.0
train_accuracy_tok: 0.8039812675005809
train_label=O_precision_sent: 0.21978021978021978
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.023323615160349854
train_label=N_precision_sent: 0.4759571209800919
train_label=N_recall_sent: 0.46948640483383686
train_label=N_f-score_sent: 0.47269961977186314
train_label=P_precision_sent: 0.4882420971472629
train_label=P_recall_sent: 0.7016620498614958
train_label=P_f-score_sent: 0.5758126847010684
train_precision_macro_sent: 0.3946598126358582
train_recall_macro_sent: 0.3944879085437644
train_f-score_macro_sent: 0.3572786398777605
train_precision_micro_sent: 0.480688202247191
train_recall_micro_sent: 0.480688202247191
train_f-score_micro_sent: 0.480688202247191
train_label=O_precision_tok: 0.8272845696996862
train_label=O_recall_tok: 0.9499465206237384
train_label=O_f-score_tok: 0.8843825688519864
train_label=N_precision_tok: 0.6232425034216748
train_label=N_recall_tok: 0.3526968032671455
train_label=N_f-score_tok: 0.450469895229102
train_label=P_precision_tok: 0.6568850529619459
train_label=P_recall_tok: 0.33465243634328656
train_label=P_f-score_tok: 0.4434087177585933
train_precision_macro_tok: 0.7024707086944356
train_recall_macro_tok: 0.5457652534113901
train_f-score_macro_tok: 0.5927537272798938
train_precision_micro_tok: 0.8039812675005809
train_recall_micro_tok: 0.8039812675005809
train_f-score_micro_tok: 0.803981267500581
train_time: 98.08274459838867
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2198    0.0123    0.0233      1624
           N     0.4760    0.4695    0.4727      3310
           P     0.4882    0.7017    0.5758      3610

   micro avg     0.4807    0.4807    0.4807      8544
   macro avg     0.3947    0.3945    0.3573      8544
weighted avg     0.4325    0.4807    0.4309      8544

F1-macro sent:  0.3572786398777605
F1-micro sent:  0.480688202247191
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8273    0.9499    0.8844    124347
           N     0.6232    0.3527    0.4505     14202
           P     0.6569    0.3347    0.4434     25017

   micro avg     0.8040    0.8040    0.8040    163566
   macro avg     0.7025    0.5458    0.5928    163566
weighted avg     0.7835    0.8040    0.7793    163566

F1-macro tok:  0.5927537272798938
F1-micro tok:  0.803981267500581
**************************************************
dev_cost_sum: 49793.08215332031
dev_cost_avg: 45.2253243899367
dev_count_sent: 1101.0
dev_total_correct_sent: 473.0
dev_accuracy_sent: 0.4296094459582198
dev_count_tok: 21274.0
dev_total_correct_tok: 17652.0
dev_accuracy_tok: 0.829745228917928
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.405893536121673
dev_label=N_recall_sent: 0.9976635514018691
dev_label=N_f-score_sent: 0.577027027027027
dev_label=P_precision_sent: 0.9387755102040817
dev_label=P_recall_sent: 0.1036036036036036
dev_label=P_f-score_sent: 0.18661257606490875
dev_precision_macro_sent: 0.4482230154419182
dev_recall_macro_sent: 0.3670890516684909
dev_f-score_macro_sent: 0.2545465343639786
dev_precision_micro_sent: 0.4296094459582198
dev_recall_micro_sent: 0.4296094459582198
dev_f-score_micro_sent: 0.4296094459582198
dev_label=O_precision_tok: 0.8345042522846126
dev_label=O_recall_tok: 0.9748842949706881
dev_label=O_f-score_tok: 0.8992486338797814
dev_label=N_precision_tok: 0.7523124357656732
dev_label=N_recall_tok: 0.39418416801292405
dev_label=N_f-score_tok: 0.5173144876325088
dev_label=P_precision_tok: 0.8189781021897811
dev_label=P_recall_tok: 0.3493150684931507
dev_label=P_f-score_tok: 0.48974247053688347
dev_precision_macro_tok: 0.801931596746689
dev_recall_macro_tok: 0.5727945104922543
dev_f-score_macro_tok: 0.6354351973497244
dev_precision_micro_tok: 0.829745228917928
dev_recall_micro_tok: 0.829745228917928
dev_f-score_micro_tok: 0.829745228917928
dev_time: 5.11957311630249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4059    0.9977    0.5770       428
           P     0.9388    0.1036    0.1866       444

   micro avg     0.4296    0.4296    0.4296      1101
   macro avg     0.4482    0.3671    0.2545      1101
weighted avg     0.5364    0.4296    0.2996      1101

F1-macro sent:  0.2545465343639786
F1-micro sent:  0.4296094459582198
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8345    0.9749    0.8992     16205
           N     0.7523    0.3942    0.5173      1857
           P     0.8190    0.3493    0.4897      3212

   micro avg     0.8297    0.8297    0.8297     21274
   macro avg     0.8019    0.5728    0.6354     21274
weighted avg     0.8250    0.8297    0.8041     21274

F1-macro tok:  0.6354351973497244
F1-micro tok:  0.829745228917928
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 373191.583984375
train_cost_avg: 43.67879026034352
train_count_sent: 8544.0
train_total_correct_sent: 4661.0
train_accuracy_sent: 0.5455290262172284
train_count_tok: 163566.0
train_total_correct_tok: 134654.0
train_accuracy_tok: 0.823239548561437
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.00847457627118644
train_label=N_precision_sent: 0.5243324182680309
train_label=N_recall_sent: 0.6347432024169184
train_label=N_f-score_sent: 0.5742790761240946
train_label=P_precision_sent: 0.5662009314703925
train_label=P_recall_sent: 0.707202216066482
train_label=P_f-score_sent: 0.6288951841359773
train_precision_macro_sent: 0.44684444991280775
train_recall_macro_sent: 0.4487519211036622
train_f-score_macro_sent: 0.4038829455104194
train_precision_micro_sent: 0.5455290262172284
train_recall_micro_sent: 0.5455290262172284
train_f-score_micro_sent: 0.5455290262172284
train_label=O_precision_tok: 0.8452423467565676
train_label=O_recall_tok: 0.9516835951008066
train_label=O_f-score_tok: 0.895310437180588
train_label=N_precision_tok: 0.6650586558491394
train_label=N_recall_tok: 0.42712294043092525
train_label=N_f-score_tok: 0.5201732195686661
train_label=P_precision_tok: 0.7098136990096267
train_label=P_recall_tok: 0.40968141663668706
train_label=P_f-score_tok: 0.5195154095701541
train_precision_macro_tok: 0.7400382338717778
train_recall_macro_tok: 0.5961626507228063
train_f-score_macro_tok: 0.6449996887731361
train_precision_micro_tok: 0.823239548561437
train_recall_micro_tok: 0.823239548561437
train_f-score_micro_tok: 0.823239548561437
train_time: 98.23954486846924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0043    0.0085      1624
           N     0.5243    0.6347    0.5743      3310
           P     0.5662    0.7072    0.6289      3610

   micro avg     0.5455    0.5455    0.5455      8544
   macro avg     0.4468    0.4488    0.4039      8544
weighted avg     0.4899    0.5455    0.4898      8544

F1-macro sent:  0.4038829455104194
F1-micro sent:  0.5455290262172284
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8452    0.9517    0.8953    124347
           N     0.6651    0.4271    0.5202     14202
           P     0.7098    0.4097    0.5195     25017

   micro avg     0.8232    0.8232    0.8232    163566
   macro avg     0.7400    0.5962    0.6450    163566
weighted avg     0.8089    0.8232    0.8053    163566

F1-macro tok:  0.6449996887731361
F1-micro tok:  0.823239548561437
**************************************************
dev_cost_sum: 48702.753173828125
dev_cost_avg: 44.23501650665588
dev_count_sent: 1101.0
dev_total_correct_sent: 585.0
dev_accuracy_sent: 0.5313351498637602
dev_count_tok: 21274.0
dev_total_correct_tok: 18175.0
dev_accuracy_tok: 0.8543292281658362
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.4606986899563319
dev_label=N_recall_sent: 0.985981308411215
dev_label=N_f-score_sent: 0.6279761904761905
dev_label=P_precision_sent: 0.8852459016393442
dev_label=P_recall_sent: 0.36486486486486486
dev_label=P_f-score_sent: 0.5167464114832536
dev_precision_macro_sent: 0.6153148638652254
dev_recall_macro_sent: 0.4517376618343847
dev_f-score_macro_sent: 0.38446020353915095
dev_precision_micro_sent: 0.5313351498637602
dev_recall_micro_sent: 0.5313351498637602
dev_f-score_micro_sent: 0.5313351498637602
dev_label=O_precision_tok: 0.8640648255333223
dev_label=O_recall_tok: 0.9672940450478248
dev_label=O_f-score_tok: 0.9127700460024458
dev_label=N_precision_tok: 0.7492984097287184
dev_label=N_recall_tok: 0.43134087237479807
dev_label=N_f-score_tok: 0.5475051264524948
dev_label=P_precision_tok: 0.8231589147286822
dev_label=P_recall_tok: 0.5289539227895392
dev_label=P_f-score_tok: 0.6440485216072782
dev_precision_macro_tok: 0.8121740499969077
dev_recall_macro_tok: 0.642529613404054
dev_f-score_macro_tok: 0.7014412313540731
dev_precision_micro_tok: 0.8543292281658362
dev_recall_micro_tok: 0.8543292281658362
dev_f-score_micro_tok: 0.8543292281658362
dev_time: 5.015812873840332
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.4607    0.9860    0.6280       428
           P     0.8852    0.3649    0.5167       444

   micro avg     0.5313    0.5313    0.5313      1101
   macro avg     0.6153    0.4517    0.3845      1101
weighted avg     0.6401    0.5313    0.4543      1101

F1-macro sent:  0.38446020353915095
F1-micro sent:  0.5313351498637602
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8641    0.9673    0.9128     16205
           N     0.7493    0.4313    0.5475      1857
           P     0.8232    0.5290    0.6440      3212

   micro avg     0.8543    0.8543    0.8543     21274
   macro avg     0.8122    0.6425    0.7014     21274
weighted avg     0.8479    0.8543    0.8403     21274

F1-macro tok:  0.7014412313540731
F1-micro tok:  0.8543292281658362
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 366234.54553222656
train_cost_avg: 42.86453014188045
train_count_sent: 8544.0
train_total_correct_sent: 4940.0
train_accuracy_sent: 0.5781835205992509
train_count_tok: 163566.0
train_total_correct_tok: 136951.0
train_accuracy_tok: 0.8372828093858137
train_label=O_precision_sent: 0.3939393939393939
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015691007845503924
train_label=N_precision_sent: 0.55209324452902
train_label=N_recall_sent: 0.7012084592145015
train_label=N_f-score_sent: 0.6177801437317008
train_label=P_precision_sent: 0.6050615277455306
train_label=P_recall_sent: 0.7218836565096953
train_label=P_f-score_sent: 0.6583301755715548
train_precision_macro_sent: 0.5170313887379815
train_recall_macro_sent: 0.4770323472775237
train_f-score_macro_sent: 0.4306004423829199
train_precision_micro_sent: 0.5781835205992509
train_recall_micro_sent: 0.5781835205992509
train_f-score_micro_sent: 0.5781835205992509
train_label=O_precision_tok: 0.8572161188035855
train_label=O_recall_tok: 0.9544178789998955
train_label=O_f-score_tok: 0.9032093579001044
train_label=N_precision_tok: 0.6890158456397543
train_label=N_recall_tok: 0.45007745387973525
train_label=N_f-score_tok: 0.5444865624600708
train_label=P_precision_tok: 0.7499053149854816
train_label=P_recall_tok: 0.47487708358316344
train_label=P_f-score_tok: 0.5815120291734991
train_precision_macro_tok: 0.7653790931429404
train_recall_macro_tok: 0.6264574721542647
train_f-score_macro_tok: 0.6764026498445581
train_precision_micro_tok: 0.8372828093858137
train_recall_micro_tok: 0.8372828093858137
train_f-score_micro_tok: 0.8372828093858138
train_time: 98.89352130889893
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3939    0.0080    0.0157      1624
           N     0.5521    0.7012    0.6178      3310
           P     0.6051    0.7219    0.6583      3610

   micro avg     0.5782    0.5782    0.5782      8544
   macro avg     0.5170    0.4770    0.4306      8544
weighted avg     0.5444    0.5782    0.5205      8544

F1-macro sent:  0.4306004423829199
F1-micro sent:  0.5781835205992509
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8572    0.9544    0.9032    124347
           N     0.6890    0.4501    0.5445     14202
           P     0.7499    0.4749    0.5815     25017

   micro avg     0.8373    0.8373    0.8373    163566
   macro avg     0.7654    0.6265    0.6764    163566
weighted avg     0.8262    0.8373    0.8229    163566

F1-macro tok:  0.6764026498445581
F1-micro tok:  0.8372828093858138
**************************************************
dev_cost_sum: 47887.06457519531
dev_cost_avg: 43.49415492751618
dev_count_sent: 1101.0
dev_total_correct_sent: 680.0
dev_accuracy_sent: 0.6176203451407811
dev_count_tok: 21274.0
dev_total_correct_tok: 18356.0
dev_accuracy_tok: 0.8628372661464698
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6187739463601533
dev_label=N_recall_sent: 0.7546728971962616
dev_label=N_f-score_sent: 0.6799999999999999
dev_label=P_precision_sent: 0.616580310880829
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.6979472140762464
dev_precision_macro_sent: 0.4117847524136608
dev_recall_macro_sent: 0.5195756504167719
dev_f-score_macro_sent: 0.4593157380254154
dev_precision_micro_sent: 0.6176203451407811
dev_recall_micro_sent: 0.6176203451407811
dev_f-score_micro_sent: 0.6176203451407811
dev_label=O_precision_tok: 0.8740302505999888
dev_label=O_recall_tok: 0.9663684048133292
dev_label=O_f-score_tok: 0.9178828908035871
dev_label=N_precision_tok: 0.7837582625118036
dev_label=N_recall_tok: 0.44695745826602046
dev_label=N_f-score_tok: 0.5692729766803841
dev_label=P_precision_tok: 0.8120104438642297
dev_label=P_recall_tok: 0.5809464508094645
dev_label=P_f-score_tok: 0.6773139745916515
dev_precision_macro_tok: 0.8232663189920073
dev_recall_macro_tok: 0.6647574379629381
dev_f-score_macro_tok: 0.721489947358541
dev_precision_micro_tok: 0.8628372661464698
dev_recall_micro_tok: 0.8628372661464698
dev_f-score_micro_tok: 0.8628372661464699
dev_time: 5.204644203186035
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6188    0.7547    0.6800       428
           P     0.6166    0.8041    0.6979       444

   micro avg     0.6176    0.6176    0.6176      1101
   macro avg     0.4118    0.5196    0.4593      1101
weighted avg     0.4892    0.6176    0.5458      1101

F1-macro sent:  0.4593157380254154
F1-micro sent:  0.6176203451407811
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8740    0.9664    0.9179     16205
           N     0.7838    0.4470    0.5693      1857
           P     0.8120    0.5809    0.6773      3212

   micro avg     0.8628    0.8628    0.8628     21274
   macro avg     0.8233    0.6648    0.7215     21274
weighted avg     0.8568    0.8628    0.8511     21274

F1-macro tok:  0.721489947358541
F1-micro tok:  0.8628372661464699
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 360265.1555175781
train_cost_avg: 42.16586558024088
train_count_sent: 8544.0
train_total_correct_sent: 4897.0
train_accuracy_sent: 0.5731507490636704
train_count_tok: 163566.0
train_total_correct_tok: 138626.0
train_accuracy_tok: 0.8475233239181738
train_label=O_precision_sent: 0.2222222222222222
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002449479485609308
train_label=N_precision_sent: 0.5450270397366564
train_label=N_recall_sent: 0.7003021148036254
train_label=N_f-score_sent: 0.6129842655031073
train_label=P_precision_sent: 0.6018215787015413
train_label=P_recall_sent: 0.7138504155124654
train_label=P_f-score_sent: 0.6530663963507349
train_precision_macro_sent: 0.45635694688680667
train_recall_macro_sent: 0.4717946858032289
train_f-score_macro_sent: 0.4228333804464839
train_precision_micro_sent: 0.5731507490636704
train_recall_micro_sent: 0.5731507490636704
train_f-score_micro_sent: 0.5731507490636704
train_label=O_precision_tok: 0.865113609948861
train_label=O_recall_tok: 0.9577633557705453
train_label=O_f-score_tok: 0.909083969756995
train_label=N_precision_tok: 0.7087782998718496
train_label=N_recall_tok: 0.4673285452753133
train_label=N_f-score_tok: 0.5632691165238055
train_label=P_precision_tok: 0.7796589672269923
train_label=P_recall_tok: 0.5154095215253628
train_label=P_f-score_tok: 0.6205751413788955
train_precision_macro_tok: 0.7845169590159009
train_recall_macro_tok: 0.6468338075237404
train_f-score_macro_tok: 0.697642742553232
train_precision_micro_tok: 0.8475233239181738
train_recall_micro_tok: 0.8475233239181738
train_f-score_micro_tok: 0.8475233239181738
train_time: 98.57990384101868
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2222    0.0012    0.0024      1624
           N     0.5450    0.7003    0.6130      3310
           P     0.6018    0.7139    0.6531      3610

   micro avg     0.5732    0.5732    0.5732      8544
   macro avg     0.4564    0.4718    0.4228      8544
weighted avg     0.5077    0.5732    0.5139      8544

F1-macro sent:  0.4228333804464839
F1-micro sent:  0.5731507490636704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8651    0.9578    0.9091    124347
           N     0.7088    0.4673    0.5633     14202
           P     0.7797    0.5154    0.6206     25017

   micro avg     0.8475    0.8475    0.8475    163566
   macro avg     0.7845    0.6468    0.6976    163566
weighted avg     0.8385    0.8475    0.8349    163566

F1-macro tok:  0.697642742553232
F1-micro tok:  0.8475233239181738
**************************************************
dev_cost_sum: 47298.435546875
dev_cost_avg: 42.959523657470484
dev_count_sent: 1101.0
dev_total_correct_sent: 668.0
dev_accuracy_sent: 0.6067211625794732
dev_count_tok: 21274.0
dev_total_correct_tok: 18477.0
dev_accuracy_tok: 0.8685249600451255
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6492027334851936
dev_label=N_recall_sent: 0.6658878504672897
dev_label=N_f-score_sent: 0.6574394463667821
dev_label=P_precision_sent: 0.5785498489425982
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.6925858951175408
dev_precision_macro_sent: 0.409250860809264
dev_recall_macro_sent: 0.5095001543599674
dev_f-score_macro_sent: 0.45000844716144095
dev_precision_micro_sent: 0.6067211625794732
dev_recall_micro_sent: 0.6067211625794732
dev_f-score_micro_sent: 0.6067211625794732
dev_label=O_precision_tok: 0.8802092120803104
dev_label=O_recall_tok: 0.9658130206726319
dev_label=O_f-score_tok: 0.9210263049490968
dev_label=N_precision_tok: 0.7405696689761355
dev_label=N_recall_tok: 0.5180398492191707
dev_label=N_f-score_tok: 0.6096324461343473
dev_label=P_precision_tok: 0.8495897903372835
dev_label=P_recall_tok: 0.5803237858032378
dev_label=P_f-score_tok: 0.6896041435442101
dev_precision_macro_tok: 0.8234562237979098
dev_recall_macro_tok: 0.6880588852316801
dev_f-score_macro_tok: 0.7400876315425514
dev_precision_micro_tok: 0.8685249600451255
dev_recall_micro_tok: 0.8685249600451255
dev_f-score_micro_tok: 0.8685249600451256
dev_time: 5.238409042358398
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6492    0.6659    0.6574       428
           P     0.5785    0.8626    0.6926       444

   micro avg     0.6067    0.6067    0.6067      1101
   macro avg     0.4093    0.5095    0.4500      1101
weighted avg     0.4857    0.6067    0.5349      1101

F1-macro sent:  0.45000844716144095
F1-micro sent:  0.6067211625794732
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8802    0.9658    0.9210     16205
           N     0.7406    0.5180    0.6096      1857
           P     0.8496    0.5803    0.6896      3212

   micro avg     0.8685    0.8685    0.8685     21274
   macro avg     0.8235    0.6881    0.7401     21274
weighted avg     0.8634    0.8685    0.8589     21274

F1-macro tok:  0.7400876315425514
F1-micro tok:  0.8685249600451256
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 355530.70703125
train_cost_avg: 41.611740055155664
train_count_sent: 8544.0
train_total_correct_sent: 5054.0
train_accuracy_sent: 0.5915262172284644
train_count_tok: 163566.0
train_total_correct_tok: 139779.0
train_accuracy_tok: 0.854572466160449
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007321537522879804
train_label=N_precision_sent: 0.568902882053766
train_label=N_recall_sent: 0.7096676737160121
train_label=N_f-score_sent: 0.6315364968409733
train_label=P_precision_sent: 0.6134090909090909
train_label=P_recall_sent: 0.7476454293628809
train_label=P_f-score_sent: 0.6739076154806491
train_precision_macro_sent: 0.5274373243209524
train_recall_macro_sent: 0.4870025614532271
train_f-score_macro_sent: 0.4375885499481675
train_precision_micro_sent: 0.5915262172284644
train_recall_micro_sent: 0.5915262172284644
train_f-score_micro_sent: 0.5915262172284644
train_label=O_precision_tok: 0.8712248383376882
train_label=O_recall_tok: 0.9599749089242201
train_label=O_f-score_tok: 0.9134492139225057
train_label=N_precision_tok: 0.7169129042256431
train_label=N_recall_tok: 0.48859315589353614
train_label=N_f-score_tok: 0.5811314434068926
train_label=P_precision_tok: 0.7983168375511172
train_label=P_recall_tok: 0.5384338649718191
train_label=P_f-score_tok: 0.6431129147767964
train_precision_macro_tok: 0.7954848600381496
train_recall_macro_tok: 0.6623339765965252
train_f-score_macro_tok: 0.7125645240353983
train_precision_micro_tok: 0.854572466160449
train_recall_micro_tok: 0.854572466160449
train_f-score_micro_tok: 0.854572466160449
train_time: 97.84514451026917
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0037    0.0073      1624
           N     0.5689    0.7097    0.6315      3310
           P     0.6134    0.7476    0.6739      3610

   micro avg     0.5915    0.5915    0.5915      8544
   macro avg     0.5274    0.4870    0.4376      8544
weighted avg     0.5556    0.5915    0.5308      8544

F1-macro sent:  0.4375885499481675
F1-micro sent:  0.5915262172284644
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8712    0.9600    0.9134    124347
           N     0.7169    0.4886    0.5811     14202
           P     0.7983    0.5384    0.6431     25017

   micro avg     0.8546    0.8546    0.8546    163566
   macro avg     0.7955    0.6623    0.7126    163566
weighted avg     0.8467    0.8546    0.8432    163566

F1-macro tok:  0.7125645240353983
F1-micro tok:  0.854572466160449
**************************************************
dev_cost_sum: 46822.69970703125
dev_cost_avg: 42.52742934335264
dev_count_sent: 1101.0
dev_total_correct_sent: 659.0
dev_accuracy_sent: 0.5985467756584922
dev_count_tok: 21274.0
dev_total_correct_tok: 18583.0
dev_accuracy_tok: 0.8735075679232867
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6864864864864865
dev_label=N_recall_sent: 0.5934579439252337
dev_label=N_f-score_sent: 0.6365914786967419
dev_label=P_precision_sent: 0.5540355677154583
dev_label=P_recall_sent: 0.9121621621621622
dev_label=P_f-score_sent: 0.6893617021276596
dev_precision_macro_sent: 0.4135073514006482
dev_recall_macro_sent: 0.5018733686957986
dev_f-score_macro_sent: 0.4419843936081338
dev_precision_micro_sent: 0.5985467756584922
dev_recall_micro_sent: 0.5985467756584922
dev_f-score_micro_sent: 0.5985467756584922
dev_label=O_precision_tok: 0.8768693918245264
dev_label=O_recall_tok: 0.9769207034865782
dev_label=O_f-score_tok: 0.9241951020169882
dev_label=N_precision_tok: 0.8090497737556561
dev_label=N_recall_tok: 0.481421647819063
dev_label=N_f-score_tok: 0.6036461850101283
dev_label=P_precision_tok: 0.8784869976359339
dev_label=P_recall_tok: 0.5784557907845579
dev_label=P_f-score_tok: 0.6975783743195044
dev_precision_macro_tok: 0.8548020544053722
dev_recall_macro_tok: 0.6789327140300664
dev_f-score_macro_tok: 0.7418065537822071
dev_precision_micro_tok: 0.8735075679232867
dev_recall_micro_tok: 0.8735075679232867
dev_f-score_micro_tok: 0.8735075679232867
dev_time: 5.128403186798096
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6865    0.5935    0.6366       428
           P     0.5540    0.9122    0.6894       444

   micro avg     0.5985    0.5985    0.5985      1101
   macro avg     0.4135    0.5019    0.4420      1101
weighted avg     0.4903    0.5985    0.5255      1101

F1-macro sent:  0.4419843936081338
F1-micro sent:  0.5985467756584922
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8769    0.9769    0.9242     16205
           N     0.8090    0.4814    0.6036      1857
           P     0.8785    0.5785    0.6976      3212

   micro avg     0.8735    0.8735    0.8735     21274
   macro avg     0.8548    0.6789    0.7418     21274
weighted avg     0.8712    0.8735    0.8620     21274

F1-macro tok:  0.7418065537822071
F1-micro tok:  0.8735075679232867
**************************************************
Best epoch: 3
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 351354.02001953125
train_cost_avg: 41.1228956015369
train_count_sent: 8544.0
train_total_correct_sent: 5098.0
train_accuracy_sent: 0.5966760299625468
train_count_tok: 163566.0
train_total_correct_tok: 140808.0
train_accuracy_tok: 0.8608635046403287
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5855764347384459
train_label=N_recall_sent: 0.6966767371601208
train_label=N_f-score_sent: 0.6363134657836643
train_label=P_precision_sent: 0.6061658706035605
train_label=P_recall_sent: 0.7734072022160665
train_label=P_f-score_sent: 0.6796494644595911
train_precision_macro_sent: 0.3972474351140021
train_recall_macro_sent: 0.4900279797920624
train_f-score_macro_sent: 0.43865431008108513
train_precision_micro_sent: 0.5966760299625468
train_recall_micro_sent: 0.5966760299625468
train_f-score_micro_sent: 0.5966760299625468
train_label=O_precision_tok: 0.8756191605024986
train_label=O_recall_tok: 0.962443806444868
train_label=O_f-score_tok: 0.9169808140247642
train_label=N_precision_tok: 0.7325888324873097
train_label=N_recall_tok: 0.5080974510632306
train_label=N_f-score_tok: 0.6000332612672543
train_label=P_precision_tok: 0.8166559070367979
train_label=P_recall_tok: 0.5562217691969461
train_label=P_f-score_tok: 0.6617367319764125
train_precision_macro_tok: 0.8082879666755355
train_recall_macro_tok: 0.6755876755683482
train_f-score_macro_tok: 0.7262502690894769
train_precision_micro_tok: 0.8608635046403287
train_recall_micro_tok: 0.8608635046403287
train_f-score_micro_tok: 0.8608635046403287
train_time: 98.63643717765808
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5856    0.6967    0.6363      3310
           P     0.6062    0.7734    0.6796      3610

   micro avg     0.5967    0.5967    0.5967      8544
   macro avg     0.3972    0.4900    0.4387      8544
weighted avg     0.4830    0.5967    0.5337      8544

F1-macro sent:  0.43865431008108513
F1-micro sent:  0.5966760299625468
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8756    0.9624    0.9170    124347
           N     0.7326    0.5081    0.6000     14202
           P     0.8167    0.5562    0.6617     25017

   micro avg     0.8609    0.8609    0.8609    163566
   macro avg     0.8083    0.6756    0.7263    163566
weighted avg     0.8542    0.8609    0.8504    163566

F1-macro tok:  0.7262502690894769
F1-micro tok:  0.8608635046403287
**************************************************
dev_cost_sum: 46512.15515136719
dev_cost_avg: 42.245372526219064
dev_count_sent: 1101.0
dev_total_correct_sent: 684.0
dev_accuracy_sent: 0.6212534059945504
dev_count_tok: 21274.0
dev_total_correct_tok: 18609.0
dev_accuracy_tok: 0.8747297170254771
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5578635014836796
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.6823956442831216
dev_label=P_precision_sent: 0.7213114754098361
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7072330654420207
dev_precision_macro_sent: 0.4263916589645052
dev_recall_macro_sent: 0.5240661221969632
dev_f-score_macro_sent: 0.46320956990838075
dev_precision_micro_sent: 0.6212534059945504
dev_recall_micro_sent: 0.6212534059945504
dev_f-score_micro_sent: 0.6212534059945504
dev_label=O_precision_tok: 0.8767963740879947
dev_label=O_recall_tok: 0.9788954026535021
dev_label=O_f-score_tok: 0.9250371752631427
dev_label=N_precision_tok: 0.8297665369649806
dev_label=N_recall_tok: 0.45934302638664515
dev_label=N_f-score_tok: 0.5913344887348354
dev_label=P_precision_tok: 0.8788300835654597
dev_label=P_recall_tok: 0.5893524283935243
dev_label=P_f-score_tok: 0.7055534849049573
dev_precision_macro_tok: 0.8617976648728116
dev_recall_macro_tok: 0.6758636191445572
dev_f-score_macro_tok: 0.7406417163009785
dev_precision_micro_tok: 0.8747297170254771
dev_recall_micro_tok: 0.8747297170254771
dev_f-score_micro_tok: 0.8747297170254771
dev_time: 5.33694052696228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5579    0.8785    0.6824       428
           P     0.7213    0.6937    0.7072       444

   micro avg     0.6213    0.6213    0.6213      1101
   macro avg     0.4264    0.5241    0.4632      1101
weighted avg     0.5077    0.6213    0.5505      1101

F1-macro sent:  0.46320956990838075
F1-micro sent:  0.6212534059945504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8768    0.9789    0.9250     16205
           N     0.8298    0.4593    0.5913      1857
           P     0.8788    0.5894    0.7056      3212

   micro avg     0.8747    0.8747    0.8747     21274
   macro avg     0.8618    0.6759    0.7406     21274
weighted avg     0.8730    0.8747    0.8628     21274

F1-macro tok:  0.7406417163009785
F1-micro tok:  0.8747297170254771
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 347320.3503417969
train_cost_avg: 40.6507900680942
train_count_sent: 8544.0
train_total_correct_sent: 5193.0
train_accuracy_sent: 0.6077949438202247
train_count_tok: 163566.0
train_total_correct_tok: 141326.0
train_accuracy_tok: 0.8640304219703361
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5647553686074829
train_label=N_recall_sent: 0.7706948640483384
train_label=N_f-score_sent: 0.6518461735019804
train_label=P_precision_sent: 0.6560715172585051
train_label=P_recall_sent: 0.7318559556786703
train_label=P_f-score_sent: 0.6918947230587926
train_precision_macro_sent: 0.4069422952886626
train_recall_macro_sent: 0.5008502732423362
train_f-score_macro_sent: 0.44791363218692437
train_precision_micro_sent: 0.6077949438202247
train_recall_micro_sent: 0.6077949438202247
train_f-score_micro_sent: 0.6077949438202247
train_label=O_precision_tok: 0.8782064436691976
train_label=O_recall_tok: 0.9636420661535864
train_label=O_f-score_tok: 0.9189427549263587
train_label=N_precision_tok: 0.7380185259766412
train_label=N_recall_tok: 0.51612448950852
train_label=N_f-score_tok: 0.6074417833761498
train_label=P_precision_tok: 0.8243164630599186
train_label=P_recall_tok: 0.5664148379102211
train_label=P_f-score_tok: 0.6714526026488498
train_precision_macro_tok: 0.8135138109019192
train_recall_macro_tok: 0.6820604645241092
train_f-score_macro_tok: 0.7326123803171195
train_precision_micro_tok: 0.8640304219703361
train_recall_micro_tok: 0.8640304219703361
train_f-score_micro_tok: 0.8640304219703361
train_time: 98.30600214004517
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5648    0.7707    0.6518      3310
           P     0.6561    0.7319    0.6919      3610

   micro avg     0.6078    0.6078    0.6078      8544
   macro avg     0.4069    0.5009    0.4479      8544
weighted avg     0.4960    0.6078    0.5449      8544

F1-macro sent:  0.44791363218692437
F1-micro sent:  0.6077949438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8782    0.9636    0.9189    124347
           N     0.7380    0.5161    0.6074     14202
           P     0.8243    0.5664    0.6715     25017

   micro avg     0.8640    0.8640    0.8640    163566
   macro avg     0.8135    0.6821    0.7326    163566
weighted avg     0.8578    0.8640    0.8540    163566

F1-macro tok:  0.7326123803171195
F1-micro tok:  0.8640304219703361
**************************************************
dev_cost_sum: 45930.248107910156
dev_cost_avg: 41.71684660118997
dev_count_sent: 1101.0
dev_total_correct_sent: 662.0
dev_accuracy_sent: 0.6012715712988193
dev_count_tok: 21274.0
dev_total_correct_tok: 18752.0
dev_accuracy_tok: 0.8814515370875247
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5136138613861386
dev_label=N_recall_sent: 0.969626168224299
dev_label=N_f-score_sent: 0.6715210355987056
dev_label=P_precision_sent: 0.8430034129692833
dev_label=P_recall_sent: 0.5563063063063063
dev_label=P_f-score_sent: 0.6702849389416554
dev_precision_macro_sent: 0.45220575811847397
dev_recall_macro_sent: 0.5086441581768685
dev_f-score_macro_sent: 0.44726865818012035
dev_precision_micro_sent: 0.6012715712988193
dev_recall_micro_sent: 0.6012715712988193
dev_f-score_micro_sent: 0.6012715712988193
dev_label=O_precision_tok: 0.8861078447841424
dev_label=O_recall_tok: 0.97655044739278
dev_label=O_f-score_tok: 0.9291333959605448
dev_label=N_precision_tok: 0.7804878048780488
dev_label=N_recall_tok: 0.5514270328486807
dev_label=N_f-score_tok: 0.6462606500473335
dev_label=P_precision_tok: 0.9048977650974798
dev_label=P_recall_tok: 0.5924657534246576
dev_label=P_f-score_tok: 0.7160865475070556
dev_precision_macro_tok: 0.857164471586557
dev_recall_macro_tok: 0.7068144112220395
dev_f-score_macro_tok: 0.7638268645049778
dev_precision_micro_tok: 0.8814515370875247
dev_recall_micro_tok: 0.8814515370875247
dev_f-score_micro_tok: 0.8814515370875247
dev_time: 5.114220380783081
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5136    0.9696    0.6715       428
           P     0.8430    0.5563    0.6703       444

   micro avg     0.6013    0.6013    0.6013      1101
   macro avg     0.4522    0.5086    0.4473      1101
weighted avg     0.5396    0.6013    0.5314      1101

F1-macro sent:  0.44726865818012035
F1-micro sent:  0.6012715712988193
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8861    0.9766    0.9291     16205
           N     0.7805    0.5514    0.6463      1857
           P     0.9049    0.5925    0.7161      3212

   micro avg     0.8815    0.8815    0.8815     21274
   macro avg     0.8572    0.7068    0.7638     21274
weighted avg     0.8797    0.8815    0.8723     21274

F1-macro tok:  0.7638268645049778
F1-micro tok:  0.8814515370875247
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 343856.8049316406
train_cost_avg: 40.245412562223855
train_count_sent: 8544.0
train_total_correct_sent: 5179.0
train_accuracy_sent: 0.6061563670411985
train_count_tok: 163566.0
train_total_correct_tok: 141979.0
train_accuracy_tok: 0.8680226942029518
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5714285714285714
train_label=N_recall_sent: 0.7456193353474321
train_label=N_f-score_sent: 0.6470048499147988
train_label=P_precision_sent: 0.6416568047337278
train_label=P_recall_sent: 0.7509695290858726
train_label=P_f-score_sent: 0.6920229738353542
train_precision_macro_sent: 0.40436179205409967
train_recall_macro_sent: 0.4988629548111015
train_f-score_macro_sent: 0.44634260791671765
train_precision_micro_sent: 0.6061563670411985
train_recall_micro_sent: 0.6061563670411985
train_f-score_micro_sent: 0.6061563670411985
train_label=O_precision_tok: 0.8815808801927257
train_label=O_recall_tok: 0.9652745944815717
train_label=O_f-score_tok: 0.9215313686424901
train_label=N_precision_tok: 0.7416650226869205
train_label=N_recall_tok: 0.5294324742993944
train_label=N_f-score_tok: 0.6178307313064914
train_label=P_precision_tok: 0.8353206760824264
train_label=P_recall_tok: 0.5768477435343966
train_label=P_f-score_tok: 0.6824297165015487
train_precision_macro_tok: 0.8195221929873576
train_recall_macro_tok: 0.6905182707717876
train_f-score_macro_tok: 0.7405972721501767
train_precision_micro_tok: 0.8680226942029518
train_recall_micro_tok: 0.8680226942029518
train_f-score_micro_tok: 0.8680226942029518
train_time: 97.05516195297241
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5714    0.7456    0.6470      3310
           P     0.6417    0.7510    0.6920      3610

   micro avg     0.6062    0.6062    0.6062      8544
   macro avg     0.4044    0.4989    0.4463      8544
weighted avg     0.4925    0.6062    0.5430      8544

F1-macro sent:  0.44634260791671765
F1-micro sent:  0.6061563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8816    0.9653    0.9215    124347
           N     0.7417    0.5294    0.6178     14202
           P     0.8353    0.5768    0.6824     25017

   micro avg     0.8680    0.8680    0.8680    163566
   macro avg     0.8195    0.6905    0.7406    163566
weighted avg     0.8624    0.8680    0.8586    163566

F1-macro tok:  0.7405972721501767
F1-micro tok:  0.8680226942029518
**************************************************
dev_cost_sum: 45583.22521972656
dev_cost_avg: 41.401657783584525
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18758.0
dev_accuracy_tok: 0.8817335714957225
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6658878504672897
dev_label=N_recall_sent: 0.6658878504672897
dev_label=N_f-score_sent: 0.6658878504672897
dev_label=P_precision_sent: 0.5824665676077266
dev_label=P_recall_sent: 0.8828828828828829
dev_label=P_f-score_sent: 0.7018800358102059
dev_precision_macro_sent: 0.4161181393583388
dev_recall_macro_sent: 0.5162569111167242
dev_f-score_macro_sent: 0.45592262875916517
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8847527625851099
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.929168009846731
dev_label=N_precision_tok: 0.7858842188739096
dev_label=N_recall_tok: 0.5336564351103931
dev_label=N_f-score_tok: 0.63566388710712
dev_label=P_precision_tok: 0.9136038186157518
dev_label=P_recall_tok: 0.5958904109589042
dev_label=P_f-score_tok: 0.7213114754098362
dev_precision_macro_tok: 0.8614136000249237
dev_recall_macro_tok: 0.7026083850777117
dev_f-score_macro_tok: 0.7620477907878959
dev_precision_micro_tok: 0.8817335714957225
dev_recall_micro_tok: 0.8817335714957225
dev_f-score_micro_tok: 0.8817335714957225
dev_time: 5.147855997085571
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6659    0.6659    0.6659       428
           P     0.5825    0.8829    0.7019       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.4161    0.5163    0.4559      1101
weighted avg     0.4937    0.6149    0.5419      1101

F1-macro sent:  0.45592262875916517
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8848    0.9783    0.9292     16205
           N     0.7859    0.5337    0.6357      1857
           P     0.9136    0.5959    0.7213      3212

   micro avg     0.8817    0.8817    0.8817     21274
   macro avg     0.8614    0.7026    0.7620     21274
weighted avg     0.8805    0.8817    0.8722     21274

F1-macro tok:  0.7620477907878959
F1-micro tok:  0.8817335714957225
**************************************************
Best epoch: 6
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 340957.75939941406
train_cost_avg: 39.90610479862056
train_count_sent: 8544.0
train_total_correct_sent: 5172.0
train_accuracy_sent: 0.6053370786516854
train_count_tok: 163566.0
train_total_correct_tok: 142454.0
train_accuracy_tok: 0.8709267207121284
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5950731331793687
train_label=N_recall_sent: 0.7006042296072508
train_label=N_f-score_sent: 0.6435410018038019
train_label=P_precision_sent: 0.6139444803098774
train_label=P_recall_sent: 0.7903047091412743
train_label=P_f-score_sent: 0.6910500181664042
train_precision_macro_sent: 0.403005871163082
train_recall_macro_sent: 0.49696964624950835
train_f-score_macro_sent: 0.444863673323402
train_precision_micro_sent: 0.6053370786516854
train_recall_micro_sent: 0.6053370786516854
train_f-score_micro_sent: 0.6053370786516854
train_label=O_precision_tok: 0.8839929380609092
train_label=O_recall_tok: 0.9664085180985468
train_label=O_f-score_tok: 0.9233653620810873
train_label=N_precision_tok: 0.7495113369820172
train_label=N_recall_tok: 0.5399943669905647
train_label=N_f-score_tok: 0.6277318490627813
train_label=P_precision_tok: 0.8402322639990801
train_label=P_recall_tok: 0.584202742135348
train_label=P_f-score_tok: 0.6892079884935512
train_precision_macro_tok: 0.8245788463473356
train_recall_macro_tok: 0.696868542408153
train_f-score_macro_tok: 0.7467683998791399
train_precision_micro_tok: 0.8709267207121284
train_recall_micro_tok: 0.8709267207121284
train_f-score_micro_tok: 0.8709267207121284
train_time: 97.85801553726196
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5951    0.7006    0.6435      3310
           P     0.6139    0.7903    0.6911      3610

   micro avg     0.6053    0.6053    0.6053      8544
   macro avg     0.4030    0.4970    0.4449      8544
weighted avg     0.4899    0.6053    0.5413      8544

F1-macro sent:  0.444863673323402
F1-micro sent:  0.6053370786516854
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8840    0.9664    0.9234    124347
           N     0.7495    0.5400    0.6277     14202
           P     0.8402    0.5842    0.6892     25017

   micro avg     0.8709    0.8709    0.8709    163566
   macro avg     0.8246    0.6969    0.7468    163566
weighted avg     0.8656    0.8709    0.8619    163566

F1-macro tok:  0.7467683998791399
F1-micro tok:  0.8709267207121284
**************************************************
dev_cost_sum: 45270.38592529297
dev_cost_avg: 41.117516735052654
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18800.0
dev_accuracy_tok: 0.883707812353107
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6361788617886179
dev_label=N_recall_sent: 0.7313084112149533
dev_label=N_f-score_sent: 0.6804347826086956
dev_label=P_precision_sent: 0.6157635467980296
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7122507122507122
dev_precision_macro_sent: 0.4173141361955492
dev_recall_macro_sent: 0.525301001936516
dev_f-score_macro_sent: 0.4642284982864693
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8823008359630183
dev_label=O_recall_tok: 0.9834618944770133
dev_label=O_f-score_tok: 0.9301389051009689
dev_label=N_precision_tok: 0.8388888888888889
dev_label=N_recall_tok: 0.4878836833602585
dev_label=N_f-score_tok: 0.6169560776302349
dev_label=P_precision_tok: 0.9183481933364618
dev_label=P_recall_tok: 0.6092777085927771
dev_label=P_f-score_tok: 0.7325472580947033
dev_precision_macro_tok: 0.8798459727294564
dev_recall_macro_tok: 0.6935410954766829
dev_f-score_macro_tok: 0.759880746941969
dev_precision_micro_tok: 0.883707812353107
dev_recall_micro_tok: 0.883707812353107
dev_f-score_micro_tok: 0.883707812353107
dev_time: 5.1829869747161865
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6362    0.7313    0.6804       428
           P     0.6158    0.8446    0.7123       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.4173    0.5253    0.4642      1101
weighted avg     0.4956    0.6249    0.5517      1101

F1-macro sent:  0.4642284982864693
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8823    0.9835    0.9301     16205
           N     0.8389    0.4879    0.6170      1857
           P     0.9183    0.6093    0.7325      3212

   micro avg     0.8837    0.8837    0.8837     21274
   macro avg     0.8798    0.6935    0.7599     21274
weighted avg     0.8840    0.8837    0.8730     21274

F1-macro tok:  0.759880746941969
F1-micro tok:  0.883707812353107
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 337828.4442138672
train_cost_avg: 39.539845998814044
train_count_sent: 8544.0
train_total_correct_sent: 5240.0
train_accuracy_sent: 0.6132958801498127
train_count_tok: 163566.0
train_total_correct_tok: 142964.0
train_accuracy_tok: 0.8740447281219813
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5782747603833865
train_label=N_recall_sent: 0.7655589123867069
train_label=N_f-score_sent: 0.6588663546541862
train_label=P_precision_sent: 0.6501681883709755
train_label=P_recall_sent: 0.749584487534626
train_label=P_f-score_sent: 0.696345856922285
train_precision_macro_sent: 0.4094809829181207
train_recall_macro_sent: 0.5050477999737777
train_f-score_macro_sent: 0.45173740385882377
train_precision_micro_sent: 0.6132958801498127
train_recall_micro_sent: 0.6132958801498127
train_f-score_micro_sent: 0.6132958801498127
train_label=O_precision_tok: 0.8860012074271495
train_label=O_recall_tok: 0.9677917440710271
train_label=O_f-score_tok: 0.9250921502231209
train_label=N_precision_tok: 0.7539766702014846
train_label=N_recall_tok: 0.5506970849176173
train_label=N_f-score_tok: 0.6365005086469989
train_label=P_precision_tok: 0.8522485173029308
train_label=P_recall_tok: 0.5916376863732662
train_label=P_f-score_tok: 0.6984239335598338
train_precision_macro_tok: 0.8307421316438551
train_recall_macro_tok: 0.7033755051206368
train_f-score_macro_tok: 0.753338864143318
train_precision_micro_tok: 0.8740447281219813
train_recall_micro_tok: 0.8740447281219813
train_f-score_micro_tok: 0.8740447281219813
train_time: 97.79882907867432
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5783    0.7656    0.6589      3310
           P     0.6502    0.7496    0.6963      3610

   micro avg     0.6133    0.6133    0.6133      8544
   macro avg     0.4095    0.5050    0.4517      8544
weighted avg     0.4987    0.6133    0.5495      8544

F1-macro sent:  0.45173740385882377
F1-micro sent:  0.6132958801498127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8860    0.9678    0.9251    124347
           N     0.7540    0.5507    0.6365     14202
           P     0.8522    0.5916    0.6984     25017

   micro avg     0.8740    0.8740    0.8740    163566
   macro avg     0.8307    0.7034    0.7533    163566
weighted avg     0.8694    0.8740    0.8654    163566

F1-macro tok:  0.753338864143318
F1-micro tok:  0.8740447281219813
**************************************************
dev_cost_sum: 44916.330810546875
dev_cost_avg: 40.795940790687446
dev_count_sent: 1101.0
dev_total_correct_sent: 682.0
dev_accuracy_sent: 0.6194368755676658
dev_count_tok: 21274.0
dev_total_correct_tok: 18883.0
dev_accuracy_tok: 0.8876092883331766
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5513361462728551
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.6883230904302019
dev_label=P_precision_sent: 0.7435897435897436
dev_label=P_recall_sent: 0.6531531531531531
dev_label=P_f-score_sent: 0.6954436450839329
dev_precision_macro_sent: 0.43164196328753296
dev_recall_macro_sent: 0.523013667873481
dev_f-score_macro_sent: 0.4612555785047116
dev_precision_micro_sent: 0.6194368755676658
dev_recall_micro_sent: 0.6194368755676658
dev_f-score_micro_sent: 0.6194368755676658
dev_label=O_precision_tok: 0.890828468792097
dev_label=O_recall_tok: 0.979389077445233
dev_label=O_f-score_tok: 0.9330119631992007
dev_label=N_precision_tok: 0.7887640449438202
dev_label=N_recall_tok: 0.567043618739903
dev_label=N_f-score_tok: 0.6597744360902256
dev_label=P_precision_tok: 0.9227508243052285
dev_label=P_recall_tok: 0.6099003735990037
dev_label=P_f-score_tok: 0.7343955014058108
dev_precision_macro_tok: 0.8674477793470485
dev_recall_macro_tok: 0.7187776899280466
dev_f-score_macro_tok: 0.7757273002317456
dev_precision_micro_tok: 0.8876092883331766
dev_recall_micro_tok: 0.8876092883331766
dev_f-score_micro_tok: 0.8876092883331766
dev_time: 5.132469415664673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5513    0.9159    0.6883       428
           P     0.7436    0.6532    0.6954       444

   micro avg     0.6194    0.6194    0.6194      1101
   macro avg     0.4316    0.5230    0.4613      1101
weighted avg     0.5142    0.6194    0.5480      1101

F1-macro sent:  0.4612555785047116
F1-micro sent:  0.6194368755676658
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9794    0.9330     16205
           N     0.7888    0.5670    0.6598      1857
           P     0.9228    0.6099    0.7344      3212

   micro avg     0.8876    0.8876    0.8876     21274
   macro avg     0.8674    0.7188    0.7757     21274
weighted avg     0.8867    0.8876    0.8792     21274

F1-macro tok:  0.7757273002317456
F1-micro tok:  0.8876092883331766
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 335098.60662841797
train_cost_avg: 39.22034253609761
train_count_sent: 8544.0
train_total_correct_sent: 5292.0
train_accuracy_sent: 0.6193820224719101
train_count_tok: 163566.0
train_total_correct_tok: 143377.0
train_accuracy_tok: 0.8765697027499603
train_label=O_precision_sent: 0.2647058823529412
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010856453558504222
train_label=N_precision_sent: 0.5796972395369546
train_label=N_recall_sent: 0.7867069486404834
train_label=N_f-score_sent: 0.6675211484234812
train_label=P_precision_sent: 0.6667496266799403
train_label=P_recall_sent: 0.7421052631578947
train_label=P_f-score_sent: 0.7024121657052963
train_precision_macro_sent: 0.503717582856612
train_recall_macro_sent: 0.5114513612398535
train_f-score_macro_sent: 0.4602632558957606
train_precision_micro_sent: 0.6193820224719101
train_recall_micro_sent: 0.6193820224719101
train_f-score_micro_sent: 0.6193820224719101
train_label=O_precision_tok: 0.8886919793835748
train_label=O_recall_tok: 0.9678721641857061
train_label=O_f-score_tok: 0.9265936028763574
train_label=N_precision_tok: 0.7585321798650062
train_label=N_recall_tok: 0.5618222785523166
train_label=N_f-score_tok: 0.64552404837992
train_label=P_precision_tok: 0.8538675444072413
train_label=P_recall_tok: 0.6014310269017068
train_label=P_f-score_tok: 0.7057554294291476
train_precision_macro_tok: 0.8336972345519408
train_recall_macro_tok: 0.7103751565465766
train_f-score_macro_tok: 0.7592910268951417
train_precision_micro_tok: 0.8765697027499603
train_recall_micro_tok: 0.8765697027499603
train_f-score_micro_tok: 0.8765697027499602
train_time: 97.46042370796204
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2647    0.0055    0.0109      1624
           N     0.5797    0.7867    0.6675      3310
           P     0.6667    0.7421    0.7024      3610

   micro avg     0.6194    0.6194    0.6194      8544
   macro avg     0.5037    0.5115    0.4603      8544
weighted avg     0.5566    0.6194    0.5574      8544

F1-macro sent:  0.4602632558957606
F1-micro sent:  0.6193820224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8887    0.9679    0.9266    124347
           N     0.7585    0.5618    0.6455     14202
           P     0.8539    0.6014    0.7058     25017

   micro avg     0.8766    0.8766    0.8766    163566
   macro avg     0.8337    0.7104    0.7593    163566
weighted avg     0.8721    0.8766    0.8684    163566

F1-macro tok:  0.7592910268951417
F1-micro tok:  0.8765697027499602
**************************************************
dev_cost_sum: 44613.824462890625
dev_cost_avg: 40.52118479826578
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18903.0
dev_accuracy_tok: 0.8885494030271693
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5861513687600645
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.693994280266921
dev_label=P_precision_sent: 0.6875
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7142857142857143
dev_precision_macro_sent: 0.4245504562533548
dev_recall_macro_sent: 0.5312368443209564
dev_f-score_macro_sent: 0.4694266648508784
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.889286113283432
dev_label=O_recall_tok: 0.982412835544585
dev_label=O_f-score_tok: 0.9335327058961504
dev_label=N_precision_tok: 0.8014354066985646
dev_label=N_recall_tok: 0.5411954765751211
dev_label=N_f-score_tok: 0.6460945033751205
dev_label=P_precision_tok: 0.9338999055712937
dev_label=P_recall_tok: 0.6158156911581569
dev_label=P_f-score_tok: 0.7422138836772982
dev_precision_macro_tok: 0.8748738085177634
dev_recall_macro_tok: 0.7131413344259544
dev_f-score_macro_tok: 0.7739470309828563
dev_precision_micro_tok: 0.8885494030271693
dev_recall_micro_tok: 0.8885494030271693
dev_f-score_micro_tok: 0.8885494030271693
dev_time: 5.075788259506226
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5862    0.8505    0.6940       428
           P     0.6875    0.7432    0.7143       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4246    0.5312    0.4694      1101
weighted avg     0.5051    0.6303    0.5578      1101

F1-macro sent:  0.4694266648508784
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8893    0.9824    0.9335     16205
           N     0.8014    0.5412    0.6461      1857
           P     0.9339    0.6158    0.7422      3212

   micro avg     0.8885    0.8885    0.8885     21274
   macro avg     0.8749    0.7131    0.7739     21274
weighted avg     0.8884    0.8885    0.8796     21274

F1-macro tok:  0.7739470309828563
F1-micro tok:  0.8885494030271693
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 332968.8370361328
train_cost_avg: 38.97107175048371
train_count_sent: 8544.0
train_total_correct_sent: 5293.0
train_accuracy_sent: 0.619499063670412
train_count_tok: 163566.0
train_total_correct_tok: 143732.0
train_accuracy_tok: 0.8787400804568186
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5776892430278885
train_label=N_recall_sent: 0.7885196374622356
train_label=N_f-score_sent: 0.6668369954011241
train_label=P_precision_sent: 0.6664182811723796
train_label=P_recall_sent: 0.743213296398892
train_label=P_f-score_sent: 0.7027239392352017
train_precision_macro_sent: 0.41470250806675607
train_recall_macro_sent: 0.5105776446203759
train_f-score_macro_sent: 0.4565203115454419
train_precision_micro_sent: 0.619499063670412
train_recall_micro_sent: 0.619499063670412
train_f-score_micro_sent: 0.619499063670412
train_label=O_precision_tok: 0.8902548947173994
train_label=O_recall_tok: 0.969030213837085
train_label=O_f-score_tok: 0.9279737540287335
train_label=N_precision_tok: 0.7650123129380565
train_label=N_recall_tok: 0.5687227151105478
train_label=N_f-score_tok: 0.6524232633279484
train_label=P_precision_tok: 0.8584777437988447
train_label=P_recall_tok: 0.6059479553903345
train_label=P_f-score_tok: 0.7104393673110719
train_precision_macro_tok: 0.8379149838181
train_recall_macro_tok: 0.7145669614459891
train_f-score_macro_tok: 0.7636121282225846
train_precision_micro_tok: 0.8787400804568186
train_recall_micro_tok: 0.8787400804568186
train_f-score_micro_tok: 0.8787400804568186
train_time: 97.994943857193
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5777    0.7885    0.6668      3310
           P     0.6664    0.7432    0.7027      3610

   micro avg     0.6195    0.6195    0.6195      8544
   macro avg     0.4147    0.5106    0.4565      8544
weighted avg     0.5054    0.6195    0.5553      8544

F1-macro sent:  0.4565203115454419
F1-micro sent:  0.619499063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8903    0.9690    0.9280    124347
           N     0.7650    0.5687    0.6524     14202
           P     0.8585    0.6059    0.7104     25017

   micro avg     0.8787    0.8787    0.8787    163566
   macro avg     0.8379    0.7146    0.7636    163566
weighted avg     0.8745    0.8787    0.8708    163566

F1-macro tok:  0.7636121282225846
F1-micro tok:  0.8787400804568186
**************************************************
dev_cost_sum: 44389.30712890625
dev_cost_avg: 40.31726351399296
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18936.0
dev_accuracy_tok: 0.8901005922722572
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5507042253521127
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.6871704745166961
dev_label=P_precision_sent: 0.7621483375959079
dev_label=P_recall_sent: 0.6711711711711712
dev_label=P_f-score_sent: 0.7137724550898203
dev_precision_macro_sent: 0.43761752098267354
dev_recall_macro_sent: 0.52824085768011
dev_f-score_macro_sent: 0.46698097653550547
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.891097424412094
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9343901365037429
dev_label=N_precision_tok: 0.8244592346089851
dev_label=N_recall_tok: 0.5336564351103931
dev_label=N_f-score_tok: 0.6479241582216411
dev_label=P_precision_tok: 0.9177215189873418
dev_label=P_recall_tok: 0.6320049813200498
dev_label=P_f-score_tok: 0.7485250737463125
dev_precision_macro_tok: 0.8777593926694737
dev_recall_macro_tok: 0.7159219017433988
dev_f-score_macro_tok: 0.7769464561572321
dev_precision_micro_tok: 0.8901005922722572
dev_recall_micro_tok: 0.8901005922722572
dev_f-score_micro_tok: 0.8901005922722572
dev_time: 5.151277303695679
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5507    0.9136    0.6872       428
           P     0.7621    0.6712    0.7138       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.4376    0.5282    0.4670      1101
weighted avg     0.5214    0.6258    0.5550      1101

F1-macro sent:  0.46698097653550547
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8911    0.9821    0.9344     16205
           N     0.8245    0.5337    0.6479      1857
           P     0.9177    0.6320    0.7485      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8778    0.7159    0.7769     21274
weighted avg     0.8893    0.8901    0.8813     21274

F1-macro tok:  0.7769464561572321
F1-micro tok:  0.8901005922722572
**************************************************
Best epoch: 11
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 330401.12646484375
train_cost_avg: 38.67054382781411
train_count_sent: 8544.0
train_total_correct_sent: 5342.0
train_accuracy_sent: 0.6252340823970037
train_count_tok: 163566.0
train_total_correct_tok: 143936.0
train_accuracy_tok: 0.8799872834207598
train_label=O_precision_sent: 0.2
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007255139056831923
train_label=N_precision_sent: 0.582010582010582
train_label=N_recall_sent: 0.797583081570997
train_label=N_f-score_sent: 0.6729543716543462
train_label=P_precision_sent: 0.6777275012569131
train_label=P_recall_sent: 0.746814404432133
train_label=P_f-score_sent: 0.7105956773853452
train_precision_macro_sent: 0.48657936108916505
train_recall_macro_sent: 0.5160306890946393
train_f-score_macro_sent: 0.46360172936550786
train_precision_micro_sent: 0.6252340823970037
train_recall_micro_sent: 0.6252340823970037
train_f-score_micro_sent: 0.6252340823970037
train_label=O_precision_tok: 0.8916422417621458
train_label=O_recall_tok: 0.9688050375159835
train_label=O_f-score_tok: 0.9286234607157311
train_label=N_precision_tok: 0.7680030044127312
train_label=N_recall_tok: 0.5759752147584847
train_label=N_f-score_tok: 0.6582706313121153
train_label=P_precision_tok: 0.8585387768854945
train_label=P_recall_tok: 0.6111044489746972
train_label=P_f-score_tok: 0.7139921539323743
train_precision_macro_tok: 0.8393946743534572
train_recall_macro_tok: 0.7186282337497217
train_f-score_macro_tok: 0.7669620819867401
train_precision_micro_tok: 0.8799872834207598
train_recall_micro_tok: 0.8799872834207598
train_f-score_micro_tok: 0.8799872834207598
train_time: 97.2494809627533
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2000    0.0037    0.0073      1624
           N     0.5820    0.7976    0.6730      3310
           P     0.6777    0.7468    0.7106      3610

   micro avg     0.6252    0.6252    0.6252      8544
   macro avg     0.4866    0.5160    0.4636      8544
weighted avg     0.5498    0.6252    0.5623      8544

F1-macro sent:  0.46360172936550786
F1-micro sent:  0.6252340823970037
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8916    0.9688    0.9286    124347
           N     0.7680    0.5760    0.6583     14202
           P     0.8585    0.6111    0.7140     25017

   micro avg     0.8800    0.8800    0.8800    163566
   macro avg     0.8394    0.7186    0.7670    163566
weighted avg     0.8758    0.8800    0.8723    163566

F1-macro tok:  0.7669620819867401
F1-micro tok:  0.8799872834207598
**************************************************
dev_cost_sum: 44127.59533691406
dev_cost_avg: 40.079559797378806
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18975.0
dev_accuracy_tok: 0.8919338159255429
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5829307568438004
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.6901811248808389
dev_label=P_precision_sent: 0.6833333333333333
dev_label=P_recall_sent: 0.7387387387387387
dev_label=P_f-score_sent: 0.70995670995671
dev_precision_macro_sent: 0.4220880300590446
dev_recall_macro_sent: 0.5281777104207012
dev_f-score_macro_sent: 0.46671261161251626
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8975100674947536
dev_label=O_recall_tok: 0.9764887380438136
dev_label=O_f-score_tok: 0.935335145998345
dev_label=N_precision_tok: 0.805450416351249
dev_label=N_recall_tok: 0.5729671513193323
dev_label=N_f-score_tok: 0.6696035242290749
dev_label=P_precision_tok: 0.8987941429801894
dev_label=P_recall_tok: 0.6497509339975094
dev_label=P_f-score_tok: 0.7542464763281533
dev_precision_macro_tok: 0.8672515422753974
dev_recall_macro_tok: 0.7330689411202185
dev_f-score_macro_tok: 0.7863950488518577
dev_precision_micro_tok: 0.8919338159255429
dev_recall_micro_tok: 0.8919338159255429
dev_f-score_micro_tok: 0.8919338159255429
dev_time: 5.042590379714966
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5829    0.8458    0.6902       428
           P     0.6833    0.7387    0.7100       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4221    0.5282    0.4667      1101
weighted avg     0.5022    0.6267    0.5546      1101

F1-macro sent:  0.46671261161251626
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8975    0.9765    0.9353     16205
           N     0.8055    0.5730    0.6696      1857
           P     0.8988    0.6498    0.7542      3212

   micro avg     0.8919    0.8919    0.8919     21274
   macro avg     0.8673    0.7331    0.7864     21274
weighted avg     0.8897    0.8919    0.8848     21274

F1-macro tok:  0.7863950488518577
F1-micro tok:  0.8919338159255429
**************************************************
Best epoch: 11
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 328250.7492675781
train_cost_avg: 38.41886110341504
train_count_sent: 8544.0
train_total_correct_sent: 5390.0
train_accuracy_sent: 0.6308520599250936
train_count_tok: 163566.0
train_total_correct_tok: 144313.0
train_accuracy_tok: 0.8822921634080433
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6038180532641999
train_label=N_recall_sent: 0.7740181268882175
train_label=N_f-score_sent: 0.6784059314179797
train_label=P_precision_sent: 0.6582867783985102
train_label=P_recall_sent: 0.7833795013850415
train_label=P_f-score_sent: 0.7154060207437389
train_precision_macro_sent: 0.4207016105542367
train_recall_macro_sent: 0.519132542757753
train_f-score_macro_sent: 0.46460398405390624
train_precision_micro_sent: 0.6308520599250936
train_recall_micro_sent: 0.6308520599250936
train_f-score_micro_sent: 0.6308520599250936
train_label=O_precision_tok: 0.8934247752218157
train_label=O_recall_tok: 0.9701239273967205
train_label=O_f-score_tok: 0.9301959756177492
train_label=N_precision_tok: 0.7697122571001495
train_label=N_recall_tok: 0.5801295592170117
train_label=N_f-score_tok: 0.6616076447442384
train_label=P_precision_tok: 0.8655829596412556
train_label=P_recall_tok: 0.6172602630211457
train_label=P_f-score_tok: 0.7206290687635625
train_precision_macro_tok: 0.8429066639877402
train_recall_macro_tok: 0.7225045832116259
train_f-score_macro_tok: 0.7708108963751834
train_precision_micro_tok: 0.8822921634080433
train_recall_micro_tok: 0.8822921634080433
train_f-score_micro_tok: 0.8822921634080433
train_time: 96.88053774833679
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6038    0.7740    0.6784      3310
           P     0.6583    0.7834    0.7154      3610

   micro avg     0.6309    0.6309    0.6309      8544
   macro avg     0.4207    0.5191    0.4646      8544
weighted avg     0.5121    0.6309    0.5651      8544

F1-macro sent:  0.46460398405390624
F1-micro sent:  0.6308520599250936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8934    0.9701    0.9302    124347
           N     0.7697    0.5801    0.6616     14202
           P     0.8656    0.6173    0.7206     25017

   micro avg     0.8823    0.8823    0.8823    163566
   macro avg     0.8429    0.7225    0.7708    163566
weighted avg     0.8784    0.8823    0.8748    163566

F1-macro tok:  0.7708108963751834
F1-micro tok:  0.8822921634080433
**************************************************
dev_cost_sum: 43965.01013183594
dev_cost_avg: 39.93188931138596
dev_count_sent: 1101.0
dev_total_correct_sent: 685.0
dev_accuracy_sent: 0.6221616712079927
dev_count_tok: 21274.0
dev_total_correct_tok: 18982.0
dev_accuracy_tok: 0.8922628560684404
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5470668485675307
dev_label=N_recall_sent: 0.9369158878504673
dev_label=N_f-score_sent: 0.6907838070628769
dev_label=P_precision_sent: 0.7717391304347826
dev_label=P_recall_sent: 0.6396396396396397
dev_label=P_f-score_sent: 0.6995073891625616
dev_precision_macro_sent: 0.4396019930007711
dev_recall_macro_sent: 0.5255185091633691
dev_f-score_macro_sent: 0.46343039874181285
dev_precision_micro_sent: 0.6221616712079927
dev_recall_micro_sent: 0.6221616712079927
dev_f-score_micro_sent: 0.6221616712079927
dev_label=O_precision_tok: 0.8995732574679943
dev_label=O_recall_tok: 0.9756248071582845
dev_label=O_f-score_tok: 0.936056838365897
dev_label=N_precision_tok: 0.7536231884057971
dev_label=N_recall_tok: 0.6160473882606354
dev_label=N_f-score_tok: 0.6779259259259259
dev_label=P_precision_tok: 0.9298486932599724
dev_label=P_recall_tok: 0.6313823163138231
dev_label=P_f-score_tok: 0.7520860374559614
dev_precision_macro_tok: 0.8610150463779213
dev_recall_macro_tok: 0.741018170577581
dev_f-score_macro_tok: 0.7886896005825949
dev_precision_micro_tok: 0.8922628560684404
dev_recall_micro_tok: 0.8922628560684404
dev_f-score_micro_tok: 0.8922628560684405
dev_time: 5.110976696014404
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5471    0.9369    0.6908       428
           P     0.7717    0.6396    0.6995       444

   micro avg     0.6222    0.6222    0.6222      1101
   macro avg     0.4396    0.5255    0.4634      1101
weighted avg     0.5239    0.6222    0.5506      1101

F1-macro sent:  0.46343039874181285
F1-micro sent:  0.6221616712079927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8996    0.9756    0.9361     16205
           N     0.7536    0.6160    0.6779      1857
           P     0.9298    0.6314    0.7521      3212

   micro avg     0.8923    0.8923    0.8923     21274
   macro avg     0.8610    0.7410    0.7887     21274
weighted avg     0.8914    0.8923    0.8857     21274

F1-macro tok:  0.7886896005825949
F1-micro tok:  0.8922628560684405
**************************************************
Best epoch: 11
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 325958.3316040039
train_cost_avg: 38.15055379260345
train_count_sent: 8544.0
train_total_correct_sent: 5396.0
train_accuracy_sent: 0.6315543071161048
train_count_tok: 163566.0
train_total_correct_tok: 144719.0
train_accuracy_tok: 0.8847743418558869
train_label=O_precision_sent: 0.35714285714285715
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006105006105006106
train_label=N_precision_sent: 0.5948040109389243
train_label=N_recall_sent: 0.7885196374622356
train_label=N_f-score_sent: 0.6780982073265783
train_label=P_precision_sent: 0.6714147754707871
train_label=P_recall_sent: 0.7703601108033241
train_label=P_f-score_sent: 0.7174922600619196
train_precision_macro_sent: 0.5411205478508562
train_recall_macro_sent: 0.5206528553331833
train_f-score_macro_sent: 0.4672318244978347
train_precision_micro_sent: 0.6315543071161048
train_recall_micro_sent: 0.6315543071161048
train_f-score_micro_sent: 0.6315543071161048
train_label=O_precision_tok: 0.8956244201150492
train_label=O_recall_tok: 0.9703732297522256
train_label=O_f-score_tok: 0.9315016674901185
train_label=N_precision_tok: 0.7757258360896729
train_label=N_recall_tok: 0.5944937332770033
train_label=N_f-score_tok: 0.6731244518855138
train_label=P_precision_tok: 0.869465946427577
train_label=P_recall_tok: 0.6240956149818123
train_label=P_f-score_tok: 0.726625401405501
train_precision_macro_tok: 0.8469387342107665
train_recall_macro_tok: 0.7296541926703471
train_f-score_macro_tok: 0.7770838402603778
train_precision_micro_tok: 0.8847743418558869
train_recall_micro_tok: 0.8847743418558869
train_f-score_micro_tok: 0.8847743418558869
train_time: 97.90984869003296
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3571    0.0031    0.0061      1624
           N     0.5948    0.7885    0.6781      3310
           P     0.6714    0.7704    0.7175      3610

   micro avg     0.6316    0.6316    0.6316      8544
   macro avg     0.5411    0.5207    0.4672      8544
weighted avg     0.5820    0.6316    0.5670      8544

F1-macro sent:  0.4672318244978347
F1-micro sent:  0.6315543071161048
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8956    0.9704    0.9315    124347
           N     0.7757    0.5945    0.6731     14202
           P     0.8695    0.6241    0.7266     25017

   micro avg     0.8848    0.8848    0.8848    163566
   macro avg     0.8469    0.7297    0.7771    163566
weighted avg     0.8812    0.8848    0.8777    163566

F1-macro tok:  0.7770838402603778
F1-micro tok:  0.8847743418558869
**************************************************
dev_cost_sum: 43790.090759277344
dev_cost_avg: 39.773016130133826
dev_count_sent: 1101.0
dev_total_correct_sent: 672.0
dev_accuracy_sent: 0.6103542234332425
dev_count_tok: 21274.0
dev_total_correct_tok: 19014.0
dev_accuracy_tok: 0.8937670395788286
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.699228791773779
dev_label=N_recall_sent: 0.6355140186915887
dev_label=N_f-score_sent: 0.6658506731946144
dev_label=P_precision_sent: 0.5625879043600562
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.6926406926406926
dev_precision_macro_sent: 0.420605565377945
dev_recall_macro_sent: 0.5121383065308299
dev_f-score_macro_sent: 0.4528304552784357
dev_precision_micro_sent: 0.6103542234332425
dev_recall_micro_sent: 0.6103542234332425
dev_f-score_micro_sent: 0.6103542234332425
dev_label=O_precision_tok: 0.8991138377641446
dev_label=O_recall_tok: 0.9767355754396791
dev_label=O_f-score_tok: 0.9363187316986601
dev_label=N_precision_tok: 0.809811320754717
dev_label=N_recall_tok: 0.5778136779752289
dev_label=N_f-score_tok: 0.6744186046511628
dev_label=P_precision_tok: 0.9010660980810234
dev_label=P_recall_tok: 0.6578455790784558
dev_label=P_f-score_tok: 0.7604822746086017
dev_precision_macro_tok: 0.8699970855332949
dev_recall_macro_tok: 0.7374649441644546
dev_f-score_macro_tok: 0.7904065369861416
dev_precision_micro_tok: 0.8937670395788286
dev_recall_micro_tok: 0.8937670395788286
dev_f-score_micro_tok: 0.8937670395788286
dev_time: 5.166264533996582
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6992    0.6355    0.6659       428
           P     0.5626    0.9009    0.6926       444

   micro avg     0.6104    0.6104    0.6104      1101
   macro avg     0.4206    0.5121    0.4528      1101
weighted avg     0.4987    0.6104    0.5382      1101

F1-macro sent:  0.4528304552784357
F1-micro sent:  0.6103542234332425
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9767    0.9363     16205
           N     0.8098    0.5778    0.6744      1857
           P     0.9011    0.6578    0.7605      3212

   micro avg     0.8938    0.8938    0.8938     21274
   macro avg     0.8700    0.7375    0.7904     21274
weighted avg     0.8916    0.8938    0.8869     21274

F1-macro tok:  0.7904065369861416
F1-micro tok:  0.8937670395788286
**************************************************
Best epoch: 11
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 323985.5189819336
train_cost_avg: 37.919653438896724
train_count_sent: 8544.0
train_total_correct_sent: 5422.0
train_accuracy_sent: 0.6345973782771536
train_count_tok: 163566.0
train_total_correct_tok: 144909.0
train_accuracy_tok: 0.8859359524595576
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6088186748408394
train_label=N_recall_sent: 0.7800604229607251
train_label=N_f-score_sent: 0.6838829294133228
train_label=P_precision_sent: 0.6600046479200558
train_label=P_recall_sent: 0.7867036011080333
train_label=P_f-score_sent: 0.717806141791988
train_precision_macro_sent: 0.42294110758696507
train_recall_macro_sent: 0.5222546746895861
train_f-score_macro_sent: 0.46722969040177026
train_precision_micro_sent: 0.6345973782771536
train_recall_micro_sent: 0.6345973782771536
train_f-score_micro_sent: 0.6345973782771536
train_label=O_precision_tok: 0.8970616649079263
train_label=O_recall_tok: 0.970783372337089
train_label=O_f-score_tok: 0.932467662882899
train_label=N_precision_tok: 0.7741668961718535
train_label=N_recall_tok: 0.5937896070975919
train_label=N_f-score_tok: 0.672086072922893
train_label=P_precision_tok: 0.8704920748881648
train_label=P_recall_tok: 0.6300515649358436
train_label=P_f-score_tok: 0.7310082552638901
train_precision_macro_tok: 0.8472402119893149
train_recall_macro_tok: 0.7315415147901749
train_f-score_macro_tok: 0.778520663689894
train_precision_micro_tok: 0.8859359524595576
train_recall_micro_tok: 0.8859359524595576
train_f-score_micro_tok: 0.8859359524595576
train_time: 97.85476160049438
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6088    0.7801    0.6839      3310
           P     0.6600    0.7867    0.7178      3610

   micro avg     0.6346    0.6346    0.6346      8544
   macro avg     0.4229    0.5223    0.4672      8544
weighted avg     0.5147    0.6346    0.5682      8544

F1-macro sent:  0.46722969040177026
F1-micro sent:  0.6345973782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8971    0.9708    0.9325    124347
           N     0.7742    0.5938    0.6721     14202
           P     0.8705    0.6301    0.7310     25017

   micro avg     0.8859    0.8859    0.8859    163566
   macro avg     0.8472    0.7315    0.7785    163566
weighted avg     0.8823    0.8859    0.8790    163566

F1-macro tok:  0.778520663689894
F1-micro tok:  0.8859359524595576
**************************************************
dev_cost_sum: 43504.15838623047
dev_cost_avg: 39.51331370229833
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 19061.0
dev_accuracy_tok: 0.8959763091097114
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5714285714285714
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.6953339432753888
dev_label=P_precision_sent: 0.7155963302752294
dev_label=P_recall_sent: 0.7027027027027027
dev_label=P_f-score_sent: 0.7090909090909091
dev_precision_macro_sent: 0.42900830056793354
dev_recall_macro_sent: 0.5301843899974741
dev_f-score_macro_sent: 0.46814161745543265
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.896559490962329
dev_label=O_recall_tok: 0.9825362542425178
dev_label=O_f-score_tok: 0.9375809680838535
dev_label=N_precision_tok: 0.8212634822804314
dev_label=N_recall_tok: 0.5740441572428648
dev_label=N_f-score_tok: 0.6757527733755943
dev_label=P_precision_tok: 0.9350473612990527
dev_label=P_recall_tok: 0.6453922789539228
dev_label=P_f-score_tok: 0.7636765518511697
dev_precision_macro_tok: 0.8842901115139378
dev_recall_macro_tok: 0.7339908968131018
dev_f-score_macro_tok: 0.7923367644368725
dev_precision_micro_tok: 0.8959763091097114
dev_recall_micro_tok: 0.8959763091097114
dev_f-score_micro_tok: 0.8959763091097114
dev_time: 5.138193607330322
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5714    0.8879    0.6953       428
           P     0.7156    0.7027    0.7091       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.4290    0.5302    0.4681      1101
weighted avg     0.5107    0.6285    0.5563      1101

F1-macro sent:  0.46814161745543265
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9825    0.9376     16205
           N     0.8213    0.5740    0.6758      1857
           P     0.9350    0.6454    0.7637      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8843    0.7340    0.7923     21274
weighted avg     0.8958    0.8960    0.8885     21274

F1-macro tok:  0.7923367644368725
F1-micro tok:  0.8959763091097114
**************************************************
Best epoch: 11
**************************************************

EPOCH: 17
Learning rate: 0.810000
train_cost_sum: 321867.75146484375
train_cost_avg: 37.67178739054819
train_count_sent: 8544.0
train_total_correct_sent: 5428.0
train_accuracy_sent: 0.6352996254681648
train_count_tok: 163566.0
train_total_correct_tok: 145270.0
train_accuracy_tok: 0.888143012606532
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.585055986218777
train_label=N_recall_sent: 0.820845921450151
train_label=N_f-score_sent: 0.6831782750817198
train_label=P_precision_sent: 0.6951282051282052
train_label=P_recall_sent: 0.7509695290858726
train_label=P_f-score_sent: 0.7219707057256991
train_precision_macro_sent: 0.42672806378232736
train_recall_macro_sent: 0.5239384835120079
train_f-score_macro_sent: 0.468382993602473
train_precision_micro_sent: 0.6352996254681648
train_recall_micro_sent: 0.6352996254681648
train_f-score_micro_sent: 0.6352996254681648
train_label=O_precision_tok: 0.8986943421493137
train_label=O_recall_tok: 0.9714589013003933
train_label=O_f-score_tok: 0.9336610476035895
train_label=N_precision_tok: 0.7845798707294552
train_label=N_recall_tok: 0.5982960146458245
train_label=N_f-score_tok: 0.6788910194950464
train_label=P_precision_tok: 0.8719502210578025
train_label=P_recall_tok: 0.6385657752728144
train_label=P_f-score_tok: 0.7372282984909317
train_precision_macro_tok: 0.851741477978857
train_recall_macro_tok: 0.7361068970730106
train_f-score_macro_tok: 0.7832601218631892
train_precision_micro_tok: 0.888143012606532
train_recall_micro_tok: 0.888143012606532
train_f-score_micro_tok: 0.888143012606532
train_time: 98.45334553718567
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5851    0.8208    0.6832      3310
           P     0.6951    0.7510    0.7220      3610

   micro avg     0.6353    0.6353    0.6353      8544
   macro avg     0.4267    0.5239    0.4684      8544
weighted avg     0.5204    0.6353    0.5697      8544

F1-macro sent:  0.468382993602473
F1-micro sent:  0.6352996254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8987    0.9715    0.9337    124347
           N     0.7846    0.5983    0.6789     14202
           P     0.8720    0.6386    0.7372     25017

   micro avg     0.8881    0.8881    0.8881    163566
   macro avg     0.8517    0.7361    0.7833    163566
weighted avg     0.8847    0.8881    0.8815    163566

F1-macro tok:  0.7832601218631892
F1-micro tok:  0.888143012606532
**************************************************
dev_cost_sum: 43425.43017578125
dev_cost_avg: 39.441807607430746
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 19024.0
dev_accuracy_tok: 0.894237096925825
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6519916142557652
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.6872928176795581
dev_label=P_precision_sent: 0.6137820512820513
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7172284644194756
dev_precision_macro_sent: 0.42192455517927224
dev_recall_macro_sent: 0.529749375543768
dev_f-score_macro_sent: 0.4681737606996779
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8956644144144145
dev_label=O_recall_tok: 0.9816106140080222
dev_label=O_f-score_tok: 0.936670101575151
dev_label=N_precision_tok: 0.829444891391794
dev_label=N_recall_tok: 0.5551965535810447
dev_label=N_f-score_tok: 0.6651612903225805
dev_label=P_precision_tok: 0.9185380889476001
dev_label=P_recall_tok: 0.6494396014943961
dev_label=P_f-score_tok: 0.7608973189859566
dev_precision_macro_tok: 0.8812157982512696
dev_recall_macro_tok: 0.7287489230278209
dev_f-score_macro_tok: 0.7875762369612294
dev_precision_micro_tok: 0.894237096925825
dev_recall_micro_tok: 0.894237096925825
dev_f-score_micro_tok: 0.894237096925825
dev_time: 5.105264186859131
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6520    0.7266    0.6873       428
           P     0.6138    0.8626    0.7172       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4219    0.5297    0.4682      1101
weighted avg     0.5010    0.6303    0.5564      1101

F1-macro sent:  0.4681737606996779
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8957    0.9816    0.9367     16205
           N     0.8294    0.5552    0.6652      1857
           P     0.9185    0.6494    0.7609      3212

   micro avg     0.8942    0.8942    0.8942     21274
   macro avg     0.8812    0.7287    0.7876     21274
weighted avg     0.8933    0.8942    0.8864     21274

F1-macro tok:  0.7875762369612294
F1-micro tok:  0.894237096925825
**************************************************
Best epoch: 11
**************************************************

EPOCH: 18
Learning rate: 0.729000
train_cost_sum: 320135.9073486328
train_cost_avg: 37.46909027956845
train_count_sent: 8544.0
train_total_correct_sent: 5465.0
train_accuracy_sent: 0.639630149812734
train_count_tok: 163566.0
train_total_correct_tok: 145467.0
train_accuracy_tok: 0.8893474193903378
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6006360745115856
train_label=N_recall_sent: 0.7987915407854985
train_label=N_f-score_sent: 0.6856846473029046
train_label=P_precision_sent: 0.6810719459198454
train_label=P_recall_sent: 0.7814404432132964
train_label=P_f-score_sent: 0.7278121775025799
train_precision_macro_sent: 0.427236006810477
train_recall_macro_sent: 0.526743994666265
train_f-score_macro_sent: 0.4711656082684948
train_precision_micro_sent: 0.639630149812734
train_recall_micro_sent: 0.639630149812734
train_f-score_micro_sent: 0.639630149812734
train_label=O_precision_tok: 0.8999843562601032
train_label=O_recall_tok: 0.9715795314724118
train_label=O_f-score_tok: 0.9344125358681443
train_label=N_precision_tok: 0.7848916296363472
train_label=N_recall_tok: 0.6094212082805238
train_label=N_f-score_tok: 0.6861151849062587
train_label=P_precision_tok: 0.8742622950819672
train_label=P_recall_tok: 0.6395251229164168
train_label=P_f-score_tok: 0.7386938153611745
train_precision_macro_tok: 0.8530460936594725
train_recall_macro_tok: 0.7401752875564509
train_f-score_macro_tok: 0.7864071787118592
train_precision_micro_tok: 0.8893474193903378
train_recall_micro_tok: 0.8893474193903378
train_f-score_micro_tok: 0.8893474193903378
train_time: 97.8891544342041
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6006    0.7988    0.6857      3310
           P     0.6811    0.7814    0.7278      3610

   micro avg     0.6396    0.6396    0.6396      8544
   macro avg     0.4272    0.5267    0.4712      8544
weighted avg     0.5205    0.6396    0.5732      8544

F1-macro sent:  0.4711656082684948
F1-micro sent:  0.639630149812734
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9000    0.9716    0.9344    124347
           N     0.7849    0.6094    0.6861     14202
           P     0.8743    0.6395    0.7387     25017

   micro avg     0.8893    0.8893    0.8893    163566
   macro avg     0.8530    0.7402    0.7864    163566
weighted avg     0.8861    0.8893    0.8829    163566

F1-macro tok:  0.7864071787118592
F1-micro tok:  0.8893474193903378
**************************************************
dev_cost_sum: 43230.68029785156
dev_cost_avg: 39.26492306798507
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 19056.0
dev_accuracy_tok: 0.8957412804362133
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5781487101669196
dev_label=N_recall_sent: 0.8901869158878505
dev_label=N_f-score_sent: 0.7010119595216192
dev_label=P_precision_sent: 0.7239819004524887
dev_label=P_recall_sent: 0.7207207207207207
dev_label=P_f-score_sent: 0.7223476297968396
dev_precision_macro_sent: 0.4340435368731361
dev_recall_macro_sent: 0.5369692122028571
dev_f-score_macro_sent: 0.4744531964394863
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.9013779751736705
dev_label=O_recall_tok: 0.9768589941376119
dev_label=O_f-score_tok: 0.9376018005745255
dev_label=N_precision_tok: 0.7858627858627859
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6872727272727274
dev_label=P_precision_tok: 0.9219920669898634
dev_label=P_recall_tok: 0.651307596513076
dev_label=P_f-score_tok: 0.7633643495712462
dev_precision_macro_tok: 0.8697442760087734
dev_recall_macro_tok: 0.7462763164312202
dev_f-score_macro_tok: 0.7960796258061663
dev_precision_micro_tok: 0.8957412804362133
dev_recall_micro_tok: 0.8957412804362133
dev_f-score_micro_tok: 0.8957412804362133
dev_time: 5.138906955718994
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5781    0.8902    0.7010       428
           P     0.7240    0.7207    0.7223       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4340    0.5370    0.4745      1101
weighted avg     0.5167    0.6367    0.5638      1101

F1-macro sent:  0.4744531964394863
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9014    0.9769    0.9376     16205
           N     0.7859    0.6107    0.6873      1857
           P     0.9220    0.6513    0.7634      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8697    0.7463    0.7961     21274
weighted avg     0.8944    0.8957    0.8894     21274

F1-macro tok:  0.7960796258061663
F1-micro tok:  0.8957412804362133
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 0.729000
train_cost_sum: 318550.7562866211
train_cost_avg: 37.28356229946408
train_count_sent: 8544.0
train_total_correct_sent: 5513.0
train_accuracy_sent: 0.6452481273408239
train_count_tok: 163566.0
train_total_correct_tok: 145911.0
train_accuracy_tok: 0.8920619199589157
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.623718887262079
train_label=N_recall_sent: 0.7722054380664652
train_label=N_f-score_sent: 0.6900647948164147
train_label=P_precision_sent: 0.6650922177237967
train_label=P_recall_sent: 0.8191135734072023
train_label=P_f-score_sent: 0.7341112214498511
train_precision_macro_sent: 0.42960370166195855
train_recall_macro_sent: 0.5304396704912225
train_f-score_macro_sent: 0.47472533875542194
train_precision_micro_sent: 0.6452481273408239
train_recall_micro_sent: 0.6452481273408239
train_f-score_micro_sent: 0.6452481273408239
train_label=O_precision_tok: 0.9026118511438982
train_label=O_recall_tok: 0.9721585562981013
train_label=O_f-score_tok: 0.9360952473139096
train_label=N_precision_tok: 0.7899091644932098
train_label=N_recall_tok: 0.6184340233769892
train_label=N_f-score_tok: 0.6937324750207339
train_label=P_precision_tok: 0.8770991954209191
train_label=P_recall_tok: 0.6492784906263741
train_label=P_f-score_tok: 0.7461870635795663
train_precision_macro_tok: 0.8565400703526757
train_recall_macro_tok: 0.7466236901004882
train_f-score_macro_tok: 0.7920049286380699
train_precision_micro_tok: 0.8920619199589157
train_recall_micro_tok: 0.8920619199589157
train_f-score_micro_tok: 0.8920619199589157
train_time: 97.71328616142273
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6237    0.7722    0.6901      3310
           P     0.6651    0.8191    0.7341      3610

   micro avg     0.6452    0.6452    0.6452      8544
   macro avg     0.4296    0.5304    0.4747      8544
weighted avg     0.5226    0.6452    0.5775      8544

F1-macro sent:  0.47472533875542194
F1-micro sent:  0.6452481273408239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9026    0.9722    0.9361    124347
           N     0.7899    0.6184    0.6937     14202
           P     0.8771    0.6493    0.7462     25017

   micro avg     0.8921    0.8921    0.8921    163566
   macro avg     0.8565    0.7466    0.7920    163566
weighted avg     0.8889    0.8921    0.8860    163566

F1-macro tok:  0.7920049286380699
F1-micro tok:  0.8920619199589157
**************************************************
dev_cost_sum: 43168.42639160156
dev_cost_avg: 39.2083800105373
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 19034.0
dev_accuracy_tok: 0.8947071542728213
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6856492027334852
dev_label=N_recall_sent: 0.7032710280373832
dev_label=N_f-score_sent: 0.6943483275663206
dev_label=P_precision_sent: 0.5936555891238671
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.7106690777576854
dev_precision_macro_sent: 0.42643493061911747
dev_recall_macro_sent: 0.5294687210575061
dev_f-score_macro_sent: 0.46833913510800196
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.9072522392372147
dev_label=O_recall_tok: 0.9688367787719839
dev_label=O_f-score_tok: 0.9370337212772307
dev_label=N_precision_tok: 0.7794624396967609
dev_label=N_recall_tok: 0.6090468497576736
dev_label=N_f-score_tok: 0.6837968561064086
dev_label=P_precision_tok: 0.874900714853058
dev_label=P_recall_tok: 0.685865504358655
dev_label=P_f-score_tok: 0.7689354275741711
dev_precision_macro_tok: 0.8538717979290111
dev_recall_macro_tok: 0.7545830442961042
dev_f-score_macro_tok: 0.7965886683192701
dev_precision_micro_tok: 0.8947071542728213
dev_recall_micro_tok: 0.8947071542728213
dev_f-score_micro_tok: 0.8947071542728212
dev_time: 4.940862417221069
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6856    0.7033    0.6943       428
           P     0.5937    0.8851    0.7107       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4264    0.5295    0.4683      1101
weighted avg     0.5059    0.6303    0.5565      1101

F1-macro sent:  0.46833913510800196
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9073    0.9688    0.9370     16205
           N     0.7795    0.6090    0.6838      1857
           P     0.8749    0.6859    0.7689      3212

   micro avg     0.8947    0.8947    0.8947     21274
   macro avg     0.8539    0.7546    0.7966     21274
weighted avg     0.8912    0.8947    0.8895     21274

F1-macro tok:  0.7965886683192701
F1-micro tok:  0.8947071542728212
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 0.729000
train_cost_sum: 317354.0107421875
train_cost_avg: 37.1434937666418
train_count_sent: 8544.0
train_total_correct_sent: 5520.0
train_accuracy_sent: 0.6460674157303371
train_count_tok: 163566.0
train_total_correct_tok: 145942.0
train_accuracy_tok: 0.8922514458995146
train_label=O_precision_sent: 0.6
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003683241252302025
train_label=N_precision_sent: 0.6205091601237211
train_label=N_recall_sent: 0.7879154078549849
train_label=N_f-score_sent: 0.6942632769865568
train_label=P_precision_sent: 0.6708948339483395
train_label=P_recall_sent: 0.8058171745152355
train_label=P_f-score_sent: 0.7321922980115783
train_precision_macro_sent: 0.6304679980240202
train_recall_macro_sent: 0.5318599576702049
train_f-score_macro_sent: 0.47671293875014564
train_precision_micro_sent: 0.6460674157303371
train_recall_micro_sent: 0.6460674157303371
train_f-score_micro_sent: 0.6460674157303371
train_label=O_precision_tok: 0.9029917659189742
train_label=O_recall_tok: 0.9718851279081924
train_label=O_f-score_tok: 0.9361726850542836
train_label=N_precision_tok: 0.7890863399748699
train_label=N_recall_tok: 0.6190677369384594
train_label=N_f-score_tok: 0.6938131313131314
train_label=P_precision_tok: 0.876761699838623
train_label=P_recall_tok: 0.6515169684614462
train_label=P_f-score_tok: 0.7475405324833169
train_precision_macro_tok: 0.8562799352441557
train_recall_macro_tok: 0.7474899444360327
train_f-score_macro_tok: 0.792508782950244
train_precision_micro_tok: 0.8922514458995146
train_recall_micro_tok: 0.8922514458995146
train_f-score_micro_tok: 0.8922514458995146
train_time: 97.50552868843079
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0018    0.0037      1624
           N     0.6205    0.7879    0.6943      3310
           P     0.6709    0.8058    0.7322      3610

   micro avg     0.6461    0.6461    0.6461      8544
   macro avg     0.6305    0.5319    0.4767      8544
weighted avg     0.6379    0.6461    0.5790      8544

F1-macro sent:  0.47671293875014564
F1-micro sent:  0.6460674157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9030    0.9719    0.9362    124347
           N     0.7891    0.6191    0.6938     14202
           P     0.8768    0.6515    0.7475     25017

   micro avg     0.8923    0.8923    0.8923    163566
   macro avg     0.8563    0.7475    0.7925    163566
weighted avg     0.8891    0.8923    0.8863    163566

F1-macro tok:  0.792508782950244
F1-micro tok:  0.8922514458995146
**************************************************
dev_cost_sum: 43026.23864746094
dev_cost_avg: 39.07923582875653
dev_count_sent: 1101.0
dev_total_correct_sent: 674.0
dev_accuracy_sent: 0.6121707538601272
dev_count_tok: 21274.0
dev_total_correct_tok: 19082.0
dev_accuracy_tok: 0.8969634295384037
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6767676767676768
dev_label=N_recall_sent: 0.6261682242990654
dev_label=N_f-score_sent: 0.6504854368932038
dev_label=P_precision_sent: 0.5758865248226951
dev_label=P_recall_sent: 0.9144144144144144
dev_label=P_f-score_sent: 0.7067014795474327
dev_precision_macro_sent: 0.41755140053012396
dev_recall_macro_sent: 0.5135275462378266
dev_f-score_macro_sent: 0.4523956388135455
dev_precision_micro_sent: 0.6121707538601272
dev_recall_micro_sent: 0.6121707538601272
dev_f-score_micro_sent: 0.6121707538601272
dev_label=O_precision_tok: 0.9046011216664759
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9386858279640131
dev_label=N_precision_tok: 0.779054054054054
dev_label=N_recall_tok: 0.620893914916532
dev_label=N_f-score_tok: 0.6910398561582259
dev_label=P_precision_tok: 0.9146551724137931
dev_label=P_recall_tok: 0.6606475716064757
dev_label=P_f-score_tok: 0.767172812725958
dev_precision_macro_tok: 0.8661034493781078
dev_recall_macro_tok: 0.7523270552114644
dev_f-score_macro_tok: 0.7989661656160657
dev_precision_micro_tok: 0.8969634295384037
dev_recall_micro_tok: 0.8969634295384037
dev_f-score_micro_tok: 0.8969634295384037
dev_time: 5.067416667938232
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6768    0.6262    0.6505       428
           P     0.5759    0.9144    0.7067       444

   micro avg     0.6122    0.6122    0.6122      1101
   macro avg     0.4176    0.5135    0.4524      1101
weighted avg     0.4953    0.6122    0.5379      1101

F1-macro sent:  0.4523956388135455
F1-micro sent:  0.6121707538601272
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9754    0.9387     16205
           N     0.7791    0.6209    0.6910      1857
           P     0.9147    0.6606    0.7672      3212

   micro avg     0.8970    0.8970    0.8970     21274
   macro avg     0.8661    0.7523    0.7990     21274
weighted avg     0.8952    0.8970    0.8912     21274

F1-macro tok:  0.7989661656160657
F1-micro tok:  0.8969634295384037
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 315978.7770385742
train_cost_avg: 36.98253476575073
train_count_sent: 8544.0
train_total_correct_sent: 5520.0
train_accuracy_sent: 0.6460674157303371
train_count_tok: 163566.0
train_total_correct_tok: 146128.0
train_accuracy_tok: 0.893388601543108
train_label=O_precision_sent: 0.75
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036855036855036856
train_label=N_precision_sent: 0.6320895522388059
train_label=N_recall_sent: 0.7676737160120846
train_label=N_f-score_sent: 0.6933151432469303
train_label=P_precision_sent: 0.6584070796460177
train_label=P_recall_sent: 0.824376731301939
train_label=P_f-score_sent: 0.7321033210332103
train_precision_macro_sent: 0.6801655439616079
train_recall_macro_sent: 0.5312992459848059
train_f-score_macro_sent: 0.47636798932188146
train_precision_micro_sent: 0.6460674157303371
train_recall_micro_sent: 0.6460674157303371
train_f-score_micro_sent: 0.6460674157303371
train_label=O_precision_tok: 0.9042148747960665
train_label=O_recall_tok: 0.971659951587091
train_label=O_f-score_tok: 0.9367249553240893
train_label=N_precision_tok: 0.7897408495858936
train_label=N_recall_tok: 0.6244190959019856
train_label=N_f-score_tok: 0.6974165388698832
train_label=P_precision_tok: 0.8782794549826343
train_label=P_recall_tok: 0.6570332174121597
train_label=P_f-score_tok: 0.7517149913107107
train_precision_macro_tok: 0.8574117264548647
train_recall_macro_tok: 0.7510374216337454
train_f-score_macro_tok: 0.7952854951682277
train_precision_micro_tok: 0.893388601543108
train_recall_micro_tok: 0.893388601543108
train_f-score_micro_tok: 0.893388601543108
train_time: 97.73659634590149
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0018    0.0037      1624
           N     0.6321    0.7677    0.6933      3310
           P     0.6584    0.8244    0.7321      3610

   micro avg     0.6461    0.6461    0.6461      8544
   macro avg     0.6802    0.5313    0.4764      8544
weighted avg     0.6656    0.6461    0.5786      8544

F1-macro sent:  0.47636798932188146
F1-micro sent:  0.6460674157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9717    0.9367    124347
           N     0.7897    0.6244    0.6974     14202
           P     0.8783    0.6570    0.7517     25017

   micro avg     0.8934    0.8934    0.8934    163566
   macro avg     0.8574    0.7510    0.7953    163566
weighted avg     0.8903    0.8934    0.8876    163566

F1-macro tok:  0.7952854951682277
F1-micro tok:  0.893388601543108
**************************************************
dev_cost_sum: 42919.82019042969
dev_cost_avg: 38.98257964616684
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 19105.0
dev_accuracy_tok: 0.8980445614364952
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034188034188034185
dev_label=N_precision_sent: 0.6317757009345795
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7019730010384216
dev_label=P_precision_sent: 0.6506238859180036
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7263681592039802
dev_precision_macro_sent: 0.6941331956175277
dev_recall_macro_sent: 0.5430863157161978
dev_f-score_macro_sent: 0.48750973147681204
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.9027556365292644
dev_label=O_recall_tok: 0.9784634372107375
dev_label=O_f-score_tok: 0.9390861440966567
dev_label=N_precision_tok: 0.8035971223021583
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.688019710502002
dev_label=P_precision_tok: 0.9189655172413793
dev_label=P_recall_tok: 0.663760896637609
dev_label=P_f-score_tok: 0.7707881417208966
dev_precision_macro_tok: 0.8751060920242674
dev_recall_macro_tok: 0.7479107140470974
dev_f-score_macro_tok: 0.7992979987731852
dev_precision_micro_tok: 0.8980445614364952
dev_recall_micro_tok: 0.8980445614364952
dev_f-score_micro_tok: 0.8980445614364952
dev_time: 5.1864073276519775
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0175    0.0342       229
           N     0.6318    0.7897    0.7020       428
           P     0.6506    0.8221    0.7264       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6941    0.5431    0.4875      1101
weighted avg     0.6744    0.6421    0.5729      1101

F1-macro sent:  0.48750973147681204
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9028    0.9785    0.9391     16205
           N     0.8036    0.6015    0.6880      1857
           P     0.9190    0.6638    0.7708      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8751    0.7479    0.7993     21274
weighted avg     0.8965    0.8980    0.8918     21274

F1-macro tok:  0.7992979987731852
F1-micro tok:  0.8980445614364952
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.729000
train_cost_sum: 314640.7398071289
train_cost_avg: 36.82592928454224
train_count_sent: 8544.0
train_total_correct_sent: 5532.0
train_accuracy_sent: 0.6474719101123596
train_count_tok: 163566.0
train_total_correct_tok: 146346.0
train_accuracy_tok: 0.8947213968673197
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6105047748976807
train_label=N_recall_sent: 0.8111782477341389
train_label=N_f-score_sent: 0.6966787752983912
train_label=P_precision_sent: 0.6880135331077816
train_label=P_recall_sent: 0.7886426592797784
train_label=P_f-score_sent: 0.7348993288590605
train_precision_macro_sent: 0.4328394360018208
train_recall_macro_sent: 0.5332736356713058
train_f-score_macro_sent: 0.4771927013858172
train_precision_micro_sent: 0.6474719101123596
train_recall_micro_sent: 0.6474719101123596
train_f-score_micro_sent: 0.6474719101123596
train_label=O_precision_tok: 0.9056750822448536
train_label=O_recall_tok: 0.9719253379655319
train_label=O_f-score_tok: 0.9376314054075022
train_label=N_precision_tok: 0.7929652715939448
train_label=N_recall_tok: 0.6270243627658076
train_label=N_f-score_tok: 0.7002988361119848
train_label=P_precision_tok: 0.8778383528290902
train_label=P_recall_tok: 0.6629491945477075
train_label=P_f-score_tok: 0.7554087907082669
train_precision_macro_tok: 0.8588262355559628
train_recall_macro_tok: 0.753966298426349
train_f-score_macro_tok: 0.7977796774092513
train_precision_micro_tok: 0.8947213968673197
train_recall_micro_tok: 0.8947213968673197
train_f-score_micro_tok: 0.8947213968673197
train_time: 96.94180059432983
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6105    0.8112    0.6967      3310
           P     0.6880    0.7886    0.7349      3610

   micro avg     0.6475    0.6475    0.6475      8544
   macro avg     0.4328    0.5333    0.4772      8544
weighted avg     0.5272    0.6475    0.5804      8544

F1-macro sent:  0.4771927013858172
F1-micro sent:  0.6474719101123596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9057    0.9719    0.9376    124347
           N     0.7930    0.6270    0.7003     14202
           P     0.8778    0.6629    0.7554     25017

   micro avg     0.8947    0.8947    0.8947    163566
   macro avg     0.8588    0.7540    0.7978    163566
weighted avg     0.8916    0.8947    0.8892    163566

F1-macro tok:  0.7977796774092513
F1-micro tok:  0.8947213968673197
**************************************************
dev_cost_sum: 42785.42956542969
dev_cost_avg: 38.86051731646656
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5776119402985075
dev_label=N_recall_sent: 0.9042056074766355
dev_label=N_f-score_sent: 0.7049180327868851
dev_label=P_precision_sent: 0.740139211136891
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7291428571428571
dev_precision_macro_sent: 0.4392503838117994
dev_recall_macro_sent: 0.540891358648368
dev_f-score_macro_sent: 0.4780202966432474
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8999660326086957
dev_label=O_recall_tok: 0.9809935205183585
dev_label=O_f-score_tok: 0.9387345360063776
dev_label=N_precision_tok: 0.8106508875739645
dev_label=N_recall_tok: 0.5901992460958535
dev_label=N_f-score_tok: 0.6830788407603615
dev_label=P_precision_tok: 0.9300265721877768
dev_label=P_recall_tok: 0.6537982565379825
dev_label=P_f-score_tok: 0.7678244972577696
dev_precision_macro_tok: 0.8802144974568124
dev_recall_macro_tok: 0.7416636743840649
dev_f-score_macro_tok: 0.7965459580081696
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 5.0758442878723145
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5776    0.9042    0.7049       428
           P     0.7401    0.7185    0.7291       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.4393    0.5409    0.4780      1101
weighted avg     0.5230    0.6412    0.5681      1101

F1-macro sent:  0.4780202966432474
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9000    0.9810    0.9387     16205
           N     0.8107    0.5902    0.6831      1857
           P     0.9300    0.6538    0.7678      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8802    0.7417    0.7965     21274
weighted avg     0.8967    0.8975    0.8906     21274

F1-macro tok:  0.7965459580081696
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 313284.73443603516
train_cost_avg: 36.667220790734454
train_count_sent: 8544.0
train_total_correct_sent: 5616.0
train_accuracy_sent: 0.6573033707865169
train_count_tok: 163566.0
train_total_correct_tok: 146635.0
train_accuracy_tok: 0.8964882677329029
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6240166589541879
train_label=N_recall_sent: 0.8148036253776435
train_label=N_f-score_sent: 0.7067610062893083
train_label=P_precision_sent: 0.6915422885572139
train_label=P_recall_sent: 0.8085872576177285
train_label=P_f-score_sent: 0.7454986591750734
train_precision_macro_sent: 0.43851964917046726
train_recall_macro_sent: 0.5411302943317907
train_f-score_macro_sent: 0.4840865551547939
train_precision_micro_sent: 0.6573033707865169
train_recall_micro_sent: 0.6573033707865169
train_f-score_micro_sent: 0.6573033707865169
train_label=O_precision_tok: 0.906922511659993
train_label=O_recall_tok: 0.9726732450320474
train_label=O_f-score_tok: 0.9386478547509013
train_label=N_precision_tok: 0.8001063264221159
train_label=N_recall_tok: 0.6358259400084495
train_label=N_f-score_tok: 0.7085687382297552
train_label=P_precision_tok: 0.8804313352362829
train_label=P_recall_tok: 0.6657872646600311
train_label=P_f-score_tok: 0.7582109935131444
train_precision_macro_tok: 0.862486724439464
train_recall_macro_tok: 0.7580954832335093
train_f-score_macro_tok: 0.8018091954979335
train_precision_micro_tok: 0.8964882677329029
train_recall_micro_tok: 0.8964882677329029
train_f-score_micro_tok: 0.8964882677329029
train_time: 98.36897945404053
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6240    0.8148    0.7068      3310
           P     0.6915    0.8086    0.7455      3610

   micro avg     0.6573    0.6573    0.6573      8544
   macro avg     0.4385    0.5411    0.4841      8544
weighted avg     0.5339    0.6573    0.5888      8544

F1-macro sent:  0.4840865551547939
F1-micro sent:  0.6573033707865169
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9069    0.9727    0.9386    124347
           N     0.8001    0.6358    0.7086     14202
           P     0.8804    0.6658    0.7582     25017

   micro avg     0.8965    0.8965    0.8965    163566
   macro avg     0.8625    0.7581    0.8018    163566
weighted avg     0.8936    0.8965    0.8911    163566

F1-macro tok:  0.8018091954979335
F1-micro tok:  0.8964882677329029
**************************************************
dev_cost_sum: 42719.957763671875
dev_cost_avg: 38.80105155646855
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 19109.0
dev_accuracy_tok: 0.8982325843752937
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6198630136986302
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7154150197628459
dev_label=P_precision_sent: 0.6769825918762089
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.72840790842872
dev_precision_macro_sent: 0.4322818685249463
dev_recall_macro_sent: 0.5446942269372176
dev_f-score_macro_sent: 0.4812743093971887
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.9032938226578527
dev_label=O_recall_tok: 0.9781548904659055
dev_label=O_f-score_tok: 0.939235030960211
dev_label=N_precision_tok: 0.801423487544484
dev_label=N_recall_tok: 0.6063543349488422
dev_label=N_f-score_tok: 0.6903740036787247
dev_label=P_precision_tok: 0.918569582076691
dev_label=P_recall_tok: 0.663760896637609
dev_label=P_f-score_tok: 0.7706488342671245
dev_precision_macro_tok: 0.8744289640930093
dev_recall_macro_tok: 0.7494233740174522
dev_f-score_macro_tok: 0.80008595630202
dev_precision_micro_tok: 0.8982325843752937
dev_recall_micro_tok: 0.8982325843752937
dev_f-score_micro_tok: 0.8982325843752937
dev_time: 5.218750476837158
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6199    0.8458    0.7154       428
           P     0.6770    0.7883    0.7284       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.4323    0.5447    0.4813      1101
weighted avg     0.5140    0.6467    0.5719      1101

F1-macro sent:  0.4812743093971887
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9033    0.9782    0.9392     16205
           N     0.8014    0.6064    0.6904      1857
           P     0.9186    0.6638    0.7706      3212

   micro avg     0.8982    0.8982    0.8982     21274
   macro avg     0.8744    0.7494    0.8001     21274
weighted avg     0.8967    0.8982    0.8921     21274

F1-macro tok:  0.80008595630202
F1-micro tok:  0.8982325843752937
**************************************************
Best epoch: 21
**************************************************

EPOCH: 24
Learning rate: 0.729000
train_cost_sum: 311977.34979248047
train_cost_avg: 36.51420292514987
train_count_sent: 8544.0
train_total_correct_sent: 5555.0
train_accuracy_sent: 0.6501638576779026
train_count_tok: 163566.0
train_total_correct_tok: 146825.0
train_accuracy_tok: 0.8976498783365736
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6122448979591837
train_label=N_recall_sent: 0.8157099697885196
train_label=N_f-score_sent: 0.6994818652849741
train_label=P_precision_sent: 0.6906144170295113
train_label=P_recall_sent: 0.7908587257617729
train_label=P_f-score_sent: 0.737345041322314
train_precision_macro_sent: 0.434286438329565
train_recall_macro_sent: 0.5355228985167642
train_f-score_macro_sent: 0.47894230220242945
train_precision_micro_sent: 0.6501638576779026
train_recall_micro_sent: 0.6501638576779026
train_f-score_micro_sent: 0.6501638576779026
train_label=O_precision_tok: 0.9080616826078469
train_label=O_recall_tok: 0.9726973710664512
train_label=O_f-score_tok: 0.9392688656351317
train_label=N_precision_tok: 0.8014078310602728
train_label=N_recall_tok: 0.641318124207858
train_label=N_f-score_tok: 0.712480932451989
train_label=P_precision_tok: 0.8822291217176236
train_label=P_recall_tok: 0.6701443018747252
train_label=P_f-score_tok: 0.7616992276238074
train_precision_macro_tok: 0.863899545128581
train_recall_macro_tok: 0.7613865990496782
train_f-score_macro_tok: 0.8044830085703093
train_precision_micro_tok: 0.8976498783365736
train_recall_micro_tok: 0.8976498783365736
train_f-score_micro_tok: 0.8976498783365736
train_time: 97.87522792816162
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6122    0.8157    0.6995      3310
           P     0.6906    0.7909    0.7373      3610

   micro avg     0.6502    0.6502    0.6502      8544
   macro avg     0.4343    0.5355    0.4789      8544
weighted avg     0.5290    0.6502    0.5825      8544

F1-macro sent:  0.47894230220242945
F1-micro sent:  0.6501638576779026
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9727    0.9393    124347
           N     0.8014    0.6413    0.7125     14202
           P     0.8822    0.6701    0.7617     25017

   micro avg     0.8976    0.8976    0.8976    163566
   macro avg     0.8639    0.7614    0.8045    163566
weighted avg     0.8949    0.8976    0.8924    163566

F1-macro tok:  0.8044830085703093
F1-micro tok:  0.8976498783365736
**************************************************
dev_cost_sum: 42666.55114746094
dev_cost_avg: 38.75254418479649
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 19137.0
dev_accuracy_tok: 0.8995487449468835
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5965463108320251
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.7136150234741785
dev_label=P_precision_sent: 0.7112068965517241
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7268722466960353
dev_precision_macro_sent: 0.4359177357945831
dev_recall_macro_sent: 0.5436979035109876
dev_f-score_macro_sent: 0.48016242339007126
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.91192852169877
dev_label=O_recall_tok: 0.9699475470533786
dev_label=O_f-score_tok: 0.9400436589814899
dev_label=N_precision_tok: 0.7700258397932817
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.7001468428781203
dev_label=P_precision_tok: 0.8943775100401606
dev_label=P_recall_tok: 0.6933374844333748
dev_label=P_f-score_tok: 0.781129428270782
dev_precision_macro_tok: 0.8587772905107375
dev_recall_macro_tok: 0.7683935206373903
dev_f-score_macro_tok: 0.8071066433767974
dev_precision_micro_tok: 0.8995487449468835
dev_recall_micro_tok: 0.8995487449468835
dev_f-score_micro_tok: 0.8995487449468835
dev_time: 5.057924270629883
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5965    0.8879    0.7136       428
           P     0.7112    0.7432    0.7269       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.4359    0.5437    0.4802      1101
weighted avg     0.5187    0.6449    0.5705      1101

F1-macro sent:  0.48016242339007126
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9699    0.9400     16205
           N     0.7700    0.6419    0.7001      1857
           P     0.8944    0.6933    0.7811      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8588    0.7684    0.8071     21274
weighted avg     0.8969    0.8995    0.8951     21274

F1-macro tok:  0.8071066433767974
F1-micro tok:  0.8995487449468835
**************************************************
Best epoch: 21
**************************************************

EPOCH: 25
Learning rate: 0.729000
train_cost_sum: 310840.00091552734
train_cost_avg: 36.38108624947652
train_count_sent: 8544.0
train_total_correct_sent: 5585.0
train_accuracy_sent: 0.6536750936329588
train_count_tok: 163566.0
train_total_correct_tok: 147042.0
train_accuracy_tok: 0.898976559920766
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.001229256299938537
train_label=N_precision_sent: 0.6151046405823476
train_label=N_recall_sent: 0.8169184290030211
train_label=N_f-score_sent: 0.70179081235401
train_label=P_precision_sent: 0.6948130277442702
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.7427466150870405
train_precision_macro_sent: 0.5477503338866504
train_recall_macro_sent: 0.5384393753559417
train_f-score_macro_sent: 0.481922227913663
train_precision_micro_sent: 0.6536750936329588
train_recall_micro_sent: 0.6536750936329588
train_f-score_micro_sent: 0.6536750936329588
train_label=O_precision_tok: 0.9100135419801384
train_label=O_recall_tok: 0.9727536651467265
train_label=O_f-score_tok: 0.9403382478125838
train_label=N_precision_tok: 0.7994577575651566
train_label=N_recall_tok: 0.6436417405999155
train_label=N_f-score_tok: 0.7131377750039009
train_label=P_precision_tok: 0.8818446804080783
train_label=P_recall_tok: 0.6772194907462925
train_label=P_f-score_tok: 0.7661036876257659
train_precision_macro_tok: 0.8637719933177911
train_recall_macro_tok: 0.7645382988309781
train_f-score_macro_tok: 0.8065265701474168
train_precision_micro_tok: 0.898976559920766
train_recall_micro_tok: 0.898976559920766
train_f-score_micro_tok: 0.898976559920766
train_time: 97.92859268188477
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0006    0.0012      1624
           N     0.6151    0.8169    0.7018      3310
           P     0.6948    0.7978    0.7427      3610

   micro avg     0.6537    0.6537    0.6537      8544
   macro avg     0.5478    0.5384    0.4819      8544
weighted avg     0.5952    0.6537    0.5859      8544

F1-macro sent:  0.481922227913663
F1-micro sent:  0.6536750936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9100    0.9728    0.9403    124347
           N     0.7995    0.6436    0.7131     14202
           P     0.8818    0.6772    0.7661     25017

   micro avg     0.8990    0.8990    0.8990    163566
   macro avg     0.8638    0.7645    0.8065    163566
weighted avg     0.8961    0.8990    0.8940    163566

F1-macro tok:  0.8065265701474168
F1-micro tok:  0.898976559920766
**************************************************
dev_cost_sum: 42531.93981933594
dev_cost_avg: 38.630281398125284
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 19148.0
dev_accuracy_tok: 0.9000658080285795
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5964343598055105
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7043062200956937
dev_label=P_precision_sent: 0.7024793388429752
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7327586206896551
dev_precision_macro_sent: 0.43297123288282857
dev_recall_macro_sent: 0.5418596166259717
dev_f-score_macro_sent: 0.47902161359511625
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.9074052812858783
dev_label=O_recall_tok: 0.9754396791113854
dev_label=O_f-score_tok: 0.9401933085501859
dev_label=N_precision_tok: 0.7773333333333333
dev_label=N_recall_tok: 0.6278944534194938
dev_label=N_f-score_tok: 0.6946678582067322
dev_label=P_precision_tok: 0.9239592183517417
dev_label=P_recall_tok: 0.677148194271482
dev_label=P_f-score_tok: 0.7815307222421847
dev_precision_macro_tok: 0.8695659443236511
dev_recall_macro_tok: 0.7601607756007871
dev_f-score_macro_tok: 0.8054639629997009
dev_precision_micro_tok: 0.9000658080285795
dev_recall_micro_tok: 0.9000658080285795
dev_f-score_micro_tok: 0.9000658080285795
dev_time: 5.127411842346191
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5964    0.8598    0.7043       428
           P     0.7025    0.7658    0.7328       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.4330    0.5419    0.4790      1101
weighted avg     0.5151    0.6431    0.5693      1101

F1-macro sent:  0.47902161359511625
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9754    0.9402     16205
           N     0.7773    0.6279    0.6947      1857
           P     0.9240    0.6771    0.7815      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8696    0.7602    0.8055     21274
weighted avg     0.8986    0.9001    0.8948     21274

F1-macro tok:  0.8054639629997009
F1-micro tok:  0.9000658080285795
**************************************************
Best epoch: 21
**************************************************

EPOCH: 26
Learning rate: 0.656100
train_cost_sum: 309257.4242553711
train_cost_avg: 36.19585958045074
train_count_sent: 8544.0
train_total_correct_sent: 5643.0
train_accuracy_sent: 0.6604634831460674
train_count_tok: 163566.0
train_total_correct_tok: 147179.0
train_accuracy_tok: 0.8998141423034127
train_label=O_precision_sent: 0.3392857142857143
train_label=O_recall_sent: 0.011699507389162561
train_label=O_f-score_sent: 0.022619047619047615
train_label=N_precision_sent: 0.6275098084468036
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7115007196127177
train_label=P_precision_sent: 0.6991576413959085
train_label=P_recall_sent: 0.8047091412742382
train_label=P_f-score_sent: 0.7482292337411461
train_precision_macro_sent: 0.5553177213761421
train_recall_macro_sent: 0.5459529332402675
train_f-score_macro_sent: 0.49411633365763713
train_precision_micro_sent: 0.6604634831460674
train_recall_micro_sent: 0.6604634831460674
train_f-score_micro_sent: 0.6604634831460674
train_label=O_precision_tok: 0.9109386771131536
train_label=O_recall_tok: 0.9724239426765423
train_label=O_f-score_tok: 0.9406776694270811
train_label=N_precision_tok: 0.8017061281337048
train_label=N_recall_tok: 0.6485002112378538
train_label=N_f-score_tok: 0.7170105099260413
train_label=P_precision_tok: 0.8817354431688903
train_label=P_recall_tok: 0.6815765279609866
train_label=P_f-score_tok: 0.7688422951189269
train_precision_macro_tok: 0.8647934161385828
train_recall_macro_tok: 0.7675002272917942
train_f-score_macro_tok: 0.8088434914906831
train_precision_micro_tok: 0.8998141423034127
train_recall_micro_tok: 0.8998141423034127
train_f-score_micro_tok: 0.8998141423034127
train_time: 98.84219336509705
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3393    0.0117    0.0226      1624
           N     0.6275    0.8215    0.7115      3310
           P     0.6992    0.8047    0.7482      3610

   micro avg     0.6605    0.6605    0.6605      8544
   macro avg     0.5553    0.5460    0.4941      8544
weighted avg     0.6030    0.6605    0.5961      8544

F1-macro sent:  0.49411633365763713
F1-micro sent:  0.6604634831460674
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9724    0.9407    124347
           N     0.8017    0.6485    0.7170     14202
           P     0.8817    0.6816    0.7688     25017

   micro avg     0.8998    0.8998    0.8998    163566
   macro avg     0.8648    0.7675    0.8088    163566
weighted avg     0.8970    0.8998    0.8950    163566

F1-macro tok:  0.8088434914906831
F1-micro tok:  0.8998141423034127
**************************************************
dev_cost_sum: 42541.69079589844
dev_cost_avg: 38.63913787093409
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 19136.0
dev_accuracy_tok: 0.8995017392121839
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6708074534161491
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.7113062568605928
dev_label=P_precision_sent: 0.6260162601626016
dev_label=P_recall_sent: 0.8671171171171171
dev_label=P_f-score_sent: 0.7271010387157696
dev_precision_macro_sent: 0.6544967934151391
dev_recall_macro_sent: 0.5442866957885527
dev_f-score_macro_sent: 0.48521622496223576
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.9083165467625899
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.9399642644431209
dev_label=N_precision_tok: 0.7938504542278128
dev_label=N_recall_tok: 0.6117393645665051
dev_label=N_f-score_tok: 0.6909975669099757
dev_label=P_precision_tok: 0.8987034035656402
dev_label=P_recall_tok: 0.6905354919053549
dev_label=P_f-score_tok: 0.7809859154929578
dev_precision_macro_tok: 0.8669568015186809
dev_recall_macro_tok: 0.7587239339530286
dev_f-score_macro_tok: 0.8039825822820181
dev_precision_micro_tok: 0.8995017392121839
dev_recall_micro_tok: 0.8995017392121839
dev_f-score_micro_tok: 0.8995017392121839
dev_time: 5.183014631271362
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6708    0.7570    0.7113       428
           P     0.6260    0.8671    0.7271       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.6545    0.5443    0.4852      1101
weighted avg     0.6519    0.6458    0.5733      1101

F1-macro sent:  0.48521622496223576
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9739    0.9400     16205
           N     0.7939    0.6117    0.6910      1857
           P     0.8987    0.6905    0.7810      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8670    0.7587    0.8040     21274
weighted avg     0.8969    0.8995    0.8942     21274

F1-macro tok:  0.8039825822820181
F1-micro tok:  0.8995017392121839
**************************************************
Best epoch: 21
**************************************************

EPOCH: 27
Learning rate: 0.590490
train_cost_sum: 308325.087890625
train_cost_avg: 36.086737814913974
train_count_sent: 8544.0
train_total_correct_sent: 5640.0
train_accuracy_sent: 0.6601123595505618
train_count_tok: 163566.0
train_total_correct_tok: 147375.0
train_accuracy_tok: 0.9010124353471993
train_label=O_precision_sent: 0.3716216216216216
train_label=O_recall_sent: 0.033866995073891626
train_label=O_f-score_sent: 0.062076749435665914
train_label=N_precision_sent: 0.6342217991432652
train_label=N_recall_sent: 0.8051359516616314
train_label=N_f-score_sent: 0.7095314164004259
train_label=P_precision_sent: 0.6962327134000954
train_label=P_recall_sent: 0.8088642659279779
train_label=P_f-score_sent: 0.7483341875961046
train_precision_macro_sent: 0.5673587113883274
train_recall_macro_sent: 0.5492890708878336
train_f-score_macro_sent: 0.5066474511440654
train_precision_micro_sent: 0.6601123595505618
train_recall_micro_sent: 0.6601123595505618
train_f-score_micro_sent: 0.6601123595505618
train_label=O_precision_tok: 0.9122152084888798
train_label=O_recall_tok: 0.9727375811237907
train_label=O_f-score_tok: 0.9415047636839156
train_label=N_precision_tok: 0.8012987012987013
train_label=N_recall_tok: 0.6516687790452049
train_label=N_f-score_tok: 0.7187791239515378
train_label=P_precision_tok: 0.8838251197281013
train_label=P_recall_tok: 0.6860534836311308
train_label=P_f-score_tok: 0.772481771536592
train_precision_macro_tok: 0.8657796765052274
train_recall_macro_tok: 0.7701532812667088
train_f-score_macro_tok: 0.8109218863906817
train_precision_micro_tok: 0.9010124353471993
train_recall_micro_tok: 0.9010124353471993
train_f-score_micro_tok: 0.9010124353471993
train_time: 98.17327404022217
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3716    0.0339    0.0621      1624
           N     0.6342    0.8051    0.7095      3310
           P     0.6962    0.8089    0.7483      3610

   micro avg     0.6601    0.6601    0.6601      8544
   macro avg     0.5674    0.5493    0.5066      8544
weighted avg     0.6105    0.6601    0.6029      8544

F1-macro sent:  0.5066474511440654
F1-micro sent:  0.6601123595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9122    0.9727    0.9415    124347
           N     0.8013    0.6517    0.7188     14202
           P     0.8838    0.6861    0.7725     25017

   micro avg     0.9010    0.9010    0.9010    163566
   macro avg     0.8658    0.7702    0.8109    163566
weighted avg     0.8982    0.9010    0.8963    163566

F1-macro tok:  0.8109218863906817
F1-micro tok:  0.9010124353471993
**************************************************
dev_cost_sum: 42419.59313964844
dev_cost_avg: 38.52824081711938
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19153.0
dev_accuracy_tok: 0.9003008367020776
dev_label=O_precision_sent: 0.45
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07228915662650603
dev_label=N_precision_sent: 0.6468401486988847
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7204968944099378
dev_label=P_precision_sent: 0.6703499079189686
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7375886524822695
dev_precision_macro_sent: 0.5890633522059511
dev_recall_macro_sent: 0.5574017473376736
dev_f-score_macro_sent: 0.5101249011729044
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9090961460913647
dev_label=O_recall_tok: 0.9738352360382598
dev_label=O_f-score_tok: 0.9403527589083542
dev_label=N_precision_tok: 0.7740667976424361
dev_label=N_recall_tok: 0.6365105008077544
dev_label=N_f-score_tok: 0.6985815602836879
dev_label=P_precision_tok: 0.9170854271356784
dev_label=P_recall_tok: 0.6818181818181818
dev_label=P_f-score_tok: 0.7821428571428571
dev_precision_macro_tok: 0.8667494569564931
dev_recall_macro_tok: 0.764054639554732
dev_f-score_macro_tok: 0.8070257254449663
dev_precision_micro_tok: 0.9003008367020776
dev_recall_micro_tok: 0.9003008367020776
dev_f-score_micro_tok: 0.9003008367020775
dev_time: 5.149061441421509
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4500    0.0393    0.0723       229
           N     0.6468    0.8131    0.7205       428
           P     0.6703    0.8198    0.7376       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.5891    0.5574    0.5101      1101
weighted avg     0.6154    0.6549    0.5926      1101

F1-macro sent:  0.5101249011729044
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9091    0.9738    0.9404     16205
           N     0.7741    0.6365    0.6986      1857
           P     0.9171    0.6818    0.7821      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8667    0.7641    0.8070     21274
weighted avg     0.8985    0.9003    0.8954     21274

F1-macro tok:  0.8070257254449663
F1-micro tok:  0.9003008367020775
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 0.590490
train_cost_sum: 307157.4548339844
train_cost_avg: 35.95007664255435
train_count_sent: 8544.0
train_total_correct_sent: 5603.0
train_accuracy_sent: 0.6557818352059925
train_count_tok: 163566.0
train_total_correct_tok: 147653.0
train_accuracy_tok: 0.9027120550725701
train_label=O_precision_sent: 0.36792452830188677
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.04508670520231213
train_label=N_precision_sent: 0.6182232346241457
train_label=N_recall_sent: 0.8199395770392749
train_label=N_f-score_sent: 0.704935064935065
train_label=P_precision_sent: 0.7040513833992095
train_label=P_recall_sent: 0.7894736842105263
train_label=P_f-score_sent: 0.7443196657090624
train_precision_macro_sent: 0.5633997154417473
train_recall_macro_sent: 0.5444760131916414
train_f-score_macro_sent: 0.49811381194881316
train_precision_micro_sent: 0.6557818352059925
train_recall_micro_sent: 0.6557818352059925
train_f-score_micro_sent: 0.6557818352059925
train_label=O_precision_tok: 0.9139745943944443
train_label=O_recall_tok: 0.9726732450320474
train_label=O_f-score_tok: 0.9424107838553841
train_label=N_precision_tok: 0.810815465426677
train_label=N_recall_tok: 0.6630052105337276
train_label=N_f-score_tok: 0.7294983536703467
train_label=P_precision_tok: 0.8811416921508665
train_label=P_recall_tok: 0.6910500859415597
train_label=P_f-score_tok: 0.7746040280484799
train_precision_macro_tok: 0.8686439173239959
train_recall_macro_tok: 0.7755761805024449
train_f-score_macro_tok: 0.815504388524737
train_precision_micro_tok: 0.9027120550725701
train_recall_micro_tok: 0.9027120550725701
train_f-score_micro_tok: 0.9027120550725701
train_time: 97.21559977531433
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3679    0.0240    0.0451      1624
           N     0.6182    0.8199    0.7049      3310
           P     0.7041    0.7895    0.7443      3610

   micro avg     0.6558    0.6558    0.6558      8544
   macro avg     0.5634    0.5445    0.4981      8544
weighted avg     0.6069    0.6558    0.5962      8544

F1-macro sent:  0.49811381194881316
F1-micro sent:  0.6557818352059925
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9140    0.9727    0.9424    124347
           N     0.8108    0.6630    0.7295     14202
           P     0.8811    0.6911    0.7746     25017

   micro avg     0.9027    0.9027    0.9027    163566
   macro avg     0.8686    0.7756    0.8155    163566
weighted avg     0.9000    0.9027    0.8983    163566

F1-macro tok:  0.815504388524737
F1-micro tok:  0.9027120550725701
**************************************************
dev_cost_sum: 42381.53125
dev_cost_avg: 38.49367052679382
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 19156.0
dev_accuracy_tok: 0.9004418539061766
dev_label=O_precision_sent: 0.29292929292929293
dev_label=O_recall_sent: 0.12663755458515283
dev_label=O_f-score_sent: 0.17682926829268292
dev_label=N_precision_sent: 0.6410748560460653
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7038988408851422
dev_label=P_precision_sent: 0.7068607068607069
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7351351351351352
dev_precision_macro_sent: 0.546954951945355
dev_recall_macro_sent: 0.5575923840422065
dev_f-score_macro_sent: 0.5386210814376534
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.9073649191235517
dev_label=O_recall_tok: 0.9761801912989818
dev_label=O_f-score_tok: 0.9405154731115668
dev_label=N_precision_tok: 0.7756452680344142
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6959619952494062
dev_label=P_precision_tok: 0.9295835122370116
dev_label=P_recall_tok: 0.6740348692403487
dev_label=P_f-score_tok: 0.7814473921674788
dev_precision_macro_tok: 0.8708645664649924
dev_recall_macro_tok: 0.7604468439098073
dev_f-score_macro_tok: 0.8059749535094839
dev_precision_micro_tok: 0.9004418539061766
dev_recall_micro_tok: 0.9004418539061766
dev_f-score_micro_tok: 0.9004418539061767
dev_time: 5.325506687164307
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2929    0.1266    0.1768       229
           N     0.6411    0.7804    0.7039       428
           P     0.7069    0.7658    0.7351       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.5470    0.5576    0.5386      1101
weighted avg     0.5952    0.6385    0.6069      1101

F1-macro sent:  0.5386210814376534
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9762    0.9405     16205
           N     0.7756    0.6311    0.6960      1857
           P     0.9296    0.6740    0.7814      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8709    0.7604    0.8060     21274
weighted avg     0.8992    0.9004    0.8952     21274

F1-macro tok:  0.8059749535094839
F1-micro tok:  0.9004418539061767
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.590490
train_cost_sum: 306200.5073852539
train_cost_avg: 35.838074366251625
train_count_sent: 8544.0
train_total_correct_sent: 5631.0
train_accuracy_sent: 0.6590589887640449
train_count_tok: 163566.0
train_total_correct_tok: 147762.0
train_accuracy_tok: 0.9033784527346759
train_label=O_precision_sent: 0.34299516908212563
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.07755324959038777
train_label=N_precision_sent: 0.634610806950726
train_label=N_recall_sent: 0.8054380664652568
train_label=N_f-score_sent: 0.7098921581680203
train_label=P_precision_sent: 0.6997098646034816
train_label=P_recall_sent: 0.8016620498614958
train_label=P_f-score_sent: 0.7472243738703848
train_precision_macro_sent: 0.5591052802121111
train_recall_macro_sent: 0.5502731093831376
train_f-score_macro_sent: 0.5115565938762643
train_precision_micro_sent: 0.6590589887640449
train_recall_micro_sent: 0.6590589887640449
train_f-score_micro_sent: 0.6590589887640449
train_label=O_precision_tok: 0.9146962077961359
train_label=O_recall_tok: 0.972793875204066
train_label=O_f-score_tok: 0.942850907276922
train_label=N_precision_tok: 0.807426376440461
train_label=N_recall_tok: 0.6660329531051965
train_label=N_f-score_tok: 0.7299455955550412
train_label=P_precision_tok: 0.8843721309803122
train_label=P_recall_tok: 0.6930886996842147
train_label=P_f-score_tok: 0.7771328686999978
train_precision_macro_tok: 0.8688315717389697
train_recall_macro_tok: 0.7773051759978257
train_f-score_macro_tok: 0.816643123843987
train_precision_micro_tok: 0.9033784527346759
train_recall_micro_tok: 0.9033784527346759
train_f-score_micro_tok: 0.9033784527346759
train_time: 98.32952284812927
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3430    0.0437    0.0776      1624
           N     0.6346    0.8054    0.7099      3310
           P     0.6997    0.8017    0.7472      3610

   micro avg     0.6591    0.6591    0.6591      8544
   macro avg     0.5591    0.5503    0.5116      8544
weighted avg     0.6067    0.6591    0.6055      8544

F1-macro sent:  0.5115565938762643
F1-micro sent:  0.6590589887640449
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9728    0.9429    124347
           N     0.8074    0.6660    0.7299     14202
           P     0.8844    0.6931    0.7771     25017

   micro avg     0.9034    0.9034    0.9034    163566
   macro avg     0.8688    0.7773    0.8166    163566
weighted avg     0.9007    0.9034    0.8990    163566

F1-macro tok:  0.816643123843987
F1-micro tok:  0.9033784527346759
**************************************************
dev_cost_sum: 42363.82940673828
dev_cost_avg: 38.4775925583454
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 19135.0
dev_accuracy_tok: 0.8994547334774843
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.6916299559471366
dev_label=N_recall_sent: 0.7336448598130841
dev_label=N_f-score_sent: 0.7120181405895691
dev_label=P_precision_sent: 0.6105919003115264
dev_label=P_recall_sent: 0.8828828828828829
dev_label=P_f-score_sent: 0.721915285451197
dev_precision_macro_sent: 0.5674072854195544
dev_recall_macro_sent: 0.5417537890500385
dev_f-score_macro_sent: 0.4836758143782611
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.9117647058823529
dev_label=O_recall_tok: 0.9698858377044122
dev_label=O_f-score_tok: 0.9399276380707472
dev_label=N_precision_tok: 0.7970813064628214
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6959951456310679
dev_label=P_precision_tok: 0.8744705429341548
dev_label=P_recall_tok: 0.7070361145703612
dev_label=P_f-score_tok: 0.7818901704252024
dev_precision_macro_tok: 0.861105518426443
dev_recall_macro_tok: 0.7648616164735692
dev_f-score_macro_tok: 0.8059376513756725
dev_precision_micro_tok: 0.8994547334774843
dev_recall_micro_tok: 0.8994547334774843
dev_f-score_micro_tok: 0.8994547334774842
dev_time: 5.135282754898071
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.6916    0.7336    0.7120       428
           P     0.6106    0.8829    0.7219       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.5674    0.5418    0.4837      1101
weighted avg     0.5983    0.6431    0.5715      1101

F1-macro sent:  0.4836758143782611
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9118    0.9699    0.9399     16205
           N     0.7971    0.6177    0.6960      1857
           P     0.8745    0.7070    0.7819      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8611    0.7649    0.8059     21274
weighted avg     0.8961    0.8995    0.8948     21274

F1-macro tok:  0.8059376513756725
F1-micro tok:  0.8994547334774842
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.590490
train_cost_sum: 304963.3887939453
train_cost_avg: 35.69328052363592
train_count_sent: 8544.0
train_total_correct_sent: 5683.0
train_accuracy_sent: 0.6651451310861424
train_count_tok: 163566.0
train_total_correct_tok: 148111.0
train_accuracy_tok: 0.9055121480014184
train_label=O_precision_sent: 0.3404255319148936
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.019150209455415918
train_label=N_precision_sent: 0.6298265895953757
train_label=N_recall_sent: 0.8229607250755288
train_label=N_f-score_sent: 0.7135559921414539
train_label=P_precision_sent: 0.7054170661553212
train_label=P_recall_sent: 0.8152354570637119
train_label=P_f-score_sent: 0.756360832690825
train_precision_macro_sent: 0.5585563958885301
train_recall_macro_sent: 0.549349466296003
train_f-score_macro_sent: 0.49635567809589826
train_precision_micro_sent: 0.6651451310861424
train_recall_micro_sent: 0.6651451310861424
train_f-score_micro_sent: 0.6651451310861424
train_label=O_precision_tok: 0.917258274930979
train_label=O_recall_tok: 0.9725606568714967
train_label=O_f-score_tok: 0.9441003001666726
train_label=N_precision_tok: 0.8154067309318451
train_label=N_recall_tok: 0.6789888748063653
train_label=N_f-score_tok: 0.7409712617181496
train_label=P_precision_tok: 0.8812324085243265
train_label=P_recall_tok: 0.7008434264700004
train_label=P_f-score_tok: 0.7807539019882884
train_precision_macro_tok: 0.8712991381290501
train_recall_macro_tok: 0.7841309860492874
train_f-score_macro_tok: 0.8219418212910369
train_precision_micro_tok: 0.9055121480014184
train_recall_micro_tok: 0.9055121480014184
train_f-score_micro_tok: 0.9055121480014184
train_time: 98.33747339248657
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3404    0.0099    0.0192      1624
           N     0.6298    0.8230    0.7136      3310
           P     0.7054    0.8152    0.7564      3610

   micro avg     0.6651    0.6651    0.6651      8544
   macro avg     0.5586    0.5493    0.4964      8544
weighted avg     0.6068    0.6651    0.5997      8544

F1-macro sent:  0.49635567809589826
F1-micro sent:  0.6651451310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9173    0.9726    0.9441    124347
           N     0.8154    0.6790    0.7410     14202
           P     0.8812    0.7008    0.7808     25017

   micro avg     0.9055    0.9055    0.9055    163566
   macro avg     0.8713    0.7841    0.8219    163566
weighted avg     0.9029    0.9055    0.9015    163566

F1-macro tok:  0.8219418212910369
F1-micro tok:  0.9055121480014184
**************************************************
dev_cost_sum: 42370.55944824219
dev_cost_avg: 38.483705220928414
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19156.0
dev_accuracy_tok: 0.9004418539061766
dev_label=O_precision_sent: 0.25
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008583690987124463
dev_label=N_precision_sent: 0.6402214022140221
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7154639175257731
dev_label=P_precision_sent: 0.6648648648648648
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7387387387387387
dev_precision_macro_sent: 0.5183620890262957
dev_recall_macro_sent: 0.5487318522865191
dev_f-score_macro_sent: 0.48759544908387875
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9080677576801608
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9407495538370018
dev_label=N_precision_tok: 0.801859799713877
dev_label=N_recall_tok: 0.6036618201400108
dev_label=N_f-score_tok: 0.6887864823348695
dev_label=P_precision_tok: 0.9024786672084518
dev_label=P_recall_tok: 0.6914694894146949
dev_label=P_f-score_tok: 0.7830072272166403
dev_precision_macro_tok: 0.8708020748674965
dev_recall_macro_tok: 0.7570009847029519
dev_f-score_macro_tok: 0.8041810877961705
dev_precision_micro_tok: 0.9004418539061766
dev_recall_micro_tok: 0.9004418539061766
dev_f-score_micro_tok: 0.9004418539061767
dev_time: 5.16340708732605
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0044    0.0086       229
           N     0.6402    0.8107    0.7155       428
           P     0.6649    0.8311    0.7387       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.5184    0.5487    0.4876      1101
weighted avg     0.5690    0.6512    0.5778      1101

F1-macro sent:  0.48759544908387875
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9759    0.9407     16205
           N     0.8019    0.6037    0.6888      1857
           P     0.9025    0.6915    0.7830      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8708    0.7570    0.8042     21274
weighted avg     0.8980    0.9004    0.8949     21274

F1-macro tok:  0.8041810877961705
F1-micro tok:  0.9004418539061767
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.590490
train_cost_sum: 304207.4118652344
train_cost_avg: 35.60480007785983
train_count_sent: 8544.0
train_total_correct_sent: 5680.0
train_accuracy_sent: 0.6647940074906367
train_count_tok: 163566.0
train_total_correct_tok: 148009.0
train_accuracy_tok: 0.9048885465194478
train_label=O_precision_sent: 0.36363636363636365
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009720534629404618
train_label=N_precision_sent: 0.6241534988713319
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7144702842377262
train_label=P_precision_sent: 0.7104105571847508
train_label=P_recall_sent: 0.8052631578947368
train_label=P_f-score_sent: 0.7548688652298103
train_precision_macro_sent: 0.5660668065641488
train_recall_macro_sent: 0.5485122327644301
train_f-score_macro_sent: 0.4930198946989804
train_precision_micro_sent: 0.6647940074906367
train_recall_micro_sent: 0.6647940074906367
train_f-score_micro_sent: 0.6647940074906367
train_label=O_precision_tok: 0.9166224512999318
train_label=O_recall_tok: 0.9725204468141572
train_label=O_f-score_tok: 0.9437444639979398
train_label=N_precision_tok: 0.8129373613244582
train_label=N_recall_tok: 0.6707505985072525
train_label=N_f-score_tok: 0.7350308641975308
train_label=P_precision_tok: 0.8812631790340396
train_label=P_recall_tok: 0.701642882839669
train_label=P_f-score_tok: 0.7812618226326916
train_precision_macro_tok: 0.8702743305528099
train_recall_macro_tok: 0.7816379760536929
train_f-score_macro_tok: 0.8200123836093874
train_precision_micro_tok: 0.9048885465194478
train_recall_micro_tok: 0.9048885465194478
train_f-score_micro_tok: 0.904888546519448
train_time: 98.43854093551636
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3636    0.0049    0.0097      1624
           N     0.6242    0.8353    0.7145      3310
           P     0.7104    0.8053    0.7549      3610

   micro avg     0.6648    0.6648    0.6648      8544
   macro avg     0.5661    0.5485    0.4930      8544
weighted avg     0.6111    0.6648    0.5976      8544

F1-macro sent:  0.4930198946989804
F1-micro sent:  0.6647940074906367
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9166    0.9725    0.9437    124347
           N     0.8129    0.6708    0.7350     14202
           P     0.8813    0.7016    0.7813     25017

   micro avg     0.9049    0.9049    0.9049    163566
   macro avg     0.8703    0.7816    0.8200    163566
weighted avg     0.9022    0.9049    0.9008    163566

F1-macro tok:  0.8200123836093874
F1-micro tok:  0.904888546519448
**************************************************
dev_cost_sum: 42285.395263671875
dev_cost_avg: 38.40635355465202
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 19173.0
dev_accuracy_tok: 0.9012409513960703
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6435452793834296
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7053854276663146
dev_label=P_precision_sent: 0.6493955094991365
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7350928641251222
dev_precision_macro_sent: 0.6532024851830776
dev_recall_macro_sent: 0.5453181010255654
dev_f-score_macro_sent: 0.4859065570339272
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.9063428571428571
dev_label=O_recall_tok: 0.9787719839555693
dev_label=O_f-score_tok: 0.9411659991099244
dev_label=N_precision_tok: 0.8181148748159057
dev_label=N_recall_tok: 0.5982767905223478
dev_label=N_f-score_tok: 0.6911353032659409
dev_label=P_precision_tok: 0.9110099337748344
dev_label=P_recall_tok: 0.6852428393524284
dev_label=P_f-score_tok: 0.7821606254442075
dev_precision_macro_tok: 0.8784892219111992
dev_recall_macro_tok: 0.7540972046101152
dev_f-score_macro_tok: 0.8048206426066908
dev_precision_micro_tok: 0.9012409513960703
dev_recall_micro_tok: 0.9012409513960703
dev_f-score_micro_tok: 0.9012409513960703
dev_time: 5.065009832382202
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6435    0.7804    0.7054       428
           P     0.6494    0.8468    0.7351       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.6532    0.5453    0.4859      1101
weighted avg     0.6507    0.6467    0.5742      1101

F1-macro sent:  0.4859065570339272
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9788    0.9412     16205
           N     0.8181    0.5983    0.6911      1857
           P     0.9110    0.6852    0.7822      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8785    0.7541    0.8048     21274
weighted avg     0.8993    0.9012    0.8953     21274

F1-macro tok:  0.8048206426066908
F1-micro tok:  0.9012409513960703
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.590490
train_cost_sum: 303175.9084472656
train_cost_avg: 35.484071681561986
train_count_sent: 8544.0
train_total_correct_sent: 5670.0
train_accuracy_sent: 0.663623595505618
train_count_tok: 163566.0
train_total_correct_tok: 148297.0
train_accuracy_tok: 0.9066493036450118
train_label=O_precision_sent: 0.30612244897959184
train_label=O_recall_sent: 0.01847290640394089
train_label=O_f-score_sent: 0.03484320557491289
train_label=N_precision_sent: 0.6284403669724771
train_label=N_recall_sent: 0.8277945619335347
train_label=N_f-score_sent: 0.7144719687092568
train_label=P_precision_sent: 0.7097405775819873
train_label=P_recall_sent: 0.8033240997229917
train_label=P_f-score_sent: 0.7536382536382535
train_precision_macro_sent: 0.5481011311780187
train_recall_macro_sent: 0.5498638560201558
train_f-score_macro_sent: 0.5009844759741411
train_precision_micro_sent: 0.663623595505618
train_recall_micro_sent: 0.663623595505618
train_f-score_micro_sent: 0.663623595505618
train_label=O_precision_tok: 0.918028931857662
train_label=O_recall_tok: 0.9732522698577368
train_label=O_f-score_tok: 0.9448343703888764
train_label=N_precision_tok: 0.8158967391304348
train_label=N_recall_tok: 0.6765244331784256
train_label=N_f-score_tok: 0.7397028254677035
train_label=P_precision_tok: 0.8850373190402244
train_label=P_recall_tok: 0.7062397569652636
train_label=P_f-score_tok: 0.7855935971542909
train_precision_macro_tok: 0.8729876633427738
train_recall_macro_tok: 0.7853388200004753
train_f-score_macro_tok: 0.8233769310036236
train_precision_micro_tok: 0.9066493036450118
train_recall_micro_tok: 0.9066493036450118
train_f-score_micro_tok: 0.9066493036450118
train_time: 98.10503053665161
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3061    0.0185    0.0348      1624
           N     0.6284    0.8278    0.7145      3310
           P     0.7097    0.8033    0.7536      3610

   micro avg     0.6636    0.6636    0.6636      8544
   macro avg     0.5481    0.5499    0.5010      8544
weighted avg     0.6015    0.6636    0.6018      8544

F1-macro sent:  0.5009844759741411
F1-micro sent:  0.663623595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9180    0.9733    0.9448    124347
           N     0.8159    0.6765    0.7397     14202
           P     0.8850    0.7062    0.7856     25017

   micro avg     0.9066    0.9066    0.9066    163566
   macro avg     0.8730    0.7853    0.8234    163566
weighted avg     0.9041    0.9066    0.9027    163566

F1-macro tok:  0.8233769310036236
F1-micro tok:  0.9066493036450118
**************************************************
dev_cost_sum: 42239.22772216797
dev_cost_avg: 38.36442118271387
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19166.0
dev_accuracy_tok: 0.9009119112531729
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05106382978723404
dev_label=N_precision_sent: 0.6121112929623568
dev_label=N_recall_sent: 0.8738317757009346
dev_label=N_f-score_sent: 0.7199230028873919
dev_label=P_precision_sent: 0.7128099173553719
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7435344827586207
dev_precision_macro_sent: 0.7749737367725761
dev_recall_macro_sent: 0.5590198920301357
dev_f-score_macro_sent: 0.5048404384777488
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9103555760794274
dev_label=O_recall_tok: 0.9732181425485961
dev_label=O_f-score_tok: 0.9407378687106683
dev_label=N_precision_tok: 0.787940379403794
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.697869786978698
dev_label=P_precision_tok: 0.9021827000808408
dev_label=P_recall_tok: 0.6948941469489415
dev_label=P_f-score_tok: 0.7850861765740416
dev_precision_macro_tok: 0.866826218521354
dev_recall_macro_tok: 0.7647970780105776
dev_f-score_macro_tok: 0.8078979440878026
dev_precision_micro_tok: 0.9009119112531729
dev_recall_micro_tok: 0.9009119112531729
dev_f-score_micro_tok: 0.9009119112531729
dev_time: 5.167775392532349
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0262    0.0511       229
           N     0.6121    0.8738    0.7199       428
           P     0.7128    0.7770    0.7435       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.7750    0.5590    0.5048      1101
weighted avg     0.7334    0.6585    0.5903      1101

F1-macro sent:  0.5048404384777488
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9104    0.9732    0.9407     16205
           N     0.7879    0.6263    0.6979      1857
           P     0.9022    0.6949    0.7851      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8668    0.7648    0.8079     21274
weighted avg     0.8984    0.9009    0.8960     21274

F1-macro tok:  0.8078979440878026
F1-micro tok:  0.9009119112531729
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.531441
train_cost_sum: 302369.2498779297
train_cost_avg: 35.389659395825106
train_count_sent: 8544.0
train_total_correct_sent: 5681.0
train_accuracy_sent: 0.6649110486891385
train_count_tok: 163566.0
train_total_correct_tok: 148466.0
train_accuracy_tok: 0.9076825257082768
train_label=O_precision_sent: 0.3673469387755102
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11261730969760166
train_label=N_precision_sent: 0.6373496816788493
train_label=N_recall_sent: 0.8166163141993957
train_label=N_f-score_sent: 0.7159316646801748
train_label=P_precision_sent: 0.7158892491893241
train_label=P_recall_sent: 0.7950138504155124
train_label=P_f-score_sent: 0.7533797086231789
train_precision_macro_sent: 0.5735286232145612
train_recall_macro_sent: 0.5593775425563651
train_f-score_macro_sent: 0.5273095610003184
train_precision_micro_sent: 0.6649110486891385
train_recall_micro_sent: 0.6649110486891385
train_f-score_micro_sent: 0.6649110486891385
train_label=O_precision_tok: 0.919543812963315
train_label=O_recall_tok: 0.97262499296324
train_label=O_f-score_tok: 0.9453398574287144
train_label=N_precision_tok: 0.813947654486161
train_label=N_recall_tok: 0.6853964230390086
train_label=N_f-score_tok: 0.7441611559191162
train_label=P_precision_tok: 0.8858181456030276
train_label=P_recall_tok: 0.7110764680017588
train_label=P_f-score_tok: 0.7888866715448236
train_precision_macro_tok: 0.8731032043508344
train_recall_macro_tok: 0.7896992946680025
train_f-score_macro_tok: 0.8261292282975514
train_precision_micro_tok: 0.9076825257082768
train_recall_micro_tok: 0.9076825257082768
train_f-score_micro_tok: 0.9076825257082768
train_time: 98.73562550544739
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3673    0.0665    0.1126      1624
           N     0.6373    0.8166    0.7159      3310
           P     0.7159    0.7950    0.7534      3610

   micro avg     0.6649    0.6649    0.6649      8544
   macro avg     0.5735    0.5594    0.5273      8544
weighted avg     0.6192    0.6649    0.6171      8544

F1-macro sent:  0.5273095610003184
F1-micro sent:  0.6649110486891385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9195    0.9726    0.9453    124347
           N     0.8139    0.6854    0.7442     14202
           P     0.8858    0.7111    0.7889     25017

   micro avg     0.9077    0.9077    0.9077    163566
   macro avg     0.8731    0.7897    0.8261    163566
weighted avg     0.9052    0.9077    0.9039    163566

F1-macro tok:  0.8261292282975514
F1-micro tok:  0.9076825257082768
**************************************************
dev_cost_sum: 42251.604064941406
dev_cost_avg: 38.37566218432462
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19185.0
dev_accuracy_tok: 0.9018050202124659
dev_label=O_precision_sent: 0.46875
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11494252873563217
dev_label=N_precision_sent: 0.6679920477137177
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.7218045112781956
dev_label=P_precision_sent: 0.6678445229681979
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.7485148514851485
dev_precision_macro_sent: 0.6015288568939718
dev_recall_macro_sent: 0.5673000879098091
dev_f-score_macro_sent: 0.5284206304996587
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9107637286571296
dev_label=O_recall_tok: 0.9743289108299907
dev_label=O_f-score_tok: 0.9414746131600131
dev_label=N_precision_tok: 0.8013840830449827
dev_label=N_recall_tok: 0.6235864297253635
dev_label=N_f-score_tok: 0.7013930950938825
dev_label=P_precision_tok: 0.8977135980746089
dev_label=P_recall_tok: 0.6967621419676214
dev_label=P_f-score_tok: 0.7845749342681859
dev_precision_macro_tok: 0.8699538032589071
dev_recall_macro_tok: 0.7648924941743251
dev_f-score_macro_tok: 0.8091475475073605
dev_precision_micro_tok: 0.9018050202124659
dev_recall_micro_tok: 0.9018050202124659
dev_f-score_micro_tok: 0.9018050202124659
dev_time: 5.1139585971832275
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4688    0.0655    0.1149       229
           N     0.6680    0.7850    0.7218       428
           P     0.6678    0.8514    0.7485       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6015    0.5673    0.5284      1101
weighted avg     0.6265    0.6621    0.6064      1101

F1-macro sent:  0.5284206304996587
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9108    0.9743    0.9415     16205
           N     0.8014    0.6236    0.7014      1857
           P     0.8977    0.6968    0.7846      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8700    0.7649    0.8091     21274
weighted avg     0.8992    0.9018    0.8968     21274

F1-macro tok:  0.8091475475073605
F1-micro tok:  0.9018050202124659
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.478297
train_cost_sum: 301190.2940673828
train_cost_avg: 35.25167299477795
train_count_sent: 8544.0
train_total_correct_sent: 5722.0
train_accuracy_sent: 0.6697097378277154
train_count_tok: 163566.0
train_total_correct_tok: 148779.0
train_accuracy_tok: 0.9095961263343237
train_label=O_precision_sent: 0.45977011494252873
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.046756282875511396
train_label=N_precision_sent: 0.6453934740882917
train_label=N_recall_sent: 0.8126888217522659
train_label=N_f-score_sent: 0.7194437015244719
train_label=P_precision_sent: 0.6975985078106784
train_label=P_recall_sent: 0.8288088642659279
train_label=P_f-score_sent: 0.7575642486390681
train_precision_macro_sent: 0.6009206989471663
train_recall_macro_sent: 0.5553760759633716
train_f-score_macro_sent: 0.5079214110130171
train_precision_micro_sent: 0.6697097378277154
train_recall_micro_sent: 0.6697097378277154
train_f-score_micro_sent: 0.6697097378277154
train_label=O_precision_tok: 0.9212647571492727
train_label=O_recall_tok: 0.9733487739953517
train_label=O_f-score_tok: 0.946590855766373
train_label=N_precision_tok: 0.8182574685861695
train_label=N_recall_tok: 0.6923672722151809
train_label=N_f-score_tok: 0.7500667454899118
train_label=P_precision_tok: 0.8880130874479476
train_label=P_recall_tok: 0.7160330974937043
train_label=P_f-score_tok: 0.7928035583881033
train_precision_macro_tok: 0.8758451043944633
train_recall_macro_tok: 0.7939163812347455
train_f-score_macro_tok: 0.8298203865481294
train_precision_micro_tok: 0.9095961263343237
train_recall_micro_tok: 0.9095961263343237
train_f-score_micro_tok: 0.9095961263343237
train_time: 97.38617181777954
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4598    0.0246    0.0468      1624
           N     0.6454    0.8127    0.7194      3310
           P     0.6976    0.8288    0.7576      3610

   micro avg     0.6697    0.6697    0.6697      8544
   macro avg     0.6009    0.5554    0.5079      8544
weighted avg     0.6322    0.6697    0.6077      8544

F1-macro sent:  0.5079214110130171
F1-micro sent:  0.6697097378277154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9213    0.9733    0.9466    124347
           N     0.8183    0.6924    0.7501     14202
           P     0.8880    0.7160    0.7928     25017

   micro avg     0.9096    0.9096    0.9096    163566
   macro avg     0.8758    0.7939    0.8298    163566
weighted avg     0.9072    0.9096    0.9060    163566

F1-macro tok:  0.8298203865481294
F1-micro tok:  0.9095961263343237
**************************************************
dev_cost_sum: 42314.332092285156
dev_cost_avg: 38.432635869468804
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19126.0
dev_accuracy_tok: 0.8990316818651876
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6589147286821705
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.7203389830508473
dev_label=P_precision_sent: 0.6547008547008547
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.7444120505344995
dev_precision_macro_sent: 0.43787186112767507
dev_recall_macro_sent: 0.5523350453256995
dev_f-score_macro_sent: 0.48825034452844895
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9115480540571893
dev_label=O_recall_tok: 0.9698241283554458
dev_label=O_f-score_tok: 0.9397835316629792
dev_label=N_precision_tok: 0.7951388888888888
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.6945708219593568
dev_label=P_precision_tok: 0.8735055919784034
dev_label=P_recall_tok: 0.7051681195516812
dev_label=P_f-score_tok: 0.7803617571059431
dev_precision_macro_tok: 0.8600641783081605
dev_recall_macro_tok: 0.7638593797098429
dev_f-score_macro_tok: 0.8049053702427598
dev_precision_micro_tok: 0.8990316818651876
dev_recall_micro_tok: 0.8990316818651876
dev_f-score_micro_tok: 0.8990316818651876
dev_time: 5.211987018585205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6589    0.7944    0.7203       428
           P     0.6547    0.8626    0.7444       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.4379    0.5523    0.4883      1101
weighted avg     0.5202    0.6567    0.5802      1101

F1-macro sent:  0.48825034452844895
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9115    0.9698    0.9398     16205
           N     0.7951    0.6166    0.6946      1857
           P     0.8735    0.7052    0.7804      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8601    0.7639    0.8049     21274
weighted avg     0.8956    0.8990    0.8943     21274

F1-macro tok:  0.8049053702427598
F1-micro tok:  0.8990316818651876
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.430467
train_cost_sum: 300362.9126586914
train_cost_avg: 35.15483528308654
train_count_sent: 8544.0
train_total_correct_sent: 5682.0
train_accuracy_sent: 0.6650280898876404
train_count_tok: 163566.0
train_total_correct_tok: 148971.0
train_accuracy_tok: 0.910769964418033
train_label=O_precision_sent: 0.23636363636363636
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015485407980941036
train_label=N_precision_sent: 0.6342504743833017
train_label=N_recall_sent: 0.8078549848942598
train_label=N_f-score_sent: 0.7106032420940738
train_label=P_precision_sent: 0.7009127076995085
train_label=P_recall_sent: 0.8296398891966759
train_label=P_f-score_sent: 0.7598629963211975
train_precision_macro_sent: 0.5238422728154822
train_recall_macro_sent: 0.54849993339977
train_f-score_macro_sent: 0.495317215465404
train_precision_micro_sent: 0.6650280898876404
train_recall_micro_sent: 0.6650280898876404
train_f-score_micro_sent: 0.6650280898876404
train_label=O_precision_tok: 0.9228029771527926
train_label=O_recall_tok: 0.973155765720122
train_label=O_f-score_tok: 0.947310737868866
train_label=N_precision_tok: 0.8184832159138002
train_label=N_recall_tok: 0.6953246021687086
train_label=N_f-score_tok: 0.751894011497316
train_label=P_precision_tok: 0.8879670086896755
train_label=P_recall_tok: 0.7229883679098214
train_label=P_f-score_tok: 0.7970299211210506
train_precision_macro_tok: 0.8764177339187561
train_recall_macro_tok: 0.7971562452662173
train_f-score_macro_tok: 0.8320782234957442
train_precision_micro_tok: 0.910769964418033
train_recall_micro_tok: 0.910769964418033
train_f-score_micro_tok: 0.910769964418033
train_time: 97.54880166053772
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2364    0.0080    0.0155      1624
           N     0.6343    0.8079    0.7106      3310
           P     0.7009    0.8296    0.7599      3610

   micro avg     0.6650    0.6650    0.6650      8544
   macro avg     0.5238    0.5485    0.4953      8544
weighted avg     0.5868    0.6650    0.5993      8544

F1-macro sent:  0.495317215465404
F1-micro sent:  0.6650280898876404
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9228    0.9732    0.9473    124347
           N     0.8185    0.6953    0.7519     14202
           P     0.8880    0.7230    0.7970     25017

   micro avg     0.9108    0.9108    0.9108    163566
   macro avg     0.8764    0.7972    0.8321    163566
weighted avg     0.9084    0.9108    0.9074    163566

F1-macro tok:  0.8320782234957442
F1-micro tok:  0.910769964418033
**************************************************
dev_cost_sum: 42255.9951171875
dev_cost_avg: 38.37965042433015
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 19166.0
dev_accuracy_tok: 0.9009119112531729
dev_label=O_precision_sent: 0.3333333333333333
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008620689655172414
dev_label=N_precision_sent: 0.6753812636165577
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.6989853438556933
dev_label=P_precision_sent: 0.6197183098591549
dev_label=P_recall_sent: 0.8918918918918919
dev_label=P_f-score_sent: 0.7313019390581718
dev_precision_macro_sent: 0.5428109689363486
dev_recall_macro_sent: 0.5401859231798424
dev_f-score_macro_sent: 0.47963599085634584
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.9127080795777507
dev_label=O_recall_tok: 0.9710583153347733
dev_label=O_f-score_tok: 0.9409794893260778
dev_label=N_precision_tok: 0.7976519337016574
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.6989409984871406
dev_label=P_precision_tok: 0.8800773694390716
dev_label=P_recall_tok: 0.7082814445828145
dev_label=P_f-score_tok: 0.7848887355528722
dev_precision_macro_tok: 0.8634791275728265
dev_recall_macro_tok: 0.7671035602525508
dev_f-score_macro_tok: 0.8082697411220302
dev_precision_micro_tok: 0.9009119112531729
dev_recall_micro_tok: 0.9009119112531729
dev_f-score_micro_tok: 0.9009119112531729
dev_time: 5.240642547607422
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0044    0.0086       229
           N     0.6754    0.7243    0.6990       428
           P     0.6197    0.8919    0.7313       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.5428    0.5402    0.4796      1101
weighted avg     0.5818    0.6421    0.5684      1101

F1-macro sent:  0.47963599085634584
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9127    0.9711    0.9410     16205
           N     0.7977    0.6220    0.6989      1857
           P     0.8801    0.7083    0.7849      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8635    0.7671    0.8083     21274
weighted avg     0.8977    0.9009    0.8963     21274

F1-macro tok:  0.8082697411220302
F1-micro tok:  0.9009119112531729
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42381.53125
test0_cost_avg: 38.49367052679382
test0_count_sent: 1101.0
test0_total_correct_sent: 703.0
test0_accuracy_sent: 0.6385104450499546
test0_count_tok: 21274.0
test0_total_correct_tok: 19156.0
test0_accuracy_tok: 0.9004418539061766
test0_label=O_precision_sent: 0.29292929292929293
test0_label=O_recall_sent: 0.12663755458515283
test0_label=O_f-score_sent: 0.17682926829268292
test0_label=N_precision_sent: 0.6410748560460653
test0_label=N_recall_sent: 0.780373831775701
test0_label=N_f-score_sent: 0.7038988408851422
test0_label=P_precision_sent: 0.7068607068607069
test0_label=P_recall_sent: 0.7657657657657657
test0_label=P_f-score_sent: 0.7351351351351352
test0_precision_macro_sent: 0.546954951945355
test0_recall_macro_sent: 0.5575923840422065
test0_f-score_macro_sent: 0.5386210814376534
test0_precision_micro_sent: 0.6385104450499546
test0_recall_micro_sent: 0.6385104450499546
test0_f-score_micro_sent: 0.6385104450499546
test0_label=O_precision_tok: 0.9073649191235517
test0_label=O_recall_tok: 0.9761801912989818
test0_label=O_f-score_tok: 0.9405154731115668
test0_label=N_precision_tok: 0.7756452680344142
test0_label=N_recall_tok: 0.6311254711900915
test0_label=N_f-score_tok: 0.6959619952494062
test0_label=P_precision_tok: 0.9295835122370116
test0_label=P_recall_tok: 0.6740348692403487
test0_label=P_f-score_tok: 0.7814473921674788
test0_precision_macro_tok: 0.8708645664649924
test0_recall_macro_tok: 0.7604468439098073
test0_f-score_macro_tok: 0.8059749535094839
test0_precision_micro_tok: 0.9004418539061766
test0_recall_micro_tok: 0.9004418539061766
test0_f-score_micro_tok: 0.9004418539061767
test0_time: 5.047642707824707
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2929    0.1266    0.1768       229
           N     0.6411    0.7804    0.7039       428
           P     0.7069    0.7658    0.7351       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.5470    0.5576    0.5386      1101
weighted avg     0.5952    0.6385    0.6069      1101

F1-macro sent:  0.5386210814376534
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9762    0.9405     16205
           N     0.7756    0.6311    0.6960      1857
           P     0.9296    0.6740    0.7814      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8709    0.7604    0.8060     21274
weighted avg     0.8992    0.9004    0.8952     21274

F1-macro tok:  0.8059749535094839
F1-micro tok:  0.9004418539061767
**************************************************
test1_cost_sum: 82218.24863052368
test1_cost_avg: 37.2028274346261
test1_count_sent: 2210.0
test1_total_correct_sent: 1460.0
test1_accuracy_sent: 0.6606334841628959
test1_count_tok: 42405.0
test1_total_correct_tok: 37839.0
test1_accuracy_tok: 0.8923240183940573
test1_label=O_precision_sent: 0.26294820717131473
test1_label=O_recall_sent: 0.16966580976863754
test1_label=O_f-score_sent: 0.20625
test1_label=N_precision_sent: 0.6824324324324325
test1_label=N_recall_sent: 0.7752192982456141
test1_label=N_f-score_sent: 0.7258726899383984
test1_label=P_precision_sent: 0.7443120260021668
test1_label=P_recall_sent: 0.7557755775577558
test1_label=P_f-score_sent: 0.75
test1_precision_macro_sent: 0.5632308885353047
test1_recall_macro_sent: 0.5668868951906691
test1_f-score_macro_sent: 0.5607075633127995
test1_precision_micro_sent: 0.6606334841628959
test1_recall_micro_sent: 0.6606334841628959
test1_f-score_micro_sent: 0.6606334841628959
test1_label=O_precision_tok: 0.8977282518165369
test1_label=O_recall_tok: 0.9768735545971623
test1_label=O_f-score_tok: 0.9356301540027239
test1_label=N_precision_tok: 0.7815517815517815
test1_label=N_recall_tok: 0.6242021276595745
test1_label=N_f-score_tok: 0.6940706786928877
test1_label=P_precision_tok: 0.9238490072005237
test1_label=P_recall_tok: 0.636979088310516
test1_label=P_f-score_tok: 0.7540516473731077
test1_precision_macro_tok: 0.867709680189614
test1_recall_macro_tok: 0.7460182568557508
test1_f-score_macro_tok: 0.7945841600229064
test1_precision_micro_tok: 0.8923240183940573
test1_recall_micro_tok: 0.8923240183940573
test1_f-score_micro_tok: 0.8923240183940573
test1_time: 9.57456660270691
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2629    0.1697    0.2062       389
           N     0.6824    0.7752    0.7259       912
           P     0.7443    0.7558    0.7500       909

   micro avg     0.6606    0.6606    0.6606      2210
   macro avg     0.5632    0.5669    0.5607      2210
weighted avg     0.6340    0.6606    0.6443      2210

F1-macro sent:  0.5607075633127995
F1-micro sent:  0.6606334841628959
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8977    0.9769    0.9356     31998
           N     0.7816    0.6242    0.6941      3760
           P     0.9238    0.6370    0.7541      6647

   micro avg     0.8923    0.8923    0.8923     42405
   macro avg     0.8677    0.7460    0.7946     42405
weighted avg     0.8915    0.8923    0.8857     42405

F1-macro tok:  0.7945841600229064
F1-micro tok:  0.8923240183940573
**************************************************
