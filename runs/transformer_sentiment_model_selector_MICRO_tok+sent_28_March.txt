to_write_filename: runs/transformer_sentiment_model_selector_MICRO_tok+sent_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_micro_sent:dev_f-score_micro_tok:high
model_selector_ratio: 1:1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'O': 0, 'P': 2, 'N': 1}
{'O': 0, 'P': 2, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 20:54:28.297804: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 20:54:33.933408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-28 20:54:33.933456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 20:54:56.486399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 20:54:56.486442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 20:54:56.486453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 20:54:56.486716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428223.2683105469
train_cost_avg: 50.11976454945539
train_count_sent: 8544.0
train_total_correct_sent: 4197.0
train_accuracy_sent: 0.49122191011235955
train_count_tok: 163566.0
train_total_correct_tok: 125891.0
train_accuracy_tok: 0.7696648447721409
train_label=O_precision_sent: 0.20833333333333334
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.04405286343612335
train_label=N_precision_sent: 0.47364400305576776
train_label=N_recall_sent: 0.5619335347432024
train_label=N_f-score_sent: 0.5140251485422136
train_label=P_precision_sent: 0.5190960451977401
train_label=P_recall_sent: 0.6362880886426593
train_label=P_f-score_sent: 0.5717485998755445
train_precision_macro_sent: 0.40035779386228043
train_recall_macro_sent: 0.40761738841926093
train_f-score_macro_sent: 0.37660887061796045
train_precision_micro_sent: 0.49122191011235955
train_recall_micro_sent: 0.49122191011235955
train_f-score_micro_sent: 0.49122191011235955
train_label=O_precision_tok: 0.7981233371020047
train_label=O_recall_tok: 0.9480727319517157
train_label=O_f-score_tok: 0.866659805334196
train_label=N_precision_tok: 0.48996319839411173
train_label=N_recall_tok: 0.20623855794958457
train_label=N_f-score_tok: 0.29028741328047575
train_label=P_precision_tok: 0.5134122886931876
train_label=P_recall_tok: 0.2027421353479634
train_label=P_f-score_tok: 0.2906923429619441
train_precision_macro_tok: 0.6004996080631013
train_recall_macro_tok: 0.45235114174975455
train_f-score_macro_tok: 0.4825465205255386
train_precision_micro_tok: 0.7696648447721409
train_recall_micro_tok: 0.7696648447721409
train_f-score_micro_tok: 0.7696648447721409
train_time: 56.9086651802063
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2083    0.0246    0.0441      1624
           N     0.4736    0.5619    0.5140      3310
           P     0.5191    0.6363    0.5717      3610

   micro avg     0.4912    0.4912    0.4912      8544
   macro avg     0.4004    0.4076    0.3766      8544
weighted avg     0.4424    0.4912    0.4491      8544

F1-macro sent:  0.37660887061796045
F1-micro sent:  0.49122191011235955
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7981    0.9481    0.8667    124347
           N     0.4900    0.2062    0.2903     14202
           P     0.5134    0.2027    0.2907     25017

   micro avg     0.7697    0.7697    0.7697    163566
   macro avg     0.6005    0.4524    0.4825    163566
weighted avg     0.7278    0.7697    0.7285    163566

F1-macro tok:  0.4825465205255386
F1-micro tok:  0.7696648447721409
**************************************************
dev_cost_sum: 50637.366455078125
dev_cost_avg: 45.99215845147877
dev_count_sent: 1101.0
dev_total_correct_sent: 585.0
dev_accuracy_sent: 0.5313351498637602
dev_count_tok: 21274.0
dev_total_correct_tok: 17465.0
dev_accuracy_tok: 0.8209551565290966
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6775510204081633
dev_label=N_recall_sent: 0.3878504672897196
dev_label=N_f-score_sent: 0.4933135215453194
dev_label=P_precision_sent: 0.4894859813084112
dev_label=P_recall_sent: 0.9436936936936937
dev_label=P_f-score_sent: 0.6446153846153846
dev_precision_macro_sent: 0.38901233390552487
dev_recall_macro_sent: 0.4438480536611378
dev_f-score_macro_sent: 0.37930963538690127
dev_precision_micro_sent: 0.5313351498637602
dev_recall_micro_sent: 0.5313351498637602
dev_f-score_micro_sent: 0.5313351498637602
dev_label=O_precision_tok: 0.8397502036383383
dev_label=O_recall_tok: 0.954273372415921
dev_label=O_f-score_tok: 0.8933564413633739
dev_label=N_precision_tok: 0.7015810276679841
dev_label=N_recall_tok: 0.3823371028540657
dev_label=N_f-score_tok: 0.4949459742070408
dev_label=P_precision_tok: 0.6989713048186248
dev_label=P_recall_tok: 0.4019302615193026
dev_label=P_f-score_tok: 0.5103775449693615
dev_precision_macro_tok: 0.7467675120416492
dev_recall_macro_tok: 0.5795135789297631
dev_f-score_macro_tok: 0.6328933201799254
dev_precision_micro_tok: 0.8209551565290966
dev_recall_micro_tok: 0.8209551565290966
dev_f-score_micro_tok: 0.8209551565290965
dev_time: 2.845926523208618
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6776    0.3879    0.4933       428
           P     0.4895    0.9437    0.6446       444

   micro avg     0.5313    0.5313    0.5313      1101
   macro avg     0.3890    0.4438    0.3793      1101
weighted avg     0.4608    0.5313    0.4517      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.37930963538690127
F1-micro sent:  0.5313351498637602
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8398    0.9543    0.8934     16205
           N     0.7016    0.3823    0.4949      1857
           P     0.6990    0.4019    0.5104      3212

   micro avg     0.8210    0.8210    0.8210     21274
   macro avg     0.7468    0.5795    0.6329     21274
weighted avg     0.8064    0.8210    0.8008     21274

F1-macro tok:  0.6328933201799254
F1-micro tok:  0.8209551565290965
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378277.69775390625
train_cost_avg: 44.27407511164633
train_count_sent: 8544.0
train_total_correct_sent: 4891.0
train_accuracy_sent: 0.5724485018726592
train_count_tok: 163566.0
train_total_correct_tok: 132437.0
train_accuracy_tok: 0.8096853869386058
train_label=O_precision_sent: 0.21153846153846154
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013126491646778043
train_label=N_precision_sent: 0.5488921001926782
train_label=N_recall_sent: 0.6885196374622357
train_label=N_f-score_sent: 0.6108281961940499
train_label=P_precision_sent: 0.5993087557603687
train_label=P_recall_sent: 0.7204986149584488
train_label=P_f-score_sent: 0.6543396226415096
train_precision_macro_sent: 0.45324643916383617
train_recall_macro_sent: 0.47193055047848764
train_f-score_macro_sent: 0.4260981034941125
train_precision_micro_sent: 0.5724485018726592
train_recall_micro_sent: 0.5724485018726592
train_f-score_micro_sent: 0.5724485018726592
train_label=O_precision_tok: 0.8331169106127115
train_label=O_recall_tok: 0.949367495798049
train_label=O_f-score_tok: 0.887451371008664
train_label=N_precision_tok: 0.6381400824014126
train_label=N_recall_tok: 0.3817068018588931
train_label=N_f-score_tok: 0.47768427545490594
train_label=P_precision_tok: 0.6703806176624542
train_label=P_recall_tok: 0.3583563177039613
train_label=P_f-score_tok: 0.46704871060171915
train_precision_macro_tok: 0.7138792035588595
train_recall_macro_tok: 0.5631435384536344
train_f-score_macro_tok: 0.610728119021763
train_precision_micro_tok: 0.8096853869386058
train_recall_micro_tok: 0.8096853869386058
train_f-score_micro_tok: 0.8096853869386058
train_time: 50.47999882698059
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2115    0.0068    0.0131      1624
           N     0.5489    0.6885    0.6108      3310
           P     0.5993    0.7205    0.6543      3610

   micro avg     0.5724    0.5724    0.5724      8544
   macro avg     0.4532    0.4719    0.4261      8544
weighted avg     0.5061    0.5724    0.5156      8544

F1-macro sent:  0.4260981034941125
F1-micro sent:  0.5724485018726592
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8331    0.9494    0.8875    124347
           N     0.6381    0.3817    0.4777     14202
           P     0.6704    0.3584    0.4670     25017

   micro avg     0.8097    0.8097    0.8097    163566
   macro avg     0.7139    0.5631    0.6107    163566
weighted avg     0.7913    0.8097    0.7876    163566

F1-macro tok:  0.610728119021763
F1-micro tok:  0.8096853869386058
**************************************************
dev_cost_sum: 49002.07922363281
dev_cost_avg: 44.506883945170586
dev_count_sent: 1101.0
dev_total_correct_sent: 683.0
dev_accuracy_sent: 0.620345140781108
dev_count_tok: 21274.0
dev_total_correct_tok: 17840.0
dev_accuracy_tok: 0.8385823070414591
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5627836611195158
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.6831955922865014
dev_label=P_precision_sent: 0.7068181818181818
dev_label=P_recall_sent: 0.7004504504504504
dev_label=P_f-score_sent: 0.7036199095022623
dev_precision_macro_sent: 0.4232006143125659
dev_recall_macro_sent: 0.5232031096517078
dev_f-score_macro_sent: 0.4622718339295879
dev_precision_micro_sent: 0.620345140781108
dev_recall_micro_sent: 0.620345140781108
dev_f-score_micro_sent: 0.620345140781108
dev_label=O_precision_tok: 0.8489286682940059
dev_label=O_recall_tok: 0.9657513113236655
dev_label=O_f-score_tok: 0.9035796766743649
dev_label=N_precision_tok: 0.7071823204419889
dev_label=N_recall_tok: 0.4824986537425956
dev_label=N_f-score_tok: 0.5736235595390524
dev_label=P_precision_tok: 0.8231552162849872
dev_label=P_recall_tok: 0.4028642590286426
dev_label=P_f-score_tok: 0.5409698996655519
dev_precision_macro_tok: 0.793088735006994
dev_recall_macro_tok: 0.6170380746983013
dev_f-score_macro_tok: 0.6727243786263232
dev_precision_micro_tok: 0.8385823070414591
dev_recall_micro_tok: 0.8385823070414591
dev_f-score_micro_tok: 0.8385823070414592
dev_time: 5.055617332458496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5628    0.8692    0.6832       428
           P     0.7068    0.7005    0.7036       444

   micro avg     0.6203    0.6203    0.6203      1101
   macro avg     0.4232    0.5232    0.4623      1101
weighted avg     0.5038    0.6203    0.5493      1101

F1-macro sent:  0.4622718339295879
F1-micro sent:  0.620345140781108
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8489    0.9658    0.9036     16205
           N     0.7072    0.4825    0.5736      1857
           P     0.8232    0.4029    0.5410      3212

   micro avg     0.8386    0.8386    0.8386     21274
   macro avg     0.7931    0.6170    0.6727     21274
weighted avg     0.8327    0.8386    0.8200     21274

F1-macro tok:  0.6727243786263232
F1-micro tok:  0.8385823070414592
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368882.7544555664
train_cost_avg: 43.1744796881515
train_count_sent: 8544.0
train_total_correct_sent: 5065.0
train_accuracy_sent: 0.5928136704119851
train_count_tok: 163566.0
train_total_correct_tok: 135514.0
train_accuracy_tok: 0.8284973649780517
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012091898428053204
train_label=N_precision_sent: 0.5595903165735568
train_label=N_recall_sent: 0.7262839879154078
train_label=N_f-score_sent: 0.6321325269524061
train_label=P_precision_sent: 0.6284969179706021
train_label=P_recall_sent: 0.7343490304709142
train_label=P_f-score_sent: 0.6773122125702605
train_precision_macro_sent: 0.5071401892924975
train_recall_macro_sent: 0.4889302179514341
train_f-score_macro_sent: 0.44051221265023993
train_precision_micro_sent: 0.5928136704119851
train_recall_micro_sent: 0.5928136704119851
train_f-score_micro_sent: 0.5928136704119851
train_label=O_precision_tok: 0.8494548895085046
train_label=O_recall_tok: 0.9530587790618189
train_label=O_f-score_tok: 0.8982793905859168
train_label=N_precision_tok: 0.671815094752985
train_label=N_recall_tok: 0.4318405858329813
train_label=N_f-score_tok: 0.5257382881145257
train_label=P_precision_tok: 0.7284240150093808
train_label=P_recall_tok: 0.4345445097333813
train_label=P_f-score_tok: 0.5443529205578228
train_precision_macro_tok: 0.7498979997569567
train_recall_macro_tok: 0.6064812915427272
train_f-score_macro_tok: 0.6561235330860885
train_precision_micro_tok: 0.8284973649780517
train_recall_micro_tok: 0.8284973649780517
train_f-score_micro_tok: 0.8284973649780517
train_time: 94.11514139175415
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0062    0.0121      1624
           N     0.5596    0.7263    0.6321      3310
           P     0.6285    0.7343    0.6773      3610

   micro avg     0.5928    0.5928    0.5928      8544
   macro avg     0.5071    0.4889    0.4405      8544
weighted avg     0.5457    0.5928    0.5334      8544

F1-macro sent:  0.44051221265023993
F1-micro sent:  0.5928136704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8495    0.9531    0.8983    124347
           N     0.6718    0.4318    0.5257     14202
           P     0.7284    0.4345    0.5444     25017

   micro avg     0.8285    0.8285    0.8285    163566
   macro avg     0.7499    0.6065    0.6561    163566
weighted avg     0.8155    0.8285    0.8118    163566

F1-macro tok:  0.6561235330860885
F1-micro tok:  0.8284973649780517
**************************************************
dev_cost_sum: 48179.129943847656
dev_cost_avg: 43.75942774191431
dev_count_sent: 1101.0
dev_total_correct_sent: 672.0
dev_accuracy_sent: 0.6103542234332425
dev_count_tok: 21274.0
dev_total_correct_tok: 18194.0
dev_accuracy_tok: 0.8552223371251293
dev_label=O_precision_sent: 0.5625
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07346938775510205
dev_label=N_precision_sent: 0.6304347826086957
dev_label=N_recall_sent: 0.677570093457944
dev_label=N_f-score_sent: 0.6531531531531531
dev_label=P_precision_sent: 0.5968
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.6978484565014031
dev_precision_macro_sent: 0.5965782608695652
dev_recall_macro_sent: 0.5189871645305674
dev_f-score_macro_sent: 0.47482366580321944
dev_precision_micro_sent: 0.6103542234332425
dev_recall_micro_sent: 0.6103542234332425
dev_f-score_micro_sent: 0.6103542234332425
dev_label=O_precision_tok: 0.8670777092706771
dev_label=O_recall_tok: 0.9632829373650108
dev_label=O_f-score_tok: 0.9126520112254443
dev_label=N_precision_tok: 0.7722277722277723
dev_label=N_recall_tok: 0.41626278944534195
dev_label=N_f-score_tok: 0.5409377186843947
dev_label=P_precision_tok: 0.7977973568281939
dev_label=P_recall_tok: 0.5638231631382317
dev_label=P_f-score_tok: 0.6607077708865378
dev_precision_macro_tok: 0.8123676127755477
dev_recall_macro_tok: 0.6477896299828615
dev_f-score_macro_tok: 0.7047658335987922
dev_precision_micro_tok: 0.8552223371251293
dev_recall_micro_tok: 0.8552223371251293
dev_f-score_micro_tok: 0.8552223371251293
dev_time: 4.814510107040405
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5625    0.0393    0.0735       229
           N     0.6304    0.6776    0.6532       428
           P     0.5968    0.8401    0.6978       444

   micro avg     0.6104    0.6104    0.6104      1101
   macro avg     0.5966    0.5190    0.4748      1101
weighted avg     0.6027    0.6104    0.5506      1101

F1-macro sent:  0.47482366580321944
F1-micro sent:  0.6103542234332425
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8671    0.9633    0.9127     16205
           N     0.7722    0.4163    0.5409      1857
           P     0.7978    0.5638    0.6607      3212

   micro avg     0.8552    0.8552    0.8552     21274
   macro avg     0.8124    0.6478    0.7048     21274
weighted avg     0.8483    0.8552    0.8422     21274

F1-macro tok:  0.7047658335987922
F1-micro tok:  0.8552223371251293
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361894.857421875
train_cost_avg: 42.35660784432058
train_count_sent: 8544.0
train_total_correct_sent: 5116.0
train_accuracy_sent: 0.5987827715355806
train_count_tok: 163566.0
train_total_correct_tok: 137754.0
train_accuracy_tok: 0.8421921426213271
train_label=O_precision_sent: 0.32142857142857145
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010895883777239709
train_label=N_precision_sent: 0.572522738152226
train_label=N_recall_sent: 0.7226586102719034
train_label=N_f-score_sent: 0.638888888888889
train_label=P_precision_sent: 0.6258644536652835
train_label=P_recall_sent: 0.7520775623268698
train_label=P_f-score_sent: 0.683190739808757
train_precision_macro_sent: 0.5066052544153603
train_recall_macro_sent: 0.49342601483998516
train_f-score_macro_sent: 0.44432517082496187
train_precision_micro_sent: 0.5987827715355806
train_recall_micro_sent: 0.5987827715355806
train_f-score_micro_sent: 0.5987827715355806
train_label=O_precision_tok: 0.861144504149588
train_label=O_recall_tok: 0.9562916676719181
train_label=O_f-score_tok: 0.9062274942556766
train_label=N_precision_tok: 0.6961546770360769
train_label=N_recall_tok: 0.4538093226306154
train_label=N_f-score_tok: 0.5494458653026427
train_label=P_precision_tok: 0.7642090987547775
train_label=P_recall_tok: 0.4955430307390974
train_label=P_f-score_tok: 0.6012269938650306
train_precision_macro_tok: 0.7738360933134808
train_recall_macro_tok: 0.6352146736805436
train_f-score_macro_tok: 0.6856334511411166
train_precision_micro_tok: 0.8421921426213271
train_recall_micro_tok: 0.8421921426213271
train_f-score_micro_tok: 0.8421921426213271
train_time: 94.69749474525452
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3214    0.0055    0.0109      1624
           N     0.5725    0.7227    0.6389      3310
           P     0.6259    0.7521    0.6832      3610

   micro avg     0.5988    0.5988    0.5988      8544
   macro avg     0.5066    0.4934    0.4443      8544
weighted avg     0.5473    0.5988    0.5382      8544

F1-macro sent:  0.44432517082496187
F1-micro sent:  0.5987827715355806
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8611    0.9563    0.9062    124347
           N     0.6962    0.4538    0.5494     14202
           P     0.7642    0.4955    0.6012     25017

   micro avg     0.8422    0.8422    0.8422    163566
   macro avg     0.7738    0.6352    0.6856    163566
weighted avg     0.8320    0.8422    0.8286    163566

F1-macro tok:  0.6856334511411166
F1-micro tok:  0.8421921426213271
**************************************************
dev_cost_sum: 47423.533935546875
dev_cost_avg: 43.073146172158836
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18429.0
dev_accuracy_tok: 0.8662686847795431
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6003490401396161
dev_label=N_recall_sent: 0.8037383177570093
dev_label=N_f-score_sent: 0.6873126873126874
dev_label=P_precision_sent: 0.6534090909090909
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7098765432098765
dev_precision_macro_sent: 0.41791937701623566
dev_recall_macro_sent: 0.5269217815946788
dev_f-score_macro_sent: 0.4657297435075212
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.8770987239758227
dev_label=O_recall_tok: 0.9671089170009256
dev_label=O_f-score_tok: 0.9199072579461743
dev_label=N_precision_tok: 0.7694323144104803
dev_label=N_recall_tok: 0.47442110931610126
dev_label=N_f-score_tok: 0.5869420386409061
dev_label=P_precision_tok: 0.8297213622291022
dev_label=P_recall_tok: 0.5840597758405978
dev_label=P_f-score_tok: 0.6855472318655217
dev_precision_macro_tok: 0.8254174668718018
dev_recall_macro_tok: 0.6751966007192083
dev_f-score_macro_tok: 0.730798842817534
dev_precision_micro_tok: 0.8662686847795431
dev_recall_micro_tok: 0.8662686847795431
dev_f-score_micro_tok: 0.8662686847795431
dev_time: 5.14731764793396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6003    0.8037    0.6873       428
           P     0.6534    0.7770    0.7099       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.4179    0.5269    0.4657      1101
weighted avg     0.4969    0.6258    0.5535      1101

F1-macro sent:  0.4657297435075212
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8771    0.9671    0.9199     16205
           N     0.7694    0.4744    0.5869      1857
           P     0.8297    0.5841    0.6855      3212

   micro avg     0.8663    0.8663    0.8663     21274
   macro avg     0.8254    0.6752    0.7308     21274
weighted avg     0.8605    0.8663    0.8555     21274

F1-macro tok:  0.730798842817534
F1-micro tok:  0.8662686847795431
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355763.0028076172
train_cost_avg: 41.638928231228604
train_count_sent: 8544.0
train_total_correct_sent: 5210.0
train_accuracy_sent: 0.6097846441947565
train_count_tok: 163566.0
train_total_correct_tok: 139208.0
train_accuracy_tok: 0.8510815206094176
train_label=O_precision_sent: 0.37142857142857144
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015672091621458713
train_label=N_precision_sent: 0.5744196631770596
train_label=N_recall_sent: 0.7625377643504532
train_label=N_f-score_sent: 0.6552440290758047
train_label=P_precision_sent: 0.6495747266099635
train_label=P_recall_sent: 0.7404432132963988
train_label=P_f-score_sent: 0.6920388349514562
train_precision_macro_sent: 0.5318076537385316
train_recall_macro_sent: 0.5036619679184088
train_f-score_macro_sent: 0.45431831854957316
train_precision_micro_sent: 0.6097846441947565
train_recall_micro_sent: 0.6097846441947565
train_f-score_micro_sent: 0.6097846441947565
train_label=O_precision_tok: 0.8678025039829479
train_label=O_recall_tok: 0.9593235059953196
train_label=O_f-score_tok: 0.9112708549776936
train_label=N_precision_tok: 0.7142857142857143
train_label=N_recall_tok: 0.4766934234614843
train_label=N_f-score_tok: 0.5717905405405406
train_label=P_precision_tok: 0.7908221567330246
train_label=P_recall_tok: 0.5256025902386378
train_label=P_f-score_tok: 0.6314955335702622
train_precision_macro_tok: 0.7909701250005622
train_recall_macro_tok: 0.6538731732318138
train_f-score_macro_tok: 0.7048523096961654
train_precision_micro_tok: 0.8510815206094176
train_recall_micro_tok: 0.8510815206094176
train_f-score_micro_tok: 0.8510815206094176
train_time: 94.14999079704285
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3714    0.0080    0.0157      1624
           N     0.5744    0.7625    0.6552      3310
           P     0.6496    0.7404    0.6920      3610

   micro avg     0.6098    0.6098    0.6098      8544
   macro avg     0.5318    0.5037    0.4543      8544
weighted avg     0.5676    0.6098    0.5492      8544

F1-macro sent:  0.45431831854957316
F1-micro sent:  0.6097846441947565
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8678    0.9593    0.9113    124347
           N     0.7143    0.4767    0.5718     14202
           P     0.7908    0.5256    0.6315     25017

   micro avg     0.8511    0.8511    0.8511    163566
   macro avg     0.7910    0.6539    0.7049    163566
weighted avg     0.8427    0.8511    0.8390    163566

F1-macro tok:  0.7048523096961654
F1-micro tok:  0.8510815206094176
**************************************************
dev_cost_sum: 46783.6103515625
dev_cost_avg: 42.49192584156449
dev_count_sent: 1101.0
dev_total_correct_sent: 676.0
dev_accuracy_sent: 0.6139872842870118
dev_count_tok: 21274.0
dev_total_correct_tok: 18512.0
dev_accuracy_tok: 0.8701701607596126
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6658986175115207
dev_label=N_recall_sent: 0.6752336448598131
dev_label=N_f-score_sent: 0.6705336426914152
dev_label=P_precision_sent: 0.5802098950524738
dev_label=P_recall_sent: 0.8716216216216216
dev_label=P_f-score_sent: 0.6966696669666967
dev_precision_macro_sent: 0.4153695041879981
dev_recall_macro_sent: 0.5156184221604782
dev_f-score_macro_sent: 0.455734436552704
dev_precision_micro_sent: 0.6139872842870118
dev_recall_micro_sent: 0.6139872842870118
dev_f-score_micro_sent: 0.6139872842870118
dev_label=O_precision_tok: 0.8818130630630631
dev_label=O_recall_tok: 0.9664301141622956
dev_label=O_f-score_tok: 0.9221846017959664
dev_label=N_precision_tok: 0.7372429550647372
dev_label=N_recall_tok: 0.5212708669897684
dev_label=N_f-score_tok: 0.6107255520504733
dev_label=P_precision_tok: 0.8555202180826896
dev_label=P_recall_tok: 0.586239103362391
dev_label=P_f-score_tok: 0.6957324958433402
dev_precision_macro_tok: 0.8248587454034966
dev_recall_macro_tok: 0.6913133615048185
dev_f-score_macro_tok: 0.7428808832299266
dev_precision_micro_tok: 0.8701701607596126
dev_recall_micro_tok: 0.8701701607596126
dev_f-score_micro_tok: 0.8701701607596126
dev_time: 5.038915157318115
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6659    0.6752    0.6705       428
           P     0.5802    0.8716    0.6967       444

   micro avg     0.6140    0.6140    0.6140      1101
   macro avg     0.4154    0.5156    0.4557      1101
weighted avg     0.4928    0.6140    0.5416      1101

F1-macro sent:  0.455734436552704
F1-micro sent:  0.6139872842870118
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8818    0.9664    0.9222     16205
           N     0.7372    0.5213    0.6107      1857
           P     0.8555    0.5862    0.6957      3212

   micro avg     0.8702    0.8702    0.8702     21274
   macro avg     0.8249    0.6913    0.7429     21274
weighted avg     0.8652    0.8702    0.8608     21274

F1-macro tok:  0.7428808832299266
F1-micro tok:  0.8701701607596126
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351204.54248046875
train_cost_avg: 41.10540057121591
train_count_sent: 8544.0
train_total_correct_sent: 5292.0
train_accuracy_sent: 0.6193820224719101
train_count_tok: 163566.0
train_total_correct_tok: 140151.0
train_accuracy_tok: 0.8568467774476358
train_label=O_precision_sent: 0.24603174603174602
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03542857142857143
train_label=N_precision_sent: 0.5878928987194412
train_label=N_recall_sent: 0.7628398791540786
train_label=N_f-score_sent: 0.6640368178829718
train_label=P_precision_sent: 0.663594470046083
train_label=P_recall_sent: 0.7578947368421053
train_label=P_f-score_sent: 0.7076167076167077
train_precision_macro_sent: 0.4991730382657567
train_recall_macro_sent: 0.5132744286489742
train_f-score_macro_sent: 0.4690273656427503
train_precision_micro_sent: 0.6193820224719101
train_recall_micro_sent: 0.6193820224719101
train_f-score_micro_sent: 0.6193820224719101
train_label=O_precision_tok: 0.8726202989955618
train_label=O_recall_tok: 0.9613581348967004
train_label=O_f-score_tok: 0.9148424077539136
train_label=N_precision_tok: 0.7188301693175988
train_label=N_recall_tok: 0.493240388677651
train_label=N_f-score_tok: 0.5850419676786236
train_label=P_precision_tok: 0.8083665101907421
train_label=P_recall_tok: 0.543790222648599
train_label=P_f-score_tok: 0.6501935668881136
train_precision_macro_tok: 0.7999389928346342
train_recall_macro_tok: 0.6661295820743168
train_f-score_macro_tok: 0.716692647440217
train_precision_micro_tok: 0.8568467774476358
train_recall_micro_tok: 0.8568467774476358
train_f-score_micro_tok: 0.8568467774476358
train_time: 94.63625288009644
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2460    0.0191    0.0354      1624
           N     0.5879    0.7628    0.6640      3310
           P     0.6636    0.7579    0.7076      3610

   micro avg     0.6194    0.6194    0.6194      8544
   macro avg     0.4992    0.5133    0.4690      8544
weighted avg     0.5549    0.6194    0.5630      8544

F1-macro sent:  0.4690273656427503
F1-micro sent:  0.6193820224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8726    0.9614    0.9148    124347
           N     0.7188    0.4932    0.5850     14202
           P     0.8084    0.5438    0.6502     25017

   micro avg     0.8568    0.8568    0.8568    163566
   macro avg     0.7999    0.6661    0.7167    163566
weighted avg     0.8494    0.8568    0.8457    163566

F1-macro tok:  0.716692647440217
F1-micro tok:  0.8568467774476358
**************************************************
dev_cost_sum: 46272.55810546875
dev_cost_avg: 42.027754864185965
dev_count_sent: 1101.0
dev_total_correct_sent: 693.0
dev_accuracy_sent: 0.6294277929155313
dev_count_tok: 21274.0
dev_total_correct_tok: 18634.0
dev_accuracy_tok: 0.8759048603929679
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6003430531732419
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.692383778437191
dev_label=P_precision_sent: 0.6621621621621622
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.713097713097713
dev_precision_macro_sent: 0.4208350717784681
dev_recall_macro_sent: 0.5300931772894389
dev_f-score_macro_sent: 0.4684938305116346
dev_precision_micro_sent: 0.6294277929155313
dev_recall_micro_sent: 0.6294277929155313
dev_f-score_micro_sent: 0.6294277929155313
dev_label=O_precision_tok: 0.8807308785025904
dev_label=O_recall_tok: 0.9756248071582845
dev_label=O_f-score_tok: 0.9257524300269352
dev_label=N_precision_tok: 0.7808219178082192
dev_label=N_recall_tok: 0.5218093699515347
dev_label=N_f-score_tok: 0.6255648805681084
dev_label=P_precision_tok: 0.8909702209414025
dev_label=P_recall_tok: 0.5775217932752179
dev_label=P_f-score_tok: 0.7007933509633547
dev_precision_macro_tok: 0.8508410057507373
dev_recall_macro_tok: 0.6916519901283458
dev_f-score_macro_tok: 0.7507035538527994
dev_precision_micro_tok: 0.8759048603929679
dev_recall_micro_tok: 0.8759048603929679
dev_f-score_micro_tok: 0.8759048603929679
dev_time: 5.062025547027588
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6003    0.8178    0.6924       428
           P     0.6622    0.7725    0.7131       444

   micro avg     0.6294    0.6294    0.6294      1101
   macro avg     0.4208    0.5301    0.4685      1101
weighted avg     0.5004    0.6294    0.5567      1101

F1-macro sent:  0.4684938305116346
F1-micro sent:  0.6294277929155313
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8807    0.9756    0.9258     16205
           N     0.7808    0.5218    0.6256      1857
           P     0.8910    0.5775    0.7008      3212

   micro avg     0.8759    0.8759    0.8759     21274
   macro avg     0.8508    0.6917    0.7507     21274
weighted avg     0.8736    0.8759    0.8656     21274

F1-macro tok:  0.7507035538527994
F1-micro tok:  0.8759048603929679
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347013.4317626953
train_cost_avg: 40.614867949753666
train_count_sent: 8544.0
train_total_correct_sent: 5315.0
train_accuracy_sent: 0.6220739700374532
train_count_tok: 163566.0
train_total_correct_tok: 141079.0
train_accuracy_tok: 0.8625203281855642
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006119951040391678
train_label=N_precision_sent: 0.5798895027624309
train_label=N_recall_sent: 0.7927492447129909
train_label=N_f-score_sent: 0.6698149329929802
train_label=P_precision_sent: 0.6699925168371165
train_label=P_recall_sent: 0.7440443213296399
train_label=P_f-score_sent: 0.7050794067462922
train_precision_macro_sent: 0.5832940065331824
train_recall_macro_sent: 0.5132907945922071
train_f-score_macro_sent: 0.4603380969265547
train_precision_micro_sent: 0.6220739700374532
train_recall_micro_sent: 0.6220739700374532
train_f-score_micro_sent: 0.6220739700374532
train_label=O_precision_tok: 0.8765015975608864
train_label=O_recall_tok: 0.9640763347728534
train_label=O_f-score_tok: 0.9182055622362304
train_label=N_precision_tok: 0.7327890333635723
train_label=N_recall_tok: 0.5118997324320518
train_label=N_f-score_tok: 0.6027442689549393
train_label=P_precision_tok: 0.8254711390304611
train_label=P_recall_tok: 0.5567813886557141
train_label=P_f-score_tok: 0.6650115776658471
train_precision_macro_tok: 0.8115872566516399
train_recall_macro_tok: 0.6775858186202064
train_f-score_macro_tok: 0.7286538029523388
train_precision_micro_tok: 0.8625203281855642
train_recall_micro_tok: 0.8625203281855642
train_f-score_micro_tok: 0.8625203281855642
train_time: 94.6510272026062
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0031    0.0061      1624
           N     0.5799    0.7927    0.6698      3310
           P     0.6700    0.7440    0.7051      3610

   micro avg     0.6221    0.6221    0.6221      8544
   macro avg     0.5833    0.5133    0.4603      8544
weighted avg     0.6028    0.6221    0.5586      8544

F1-macro sent:  0.4603380969265547
F1-micro sent:  0.6220739700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8765    0.9641    0.9182    124347
           N     0.7328    0.5119    0.6027     14202
           P     0.8255    0.5568    0.6650     25017

   micro avg     0.8625    0.8625    0.8625    163566
   macro avg     0.8116    0.6776    0.7287    163566
weighted avg     0.8562    0.8625    0.8521    163566

F1-macro tok:  0.7286538029523388
F1-micro tok:  0.8625203281855642
**************************************************
dev_cost_sum: 45976.904541015625
dev_cost_avg: 41.75922301636297
dev_count_sent: 1101.0
dev_total_correct_sent: 674.0
dev_accuracy_sent: 0.6121707538601272
dev_count_tok: 21274.0
dev_total_correct_tok: 18701.0
dev_accuracy_tok: 0.8790542446178434
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.6559633027522935
dev_label=N_recall_sent: 0.6682242990654206
dev_label=N_f-score_sent: 0.662037037037037
dev_label=P_precision_sent: 0.5833333333333334
dev_label=P_recall_sent: 0.8671171171171171
dev_label=P_f-score_sent: 0.697463768115942
dev_precision_macro_sent: 0.613098878695209
dev_recall_macro_sent: 0.5161472842879201
dev_f-score_macro_sent: 0.46171394359800155
dev_precision_micro_sent: 0.6121707538601272
dev_recall_micro_sent: 0.6121707538601272
dev_f-score_micro_sent: 0.6121707538601272
dev_label=O_precision_tok: 0.8821957465761051
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9275616823250505
dev_label=N_precision_tok: 0.8213961922030825
dev_label=N_recall_tok: 0.4878836833602585
dev_label=N_f-score_tok: 0.6121621621621621
dev_label=P_precision_tok: 0.8822996831145314
dev_label=P_recall_tok: 0.6067870485678705
dev_label=P_f-score_tok: 0.7190555248109205
dev_precision_macro_tok: 0.861963873964573
dev_recall_macro_tok: 0.690839025216401
dev_f-score_macro_tok: 0.752926456432711
dev_precision_micro_tok: 0.8790542446178434
dev_recall_micro_tok: 0.8790542446178434
dev_f-score_micro_tok: 0.8790542446178434
dev_time: 4.439526319503784
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.6560    0.6682    0.6620       428
           P     0.5833    0.8671    0.6975       444

   micro avg     0.6122    0.6122    0.6122      1101
   macro avg     0.6131    0.5161    0.4617      1101
weighted avg     0.6150    0.6122    0.5440      1101

F1-macro sent:  0.46171394359800155
F1-micro sent:  0.6121707538601272
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8822    0.9778    0.9276     16205
           N     0.8214    0.4879    0.6122      1857
           P     0.8823    0.6068    0.7191      3212

   micro avg     0.8791    0.8791    0.8791     21274
   macro avg     0.8620    0.6908    0.7529     21274
weighted avg     0.8769    0.8791    0.8685     21274

F1-macro tok:  0.752926456432711
F1-micro tok:  0.8790542446178434
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342915.47595214844
train_cost_avg: 40.135238290279545
train_count_sent: 8544.0
train_total_correct_sent: 5381.0
train_accuracy_sent: 0.6297986891385767
train_count_tok: 163566.0
train_total_correct_tok: 141797.0
train_accuracy_tok: 0.8669099935194355
train_label=O_precision_sent: 0.38461538461538464
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006108735491753207
train_label=N_precision_sent: 0.5954797047970479
train_label=N_recall_sent: 0.7800604229607251
train_label=N_f-score_sent: 0.6753858226523672
train_label=P_precision_sent: 0.666030989272944
train_label=P_recall_sent: 0.7739612188365651
train_label=P_f-score_sent: 0.7159513132607304
train_precision_macro_sent: 0.5487086928951256
train_recall_macro_sent: 0.5190334865104268
train_f-score_macro_sent: 0.46581529046828357
train_precision_micro_sent: 0.6297986891385767
train_recall_micro_sent: 0.6297986891385767
train_f-score_micro_sent: 0.6297986891385767
train_label=O_precision_tok: 0.8799812401987367
train_label=O_recall_tok: 0.9657169051123067
train_label=O_f-score_tok: 0.9208577924841551
train_label=N_precision_tok: 0.7427116613418531
train_label=N_recall_tok: 0.5237994648641037
train_label=N_f-score_tok: 0.6143364439672971
train_label=P_precision_tok: 0.8353230337078652
train_label=P_recall_tok: 0.5705720110324979
train_label=P_f-score_tok: 0.6780192376202351
train_precision_macro_tok: 0.8193386450828184
train_recall_macro_tok: 0.6866961270029694
train_f-score_macro_tok: 0.7377378246905625
train_precision_micro_tok: 0.8669099935194355
train_recall_micro_tok: 0.8669099935194355
train_f-score_micro_tok: 0.8669099935194355
train_time: 95.10236263275146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.0031    0.0061      1624
           N     0.5955    0.7801    0.6754      3310
           P     0.6660    0.7740    0.7160      3610

   micro avg     0.6298    0.6298    0.6298      8544
   macro avg     0.5487    0.5190    0.4658      8544
weighted avg     0.5852    0.6298    0.5653      8544

F1-macro sent:  0.46581529046828357
F1-micro sent:  0.6297986891385767
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8800    0.9657    0.9209    124347
           N     0.7427    0.5238    0.6143     14202
           P     0.8353    0.5706    0.6780     25017

   micro avg     0.8669    0.8669    0.8669    163566
   macro avg     0.8193    0.6867    0.7377    163566
weighted avg     0.8612    0.8669    0.8571    163566

F1-macro tok:  0.7377378246905625
F1-micro tok:  0.8669099935194355
**************************************************
dev_cost_sum: 45420.37579345703
dev_cost_avg: 41.25374731467487
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18795.0
dev_accuracy_tok: 0.8834727836796089
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5957792207792207
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7030651340996168
dev_label=P_precision_sent: 0.6845360824742268
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7147470398277717
dev_precision_macro_sent: 0.42677176775114917
dev_recall_macro_sent: 0.5350747944205888
dev_f-score_macro_sent: 0.4726040579757962
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8955598675950234
dev_label=O_recall_tok: 0.968343103980253
dev_label=O_f-score_tok: 0.9305304355560827
dev_label=N_precision_tok: 0.7324503311258278
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.656964656964657
dev_label=P_precision_tok: 0.8907225691347012
dev_label=P_recall_tok: 0.6217310087173101
dev_label=P_f-score_tok: 0.7323065639897323
dev_precision_macro_tok: 0.8395775892851841
dev_recall_macro_tok: 0.7285527961370265
dev_f-score_macro_tok: 0.7732672188368239
dev_precision_micro_tok: 0.8834727836796089
dev_recall_micro_tok: 0.8834727836796089
dev_f-score_micro_tok: 0.8834727836796089
dev_time: 4.086677551269531
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5958    0.8575    0.7031       428
           P     0.6845    0.7477    0.7147       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.4268    0.5351    0.4726      1101
weighted avg     0.5077    0.6349    0.5615      1101

F1-macro sent:  0.4726040579757962
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8956    0.9683    0.9305     16205
           N     0.7325    0.5956    0.6570      1857
           P     0.8907    0.6217    0.7323      3212

   micro avg     0.8835    0.8835    0.8835     21274
   macro avg     0.8396    0.7286    0.7733     21274
weighted avg     0.8806    0.8835    0.8767     21274

F1-macro tok:  0.7732672188368239
F1-micro tok:  0.8834727836796089
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339487.400390625
train_cost_avg: 39.73401221800386
train_count_sent: 8544.0
train_total_correct_sent: 5394.0
train_accuracy_sent: 0.6313202247191011
train_count_tok: 163566.0
train_total_correct_tok: 142484.0
train_accuracy_tok: 0.871110132912708
train_label=O_precision_sent: 0.4117647058823529
train_label=O_recall_sent: 0.01293103448275862
train_label=O_f-score_sent: 0.02507462686567164
train_label=N_precision_sent: 0.5962732919254659
train_label=N_recall_sent: 0.7830815709969788
train_label=N_f-score_sent: 0.6770275564842627
train_label=P_precision_sent: 0.670767004341534
train_label=P_recall_sent: 0.7703601108033241
train_label=P_f-score_sent: 0.7171222279525528
train_precision_macro_sent: 0.5596016673831176
train_recall_macro_sent: 0.5221242387610205
train_f-score_macro_sent: 0.47307480376749567
train_precision_micro_sent: 0.6313202247191011
train_recall_micro_sent: 0.6313202247191011
train_f-score_micro_sent: 0.6313202247191011
train_label=O_precision_tok: 0.8833272126331252
train_label=O_recall_tok: 0.9671725091879981
train_label=O_f-score_tok: 0.9233503648794419
train_label=N_precision_tok: 0.7512506130456106
train_label=N_recall_tok: 0.5392902408111534
train_label=N_f-score_tok: 0.6278640816493831
train_label=P_precision_tok: 0.8454793565995006
train_label=P_recall_tok: 0.5820042371187593
train_label=P_f-score_tok: 0.6894265826980444
train_precision_macro_tok: 0.8266857274260788
train_recall_macro_tok: 0.6961556623726369
train_f-score_macro_tok: 0.746880343075623
train_precision_micro_tok: 0.871110132912708
train_recall_micro_tok: 0.871110132912708
train_f-score_micro_tok: 0.871110132912708
train_time: 95.31515336036682
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4118    0.0129    0.0251      1624
           N     0.5963    0.7831    0.6770      3310
           P     0.6708    0.7704    0.7171      3610

   micro avg     0.6313    0.6313    0.6313      8544
   macro avg     0.5596    0.5221    0.4731      8544
weighted avg     0.5927    0.6313    0.5700      8544

F1-macro sent:  0.47307480376749567
F1-micro sent:  0.6313202247191011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8833    0.9672    0.9234    124347
           N     0.7513    0.5393    0.6279     14202
           P     0.8455    0.5820    0.6894     25017

   micro avg     0.8711    0.8711    0.8711    163566
   macro avg     0.8267    0.6962    0.7469    163566
weighted avg     0.8661    0.8711    0.8619    163566

F1-macro tok:  0.746880343075623
F1-micro tok:  0.871110132912708
**************************************************
dev_cost_sum: 45079.19738769531
dev_cost_avg: 40.94386683714379
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18827.0
dev_accuracy_tok: 0.8849769671899972
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6463878326996197
dev_label=N_recall_sent: 0.794392523364486
dev_label=N_f-score_sent: 0.7127882599580713
dev_label=P_precision_sent: 0.6382608695652174
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7203140333660452
dev_precision_macro_sent: 0.4282162340882791
dev_recall_macro_sent: 0.5403230333136876
dev_f-score_macro_sent: 0.47770076444137216
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8906848389276865
dev_label=O_recall_tok: 0.9759333539031163
dev_label=O_f-score_tok: 0.9313624451576809
dev_label=N_precision_tok: 0.7626514611546685
dev_label=N_recall_tok: 0.57619816908993
dev_label=N_f-score_tok: 0.6564417177914111
dev_label=P_precision_tok: 0.9182033096926714
dev_label=P_recall_tok: 0.6046077210460772
dev_label=P_f-score_tok: 0.7291158250422376
dev_precision_macro_tok: 0.8571798699250088
dev_recall_macro_tok: 0.7189130813463745
dev_f-score_macro_tok: 0.7723066626637766
dev_precision_micro_tok: 0.8849769671899972
dev_recall_micro_tok: 0.8849769671899972
dev_f-score_micro_tok: 0.8849769671899972
dev_time: 3.6370506286621094
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6464    0.7944    0.7128       428
           P     0.6383    0.8266    0.7203       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.4282    0.5403    0.4777      1101
weighted avg     0.5087    0.6421    0.5676      1101

F1-macro sent:  0.47770076444137216
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8907    0.9759    0.9314     16205
           N     0.7627    0.5762    0.6564      1857
           P     0.9182    0.6046    0.7291      3212

   micro avg     0.8850    0.8850    0.8850     21274
   macro avg     0.8572    0.7189    0.7723     21274
weighted avg     0.8837    0.8850    0.8768     21274

F1-macro tok:  0.7723066626637766
F1-micro tok:  0.8849769671899972
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336390.1405029297
train_cost_avg: 39.371505208676226
train_count_sent: 8544.0
train_total_correct_sent: 5395.0
train_accuracy_sent: 0.631437265917603
train_count_tok: 163566.0
train_total_correct_tok: 142875.0
train_accuracy_tok: 0.873500605260262
train_label=O_precision_sent: 0.4827586206896552
train_label=O_recall_sent: 0.017241379310344827
train_label=O_f-score_sent: 0.03329369797859691
train_label=N_precision_sent: 0.6028605482717521
train_label=N_recall_sent: 0.7640483383685801
train_label=N_f-score_sent: 0.6739506995336442
train_label=P_precision_sent: 0.661384292705663
train_label=P_recall_sent: 0.7861495844875346
train_label=P_f-score_sent: 0.718390077205417
train_precision_macro_sent: 0.5823344872223567
train_recall_macro_sent: 0.5224797673888198
train_f-score_macro_sent: 0.4752114915725527
train_precision_micro_sent: 0.631437265917603
train_recall_micro_sent: 0.631437265917603
train_f-score_micro_sent: 0.631437265917603
train_label=O_precision_tok: 0.8853411807982343
train_label=O_recall_tok: 0.9677756600480912
train_label=O_f-score_tok: 0.9247249031782137
train_label=N_precision_tok: 0.75263107077339
train_label=N_recall_tok: 0.5488663568511477
train_label=N_f-score_tok: 0.6347978337880207
train_label=P_precision_tok: 0.8528118491090025
train_label=P_recall_tok: 0.5891993444457768
train_label=P_f-score_tok: 0.69691023852864
train_precision_macro_tok: 0.8302613668935424
train_recall_macro_tok: 0.7019471204483386
train_f-score_macro_tok: 0.7521443251649581
train_precision_micro_tok: 0.873500605260262
train_recall_micro_tok: 0.873500605260262
train_f-score_micro_tok: 0.873500605260262
train_time: 95.4205641746521
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4828    0.0172    0.0333      1624
           N     0.6029    0.7640    0.6740      3310
           P     0.6614    0.7861    0.7184      3610

   micro avg     0.6314    0.6314    0.6314      8544
   macro avg     0.5823    0.5225    0.4752      8544
weighted avg     0.6048    0.6314    0.5710      8544

F1-macro sent:  0.4752114915725527
F1-micro sent:  0.631437265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8853    0.9678    0.9247    124347
           N     0.7526    0.5489    0.6348     14202
           P     0.8528    0.5892    0.6969     25017

   micro avg     0.8735    0.8735    0.8735    163566
   macro avg     0.8303    0.7019    0.7521    163566
weighted avg     0.8688    0.8735    0.8647    163566

F1-macro tok:  0.7521443251649581
F1-micro tok:  0.873500605260262
**************************************************
dev_cost_sum: 44857.0517578125
dev_cost_avg: 40.742099689202995
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18823.0
dev_accuracy_tok: 0.8847889442511987
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6232142857142857
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7064777327935221
dev_label=P_precision_sent: 0.660482374768089
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7243133265513733
dev_precision_macro_sent: 0.7612322201607915
dev_recall_macro_sent: 0.5419853290012046
dev_f-score_macro_sent: 0.48270235888697083
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.88060112297699
dev_label=O_recall_tok: 0.9871644554149954
dev_label=O_f-score_tok: 0.9308428617148178
dev_label=N_precision_tok: 0.8466542750929368
dev_label=N_recall_tok: 0.4905761981690899
dev_label=N_f-score_tok: 0.6212069553358336
dev_label=P_precision_tok: 0.9424212598425197
dev_label=P_recall_tok: 0.5962017434620175
dev_label=P_f-score_tok: 0.7303585049580473
dev_precision_macro_tok: 0.8898922193041487
dev_recall_macro_tok: 0.691314132348701
dev_f-score_macro_tok: 0.7608027740028995
dev_precision_micro_tok: 0.8847889442511987
dev_recall_micro_tok: 0.8847889442511987
dev_f-score_micro_tok: 0.8847889442511987
dev_time: 3.8409628868103027
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6232    0.8154    0.7065       428
           P     0.6605    0.8018    0.7243       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7612    0.5420    0.4827      1101
weighted avg     0.7166    0.6421    0.5703      1101

F1-macro sent:  0.48270235888697083
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9872    0.9308     16205
           N     0.8467    0.4906    0.6212      1857
           P     0.9424    0.5962    0.7304      3212

   micro avg     0.8848    0.8848    0.8848     21274
   macro avg     0.8899    0.6913    0.7608     21274
weighted avg     0.8870    0.8848    0.8735     21274

F1-macro tok:  0.7608027740028995
F1-micro tok:  0.8847889442511987
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333531.42224121094
train_cost_avg: 39.03691739714547
train_count_sent: 8544.0
train_total_correct_sent: 5508.0
train_accuracy_sent: 0.6446629213483146
train_count_tok: 163566.0
train_total_correct_tok: 143332.0
train_accuracy_tok: 0.8762945844490909
train_label=O_precision_sent: 0.43661971830985913
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03657817109144543
train_label=N_precision_sent: 0.6148966165413534
train_label=N_recall_sent: 0.7906344410876133
train_label=N_f-score_sent: 0.6917790113666402
train_label=P_precision_sent: 0.6782072563433721
train_label=P_recall_sent: 0.7922437673130194
train_label=P_f-score_sent: 0.7308036284655679
train_precision_macro_sent: 0.5765745303981948
train_recall_macro_sent: 0.5339889594504572
train_f-score_macro_sent: 0.4863869369745512
train_precision_micro_sent: 0.6446629213483146
train_recall_micro_sent: 0.6446629213483146
train_f-score_micro_sent: 0.6446629213483146
train_label=O_precision_tok: 0.8873362831206885
train_label=O_recall_tok: 0.9692714741811221
train_label=O_f-score_tok: 0.9264959104606113
train_label=N_precision_tok: 0.7593448940269749
train_label=N_recall_tok: 0.5549922546120265
train_label=N_f-score_tok: 0.6412822390366936
train_label=P_precision_tok: 0.8598260067984098
train_label=P_recall_tok: 0.5965543430467283
train_label=P_f-score_tok: 0.7043942039930147
train_precision_macro_tok: 0.835502394648691
train_recall_macro_tok: 0.706939357279959
train_f-score_macro_tok: 0.7573907844967732
train_precision_micro_tok: 0.8762945844490909
train_recall_micro_tok: 0.8762945844490909
train_f-score_micro_tok: 0.8762945844490909
train_time: 95.99435067176819
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4366    0.0191    0.0366      1624
           N     0.6149    0.7906    0.6918      3310
           P     0.6782    0.7922    0.7308      3610

   micro avg     0.6447    0.6447    0.6447      8544
   macro avg     0.5766    0.5340    0.4864      8544
weighted avg     0.6078    0.6447    0.5837      8544

F1-macro sent:  0.4863869369745512
F1-micro sent:  0.6446629213483146
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8873    0.9693    0.9265    124347
           N     0.7593    0.5550    0.6413     14202
           P     0.8598    0.5966    0.7044     25017

   micro avg     0.8763    0.8763    0.8763    163566
   macro avg     0.8355    0.7069    0.7574    163566
weighted avg     0.8720    0.8763    0.8678    163566

F1-macro tok:  0.7573907844967732
F1-micro tok:  0.8762945844490909
**************************************************
dev_cost_sum: 44394.76208496094
dev_cost_avg: 40.32221806081829
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 18929.0
dev_accuracy_tok: 0.8897715521293598
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6117850953206239
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7024875621890546
dev_label=P_precision_sent: 0.6564885496183206
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7107438016528925
dev_precision_macro_sent: 0.42275788164631484
dev_recall_macro_sent: 0.5331803766383206
dev_f-score_macro_sent: 0.47107712128064905
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8989392038325539
dev_label=O_recall_tok: 0.9726627584078988
dev_label=O_f-score_tok: 0.934348972998607
dev_label=N_precision_tok: 0.7638121546961326
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6692889561270802
dev_label=P_precision_tok: 0.8992146596858639
dev_label=P_recall_tok: 0.6416562889165629
dev_label=P_f-score_tok: 0.7489098837209303
dev_precision_macro_tok: 0.8539886727381835
dev_recall_macro_tok: 0.7366344410126594
dev_f-score_macro_tok: 0.7841826042822057
dev_precision_micro_tok: 0.8897715521293598
dev_recall_micro_tok: 0.8897715521293598
dev_f-score_micro_tok: 0.8897715521293598
dev_time: 3.91955828666687
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6118    0.8248    0.7025       428
           P     0.6565    0.7748    0.7107       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.4228    0.5332    0.4711      1101
weighted avg     0.5026    0.6331    0.5597      1101

F1-macro sent:  0.47107712128064905
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9727    0.9343     16205
           N     0.7638    0.5956    0.6693      1857
           P     0.8992    0.6417    0.7489      3212

   micro avg     0.8898    0.8898    0.8898     21274
   macro avg     0.8540    0.7366    0.7842     21274
weighted avg     0.8872    0.8898    0.8832     21274

F1-macro tok:  0.7841826042822057
F1-micro tok:  0.8897715521293598
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330923.28338623047
train_cost_avg: 38.73165769969926
train_count_sent: 8544.0
train_total_correct_sent: 5460.0
train_accuracy_sent: 0.6390449438202247
train_count_tok: 163566.0
train_total_correct_tok: 143606.0
train_accuracy_tok: 0.8779697492143844
train_label=O_precision_sent: 0.38333333333333336
train_label=O_recall_sent: 0.01416256157635468
train_label=O_f-score_sent: 0.02731591448931116
train_label=N_precision_sent: 0.6012788307832838
train_label=N_recall_sent: 0.7954682779456194
train_label=N_f-score_sent: 0.6848744960332943
train_label=P_precision_sent: 0.6830694275274056
train_label=P_recall_sent: 0.7767313019390581
train_label=P_f-score_sent: 0.7268956578094622
train_precision_macro_sent: 0.555893863881341
train_recall_macro_sent: 0.5287873804870107
train_f-score_macro_sent: 0.4796953561106892
train_precision_micro_sent: 0.6390449438202247
train_recall_micro_sent: 0.6390449438202247
train_f-score_micro_sent: 0.6390449438202247
train_label=O_precision_tok: 0.8894024186760775
train_label=O_recall_tok: 0.9687889534930477
train_label=O_f-score_tok: 0.9273998914520407
train_label=N_precision_tok: 0.7634469696969697
train_label=N_recall_tok: 0.5676665258414307
train_label=N_f-score_tok: 0.6511590340037153
train_label=P_precision_tok: 0.8586560364464693
train_label=P_recall_tok: 0.6027101570931767
train_label=P_f-score_tok: 0.7082697230899312
train_precision_macro_tok: 0.8371684749398388
train_recall_macro_tok: 0.7130552121425517
train_f-score_macro_tok: 0.7622762161818958
train_precision_micro_tok: 0.8779697492143844
train_recall_micro_tok: 0.8779697492143844
train_f-score_micro_tok: 0.8779697492143844
train_time: 95.71718311309814
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3833    0.0142    0.0273      1624
           N     0.6013    0.7955    0.6849      3310
           P     0.6831    0.7767    0.7269      3610

   micro avg     0.6390    0.6390    0.6390      8544
   macro avg     0.5559    0.5288    0.4797      8544
weighted avg     0.5944    0.6390    0.5776      8544

F1-macro sent:  0.4796953561106892
F1-micro sent:  0.6390449438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8894    0.9688    0.9274    124347
           N     0.7634    0.5677    0.6512     14202
           P     0.8587    0.6027    0.7083     25017

   micro avg     0.8780    0.8780    0.8780    163566
   macro avg     0.8372    0.7131    0.7623    163566
weighted avg     0.8738    0.8780    0.8699    163566

F1-macro tok:  0.7622762161818958
F1-micro tok:  0.8779697492143844
**************************************************
dev_cost_sum: 44152.390869140625
dev_cost_avg: 40.10208071674898
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 18940.0
dev_accuracy_tok: 0.8902886152110557
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5875190258751902
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.711520737327189
dev_label=P_precision_sent: 0.7184684684684685
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7184684684684685
dev_precision_macro_sent: 0.4353291647812196
dev_recall_macro_sent: 0.5401125424489911
dev_f-score_macro_sent: 0.47666306859855245
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.8944873892681826
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9345083706672954
dev_label=N_precision_tok: 0.779869659666908
dev_label=N_recall_tok: 0.5799676898222941
dev_label=N_f-score_tok: 0.6652254478072884
dev_label=P_precision_tok: 0.9262672811059908
dev_label=P_recall_tok: 0.6257783312577833
dev_label=P_f-score_tok: 0.7469342251950948
dev_precision_macro_tok: 0.8668747766803605
dev_recall_macro_tok: 0.7280081100813053
dev_f-score_macro_tok: 0.7822226812232262
dev_precision_micro_tok: 0.8902886152110557
dev_recall_micro_tok: 0.8902886152110557
dev_f-score_micro_tok: 0.8902886152110557
dev_time: 4.207120418548584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5875    0.9019    0.7115       428
           P     0.7185    0.7185    0.7185       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.4353    0.5401    0.4767      1101
weighted avg     0.5181    0.6403    0.5663      1101

F1-macro sent:  0.47666306859855245
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8945    0.9783    0.9345     16205
           N     0.7799    0.5800    0.6652      1857
           P     0.9263    0.6258    0.7469      3212

   micro avg     0.8903    0.8903    0.8903     21274
   macro avg     0.8669    0.7280    0.7822     21274
weighted avg     0.8893    0.8903    0.8827     21274

F1-macro tok:  0.7822226812232262
F1-micro tok:  0.8902886152110557
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328350.8516845703
train_cost_avg: 38.430577210272745
train_count_sent: 8544.0
train_total_correct_sent: 5531.0
train_accuracy_sent: 0.6473548689138576
train_count_tok: 163566.0
train_total_correct_tok: 144002.0
train_accuracy_tok: 0.8803907902620349
train_label=O_precision_sent: 0.4084507042253521
train_label=O_recall_sent: 0.017857142857142856
train_label=O_f-score_sent: 0.03421828908554572
train_label=N_precision_sent: 0.6140675613142064
train_label=N_recall_sent: 0.8018126888217523
train_label=N_f-score_sent: 0.6954926624737946
train_label=P_precision_sent: 0.6860997350036135
train_label=P_recall_sent: 0.7889196675900277
train_label=P_f-score_sent: 0.7339260404587038
train_precision_macro_sent: 0.5695393335143907
train_recall_macro_sent: 0.5361964997563077
train_f-score_macro_sent: 0.48787899733934803
train_precision_micro_sent: 0.6473548689138576
train_recall_micro_sent: 0.6473548689138576
train_f-score_micro_sent: 0.6473548689138576
train_label=O_precision_tok: 0.8912613038595661
train_label=O_recall_tok: 0.9701400114196563
train_label=O_f-score_tok: 0.9290293763164278
train_label=N_precision_tok: 0.7687724607527898
train_label=N_recall_tok: 0.5723841712434868
train_label=N_f-score_tok: 0.6561995479496286
train_label=P_precision_tok: 0.8638888888888889
train_label=P_recall_tok: 0.6091457808690091
train_label=P_f-score_tok: 0.7144900016409967
train_precision_macro_tok: 0.8413075511670817
train_recall_macro_tok: 0.717223321177384
train_f-score_macro_tok: 0.766572975302351
train_precision_micro_tok: 0.8803907902620349
train_recall_micro_tok: 0.8803907902620349
train_f-score_micro_tok: 0.880390790262035
train_time: 95.37073063850403
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4085    0.0179    0.0342      1624
           N     0.6141    0.8018    0.6955      3310
           P     0.6861    0.7889    0.7339      3610

   micro avg     0.6474    0.6474    0.6474      8544
   macro avg     0.5695    0.5362    0.4879      8544
weighted avg     0.6054    0.6474    0.5860      8544

F1-macro sent:  0.48787899733934803
F1-micro sent:  0.6473548689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8913    0.9701    0.9290    124347
           N     0.7688    0.5724    0.6562     14202
           P     0.8639    0.6091    0.7145     25017

   micro avg     0.8804    0.8804    0.8804    163566
   macro avg     0.8413    0.7172    0.7666    163566
weighted avg     0.8764    0.8804    0.8725    163566

F1-macro tok:  0.766572975302351
F1-micro tok:  0.880390790262035
**************************************************
dev_cost_sum: 43864.023986816406
dev_cost_avg: 39.84016710882507
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18963.0
dev_accuracy_tok: 0.8913697471091473
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6119402985074627
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7158098933074684
dev_label=P_precision_sent: 0.6847389558232931
dev_label=P_recall_sent: 0.7680180180180181
dev_label=P_f-score_sent: 0.7239915074309979
dev_precision_macro_sent: 0.4322264181102519
dev_recall_macro_sent: 0.5433891835760994
dev_f-score_macro_sent: 0.47993380024615545
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8931460674157303
dev_label=O_recall_tok: 0.9810552298673249
dev_label=O_f-score_tok: 0.935038964858109
dev_label=N_precision_tok: 0.8361486486486487
dev_label=N_recall_tok: 0.5331179321486268
dev_label=N_f-score_tok: 0.6511016113120683
dev_label=P_precision_tok: 0.9061135371179039
dev_label=P_recall_tok: 0.6460149439601495
dev_label=P_f-score_tok: 0.7542711741185024
dev_precision_macro_tok: 0.8784694177274277
dev_recall_macro_tok: 0.7200627019920338
dev_f-score_macro_tok: 0.7801372500962266
dev_precision_micro_tok: 0.8913697471091473
dev_recall_micro_tok: 0.8913697471091473
dev_f-score_micro_tok: 0.8913697471091473
dev_time: 4.148606777191162
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6119    0.8621    0.7158       428
           P     0.6847    0.7680    0.7240       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.4322    0.5434    0.4799      1101
weighted avg     0.5140    0.6449    0.5702      1101

F1-macro sent:  0.47993380024615545
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8931    0.9811    0.9350     16205
           N     0.8361    0.5331    0.6511      1857
           P     0.9061    0.6460    0.7543      3212

   micro avg     0.8914    0.8914    0.8914     21274
   macro avg     0.8785    0.7201    0.7801     21274
weighted avg     0.8901    0.8914    0.8830     21274

F1-macro tok:  0.7801372500962266
F1-micro tok:  0.8913697471091473
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325624.9132080078
train_cost_avg: 38.1115301039335
train_count_sent: 8544.0
train_total_correct_sent: 5575.0
train_accuracy_sent: 0.6525046816479401
train_count_tok: 163566.0
train_total_correct_tok: 144402.0
train_accuracy_tok: 0.8828362862697626
train_label=O_precision_sent: 0.32142857142857145
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010895883777239709
train_label=N_precision_sent: 0.6228624970719138
train_label=N_recall_sent: 0.8033232628398792
train_label=N_f-score_sent: 0.7016756828077583
train_label=P_precision_sent: 0.6844831645867672
train_label=P_recall_sent: 0.8052631578947368
train_label=P_f-score_sent: 0.7399770904925544
train_precision_macro_sent: 0.5429247443624176
train_recall_macro_sent: 0.5380427642185994
train_f-score_macro_sent: 0.4841828856925175
train_precision_micro_sent: 0.6525046816479401
train_recall_micro_sent: 0.6525046816479401
train_f-score_micro_sent: 0.6525046816479401
train_label=O_precision_tok: 0.8940463130429626
train_label=O_recall_tok: 0.9699791711902981
train_label=O_f-score_tok: 0.9304661433723554
train_label=N_precision_tok: 0.7692021918826043
train_label=N_recall_tok: 0.5831573017884805
train_label=N_f-score_tok: 0.6633825944170771
train_label=P_precision_tok: 0.8666927505449668
train_label=P_recall_tok: 0.6198185234040853
train_label=P_f-score_tok: 0.722755663279575
train_precision_macro_tok: 0.8433137518235112
train_recall_macro_tok: 0.7243183321276213
train_f-score_macro_tok: 0.7722014670230025
train_precision_micro_tok: 0.8828362862697626
train_recall_micro_tok: 0.8828362862697626
train_f-score_micro_tok: 0.8828362862697626
train_time: 95.74760460853577
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3214    0.0055    0.0109      1624
           N     0.6229    0.8033    0.7017      3310
           P     0.6845    0.8053    0.7400      3610

   micro avg     0.6525    0.6525    0.6525      8544
   macro avg     0.5429    0.5380    0.4842      8544
weighted avg     0.5916    0.6525    0.5866      8544

F1-macro sent:  0.4841828856925175
F1-micro sent:  0.6525046816479401
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8940    0.9700    0.9305    124347
           N     0.7692    0.5832    0.6634     14202
           P     0.8667    0.6198    0.7228     25017

   micro avg     0.8828    0.8828    0.8828    163566
   macro avg     0.8433    0.7243    0.7722    163566
weighted avg     0.8790    0.8828    0.8755    163566

F1-macro tok:  0.7722014670230025
F1-micro tok:  0.8828362862697626
**************************************************
dev_cost_sum: 43729.12487792969
dev_cost_avg: 39.7176429408989
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 18994.0
dev_accuracy_tok: 0.892826924884836
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6827586206896552
dev_label=N_recall_sent: 0.6939252336448598
dev_label=N_f-score_sent: 0.6882966396292005
dev_label=P_precision_sent: 0.6006006006006006
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.7207207207207208
dev_precision_macro_sent: 0.4277864070967519
dev_recall_macro_sent: 0.5316087115152536
dev_f-score_macro_sent: 0.4696724534499738
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8999145542580461
dev_label=O_recall_tok: 0.9748842949706881
dev_label=O_f-score_tok: 0.9359004739336493
dev_label=N_precision_tok: 0.7963369963369963
dev_label=N_recall_tok: 0.5853527194399569
dev_label=N_f-score_tok: 0.6747361887026692
dev_label=P_precision_tok: 0.8959218351741717
dev_label=P_recall_tok: 0.6566002490660025
dev_label=P_f-score_tok: 0.7578153072224219
dev_precision_macro_tok: 0.8640577952564047
dev_recall_macro_tok: 0.7389457544922159
dev_f-score_macro_tok: 0.7894839899529135
dev_precision_micro_tok: 0.892826924884836
dev_recall_micro_tok: 0.892826924884836
dev_f-score_micro_tok: 0.892826924884836
dev_time: 4.202917814254761
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6828    0.6939    0.6883       428
           P     0.6006    0.9009    0.7207       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.4278    0.5316    0.4697      1101
weighted avg     0.5076    0.6331    0.5582      1101

F1-macro sent:  0.4696724534499738
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8999    0.9749    0.9359     16205
           N     0.7963    0.5854    0.6747      1857
           P     0.8959    0.6566    0.7578      3212

   micro avg     0.8928    0.8928    0.8928     21274
   macro avg     0.8641    0.7389    0.7895     21274
weighted avg     0.8903    0.8928    0.8862     21274

F1-macro tok:  0.7894839899529135
F1-micro tok:  0.892826924884836
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323549.7166748047
train_cost_avg: 37.868646614560475
train_count_sent: 8544.0
train_total_correct_sent: 5620.0
train_accuracy_sent: 0.6577715355805244
train_count_tok: 163566.0
train_total_correct_tok: 144631.0
train_accuracy_tok: 0.8842363327341868
train_label=O_precision_sent: 0.46
train_label=O_recall_sent: 0.01416256157635468
train_label=O_f-score_sent: 0.027479091995221024
train_label=N_precision_sent: 0.6316165951359084
train_label=N_recall_sent: 0.8003021148036253
train_label=N_f-score_sent: 0.7060234541577824
train_label=P_precision_sent: 0.6855813953488372
train_label=P_recall_sent: 0.8166204986149584
train_label=P_f-score_sent: 0.7453855878634639
train_precision_macro_sent: 0.5923993301615819
train_recall_macro_sent: 0.5436950583316461
train_f-score_macro_sent: 0.4929627113388224
train_precision_micro_sent: 0.6577715355805244
train_recall_micro_sent: 0.6577715355805244
train_f-score_micro_sent: 0.6577715355805244
train_label=O_precision_tok: 0.8947766282275517
train_label=O_recall_tok: 0.9709442125664471
train_label=O_f-score_tok: 0.93130565915481
train_label=N_precision_tok: 0.7752882112309408
train_label=N_recall_tok: 0.5871708210111252
train_label=N_f-score_tok: 0.6682426476480487
train_label=P_precision_tok: 0.8702315695267927
train_label=P_recall_tok: 0.6218971099652236
train_label=P_f-score_tok: 0.7253992306795664
train_precision_macro_tok: 0.8467654696617618
train_recall_macro_tok: 0.7266707145142653
train_f-score_macro_tok: 0.7749825124941417
train_precision_micro_tok: 0.8842363327341868
train_recall_micro_tok: 0.8842363327341868
train_f-score_micro_tok: 0.8842363327341868
train_time: 95.55057740211487
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4600    0.0142    0.0275      1624
           N     0.6316    0.8003    0.7060      3310
           P     0.6856    0.8166    0.7454      3610

   micro avg     0.6578    0.6578    0.6578      8544
   macro avg     0.5924    0.5437    0.4930      8544
weighted avg     0.6218    0.6578    0.5937      8544

F1-macro sent:  0.4929627113388224
F1-micro sent:  0.6577715355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9709    0.9313    124347
           N     0.7753    0.5872    0.6682     14202
           P     0.8702    0.6219    0.7254     25017

   micro avg     0.8842    0.8842    0.8842    163566
   macro avg     0.8468    0.7267    0.7750    163566
weighted avg     0.8806    0.8842    0.8770    163566

F1-macro tok:  0.7749825124941417
F1-micro tok:  0.8842363327341868
**************************************************
dev_cost_sum: 43391.026794433594
dev_cost_avg: 39.41056021292788
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19001.0
dev_accuracy_tok: 0.8931559650277334
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.6295025728987993
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7260138476755686
dev_label=P_precision_sent: 0.6867704280155642
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7369519832985386
dev_precision_macro_sent: 0.7720910003047878
dev_recall_macro_sent: 0.5566629764891202
dev_f-score_macro_sent: 0.499100198307535
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8974417025130179
dev_label=O_recall_tok: 0.9784634372107375
dev_label=O_f-score_tok: 0.9362028754465208
dev_label=N_precision_tok: 0.7877055039313795
dev_label=N_recall_tok: 0.5934302638664513
dev_label=N_f-score_tok: 0.6769041769041769
dev_label=P_precision_tok: 0.9256909832351609
dev_label=P_recall_tok: 0.636052303860523
dev_label=P_f-score_tok: 0.7540136556560251
dev_precision_macro_tok: 0.8702793965598526
dev_recall_macro_tok: 0.7359820016459039
dev_f-score_macro_tok: 0.7890402360022409
dev_precision_micro_tok: 0.8931559650277334
dev_recall_micro_tok: 0.8931559650277334
dev_f-score_micro_tok: 0.8931559650277334
dev_time: 4.119582414627075
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.6295    0.8575    0.7260       428
           P     0.6868    0.7950    0.7370       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7721    0.5567    0.4991      1101
weighted avg     0.7297    0.6576    0.5866      1101

F1-macro sent:  0.499100198307535
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8974    0.9785    0.9362     16205
           N     0.7877    0.5934    0.6769      1857
           P     0.9257    0.6361    0.7540      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8703    0.7360    0.7890     21274
weighted avg     0.8921    0.8932    0.8861     21274

F1-macro tok:  0.7890402360022409
F1-micro tok:  0.8931559650277334
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321470.20404052734
train_cost_avg: 37.62525796354487
train_count_sent: 8544.0
train_total_correct_sent: 5624.0
train_accuracy_sent: 0.6582397003745318
train_count_tok: 163566.0
train_total_correct_tok: 144949.0
train_accuracy_tok: 0.8861805020603304
train_label=O_precision_sent: 0.4013605442176871
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06662902315076227
train_label=N_precision_sent: 0.6293225959261014
train_label=N_recall_sent: 0.8027190332326284
train_label=N_f-score_sent: 0.7055231014338821
train_label=P_precision_sent: 0.6965269461077844
train_label=P_recall_sent: 0.8055401662049861
train_label=P_f-score_sent: 0.747077713551702
train_precision_macro_sent: 0.575736695417191
train_recall_macro_sent: 0.5481964162328995
train_f-score_macro_sent: 0.5064099460454488
train_precision_micro_sent: 0.6582397003745318
train_recall_micro_sent: 0.6582397003745318
train_f-score_micro_sent: 0.6582397003745318
train_label=O_precision_tok: 0.8970130285170679
train_label=O_recall_tok: 0.9706225321077308
train_label=O_f-score_tok: 0.9323671870775364
train_label=N_precision_tok: 0.7784902894833272
train_label=N_recall_tok: 0.5983664272637657
train_label=N_f-score_tok: 0.6766462297953658
train_label=P_precision_tok: 0.8706005856677165
train_label=P_recall_tok: 0.6298517008434265
train_label=P_f-score_tok: 0.730911958437703
train_precision_macro_tok: 0.8487013012227038
train_recall_macro_tok: 0.7329468867383077
train_f-score_macro_tok: 0.7799751251035351
train_precision_micro_tok: 0.8861805020603304
train_recall_micro_tok: 0.8861805020603304
train_f-score_micro_tok: 0.8861805020603304
train_time: 95.91523718833923
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4014    0.0363    0.0666      1624
           N     0.6293    0.8027    0.7055      3310
           P     0.6965    0.8055    0.7471      3610

   micro avg     0.6582    0.6582    0.6582      8544
   macro avg     0.5757    0.5482    0.5064      8544
weighted avg     0.6144    0.6582    0.6016      8544

F1-macro sent:  0.5064099460454488
F1-micro sent:  0.6582397003745318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8970    0.9706    0.9324    124347
           N     0.7785    0.5984    0.6766     14202
           P     0.8706    0.6299    0.7309     25017

   micro avg     0.8862    0.8862    0.8862    163566
   macro avg     0.8487    0.7329    0.7800    163566
weighted avg     0.8827    0.8862    0.8794    163566

F1-macro tok:  0.7799751251035351
F1-micro tok:  0.8861805020603304
**************************************************
dev_cost_sum: 43319.55651855469
dev_cost_avg: 39.34564624755194
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19040.0
dev_accuracy_tok: 0.8949891886810191
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05761316872427984
dev_label=N_precision_sent: 0.6660117878192534
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7235859124866595
dev_label=P_precision_sent: 0.6487889273356401
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7338551859099804
dev_precision_macro_sent: 0.6049335717182979
dev_recall_macro_sent: 0.5557394516501565
dev_f-score_macro_sent: 0.5050180890403065
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.89859011381009
dev_label=O_recall_tok: 0.9793273680962666
dev_label=O_f-score_tok: 0.9372231736845215
dev_label=N_precision_tok: 0.8160123171670516
dev_label=N_recall_tok: 0.5708131394722671
dev_label=N_f-score_tok: 0.6717363751584283
dev_label=P_precision_tok: 0.9118409680207433
dev_label=P_recall_tok: 0.6569115815691158
dev_label=P_f-score_tok: 0.7636626854867896
dev_precision_macro_tok: 0.875481132999295
dev_recall_macro_tok: 0.7356840297125498
dev_f-score_macro_tok: 0.7908740781099132
dev_precision_micro_tok: 0.8949891886810191
dev_recall_micro_tok: 0.8949891886810191
dev_f-score_micro_tok: 0.8949891886810191
dev_time: 3.952610731124878
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0306    0.0576       229
           N     0.6660    0.7921    0.7236       428
           P     0.6488    0.8446    0.7339       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6049    0.5557    0.5050      1101
weighted avg     0.6245    0.6549    0.5892      1101

F1-macro sent:  0.5050180890403065
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8986    0.9793    0.9372     16205
           N     0.8160    0.5708    0.6717      1857
           P     0.9118    0.6569    0.7637      3212

   micro avg     0.8950    0.8950    0.8950     21274
   macro avg     0.8755    0.7357    0.7909     21274
weighted avg     0.8934    0.8950    0.8878     21274

F1-macro tok:  0.7908740781099132
F1-micro tok:  0.8949891886810191
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319268.06774902344
train_cost_avg: 37.36751729272278
train_count_sent: 8544.0
train_total_correct_sent: 5672.0
train_accuracy_sent: 0.6638576779026217
train_count_tok: 163566.0
train_total_correct_tok: 145370.0
train_accuracy_tok: 0.8887543866084638
train_label=O_precision_sent: 0.4748201438848921
train_label=O_recall_sent: 0.04064039408866995
train_label=O_f-score_sent: 0.07487237663074305
train_label=N_precision_sent: 0.6293162588611937
train_label=N_recall_sent: 0.8314199395770393
train_label=N_f-score_sent: 0.716386828061955
train_label=P_precision_sent: 0.7078373015873016
train_label=P_recall_sent: 0.7905817174515235
train_label=P_f-score_sent: 0.7469248887725727
train_precision_macro_sent: 0.6039912347777958
train_recall_macro_sent: 0.5542140170390776
train_f-score_macro_sent: 0.5127280311550902
train_precision_micro_sent: 0.6638576779026217
train_recall_micro_sent: 0.6638576779026217
train_f-score_micro_sent: 0.6638576779026217
train_label=O_precision_tok: 0.8998412544623893
train_label=O_recall_tok: 0.9709763806123187
train_label=O_f-score_tok: 0.9340564125574414
train_label=N_precision_tok: 0.7813036795949734
train_label=N_recall_tok: 0.6085058442472892
train_label=N_f-score_tok: 0.6841626093496418
train_label=P_precision_tok: 0.8724356176342208
train_label=P_recall_tok: 0.6391653675500659
train_label=P_f-score_tok: 0.7378013611719921
train_precision_macro_tok: 0.8511935172305279
train_recall_macro_tok: 0.7395491974698913
train_f-score_macro_tok: 0.7853401276930251
train_precision_micro_tok: 0.8887543866084638
train_recall_micro_tok: 0.8887543866084638
train_f-score_micro_tok: 0.8887543866084638
train_time: 95.13682270050049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4748    0.0406    0.0749      1624
           N     0.6293    0.8314    0.7164      3310
           P     0.7078    0.7906    0.7469      3610

   micro avg     0.6639    0.6639    0.6639      8544
   macro avg     0.6040    0.5542    0.5127      8544
weighted avg     0.6331    0.6639    0.6074      8544

F1-macro sent:  0.5127280311550902
F1-micro sent:  0.6638576779026217
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8998    0.9710    0.9341    124347
           N     0.7813    0.6085    0.6842     14202
           P     0.8724    0.6392    0.7378     25017

   micro avg     0.8888    0.8888    0.8888    163566
   macro avg     0.8512    0.7395    0.7853    163566
weighted avg     0.8854    0.8888    0.8823    163566

F1-macro tok:  0.7853401276930251
F1-micro tok:  0.8887543866084638
**************************************************
dev_cost_sum: 43073.605224609375
dev_cost_avg: 39.12225724306029
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19055.0
dev_accuracy_tok: 0.8956942747015136
dev_label=O_precision_sent: 0.9
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07531380753138077
dev_label=N_precision_sent: 0.6333907056798623
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7294350842418236
dev_label=P_precision_sent: 0.692156862745098
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.740041928721174
dev_precision_macro_sent: 0.7418491894749867
dev_recall_macro_sent: 0.5647198130669543
dev_f-score_macro_sent: 0.5149302734981261
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.8972289632597776
dev_label=O_recall_tok: 0.9810552298673249
dev_label=O_f-score_tok: 0.9372715481664897
dev_label=N_precision_tok: 0.8276679841897233
dev_label=N_recall_tok: 0.5638126009693053
dev_label=N_f-score_tok: 0.6707238949391415
dev_label=P_precision_tok: 0.9213973799126638
dev_label=P_recall_tok: 0.6569115815691158
dev_label=P_f-score_tok: 0.7669938204289348
dev_precision_macro_tok: 0.8820981091207215
dev_recall_macro_tok: 0.7339264708019154
dev_f-score_macro_tok: 0.7916630878448553
dev_precision_micro_tok: 0.8956942747015136
dev_recall_micro_tok: 0.8956942747015136
dev_f-score_micro_tok: 0.8956942747015136
dev_time: 4.179208755493164
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.9000    0.0393    0.0753       229
           N     0.6334    0.8598    0.7294       428
           P     0.6922    0.7950    0.7400       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.7418    0.5647    0.5149      1101
weighted avg     0.7125    0.6630    0.5977      1101

F1-macro sent:  0.5149302734981261
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9811    0.9373     16205
           N     0.8277    0.5638    0.6707      1857
           P     0.9214    0.6569    0.7670      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8821    0.7339    0.7917     21274
weighted avg     0.8948    0.8957    0.8883     21274

F1-macro tok:  0.7916630878448553
F1-micro tok:  0.8956942747015136
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317543.8095703125
train_cost_avg: 37.16570804895979
train_count_sent: 8544.0
train_total_correct_sent: 5673.0
train_accuracy_sent: 0.6639747191011236
train_count_tok: 163566.0
train_total_correct_tok: 145640.0
train_accuracy_tok: 0.8904050964136802
train_label=O_precision_sent: 0.4258064516129032
train_label=O_recall_sent: 0.04064039408866995
train_label=O_f-score_sent: 0.07419898819561552
train_label=N_precision_sent: 0.632767046776821
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7148678848429079
train_label=P_precision_sent: 0.7057673509286413
train_label=P_recall_sent: 0.8
train_label=P_f-score_sent: 0.7499350817969359
train_precision_macro_sent: 0.5881136164394551
train_recall_macro_sent: 0.5540301817153573
train_f-score_macro_sent: 0.5130006516118198
train_precision_micro_sent: 0.6639747191011236
train_recall_micro_sent: 0.6639747191011236
train_f-score_micro_sent: 0.6639747191011236
train_label=O_precision_tok: 0.9011571949772814
train_label=O_recall_tok: 0.9713382711283747
train_label=O_f-score_tok: 0.9349325406961894
train_label=N_precision_tok: 0.7865515674693321
train_label=N_recall_tok: 0.609491620898465
train_label=N_f-score_tok: 0.6867933510532788
train_label=P_precision_tok: 0.8743119266055046
train_label=P_recall_tok: 0.64759963225007
train_label=P_f-score_tok: 0.7440696259214183
train_precision_macro_tok: 0.854006896350706
train_recall_macro_tok: 0.7428098414256366
train_f-score_macro_tok: 0.7885985058902955
train_precision_micro_tok: 0.8904050964136802
train_recall_micro_tok: 0.8904050964136802
train_f-score_micro_tok: 0.8904050964136802
train_time: 96.0049991607666
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4258    0.0406    0.0742      1624
           N     0.6328    0.8215    0.7149      3310
           P     0.7058    0.8000    0.7499      3610

   micro avg     0.6640    0.6640    0.6640      8544
   macro avg     0.5881    0.5540    0.5130      8544
weighted avg     0.6243    0.6640    0.6079      8544

F1-macro sent:  0.5130006516118198
F1-micro sent:  0.6639747191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9012    0.9713    0.9349    124347
           N     0.7866    0.6095    0.6868     14202
           P     0.8743    0.6476    0.7441     25017

   micro avg     0.8904    0.8904    0.8904    163566
   macro avg     0.8540    0.7428    0.7886    163566
weighted avg     0.8871    0.8904    0.8842    163566

F1-macro tok:  0.7885985058902955
F1-micro tok:  0.8904050964136802
**************************************************
dev_cost_sum: 43050.63659667969
dev_cost_avg: 39.10139563731125
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19038.0
dev_accuracy_tok: 0.8948951772116198
dev_label=O_precision_sent: 0.8235294117647058
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.1138211382113821
dev_label=N_precision_sent: 0.6478102189781022
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7274590163934426
dev_label=P_precision_sent: 0.6772388059701493
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7408163265306122
dev_precision_macro_sent: 0.7161928122376525
dev_recall_macro_sent: 0.5693807303610184
dev_f-score_macro_sent: 0.5273654937118123
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.8950620751643166
dev_label=O_recall_tok: 0.9832150570811478
dev_label=O_f-score_tok: 0.9370699288360878
dev_label=N_precision_tok: 0.8366174055829229
dev_label=N_recall_tok: 0.5487345180398492
dev_label=N_f-score_tok: 0.6627642276422764
dev_label=P_precision_tok: 0.9250554323725055
dev_label=P_recall_tok: 0.6494396014943961
dev_label=P_f-score_tok: 0.7631241997439182
dev_precision_macro_tok: 0.8855783043732485
dev_recall_macro_tok: 0.7271297255384644
dev_f-score_macro_tok: 0.7876527854074274
dev_precision_micro_tok: 0.8948951772116198
dev_recall_micro_tok: 0.8948951772116198
dev_f-score_micro_tok: 0.8948951772116199
dev_time: 4.124038457870483
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8235    0.0611    0.1138       229
           N     0.6478    0.8294    0.7275       428
           P     0.6772    0.8176    0.7408       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7162    0.5694    0.5274      1101
weighted avg     0.6962    0.6649    0.6052      1101

F1-macro sent:  0.5273654937118123
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8951    0.9832    0.9371     16205
           N     0.8366    0.5487    0.6628      1857
           P     0.9251    0.6494    0.7631      3212

   micro avg     0.8949    0.8949    0.8949     21274
   macro avg     0.8856    0.7271    0.7877     21274
weighted avg     0.8945    0.8949    0.8869     21274

F1-macro tok:  0.7876527854074274
F1-micro tok:  0.8948951772116199
**************************************************
Best epoch: 17
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315559.69219970703
train_cost_avg: 36.93348457393575
train_count_sent: 8544.0
train_total_correct_sent: 5691.0
train_accuracy_sent: 0.6660814606741573
train_count_tok: 163566.0
train_total_correct_tok: 145725.0
train_accuracy_tok: 0.8909247643153223
train_label=O_precision_sent: 0.41605839416058393
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.06473594548551959
train_label=N_precision_sent: 0.6256503053607781
train_label=N_recall_sent: 0.8356495468277946
train_label=N_f-score_sent: 0.7155607295304618
train_label=P_precision_sent: 0.7195183140993477
train_label=P_recall_sent: 0.7944598337950138
train_label=P_f-score_sent: 0.755134281200632
train_precision_macro_sent: 0.5870756712069033
train_recall_macro_sent: 0.5550693009300987
train_f-score_macro_sent: 0.5118103187388711
train_precision_micro_sent: 0.6660814606741573
train_recall_micro_sent: 0.6660814606741573
train_f-score_micro_sent: 0.6660814606741573
train_label=O_precision_tok: 0.9018103873213139
train_label=O_recall_tok: 0.97104875871553
train_label=O_f-score_tok: 0.9351497244821697
train_label=N_precision_tok: 0.7876322213181448
train_label=N_recall_tok: 0.6134347275031685
train_label=N_f-score_tok: 0.6897043106519416
train_label=P_precision_tok: 0.873999247756703
train_label=P_recall_tok: 0.6501978654514929
train_label=P_f-score_tok: 0.7456679196846061
train_precision_macro_tok: 0.8544806187987205
train_recall_macro_tok: 0.7448937838900638
train_f-score_macro_tok: 0.7901739849395725
train_precision_micro_tok: 0.8909247643153223
train_recall_micro_tok: 0.8909247643153223
train_f-score_micro_tok: 0.8909247643153223
train_time: 94.8320631980896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4161    0.0351    0.0647      1624
           N     0.6257    0.8356    0.7156      3310
           P     0.7195    0.7945    0.7551      3610

   micro avg     0.6661    0.6661    0.6661      8544
   macro avg     0.5871    0.5551    0.5118      8544
weighted avg     0.6255    0.6661    0.6086      8544

F1-macro sent:  0.5118103187388711
F1-micro sent:  0.6660814606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9018    0.9710    0.9351    124347
           N     0.7876    0.6134    0.6897     14202
           P     0.8740    0.6502    0.7457     25017

   micro avg     0.8909    0.8909    0.8909    163566
   macro avg     0.8545    0.7449    0.7902    163566
weighted avg     0.8876    0.8909    0.8849    163566

F1-macro tok:  0.7901739849395725
F1-micro tok:  0.8909247643153223
**************************************************
dev_cost_sum: 42777.00866699219
dev_cost_avg: 38.85286890734985
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6404293381037567
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7254305977710234
dev_label=P_precision_sent: 0.6847014925373134
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7489795918367347
dev_precision_macro_sent: 0.7194880546581345
dev_recall_macro_sent: 0.5616197452809296
dev_f-score_macro_sent: 0.5056544603657066
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9054503729202524
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.9384272335364947
dev_label=N_precision_tok: 0.7839127471029311
dev_label=N_recall_tok: 0.6192784060312332
dev_label=N_f-score_tok: 0.6919374247894103
dev_label=P_precision_tok: 0.9057635675220866
dev_label=P_recall_tok: 0.6702988792029888
dev_label=P_f-score_tok: 0.7704419395240651
dev_precision_macro_tok: 0.8650422291817567
dev_recall_macro_tok: 0.7544914102071494
dev_f-score_macro_tok: 0.80026886594999
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 4.408725023269653
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6404    0.8364    0.7254       428
           P     0.6847    0.8266    0.7490       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.7195    0.5616    0.5057      1101
weighted avg     0.6984    0.6630    0.5929      1101

F1-macro sent:  0.5056544603657066
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9055    0.9739    0.9384     16205
           N     0.7839    0.6193    0.6919      1857
           P     0.9058    0.6703    0.7704      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8650    0.7545    0.8003     21274
weighted avg     0.8949    0.8971    0.8915     21274

F1-macro tok:  0.80026886594999
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 313886.5272216797
train_cost_avg: 36.73765533961607
train_count_sent: 8544.0
train_total_correct_sent: 5756.0
train_accuracy_sent: 0.673689138576779
train_count_tok: 163566.0
train_total_correct_tok: 146006.0
train_accuracy_tok: 0.8926427252607511
train_label=O_precision_sent: 0.4918032786885246
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.09961261759822912
train_label=N_precision_sent: 0.6495215311004785
train_label=N_recall_sent: 0.8202416918429003
train_label=N_f-score_sent: 0.7249666221628839
train_label=P_precision_sent: 0.7058120066969624
train_label=P_recall_sent: 0.8174515235457064
train_label=P_f-score_sent: 0.7575407521499166
train_precision_macro_sent: 0.6157122721619884
train_recall_macro_sent: 0.5643706448668098
train_f-score_macro_sent: 0.5273733306370099
train_precision_micro_sent: 0.673689138576779
train_recall_micro_sent: 0.673689138576779
train_f-score_micro_sent: 0.673689138576779
train_label=O_precision_tok: 0.9037661287908272
train_label=O_recall_tok: 0.9711050527958053
train_label=O_f-score_tok: 0.9362262995282196
train_label=N_precision_tok: 0.7895579471671262
train_label=N_recall_tok: 0.6250528094634559
train_label=N_f-score_tok: 0.6977402240125762
train_label=P_precision_tok: 0.8751536529314307
train_label=P_recall_tok: 0.654554902666187
train_label=P_f-score_tok: 0.7489480424442005
train_precision_macro_tok: 0.8561592429631281
train_recall_macro_tok: 0.7502375883084828
train_f-score_macro_tok: 0.7943048553283321
train_precision_micro_tok: 0.8926427252607511
train_recall_micro_tok: 0.8926427252607511
train_f-score_micro_tok: 0.8926427252607512
train_time: 95.2344913482666
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4918    0.0554    0.0996      1624
           N     0.6495    0.8202    0.7250      3310
           P     0.7058    0.8175    0.7575      3610

   micro avg     0.6737    0.6737    0.6737      8544
   macro avg     0.6157    0.5644    0.5274      8544
weighted avg     0.6433    0.6737    0.6199      8544

F1-macro sent:  0.5273733306370099
F1-micro sent:  0.673689138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9038    0.9711    0.9362    124347
           N     0.7896    0.6251    0.6977     14202
           P     0.8752    0.6546    0.7489     25017

   micro avg     0.8926    0.8926    0.8926    163566
   macro avg     0.8562    0.7502    0.7943    163566
weighted avg     0.8895    0.8926    0.8869    163566

F1-macro tok:  0.7943048553283321
F1-micro tok:  0.8926427252607512
**************************************************
dev_cost_sum: 42665.797119140625
dev_cost_avg: 38.751859327103205
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19102.0
dev_accuracy_tok: 0.8979035442323964
dev_label=O_precision_sent: 0.65
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10441767068273092
dev_label=N_precision_sent: 0.6319444444444444
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.7250996015936255
dev_label=P_precision_sent: 0.697029702970297
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7418335089567966
dev_precision_macro_sent: 0.6596580491382472
dev_recall_macro_sent: 0.5666762138214613
dev_f-score_macro_sent: 0.5237835937443843
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9087810514153668
dev_label=O_recall_tok: 0.9707497685899413
dev_label=O_f-score_tok: 0.938743846039087
dev_label=N_precision_tok: 0.786342123056119
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.697242206235012
dev_label=P_precision_tok: 0.8885311871227364
dev_label=P_recall_tok: 0.6874221668742216
dev_label=P_f-score_tok: 0.7751448130595049
dev_precision_macro_tok: 0.8612181205314074
dev_recall_macro_tok: 0.7614836266661192
dev_f-score_macro_tok: 0.8037102884445346
dev_precision_micro_tok: 0.8979035442323964
dev_recall_micro_tok: 0.8979035442323964
dev_f-score_micro_tok: 0.8979035442323964
dev_time: 4.455942392349243
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6500    0.0568    0.1044       229
           N     0.6319    0.8505    0.7251       428
           P     0.6970    0.7928    0.7418       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6597    0.5667    0.5238      1101
weighted avg     0.6619    0.6621    0.6028      1101

F1-macro sent:  0.5237835937443843
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9707    0.9387     16205
           N     0.7863    0.6263    0.6972      1857
           P     0.8885    0.6874    0.7751      3212

   micro avg     0.8979    0.8979    0.8979     21274
   macro avg     0.8612    0.7615    0.8037     21274
weighted avg     0.8950    0.8979    0.8930     21274

F1-macro tok:  0.8037102884445346
F1-micro tok:  0.8979035442323964
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 312008.67474365234
train_cost_avg: 36.517869234978036
train_count_sent: 8544.0
train_total_correct_sent: 5708.0
train_accuracy_sent: 0.6680711610486891
train_count_tok: 163566.0
train_total_correct_tok: 146465.0
train_accuracy_tok: 0.8954489319296186
train_label=O_precision_sent: 0.4222222222222222
train_label=O_recall_sent: 0.058497536945812806
train_label=O_f-score_sent: 0.10275824770146025
train_label=N_precision_sent: 0.6449448969813129
train_label=N_recall_sent: 0.8132930513595166
train_label=N_f-score_sent: 0.7194013896312133
train_label=P_precision_sent: 0.7047044632086852
train_label=P_recall_sent: 0.8091412742382271
train_label=P_f-score_sent: 0.7533204384268214
train_precision_macro_sent: 0.5906238608040734
train_recall_macro_sent: 0.5603106208478522
train_f-score_macro_sent: 0.525160025253165
train_precision_micro_sent: 0.6680711610486891
train_recall_micro_sent: 0.6680711610486891
train_f-score_micro_sent: 0.6680711610486891
train_label=O_precision_tok: 0.9064853995978512
train_label=O_recall_tok: 0.9716358255526872
train_label=O_f-score_tok: 0.9379306061770518
train_label=N_precision_tok: 0.7931125362382501
train_label=N_recall_tok: 0.6356851147725673
train_label=N_f-score_tok: 0.7057260113347665
train_label=P_precision_tok: 0.8792528705222499
train_label=P_recall_tok: 0.6642283247391774
train_label=P_f-score_tok: 0.7567629110119318
train_precision_macro_tok: 0.8596169354527837
train_recall_macro_tok: 0.7571830883548106
train_f-score_macro_tok: 0.8001398428412502
train_precision_micro_tok: 0.8954489319296186
train_recall_micro_tok: 0.8954489319296186
train_f-score_micro_tok: 0.8954489319296186
train_time: 163.79841589927673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4222    0.0585    0.1028      1624
           N     0.6449    0.8133    0.7194      3310
           P     0.7047    0.8091    0.7533      3610

   micro avg     0.6681    0.6681    0.6681      8544
   macro avg     0.5906    0.5603    0.5252      8544
weighted avg     0.6279    0.6681    0.6165      8544

F1-macro sent:  0.525160025253165
F1-micro sent:  0.6680711610486891
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9716    0.9379    124347
           N     0.7931    0.6357    0.7057     14202
           P     0.8793    0.6642    0.7568     25017

   micro avg     0.8954    0.8954    0.8954    163566
   macro avg     0.8596    0.7572    0.8001    163566
weighted avg     0.8925    0.8954    0.8901    163566

F1-macro tok:  0.8001398428412502
F1-micro tok:  0.8954489319296186
**************************************************
dev_cost_sum: 42518.026611328125
dev_cost_avg: 38.617644515284404
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19129.0
dev_accuracy_tok: 0.8991726990692864
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.7060133630289532
dev_label=N_recall_sent: 0.7406542056074766
dev_label=N_f-score_sent: 0.7229190421892817
dev_label=P_precision_sent: 0.6242236024844721
dev_label=P_recall_sent: 0.9054054054054054
dev_label=P_f-score_sent: 0.738970588235294
dev_precision_macro_sent: 0.6934123218378083
dev_recall_macro_sent: 0.5574201614584425
dev_f-score_macro_sent: 0.5041741806056602
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9084365102217103
dev_label=O_recall_tok: 0.9734649799444616
dev_label=O_f-score_tok: 0.9398272266904976
dev_label=N_precision_tok: 0.7886843899113838
dev_label=N_recall_tok: 0.6230479267635972
dev_label=N_f-score_tok: 0.6961492178098676
dev_label=P_precision_tok: 0.8996723996723996
dev_label=P_recall_tok: 0.683997509339975
dev_label=P_f-score_tok: 0.7771489211177927
dev_precision_macro_tok: 0.8655977666018314
dev_recall_macro_tok: 0.7601701386826779
dev_f-score_macro_tok: 0.8043751218727193
dev_precision_micro_tok: 0.8991726990692864
dev_recall_micro_tok: 0.8991726990692864
dev_f-score_micro_tok: 0.8991726990692864
dev_time: 11.302834510803223
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.7060    0.7407    0.7229       428
           P     0.6242    0.9054    0.7390       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.6934    0.5574    0.5042      1101
weighted avg     0.6822    0.6585    0.5896      1101

F1-macro sent:  0.5041741806056602
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9735    0.9398     16205
           N     0.7887    0.6230    0.6961      1857
           P     0.8997    0.6840    0.7771      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8656    0.7602    0.8044     21274
weighted avg     0.8967    0.8992    0.8940     21274

F1-macro tok:  0.8043751218727193
F1-micro tok:  0.8991726990692864
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 1.000000
train_cost_sum: 310517.1331176758
train_cost_avg: 36.34329741545831
train_count_sent: 8544.0
train_total_correct_sent: 5784.0
train_accuracy_sent: 0.6769662921348315
train_count_tok: 163566.0
train_total_correct_tok: 146611.0
train_accuracy_tok: 0.8963415379724392
train_label=O_precision_sent: 0.49404761904761907
train_label=O_recall_sent: 0.05110837438423645
train_label=O_f-score_sent: 0.09263392857142858
train_label=N_precision_sent: 0.6463905325443787
train_label=N_recall_sent: 0.8250755287009064
train_label=N_f-score_sent: 0.7248838752488388
train_label=P_precision_sent: 0.7154902433148639
train_label=P_recall_sent: 0.8227146814404432
train_label=P_f-score_sent: 0.7653652879783533
train_precision_macro_sent: 0.6186427983022872
train_recall_macro_sent: 0.5662995281751954
train_f-score_macro_sent: 0.527627697266207
train_precision_micro_sent: 0.6769662921348315
train_recall_micro_sent: 0.6769662921348315
train_f-score_micro_sent: 0.6769662921348315
train_label=O_precision_tok: 0.9069552821128452
train_label=O_recall_tok: 0.9721103042292938
train_label=O_f-score_tok: 0.9384031953172609
train_label=N_precision_tok: 0.7989572287027218
train_label=N_recall_tok: 0.636600478805802
train_label=N_f-score_tok: 0.708597852496277
train_label=P_precision_tok: 0.8798629414865577
train_label=P_recall_tok: 0.6671863133069513
train_label=P_f-score_tok: 0.7589060404210335
train_precision_macro_tok: 0.8619251507673749
train_recall_macro_tok: 0.7586323654473489
train_f-score_macro_tok: 0.8019690294115239
train_precision_micro_tok: 0.8963415379724392
train_recall_micro_tok: 0.8963415379724392
train_f-score_micro_tok: 0.8963415379724393
train_time: 196.92822432518005
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4940    0.0511    0.0926      1624
           N     0.6464    0.8251    0.7249      3310
           P     0.7155    0.8227    0.7654      3610

   micro avg     0.6770    0.6770    0.6770      8544
   macro avg     0.6186    0.5663    0.5276      8544
weighted avg     0.6466    0.6770    0.6218      8544

F1-macro sent:  0.527627697266207
F1-micro sent:  0.6769662921348315
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9070    0.9721    0.9384    124347
           N     0.7990    0.6366    0.7086     14202
           P     0.8799    0.6672    0.7589     25017

   micro avg     0.8963    0.8963    0.8963    163566
   macro avg     0.8619    0.7586    0.8020    163566
weighted avg     0.8934    0.8963    0.8910    163566

F1-macro tok:  0.8019690294115239
F1-micro tok:  0.8963415379724393
**************************************************
dev_cost_sum: 42419.51641845703
dev_cost_avg: 38.528171133930094
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19131.0
dev_accuracy_tok: 0.8992667105386857
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.6298157453936348
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7336585365853658
dev_label=P_precision_sent: 0.7
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7415254237288137
dev_precision_macro_sent: 0.7766052484645449
dev_recall_macro_sent: 0.5614200700312605
dev_f-score_macro_sent: 0.5031729080875591
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9041642897889333
dev_label=O_recall_tok: 0.9780931811169392
dev_label=O_f-score_tok: 0.9396768934341189
dev_label=N_precision_tok: 0.8186528497409327
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6895261845386534
dev_label=P_precision_tok: 0.9089009611366485
dev_label=P_recall_tok: 0.677148194271482
dev_label=P_f-score_tok: 0.776092774308653
dev_precision_macro_tok: 0.8772393668888382
dev_recall_macro_tok: 0.7502752170339791
dev_f-score_macro_tok: 0.8017652840938084
dev_precision_micro_tok: 0.8992667105386857
dev_recall_micro_tok: 0.8992667105386857
dev_f-score_micro_tok: 0.8992667105386858
dev_time: 11.411981105804443
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.6298    0.8785    0.7337       428
           P     0.7000    0.7883    0.7415       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.7766    0.5614    0.5032      1101
weighted avg     0.7351    0.6630    0.5914      1101

F1-macro sent:  0.5031729080875591
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9781    0.9397     16205
           N     0.8187    0.5956    0.6895      1857
           P     0.9089    0.6771    0.7761      3212

   micro avg     0.8993    0.8993    0.8993     21274
   macro avg     0.8772    0.7503    0.8018     21274
weighted avg     0.8974    0.8993    0.8931     21274

F1-macro tok:  0.8017652840938084
F1-micro tok:  0.8992667105386858
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 1.000000
train_cost_sum: 308687.5090942383
train_cost_avg: 36.12915602694736
train_count_sent: 8544.0
train_total_correct_sent: 5773.0
train_accuracy_sent: 0.6756788389513109
train_count_tok: 163566.0
train_total_correct_tok: 146846.0
train_accuracy_tok: 0.8977782668769794
train_label=O_precision_sent: 0.4375
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.09251101321585903
train_label=N_precision_sent: 0.6570871894788115
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.7276159654800431
train_label=P_precision_sent: 0.704427696655676
train_label=P_recall_sent: 0.8285318559556787
train_label=P_f-score_sent: 0.7614562118126273
train_precision_macro_sent: 0.5996716287114958
train_recall_macro_sent: 0.5651205780226607
train_f-score_macro_sent: 0.5271943968361765
train_precision_micro_sent: 0.6756788389513109
train_recall_micro_sent: 0.6756788389513109
train_f-score_micro_sent: 0.6756788389513109
train_label=O_precision_tok: 0.9088665874245822
train_label=O_recall_tok: 0.971571489460944
train_label=O_f-score_tok: 0.9391735627135377
train_label=N_precision_tok: 0.7997563310416848
train_label=N_recall_tok: 0.6470919588790311
train_label=N_f-score_tok: 0.7153699451212391
train_label=P_precision_tok: 0.879628179017181
train_label=P_recall_tok: 0.6733021545349163
train_label=P_f-score_tok: 0.7627586831499343
train_precision_macro_tok: 0.8627503658278161
train_recall_macro_tok: 0.7639885342916305
train_f-score_macro_tok: 0.8057673969949036
train_precision_micro_tok: 0.8977782668769794
train_recall_micro_tok: 0.8977782668769794
train_f-score_micro_tok: 0.8977782668769794
train_time: 195.97439074516296
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4375    0.0517    0.0925      1624
           N     0.6571    0.8151    0.7276      3310
           P     0.7044    0.8285    0.7615      3610

   micro avg     0.6757    0.6757    0.6757      8544
   macro avg     0.5997    0.5651    0.5272      8544
weighted avg     0.6354    0.6757    0.6212      8544

F1-macro sent:  0.5271943968361765
F1-micro sent:  0.6756788389513109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9089    0.9716    0.9392    124347
           N     0.7998    0.6471    0.7154     14202
           P     0.8796    0.6733    0.7628     25017

   micro avg     0.8978    0.8978    0.8978    163566
   macro avg     0.8628    0.7640    0.8058    163566
weighted avg     0.8949    0.8978    0.8928    163566

F1-macro tok:  0.8057673969949036
F1-micro tok:  0.8977782668769794
**************************************************
dev_cost_sum: 42341.54577636719
dev_cost_avg: 38.45735311205012
dev_count_sent: 1101.0
dev_total_correct_sent: 753.0
dev_accuracy_sent: 0.6839237057220708
dev_count_tok: 21274.0
dev_total_correct_tok: 19113.0
dev_accuracy_tok: 0.8984206073140923
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1556420233463035
dev_label=N_precision_sent: 0.6806083650190115
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7505241090146751
dev_label=P_precision_sent: 0.6855575868372943
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.756811301715439
dev_precision_macro_sent: 0.6934838887140066
dev_recall_macro_sent: 0.5894598124223068
dev_f-score_macro_sent: 0.5543258113588059
dev_precision_micro_sent: 0.6839237057220708
dev_recall_micro_sent: 0.6839237057220708
dev_f-score_micro_sent: 0.6839237057220708
dev_label=O_precision_tok: 0.9034942712192897
dev_label=O_recall_tok: 0.9780931811169392
dev_label=O_f-score_tok: 0.9393149223657699
dev_label=N_precision_tok: 0.8295543393275997
dev_label=N_recall_tok: 0.5713516424340334
dev_label=N_f-score_tok: 0.676658163265306
dev_label=P_precision_tok: 0.898042414355628
dev_label=P_recall_tok: 0.6855541718555417
dev_label=P_f-score_tok: 0.7775423728813559
dev_precision_macro_tok: 0.8770303416341725
dev_recall_macro_tok: 0.7449996651355048
dev_f-score_macro_tok: 0.7978384861708107
dev_precision_micro_tok: 0.8984206073140923
dev_recall_micro_tok: 0.8984206073140923
dev_f-score_micro_tok: 0.8984206073140923
dev_time: 11.157238006591797
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0873    0.1556       229
           N     0.6806    0.8364    0.7505       428
           P     0.6856    0.8446    0.7568       444

   micro avg     0.6839    0.6839    0.6839      1101
   macro avg     0.6935    0.5895    0.5543      1101
weighted avg     0.6896    0.6839    0.6293      1101

F1-macro sent:  0.5543258113588059
F1-micro sent:  0.6839237057220708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9035    0.9781    0.9393     16205
           N     0.8296    0.5714    0.6767      1857
           P     0.8980    0.6856    0.7775      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8770    0.7450    0.7978     21274
weighted avg     0.8962    0.8984    0.8920     21274

F1-macro tok:  0.7978384861708107
F1-micro tok:  0.8984206073140923
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 1.000000
train_cost_sum: 306886.2262573242
train_cost_avg: 35.918331724874086
train_count_sent: 8544.0
train_total_correct_sent: 5804.0
train_accuracy_sent: 0.6793071161048689
train_count_tok: 163566.0
train_total_correct_tok: 147287.0
train_accuracy_tok: 0.9004744262254992
train_label=O_precision_sent: 0.41729323308270677
train_label=O_recall_sent: 0.06834975369458128
train_label=O_f-score_sent: 0.11746031746031746
train_label=N_precision_sent: 0.6524230126521843
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.7288971862915056
train_label=P_precision_sent: 0.7238933724627048
train_label=P_recall_sent: 0.8199445983379502
train_label=P_f-score_sent: 0.7689310300038967
train_precision_macro_sent: 0.5978698727325319
train_recall_macro_sent: 0.5713247034468961
train_f-score_macro_sent: 0.5384295112519065
train_precision_micro_sent: 0.6793071161048689
train_recall_micro_sent: 0.6793071161048689
train_f-score_micro_sent: 0.6793071161048689
train_label=O_precision_tok: 0.911381813521887
train_label=O_recall_tok: 0.9723033125045236
train_label=O_f-score_tok: 0.9408574118892167
train_label=N_precision_tok: 0.8057547740430312
train_label=N_recall_tok: 0.6565976623010844
train_label=N_f-score_tok: 0.7235693501454898
train_label=P_precision_tok: 0.8823316437364229
train_label=P_recall_tok: 0.681896310508854
train_label=P_f-score_tok: 0.7692723952109312
train_precision_macro_tok: 0.8664894104337804
train_recall_macro_tok: 0.7702657617714873
train_f-score_macro_tok: 0.8112330524152126
train_precision_micro_tok: 0.9004744262254992
train_recall_micro_tok: 0.9004744262254992
train_f-score_micro_tok: 0.9004744262254992
train_time: 197.6941680908203
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4173    0.0683    0.1175      1624
           N     0.6524    0.8257    0.7289      3310
           P     0.7239    0.8199    0.7689      3610

   micro avg     0.6793    0.6793    0.6793      8544
   macro avg     0.5979    0.5713    0.5384      8544
weighted avg     0.6379    0.6793    0.6296      8544

F1-macro sent:  0.5384295112519065
F1-micro sent:  0.6793071161048689
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9723    0.9409    124347
           N     0.8058    0.6566    0.7236     14202
           P     0.8823    0.6819    0.7693     25017

   micro avg     0.9005    0.9005    0.9005    163566
   macro avg     0.8665    0.7703    0.8112    163566
weighted avg     0.8978    0.9005    0.8957    163566

F1-macro tok:  0.8112330524152126
F1-micro tok:  0.9004744262254992
**************************************************
dev_cost_sum: 42355.863525390625
dev_cost_avg: 38.47035742542291
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19106.0
dev_accuracy_tok: 0.8980915671711949
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.708803611738149
dev_label=N_recall_sent: 0.7336448598130841
dev_label=N_f-score_sent: 0.7210103329506315
dev_label=P_precision_sent: 0.6209553158705701
dev_label=P_recall_sent: 0.9076576576576577
dev_label=P_f-score_sent: 0.737419945105215
dev_precision_macro_sent: 0.7025122351288323
dev_recall_macro_sent: 0.5572900676867538
dev_f-score_macro_sent: 0.5057512691558704
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9064867967853042
dev_label=O_recall_tok: 0.9744523295279235
dev_label=O_f-score_tok: 0.9392416356877323
dev_label=N_precision_tok: 0.7883161512027491
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6926328502415459
dev_label=P_precision_tok: 0.9037098791162984
dev_label=P_recall_tok: 0.6749688667496887
dev_label=P_f-score_tok: 0.772767777579754
dev_precision_macro_tok: 0.8661709423681172
dev_recall_macro_tok: 0.7556946978078488
dev_f-score_macro_tok: 0.8015474211696775
dev_precision_micro_tok: 0.8980915671711949
dev_recall_micro_tok: 0.8980915671711949
dev_f-score_micro_tok: 0.8980915671711949
dev_time: 11.225681781768799
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.7088    0.7336    0.7210       428
           P     0.6210    0.9077    0.7374       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7025    0.5573    0.5058      1101
weighted avg     0.6877    0.6576    0.5899      1101

F1-macro sent:  0.5057512691558704
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9745    0.9392     16205
           N     0.7883    0.6177    0.6926      1857
           P     0.9037    0.6750    0.7728      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8662    0.7557    0.8015     21274
weighted avg     0.8958    0.8981    0.8926     21274

F1-macro tok:  0.8015474211696775
F1-micro tok:  0.8980915671711949
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 1.000000
train_cost_sum: 305289.9772338867
train_cost_avg: 35.73150482606352
train_count_sent: 8544.0
train_total_correct_sent: 5810.0
train_accuracy_sent: 0.6800093632958801
train_count_tok: 163566.0
train_total_correct_tok: 147450.0
train_accuracy_tok: 0.9014709658486483
train_label=O_precision_sent: 0.42857142857142855
train_label=O_recall_sent: 0.0480295566502463
train_label=O_f-score_sent: 0.08637873754152824
train_label=N_precision_sent: 0.6505796072864916
train_label=N_recall_sent: 0.8308157099697885
train_label=N_f-score_sent: 0.7297333156428287
train_label=P_precision_sent: 0.7211608222490931
train_label=P_recall_sent: 0.8260387811634349
train_label=P_f-score_sent: 0.7700451904454486
train_precision_macro_sent: 0.6001039527023377
train_recall_macro_sent: 0.5682946825944899
train_f-score_macro_sent: 0.5287190812099353
train_precision_micro_sent: 0.6800093632958801
train_recall_micro_sent: 0.6800093632958801
train_f-score_micro_sent: 0.6800093632958801
train_label=O_precision_tok: 0.9129606963144294
train_label=O_recall_tok: 0.971748413713238
train_label=O_f-score_tok: 0.9414377037876751
train_label=N_precision_tok: 0.8045908353955116
train_label=N_recall_tok: 0.6639205745669624
train_label=N_f-score_tok: 0.7275182284634081
train_label=P_precision_tok: 0.8817011234802237
train_label=P_recall_tok: 0.6870128312747332
train_label=P_f-score_tok: 0.7722758930577398
train_precision_macro_tok: 0.8664175517300549
train_recall_macro_tok: 0.7742272731849779
train_f-score_macro_tok: 0.8137439417696077
train_precision_micro_tok: 0.9014709658486483
train_recall_micro_tok: 0.9014709658486483
train_f-score_micro_tok: 0.9014709658486483
train_time: 195.74618673324585
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0480    0.0864      1624
           N     0.6506    0.8308    0.7297      3310
           P     0.7212    0.8260    0.7700      3610

   micro avg     0.6800    0.6800    0.6800      8544
   macro avg     0.6001    0.5683    0.5287      8544
weighted avg     0.6382    0.6800    0.6245      8544

F1-macro sent:  0.5287190812099353
F1-micro sent:  0.6800093632958801
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9130    0.9717    0.9414    124347
           N     0.8046    0.6639    0.7275     14202
           P     0.8817    0.6870    0.7723     25017

   micro avg     0.9015    0.9015    0.9015    163566
   macro avg     0.8664    0.7742    0.8137    163566
weighted avg     0.8988    0.9015    0.8970    163566

F1-macro tok:  0.8137439417696077
F1-micro tok:  0.9014709658486483
**************************************************
dev_cost_sum: 42133.80310058594
dev_cost_avg: 38.26866766629059
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19165.0
dev_accuracy_tok: 0.9008649055184732
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6177924217462932
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7246376811594203
dev_label=P_precision_sent: 0.7051546391752578
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.736275565123789
dev_precision_macro_sent: 0.7002416128997763
dev_recall_macro_sent: 0.5590020600529518
dev_f-score_macro_sent: 0.506578925231658
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9136908223799
dev_label=O_recall_tok: 0.9694538722616476
dev_label=O_f-score_tok: 0.9407467289439803
dev_label=N_precision_tok: 0.7733674775928298
dev_label=N_recall_tok: 0.650511577813678
dev_label=N_f-score_tok: 0.7066393682363264
dev_label=P_precision_tok: 0.892374900714853
dev_label=P_recall_tok: 0.6995641344956414
dev_label=P_f-score_tok: 0.7842931937172775
dev_precision_macro_tok: 0.859811066895861
dev_recall_macro_tok: 0.7731765281903223
dev_f-score_macro_tok: 0.810559763632528
dev_precision_micro_tok: 0.9008649055184732
dev_recall_micro_tok: 0.9008649055184732
dev_f-score_micro_tok: 0.9008649055184732
dev_time: 11.302393436431885
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6178    0.8762    0.7246       428
           P     0.7052    0.7703    0.7363       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7002    0.5590    0.5066      1101
weighted avg     0.6863    0.6576    0.5908      1101

F1-macro sent:  0.506578925231658
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9137    0.9695    0.9407     16205
           N     0.7734    0.6505    0.7066      1857
           P     0.8924    0.6996    0.7843      3212

   micro avg     0.9009    0.9009    0.9009     21274
   macro avg     0.8598    0.7732    0.8106     21274
weighted avg     0.8982    0.9009    0.8967     21274

F1-macro tok:  0.810559763632528
F1-micro tok:  0.9008649055184732
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 1.000000
train_cost_sum: 304051.2849121094
train_cost_avg: 35.58652679214763
train_count_sent: 8544.0
train_total_correct_sent: 5833.0
train_accuracy_sent: 0.6827013108614233
train_count_tok: 163566.0
train_total_correct_tok: 147593.0
train_accuracy_tok: 0.9023452306714109
train_label=O_precision_sent: 0.4820717131474104
train_label=O_recall_sent: 0.07450738916256158
train_label=O_f-score_sent: 0.12906666666666666
train_label=N_precision_sent: 0.655484177968118
train_label=N_recall_sent: 0.8323262839879154
train_label=N_f-score_sent: 0.7333954478903233
train_label=P_precision_sent: 0.7229828850855746
train_label=P_recall_sent: 0.8191135734072023
train_label=P_f-score_sent: 0.7680519480519481
train_precision_macro_sent: 0.6201795920670343
train_recall_macro_sent: 0.5753157488525598
train_f-score_macro_sent: 0.5435046875363126
train_precision_micro_sent: 0.6827013108614233
train_recall_micro_sent: 0.6827013108614233
train_f-score_micro_sent: 0.6827013108614233
train_label=O_precision_tok: 0.9142078983204721
train_label=O_recall_tok: 0.9717966657820454
train_label=O_f-score_tok: 0.9421230513747092
train_label=N_precision_tok: 0.8050617910953106
train_label=N_recall_tok: 0.6696944092381355
train_label=N_f-score_tok: 0.7311654366543666
train_label=P_precision_tok: 0.8809523809523809
train_label=P_recall_tok: 0.6892113362913219
train_label=P_f-score_tok: 0.773374599116374
train_precision_macro_tok: 0.8667406901227213
train_recall_macro_tok: 0.7769008037705009
train_f-score_macro_tok: 0.8155543623818166
train_precision_micro_tok: 0.9023452306714109
train_recall_micro_tok: 0.9023452306714109
train_f-score_micro_tok: 0.9023452306714109
train_time: 196.58573627471924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4821    0.0745    0.1291      1624
           N     0.6555    0.8323    0.7334      3310
           P     0.7230    0.8191    0.7681      3610

   micro avg     0.6827    0.6827    0.6827      8544
   macro avg     0.6202    0.5753    0.5435      8544
weighted avg     0.6510    0.6827    0.6332      8544

F1-macro sent:  0.5435046875363126
F1-micro sent:  0.6827013108614233
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9142    0.9718    0.9421    124347
           N     0.8051    0.6697    0.7312     14202
           P     0.8810    0.6892    0.7734     25017

   micro avg     0.9023    0.9023    0.9023    163566
   macro avg     0.8667    0.7769    0.8156    163566
weighted avg     0.8996    0.9023    0.8980    163566

F1-macro tok:  0.8155543623818166
F1-micro tok:  0.9023452306714109
**************************************************
dev_cost_sum: 42090.271484375
dev_cost_avg: 38.22912941360127
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19174.0
dev_accuracy_tok: 0.9012879571307699
dev_label=O_precision_sent: 0.5925925925925926
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.125
dev_label=N_precision_sent: 0.6862348178137652
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7353579175704988
dev_label=P_precision_sent: 0.6706896551724137
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.759765625
dev_precision_macro_sent: 0.6498390218595905
dev_recall_macro_sent: 0.5793503988418897
dev_f-score_macro_sent: 0.540041180856833
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9079634839524603
dev_label=O_recall_tok: 0.97587164455415
dev_label=O_f-score_tok: 0.9406935934804592
dev_label=N_precision_tok: 0.8109065155807366
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.7005200367084735
dev_label=P_precision_tok: 0.9059304703476483
dev_label=P_recall_tok: 0.6896014943960149
dev_label=P_f-score_tok: 0.7831005833480643
dev_precision_macro_tok: 0.8749334899602816
dev_recall_macro_tok: 0.7606863433908555
dev_f-score_macro_tok: 0.8081047378456656
dev_precision_micro_tok: 0.9012879571307699
dev_recall_micro_tok: 0.9012879571307699
dev_f-score_micro_tok: 0.9012879571307699
dev_time: 11.576499462127686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5926    0.0699    0.1250       229
           N     0.6862    0.7921    0.7354       428
           P     0.6707    0.8761    0.7598       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6498    0.5794    0.5400      1101
weighted avg     0.6605    0.6757    0.6183      1101

F1-macro sent:  0.540041180856833
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9759    0.9407     16205
           N     0.8109    0.6166    0.7005      1857
           P     0.9059    0.6896    0.7831      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8749    0.7607    0.8081     21274
weighted avg     0.8992    0.9013    0.8959     21274

F1-macro tok:  0.8081047378456656
F1-micro tok:  0.9012879571307699
**************************************************
Best epoch: 22
**************************************************

EPOCH: 26
Learning rate: 1.000000
train_cost_sum: 302403.6160888672
train_cost_avg: 35.393681658341194
train_count_sent: 8544.0
train_total_correct_sent: 5893.0
train_accuracy_sent: 0.6897237827715356
train_count_tok: 163566.0
train_total_correct_tok: 147928.0
train_accuracy_tok: 0.904393333577883
train_label=O_precision_sent: 0.4666666666666667
train_label=O_recall_sent: 0.07327586206896551
train_label=O_f-score_sent: 0.12666311868014898
train_label=N_precision_sent: 0.65884561238855
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7416798732171157
train_label=P_precision_sent: 0.7365284330767321
train_label=P_recall_sent: 0.821606648199446
train_label=P_f-score_sent: 0.7767447950766009
train_precision_macro_sent: 0.6206802373773163
train_recall_macro_sent: 0.5810736262828239
train_f-score_macro_sent: 0.5483625956579552
train_precision_micro_sent: 0.6897237827715356
train_recall_micro_sent: 0.6897237827715356
train_f-score_micro_sent: 0.6897237827715356
train_label=O_precision_tok: 0.9158552018368785
train_label=O_recall_tok: 0.9719494639999356
train_label=O_f-score_tok: 0.9430689399555227
train_label=N_precision_tok: 0.8096526075564195
train_label=N_recall_tok: 0.6744824672581327
train_label=N_f-score_tok: 0.7359121115507241
train_label=P_precision_tok: 0.8845842605705038
train_label=P_recall_tok: 0.6991245952752129
train_label=P_f-score_tok: 0.7809953336756794
train_precision_macro_tok: 0.8700306899879339
train_recall_macro_tok: 0.7818521755110938
train_f-score_macro_tok: 0.8199921283939754
train_precision_micro_tok: 0.904393333577883
train_recall_micro_tok: 0.904393333577883
train_f-score_micro_tok: 0.904393333577883
train_time: 197.29364442825317
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0733    0.1267      1624
           N     0.6588    0.8483    0.7417      3310
           P     0.7365    0.8216    0.7767      3610

   micro avg     0.6897    0.6897    0.6897      8544
   macro avg     0.6207    0.5811    0.5484      8544
weighted avg     0.6551    0.6897    0.6396      8544

F1-macro sent:  0.5483625956579552
F1-micro sent:  0.6897237827715356
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9159    0.9719    0.9431    124347
           N     0.8097    0.6745    0.7359     14202
           P     0.8846    0.6991    0.7810     25017

   micro avg     0.9044    0.9044    0.9044    163566
   macro avg     0.8700    0.7819    0.8200    163566
weighted avg     0.9019    0.9044    0.9003    163566

F1-macro tok:  0.8199921283939754
F1-micro tok:  0.904393333577883
**************************************************
dev_cost_sum: 42041.494140625
dev_cost_avg: 38.18482664906903
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 19140.0
dev_accuracy_tok: 0.8996897621509824
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.5808823529411765
dev_label=N_recall_sent: 0.9228971962616822
dev_label=N_f-score_sent: 0.7129963898916968
dev_label=P_precision_sent: 0.7518072289156627
dev_label=P_recall_sent: 0.7027027027027027
dev_label=P_f-score_sent: 0.7264260768335273
dev_precision_macro_sent: 0.7220076383967241
dev_recall_macro_sent: 0.5491446533665854
dev_f-score_macro_sent: 0.4939918860715286
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.9115516142120211
dev_label=O_recall_tok: 0.9705029311940759
dev_label=O_f-score_tok: 0.9401040109988643
dev_label=N_precision_tok: 0.7822311289245157
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.6982707215265355
dev_label=P_precision_tok: 0.8882725832012678
dev_label=P_recall_tok: 0.6980074719800747
dev_label=P_f-score_tok: 0.7817294281729428
dev_precision_macro_tok: 0.8606851087792683
dev_recall_macro_tok: 0.766365790467492
dev_f-score_macro_tok: 0.8067013868994475
dev_precision_micro_tok: 0.8996897621509824
dev_recall_micro_tok: 0.8996897621509824
dev_f-score_micro_tok: 0.8996897621509824
dev_time: 11.460766315460205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.5809    0.9229    0.7130       428
           P     0.7518    0.7027    0.7264       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.7220    0.5491    0.4940      1101
weighted avg     0.7023    0.6467    0.5790      1101

F1-macro sent:  0.4939918860715286
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9116    0.9705    0.9401     16205
           N     0.7822    0.6306    0.6983      1857
           P     0.8883    0.6980    0.7817      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8607    0.7664    0.8067     21274
weighted avg     0.8967    0.8997    0.8951     21274

F1-macro tok:  0.8067013868994475
F1-micro tok:  0.8996897621509824
**************************************************
Best epoch: 22
**************************************************

EPOCH: 27
Learning rate: 0.900000
train_cost_sum: 300729.2902832031
train_cost_avg: 35.19771655936366
train_count_sent: 8544.0
train_total_correct_sent: 5902.0
train_accuracy_sent: 0.6907771535580525
train_count_tok: 163566.0
train_total_correct_tok: 148340.0
train_accuracy_tok: 0.9069121944658425
train_label=O_precision_sent: 0.47161572052401746
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11656772800863466
train_label=N_precision_sent: 0.658502119642016
train_label=N_recall_sent: 0.8447129909365559
train_label=N_f-score_sent: 0.7400741132874536
train_label=P_precision_sent: 0.7367903661833374
train_label=P_recall_sent: 0.8304709141274238
train_label=P_f-score_sent: 0.7808308373486131
train_precision_macro_sent: 0.6223027354497903
train_recall_macro_sent: 0.5805621227060557
train_f-score_macro_sent: 0.5458242262149006
train_precision_micro_sent: 0.6907771535580525
train_recall_micro_sent: 0.6907771535580525
train_f-score_micro_sent: 0.6907771535580525
train_label=O_precision_tok: 0.918702832518867
train_label=O_recall_tok: 0.9721344302636975
train_label=O_f-score_tok: 0.9446636918484249
train_label=N_precision_tok: 0.8178771885733433
train_label=N_recall_tok: 0.6874383889593015
train_label=N_f-score_tok: 0.7470063889207699
train_label=P_precision_tok: 0.8825436408977556
train_label=P_recall_tok: 0.7073190230643163
train_label=P_f-score_tok: 0.7852752568398164
train_precision_macro_tok: 0.873041220663322
train_recall_macro_tok: 0.7889639474291051
train_f-score_macro_tok: 0.8256484458696703
train_precision_micro_tok: 0.9069121944658425
train_recall_micro_tok: 0.9069121944658425
train_f-score_micro_tok: 0.9069121944658425
train_time: 197.06621098518372
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4716    0.0665    0.1166      1624
           N     0.6585    0.8447    0.7401      3310
           P     0.7368    0.8305    0.7808      3610

   micro avg     0.6908    0.6908    0.6908      8544
   macro avg     0.6223    0.5806    0.5458      8544
weighted avg     0.6561    0.6908    0.6388      8544

F1-macro sent:  0.5458242262149006
F1-micro sent:  0.6907771535580525
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9187    0.9721    0.9447    124347
           N     0.8179    0.6874    0.7470     14202
           P     0.8825    0.7073    0.7853     25017

   micro avg     0.9069    0.9069    0.9069    163566
   macro avg     0.8730    0.7890    0.8256    163566
weighted avg     0.9044    0.9069    0.9031    163566

F1-macro tok:  0.8256484458696703
F1-micro tok:  0.9069121944658425
**************************************************
dev_cost_sum: 42006.895751953125
dev_cost_avg: 38.15340213619721
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11244979919678715
dev_label=N_precision_sent: 0.6451048951048951
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.738
dev_label=P_precision_sent: 0.7033398821218074
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7513116474291711
dev_precision_macro_sent: 0.6828149257422341
dev_recall_macro_sent: 0.576530403398542
dev_f-score_macro_sent: 0.5339204822086527
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9083395511679964
dev_label=O_recall_tok: 0.9766121567417464
dev_label=O_f-score_tok: 0.9412394433210419
dev_label=N_precision_tok: 0.7828114590273151
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.6998213222156044
dev_label=P_precision_tok: 0.9276595744680851
dev_label=P_recall_tok: 0.6787048567870486
dev_label=P_f-score_tok: 0.7838906868033082
dev_precision_macro_tok: 0.8729368615544656
dev_recall_macro_tok: 0.7626859978680618
dev_f-score_macro_tok: 0.808317150779985
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 11.606898069381714
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0611    0.1124       229
           N     0.6451    0.8621    0.7380       428
           P     0.7033    0.8063    0.7513       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6828    0.5765    0.5339      1101
weighted avg     0.6800    0.6730    0.6133      1101

F1-macro sent:  0.5339204822086527
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9766    0.9412     16205
           N     0.7828    0.6327    0.6998      1857
           P     0.9277    0.6787    0.7839      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8729    0.7627    0.8083     21274
weighted avg     0.9003    0.9016    0.8964     21274

F1-macro tok:  0.808317150779985
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 22
**************************************************

EPOCH: 28
Learning rate: 0.810000
train_cost_sum: 298819.9039916992
train_cost_avg: 34.974239699403
train_count_sent: 8544.0
train_total_correct_sent: 5895.0
train_accuracy_sent: 0.6899578651685393
train_count_tok: 163566.0
train_total_correct_tok: 148641.0
train_accuracy_tok: 0.9087524302116576
train_label=O_precision_sent: 0.5224719101123596
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.10321864594894561
train_label=N_precision_sent: 0.6553896406906207
train_label=N_recall_sent: 0.8486404833836858
train_label=N_f-score_sent: 0.7395997893628226
train_label=P_precision_sent: 0.733578431372549
train_label=P_recall_sent: 0.8290858725761773
train_label=P_f-score_sent: 0.7784135240572171
train_precision_macro_sent: 0.6371466607251763
train_recall_macro_sent: 0.5783307886040266
train_f-score_macro_sent: 0.5404106531229951
train_precision_micro_sent: 0.6899578651685393
train_recall_micro_sent: 0.6899578651685393
train_f-score_micro_sent: 0.6899578651685393
train_label=O_precision_tok: 0.920559146661794
train_label=O_recall_tok: 0.972351564573331
train_label=O_f-score_tok: 0.945746802768978
train_label=N_precision_tok: 0.8166416291103321
train_label=N_recall_tok: 0.6889874665540064
train_label=N_f-score_tok: 0.7474029941949282
train_label=P_precision_tok: 0.886665678573193
train_label=P_recall_tok: 0.7173921733221409
train_label=P_f-score_tok: 0.7930973529541737
train_precision_macro_tok: 0.8746221514484397
train_recall_macro_tok: 0.7929104014831595
train_f-score_macro_tok: 0.8287490499726933
train_precision_micro_tok: 0.9087524302116576
train_recall_micro_tok: 0.9087524302116576
train_f-score_micro_tok: 0.9087524302116576
train_time: 196.52430510520935
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5225    0.0573    0.1032      1624
           N     0.6554    0.8486    0.7396      3310
           P     0.7336    0.8291    0.7784      3610

   micro avg     0.6900    0.6900    0.6900      8544
   macro avg     0.6371    0.5783    0.5404      8544
weighted avg     0.6632    0.6900    0.6350      8544

F1-macro sent:  0.5404106531229951
F1-micro sent:  0.6899578651685393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9206    0.9724    0.9457    124347
           N     0.8166    0.6890    0.7474     14202
           P     0.8867    0.7174    0.7931     25017

   micro avg     0.9088    0.9088    0.9088    163566
   macro avg     0.8746    0.7929    0.8287    163566
weighted avg     0.9064    0.9088    0.9052    163566

F1-macro tok:  0.8287490499726933
F1-micro tok:  0.9087524302116576
**************************************************
dev_cost_sum: 42023.47674560547
dev_cost_avg: 38.16846207593594
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19177.0
dev_accuracy_tok: 0.9014289743348689
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.14869888475836432
dev_label=N_precision_sent: 0.6612021857923497
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.743091095189355
dev_label=P_precision_sent: 0.701171875
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.7510460251046024
dev_precision_macro_sent: 0.62079135359745
dev_recall_macro_sent: 0.5813418814071795
dev_f-score_macro_sent: 0.5476120016841072
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9102231447846393
dev_label=O_recall_tok: 0.9741437827830917
dev_label=O_f-score_tok: 0.9410993203767735
dev_label=N_precision_tok: 0.7965986394557824
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.7039374812143072
dev_label=P_precision_tok: 0.9020723283218204
dev_label=P_recall_tok: 0.6911581569115816
dev_label=P_f-score_tok: 0.7826546800634584
dev_precision_macro_tok: 0.8696313708540807
dev_recall_macro_tok: 0.7652963026409996
dev_f-score_macro_tok: 0.8092304938848464
dev_precision_micro_tok: 0.9014289743348689
dev_recall_micro_tok: 0.9014289743348689
dev_f-score_micro_tok: 0.9014289743348689
dev_time: 11.825071096420288
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0873    0.1487       229
           N     0.6612    0.8481    0.7431       428
           P     0.7012    0.8086    0.7510       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6208    0.5813    0.5476      1101
weighted avg     0.6438    0.6739    0.6227      1101

F1-macro sent:  0.5476120016841072
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9741    0.9411     16205
           N     0.7966    0.6306    0.7039      1857
           P     0.9021    0.6912    0.7827      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8696    0.7653    0.8092     21274
weighted avg     0.8991    0.9014    0.8965     21274

F1-macro tok:  0.8092304938848464
F1-micro tok:  0.9014289743348689
**************************************************
Best epoch: 22
**************************************************

EPOCH: 29
Learning rate: 0.729000
train_cost_sum: 297233.9970703125
train_cost_avg: 34.78862325261148
train_count_sent: 8544.0
train_total_correct_sent: 5943.0
train_accuracy_sent: 0.6955758426966292
train_count_tok: 163566.0
train_total_correct_tok: 148911.0
train_accuracy_tok: 0.910403140016874
train_label=O_precision_sent: 0.45871559633027525
train_label=O_recall_sent: 0.09236453201970443
train_label=O_f-score_sent: 0.15376729882111737
train_label=N_precision_sent: 0.669713735867212
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.74568099638409
train_label=P_precision_sent: 0.7411330049261083
train_label=P_recall_sent: 0.8335180055401662
train_label=P_f-score_sent: 0.7846153846153846
train_precision_macro_sent: 0.6231874457078651
train_recall_macro_sent: 0.5889900502843073
train_f-score_macro_sent: 0.5613545599401973
train_precision_micro_sent: 0.6955758426966292
train_recall_micro_sent: 0.6955758426966292
train_f-score_micro_sent: 0.6955758426966292
train_label=O_precision_tok: 0.9224912650096886
train_label=O_recall_tok: 0.9724561107224139
train_label=O_f-score_tok: 0.9468149661941283
train_label=N_precision_tok: 0.8198034519778677
train_label=N_recall_tok: 0.6989860583016476
train_label=N_f-score_tok: 0.7545893352590171
train_label=P_precision_tok: 0.886478527607362
train_label=P_recall_tok: 0.7219890474477355
train_label=P_f-score_tok: 0.7958230525202679
train_precision_macro_tok: 0.8762577481983062
train_recall_macro_tok: 0.797810405490599
train_f-score_macro_tok: 0.8324091179911376
train_precision_micro_tok: 0.910403140016874
train_recall_micro_tok: 0.910403140016874
train_f-score_micro_tok: 0.9104031400168738
train_time: 248.98600316047668
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4587    0.0924    0.1538      1624
           N     0.6697    0.8411    0.7457      3310
           P     0.7411    0.8335    0.7846      3610

   micro avg     0.6956    0.6956    0.6956      8544
   macro avg     0.6232    0.5890    0.5614      8544
weighted avg     0.6598    0.6956    0.6496      8544

F1-macro sent:  0.5613545599401973
F1-micro sent:  0.6955758426966292
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9225    0.9725    0.9468    124347
           N     0.8198    0.6990    0.7546     14202
           P     0.8865    0.7220    0.7958     25017

   micro avg     0.9104    0.9104    0.9104    163566
   macro avg     0.8763    0.7978    0.8324    163566
weighted avg     0.9081    0.9104    0.9070    163566

F1-macro tok:  0.8324091179911376
F1-micro tok:  0.9104031400168738
**************************************************
dev_cost_sum: 41881.07775878906
dev_cost_avg: 38.039126029781166
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19162.0
dev_accuracy_tok: 0.9007238883143743
dev_label=O_precision_sent: 0.6153846153846154
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06611570247933884
dev_label=N_precision_sent: 0.6782945736434108
dev_label=N_recall_sent: 0.8177570093457944
dev_label=N_f-score_sent: 0.7415254237288135
dev_label=P_precision_sent: 0.6643356643356644
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7480314960629922
dev_precision_macro_sent: 0.6526716177878968
dev_recall_macro_sent: 0.569515787672748
dev_f-score_macro_sent: 0.5185575407570482
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9135515377012965
dev_label=O_recall_tok: 0.9697007096575131
dev_label=O_f-score_tok: 0.9407890798060229
dev_label=N_precision_tok: 0.7822368421052631
dev_label=N_recall_tok: 0.6402800215401184
dev_label=N_f-score_tok: 0.7041753035238377
dev_label=P_precision_tok: 0.8848413631022327
dev_label=P_recall_tok: 0.7033001245330013
dev_label=P_f-score_tok: 0.7836947094535993
dev_precision_macro_tok: 0.8602099143029308
dev_recall_macro_tok: 0.7710936185768776
dev_f-score_macro_tok: 0.8095530309278199
dev_precision_micro_tok: 0.9007238883143743
dev_recall_micro_tok: 0.9007238883143743
dev_f-score_micro_tok: 0.9007238883143743
dev_time: 14.305526971817017
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6154    0.0349    0.0661       229
           N     0.6783    0.8178    0.7415       428
           P     0.6643    0.8559    0.7480       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6527    0.5695    0.5186      1101
weighted avg     0.6596    0.6703    0.6037      1101

F1-macro sent:  0.5185575407570482
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9697    0.9408     16205
           N     0.7822    0.6403    0.7042      1857
           P     0.8848    0.7033    0.7837      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8602    0.7711    0.8096     21274
weighted avg     0.8978    0.9007    0.8964     21274

F1-macro tok:  0.8095530309278199
F1-micro tok:  0.9007238883143743
**************************************************
Best epoch: 22
**************************************************

test0_cost_sum: 42341.54577636719
test0_cost_avg: 38.45735311205012
test0_count_sent: 1101.0
test0_total_correct_sent: 753.0
test0_accuracy_sent: 0.6839237057220708
test0_count_tok: 21274.0
test0_total_correct_tok: 19113.0
test0_accuracy_tok: 0.8984206073140923
test0_label=O_precision_sent: 0.7142857142857143
test0_label=O_recall_sent: 0.08733624454148471
test0_label=O_f-score_sent: 0.1556420233463035
test0_label=N_precision_sent: 0.6806083650190115
test0_label=N_recall_sent: 0.8364485981308412
test0_label=N_f-score_sent: 0.7505241090146751
test0_label=P_precision_sent: 0.6855575868372943
test0_label=P_recall_sent: 0.8445945945945946
test0_label=P_f-score_sent: 0.756811301715439
test0_precision_macro_sent: 0.6934838887140066
test0_recall_macro_sent: 0.5894598124223068
test0_f-score_macro_sent: 0.5543258113588059
test0_precision_micro_sent: 0.6839237057220708
test0_recall_micro_sent: 0.6839237057220708
test0_f-score_micro_sent: 0.6839237057220708
test0_label=O_precision_tok: 0.9034942712192897
test0_label=O_recall_tok: 0.9780931811169392
test0_label=O_f-score_tok: 0.9393149223657699
test0_label=N_precision_tok: 0.8295543393275997
test0_label=N_recall_tok: 0.5713516424340334
test0_label=N_f-score_tok: 0.676658163265306
test0_label=P_precision_tok: 0.898042414355628
test0_label=P_recall_tok: 0.6855541718555417
test0_label=P_f-score_tok: 0.7775423728813559
test0_precision_macro_tok: 0.8770303416341725
test0_recall_macro_tok: 0.7449996651355048
test0_f-score_macro_tok: 0.7978384861708107
test0_precision_micro_tok: 0.8984206073140923
test0_recall_micro_tok: 0.8984206073140923
test0_f-score_micro_tok: 0.8984206073140923
test0_time: 13.252290725708008
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0873    0.1556       229
           N     0.6806    0.8364    0.7505       428
           P     0.6856    0.8446    0.7568       444

   micro avg     0.6839    0.6839    0.6839      1101
   macro avg     0.6935    0.5895    0.5543      1101
weighted avg     0.6896    0.6839    0.6293      1101

F1-macro sent:  0.5543258113588059
F1-micro sent:  0.6839237057220708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9035    0.9781    0.9393     16205
           N     0.8296    0.5714    0.6767      1857
           P     0.8980    0.6856    0.7775      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8770    0.7450    0.7978     21274
weighted avg     0.8962    0.8984    0.8920     21274

F1-macro tok:  0.7978384861708107
F1-micro tok:  0.8984206073140923
**************************************************
test1_cost_sum: 81987.92225646973
test1_cost_avg: 37.09860735586865
test1_count_sent: 2210.0
test1_total_correct_sent: 1549.0
test1_accuracy_sent: 0.7009049773755656
test1_count_tok: 42405.0
test1_total_correct_tok: 37887.0
test1_accuracy_tok: 0.8934559603820305
test1_label=O_precision_sent: 0.5303030303030303
test1_label=O_recall_sent: 0.08997429305912596
test1_label=O_f-score_sent: 0.15384615384615385
test1_label=N_precision_sent: 0.7002854424357755
test1_label=N_recall_sent: 0.8070175438596491
test1_label=N_f-score_sent: 0.7498726439123791
test1_label=P_precision_sent: 0.7118023787740164
test1_label=P_recall_sent: 0.8558855885588559
test1_label=P_f-score_sent: 0.7772227772227772
test1_precision_macro_sent: 0.6474636171709408
test1_recall_macro_sent: 0.5842924751592103
test1_f-score_macro_sent: 0.5603138583271033
test1_precision_micro_sent: 0.7009049773755656
test1_recall_micro_sent: 0.7009049773755656
test1_f-score_micro_sent: 0.7009049773755656
test1_label=O_precision_tok: 0.8957072725196941
test1_label=O_recall_tok: 0.9807487967998
test1_label=O_f-score_tok: 0.9363009815914312
test1_label=N_precision_tok: 0.8332695984703633
test1_label=N_recall_tok: 0.5795212765957447
test1_label=N_f-score_tok: 0.683607843137255
test1_label=P_precision_tok: 0.9099705511148507
test1_label=P_recall_tok: 0.6508199187603431
test1_label=P_f-score_tok: 0.7588807999298307
test1_precision_macro_tok: 0.8796491407016359
test1_recall_macro_tok: 0.737029997385296
test1_f-score_macro_tok: 0.7929298748861723
test1_precision_micro_tok: 0.8934559603820305
test1_recall_micro_tok: 0.8934559603820305
test1_f-score_micro_tok: 0.8934559603820305
test1_time: 28.311603784561157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5303    0.0900    0.1538       389
           N     0.7003    0.8070    0.7499       912
           P     0.7118    0.8559    0.7772       909

   micro avg     0.7009    0.7009    0.7009      2210
   macro avg     0.6475    0.5843    0.5603      2210
weighted avg     0.6751    0.7009    0.6562      2210

F1-macro sent:  0.5603138583271033
F1-micro sent:  0.7009049773755656
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8957    0.9807    0.9363     31998
           N     0.8333    0.5795    0.6836      3760
           P     0.9100    0.6508    0.7589      6647

   micro avg     0.8935    0.8935    0.8935     42405
   macro avg     0.8796    0.7370    0.7929     42405
weighted avg     0.8924    0.8935    0.8861     42405

F1-macro tok:  0.7929298748861723
F1-micro tok:  0.8934559603820305
**************************************************
