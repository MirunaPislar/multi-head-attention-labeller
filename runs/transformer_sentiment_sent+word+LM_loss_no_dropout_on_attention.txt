to_write_filename: runs/transformer_sentiment_sent+word+LM_loss_no_dropout_on_attention.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'N': 1, 'P': 2, 'O': 0}
{'N': 1, 'P': 2, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 427161.22900390625
train_cost_avg: 49.99546219615008
train_count_sent: 8544.0
train_total_correct_sent: 4253.0
train_accuracy_sent: 0.49777621722846443
train_count_tok: 163566.0
train_total_correct_tok: 126403.0
train_accuracy_tok: 0.7727950796620324
train_label=O_precision_sent: 0.2509090909090909
train_label=O_recall_sent: 0.042487684729064036
train_label=O_f-score_sent: 0.07266982622432859
train_label=N_precision_sent: 0.4862483311081442
train_label=N_recall_sent: 0.5501510574018127
train_label=N_f-score_sent: 0.5162296243798724
train_label=P_precision_sent: 0.5223253757736517
train_label=P_recall_sent: 0.6545706371191136
train_label=P_f-score_sent: 0.581017949348414
train_precision_macro_sent: 0.41982759926362895
train_recall_macro_sent: 0.4157364597499968
train_f-score_macro_sent: 0.38997246665087165
train_precision_micro_sent: 0.49777621722846443
train_recall_micro_sent: 0.49777621722846443
train_f-score_micro_sent: 0.49777621722846443
train_label=O_precision_tok: 0.7981264668591006
train_label=O_recall_tok: 0.9517157631466783
train_label=O_f-score_tok: 0.8681806010498013
train_label=N_precision_tok: 0.5120068610634648
train_label=N_recall_tok: 0.21018166455428813
train_label=N_f-score_tok: 0.29802316293929715
train_label=P_precision_tok: 0.5364693446088795
train_label=P_recall_tok: 0.20286205380341368
train_label=P_f-score_tok: 0.2943991646604983
train_precision_macro_tok: 0.6155342241771483
train_recall_macro_tok: 0.4549198271681267
train_f-score_macro_tok: 0.486867642883199
train_precision_micro_tok: 0.7727950796620324
train_recall_micro_tok: 0.7727950796620324
train_f-score_micro_tok: 0.7727950796620324
train_time: 143.31236577033997
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2509    0.0425    0.0727      1624
           N     0.4862    0.5502    0.5162      3310
           P     0.5223    0.6546    0.5810      3610

   micro avg     0.4978    0.4978    0.4978      8544
   macro avg     0.4198    0.4157    0.3900      8544
weighted avg     0.4568    0.4978    0.4593      8544

F1-macro sent:  0.38997246665087165
F1-micro sent:  0.49777621722846443
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7981    0.9517    0.8682    124347
           N     0.5120    0.2102    0.2980     14202
           P     0.5365    0.2029    0.2944     25017

   micro avg     0.7728    0.7728    0.7728    163566
   macro avg     0.6155    0.4549    0.4869    163566
weighted avg     0.7333    0.7728    0.7309    163566

F1-macro tok:  0.486867642883199
F1-micro tok:  0.7727950796620324
**************************************************
dev_cost_sum: 50512.95666503906
dev_cost_avg: 45.87916136697463
dev_count_sent: 1101.0
dev_total_correct_sent: 593.0
dev_accuracy_sent: 0.5386012715712988
dev_count_tok: 21274.0
dev_total_correct_tok: 17461.0
dev_accuracy_tok: 0.8207671335902981
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6498194945848376
dev_label=N_recall_sent: 0.4205607476635514
dev_label=N_f-score_sent: 0.5106382978723404
dev_label=P_precision_sent: 0.5012135922330098
dev_label=P_recall_sent: 0.9301801801801802
dev_label=P_f-score_sent: 0.6514195583596215
dev_precision_macro_sent: 0.3836776956059491
dev_recall_macro_sent: 0.4502469759479106
dev_f-score_macro_sent: 0.3873526187439873
dev_precision_micro_sent: 0.5386012715712988
dev_recall_micro_sent: 0.5386012715712988
dev_f-score_micro_sent: 0.5386012715712988
dev_label=O_precision_tok: 0.8319850984566258
dev_label=O_recall_tok: 0.9647022523912373
dev_label=O_f-score_tok: 0.8934419202743249
dev_label=N_precision_tok: 0.710691823899371
dev_label=N_recall_tok: 0.3651050080775444
dev_label=N_f-score_tok: 0.4823906083244398
dev_label=P_precision_tok: 0.7516339869281046
dev_label=P_recall_tok: 0.3580323785803238
dev_label=P_f-score_tok: 0.4850274145929988
dev_precision_macro_tok: 0.7647703030947005
dev_recall_macro_tok: 0.5626132130163685
dev_f-score_macro_tok: 0.6202866477305878
dev_precision_micro_tok: 0.8207671335902981
dev_recall_micro_tok: 0.8207671335902981
dev_f-score_micro_tok: 0.8207671335902981
dev_time: 8.76404857635498
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6498    0.4206    0.5106       428
           P     0.5012    0.9302    0.6514       444

   micro avg     0.5386    0.5386    0.5386      1101
   macro avg     0.3837    0.4502    0.3874      1101
weighted avg     0.4547    0.5386    0.4612      1101

F1-macro sent:  0.3873526187439873
F1-micro sent:  0.5386012715712988
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8320    0.9647    0.8934     16205
           N     0.7107    0.3651    0.4824      1857
           P     0.7516    0.3580    0.4850      3212

   micro avg     0.8208    0.8208    0.8208     21274
   macro avg     0.7648    0.5626    0.6203     21274
weighted avg     0.8093    0.8208    0.7959     21274

F1-macro tok:  0.6202866477305878
F1-micro tok:  0.8207671335902981
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378515.6701660156
train_cost_avg: 44.30192768796999
train_count_sent: 8544.0
train_total_correct_sent: 4850.0
train_accuracy_sent: 0.5676498127340824
train_count_tok: 163566.0
train_total_correct_tok: 132395.0
train_accuracy_tok: 0.8094286098577944
train_label=O_precision_sent: 0.08333333333333333
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012224938875305623
train_label=N_precision_sent: 0.5350011475786092
train_label=N_recall_sent: 0.7042296072507553
train_label=N_f-score_sent: 0.608060519107865
train_label=P_precision_sent: 0.6031137724550898
train_label=P_recall_sent: 0.6975069252077563
train_label=P_f-score_sent: 0.6468850353243416
train_precision_macro_sent: 0.40714941778901076
train_recall_macro_sent: 0.4674507653351032
train_f-score_macro_sent: 0.41872268277324576
train_precision_micro_sent: 0.5676498127340824
train_recall_micro_sent: 0.5676498127340824
train_f-score_micro_sent: 0.5676498127340824
train_label=O_precision_tok: 0.8329088741366782
train_label=O_recall_tok: 0.9494720419471319
train_label=O_f-score_tok: 0.8873789910408274
train_label=N_precision_tok: 0.6439210252857638
train_label=N_recall_tok: 0.39269117025771016
train_label=N_f-score_tok: 0.4878624852381577
train_label=P_precision_tok: 0.6653998175737306
train_label=P_recall_tok: 0.3499220530039573
train_label=P_f-score_tok: 0.4586487831713515
train_precision_macro_tok: 0.7140765723320576
train_recall_macro_tok: 0.5640284217362664
train_f-score_macro_tok: 0.6112967531501122
train_precision_micro_tok: 0.8094286098577944
train_recall_micro_tok: 0.8094286098577944
train_f-score_micro_tok: 0.8094286098577945
train_time: 141.9835650920868
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0833    0.0006    0.0012      1624
           N     0.5350    0.7042    0.6081      3310
           P     0.6031    0.6975    0.6469      3610

   micro avg     0.5676    0.5676    0.5676      8544
   macro avg     0.4071    0.4675    0.4187      8544
weighted avg     0.4779    0.5676    0.5091      8544

F1-macro sent:  0.41872268277324576
F1-micro sent:  0.5676498127340824
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8329    0.9495    0.8874    124347
           N     0.6439    0.3927    0.4879     14202
           P     0.6654    0.3499    0.4586     25017

   micro avg     0.8094    0.8094    0.8094    163566
   macro avg     0.7141    0.5640    0.6113    163566
weighted avg     0.7909    0.8094    0.7871    163566

F1-macro tok:  0.6112967531501122
F1-micro tok:  0.8094286098577945
**************************************************
dev_cost_sum: 48955.02722167969
dev_cost_avg: 44.46414824857374
dev_count_sent: 1101.0
dev_total_correct_sent: 644.0
dev_accuracy_sent: 0.5849227974568574
dev_count_tok: 21274.0
dev_total_correct_tok: 17853.0
dev_accuracy_tok: 0.8391933815925543
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5068664169787765
dev_label=N_recall_sent: 0.9485981308411215
dev_label=N_f-score_sent: 0.660699755899105
dev_label=P_precision_sent: 0.7933333333333333
dev_label=P_recall_sent: 0.536036036036036
dev_label=P_f-score_sent: 0.6397849462365591
dev_precision_macro_sent: 0.4333999167707033
dev_recall_macro_sent: 0.49487805562571924
dev_f-score_macro_sent: 0.43349490071188806
dev_precision_micro_sent: 0.5849227974568574
dev_recall_micro_sent: 0.5849227974568574
dev_f-score_micro_sent: 0.5849227974568574
dev_label=O_precision_tok: 0.8499538068583229
dev_label=O_recall_tok: 0.9651342178340019
dev_label=O_f-score_tok: 0.9038894989308212
dev_label=N_precision_tok: 0.7017268445839875
dev_label=N_recall_tok: 0.481421647819063
dev_label=N_f-score_tok: 0.5710635579687001
dev_label=P_precision_tok: 0.8248905565978737
dev_label=P_recall_tok: 0.4106475716064757
dev_label=P_f-score_tok: 0.5483267511951777
dev_precision_macro_tok: 0.7921904026800615
dev_recall_macro_tok: 0.6190678124198469
dev_f-score_macro_tok: 0.6744266026982331
dev_precision_micro_tok: 0.8391933815925543
dev_recall_micro_tok: 0.8391933815925543
dev_f-score_micro_tok: 0.8391933815925543
dev_time: 8.336956262588501
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5069    0.9486    0.6607       428
           P     0.7933    0.5360    0.6398       444

   micro avg     0.5849    0.5849    0.5849      1101
   macro avg     0.4334    0.4949    0.4335      1101
weighted avg     0.5170    0.5849    0.5148      1101

F1-macro sent:  0.43349490071188806
F1-micro sent:  0.5849227974568574
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8500    0.9651    0.9039     16205
           N     0.7017    0.4814    0.5711      1857
           P     0.8249    0.4106    0.5483      3212

   micro avg     0.8392    0.8392    0.8392     21274
   macro avg     0.7922    0.6191    0.6744     21274
weighted avg     0.8332    0.8392    0.8212     21274

F1-macro tok:  0.6744266026982331
F1-micro tok:  0.8391933815925543
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368400.96075439453
train_cost_avg: 43.11808997593569
train_count_sent: 8544.0
train_total_correct_sent: 4983.0
train_accuracy_sent: 0.5832162921348315
train_count_tok: 163566.0
train_total_correct_tok: 135564.0
train_accuracy_tok: 0.8288030519790176
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5534252981061492
train_label=N_recall_sent: 0.7151057401812689
train_label=N_f-score_sent: 0.6239620403321472
train_label=P_precision_sent: 0.6140845070422535
train_label=P_recall_sent: 0.7246537396121884
train_label=P_f-score_sent: 0.6648030495552731
train_precision_macro_sent: 0.3891699350494675
train_recall_macro_sent: 0.4799198265978191
train_f-score_macro_sent: 0.4295883632958068
train_precision_micro_sent: 0.5832162921348315
train_recall_micro_sent: 0.5832162921348315
train_f-score_micro_sent: 0.5832162921348315
train_label=O_precision_tok: 0.8487299986409448
train_label=O_recall_tok: 0.9542248707246657
train_label=O_f-score_tok: 0.8983910656823776
train_label=N_precision_tok: 0.6816820148674138
train_label=N_recall_tok: 0.43261512463033375
train_label=N_f-score_tok: 0.5293129442171011
train_label=P_precision_tok: 0.7298305084745763
train_label=P_recall_tok: 0.43030739097413756
train_label=P_f-score_tok: 0.5414036764151181
train_precision_macro_tok: 0.7534141739943117
train_recall_macro_tok: 0.6057157954430457
train_f-score_macro_tok: 0.6563692287715323
train_precision_micro_tok: 0.8288030519790176
train_recall_micro_tok: 0.8288030519790176
train_f-score_micro_tok: 0.8288030519790176
train_time: 141.09756541252136
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5534    0.7151    0.6240      3310
           P     0.6141    0.7247    0.6648      3610

   micro avg     0.5832    0.5832    0.5832      8544
   macro avg     0.3892    0.4799    0.4296      8544
weighted avg     0.4739    0.5832    0.5226      8544

F1-macro sent:  0.4295883632958068
F1-micro sent:  0.5832162921348315
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8487    0.9542    0.8984    124347
           N     0.6817    0.4326    0.5293     14202
           P     0.7298    0.4303    0.5414     25017

   micro avg     0.8288    0.8288    0.8288    163566
   macro avg     0.7534    0.6057    0.6564    163566
weighted avg     0.8160    0.8288    0.8117    163566

F1-macro tok:  0.6563692287715323
F1-micro tok:  0.8288030519790176
**************************************************
dev_cost_sum: 48217.506286621094
dev_cost_avg: 43.794283639074564
dev_count_sent: 1101.0
dev_total_correct_sent: 552.0
dev_accuracy_sent: 0.5013623978201635
dev_count_tok: 21274.0
dev_total_correct_tok: 18214.0
dev_accuracy_tok: 0.856162451819122
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7515527950310559
dev_label=N_recall_sent: 0.2827102803738318
dev_label=N_f-score_sent: 0.4108658743633277
dev_label=P_precision_sent: 0.45851063829787236
dev_label=P_recall_sent: 0.9707207207207207
dev_label=P_f-score_sent: 0.6228323699421966
dev_precision_macro_sent: 0.4033544777763094
dev_recall_macro_sent: 0.41781033369818416
dev_f-score_macro_sent: 0.34456608143517475
dev_precision_micro_sent: 0.5013623978201635
dev_recall_micro_sent: 0.5013623978201635
dev_f-score_micro_sent: 0.5013623978201635
dev_label=O_precision_tok: 0.8722543677321499
dev_label=O_recall_tok: 0.9581610614008023
dev_label=O_f-score_tok: 0.9131917896841735
dev_label=N_precision_tok: 0.7356223175965665
dev_label=N_recall_tok: 0.4614970382337103
dev_label=N_f-score_tok: 0.5671740569159497
dev_label=P_precision_tok: 0.792894280762565
dev_label=P_recall_tok: 0.5697384806973848
dev_label=P_f-score_tok: 0.6630434782608694
dev_precision_macro_tok: 0.8002569886970937
dev_recall_macro_tok: 0.6631321934439658
dev_f-score_macro_tok: 0.7144697749536641
dev_precision_micro_tok: 0.856162451819122
dev_recall_micro_tok: 0.856162451819122
dev_f-score_micro_tok: 0.856162451819122
dev_time: 8.136884927749634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7516    0.2827    0.4109       428
           P     0.4585    0.9707    0.6228       444

   micro avg     0.5014    0.5014    0.5014      1101
   macro avg     0.4034    0.4178    0.3446      1101
weighted avg     0.4771    0.5014    0.4109      1101

F1-macro sent:  0.34456608143517475
F1-micro sent:  0.5013623978201635
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8723    0.9582    0.9132     16205
           N     0.7356    0.4615    0.5672      1857
           P     0.7929    0.5697    0.6630      3212

   micro avg     0.8562    0.8562    0.8562     21274
   macro avg     0.8003    0.6631    0.7145     21274
weighted avg     0.8483    0.8562    0.8452     21274

F1-macro tok:  0.7144697749536641
F1-micro tok:  0.856162451819122
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361332.03857421875
train_cost_avg: 42.29073485185145
train_count_sent: 8544.0
train_total_correct_sent: 5105.0
train_accuracy_sent: 0.5974953183520599
train_count_tok: 163566.0
train_total_correct_tok: 137834.0
train_accuracy_tok: 0.8426812418228727
train_label=O_precision_sent: 1.0
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012307692307692308
train_label=N_precision_sent: 0.5639508420573509
train_label=N_recall_sent: 0.7486404833836858
train_label=N_f-score_sent: 0.6433021806853583
train_label=P_precision_sent: 0.6329235960472402
train_label=P_recall_sent: 0.7274238227146814
train_label=P_f-score_sent: 0.6768913519783477
train_precision_macro_sent: 0.732291479368197
train_recall_macro_sent: 0.49222668988172175
train_f-score_macro_sent: 0.4404747672981584
train_precision_micro_sent: 0.5974953183520599
train_recall_micro_sent: 0.5974953183520599
train_f-score_micro_sent: 0.5974953183520599
train_label=O_precision_tok: 0.8616272410268307
train_label=O_recall_tok: 0.9558091469838436
train_label=O_f-score_tok: 0.9062778798715906
train_label=N_precision_tok: 0.6940362087326943
train_label=N_recall_tok: 0.45887903112237716
train_label=N_f-score_tok: 0.5524754153950492
train_label=P_precision_tok: 0.7676910759376732
train_label=P_recall_tok: 0.4982611823959707
train_label=P_f-score_tok: 0.6043050370873128
train_precision_macro_tok: 0.7744515085657327
train_recall_macro_tok: 0.6376497868340638
train_f-score_macro_tok: 0.6876861107846509
train_precision_micro_tok: 0.8426812418228727
train_recall_micro_tok: 0.8426812418228727
train_f-score_micro_tok: 0.8426812418228727
train_time: 142.0473620891571
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0006    0.0012      1624
           N     0.5640    0.7486    0.6433      3310
           P     0.6329    0.7274    0.6769      3610

   micro avg     0.5975    0.5975    0.5975      8544
   macro avg     0.7323    0.4922    0.4405      8544
weighted avg     0.6760    0.5975    0.5355      8544

F1-macro sent:  0.4404747672981584
F1-micro sent:  0.5974953183520599
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8616    0.9558    0.9063    124347
           N     0.6940    0.4589    0.5525     14202
           P     0.7677    0.4983    0.6043     25017

   micro avg     0.8427    0.8427    0.8427    163566
   macro avg     0.7745    0.6376    0.6877    163566
weighted avg     0.8327    0.8427    0.8294    163566

F1-macro tok:  0.6876861107846509
F1-micro tok:  0.8426812418228727
**************************************************
dev_cost_sum: 47361.658630371094
dev_cost_avg: 43.01694698489654
dev_count_sent: 1101.0
dev_total_correct_sent: 678.0
dev_accuracy_sent: 0.6158038147138964
dev_count_tok: 21274.0
dev_total_correct_tok: 18418.0
dev_accuracy_tok: 0.8657516216978471
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6242544731610338
dev_label=N_recall_sent: 0.7336448598130841
dev_label=N_f-score_sent: 0.6745435016111708
dev_label=P_precision_sent: 0.6086956521739131
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.6986564299424184
dev_precision_macro_sent: 0.41098337511164895
dev_recall_macro_sent: 0.5178215598776347
dev_f-score_macro_sent: 0.4577333105178631
dev_precision_micro_sent: 0.6158038147138964
dev_recall_micro_sent: 0.6158038147138964
dev_f-score_micro_sent: 0.6158038147138964
dev_label=O_precision_tok: 0.8745126434220787
dev_label=O_recall_tok: 0.9688984881209504
dev_label=O_f-score_tok: 0.9192892063585001
dev_label=N_precision_tok: 0.7548936170212766
dev_label=N_recall_tok: 0.47765212708669896
dev_label=N_f-score_tok: 0.5850923482849605
dev_label=P_precision_tok: 0.8531468531468531
dev_label=P_recall_tok: 0.5697384806973848
dev_label=P_f-score_tok: 0.6832182191525107
dev_precision_macro_tok: 0.8275177045300696
dev_recall_macro_tok: 0.672096365301678
dev_f-score_macro_tok: 0.729199924598657
dev_precision_micro_tok: 0.8657516216978471
dev_recall_micro_tok: 0.8657516216978471
dev_f-score_micro_tok: 0.8657516216978471
dev_time: 8.04581332206726
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6243    0.7336    0.6745       428
           P     0.6087    0.8198    0.6987       444

   micro avg     0.6158    0.6158    0.6158      1101
   macro avg     0.4110    0.5178    0.4577      1101
weighted avg     0.4881    0.6158    0.5440      1101

F1-macro sent:  0.4577333105178631
F1-micro sent:  0.6158038147138964
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8745    0.9689    0.9193     16205
           N     0.7549    0.4777    0.5851      1857
           P     0.8531    0.5697    0.6832      3212

   micro avg     0.8658    0.8658    0.8658     21274
   macro avg     0.8275    0.6721    0.7292     21274
weighted avg     0.8608    0.8658    0.8545     21274

F1-macro tok:  0.729199924598657
F1-micro tok:  0.8657516216978471
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355476.25244140625
train_cost_avg: 41.60536662469642
train_count_sent: 8544.0
train_total_correct_sent: 5231.0
train_accuracy_sent: 0.6122425093632958
train_count_tok: 163566.0
train_total_correct_tok: 139213.0
train_accuracy_tok: 0.8511120893095142
train_label=O_precision_sent: 0.6666666666666666
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004907975460122699
train_label=N_precision_sent: 0.572470172337605
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.6613067891781521
train_label=P_precision_sent: 0.6570289132602194
train_label=P_recall_sent: 0.7301939058171745
train_label=P_f-score_sent: 0.6916819732353713
train_precision_macro_sent: 0.6320552507548304
train_recall_macro_sent: 0.5051454720659067
train_f-score_macro_sent: 0.452632245957882
train_precision_micro_sent: 0.6122425093632958
train_recall_micro_sent: 0.6122425093632958
train_f-score_micro_sent: 0.6122425093632958
train_label=O_precision_tok: 0.8673826790878835
train_label=O_recall_tok: 0.9599266568554127
train_label=O_f-score_tok: 0.9113112257168051
train_label=N_precision_tok: 0.711237254283612
train_label=N_recall_tok: 0.47641177298971976
train_label=N_f-score_tok: 0.5706093189964158
train_label=P_precision_tok: 0.7958513291562748
train_label=P_recall_tok: 0.5229643842187313
train_label=P_f-score_tok: 0.6311752219220379
train_precision_macro_tok: 0.79149042084259
train_recall_macro_tok: 0.6531009380212879
train_f-score_macro_tok: 0.7043652555450862
train_precision_micro_tok: 0.8511120893095142
train_recall_micro_tok: 0.8511120893095142
train_f-score_micro_tok: 0.8511120893095142
train_time: 141.30100798606873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0025    0.0049      1624
           N     0.5725    0.7828    0.6613      3310
           P     0.6570    0.7302    0.6917      3610

   micro avg     0.6122    0.6122    0.6122      8544
   macro avg     0.6321    0.5051    0.4526      8544
weighted avg     0.6261    0.6122    0.5494      8544

F1-macro sent:  0.452632245957882
F1-micro sent:  0.6122425093632958
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8674    0.9599    0.9113    124347
           N     0.7112    0.4764    0.5706     14202
           P     0.7959    0.5230    0.6312     25017

   micro avg     0.8511    0.8511    0.8511    163566
   macro avg     0.7915    0.6531    0.7044    163566
weighted avg     0.8429    0.8511    0.8389    163566

F1-macro tok:  0.7043652555450862
F1-micro tok:  0.8511120893095142
**************************************************
dev_cost_sum: 46692.04162597656
dev_cost_avg: 42.408757153475534
dev_count_sent: 1101.0
dev_total_correct_sent: 670.0
dev_accuracy_sent: 0.6085376930063578
dev_count_tok: 21274.0
dev_total_correct_tok: 18520.0
dev_accuracy_tok: 0.8705462066372097
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6566820276497696
dev_label=N_recall_sent: 0.6658878504672897
dev_label=N_f-score_sent: 0.6612529002320185
dev_label=P_precision_sent: 0.5772113943028486
dev_label=P_recall_sent: 0.8671171171171171
dev_label=P_f-score_sent: 0.6930693069306932
dev_precision_macro_sent: 0.41129780731753945
dev_recall_macro_sent: 0.511001655861469
dev_f-score_macro_sent: 0.4514407357209039
dev_precision_micro_sent: 0.6085376930063578
dev_recall_micro_sent: 0.6085376930063578
dev_f-score_micro_sent: 0.6085376930063578
dev_label=O_precision_tok: 0.880608749368226
dev_label=O_recall_tok: 0.9676643011416229
dev_label=O_f-score_tok: 0.9220863224744208
dev_label=N_precision_tok: 0.7469418960244648
dev_label=N_recall_tok: 0.526117393645665
dev_label=N_f-score_tok: 0.6173775671406002
dev_label=P_precision_tok: 0.8624363131079203
dev_label=P_recall_tok: 0.5797011207970112
dev_label=P_f-score_tok: 0.6933531930739155
dev_precision_macro_tok: 0.8299956528335369
dev_recall_macro_tok: 0.6911609385280997
dev_f-score_macro_tok: 0.7442723608963121
dev_precision_micro_tok: 0.8705462066372097
dev_recall_micro_tok: 0.8705462066372097
dev_f-score_micro_tok: 0.8705462066372097
dev_time: 8.138200283050537
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6567    0.6659    0.6613       428
           P     0.5772    0.8671    0.6931       444

   micro avg     0.6085    0.6085    0.6085      1101
   macro avg     0.4113    0.5110    0.4514      1101
weighted avg     0.4880    0.6085    0.5365      1101

F1-macro sent:  0.4514407357209039
F1-micro sent:  0.6085376930063578
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9677    0.9221     16205
           N     0.7469    0.5261    0.6174      1857
           P     0.8624    0.5797    0.6934      3212

   micro avg     0.8705    0.8705    0.8705     21274
   macro avg     0.8300    0.6912    0.7443     21274
weighted avg     0.8662    0.8705    0.8610     21274

F1-macro tok:  0.7442723608963121
F1-micro tok:  0.8705462066372097
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350839.7413330078
train_cost_avg: 41.06270380770223
train_count_sent: 8544.0
train_total_correct_sent: 5242.0
train_accuracy_sent: 0.6135299625468165
train_count_tok: 163566.0
train_total_correct_tok: 140325.0
train_accuracy_tok: 0.8579105682109974
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.01680672268907563
train_label=N_precision_sent: 0.5818224081822408
train_label=N_recall_sent: 0.7561933534743203
train_label=N_f-score_sent: 0.6576458223857068
train_label=P_precision_sent: 0.6488095238095238
train_label=P_recall_sent: 0.7548476454293629
train_label=P_f-score_sent: 0.6978233034571063
train_precision_macro_sent: 0.521321755108366
train_recall_macro_sent: 0.5065538961862851
train_f-score_macro_sent: 0.45742528284396294
train_precision_micro_sent: 0.6135299625468165
train_recall_micro_sent: 0.6135299625468165
train_f-score_micro_sent: 0.6135299625468165
train_label=O_precision_tok: 0.8729615550188613
train_label=O_recall_tok: 0.9621623360434912
train_label=O_f-score_tok: 0.9153940321346595
train_label=N_precision_tok: 0.7225066557444194
train_label=N_recall_tok: 0.4968314321926489
train_label=N_f-score_tok: 0.5887850467289719
train_label=P_precision_tok: 0.813697975756852
train_label=P_recall_tok: 0.5447095974737178
train_label=P_f-score_tok: 0.6525715927593142
train_precision_macro_tok: 0.8030553955067109
train_recall_macro_tok: 0.6679011219032859
train_f-score_macro_tok: 0.7189168905409818
train_precision_micro_tok: 0.8579105682109974
train_recall_micro_tok: 0.8579105682109974
train_f-score_micro_tok: 0.8579105682109973
train_time: 141.46000576019287
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0086    0.0168      1624
           N     0.5818    0.7562    0.6576      3310
           P     0.6488    0.7548    0.6978      3610

   micro avg     0.6135    0.6135    0.6135      8544
   macro avg     0.5213    0.5066    0.4574      8544
weighted avg     0.5629    0.6135    0.5528      8544

F1-macro sent:  0.45742528284396294
F1-micro sent:  0.6135299625468165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8730    0.9622    0.9154    124347
           N     0.7225    0.4968    0.5888     14202
           P     0.8137    0.5447    0.6526     25017

   micro avg     0.8579    0.8579    0.8579    163566
   macro avg     0.8031    0.6679    0.7189    163566
weighted avg     0.8508    0.8579    0.8468    163566

F1-macro tok:  0.7189168905409818
F1-micro tok:  0.8579105682109973
**************************************************
dev_cost_sum: 46235.676696777344
dev_cost_avg: 41.99425676364881
dev_count_sent: 1101.0
dev_total_correct_sent: 679.0
dev_accuracy_sent: 0.6167120799273388
dev_count_tok: 21274.0
dev_total_correct_tok: 18620.0
dev_accuracy_tok: 0.875246780107173
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.665903890160183
dev_label=N_recall_sent: 0.6799065420560748
dev_label=N_f-score_sent: 0.6728323699421965
dev_label=P_precision_sent: 0.5843373493975904
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.700361010830325
dev_precision_macro_sent: 0.4167470798525912
dev_recall_macro_sent: 0.5179268053099829
dev_f-score_macro_sent: 0.4577311269241739
dev_precision_micro_sent: 0.6167120799273388
dev_recall_micro_sent: 0.6167120799273388
dev_f-score_micro_sent: 0.6167120799273388
dev_label=O_precision_tok: 0.8816885658372938
dev_label=O_recall_tok: 0.9730947238506634
dev_label=O_f-score_tok: 0.925139337048988
dev_label=N_precision_tok: 0.7755905511811023
dev_label=N_recall_tok: 0.5304254173397954
dev_label=N_f-score_tok: 0.6299968020466902
dev_label=P_precision_tok: 0.8806040585181689
dev_label=P_recall_tok: 0.5809464508094645
dev_label=P_f-score_tok: 0.7000562746201464
dev_precision_macro_tok: 0.8459610585121884
dev_recall_macro_tok: 0.6948221973333077
dev_f-score_macro_tok: 0.7517308045719414
dev_precision_micro_tok: 0.875246780107173
dev_recall_micro_tok: 0.875246780107173
dev_f-score_micro_tok: 0.875246780107173
dev_time: 8.186671495437622
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6659    0.6799    0.6728       428
           P     0.5843    0.8739    0.7004       444

   micro avg     0.6167    0.6167    0.6167      1101
   macro avg     0.4167    0.5179    0.4577      1101
weighted avg     0.4945    0.6167    0.5440      1101

F1-macro sent:  0.4577311269241739
F1-micro sent:  0.6167120799273388
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8817    0.9731    0.9251     16205
           N     0.7756    0.5304    0.6300      1857
           P     0.8806    0.5809    0.7001      3212

   micro avg     0.8752    0.8752    0.8752     21274
   macro avg     0.8460    0.6948    0.7517     21274
weighted avg     0.8723    0.8752    0.8654     21274

F1-macro tok:  0.7517308045719414
F1-micro tok:  0.875246780107173
**************************************************
Best epoch: 3
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346590.3532104492
train_cost_avg: 40.565350328938344
train_count_sent: 8544.0
train_total_correct_sent: 5369.0
train_accuracy_sent: 0.6283941947565543
train_count_tok: 163566.0
train_total_correct_tok: 141151.0
train_accuracy_tok: 0.8629605174669552
train_label=O_precision_sent: 0.3939393939393939
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.015691007845503924
train_label=N_precision_sent: 0.59822263797942
train_label=N_recall_sent: 0.7728096676737161
train_label=N_f-score_sent: 0.674400210914843
train_label=P_precision_sent: 0.6606847697756789
train_label=P_recall_sent: 0.7750692520775623
train_label=P_f-score_sent: 0.7133205863607394
train_precision_macro_sent: 0.5509489338981642
train_recall_macro_sent: 0.5186279486198843
train_f-score_macro_sent: 0.46780393504036216
train_precision_micro_sent: 0.6283941947565543
train_recall_micro_sent: 0.6283941947565543
train_f-score_micro_sent: 0.6283941947565543
train_label=O_precision_tok: 0.876417382664095
train_label=O_recall_tok: 0.9646955696558823
train_label=O_f-score_tok: 0.918440082842366
train_label=N_precision_tok: 0.7346713497240341
train_label=N_recall_tok: 0.5154907759470497
train_label=N_f-score_tok: 0.6058675052757894
train_label=P_precision_tok: 0.8292784984159245
train_label=P_recall_tok: 0.554542910820642
train_label=P_f-score_tok: 0.6646385282422268
train_precision_macro_tok: 0.8134557436013511
train_recall_macro_tok: 0.6782430854745246
train_f-score_macro_tok: 0.7296487054534607
train_precision_micro_tok: 0.8629605174669552
train_recall_micro_tok: 0.8629605174669552
train_f-score_micro_tok: 0.8629605174669552
train_time: 141.66414618492126
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3939    0.0080    0.0157      1624
           N     0.5982    0.7728    0.6744      3310
           P     0.6607    0.7751    0.7133      3610

   micro avg     0.6284    0.6284    0.6284      8544
   macro avg     0.5509    0.5186    0.4678      8544
weighted avg     0.5858    0.6284    0.5656      8544

F1-macro sent:  0.46780393504036216
F1-micro sent:  0.6283941947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8764    0.9647    0.9184    124347
           N     0.7347    0.5155    0.6059     14202
           P     0.8293    0.5545    0.6646     25017

   micro avg     0.8630    0.8630    0.8630    163566
   macro avg     0.8135    0.6782    0.7296    163566
weighted avg     0.8569    0.8630    0.8525    163566

F1-macro tok:  0.7296487054534607
F1-micro tok:  0.8629605174669552
**************************************************
dev_cost_sum: 46068.680114746094
dev_cost_avg: 41.842579577426065
dev_count_sent: 1101.0
dev_total_correct_sent: 652.0
dev_accuracy_sent: 0.592188919164396
dev_count_tok: 21274.0
dev_total_correct_tok: 18678.0
dev_accuracy_tok: 0.8779731127197518
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.7371794871794872
dev_label=N_recall_sent: 0.5373831775700935
dev_label=N_f-score_sent: 0.6216216216216217
dev_label=P_precision_sent: 0.5357142857142857
dev_label=P_recall_sent: 0.9459459459459459
dev_label=P_f-score_sent: 0.6840390879478827
dev_precision_macro_sent: 0.5576312576312575
dev_recall_macro_sent: 0.49735424932339595
dev_f-score_macro_sent: 0.4409182422211739
dev_precision_micro_sent: 0.592188919164396
dev_recall_micro_sent: 0.592188919164396
dev_f-score_micro_sent: 0.592188919164396
dev_label=O_precision_tok: 0.8785181089300526
dev_label=O_recall_tok: 0.9804381363776612
dev_label=O_f-score_tok: 0.9266841644794401
dev_label=N_precision_tok: 0.843098311817279
dev_label=N_recall_tok: 0.45718901453957994
dev_label=N_f-score_tok: 0.592877094972067
dev_label=P_precision_tok: 0.8895508707607699
dev_label=P_recall_tok: 0.6042963885429639
dev_label=P_f-score_tok: 0.7196885428253615
dev_precision_macro_tok: 0.8703890971693672
dev_recall_macro_tok: 0.6806411798200683
dev_f-score_macro_tok: 0.7464166007589562
dev_precision_micro_tok: 0.8779731127197518
dev_recall_micro_tok: 0.8779731127197518
dev_f-score_micro_tok: 0.8779731127197518
dev_time: 8.063665390014648
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.7372    0.5374    0.6216       428
           P     0.5357    0.9459    0.6840       444

   micro avg     0.5922    0.5922    0.5922      1101
   macro avg     0.5576    0.4974    0.4409      1101
weighted avg     0.5858    0.5922    0.5211      1101

F1-macro sent:  0.4409182422211739
F1-micro sent:  0.592188919164396
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8785    0.9804    0.9267     16205
           N     0.8431    0.4572    0.5929      1857
           P     0.8896    0.6043    0.7197      3212

   micro avg     0.8780    0.8780    0.8780     21274
   macro avg     0.8704    0.6806    0.7464     21274
weighted avg     0.8771    0.8780    0.8663     21274

F1-macro tok:  0.7464166007589562
F1-micro tok:  0.8779731127197518
**************************************************
Best epoch: 3
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 342796.5869140625
train_cost_avg: 40.12132337477323
train_count_sent: 8544.0
train_total_correct_sent: 5382.0
train_accuracy_sent: 0.6299157303370787
train_count_tok: 163566.0
train_total_correct_tok: 141756.0
train_accuracy_tok: 0.8666593301786435
train_label=O_precision_sent: 0.3384615384615385
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026050917702782714
train_label=N_precision_sent: 0.5970840083314047
train_label=N_recall_sent: 0.7794561933534743
train_label=N_f-score_sent: 0.6761892281483423
train_label=P_precision_sent: 0.6685906685906686
train_label=P_recall_sent: 0.7700831024930748
train_label=P_f-score_sent: 0.7157569515962925
train_precision_macro_sent: 0.5347120717945373
train_recall_macro_sent: 0.5210286979587019
train_f-score_macro_sent: 0.47266569914913914
train_precision_micro_sent: 0.6299157303370787
train_recall_micro_sent: 0.6299157303370787
train_f-score_micro_sent: 0.6299157303370787
train_label=O_precision_tok: 0.8796064295866485
train_label=O_recall_tok: 0.9655319388485448
train_label=O_f-score_tok: 0.9205684689140127
train_label=N_precision_tok: 0.742442322991249
train_label=N_recall_tok: 0.5257006055485143
train_label=N_f-score_tok: 0.6155495094401846
train_label=P_precision_tok: 0.836212976022567
train_label=P_recall_tok: 0.5687732342007435
train_label=P_f-score_tok: 0.6770394689886519
train_precision_macro_tok: 0.8194205762001548
train_recall_macro_tok: 0.6866685928659342
train_f-score_macro_tok: 0.7377191491142829
train_precision_micro_tok: 0.8666593301786435
train_recall_micro_tok: 0.8666593301786435
train_f-score_micro_tok: 0.8666593301786436
train_time: 142.06135988235474
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3385    0.0135    0.0261      1624
           N     0.5971    0.7795    0.6762      3310
           P     0.6686    0.7701    0.7158      3610

   micro avg     0.6299    0.6299    0.6299      8544
   macro avg     0.5347    0.5210    0.4727      8544
weighted avg     0.5781    0.6299    0.5693      8544

F1-macro sent:  0.47266569914913914
F1-micro sent:  0.6299157303370787
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8796    0.9655    0.9206    124347
           N     0.7424    0.5257    0.6155     14202
           P     0.8362    0.5688    0.6770     25017

   micro avg     0.8667    0.8667    0.8667    163566
   macro avg     0.8194    0.6867    0.7377    163566
weighted avg     0.8611    0.8667    0.8568    163566

F1-macro tok:  0.7377191491142829
F1-micro tok:  0.8666593301786436
**************************************************
dev_cost_sum: 45384.37561035156
dev_cost_avg: 41.22104960068262
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 18777.0
dev_accuracy_tok: 0.8826266804550155
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6091549295774648
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.6947791164658635
dev_label=P_precision_sent: 0.6566604127579737
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7164790174002047
dev_precision_macro_sent: 0.4219384474451462
dev_recall_macro_sent: 0.5322331677471864
dev_f-score_macro_sent: 0.47041937795535604
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.8882706682403192
dev_label=O_recall_tok: 0.9753162604134527
dev_label=O_f-score_tok: 0.9297605741514207
dev_label=N_precision_tok: 0.7651006711409396
dev_label=N_recall_tok: 0.5525040387722132
dev_label=N_f-score_tok: 0.6416510318949342
dev_label=P_precision_tok: 0.9093457943925234
dev_label=P_recall_tok: 0.6058530510585305
dev_label=P_f-score_tok: 0.727204783258595
dev_precision_macro_tok: 0.8542390445912608
dev_recall_macro_tok: 0.7112244500813988
dev_f-score_macro_tok: 0.7662054631016498
dev_precision_micro_tok: 0.8826266804550155
dev_recall_micro_tok: 0.8826266804550155
dev_f-score_micro_tok: 0.8826266804550155
dev_time: 8.183857917785645
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6092    0.8084    0.6948       428
           P     0.6567    0.7883    0.7165       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.4219    0.5322    0.4704      1101
weighted avg     0.5016    0.6322    0.5590      1101

F1-macro sent:  0.47041937795535604
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8883    0.9753    0.9298     16205
           N     0.7651    0.5525    0.6417      1857
           P     0.9093    0.6059    0.7272      3212

   micro avg     0.8826    0.8826    0.8826     21274
   macro avg     0.8542    0.7112    0.7662     21274
weighted avg     0.8807    0.8826    0.8740     21274

F1-macro tok:  0.7662054631016498
F1-micro tok:  0.8826266804550155
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 339293.46270751953
train_cost_avg: 39.71131351913852
train_count_sent: 8544.0
train_total_correct_sent: 5416.0
train_accuracy_sent: 0.6338951310861424
train_count_tok: 163566.0
train_total_correct_tok: 142416.0
train_accuracy_tok: 0.8706943985913943
train_label=O_precision_sent: 0.3902439024390244
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.01921921921921922
train_label=N_precision_sent: 0.5961668545659526
train_label=N_recall_sent: 0.7987915407854985
train_label=N_f-score_sent: 0.6827630729502906
train_label=P_precision_sent: 0.6774827925270404
train_label=P_recall_sent: 0.7634349030470914
train_label=P_f-score_sent: 0.7178952852305287
train_precision_macro_sent: 0.5546311831773392
train_recall_macro_sent: 0.5240262201937861
train_f-score_macro_sent: 0.47329252580001285
train_precision_micro_sent: 0.6338951310861424
train_recall_micro_sent: 0.6338951310861424
train_f-score_micro_sent: 0.6338951310861424
train_label=O_precision_tok: 0.8828399674106914
train_label=O_recall_tok: 0.9672850973485488
train_label=O_f-score_tok: 0.9231353707768586
train_label=N_precision_tok: 0.7488969506814394
train_label=N_recall_tok: 0.5378115758343895
train_label=N_f-score_tok: 0.626039916396869
train_label=P_precision_tok: 0.8466074973724163
train_label=P_recall_tok: 0.5795658951912699
train_label=P_f-score_tok: 0.6880858030989725
train_precision_macro_tok: 0.826114805154849
train_recall_macro_tok: 0.6948875227914026
train_f-score_macro_tok: 0.7457536967575665
train_precision_micro_tok: 0.8706943985913943
train_recall_micro_tok: 0.8706943985913943
train_f-score_micro_tok: 0.8706943985913943
train_time: 141.26477909088135
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3902    0.0099    0.0192      1624
           N     0.5962    0.7988    0.6828      3310
           P     0.6775    0.7634    0.7179      3610

   micro avg     0.6339    0.6339    0.6339      8544
   macro avg     0.5546    0.5240    0.4733      8544
weighted avg     0.5914    0.6339    0.5715      8544

F1-macro sent:  0.47329252580001285
F1-micro sent:  0.6338951310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8828    0.9673    0.9231    124347
           N     0.7489    0.5378    0.6260     14202
           P     0.8466    0.5796    0.6881     25017

   micro avg     0.8707    0.8707    0.8707    163566
   macro avg     0.8261    0.6949    0.7458    163566
weighted avg     0.8657    0.8707    0.8614    163566

F1-macro tok:  0.7457536967575665
F1-micro tok:  0.8706943985913943
**************************************************
dev_cost_sum: 45040.536560058594
dev_cost_avg: 40.90875255227847
dev_count_sent: 1101.0
dev_total_correct_sent: 698.0
dev_accuracy_sent: 0.633969118982743
dev_count_tok: 21274.0
dev_total_correct_tok: 18782.0
dev_accuracy_tok: 0.8828617091285137
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.5689404934687954
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.701880035810206
dev_label=P_precision_sent: 0.7413793103448276
dev_label=P_recall_sent: 0.6779279279279279
dev_label=P_f-score_sent: 0.7082352941176471
dev_precision_macro_sent: 0.7145510457156522
dev_recall_macro_sent: 0.5385499465101963
dev_f-score_macro_sent: 0.48422284047240494
dev_precision_micro_sent: 0.633969118982743
dev_recall_micro_sent: 0.633969118982743
dev_f-score_micro_sent: 0.633969118982743
dev_label=O_precision_tok: 0.8866689053055742
dev_label=O_recall_tok: 0.9776612156741746
dev_label=O_f-score_tok: 0.929944530860212
dev_label=N_precision_tok: 0.7681159420289855
dev_label=N_recall_tok: 0.5708131394722671
dev_label=N_f-score_tok: 0.6549274019153537
dev_label=P_precision_tok: 0.9274432379072063
dev_label=P_recall_tok: 0.5849937733499377
dev_label=P_f-score_tok: 0.7174494081710577
dev_precision_macro_tok: 0.8607426950805886
dev_recall_macro_tok: 0.7111560428321265
dev_f-score_macro_tok: 0.7674404469822078
dev_precision_micro_tok: 0.8828617091285137
dev_recall_micro_tok: 0.8828617091285137
dev_f-score_micro_tok: 0.8828617091285137
dev_time: 8.237397909164429
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.5689    0.9159    0.7019       428
           P     0.7414    0.6779    0.7082       444

   micro avg     0.6340    0.6340    0.6340      1101
   macro avg     0.7146    0.5385    0.4842      1101
weighted avg     0.6935    0.6340    0.5673      1101

F1-macro sent:  0.48422284047240494
F1-micro sent:  0.633969118982743
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8867    0.9777    0.9299     16205
           N     0.7681    0.5708    0.6549      1857
           P     0.9274    0.5850    0.7174      3212

   micro avg     0.8829    0.8829    0.8829     21274
   macro avg     0.8607    0.7112    0.7674     21274
weighted avg     0.8825    0.8829    0.8739     21274

F1-macro tok:  0.7674404469822078
F1-micro tok:  0.8828617091285137
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 336207.17321777344
train_cost_avg: 39.35009049833491
train_count_sent: 8544.0
train_total_correct_sent: 5474.0
train_accuracy_sent: 0.6406835205992509
train_count_tok: 163566.0
train_total_correct_tok: 142666.0
train_accuracy_tok: 0.8722228335962241
train_label=O_precision_sent: 0.4810126582278481
train_label=O_recall_sent: 0.023399014778325122
train_label=O_f-score_sent: 0.04462712859659425
train_label=N_precision_sent: 0.6022675736961451
train_label=N_recall_sent: 0.802416918429003
train_label=N_f-score_sent: 0.6880829015544041
train_label=P_precision_sent: 0.6855733662145499
train_label=P_recall_sent: 0.7700831024930748
train_label=P_f-score_sent: 0.7253750815394651
train_precision_macro_sent: 0.589617866046181
train_recall_macro_sent: 0.5319663452334676
train_f-score_macro_sent: 0.4860283705634878
train_precision_micro_sent: 0.6406835205992509
train_recall_micro_sent: 0.6406835205992509
train_f-score_micro_sent: 0.6406835205992509
train_label=O_precision_tok: 0.8846552675124104
train_label=O_recall_tok: 0.9673816014861637
train_label=O_f-score_tok: 0.9241708345817873
train_label=N_precision_tok: 0.7472230271418913
train_label=N_recall_tok: 0.5447120123926208
train_label=N_f-score_tok: 0.6300957035227042
train_label=P_precision_tok: 0.84922844877596
train_label=P_recall_tok: 0.5851620897789503
train_label=P_f-score_tok: 0.6928884155721216
train_precision_macro_tok: 0.8270355811434206
train_recall_macro_tok: 0.6990852345525783
train_f-score_macro_tok: 0.7490516512255376
train_precision_micro_tok: 0.8722228335962241
train_recall_micro_tok: 0.8722228335962241
train_f-score_micro_tok: 0.8722228335962241
train_time: 141.21448612213135
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4810    0.0234    0.0446      1624
           N     0.6023    0.8024    0.6881      3310
           P     0.6856    0.7701    0.7254      3610

   micro avg     0.6407    0.6407    0.6407      8544
   macro avg     0.5896    0.5320    0.4860      8544
weighted avg     0.6144    0.6407    0.5815      8544

F1-macro sent:  0.4860283705634878
F1-micro sent:  0.6406835205992509
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9674    0.9242    124347
           N     0.7472    0.5447    0.6301     14202
           P     0.8492    0.5852    0.6929     25017

   micro avg     0.8722    0.8722    0.8722    163566
   macro avg     0.8270    0.6991    0.7491    163566
weighted avg     0.8673    0.8722    0.8633    163566

F1-macro tok:  0.7490516512255376
F1-micro tok:  0.8722228335962241
**************************************************
dev_cost_sum: 44834.05480957031
dev_cost_avg: 40.72121236109928
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18799.0
dev_accuracy_tok: 0.8836608066184074
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6608695652173913
dev_label=N_recall_sent: 0.7102803738317757
dev_label=N_f-score_sent: 0.6846846846846847
dev_label=P_precision_sent: 0.608424336973479
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.71889400921659
dev_precision_macro_sent: 0.42309796739695676
dev_recall_macro_sent: 0.5295529174033847
dev_f-score_macro_sent: 0.4678595646337582
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8797534533047163
dev_label=O_recall_tok: 0.9864856525763653
dev_label=O_f-score_tok: 0.9300674889457762
dev_label=N_precision_tok: 0.8549323017408124
dev_label=N_recall_tok: 0.4760366182014001
dev_label=N_f-score_tok: 0.6115530958145969
dev_label=P_precision_tok: 0.9323344610923151
dev_label=P_recall_tok: 0.6005603985056039
dev_label=P_f-score_tok: 0.7305434576784698
dev_precision_macro_tok: 0.8890067387126145
dev_recall_macro_tok: 0.6876942230944564
dev_f-score_macro_tok: 0.7573880141462809
dev_precision_micro_tok: 0.8836608066184074
dev_recall_micro_tok: 0.8836608066184074
dev_f-score_micro_tok: 0.8836608066184074
dev_time: 8.084458589553833
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6609    0.7103    0.6847       428
           P     0.6084    0.8784    0.7189       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.4231    0.5296    0.4679      1101
weighted avg     0.5023    0.6303    0.5561      1101

F1-macro sent:  0.4678595646337582
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8798    0.9865    0.9301     16205
           N     0.8549    0.4760    0.6116      1857
           P     0.9323    0.6006    0.7305      3212

   micro avg     0.8837    0.8837    0.8837     21274
   macro avg     0.8890    0.6877    0.7574     21274
weighted avg     0.8855    0.8837    0.8721     21274

F1-macro tok:  0.7573880141462809
F1-micro tok:  0.8836608066184074
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333274.0442504883
train_cost_avg: 39.00679356864329
train_count_sent: 8544.0
train_total_correct_sent: 5473.0
train_accuracy_sent: 0.6405664794007491
train_count_tok: 163566.0
train_total_correct_tok: 143380.0
train_accuracy_tok: 0.8765880439700182
train_label=O_precision_sent: 0.3275862068965517
train_label=O_recall_sent: 0.011699507389162561
train_label=O_f-score_sent: 0.022592152199762187
train_label=N_precision_sent: 0.6095017381228274
train_label=N_recall_sent: 0.7945619335347432
train_label=N_f-score_sent: 0.6898360655737705
train_label=P_precision_sent: 0.6770558619036202
train_label=P_recall_sent: 0.7822714681440444
train_label=P_f-score_sent: 0.7258707107055649
train_precision_macro_sent: 0.5380479356409998
train_recall_macro_sent: 0.5295109696893167
train_f-score_macro_sent: 0.4794329761596992
train_precision_micro_sent: 0.6405664794007491
train_recall_micro_sent: 0.6405664794007491
train_f-score_micro_sent: 0.6405664794007491
train_label=O_precision_tok: 0.8879120393229032
train_label=O_recall_tok: 0.9689578357338737
train_label=O_f-score_tok: 0.9266662564796726
train_label=N_precision_tok: 0.757593123209169
train_label=N_recall_tok: 0.5585128855090832
train_label=N_f-score_tok: 0.6429961089494163
train_label=P_precision_tok: 0.8598770044255417
train_label=P_recall_tok: 0.5980333373306151
train_label=P_f-score_tok: 0.7054413428894757
train_precision_macro_tok: 0.8351273889858714
train_recall_macro_tok: 0.7085013528578573
train_f-score_macro_tok: 0.7583679027728548
train_precision_micro_tok: 0.8765880439700182
train_recall_micro_tok: 0.8765880439700182
train_f-score_micro_tok: 0.8765880439700182
train_time: 104.19080638885498
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3276    0.0117    0.0226      1624
           N     0.6095    0.7946    0.6898      3310
           P     0.6771    0.7823    0.7259      3610

   micro avg     0.6406    0.6406    0.6406      8544
   macro avg     0.5380    0.5295    0.4794      8544
weighted avg     0.5845    0.6406    0.5782      8544

F1-macro sent:  0.4794329761596992
F1-micro sent:  0.6405664794007491
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8879    0.9690    0.9267    124347
           N     0.7576    0.5585    0.6430     14202
           P     0.8599    0.5980    0.7054     25017

   micro avg     0.8766    0.8766    0.8766    163566
   macro avg     0.8351    0.7085    0.7584    163566
weighted avg     0.8723    0.8766    0.8682    163566

F1-macro tok:  0.7583679027728548
F1-micro tok:  0.8765880439700182
**************************************************
dev_cost_sum: 44343.445068359375
dev_cost_avg: 40.27560859978145
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 18903.0
dev_accuracy_tok: 0.8885494030271693
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6223776223776224
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7120000000000001
dev_label=P_precision_sent: 0.6692015209125475
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7257731958762887
dev_precision_macro_sent: 0.6527486033189455
dev_recall_macro_sent: 0.5444340393938402
dev_f-score_macro_sent: 0.4850048583955446
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8949544141797384
dev_label=O_recall_tok: 0.9752545510644862
dev_label=O_f-score_tok: 0.933380581148122
dev_label=N_precision_tok: 0.7767272727272727
dev_label=N_recall_tok: 0.5751211631663974
dev_label=N_f-score_tok: 0.6608910891089109
dev_label=P_precision_tok: 0.9066964285714286
dev_label=P_recall_tok: 0.6323163138231631
dev_label=P_f-score_tok: 0.7450476889214966
dev_precision_macro_tok: 0.8594593718261466
dev_recall_macro_tok: 0.7275640093513488
dev_f-score_macro_tok: 0.7797731197261766
dev_precision_micro_tok: 0.8885494030271693
dev_recall_micro_tok: 0.8885494030271693
dev_f-score_micro_tok: 0.8885494030271693
dev_time: 4.849095582962036
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6224    0.8318    0.7120       428
           P     0.6692    0.7928    0.7258       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.6527    0.5444    0.4850      1101
weighted avg     0.6505    0.6449    0.5730      1101

F1-macro sent:  0.4850048583955446
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9753    0.9334     16205
           N     0.7767    0.5751    0.6609      1857
           P     0.9067    0.6323    0.7450      3212

   micro avg     0.8885    0.8885    0.8885     21274
   macro avg     0.8595    0.7276    0.7798     21274
weighted avg     0.8864    0.8885    0.8812     21274

F1-macro tok:  0.7797731197261766
F1-micro tok:  0.8885494030271693
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 330499.80041503906
train_cost_avg: 38.682092745205885
train_count_sent: 8544.0
train_total_correct_sent: 5497.0
train_accuracy_sent: 0.643375468164794
train_count_tok: 163566.0
train_total_correct_tok: 143827.0
train_accuracy_tok: 0.879320885758654
train_label=O_precision_sent: 0.4074074074074074
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026221692491060787
train_label=N_precision_sent: 0.6044080890706658
train_label=N_recall_sent: 0.8036253776435045
train_label=N_f-score_sent: 0.6899234859291921
train_label=P_precision_sent: 0.6884323795549034
train_label=P_recall_sent: 0.7797783933518005
train_label=P_f-score_sent: 0.7312638004935705
train_precision_macro_sent: 0.5667492920109922
train_recall_macro_sent: 0.5323168563416205
train_f-score_macro_sent: 0.48246965963794114
train_precision_micro_sent: 0.643375468164794
train_recall_micro_sent: 0.643375468164794
train_f-score_micro_sent: 0.643375468164794
train_label=O_precision_tok: 0.8904894877591123
train_label=O_recall_tok: 0.9694001463646087
train_label=O_f-score_tok: 0.9282708220227712
train_label=N_precision_tok: 0.7668305597579426
train_label=N_recall_tok: 0.5710463315026053
train_label=N_f-score_tok: 0.6546129631124386
train_label=P_precision_tok: 0.86104176123468
train_label=P_recall_tok: 0.6065875204860695
train_label=P_f-score_tok: 0.7117562908937407
train_precision_macro_tok: 0.8394539362505783
train_recall_macro_tok: 0.7156779994510946
train_f-score_macro_tok: 0.7648800253429835
train_precision_micro_tok: 0.879320885758654
train_recall_micro_tok: 0.879320885758654
train_f-score_micro_tok: 0.879320885758654
train_time: 92.7955048084259
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4074    0.0135    0.0262      1624
           N     0.6044    0.8036    0.6899      3310
           P     0.6884    0.7798    0.7313      3610

   micro avg     0.6434    0.6434    0.6434      8544
   macro avg     0.5667    0.5323    0.4825      8544
weighted avg     0.6025    0.6434    0.5812      8544

F1-macro sent:  0.48246965963794114
F1-micro sent:  0.643375468164794
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8905    0.9694    0.9283    124347
           N     0.7668    0.5710    0.6546     14202
           P     0.8610    0.6066    0.7118     25017

   micro avg     0.8793    0.8793    0.8793    163566
   macro avg     0.8395    0.7157    0.7649    163566
weighted avg     0.8752    0.8793    0.8714    163566

F1-macro tok:  0.7648800253429835
F1-micro tok:  0.879320885758654
**************************************************
dev_cost_sum: 44100.484375
dev_cost_avg: 40.0549358537693
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18964.0
dev_accuracy_tok: 0.8914167528438469
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6087689713322091
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7071498530852105
dev_label=P_precision_sent: 0.6719367588932806
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7157894736842105
dev_precision_macro_sent: 0.7602352434084966
dev_recall_macro_sent: 0.539319111381716
dev_f-score_macro_sent: 0.48008511469514614
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8947546531302877
dev_label=O_recall_tok: 0.9789571120024684
dev_label=O_f-score_tok: 0.9349639015765434
dev_label=N_precision_tok: 0.8035034272658035
dev_label=N_recall_tok: 0.5681206246634356
dev_label=N_f-score_tok: 0.6656151419558359
dev_label=P_precision_tok: 0.916629314208875
dev_label=P_recall_tok: 0.6366749688667497
dev_label=P_f-score_tok: 0.7514238471431196
dev_precision_macro_tok: 0.8716291315349887
dev_recall_macro_tok: 0.7279175685108846
dev_f-score_macro_tok: 0.7840009635584996
dev_precision_micro_tok: 0.8914167528438469
dev_recall_micro_tok: 0.8914167528438469
dev_f-score_micro_tok: 0.8914167528438469
dev_time: 4.915454387664795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6088    0.8435    0.7071       428
           P     0.6719    0.7658    0.7158       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.7602    0.5393    0.4801      1101
weighted avg     0.7156    0.6385    0.5672      1101

F1-macro sent:  0.48008511469514614
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9790    0.9350     16205
           N     0.8035    0.5681    0.6656      1857
           P     0.9166    0.6367    0.7514      3212

   micro avg     0.8914    0.8914    0.8914     21274
   macro avg     0.8716    0.7279    0.7840     21274
weighted avg     0.8901    0.8914    0.8837     21274

F1-macro tok:  0.7840009635584996
F1-micro tok:  0.8914167528438469
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328281.24322509766
train_cost_avg: 38.422430152750195
train_count_sent: 8544.0
train_total_correct_sent: 5520.0
train_accuracy_sent: 0.6460674157303371
train_count_tok: 163566.0
train_total_correct_tok: 144109.0
train_accuracy_tok: 0.8810449604441021
train_label=O_precision_sent: 0.31666666666666665
train_label=O_recall_sent: 0.023399014778325122
train_label=O_f-score_sent: 0.04357798165137614
train_label=N_precision_sent: 0.6034790365744871
train_label=N_recall_sent: 0.817522658610272
train_label=N_f-score_sent: 0.6943802925327175
train_label=P_precision_sent: 0.7045685279187818
train_label=P_recall_sent: 0.7689750692520776
train_label=P_f-score_sent: 0.7353642384105962
train_precision_macro_sent: 0.5415714103866452
train_recall_macro_sent: 0.5366322475468915
train_f-score_macro_sent: 0.49110750419822996
train_precision_micro_sent: 0.6460674157303371
train_recall_micro_sent: 0.6460674157303371
train_f-score_micro_sent: 0.6460674157303371
train_label=O_precision_tok: 0.891883500887049
train_label=O_recall_tok: 0.9703008516490145
train_label=O_f-score_tok: 0.9294410827841479
train_label=N_precision_tok: 0.7683065279091769
train_label=N_recall_tok: 0.5718208702999578
train_label=N_f-score_tok: 0.6556596156951396
train_label=P_precision_tok: 0.8655452698125988
train_label=P_recall_tok: 0.6129431986249351
train_label=P_f-score_tok: 0.7176655044111109
train_precision_macro_tok: 0.8419117662029416
train_recall_macro_tok: 0.7183549735246357
train_f-score_macro_tok: 0.7675887342967994
train_precision_micro_tok: 0.8810449604441021
train_recall_micro_tok: 0.8810449604441021
train_f-score_micro_tok: 0.8810449604441021
train_time: 92.56451487541199
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3167    0.0234    0.0436      1624
           N     0.6035    0.8175    0.6944      3310
           P     0.7046    0.7690    0.7354      3610

   micro avg     0.6461    0.6461    0.6461      8544
   macro avg     0.5416    0.5366    0.4911      8544
weighted avg     0.5917    0.6461    0.5880      8544

F1-macro sent:  0.49110750419822996
F1-micro sent:  0.6460674157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8919    0.9703    0.9294    124347
           N     0.7683    0.5718    0.6557     14202
           P     0.8655    0.6129    0.7177     25017

   micro avg     0.8810    0.8810    0.8810    163566
   macro avg     0.8419    0.7184    0.7676    163566
weighted avg     0.8771    0.8810    0.8733    163566

F1-macro tok:  0.7675887342967994
F1-micro tok:  0.8810449604441021
**************************************************
dev_cost_sum: 43825.48962402344
dev_cost_avg: 39.805167687578056
dev_count_sent: 1101.0
dev_total_correct_sent: 694.0
dev_accuracy_sent: 0.6303360581289736
dev_count_tok: 21274.0
dev_total_correct_tok: 18974.0
dev_accuracy_tok: 0.8918868101908433
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.565028901734104
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.6982142857142856
dev_label=P_precision_sent: 0.7425742574257426
dev_label=P_recall_sent: 0.6756756756756757
dev_label=P_f-score_sent: 0.7075471698113207
dev_precision_macro_sent: 0.6358677197199488
dev_recall_macro_sent: 0.5341091714086857
dev_f-score_macro_sent: 0.4771341603888773
dev_precision_micro_sent: 0.6303360581289736
dev_recall_micro_sent: 0.6303360581289736
dev_f-score_micro_sent: 0.6303360581289736
dev_label=O_precision_tok: 0.8949802594472646
dev_label=O_recall_tok: 0.9792039493983339
dev_label=O_f-score_tok: 0.9351996463827906
dev_label=N_precision_tok: 0.8234336859235151
dev_label=N_recall_tok: 0.5449649973074852
dev_label=N_f-score_tok: 0.6558651976668827
dev_label=P_precision_tok: 0.9045356371490281
dev_label=P_recall_tok: 0.6519302615193027
dev_label=P_f-score_tok: 0.7577347566491769
dev_precision_macro_tok: 0.8743165275066026
dev_recall_macro_tok: 0.7253664027417073
dev_f-score_macro_tok: 0.7829332002329501
dev_precision_micro_tok: 0.8918868101908433
dev_recall_micro_tok: 0.8918868101908433
dev_f-score_micro_tok: 0.8918868101908433
dev_time: 4.954547643661499
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.5650    0.9136    0.6982       428
           P     0.7426    0.6757    0.7075       444

   micro avg     0.6303    0.6303    0.6303      1101
   macro avg     0.6359    0.5341    0.4771      1101
weighted avg     0.6439    0.6303    0.5621      1101

F1-macro sent:  0.4771341603888773
F1-micro sent:  0.6303360581289736
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9792    0.9352     16205
           N     0.8234    0.5450    0.6559      1857
           P     0.9045    0.6519    0.7577      3212

   micro avg     0.8919    0.8919    0.8919     21274
   macro avg     0.8743    0.7254    0.7829     21274
weighted avg     0.8902    0.8919    0.8840     21274

F1-macro tok:  0.7829332002329501
F1-micro tok:  0.8918868101908433
**************************************************
Best epoch: 10
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 325549.9478149414
train_cost_avg: 38.10275606448284
train_count_sent: 8544.0
train_total_correct_sent: 5547.0
train_accuracy_sent: 0.6492275280898876
train_count_tok: 163566.0
train_total_correct_tok: 144366.0
train_accuracy_tok: 0.8826161916290671
train_label=O_precision_sent: 0.2926829268292683
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014414414414414413
train_label=N_precision_sent: 0.6171455267460874
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.6960874720063233
train_label=P_precision_sent: 0.6852202747513026
train_label=P_recall_sent: 0.8013850415512466
train_label=P_f-score_sent: 0.7387640449438202
train_precision_macro_sent: 0.5316829094422194
train_recall_macro_sent: 0.535653838430357
train_f-score_macro_sent: 0.483088643788186
train_precision_micro_sent: 0.6492275280898876
train_recall_micro_sent: 0.6492275280898876
train_f-score_micro_sent: 0.6492275280898876
train_label=O_precision_tok: 0.8936993285805332
train_label=O_recall_tok: 0.96981833096094
train_label=O_f-score_tok: 0.9302042154386099
train_label=N_precision_tok: 0.7739261492087415
train_label=N_recall_tok: 0.5785100690043656
train_label=N_f-score_tok: 0.6621000886453381
train_label=P_precision_tok: 0.8636464579169443
train_label=P_recall_tok: 0.6218171643282567
train_label=P_f-score_tok: 0.7230472472053732
train_precision_macro_tok: 0.843757311902073
train_recall_macro_tok: 0.7233818547645208
train_f-score_macro_tok: 0.7717838504297737
train_precision_micro_tok: 0.8826161916290671
train_recall_micro_tok: 0.8826161916290671
train_f-score_micro_tok: 0.8826161916290671
train_time: 93.20635771751404
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2927    0.0074    0.0144      1624
           N     0.6171    0.7982    0.6961      3310
           P     0.6852    0.8014    0.7388      3610

   micro avg     0.6492    0.6492    0.6492      8544
   macro avg     0.5317    0.5357    0.4831      8544
weighted avg     0.5842    0.6492    0.5846      8544

F1-macro sent:  0.483088643788186
F1-micro sent:  0.6492275280898876
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8937    0.9698    0.9302    124347
           N     0.7739    0.5785    0.6621     14202
           P     0.8636    0.6218    0.7230     25017

   micro avg     0.8826    0.8826    0.8826    163566
   macro avg     0.8438    0.7234    0.7718    163566
weighted avg     0.8787    0.8826    0.8752    163566

F1-macro tok:  0.7717838504297737
F1-micro tok:  0.8826161916290671
**************************************************
dev_cost_sum: 43701.329833984375
dev_cost_avg: 39.69239766937727
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 18978.0
dev_accuracy_tok: 0.8920748331296419
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6607495069033531
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7165775401069518
dev_label=P_precision_sent: 0.6430976430976431
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7360308285163776
dev_precision_macro_sent: 0.4346157166669988
dev_recall_macro_sent: 0.547690213578064
dev_f-score_macro_sent: 0.4842027895411098
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.898742818135275
dev_label=O_recall_tok: 0.9749460043196544
dev_label=O_f-score_tok: 0.9352948141131895
dev_label=N_precision_tok: 0.797037037037037
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6710321172435297
dev_label=P_precision_tok: 0.8968017057569296
dev_label=P_recall_tok: 0.6547322540473225
dev_label=P_f-score_tok: 0.756883210365305
dev_precision_macro_tok: 0.8641938536430805
dev_recall_macro_tok: 0.7363691484091682
dev_f-score_macro_tok: 0.7877367139073415
dev_precision_micro_tok: 0.8920748331296419
dev_recall_micro_tok: 0.8920748331296419
dev_f-score_micro_tok: 0.8920748331296419
dev_time: 5.074838161468506
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6607    0.7827    0.7166       428
           P     0.6431    0.8604    0.7360       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.4346    0.5477    0.4842      1101
weighted avg     0.5162    0.6512    0.5754      1101

F1-macro sent:  0.4842027895411098
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8987    0.9749    0.9353     16205
           N     0.7970    0.5794    0.6710      1857
           P     0.8968    0.6547    0.7569      3212

   micro avg     0.8921    0.8921    0.8921     21274
   macro avg     0.8642    0.7364    0.7877     21274
weighted avg     0.8896    0.8921    0.8853     21274

F1-macro tok:  0.7877367139073415
F1-micro tok:  0.8920748331296419
**************************************************
Best epoch: 10
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 323567.3585205078
train_cost_avg: 37.870711437325355
train_count_sent: 8544.0
train_total_correct_sent: 5577.0
train_accuracy_sent: 0.6527387640449438
train_count_tok: 163566.0
train_total_correct_tok: 144745.0
train_accuracy_tok: 0.8849332990963892
train_label=O_precision_sent: 0.4423076923076923
train_label=O_recall_sent: 0.02832512315270936
train_label=O_f-score_sent: 0.05324074074074074
train_label=N_precision_sent: 0.6147018661811561
train_label=N_recall_sent: 0.816012084592145
train_label=N_f-score_sent: 0.7011941848390447
train_label=P_precision_sent: 0.6994562530894711
train_label=P_recall_sent: 0.7839335180055401
train_label=P_f-score_sent: 0.7392894461859979
train_precision_macro_sent: 0.5854886038594399
train_recall_macro_sent: 0.5427569085834648
train_f-score_macro_sent: 0.4979081239219278
train_precision_micro_sent: 0.6527387640449438
train_recall_micro_sent: 0.6527387640449438
train_f-score_micro_sent: 0.6527387640449438
train_label=O_precision_tok: 0.8953887689785868
train_label=O_recall_tok: 0.9708235823944285
train_label=O_f-score_tok: 0.9315815873750821
train_label=N_precision_tok: 0.7806944056594992
train_label=N_recall_tok: 0.5905506266722996
train_label=N_f-score_tok: 0.6724393666065344
train_label=P_precision_tok: 0.8688333333333333
train_label=P_recall_tok: 0.6251349082623816
train_label=P_f-score_tok: 0.7271078875793292
train_precision_macro_tok: 0.8483055026571398
train_recall_macro_tok: 0.7288363724430367
train_f-score_macro_tok: 0.777042947186982
train_precision_micro_tok: 0.8849332990963892
train_recall_micro_tok: 0.8849332990963892
train_f-score_micro_tok: 0.8849332990963892
train_time: 92.72589921951294
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4423    0.0283    0.0532      1624
           N     0.6147    0.8160    0.7012      3310
           P     0.6995    0.7839    0.7393      3610

   micro avg     0.6527    0.6527    0.6527      8544
   macro avg     0.5855    0.5428    0.4979      8544
weighted avg     0.6177    0.6527    0.5941      8544

F1-macro sent:  0.4979081239219278
F1-micro sent:  0.6527387640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8954    0.9708    0.9316    124347
           N     0.7807    0.5906    0.6724     14202
           P     0.8688    0.6251    0.7271     25017

   micro avg     0.8849    0.8849    0.8849    163566
   macro avg     0.8483    0.7288    0.7770    163566
weighted avg     0.8814    0.8849    0.8778    163566

F1-macro tok:  0.777042947186982
F1-micro tok:  0.8849332990963892
**************************************************
dev_cost_sum: 43404.61962890625
dev_cost_avg: 39.42290611163147
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19017.0
dev_accuracy_tok: 0.8939080567829275
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11067193675889327
dev_label=N_precision_sent: 0.6311188811188811
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7220000000000001
dev_label=P_precision_sent: 0.6871287128712872
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7312961011591148
dev_precision_macro_sent: 0.6338603091078339
dev_recall_macro_sent: 0.5620416155452682
dev_f-score_macro_sent: 0.5213226793060027
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.8971012035938295
dev_label=O_recall_tok: 0.9796976241900648
dev_label=O_f-score_tok: 0.9365819125715298
dev_label=N_precision_tok: 0.7928779069767442
dev_label=N_recall_tok: 0.5875067312870221
dev_label=N_f-score_tok: 0.6749149396845036
dev_label=P_precision_tok: 0.93139482053612
dev_label=P_recall_tok: 0.6382316313823163
dev_label=P_f-score_tok: 0.7574358026972104
dev_precision_macro_tok: 0.8737913103688979
dev_recall_macro_tok: 0.7351453289531343
dev_f-score_macro_tok: 0.7896442183177479
dev_precision_micro_tok: 0.8939080567829275
dev_recall_micro_tok: 0.8939080567829275
dev_f-score_micro_tok: 0.8939080567829275
dev_time: 4.851947069168091
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0611    0.1107       229
           N     0.6311    0.8435    0.7220       428
           P     0.6871    0.7815    0.7313       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.6339    0.5620    0.5213      1101
weighted avg     0.6438    0.6558    0.5986      1101

F1-macro sent:  0.5213226793060027
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8971    0.9797    0.9366     16205
           N     0.7929    0.5875    0.6749      1857
           P     0.9314    0.6382    0.7574      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8738    0.7351    0.7896     21274
weighted avg     0.8932    0.8939    0.8867     21274

F1-macro tok:  0.7896442183177479
F1-micro tok:  0.8939080567829275
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 321408.2933959961
train_cost_avg: 37.618011867508905
train_count_sent: 8544.0
train_total_correct_sent: 5612.0
train_accuracy_sent: 0.6568352059925093
train_count_tok: 163566.0
train_total_correct_tok: 144913.0
train_accuracy_tok: 0.8859604074196349
train_label=O_precision_sent: 0.3466666666666667
train_label=O_recall_sent: 0.01600985221674877
train_label=O_f-score_sent: 0.03060623896409653
train_label=N_precision_sent: 0.6236683649837887
train_label=N_recall_sent: 0.813595166163142
train_label=N_f-score_sent: 0.7060828526481384
train_label=P_precision_sent: 0.69694049626596
train_label=P_recall_sent: 0.8013850415512466
train_label=P_f-score_sent: 0.7455224842159515
train_precision_macro_sent: 0.5557585093054719
train_recall_macro_sent: 0.5436633533103791
train_f-score_macro_sent: 0.49407052527606216
train_precision_micro_sent: 0.6568352059925093
train_recall_micro_sent: 0.6568352059925093
train_f-score_micro_sent: 0.6568352059925093
train_label=O_precision_tok: 0.8968794115461772
train_label=O_recall_tok: 0.9707592463026852
train_label=O_f-score_tok: 0.9323580639306086
train_label=N_precision_tok: 0.7773695811903012
train_label=N_recall_tok: 0.595972398253767
train_label=N_f-score_tok: 0.6746911119968114
train_label=P_precision_tok: 0.870079610791685
train_label=P_recall_tok: 0.6290922172922413
train_label=P_f-score_tok: 0.7302169121911611
train_precision_macro_tok: 0.8481095345093879
train_recall_macro_tok: 0.7319412872828979
train_f-score_macro_tok: 0.7790886960395271
train_precision_micro_tok: 0.8859604074196349
train_recall_micro_tok: 0.8859604074196349
train_f-score_micro_tok: 0.8859604074196349
train_time: 93.03123879432678
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3467    0.0160    0.0306      1624
           N     0.6237    0.8136    0.7061      3310
           P     0.6969    0.8014    0.7455      3610

   micro avg     0.6568    0.6568    0.6568      8544
   macro avg     0.5558    0.5437    0.4941      8544
weighted avg     0.6020    0.6568    0.5944      8544

F1-macro sent:  0.49407052527606216
F1-micro sent:  0.6568352059925093
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8969    0.9708    0.9324    124347
           N     0.7774    0.5960    0.6747     14202
           P     0.8701    0.6291    0.7302     25017

   micro avg     0.8860    0.8860    0.8860    163566
   macro avg     0.8481    0.7319    0.7791    163566
weighted avg     0.8824    0.8860    0.8791    163566

F1-macro tok:  0.7790886960395271
F1-micro tok:  0.8859604074196349
**************************************************
dev_cost_sum: 43290.15466308594
dev_cost_avg: 39.31894156501902
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 19020.0
dev_accuracy_tok: 0.8940490739870264
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.7232876712328767
dev_label=N_recall_sent: 0.616822429906542
dev_label=N_f-score_sent: 0.665825977301387
dev_label=P_precision_sent: 0.5785123966942148
dev_label=P_recall_sent: 0.9459459459459459
dev_label=P_f-score_sent: 0.717948717948718
dev_precision_macro_sent: 0.7006000226423638
dev_recall_macro_sent: 0.5325676245563606
dev_f-score_macro_sent: 0.4835734339815552
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.8999203459262631
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.9364435629495871
dev_label=N_precision_tok: 0.8022388059701493
dev_label=N_recall_tok: 0.5788906838987614
dev_label=N_f-score_tok: 0.6725054738817641
dev_label=P_precision_tok: 0.9024597116200169
dev_label=P_recall_tok: 0.6625155666251556
dev_label=P_f-score_tok: 0.7640933572710951
dev_precision_macro_tok: 0.8682062878388098
dev_recall_macro_tok: 0.7391543410416554
dev_f-score_macro_tok: 0.7910141313674822
dev_precision_micro_tok: 0.8940490739870264
dev_recall_micro_tok: 0.8940490739870264
dev_f-score_micro_tok: 0.8940490739870264
dev_time: 5.055513381958008
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.7233    0.6168    0.6658       428
           P     0.5785    0.9459    0.7179       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.7006    0.5326    0.4836      1101
weighted avg     0.6809    0.6285    0.5623      1101

F1-macro sent:  0.4835734339815552
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8999    0.9761    0.9364     16205
           N     0.8022    0.5789    0.6725      1857
           P     0.9025    0.6625    0.7641      3212

   micro avg     0.8940    0.8940    0.8940     21274
   macro avg     0.8682    0.7392    0.7910     21274
weighted avg     0.8918    0.8940    0.8874     21274

F1-macro tok:  0.7910141313674822
F1-micro tok:  0.8940490739870264
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 319446.4362182617
train_cost_avg: 37.388393752137375
train_count_sent: 8544.0
train_total_correct_sent: 5580.0
train_accuracy_sent: 0.6530898876404494
train_count_tok: 163566.0
train_total_correct_tok: 145246.0
train_accuracy_tok: 0.8879962828460682
train_label=O_precision_sent: 0.32231404958677684
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.04469914040114613
train_label=N_precision_sent: 0.6221144967682364
train_label=N_recall_sent: 0.8141993957703928
train_label=N_f-score_sent: 0.7053127453546193
train_label=P_precision_sent: 0.6956734294793449
train_label=P_recall_sent: 0.788365650969529
train_label=P_f-score_sent: 0.739124788988443
train_precision_macro_sent: 0.5467006586114528
train_recall_macro_sent: 0.5421932750216817
train_f-score_macro_sent: 0.49637889158140275
train_precision_micro_sent: 0.6530898876404494
train_recall_micro_sent: 0.6530898876404494
train_f-score_micro_sent: 0.6530898876404494
train_label=O_precision_tok: 0.8990897443537333
train_label=O_recall_tok: 0.9706788261880062
train_label=O_f-score_tok: 0.9335137957037065
train_label=N_precision_tok: 0.7811846055863889
train_label=N_recall_tok: 0.6045627376425855
train_label=N_f-score_tok: 0.6816179097368317
train_label=P_precision_tok: 0.8707917280515087
train_label=P_recall_tok: 0.6379262101770796
train_label=P_f-score_tok: 0.7363879660391288
train_precision_macro_tok: 0.8503553593305436
train_recall_macro_tok: 0.7377225913358904
train_f-score_macro_tok: 0.7838398904932223
train_precision_micro_tok: 0.8879962828460682
train_recall_micro_tok: 0.8879962828460682
train_f-score_micro_tok: 0.8879962828460682
train_time: 92.37387776374817
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3223    0.0240    0.0447      1624
           N     0.6221    0.8142    0.7053      3310
           P     0.6957    0.7884    0.7391      3610

   micro avg     0.6531    0.6531    0.6531      8544
   macro avg     0.5467    0.5422    0.4964      8544
weighted avg     0.5962    0.6531    0.5940      8544

F1-macro sent:  0.49637889158140275
F1-micro sent:  0.6530898876404494
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9707    0.9335    124347
           N     0.7812    0.6046    0.6816     14202
           P     0.8708    0.6379    0.7364     25017

   micro avg     0.8880    0.8880    0.8880    163566
   macro avg     0.8504    0.7377    0.7838    163566
weighted avg     0.8845    0.8880    0.8815    163566

F1-macro tok:  0.7838398904932223
F1-micro tok:  0.8879962828460682
**************************************************
dev_cost_sum: 43021.79333496094
dev_cost_avg: 39.0751983060499
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19047.0
dev_accuracy_tok: 0.8953182288239165
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.042553191489361694
dev_label=N_precision_sent: 0.6344463971880492
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.724172517552658
dev_label=P_precision_sent: 0.6768060836501901
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7340206185567011
dev_precision_macro_sent: 0.714861938057191
dev_recall_macro_sent: 0.5556979356208022
dev_f-score_macro_sent: 0.5002487758662403
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9005009107468124
dev_label=O_recall_tok: 0.9762419006479481
dev_label=O_f-score_tok: 0.9368430402984633
dev_label=N_precision_tok: 0.8144796380090498
dev_label=N_recall_tok: 0.5815831987075929
dev_label=N_f-score_tok: 0.6786050895381714
dev_label=P_precision_tok: 0.9021008403361345
dev_label=P_recall_tok: 0.6684308841843088
dev_label=P_f-score_tok: 0.7678826895565093
dev_precision_macro_tok: 0.8723604630306655
dev_recall_macro_tok: 0.7420853278466165
dev_f-score_macro_tok: 0.7944436064643813
dev_precision_micro_tok: 0.8953182288239165
dev_recall_micro_tok: 0.8953182288239165
dev_f-score_micro_tok: 0.8953182288239167
dev_time: 4.760885000228882
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0218    0.0426       229
           N     0.6344    0.8435    0.7242       428
           P     0.6768    0.8018    0.7340       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.7149    0.5557    0.5002      1101
weighted avg     0.6929    0.6558    0.5864      1101

F1-macro sent:  0.5002487758662403
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9005    0.9762    0.9368     16205
           N     0.8145    0.5816    0.6786      1857
           P     0.9021    0.6684    0.7679      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8724    0.7421    0.7944     21274
weighted avg     0.8932    0.8953    0.8888     21274

F1-macro tok:  0.7944436064643813
F1-micro tok:  0.8953182288239167
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 317277.927734375
train_cost_avg: 37.134588920221795
train_count_sent: 8544.0
train_total_correct_sent: 5660.0
train_accuracy_sent: 0.6624531835205992
train_count_tok: 163566.0
train_total_correct_tok: 145538.0
train_accuracy_tok: 0.8897814949317095
train_label=O_precision_sent: 0.4066666666666667
train_label=O_recall_sent: 0.037561576354679806
train_label=O_f-score_sent: 0.06877113866967306
train_label=N_precision_sent: 0.6255506607929515
train_label=N_recall_sent: 0.8151057401812689
train_label=N_f-score_sent: 0.7078577987668897
train_label=P_precision_sent: 0.7108551825532957
train_label=P_recall_sent: 0.803601108033241
train_label=P_f-score_sent: 0.7543882460018204
train_precision_macro_sent: 0.5810241700043046
train_recall_macro_sent: 0.5520894748563966
train_f-score_macro_sent: 0.5103390611461277
train_precision_micro_sent: 0.6624531835205992
train_recall_micro_sent: 0.6624531835205992
train_f-score_micro_sent: 0.6624531835205992
train_label=O_precision_tok: 0.9008916246968849
train_label=O_recall_tok: 0.9710085486581904
train_label=O_f-score_tok: 0.9346368801572925
train_label=N_precision_tok: 0.7815967523680649
train_label=N_recall_tok: 0.6100549218419941
train_label=N_f-score_tok: 0.685253292205481
train_label=P_precision_tok: 0.8740788903337668
train_label=P_recall_tok: 0.6448415077747132
train_label=P_f-score_tok: 0.742161801577991
train_precision_macro_tok: 0.8521890891329056
train_recall_macro_tok: 0.7419683260916324
train_f-score_macro_tok: 0.7873506579802548
train_precision_micro_tok: 0.8897814949317095
train_recall_micro_tok: 0.8897814949317095
train_f-score_micro_tok: 0.8897814949317095
train_time: 93.6510066986084
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4067    0.0376    0.0688      1624
           N     0.6256    0.8151    0.7079      3310
           P     0.7109    0.8036    0.7544      3610

   micro avg     0.6625    0.6625    0.6625      8544
   macro avg     0.5810    0.5521    0.5103      8544
weighted avg     0.6200    0.6625    0.6060      8544

F1-macro sent:  0.5103390611461277
F1-micro sent:  0.6624531835205992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9710    0.9346    124347
           N     0.7816    0.6101    0.6853     14202
           P     0.8741    0.6448    0.7422     25017

   micro avg     0.8898    0.8898    0.8898    163566
   macro avg     0.8522    0.7420    0.7874    163566
weighted avg     0.8864    0.8898    0.8835    163566

F1-macro tok:  0.7873506579802548
F1-micro tok:  0.8897814949317095
**************************************************
dev_cost_sum: 42976.98303222656
dev_cost_avg: 39.034498666872445
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19044.0
dev_accuracy_tok: 0.8951772116198177
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6128500823723229
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7188405797101449
dev_label=P_precision_sent: 0.6983805668016194
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7356076759061834
dev_precision_macro_sent: 0.43707688305798076
dev_recall_macro_sent: 0.5487286351772332
dev_f-score_macro_sent: 0.4848160852054428
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.894270658145532
dev_label=O_recall_tok: 0.9843875347115087
dev_label=O_f-score_tok: 0.9371676996739418
dev_label=N_precision_tok: 0.8317307692307693
dev_label=N_recall_tok: 0.5589660743134087
dev_label=N_f-score_tok: 0.6685990338164252
dev_label=P_precision_tok: 0.9387568555758684
dev_label=P_recall_tok: 0.6394769613947696
dev_label=P_f-score_tok: 0.7607407407407408
dev_precision_macro_tok: 0.8882527609840566
dev_recall_macro_tok: 0.7276101901398957
dev_f-score_macro_tok: 0.7888358247437025
dev_precision_micro_tok: 0.8951772116198177
dev_recall_micro_tok: 0.8951772116198177
dev_f-score_micro_tok: 0.8951772116198177
dev_time: 4.8192315101623535
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6129    0.8692    0.7188       428
           P     0.6984    0.7770    0.7356       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.4371    0.5487    0.4848      1101
weighted avg     0.5199    0.6512    0.5761      1101

F1-macro sent:  0.4848160852054428
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8943    0.9844    0.9372     16205
           N     0.8317    0.5590    0.6686      1857
           P     0.9388    0.6395    0.7607      3212

   micro avg     0.8952    0.8952    0.8952     21274
   macro avg     0.8883    0.7276    0.7888     21274
weighted avg     0.8955    0.8952    0.8871     21274

F1-macro tok:  0.7888358247437025
F1-micro tok:  0.8951772116198177
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 315543.8941040039
train_cost_avg: 36.93163554588061
train_count_sent: 8544.0
train_total_correct_sent: 5696.0
train_accuracy_sent: 0.6666666666666666
train_count_tok: 163566.0
train_total_correct_tok: 145860.0
train_accuracy_tok: 0.8917501192179303
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.027093596059113302
train_label=O_f-score_sent: 0.05011389521640091
train_label=N_precision_sent: 0.6386554621848739
train_label=N_recall_sent: 0.8265861027190332
train_label=N_f-score_sent: 0.7205688701606531
train_label=P_precision_sent: 0.7063953488372093
train_label=P_recall_sent: 0.8077562326869806
train_label=P_f-score_sent: 0.7536831222538124
train_precision_macro_sent: 0.5594613814518055
train_recall_macro_sent: 0.5538119771550424
train_f-score_macro_sent: 0.5081219625436221
train_precision_micro_sent: 0.6666666666666666
train_recall_micro_sent: 0.6666666666666666
train_f-score_micro_sent: 0.6666666666666666
train_label=O_precision_tok: 0.9024333754211898
train_label=O_recall_tok: 0.9713784811857141
train_label=O_f-score_tok: 0.9356375438623671
train_label=N_precision_tok: 0.7918991899189919
train_label=N_recall_tok: 0.6194902126461062
train_label=N_f-score_tok: 0.6951643489254109
train_label=P_precision_tok: 0.8745230802299963
train_label=P_recall_tok: 0.6505176479993604
train_label=P_f-score_tok: 0.7460688580204465
train_precision_macro_tok: 0.8562852151900593
train_recall_macro_tok: 0.7471287806103936
train_f-score_macro_tok: 0.7922902502694081
train_precision_micro_tok: 0.8917501192179303
train_recall_micro_tok: 0.8917501192179303
train_f-score_micro_tok: 0.8917501192179303
train_time: 93.49445986747742
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0271    0.0501      1624
           N     0.6387    0.8266    0.7206      3310
           P     0.7064    0.8078    0.7537      3610

   micro avg     0.6667    0.6667    0.6667      8544
   macro avg     0.5595    0.5538    0.5081      8544
weighted avg     0.6092    0.6667    0.6071      8544

F1-macro sent:  0.5081219625436221
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9714    0.9356    124347
           N     0.7919    0.6195    0.6952     14202
           P     0.8745    0.6505    0.7461     25017

   micro avg     0.8918    0.8918    0.8918    163566
   macro avg     0.8563    0.7471    0.7923    163566
weighted avg     0.8886    0.8918    0.8858    163566

F1-macro tok:  0.7922902502694081
F1-micro tok:  0.8917501192179303
**************************************************
dev_cost_sum: 42766.01922607422
dev_cost_avg: 38.84288758044888
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19097.0
dev_accuracy_tok: 0.8976685155588982
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017167381974248927
dev_label=N_precision_sent: 0.5875190258751902
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.711520737327189
dev_label=P_precision_sent: 0.7295454545454545
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.7262443438914028
dev_precision_macro_sent: 0.605688160140215
dev_recall_macro_sent: 0.5445252521018754
dev_f-score_macro_sent: 0.48497748773094695
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.9022599191666192
dev_label=O_recall_tok: 0.9780931811169392
dev_label=O_f-score_tok: 0.9386474002131945
dev_label=N_precision_tok: 0.799288256227758
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.6885346413243408
dev_label=P_precision_tok: 0.9226759339704604
dev_label=P_recall_tok: 0.6612702366127023
dev_label=P_f-score_tok: 0.7704026115342764
dev_precision_macro_tok: 0.8747413697882792
dev_recall_macro_tok: 0.748034081264395
dev_f-score_macro_tok: 0.7991948843572706
dev_precision_micro_tok: 0.8976685155588982
dev_recall_micro_tok: 0.8976685155588982
dev_f-score_micro_tok: 0.8976685155588982
dev_time: 5.0043323040008545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0087    0.0172       229
           N     0.5875    0.9019    0.7115       428
           P     0.7295    0.7230    0.7262       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.6057    0.5445    0.4850      1101
weighted avg     0.6266    0.6440    0.5730      1101

F1-macro sent:  0.48497748773094695
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9023    0.9781    0.9386     16205
           N     0.7993    0.6047    0.6885      1857
           P     0.9227    0.6613    0.7704      3212

   micro avg     0.8977    0.8977    0.8977     21274
   macro avg     0.8747    0.7480    0.7992     21274
weighted avg     0.8964    0.8977    0.8914     21274

F1-macro tok:  0.7991948843572706
F1-micro tok:  0.8976685155588982
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 313622.2102050781
train_cost_avg: 36.706719359208584
train_count_sent: 8544.0
train_total_correct_sent: 5685.0
train_accuracy_sent: 0.6653792134831461
train_count_tok: 163566.0
train_total_correct_tok: 146199.0
train_accuracy_tok: 0.8938226770844797
train_label=O_precision_sent: 0.43137254901960786
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.0962800875273523
train_label=N_precision_sent: 0.6415865384615385
train_label=N_recall_sent: 0.806344410876133
train_label=N_f-score_sent: 0.7145917001338687
train_label=P_precision_sent: 0.7004784688995215
train_label=P_recall_sent: 0.8110803324099723
train_label=P_f-score_sent: 0.7517329910141206
train_precision_macro_sent: 0.5911458521268892
train_recall_macro_sent: 0.5572039784681107
train_f-score_macro_sent: 0.5208682595584472
train_precision_micro_sent: 0.6653792134831461
train_recall_micro_sent: 0.6653792134831461
train_f-score_micro_sent: 0.6653792134831461
train_label=O_precision_tok: 0.9044871938764057
train_label=O_recall_tok: 0.9721344302636975
train_label=O_f-score_tok: 0.9370915602688434
train_label=N_precision_tok: 0.7913136537947025
train_label=N_recall_tok: 0.6247711589916913
train_label=N_f-score_tok: 0.6982490655124926
train_label=P_precision_tok: 0.8790762322249546
train_label=P_recall_tok: 0.6573130271415437
train_label=P_f-score_tok: 0.7521899229238616
train_precision_macro_tok: 0.8582923599653544
train_recall_macro_tok: 0.7514062054656442
train_f-score_macro_tok: 0.7958435162350659
train_precision_micro_tok: 0.8938226770844797
train_recall_micro_tok: 0.8938226770844797
train_f-score_micro_tok: 0.8938226770844797
train_time: 93.06391501426697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4314    0.0542    0.0963      1624
           N     0.6416    0.8063    0.7146      3310
           P     0.7005    0.8111    0.7517      3610

   micro avg     0.6654    0.6654    0.6654      8544
   macro avg     0.5911    0.5572    0.5209      8544
weighted avg     0.6265    0.6654    0.6128      8544

F1-macro sent:  0.5208682595584472
F1-micro sent:  0.6653792134831461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9045    0.9721    0.9371    124347
           N     0.7913    0.6248    0.6982     14202
           P     0.8791    0.6573    0.7522     25017

   micro avg     0.8938    0.8938    0.8938    163566
   macro avg     0.8583    0.7514    0.7958    163566
weighted avg     0.8908    0.8938    0.8881    163566

F1-macro tok:  0.7958435162350659
F1-micro tok:  0.8938226770844797
**************************************************
dev_cost_sum: 42625.69659423828
dev_cost_avg: 38.71543741529363
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19065.0
dev_accuracy_tok: 0.8961643320485099
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04184100418410041
dev_label=N_precision_sent: 0.6312949640287769
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7134146341463413
dev_label=P_precision_sent: 0.6747663551401869
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7374872318692544
dev_precision_macro_sent: 0.6020204397229879
dev_recall_macro_sent: 0.5516635273807865
dev_f-score_macro_sent: 0.49758095673323205
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9093331788424772
dev_label=O_recall_tok: 0.9685899413761185
dev_label=O_f-score_tok: 0.9380266539174087
dev_label=N_precision_tok: 0.771847898599066
dev_label=N_recall_tok: 0.6230479267635972
dev_label=N_f-score_tok: 0.6895113230035758
dev_label=P_precision_tok: 0.8798727128082736
dev_label=P_recall_tok: 0.688667496886675
dev_label=P_f-score_tok: 0.7726161369193153
dev_precision_macro_tok: 0.853684596749939
dev_recall_macro_tok: 0.7601017883421303
dev_f-score_macro_tok: 0.8000513712800998
dev_precision_micro_tok: 0.8961643320485099
dev_recall_micro_tok: 0.8961643320485099
dev_f-score_micro_tok: 0.89616433204851
dev_time: 4.828412055969238
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0218    0.0418       229
           N     0.6313    0.8201    0.7134       428
           P     0.6748    0.8131    0.7375       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6020    0.5517    0.4976      1101
weighted avg     0.6215    0.6512    0.5834      1101

F1-macro sent:  0.49758095673323205
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9093    0.9686    0.9380     16205
           N     0.7718    0.6230    0.6895      1857
           P     0.8799    0.6887    0.7726      3212

   micro avg     0.8962    0.8962    0.8962     21274
   macro avg     0.8537    0.7601    0.8001     21274
weighted avg     0.8929    0.8962    0.8914     21274

F1-macro tok:  0.8000513712800998
F1-micro tok:  0.89616433204851
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.810000
train_cost_sum: 311820.7205810547
train_cost_avg: 36.49587085452419
train_count_sent: 8544.0
train_total_correct_sent: 5771.0
train_accuracy_sent: 0.6754447565543071
train_count_tok: 163566.0
train_total_correct_tok: 146402.0
train_accuracy_tok: 0.8950637663084015
train_label=O_precision_sent: 0.4744897959183674
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.1021978021978022
train_label=N_precision_sent: 0.654052734375
train_label=N_recall_sent: 0.8093655589123867
train_label=N_f-score_sent: 0.7234674588171752
train_label=P_precision_sent: 0.7053151458137347
train_label=P_recall_sent: 0.8307479224376731
train_label=P_f-score_sent: 0.7629102009666751
train_precision_macro_sent: 0.6112858920357006
train_recall_macro_sent: 0.5657931637340922
train_f-score_macro_sent: 0.5295251539938842
train_precision_micro_sent: 0.6754447565543071
train_recall_micro_sent: 0.6754447565543071
train_f-score_micro_sent: 0.6754447565543071
train_label=O_precision_tok: 0.9061995903453554
train_label=O_recall_tok: 0.9713221871054388
train_label=O_f-score_tok: 0.9376314870162636
train_label=N_precision_tok: 0.7957409050576753
train_label=N_recall_tok: 0.6314603576960991
train_label=N_f-score_tok: 0.704145728643216
train_label=P_precision_tok: 0.8758744017251354
train_label=P_recall_tok: 0.6656673462045809
train_label=P_f-score_tok: 0.7564387917329093
train_precision_macro_tok: 0.8592716323760553
train_recall_macro_tok: 0.7561499636687063
train_f-score_macro_tok: 0.799405335797463
train_precision_micro_tok: 0.8950637663084015
train_recall_micro_tok: 0.8950637663084015
train_f-score_micro_tok: 0.8950637663084015
train_time: 92.98467707633972
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4745    0.0573    0.1022      1624
           N     0.6541    0.8094    0.7235      3310
           P     0.7053    0.8307    0.7629      3610

   micro avg     0.6754    0.6754    0.6754      8544
   macro avg     0.6113    0.5658    0.5295      8544
weighted avg     0.6416    0.6754    0.6220      8544

F1-macro sent:  0.5295251539938842
F1-micro sent:  0.6754447565543071
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9062    0.9713    0.9376    124347
           N     0.7957    0.6315    0.7041     14202
           P     0.8759    0.6657    0.7564     25017

   micro avg     0.8951    0.8951    0.8951    163566
   macro avg     0.8593    0.7561    0.7994    163566
weighted avg     0.8920    0.8951    0.8896    163566

F1-macro tok:  0.799405335797463
F1-micro tok:  0.8950637663084015
**************************************************
dev_cost_sum: 42553.68292236328
dev_cost_avg: 38.650029902237314
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19107.0
dev_accuracy_tok: 0.8981385729058945
dev_label=O_precision_sent: 0.8571428571428571
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05084745762711864
dev_label=N_precision_sent: 0.6627450980392157
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7206823027718551
dev_label=P_precision_sent: 0.6541095890410958
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7431906614785992
dev_precision_macro_sent: 0.7246658480743896
dev_recall_macro_sent: 0.5587602866303434
dev_f-score_macro_sent: 0.5049068072925244
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9102177942539388
dev_label=O_recall_tok: 0.9697007096575131
dev_label=O_f-score_tok: 0.9390181959425139
dev_label=N_precision_tok: 0.7768268597761685
dev_label=N_recall_tok: 0.6354334948842219
dev_label=N_f-score_tok: 0.6990521327014219
dev_label=P_precision_tok: 0.888398233641108
dev_label=P_recall_tok: 0.6889788293897883
dev_label=P_f-score_tok: 0.7760827634578291
dev_precision_macro_tok: 0.8584809625570718
dev_recall_macro_tok: 0.7647043446438411
dev_f-score_macro_tok: 0.8047176973672551
dev_precision_micro_tok: 0.8981385729058945
dev_recall_micro_tok: 0.8981385729058945
dev_f-score_micro_tok: 0.8981385729058945
dev_time: 4.942035436630249
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8571    0.0262    0.0508       229
           N     0.6627    0.7897    0.7207       428
           P     0.6541    0.8604    0.7432       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.7247    0.5588    0.5049      1101
weighted avg     0.6997    0.6594    0.5904      1101

F1-macro sent:  0.5049068072925244
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9697    0.9390     16205
           N     0.7768    0.6354    0.6991      1857
           P     0.8884    0.6890    0.7761      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8585    0.7647    0.8047     21274
weighted avg     0.8953    0.8981    0.8935     21274

F1-macro tok:  0.8047176973672551
F1-micro tok:  0.8981385729058945
**************************************************
Best epoch: 14
**************************************************

EPOCH: 21
Learning rate: 0.729000
train_cost_sum: 310132.71325683594
train_cost_avg: 36.29830445421769
train_count_sent: 8544.0
train_total_correct_sent: 5727.0
train_accuracy_sent: 0.6702949438202247
train_count_tok: 163566.0
train_total_correct_tok: 146729.0
train_accuracy_tok: 0.8970629592947189
train_label=O_precision_sent: 0.4349775784753363
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10503519220357337
train_label=N_precision_sent: 0.641086186540732
train_label=N_recall_sent: 0.8202416918429003
train_label=N_f-score_sent: 0.7196819085487077
train_label=P_precision_sent: 0.7134116495349976
train_label=P_recall_sent: 0.8074792243767313
train_label=P_f-score_sent: 0.7575363825363826
train_precision_macro_sent: 0.5964918048503552
train_recall_macro_sent: 0.5624833267530135
train_f-score_macro_sent: 0.5274178277628879
train_precision_micro_sent: 0.6702949438202247
train_recall_micro_sent: 0.6702949438202247
train_f-score_micro_sent: 0.6702949438202247
train_label=O_precision_tok: 0.9079903511606412
train_label=O_recall_tok: 0.9717082036558984
train_label=O_f-score_tok: 0.9387693263926656
train_label=N_precision_tok: 0.7992591285941083
train_label=N_recall_tok: 0.6380791437825658
train_label=N_f-score_tok: 0.7096319498825371
train_label=P_precision_tok: 0.8790394152962673
train_label=P_recall_tok: 0.6730623176240157
train_label=P_f-score_tok: 0.7623834103051705
train_precision_macro_tok: 0.862096298350339
train_recall_macro_tok: 0.76094988835416
train_f-score_macro_tok: 0.8035948955267912
train_precision_micro_tok: 0.8970629592947189
train_recall_micro_tok: 0.8970629592947189
train_f-score_micro_tok: 0.8970629592947189
train_time: 93.51494431495667
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4350    0.0597    0.1050      1624
           N     0.6411    0.8202    0.7197      3310
           P     0.7134    0.8075    0.7575      3610

   micro avg     0.6703    0.6703    0.6703      8544
   macro avg     0.5965    0.5625    0.5274      8544
weighted avg     0.6325    0.6703    0.6188      8544

F1-macro sent:  0.5274178277628879
F1-micro sent:  0.6702949438202247
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9717    0.9388    124347
           N     0.7993    0.6381    0.7096     14202
           P     0.8790    0.6731    0.7624     25017

   micro avg     0.8971    0.8971    0.8971    163566
   macro avg     0.8621    0.7609    0.8036    163566
weighted avg     0.8941    0.8971    0.8919    163566

F1-macro tok:  0.8035948955267912
F1-micro tok:  0.8970629592947189
**************************************************
dev_cost_sum: 42459.818115234375
dev_cost_avg: 38.56477576315565
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19130.0
dev_accuracy_tok: 0.899219704803986
dev_label=O_precision_sent: 0.6875
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08979591836734695
dev_label=N_precision_sent: 0.6610486891385767
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7338877338877339
dev_label=P_precision_sent: 0.676950998185118
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7497487437185929
dev_precision_macro_sent: 0.6751665624412316
dev_recall_macro_sent: 0.5709637932426979
dev_f-score_macro_sent: 0.524477465324558
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9036433091966475
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9393669985775248
dev_label=N_precision_tok: 0.8236623963828184
dev_label=N_recall_tok: 0.5885837372105547
dev_label=N_f-score_tok: 0.6865577889447236
dev_label=P_precision_tok: 0.9086378737541528
dev_label=P_recall_tok: 0.6811955168119551
dev_label=P_f-score_tok: 0.7786476868327402
dev_precision_macro_tok: 0.8786478597778729
dev_recall_macro_tok: 0.7492702419301609
dev_f-score_macro_tok: 0.8015241581183296
dev_precision_micro_tok: 0.899219704803986
dev_recall_micro_tok: 0.899219704803986
dev_f-score_micro_tok: 0.899219704803986
dev_time: 4.915587902069092
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6875    0.0480    0.0898       229
           N     0.6610    0.8248    0.7339       428
           P     0.6770    0.8401    0.7497       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6752    0.5710    0.5245      1101
weighted avg     0.6730    0.6694    0.6063      1101

F1-macro sent:  0.524477465324558
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9036    0.9780    0.9394     16205
           N     0.8237    0.5886    0.6866      1857
           P     0.9086    0.6812    0.7786      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8786    0.7493    0.8015     21274
weighted avg     0.8974    0.8992    0.8930     21274

F1-macro tok:  0.8015241581183296
F1-micro tok:  0.899219704803986
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.729000
train_cost_sum: 308815.0580444336
train_cost_avg: 36.14408450894588
train_count_sent: 8544.0
train_total_correct_sent: 5826.0
train_accuracy_sent: 0.6818820224719101
train_count_tok: 163566.0
train_total_correct_tok: 146900.0
train_accuracy_tok: 0.8981084088380226
train_label=O_precision_sent: 0.468
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.12486659551760938
train_label=N_precision_sent: 0.663235294117647
train_label=N_recall_sent: 0.817522658610272
train_label=N_f-score_sent: 0.73234100135318
train_label=P_precision_sent: 0.7126245847176079
train_label=P_recall_sent: 0.8318559556786703
train_label=P_f-score_sent: 0.767638036809816
train_precision_macro_sent: 0.6146199596117516
train_recall_macro_sent: 0.5738076497547705
train_f-score_macro_sent: 0.5416152112268685
train_precision_micro_sent: 0.6818820224719101
train_recall_micro_sent: 0.6818820224719101
train_f-score_micro_sent: 0.6818820224719101
train_label=O_precision_tok: 0.9091709497543026
train_label=O_recall_tok: 0.9716116995182835
train_label=O_f-score_tok: 0.9393548286773911
train_label=N_precision_tok: 0.8008888114325549
train_label=N_recall_tok: 0.6471623714969723
train_label=N_f-score_tok: 0.7158657216294105
train_label=P_precision_tok: 0.8796542206946831
train_label=P_recall_tok: 0.6752208498221209
train_label=P_f-score_tok: 0.7639981908638626
train_precision_macro_tok: 0.8632379939605134
train_recall_macro_tok: 0.7646649736124589
train_f-score_macro_tok: 0.8064062470568881
train_precision_micro_tok: 0.8981084088380226
train_recall_micro_tok: 0.8981084088380226
train_f-score_micro_tok: 0.8981084088380226
train_time: 91.78814387321472
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4680    0.0720    0.1249      1624
           N     0.6632    0.8175    0.7323      3310
           P     0.7126    0.8319    0.7676      3610

   micro avg     0.6819    0.6819    0.6819      8544
   macro avg     0.6146    0.5738    0.5416      8544
weighted avg     0.6470    0.6819    0.6318      8544

F1-macro sent:  0.5416152112268685
F1-micro sent:  0.6818820224719101
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9716    0.9394    124347
           N     0.8009    0.6472    0.7159     14202
           P     0.8797    0.6752    0.7640     25017

   micro avg     0.8981    0.8981    0.8981    163566
   macro avg     0.8632    0.7647    0.8064    163566
weighted avg     0.8953    0.8981    0.8931    163566

F1-macro tok:  0.8064062470568881
F1-micro tok:  0.8981084088380226
**************************************************
dev_cost_sum: 42380.97491455078
dev_cost_avg: 38.49316522665829
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19109.0
dev_accuracy_tok: 0.8982325843752937
dev_label=O_precision_sent: 0.6428571428571429
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07407407407407408
dev_label=N_precision_sent: 0.6641074856046065
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7291886195995786
dev_label=P_precision_sent: 0.666077738515901
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7465346534653464
dev_precision_macro_sent: 0.6576807889925501
dev_recall_macro_sent: 0.5656038746986795
dev_f-score_macro_sent: 0.5165991157129998
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9046556851978952
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.9390008608151028
dev_label=N_precision_tok: 0.825057295645531
dev_label=N_recall_tok: 0.5815831987075929
dev_label=N_f-score_tok: 0.6822488945041062
dev_label=P_precision_tok: 0.8915759774284563
dev_label=P_recall_tok: 0.688667496886675
dev_label=P_f-score_tok: 0.7770946776743369
dev_precision_macro_tok: 0.8737629860906275
dev_recall_macro_tok: 0.7487691560651056
dev_f-score_macro_tok: 0.799448144331182
dev_precision_micro_tok: 0.8982325843752937
dev_recall_micro_tok: 0.8982325843752937
dev_f-score_micro_tok: 0.8982325843752937
dev_time: 4.874475717544556
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6429    0.0393    0.0741       229
           N     0.6641    0.8084    0.7292       428
           P     0.6661    0.8491    0.7465       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6577    0.5656    0.5166      1101
weighted avg     0.6605    0.6649    0.5999      1101

F1-macro sent:  0.5165991157129998
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9047    0.9761    0.9390     16205
           N     0.8251    0.5816    0.6822      1857
           P     0.8916    0.6887    0.7771      3212

   micro avg     0.8982    0.8982    0.8982     21274
   macro avg     0.8738    0.7488    0.7994     21274
weighted avg     0.8957    0.8982    0.8921     21274

F1-macro tok:  0.799448144331182
F1-micro tok:  0.8982325843752937
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 0.729000
train_cost_sum: 307383.0498046875
train_cost_avg: 35.97648054830144
train_count_sent: 8544.0
train_total_correct_sent: 5847.0
train_accuracy_sent: 0.6843398876404494
train_count_tok: 163566.0
train_total_correct_tok: 147175.0
train_accuracy_tok: 0.8997896873433354
train_label=O_precision_sent: 0.4675324675324675
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11644204851752021
train_label=N_precision_sent: 0.6652740231014992
train_label=N_recall_sent: 0.8178247734138973
train_label=N_f-score_sent: 0.733703753896192
train_label=P_precision_sent: 0.7144203581526861
train_label=P_recall_sent: 0.8398891966759002
train_label=P_f-score_sent: 0.7720906544435956
train_precision_macro_sent: 0.6157422829288843
train_recall_macro_sent: 0.5747388110479948
train_f-score_macro_sent: 0.5407454856191026
train_precision_micro_sent: 0.6843398876404494
train_recall_micro_sent: 0.6843398876404494
train_f-score_micro_sent: 0.6843398876404494
train_label=O_precision_tok: 0.9109433166041205
train_label=O_recall_tok: 0.9721505142866333
train_label=O_f-score_tok: 0.9405521904383989
train_label=N_precision_tok: 0.807574832009774
train_label=N_recall_tok: 0.6515983664272638
train_label=N_f-score_tok: 0.7212501461361599
train_label=P_precision_tok: 0.8779695954650863
train_label=P_recall_tok: 0.6810169085022185
train_label=P_f-score_tok: 0.7670523614425285
train_precision_macro_tok: 0.8654959146929936
train_recall_macro_tok: 0.7682552630720386
train_f-score_macro_tok: 0.8096182326723623
train_precision_micro_tok: 0.8997896873433354
train_recall_micro_tok: 0.8997896873433354
train_f-score_micro_tok: 0.8997896873433353
train_time: 93.72782707214355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4675    0.0665    0.1164      1624
           N     0.6653    0.8178    0.7337      3310
           P     0.7144    0.8399    0.7721      3610

   micro avg     0.6843    0.6843    0.6843      8544
   macro avg     0.6157    0.5747    0.5407      8544
weighted avg     0.6485    0.6843    0.6326      8544

F1-macro sent:  0.5407454856191026
F1-micro sent:  0.6843398876404494
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9722    0.9406    124347
           N     0.8076    0.6516    0.7213     14202
           P     0.8780    0.6810    0.7671     25017

   micro avg     0.8998    0.8998    0.8998    163566
   macro avg     0.8655    0.7683    0.8096    163566
weighted avg     0.8969    0.8998    0.8950    163566

F1-macro tok:  0.8096182326723623
F1-micro tok:  0.8997896873433353
**************************************************
dev_cost_sum: 42433.276428222656
dev_cost_avg: 38.540668872136834
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19072.0
dev_accuracy_tok: 0.8964933721914073
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.716589861751152
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.7215777262180973
dev_label=P_precision_sent: 0.6152671755725191
dev_label=P_recall_sent: 0.9076576576576577
dev_label=P_f-score_sent: 0.7333939945404915
dev_precision_macro_sent: 0.7217301235523349
dev_recall_macro_sent: 0.5593204313156973
dev_f-score_macro_sent: 0.5126530908752697
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9081709362169664
dev_label=O_recall_tok: 0.9691453255168158
dev_label=O_f-score_tok: 0.9376679204728641
dev_label=N_precision_tok: 0.7904109589041096
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.695809466385288
dev_label=P_precision_tok: 0.8778262594208648
dev_label=P_recall_tok: 0.6889788293897883
dev_label=P_f-score_tok: 0.7720216291644864
dev_precision_macro_tok: 0.8588027181806469
dev_recall_macro_tok: 0.7598521909283008
dev_f-score_macro_tok: 0.8018330053408794
dev_precision_micro_tok: 0.8964933721914073
dev_recall_micro_tok: 0.8964933721914073
dev_f-score_micro_tok: 0.8964933721914073
dev_time: 4.972852468490601
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.7166    0.7266    0.7216       428
           P     0.6153    0.9077    0.7334       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.7217    0.5593    0.5127      1101
weighted avg     0.7000    0.6576    0.5935      1101

F1-macro sent:  0.5126530908752697
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9082    0.9691    0.9377     16205
           N     0.7904    0.6214    0.6958      1857
           P     0.8778    0.6890    0.7720      3212

   micro avg     0.8965    0.8965    0.8965     21274
   macro avg     0.8588    0.7599    0.8018     21274
weighted avg     0.8933    0.8965    0.8915     21274

F1-macro tok:  0.8018330053408794
F1-micro tok:  0.8964933721914073
**************************************************
Best epoch: 21
**************************************************

EPOCH: 24
Learning rate: 0.729000
train_cost_sum: 306142.8356323242
train_cost_avg: 35.831324395169034
train_count_sent: 8544.0
train_total_correct_sent: 5832.0
train_accuracy_sent: 0.6825842696629213
train_count_tok: 163566.0
train_total_correct_tok: 147360.0
train_accuracy_tok: 0.9009207292469095
train_label=O_precision_sent: 0.4249084249084249
train_label=O_recall_sent: 0.07142857142857142
train_label=O_f-score_sent: 0.12229836584080125
train_label=N_precision_sent: 0.6619891678975874
train_label=N_recall_sent: 0.8123867069486405
train_label=N_f-score_sent: 0.729517091698318
train_label=P_precision_sent: 0.7191732002851033
train_label=P_recall_sent: 0.8385041551246537
train_label=P_f-score_sent: 0.7742678091827598
train_precision_macro_sent: 0.6020235976970385
train_recall_macro_sent: 0.5741064778339552
train_f-score_macro_sent: 0.5420277555739598
train_precision_micro_sent: 0.6825842696629213
train_recall_micro_sent: 0.6825842696629213
train_f-score_micro_sent: 0.6825842696629213
train_label=O_precision_tok: 0.9124467795996014
train_label=O_recall_tok: 0.9720379261260826
train_label=O_f-score_tok: 0.9413001577010688
train_label=N_precision_tok: 0.8041825095057035
train_label=N_recall_tok: 0.6552598225602028
train_label=N_f-score_tok: 0.7221230697602236
train_label=P_precision_tok: 0.8800573594182116
train_label=P_recall_tok: 0.6868929128192829
train_label=P_f-score_tok: 0.7715690456412904
train_precision_macro_tok: 0.8655622161745055
train_recall_macro_tok: 0.7713968871685228
train_f-score_macro_tok: 0.8116640910341942
train_precision_micro_tok: 0.9009207292469095
train_recall_micro_tok: 0.9009207292469095
train_f-score_micro_tok: 0.9009207292469095
train_time: 92.87813806533813
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4249    0.0714    0.1223      1624
           N     0.6620    0.8124    0.7295      3310
           P     0.7192    0.8385    0.7743      3610

   micro avg     0.6826    0.6826    0.6826      8544
   macro avg     0.6020    0.5741    0.5420      8544
weighted avg     0.6411    0.6826    0.6330      8544

F1-macro sent:  0.5420277555739598
F1-micro sent:  0.6825842696629213
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9124    0.9720    0.9413    124347
           N     0.8042    0.6553    0.7221     14202
           P     0.8801    0.6869    0.7716     25017

   micro avg     0.9009    0.9009    0.9009    163566
   macro avg     0.8656    0.7714    0.8117    163566
weighted avg     0.8981    0.9009    0.8963    163566

F1-macro tok:  0.8116640910341942
F1-micro tok:  0.9009207292469095
**************************************************
dev_cost_sum: 42262.44873046875
dev_cost_avg: 38.38551201677452
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19133.0
dev_accuracy_tok: 0.899360722008085
dev_label=O_precision_sent: 0.48484848484848486
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12213740458015268
dev_label=N_precision_sent: 0.6258278145695364
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.7325581395348837
dev_label=P_precision_sent: 0.7306034482758621
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.7466960352422907
dev_precision_macro_sent: 0.6137599158979611
dev_recall_macro_sent: 0.5721866930800531
dev_f-score_macro_sent: 0.533797193119109
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9104961500607885
dev_label=O_recall_tok: 0.9705029311940759
dev_label=O_f-score_tok: 0.9395423860445665
dev_label=N_precision_tok: 0.784741144414169
dev_label=N_recall_tok: 0.6203554119547657
dev_label=N_f-score_tok: 0.6929323308270676
dev_label=P_precision_tok: 0.8898539281484406
dev_label=P_recall_tok: 0.7017434620174346
dev_label=P_f-score_tok: 0.7846823324630112
dev_precision_macro_tok: 0.8616970742077994
dev_recall_macro_tok: 0.764200601722092
dev_f-score_macro_tok: 0.8057190164448818
dev_precision_micro_tok: 0.899360722008085
dev_recall_micro_tok: 0.899360722008085
dev_f-score_micro_tok: 0.899360722008085
dev_time: 4.957191705703735
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4848    0.0699    0.1221       229
           N     0.6258    0.8832    0.7326       428
           P     0.7306    0.7635    0.7467       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6138    0.5722    0.5338      1101
weighted avg     0.6388    0.6658    0.6113      1101

F1-macro sent:  0.533797193119109
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9705    0.9395     16205
           N     0.7847    0.6204    0.6929      1857
           P     0.8899    0.7017    0.7847      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8617    0.7642    0.8057     21274
weighted avg     0.8964    0.8994    0.8946     21274

F1-macro tok:  0.8057190164448818
F1-micro tok:  0.899360722008085
**************************************************
Best epoch: 24
**************************************************

EPOCH: 25
Learning rate: 0.729000
train_cost_sum: 304856.1732788086
train_cost_avg: 35.680731891246324
train_count_sent: 8544.0
train_total_correct_sent: 5873.0
train_accuracy_sent: 0.6873829588014981
train_count_tok: 163566.0
train_total_correct_tok: 147656.0
train_accuracy_tok: 0.9027303962926281
train_label=O_precision_sent: 0.49137931034482757
train_label=O_recall_sent: 0.07019704433497537
train_label=O_f-score_sent: 0.12284482758620689
train_label=N_precision_sent: 0.6639941690962099
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.7360624831672502
train_label=P_precision_sent: 0.721163012392755
train_label=P_recall_sent: 0.8382271468144045
train_label=P_f-score_sent: 0.7753010504739944
train_precision_macro_sent: 0.6255121639445975
train_recall_macro_sent: 0.578034649819179
train_f-score_macro_sent: 0.5447361204091505
train_precision_micro_sent: 0.6873829588014981
train_recall_micro_sent: 0.6873829588014981
train_f-score_micro_sent: 0.6873829588014981
train_label=O_precision_tok: 0.9144524685470319
train_label=O_recall_tok: 0.971483027334797
train_label=O_f-score_tok: 0.9421054478668274
train_label=N_precision_tok: 0.8047241408714931
train_label=N_recall_tok: 0.6644838755104915
train_label=N_f-score_tok: 0.7279108334297505
train_label=P_precision_tok: 0.8825049399604803
train_label=P_recall_tok: 0.6962465523444058
train_label=P_f-score_tok: 0.7783885239308217
train_precision_macro_tok: 0.8672271831263352
train_recall_macro_tok: 0.7774044850632315
train_f-score_macro_tok: 0.8161349350757998
train_precision_micro_tok: 0.9027303962926281
train_recall_micro_tok: 0.9027303962926281
train_f-score_micro_tok: 0.9027303962926281
train_time: 92.17848873138428
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4914    0.0702    0.1228      1624
           N     0.6640    0.8257    0.7361      3310
           P     0.7212    0.8382    0.7753      3610

   micro avg     0.6874    0.6874    0.6874      8544
   macro avg     0.6255    0.5780    0.5447      8544
weighted avg     0.6553    0.6874    0.6361      8544

F1-macro sent:  0.5447361204091505
F1-micro sent:  0.6873829588014981
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9145    0.9715    0.9421    124347
           N     0.8047    0.6645    0.7279     14202
           P     0.8825    0.6962    0.7784     25017

   micro avg     0.9027    0.9027    0.9027    163566
   macro avg     0.8672    0.7774    0.8161    163566
weighted avg     0.9000    0.9027    0.8985    163566

F1-macro tok:  0.8161349350757998
F1-micro tok:  0.9027303962926281
**************************************************
dev_cost_sum: 42265.772033691406
dev_cost_avg: 38.38853045748538
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19164.0
dev_accuracy_tok: 0.9008178997837736
dev_label=O_precision_sent: 0.5862068965517241
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.13178294573643412
dev_label=N_precision_sent: 0.698744769874477
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7373068432671082
dev_label=P_precision_sent: 0.6498316498316499
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7437379576107901
dev_precision_macro_sent: 0.6449277720859503
dev_recall_macro_sent: 0.5746596696684442
dev_f-score_macro_sent: 0.5376092488714441
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9080565452246868
dev_label=O_recall_tok: 0.9751311323665536
dev_label=O_f-score_tok: 0.9403993215699111
dev_label=N_precision_tok: 0.79957805907173
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6935041171088747
dev_label=P_precision_tok: 0.9081632653061225
dev_label=P_recall_tok: 0.6927148194271482
dev_label=P_f-score_tok: 0.7859413634758037
dev_precision_macro_tok: 0.8719326232008463
dev_recall_macro_tok: 0.7600412731073245
dev_f-score_macro_tok: 0.8066149340515297
dev_precision_micro_tok: 0.9008178997837736
dev_recall_micro_tok: 0.9008178997837736
dev_f-score_micro_tok: 0.9008178997837736
dev_time: 5.086070775985718
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5862    0.0742    0.1318       229
           N     0.6987    0.7804    0.7373       428
           P     0.6498    0.8694    0.7437       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6449    0.5747    0.5376      1101
weighted avg     0.6556    0.6694    0.6140      1101

F1-macro sent:  0.5376092488714441
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9751    0.9404     16205
           N     0.7996    0.6123    0.6935      1857
           P     0.9082    0.6927    0.7859      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8719    0.7600    0.8066     21274
weighted avg     0.8986    0.9008    0.8955     21274

F1-macro tok:  0.8066149340515297
F1-micro tok:  0.9008178997837736
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 0.729000
train_cost_sum: 303721.7814941406
train_cost_avg: 35.54796131719811
train_count_sent: 8544.0
train_total_correct_sent: 5886.0
train_accuracy_sent: 0.6889044943820225
train_count_tok: 163566.0
train_total_correct_tok: 147696.0
train_accuracy_tok: 0.9029749458934009
train_label=O_precision_sent: 0.4827586206896552
train_label=O_recall_sent: 0.0603448275862069
train_label=O_f-score_sent: 0.10727969348659004
train_label=N_precision_sent: 0.6605157321977762
train_label=N_recall_sent: 0.8435045317220544
train_label=N_f-score_sent: 0.7408783335544646
train_label=P_precision_sent: 0.7282450170150705
train_label=P_recall_sent: 0.8299168975069252
train_label=P_f-score_sent: 0.7757638529259452
train_precision_macro_sent: 0.6238397899675007
train_recall_macro_sent: 0.5779220856050622
train_f-score_macro_sent: 0.5413072933223333
train_precision_micro_sent: 0.6889044943820225
train_recall_micro_sent: 0.6889044943820225
train_f-score_micro_sent: 0.6889044943820225
train_label=O_precision_tok: 0.9147309125049214
train_label=O_recall_tok: 0.9715875734838798
train_label=O_f-score_tok: 0.9423023675723317
train_label=N_precision_tok: 0.8081444879877322
train_label=N_recall_tok: 0.6679340937896071
train_label=N_f-score_tok: 0.7313801079414032
train_label=P_precision_tok: 0.8807209396516809
train_label=P_recall_tok: 0.6953671503377703
train_label=P_f-score_tok: 0.7771448993723334
train_precision_macro_tok: 0.8678654467147782
train_recall_macro_tok: 0.7782962725370858
train_f-score_macro_tok: 0.816942458295356
train_precision_micro_tok: 0.9029749458934009
train_recall_micro_tok: 0.9029749458934009
train_f-score_micro_tok: 0.9029749458934009
train_time: 93.29680490493774
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4828    0.0603    0.1073      1624
           N     0.6605    0.8435    0.7409      3310
           P     0.7282    0.8299    0.7758      3610

   micro avg     0.6889    0.6889    0.6889      8544
   macro avg     0.6238    0.5779    0.5413      8544
weighted avg     0.6553    0.6889    0.6352      8544

F1-macro sent:  0.5413072933223333
F1-micro sent:  0.6889044943820225
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9716    0.9423    124347
           N     0.8081    0.6679    0.7314     14202
           P     0.8807    0.6954    0.7771     25017

   micro avg     0.9030    0.9030    0.9030    163566
   macro avg     0.8679    0.7783    0.8169    163566
weighted avg     0.9003    0.9030    0.8987    163566

F1-macro tok:  0.816942458295356
F1-micro tok:  0.9029749458934009
**************************************************
dev_cost_sum: 42052.86309814453
dev_cost_avg: 38.19515267769712
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19130.0
dev_accuracy_tok: 0.899219704803986
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6046875
dev_label=N_recall_sent: 0.9042056074766355
dev_label=N_f-score_sent: 0.7247191011235955
dev_label=P_precision_sent: 0.7248908296943232
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7361419068736142
dev_precision_macro_sent: 0.6654149987869967
dev_recall_macro_sent: 0.5535623265595105
dev_f-score_macro_sent: 0.4927007957691849
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9091958667667264
dev_label=O_recall_tok: 0.9719222462203023
dev_label=O_f-score_tok: 0.939513242662849
dev_label=N_precision_tok: 0.7853223593964335
dev_label=N_recall_tok: 0.6165858912224017
dev_label=N_f-score_tok: 0.6907993966817496
dev_label=P_precision_tok: 0.8965102286401926
dev_label=P_recall_tok: 0.6958281444582815
dev_label=P_f-score_tok: 0.7835232252410166
dev_precision_macro_tok: 0.8636761516011174
dev_recall_macro_tok: 0.7614454273003285
dev_f-score_macro_tok: 0.8046119548618718
dev_precision_micro_tok: 0.899219704803986
dev_recall_micro_tok: 0.899219704803986
dev_f-score_micro_tok: 0.899219704803986
dev_time: 4.943556070327759
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6047    0.9042    0.7247       428
           P     0.7249    0.7477    0.7361       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6654    0.5536    0.4927      1101
weighted avg     0.6661    0.6549    0.5822      1101

F1-macro sent:  0.4927007957691849
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9719    0.9395     16205
           N     0.7853    0.6166    0.6908      1857
           P     0.8965    0.6958    0.7835      3212

   micro avg     0.8992    0.8992    0.8992     21274
   macro avg     0.8637    0.7614    0.8046     21274
weighted avg     0.8965    0.8992    0.8943     21274

F1-macro tok:  0.8046119548618718
F1-micro tok:  0.899219704803986
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 0.729000
train_cost_sum: 302508.57373046875
train_cost_avg: 35.40596602650617
train_count_sent: 8544.0
train_total_correct_sent: 5933.0
train_accuracy_sent: 0.6944054307116105
train_count_tok: 163566.0
train_total_correct_tok: 147985.0
train_accuracy_tok: 0.9047418167589841
train_label=O_precision_sent: 0.450199203187251
train_label=O_recall_sent: 0.06958128078817734
train_label=O_f-score_sent: 0.12053333333333333
train_label=N_precision_sent: 0.6674601285408236
train_label=N_recall_sent: 0.8471299093655589
train_label=N_f-score_sent: 0.7466382638796432
train_label=P_precision_sent: 0.7370478983382209
train_label=P_recall_sent: 0.8354570637119113
train_label=P_f-score_sent: 0.7831732017657751
train_precision_macro_sent: 0.6182357433554319
train_recall_macro_sent: 0.5840560846218825
train_f-score_macro_sent: 0.5501149329929172
train_precision_micro_sent: 0.6944054307116105
train_recall_micro_sent: 0.6944054307116105
train_f-score_micro_sent: 0.6944054307116105
train_label=O_precision_tok: 0.9168019665265618
train_label=O_recall_tok: 0.9717966657820454
train_label=O_f-score_tok: 0.9434986121575777
train_label=N_precision_tok: 0.8105138607167005
train_label=N_recall_tok: 0.6752570060554851
train_label=N_f-score_tok: 0.7367288929860951
train_label=P_precision_tok: 0.880921316740265
train_label=P_recall_tok: 0.7017228284766359
train_label=P_f-score_tok: 0.7811769941039047
train_precision_macro_tok: 0.8694123813278424
train_recall_macro_tok: 0.7829255001047222
train_f-score_macro_tok: 0.8204681664158592
train_precision_micro_tok: 0.9047418167589841
train_recall_micro_tok: 0.9047418167589841
train_f-score_micro_tok: 0.9047418167589841
train_time: 93.11735701560974
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4502    0.0696    0.1205      1624
           N     0.6675    0.8471    0.7466      3310
           P     0.7370    0.8355    0.7832      3610

   micro avg     0.6944    0.6944    0.6944      8544
   macro avg     0.6182    0.5841    0.5501      8544
weighted avg     0.6556    0.6944    0.6431      8544

F1-macro sent:  0.5501149329929172
F1-micro sent:  0.6944054307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9168    0.9718    0.9435    124347
           N     0.8105    0.6753    0.7367     14202
           P     0.8809    0.7017    0.7812     25017

   micro avg     0.9047    0.9047    0.9047    163566
   macro avg     0.8694    0.7829    0.8205    163566
weighted avg     0.9021    0.9047    0.9007    163566

F1-macro tok:  0.8204681664158592
F1-micro tok:  0.9047418167589841
**************************************************
dev_cost_sum: 42102.234436035156
dev_cost_avg: 38.239994946444284
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06639004149377593
dev_label=N_precision_sent: 0.6199021207177814
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.7300672430355428
dev_label=P_precision_sent: 0.7205882352941176
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7456521739130434
dev_precision_macro_sent: 0.6690523408928551
dev_recall_macro_sent: 0.5651024958762787
dev_f-score_macro_sent: 0.5140364861474541
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9083390764989663
dev_label=O_recall_tok: 0.9759950632520827
dev_label=O_f-score_tok: 0.9409524942737306
dev_label=N_precision_tok: 0.7834224598930482
dev_label=N_recall_tok: 0.6311254711900915
dev_label=N_f-score_tok: 0.6990754548165822
dev_label=P_precision_tok: 0.9230769230769231
dev_label=P_recall_tok: 0.6799501867995019
dev_label=P_f-score_tok: 0.7830763714593044
dev_precision_macro_tok: 0.8716128198229791
dev_recall_macro_tok: 0.7623569070805587
dev_f-score_macro_tok: 0.8077014401832058
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 4.862219572067261
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0349    0.0664       229
           N     0.6199    0.8879    0.7301       428
           P     0.7206    0.7725    0.7457       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6691    0.5651    0.5140      1101
weighted avg     0.6702    0.6639    0.5983      1101

F1-macro sent:  0.5140364861474541
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9760    0.9410     16205
           N     0.7834    0.6311    0.6991      1857
           P     0.9231    0.6800    0.7831      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8716    0.7624    0.8077     21274
weighted avg     0.8997    0.9012    0.8960     21274

F1-macro tok:  0.8077014401832058
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 25
**************************************************

EPOCH: 28
Learning rate: 0.729000
train_cost_sum: 301608.72088623047
train_cost_avg: 35.30064617114121
train_count_sent: 8544.0
train_total_correct_sent: 5884.0
train_accuracy_sent: 0.6886704119850188
train_count_tok: 163566.0
train_total_correct_tok: 148119.0
train_accuracy_tok: 0.9055610579215729
train_label=O_precision_sent: 0.42388059701492536
train_label=O_recall_sent: 0.0874384236453202
train_label=O_f-score_sent: 0.14497192445125062
train_label=N_precision_sent: 0.6664235351325067
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7385154250303113
train_label=P_precision_sent: 0.732666015625
train_label=P_recall_sent: 0.8313019390581717
train_label=P_f-score_sent: 0.7788736049831301
train_precision_macro_sent: 0.607656715924144
train_recall_macro_sent: 0.582279013146884
train_f-score_macro_sent: 0.5541203181548974
train_precision_micro_sent: 0.6886704119850188
train_recall_micro_sent: 0.6886704119850188
train_f-score_micro_sent: 0.6886704119850188
train_label=O_precision_tok: 0.9176660919496579
train_label=O_recall_tok: 0.9716277835412194
train_label=O_f-score_tok: 0.9438763153988579
train_label=N_precision_tok: 0.8105076741440378
train_label=N_recall_tok: 0.676735671032249
train_label=N_f-score_tok: 0.7376055257099002
train_label=P_precision_tok: 0.8822883934360816
train_label=P_recall_tok: 0.7070791861534157
train_label=P_f-score_tok: 0.7850264057160609
train_precision_macro_tok: 0.8701540531765923
train_recall_macro_tok: 0.7851475469089614
train_f-score_macro_tok: 0.822169415608273
train_precision_micro_tok: 0.9055610579215729
train_recall_micro_tok: 0.9055610579215729
train_f-score_micro_tok: 0.9055610579215729
train_time: 92.91184163093567
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4239    0.0874    0.1450      1624
           N     0.6664    0.8281    0.7385      3310
           P     0.7327    0.8313    0.7789      3610

   micro avg     0.6887    0.6887    0.6887      8544
   macro avg     0.6077    0.5823    0.5541      8544
weighted avg     0.6483    0.6887    0.6427      8544

F1-macro sent:  0.5541203181548974
F1-micro sent:  0.6886704119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9177    0.9716    0.9439    124347
           N     0.8105    0.6767    0.7376     14202
           P     0.8823    0.7071    0.7850     25017

   micro avg     0.9056    0.9056    0.9056    163566
   macro avg     0.8702    0.7851    0.8222    163566
weighted avg     0.9030    0.9056    0.9017    163566

F1-macro tok:  0.822169415608273
F1-micro tok:  0.9055610579215729
**************************************************
dev_cost_sum: 42034.55548095703
dev_cost_avg: 38.178524505864694
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.5098039215686274
dev_label=O_recall_sent: 0.11353711790393013
dev_label=O_f-score_sent: 0.1857142857142857
dev_label=N_precision_sent: 0.6377551020408163
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7381889763779528
dev_label=P_precision_sent: 0.7316017316017316
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.7461368653421633
dev_precision_macro_sent: 0.6263869184037251
dev_recall_macro_sent: 0.5836555344880856
dev_f-score_macro_sent: 0.556680042478134
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9080519182173213
dev_label=O_recall_tok: 0.9756865165072508
dev_label=O_f-score_tok: 0.9406550257310289
dev_label=N_precision_tok: 0.8046709129511678
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6954128440366973
dev_label=P_precision_tok: 0.907309105757452
dev_label=P_recall_tok: 0.6917808219178082
dev_label=P_f-score_tok: 0.7850203144320791
dev_precision_macro_tok: 0.8733439789753138
dev_recall_macro_tok: 0.7599150686511101
dev_f-score_macro_tok: 0.8070293947332684
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 4.948822259902954
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5098    0.1135    0.1857       229
           N     0.6378    0.8762    0.7382       428
           P     0.7316    0.7613    0.7461       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6264    0.5837    0.5567      1101
weighted avg     0.6490    0.6712    0.6265      1101

F1-macro sent:  0.556680042478134
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9757    0.9407     16205
           N     0.8047    0.6123    0.6954      1857
           P     0.9073    0.6918    0.7850      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8733    0.7599    0.8070     21274
weighted avg     0.8989    0.9011    0.8957     21274

F1-macro tok:  0.8070293947332684
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.729000
train_cost_sum: 299963.97985839844
train_cost_avg: 35.108143710018545
train_count_sent: 8544.0
train_total_correct_sent: 5908.0
train_accuracy_sent: 0.6914794007490637
train_count_tok: 163566.0
train_total_correct_tok: 148524.0
train_accuracy_tok: 0.9080371226293973
train_label=O_precision_sent: 0.4725274725274725
train_label=O_recall_sent: 0.07943349753694581
train_label=O_f-score_sent: 0.136004217185029
train_label=N_precision_sent: 0.6546961325966851
train_label=N_recall_sent: 0.859214501510574
train_label=N_f-score_sent: 0.7431408413901227
train_label=P_precision_sent: 0.7473898650369238
train_label=P_recall_sent: 0.8130193905817175
train_label=P_f-score_sent: 0.7788244659678917
train_precision_macro_sent: 0.6248711567203605
train_recall_macro_sent: 0.5838891298764124
train_f-score_macro_sent: 0.5526565081810144
train_precision_micro_sent: 0.6914794007490637
train_recall_micro_sent: 0.6914794007490637
train_f-score_micro_sent: 0.6914794007490637
train_label=O_precision_tok: 0.9200539013787485
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.9452557313706013
train_label=N_precision_tok: 0.8171361893648942
train_label=N_recall_tok: 0.6903253062948881
train_label=N_f-score_tok: 0.7483969465648855
train_label=P_precision_tok: 0.8839095810456546
train_label=P_recall_tok: 0.7143142662989167
train_label=P_f-score_tok: 0.7901136313392579
train_precision_macro_tok: 0.8736998905964325
train_recall_macro_tok: 0.7921722194968431
train_f-score_macro_tok: 0.8279221030915815
train_precision_micro_tok: 0.9080371226293973
train_recall_micro_tok: 0.9080371226293973
train_f-score_micro_tok: 0.9080371226293973
train_time: 129.31604957580566
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4725    0.0794    0.1360      1624
           N     0.6547    0.8592    0.7431      3310
           P     0.7474    0.8130    0.7788      3610

   micro avg     0.6915    0.6915    0.6915      8544
   macro avg     0.6249    0.5839    0.5527      8544
weighted avg     0.6592    0.6915    0.6428      8544

F1-macro sent:  0.5526565081810144
F1-micro sent:  0.6914794007490637
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9201    0.9719    0.9453    124347
           N     0.8171    0.6903    0.7484     14202
           P     0.8839    0.7143    0.7901     25017

   micro avg     0.9080    0.9080    0.9080    163566
   macro avg     0.8737    0.7922    0.8279    163566
weighted avg     0.9056    0.9080    0.9044    163566

F1-macro tok:  0.8279221030915815
F1-micro tok:  0.9080371226293973
**************************************************
dev_cost_sum: 41924.98699951172
dev_cost_avg: 38.07900726567822
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19143.0
dev_accuracy_tok: 0.8998307793550813
dev_label=O_precision_sent: 0.5675675675675675
dev_label=O_recall_sent: 0.09170305676855896
dev_label=O_f-score_sent: 0.15789473684210528
dev_label=N_precision_sent: 0.6857707509881423
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7430406852248393
dev_label=P_precision_sent: 0.6738351254480287
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.750499001996008
dev_precision_macro_sent: 0.6423911480012462
dev_recall_macro_sent: 0.5830991890556025
dev_f-score_macro_sent: 0.5504781413543176
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9111021022760178
dev_label=O_recall_tok: 0.9708114779389078
dev_label=O_f-score_tok: 0.9400095602294455
dev_label=N_precision_tok: 0.7888965044551063
dev_label=N_recall_tok: 0.6198169089929995
dev_label=N_f-score_tok: 0.6942098914354645
dev_label=P_precision_tok: 0.8869701726844584
dev_label=P_recall_tok: 0.7036114570361146
dev_label=P_f-score_tok: 0.7847222222222222
dev_precision_macro_tok: 0.8623229264718608
dev_recall_macro_tok: 0.7647466146560072
dev_f-score_macro_tok: 0.8063138912957107
dev_precision_micro_tok: 0.8998307793550813
dev_recall_micro_tok: 0.8998307793550813
dev_f-score_micro_tok: 0.8998307793550813
dev_time: 8.04299783706665
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5676    0.0917    0.1579       229
           N     0.6858    0.8107    0.7430       428
           P     0.6738    0.8468    0.7505       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6424    0.5831    0.5505      1101
weighted avg     0.6564    0.6757    0.6243      1101

F1-macro sent:  0.5504781413543176
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9111    0.9708    0.9400     16205
           N     0.7889    0.6198    0.6942      1857
           P     0.8870    0.7036    0.7847      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8623    0.7647    0.8063     21274
weighted avg     0.8968    0.8998    0.8951     21274

F1-macro tok:  0.8063138912957107
F1-micro tok:  0.8998307793550813
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.729000
train_cost_sum: 299015.86267089844
train_cost_avg: 34.99717493807332
train_count_sent: 8544.0
train_total_correct_sent: 5977.0
train_accuracy_sent: 0.6995552434456929
train_count_tok: 163566.0
train_total_correct_tok: 148587.0
train_accuracy_tok: 0.9084222882506144
train_label=O_precision_sent: 0.4749262536873156
train_label=O_recall_sent: 0.09913793103448276
train_label=O_f-score_sent: 0.1640346408558329
train_label=N_precision_sent: 0.6670599339310995
train_label=N_recall_sent: 0.8540785498489426
train_label=N_f-score_sent: 0.7490726020137783
train_label=P_precision_sent: 0.7534660952861104
train_label=P_recall_sent: 0.8279778393351801
train_label=P_f-score_sent: 0.7889666094760459
train_precision_macro_sent: 0.6318174276348419
train_recall_macro_sent: 0.5937314400728685
train_f-score_macro_sent: 0.5673579507818857
train_precision_micro_sent: 0.6995552434456929
train_recall_micro_sent: 0.6995552434456929
train_f-score_micro_sent: 0.6995552434456929
train_label=O_precision_tok: 0.9210921595388591
train_label=O_recall_tok: 0.9715071533692007
train_label=O_f-score_tok: 0.9456281800391388
train_label=N_precision_tok: 0.814051638530288
train_label=N_recall_tok: 0.6926489226869454
train_label=N_f-score_tok: 0.7484592558776534
train_label=P_precision_tok: 0.8827782970141178
train_label=P_recall_tok: 0.7173522005036576
train_label=P_f-score_tok: 0.7915141357561858
train_precision_macro_tok: 0.8726406983610883
train_recall_macro_tok: 0.7938360921866012
train_f-score_macro_tok: 0.8285338572243259
train_precision_micro_tok: 0.9084222882506144
train_recall_micro_tok: 0.9084222882506144
train_f-score_micro_tok: 0.9084222882506144
train_time: 141.26509380340576
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4749    0.0991    0.1640      1624
           N     0.6671    0.8541    0.7491      3310
           P     0.7535    0.8280    0.7890      3610

   micro avg     0.6996    0.6996    0.6996      8544
   macro avg     0.6318    0.5937    0.5674      8544
weighted avg     0.6670    0.6996    0.6547      8544

F1-macro sent:  0.5673579507818857
F1-micro sent:  0.6995552434456929
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9211    0.9715    0.9456    124347
           N     0.8141    0.6926    0.7485     14202
           P     0.8828    0.7174    0.7915     25017

   micro avg     0.9084    0.9084    0.9084    163566
   macro avg     0.8726    0.7938    0.8285    163566
weighted avg     0.9059    0.9084    0.9049    163566

F1-macro tok:  0.8285338572243259
F1-micro tok:  0.9084222882506144
**************************************************
dev_cost_sum: 42038.815368652344
dev_cost_avg: 38.18239361367152
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.6060606060606061
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.15267175572519084
dev_label=N_precision_sent: 0.6348408710217756
dev_label=N_recall_sent: 0.8855140186915887
dev_label=N_f-score_sent: 0.7395121951219512
dev_label=P_precision_sent: 0.7303609341825902
dev_label=P_recall_sent: 0.7747747747747747
dev_label=P_f-score_sent: 0.7519125683060108
dev_precision_macro_sent: 0.6570874704216573
dev_recall_macro_sent: 0.5825416793359494
dev_f-score_macro_sent: 0.548032173051051
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9118753980661224
dev_label=O_recall_tok: 0.971860536871336
dev_label=O_f-score_tok: 0.9409128928187359
dev_label=N_precision_tok: 0.7994486560992419
dev_label=N_recall_tok: 0.624663435648896
dev_label=N_f-score_tok: 0.7013301088270858
dev_label=P_precision_tok: 0.8859717868338558
dev_label=P_recall_tok: 0.7039227895392279
dev_label=P_f-score_tok: 0.7845246356696739
dev_precision_macro_tok: 0.8657652803330733
dev_recall_macro_tok: 0.7668155873531534
dev_f-score_macro_tok: 0.808922545771832
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 8.099326372146606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6061    0.0873    0.1527       229
           N     0.6348    0.8855    0.7395       428
           P     0.7304    0.7748    0.7519       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6571    0.5825    0.5480      1101
weighted avg     0.6674    0.6748    0.6225      1101

F1-macro sent:  0.548032173051051
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9719    0.9409     16205
           N     0.7994    0.6247    0.7013      1857
           P     0.8860    0.7039    0.7845      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8658    0.7668    0.8089     21274
weighted avg     0.8982    0.9011    0.8964     21274

F1-macro tok:  0.808922545771832
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 298103.5422363281
train_cost_avg: 34.89039586099346
train_count_sent: 8544.0
train_total_correct_sent: 5955.0
train_accuracy_sent: 0.6969803370786517
train_count_tok: 163566.0
train_total_correct_tok: 148838.0
train_accuracy_tok: 0.9099568369954636
train_label=O_precision_sent: 0.45121951219512196
train_label=O_recall_sent: 0.09113300492610837
train_label=O_f-score_sent: 0.15163934426229508
train_label=N_precision_sent: 0.6658031088082902
train_label=N_recall_sent: 0.8540785498489426
train_label=N_f-score_sent: 0.7482795129698254
train_label=P_precision_sent: 0.7506297229219143
train_label=P_recall_sent: 0.8254847645429363
train_label=P_f-score_sent: 0.7862796833773086
train_precision_macro_sent: 0.6225507813084422
train_recall_macro_sent: 0.5902321064393291
train_f-score_macro_sent: 0.562066180203143
train_precision_micro_sent: 0.6969803370786517
train_recall_micro_sent: 0.6969803370786517
train_f-score_micro_sent: 0.6969803370786517
train_label=O_precision_tok: 0.9224145170278875
train_label=O_recall_tok: 0.9717001616444305
train_label=O_f-score_tok: 0.9464161229429228
train_label=N_precision_tok: 0.8187236155947355
train_label=N_recall_tok: 0.6964512040557668
train_label=N_f-score_tok: 0.7526538066430772
train_label=P_precision_tok: 0.8841124231482385
train_label=P_recall_tok: 0.7242674981012911
train_label=P_f-score_tok: 0.7962470611500516
train_precision_macro_tok: 0.8750835185902872
train_recall_macro_tok: 0.797472954600496
train_f-score_macro_tok: 0.8317723302453505
train_precision_micro_tok: 0.9099568369954636
train_recall_micro_tok: 0.9099568369954636
train_f-score_micro_tok: 0.9099568369954636
train_time: 141.02277970314026
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4512    0.0911    0.1516      1624
           N     0.6658    0.8541    0.7483      3310
           P     0.7506    0.8255    0.7863      3610

   micro avg     0.6970    0.6970    0.6970      8544
   macro avg     0.6226    0.5902    0.5621      8544
weighted avg     0.6609    0.6970    0.6509      8544

F1-macro sent:  0.562066180203143
F1-micro sent:  0.6969803370786517
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9224    0.9717    0.9464    124347
           N     0.8187    0.6965    0.7527     14202
           P     0.8841    0.7243    0.7962     25017

   micro avg     0.9100    0.9100    0.9100    163566
   macro avg     0.8751    0.7975    0.8318    163566
weighted avg     0.9076    0.9100    0.9066    163566

F1-macro tok:  0.8317723302453505
F1-micro tok:  0.9099568369954636
**************************************************
dev_cost_sum: 41939.089904785156
dev_cost_avg: 38.091816443946556
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19134.0
dev_accuracy_tok: 0.8994077277427847
dev_label=O_precision_sent: 0.631578947368421
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0967741935483871
dev_label=N_precision_sent: 0.6381118881118881
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.73
dev_label=P_precision_sent: 0.7
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7484276729559748
dev_precision_macro_sent: 0.6565636118267697
dev_recall_macro_sent: 0.5697531796989006
dev_f-score_macro_sent: 0.5250672888347873
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9108549582947173
dev_label=O_recall_tok: 0.9703795124961432
dev_label=O_f-score_tok: 0.9396755206310317
dev_label=N_precision_tok: 0.8
dev_label=N_recall_tok: 0.6203554119547657
dev_label=N_f-score_tok: 0.6988171064604186
dev_label=P_precision_tok: 0.8782101167315175
dev_label=P_recall_tok: 0.7026774595267746
dev_label=P_f-score_tok: 0.7806987201660325
dev_precision_macro_tok: 0.8630216916754115
dev_recall_macro_tok: 0.7644707946592278
dev_f-score_macro_tok: 0.8063971157524943
dev_precision_micro_tok: 0.8994077277427847
dev_recall_micro_tok: 0.8994077277427847
dev_f-score_micro_tok: 0.8994077277427848
dev_time: 8.15234923362732
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6316    0.0524    0.0968       229
           N     0.6381    0.8528    0.7300       428
           P     0.7000    0.8041    0.7484       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6566    0.5698    0.5251      1101
weighted avg     0.6617    0.6667    0.6057      1101

F1-macro sent:  0.5250672888347873
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9704    0.9397     16205
           N     0.8000    0.6204    0.6988      1857
           P     0.8782    0.7027    0.7807      3212

   micro avg     0.8994    0.8994    0.8994     21274
   macro avg     0.8630    0.7645    0.8064     21274
weighted avg     0.8962    0.8994    0.8946     21274

F1-macro tok:  0.8063971157524943
F1-micro tok:  0.8994077277427848
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.729000
train_cost_sum: 296702.0037841797
train_cost_avg: 34.72635812080755
train_count_sent: 8544.0
train_total_correct_sent: 5953.0
train_accuracy_sent: 0.696746254681648
train_count_tok: 163566.0
train_total_correct_tok: 149048.0
train_accuracy_tok: 0.9112407223995207
train_label=O_precision_sent: 0.47619047619047616
train_label=O_recall_sent: 0.06773399014778325
train_label=O_f-score_sent: 0.11859838274932614
train_label=N_precision_sent: 0.6615168539325843
train_label=N_recall_sent: 0.8537764350453172
train_label=N_f-score_sent: 0.7454497494064891
train_label=P_precision_sent: 0.7465973768869092
train_label=P_recall_sent: 0.8357340720221607
train_label=P_f-score_sent: 0.788655077767612
train_precision_macro_sent: 0.6281015690033233
train_recall_macro_sent: 0.5857481657384204
train_f-score_macro_sent: 0.5509010699744757
train_precision_micro_sent: 0.696746254681648
train_recall_micro_sent: 0.696746254681648
train_f-score_micro_sent: 0.696746254681648
train_label=O_precision_tok: 0.9241108654574386
train_label=O_recall_tok: 0.9714508592889254
train_label=O_f-score_tok: 0.9471897249317818
train_label=N_precision_tok: 0.8205043949724801
train_label=N_recall_tok: 0.7032812279960569
train_label=N_f-score_tok: 0.7573838862559241
train_label=P_precision_tok: 0.8832946411298124
train_label=P_recall_tok: 0.7300235839629052
train_label=P_f-score_tok: 0.7993784605957149
train_precision_macro_tok: 0.8759699671865769
train_recall_macro_tok: 0.8015852237492957
train_f-score_macro_tok: 0.8346506905944736
train_precision_micro_tok: 0.9112407223995207
train_recall_micro_tok: 0.9112407223995207
train_f-score_micro_tok: 0.9112407223995207
train_time: 135.48274040222168
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4762    0.0677    0.1186      1624
           N     0.6615    0.8538    0.7454      3310
           P     0.7466    0.8357    0.7887      3610

   micro avg     0.6967    0.6967    0.6967      8544
   macro avg     0.6281    0.5857    0.5509      8544
weighted avg     0.6622    0.6967    0.6446      8544

F1-macro sent:  0.5509010699744757
F1-micro sent:  0.696746254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9241    0.9715    0.9472    124347
           N     0.8205    0.7033    0.7574     14202
           P     0.8833    0.7300    0.7994     25017

   micro avg     0.9112    0.9112    0.9112    163566
   macro avg     0.8760    0.8016    0.8347    163566
weighted avg     0.9089    0.9112    0.9081    163566

F1-macro tok:  0.8346506905944736
F1-micro tok:  0.9112407223995207
**************************************************
dev_cost_sum: 41974.13525390625
dev_cost_avg: 38.12364691544619
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19143.0
dev_accuracy_tok: 0.8998307793550813
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1509433962264151
dev_label=N_precision_sent: 0.6557971014492754
dev_label=N_recall_sent: 0.8457943925233645
dev_label=N_f-score_sent: 0.7387755102040817
dev_label=P_precision_sent: 0.695906432748538
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7460815047021944
dev_precision_macro_sent: 0.6357530299177897
dev_recall_macro_sent: 0.5790615637063011
dev_f-score_macro_sent: 0.5452668037108971
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.912528315037463
dev_label=O_recall_tok: 0.969515581610614
dev_label=O_f-score_tok: 0.9401591765902699
dev_label=N_precision_tok: 0.7819397993311037
dev_label=N_recall_tok: 0.6295099623047927
dev_label=N_f-score_tok: 0.697494033412888
dev_label=P_precision_tok: 0.8832943013270882
dev_label=P_recall_tok: 0.7045454545454546
dev_label=P_f-score_tok: 0.7838586768271562
dev_precision_macro_tok: 0.8592541385652183
dev_recall_macro_tok: 0.7678569994869537
dev_f-score_macro_tok: 0.8071706289434379
dev_precision_micro_tok: 0.8998307793550813
dev_recall_micro_tok: 0.8998307793550813
dev_f-score_micro_tok: 0.8998307793550813
dev_time: 4.972769498825073
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0873    0.1509       229
           N     0.6558    0.8458    0.7388       428
           P     0.6959    0.8041    0.7461       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6358    0.5791    0.5453      1101
weighted avg     0.6511    0.6712    0.6195      1101

F1-macro sent:  0.5452668037108971
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9125    0.9695    0.9402     16205
           N     0.7819    0.6295    0.6975      1857
           P     0.8833    0.7045    0.7839      3212

   micro avg     0.8998    0.8998    0.8998     21274
   macro avg     0.8593    0.7679    0.8072     21274
weighted avg     0.8967    0.8998    0.8954     21274

F1-macro tok:  0.8071706289434379
F1-micro tok:  0.8998307793550813
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.656100
train_cost_sum: 295529.37689208984
train_cost_avg: 34.589112463961825
train_count_sent: 8544.0
train_total_correct_sent: 5974.0
train_accuracy_sent: 0.6992041198501873
train_count_tok: 163566.0
train_total_correct_tok: 149345.0
train_accuracy_tok: 0.9130565031852586
train_label=O_precision_sent: 0.4289855072463768
train_label=O_recall_sent: 0.09113300492610837
train_label=O_f-score_sent: 0.15033011681056374
train_label=N_precision_sent: 0.6766265060240964
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7528150134048257
train_label=P_precision_sent: 0.7453692269696222
train_label=P_recall_sent: 0.83601108033241
train_label=P_f-score_sent: 0.7880924402663534
train_precision_macro_sent: 0.6169937467466985
train_recall_macro_sent: 0.5918274846128596
train_f-score_macro_sent: 0.5637458568272476
train_precision_micro_sent: 0.6992041198501873
train_recall_micro_sent: 0.6992041198501873
train_f-score_micro_sent: 0.6992041198501873
train_label=O_precision_tok: 0.9257033492822967
train_label=O_recall_tok: 0.972440026699478
train_label=O_f-score_tok: 0.9484963054766797
train_label=N_precision_tok: 0.823370676261346
train_label=N_recall_tok: 0.7089846500492888
train_label=N_f-score_tok: 0.7619083651772539
train_label=P_precision_tok: 0.8862495171881035
train_label=P_recall_tok: 0.7337410560818644
train_label=P_f-score_tok: 0.8028165934089965
train_precision_macro_tok: 0.8784411809105821
train_recall_macro_tok: 0.8050552442768771
train_f-score_macro_tok: 0.8377404213543101
train_precision_micro_tok: 0.9130565031852586
train_recall_micro_tok: 0.9130565031852586
train_f-score_micro_tok: 0.9130565031852586
train_time: 92.59656071662903
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4290    0.0911    0.1503      1624
           N     0.6766    0.8483    0.7528      3310
           P     0.7454    0.8360    0.7881      3610

   micro avg     0.6992    0.6992    0.6992      8544
   macro avg     0.6170    0.5918    0.5637      8544
weighted avg     0.6586    0.6992    0.6532      8544

F1-macro sent:  0.5637458568272476
F1-micro sent:  0.6992041198501873
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9257    0.9724    0.9485    124347
           N     0.8234    0.7090    0.7619     14202
           P     0.8862    0.7337    0.8028     25017

   micro avg     0.9131    0.9131    0.9131    163566
   macro avg     0.8784    0.8051    0.8377    163566
weighted avg     0.9108    0.9131    0.9100    163566

F1-macro tok:  0.8377404213543101
F1-micro tok:  0.9130565031852586
**************************************************
dev_cost_sum: 41984.03503417969
dev_cost_avg: 38.13263854148927
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.45652173913043476
dev_label=O_recall_sent: 0.09170305676855896
dev_label=O_f-score_sent: 0.1527272727272727
dev_label=N_precision_sent: 0.6915113871635611
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7332601536772776
dev_label=P_precision_sent: 0.6590909090909091
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7421259842519684
dev_precision_macro_sent: 0.602374678461635
dev_recall_macro_sent: 0.573725329214453
dev_f-score_macro_sent: 0.5427044702188396
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9135565631903267
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.9408207860628013
dev_label=N_precision_tok: 0.7885906040268457
dev_label=N_recall_tok: 0.6327409800753904
dev_label=N_f-score_tok: 0.7021213026590977
dev_label=P_precision_tok: 0.8838109992254066
dev_label=P_recall_tok: 0.7104607721046077
dev_label=P_f-score_tok: 0.7877114256127027
dev_precision_macro_tok: 0.8619860554808597
dev_recall_macro_tok: 0.7709880570621591
dev_f-score_macro_tok: 0.8102178381115338
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 5.034402370452881
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4565    0.0917    0.1527       229
           N     0.6915    0.7804    0.7333       428
           P     0.6591    0.8491    0.7421       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6024    0.5737    0.5427      1101
weighted avg     0.6296    0.6649    0.6161      1101

F1-macro sent:  0.5427044702188396
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9698    0.9408     16205
           N     0.7886    0.6327    0.7021      1857
           P     0.8838    0.7105    0.7877      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8620    0.7710    0.8102     21274
weighted avg     0.8982    0.9012    0.8969     21274

F1-macro tok:  0.8102178381115338
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.590490
train_cost_sum: 294649.3568725586
train_cost_avg: 34.48611386617025
train_count_sent: 8544.0
train_total_correct_sent: 5995.0
train_accuracy_sent: 0.7016619850187266
train_count_tok: 163566.0
train_total_correct_tok: 149453.0
train_accuracy_tok: 0.913716787107345
train_label=O_precision_sent: 0.4594594594594595
train_label=O_recall_sent: 0.10467980295566502
train_label=O_f-score_sent: 0.17051153460381147
train_label=N_precision_sent: 0.6754280202556064
train_label=N_recall_sent: 0.8462235649546828
train_label=N_f-score_sent: 0.751240445219257
train_label=P_precision_sent: 0.7509312143034517
train_label=P_recall_sent: 0.8376731301939058
train_label=P_f-score_sent: 0.7919340054995416
train_precision_macro_sent: 0.6286062313395059
train_recall_macro_sent: 0.5961921660347512
train_f-score_macro_sent: 0.5712286617742034
train_precision_micro_sent: 0.7016619850187266
train_recall_micro_sent: 0.7016619850187266
train_f-score_micro_sent: 0.7016619850187266
train_label=O_precision_tok: 0.9269873658532843
train_label=O_recall_tok: 0.9718207918164491
train_label=O_f-score_tok: 0.9488747899555569
train_label=N_precision_tok: 0.8238840013033562
train_label=N_recall_tok: 0.7121532178566399
train_label=N_f-score_tok: 0.7639549814940706
train_label=P_precision_tok: 0.8837498208227818
train_label=P_recall_tok: 0.7393372506695447
train_label=P_f-score_tok: 0.8051190528011144
train_precision_macro_tok: 0.8782070626598074
train_recall_macro_tok: 0.8077704201142112
train_f-score_macro_tok: 0.8393162747502473
train_precision_micro_tok: 0.913716787107345
train_recall_micro_tok: 0.913716787107345
train_f-score_micro_tok: 0.913716787107345
train_time: 92.36476540565491
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4595    0.1047    0.1705      1624
           N     0.6754    0.8462    0.7512      3310
           P     0.7509    0.8377    0.7919      3610

   micro avg     0.7017    0.7017    0.7017      8544
   macro avg     0.6286    0.5962    0.5712      8544
weighted avg     0.6663    0.7017    0.6581      8544

F1-macro sent:  0.5712286617742034
F1-micro sent:  0.7016619850187266
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9270    0.9718    0.9489    124347
           N     0.8239    0.7122    0.7640     14202
           P     0.8837    0.7393    0.8051     25017

   micro avg     0.9137    0.9137    0.9137    163566
   macro avg     0.8782    0.8078    0.8393    163566
weighted avg     0.9114    0.9137    0.9108    163566

F1-macro tok:  0.8393162747502473
F1-micro tok:  0.913716787107345
**************************************************
dev_cost_sum: 41884.28790283203
dev_cost_avg: 38.042041691945535
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19147.0
dev_accuracy_tok: 0.9000188022938799
dev_label=O_precision_sent: 0.5517241379310345
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12403100775193798
dev_label=N_precision_sent: 0.6482142857142857
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7348178137651822
dev_label=P_precision_sent: 0.69921875
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7489539748953975
dev_precision_macro_sent: 0.6330523912151067
dev_recall_macro_sent: 0.5747687143536632
dev_f-score_macro_sent: 0.5359342654708392
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9146960938868454
dev_label=O_recall_tok: 0.9667386609071275
dev_label=O_f-score_tok: 0.9399975999039963
dev_label=N_precision_tok: 0.781127129750983
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.7046999704404376
dev_label=P_precision_tok: 0.8733307897748951
dev_label=P_recall_tok: 0.712640099626401
dev_label=P_f-score_tok: 0.7848448482770444
dev_precision_macro_tok: 0.8563846711375745
dev_recall_macro_tok: 0.7737580969863153
dev_f-score_macro_tok: 0.8098474728738262
dev_precision_micro_tok: 0.9000188022938799
dev_recall_micro_tok: 0.9000188022938799
dev_f-score_micro_tok: 0.9000188022938799
dev_time: 4.83490252494812
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5517    0.0699    0.1240       229
           N     0.6482    0.8481    0.7348       428
           P     0.6992    0.8063    0.7490       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6331    0.5748    0.5359      1101
weighted avg     0.6487    0.6694    0.6135      1101

F1-macro sent:  0.5359342654708392
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9667    0.9400     16205
           N     0.7811    0.6419    0.7047      1857
           P     0.8733    0.7126    0.7848      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8564    0.7738    0.8098     21274
weighted avg     0.8968    0.9000    0.8960     21274

F1-macro tok:  0.8098474728738262
F1-micro tok:  0.9000188022938799
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.531441
train_cost_sum: 293446.53424072266
train_cost_avg: 34.34533406375499
train_count_sent: 8544.0
train_total_correct_sent: 6068.0
train_accuracy_sent: 0.7102059925093633
train_count_tok: 163566.0
train_total_correct_tok: 149721.0
train_accuracy_tok: 0.9153552694325227
train_label=O_precision_sent: 0.45036319612590797
train_label=O_recall_sent: 0.1145320197044335
train_label=O_f-score_sent: 0.18262150220913104
train_label=N_precision_sent: 0.6864550520959535
train_label=N_recall_sent: 0.8558912386706948
train_label=N_f-score_sent: 0.7618663439558961
train_label=P_precision_sent: 0.7614885114885115
train_label=P_recall_sent: 0.8445983379501385
train_label=P_f-score_sent: 0.8008930916732335
train_precision_macro_sent: 0.6327689199034576
train_recall_macro_sent: 0.6050071987750889
train_f-score_macro_sent: 0.581793645946087
train_precision_micro_sent: 0.7102059925093633
train_recall_micro_sent: 0.7102059925093633
train_f-score_micro_sent: 0.7102059925093634
train_label=O_precision_tok: 0.9281087884090002
train_label=O_recall_tok: 0.9726008669288363
train_label=O_f-score_tok: 0.9498340892580159
train_label=N_precision_tok: 0.8264294996751137
train_label=N_recall_tok: 0.7164483875510491
train_label=N_f-score_tok: 0.7675190465414498
train_label=P_precision_tok: 0.8882841592666858
train_label=P_recall_tok: 0.7437342607027222
train_label=P_f-score_tok: 0.8096077279550944
train_precision_macro_tok: 0.8809408157836
train_recall_macro_tok: 0.8109278383942025
train_f-score_macro_tok: 0.8423202879181867
train_precision_micro_tok: 0.9153552694325227
train_recall_micro_tok: 0.9153552694325227
train_f-score_micro_tok: 0.9153552694325227
train_time: 92.2094931602478
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4504    0.1145    0.1826      1624
           N     0.6865    0.8559    0.7619      3310
           P     0.7615    0.8446    0.8009      3610

   micro avg     0.7102    0.7102    0.7102      8544
   macro avg     0.6328    0.6050    0.5818      8544
weighted avg     0.6733    0.7102    0.6683      8544

F1-macro sent:  0.581793645946087
F1-micro sent:  0.7102059925093634
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9281    0.9726    0.9498    124347
           N     0.8264    0.7164    0.7675     14202
           P     0.8883    0.7437    0.8096     25017

   micro avg     0.9154    0.9154    0.9154    163566
   macro avg     0.8809    0.8109    0.8423    163566
weighted avg     0.9132    0.9154    0.9126    163566

F1-macro tok:  0.8423202879181867
F1-micro tok:  0.9153552694325227
**************************************************
dev_cost_sum: 41974.6396484375
dev_cost_avg: 38.12410503945277
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19146.0
dev_accuracy_tok: 0.8999717965591802
dev_label=O_precision_sent: 0.5263157894736842
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08064516129032258
dev_label=N_precision_sent: 0.6542553191489362
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7439516129032259
dev_label=P_precision_sent: 0.694980694980695
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7484407484407485
dev_precision_macro_sent: 0.6251839345344384
dev_recall_macro_sent: 0.5722094885972778
dev_f-score_macro_sent: 0.524345840878099
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9156288370461323
dev_label=O_recall_tok: 0.9663684048133292
dev_label=O_f-score_tok: 0.9403146391257355
dev_label=N_precision_tok: 0.785234899328859
dev_label=N_recall_tok: 0.630048465266559
dev_label=N_f-score_tok: 0.6991335524350165
dev_label=P_precision_tok: 0.8638567698619918
dev_label=P_recall_tok: 0.7210460772104608
dev_label=P_f-score_tok: 0.7860173086713049
dev_precision_macro_tok: 0.8549068354123276
dev_recall_macro_tok: 0.772487649096783
dev_f-score_macro_tok: 0.8084885000773522
dev_precision_micro_tok: 0.8999717965591802
dev_recall_micro_tok: 0.8999717965591802
dev_f-score_micro_tok: 0.8999717965591802
dev_time: 4.928979873657227
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5263    0.0437    0.0806       229
           N     0.6543    0.8621    0.7440       428
           P     0.6950    0.8108    0.7484       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6252    0.5722    0.5243      1101
weighted avg     0.6441    0.6712    0.6078      1101

F1-macro sent:  0.524345840878099
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9156    0.9664    0.9403     16205
           N     0.7852    0.6300    0.6991      1857
           P     0.8639    0.7210    0.7860      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8549    0.7725    0.8085     21274
weighted avg     0.8964    0.9000    0.8960     21274

F1-macro tok:  0.8084885000773522
F1-micro tok:  0.8999717965591802
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42034.555236816406
test0_cost_avg: 38.17852428412026
test0_count_sent: 1101.0
test0_total_correct_sent: 739.0
test0_accuracy_sent: 0.6712079927338783
test0_count_tok: 21274.0
test0_total_correct_tok: 19170.0
test0_accuracy_tok: 0.9010999341919714
test0_label=O_precision_sent: 0.5098039215686274
test0_label=O_recall_sent: 0.11353711790393013
test0_label=O_f-score_sent: 0.1857142857142857
test0_label=N_precision_sent: 0.6377551020408163
test0_label=N_recall_sent: 0.8761682242990654
test0_label=N_f-score_sent: 0.7381889763779528
test0_label=P_precision_sent: 0.7316017316017316
test0_label=P_recall_sent: 0.7612612612612613
test0_label=P_f-score_sent: 0.7461368653421633
test0_precision_macro_sent: 0.6263869184037251
test0_recall_macro_sent: 0.5836555344880856
test0_f-score_macro_sent: 0.556680042478134
test0_precision_micro_sent: 0.6712079927338783
test0_recall_micro_sent: 0.6712079927338783
test0_f-score_micro_sent: 0.6712079927338783
test0_label=O_precision_tok: 0.9080519182173213
test0_label=O_recall_tok: 0.9756865165072508
test0_label=O_f-score_tok: 0.9406550257310289
test0_label=N_precision_tok: 0.8046709129511678
test0_label=N_recall_tok: 0.6122778675282714
test0_label=N_f-score_tok: 0.6954128440366973
test0_label=P_precision_tok: 0.907309105757452
test0_label=P_recall_tok: 0.6917808219178082
test0_label=P_f-score_tok: 0.7850203144320791
test0_precision_macro_tok: 0.8733439789753138
test0_recall_macro_tok: 0.7599150686511101
test0_f-score_macro_tok: 0.8070293947332684
test0_precision_micro_tok: 0.9010999341919714
test0_recall_micro_tok: 0.9010999341919714
test0_f-score_micro_tok: 0.9010999341919714
test0_time: 4.793933391571045
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5098    0.1135    0.1857       229
           N     0.6378    0.8762    0.7382       428
           P     0.7316    0.7613    0.7461       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6264    0.5837    0.5567      1101
weighted avg     0.6490    0.6712    0.6265      1101

F1-macro sent:  0.556680042478134
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9081    0.9757    0.9407     16205
           N     0.8047    0.6123    0.6954      1857
           P     0.9073    0.6918    0.7850      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8733    0.7599    0.8070     21274
weighted avg     0.8989    0.9011    0.8957     21274

F1-macro tok:  0.8070293947332684
F1-micro tok:  0.9010999341919714
**************************************************
test1_cost_sum: 81433.21004104614
test1_cost_avg: 36.84760635341454
test1_count_sent: 2210.0
test1_total_correct_sent: 1535.0
test1_accuracy_sent: 0.6945701357466063
test1_count_tok: 42405.0
test1_total_correct_tok: 37936.0
test1_accuracy_tok: 0.894611484494753
test1_label=O_precision_sent: 0.3425925925925926
test1_label=O_recall_sent: 0.09511568123393316
test1_label=O_f-score_sent: 0.14889336016096577
test1_label=N_precision_sent: 0.6689019279128248
test1_label=N_recall_sent: 0.875
test1_label=N_f-score_sent: 0.7581947743467933
test1_label=P_precision_sent: 0.77007700770077
test1_label=P_recall_sent: 0.77007700770077
test1_label=P_f-score_sent: 0.77007700770077
test1_precision_macro_sent: 0.5938571760687291
test1_recall_macro_sent: 0.580064229644901
test1_f-score_macro_sent: 0.559055047402843
test1_precision_micro_sent: 0.6945701357466063
test1_recall_micro_sent: 0.6945701357466063
test1_f-score_micro_sent: 0.6945701357466063
test1_label=O_precision_tok: 0.8990203682955558
test1_label=O_recall_tok: 0.9779986249140571
test1_label=O_f-score_tok: 0.9368479350966216
test1_label=N_precision_tok: 0.81169757489301
test1_label=N_recall_tok: 0.6053191489361702
test1_label=N_f-score_tok: 0.6934795856185253
test1_label=P_precision_tok: 0.91110183639399
test1_label=P_recall_tok: 0.656837671129833
test1_label=P_f-score_tok: 0.7633534399860128
test1_precision_macro_tok: 0.8739399265275186
test1_recall_macro_tok: 0.7467184816600202
test1_f-score_macro_tok: 0.7978936535670532
test1_precision_micro_tok: 0.894611484494753
test1_recall_micro_tok: 0.894611484494753
test1_f-score_micro_tok: 0.894611484494753
test1_time: 9.998059034347534
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3426    0.0951    0.1489       389
           N     0.6689    0.8750    0.7582       912
           P     0.7701    0.7701    0.7701       909

   micro avg     0.6946    0.6946    0.6946      2210
   macro avg     0.5939    0.5801    0.5591      2210
weighted avg     0.6531    0.6946    0.6558      2210

F1-macro sent:  0.559055047402843
F1-micro sent:  0.6945701357466063
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9780    0.9368     31998
           N     0.8117    0.6053    0.6935      3760
           P     0.9111    0.6568    0.7634      6647

   micro avg     0.8946    0.8946    0.8946     42405
   macro avg     0.8739    0.7467    0.7979     42405
weighted avg     0.8932    0.8946    0.8881     42405

F1-macro tok:  0.7978936535670532
F1-micro tok:  0.894611484494753
**************************************************
