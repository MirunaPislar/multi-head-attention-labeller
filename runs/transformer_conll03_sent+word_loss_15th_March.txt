to_write_filename: runs/transformer_conll03_sent+word_loss.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: binary
path_train: ../mltagger/data/conll03/train_fine-grained_dense_labels.tsv
path_dev: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv
path_test: ../mltagger/data/conll03/testa_fine-grained_dense_labels.tsv:../mltagger/data/conll03/testb_fine-grained_dense_labels.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'0': 0, '1': 1}
{'PER': 4, 'O': 0, 'LOC': 1, 'ORG': 3, 'MISC': 2}
Total number of words: 21890
Total number of chars: 86
Total number of singletons: 7759
Notwork built.
2019-03-16 11:33:41.601810: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-16 11:33:41.689683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 8191:00:00.0
totalMemory: 11.17GiB freeMemory: 8.98GiB
2019-03-16 11:33:41.689728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-16 11:33:42.074806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-16 11:33:42.074859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-16 11:33:42.074868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-16 11:33:42.075086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 8191:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 19871
Parameter count: 8600002.
Parameter count without word embeddings: 2033002.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 62803.899768829346
train_cost_avg: 4.472893652078153
train_count_sent: 14041.0
train_total_correct_sent: 11648.0
train_accuracy_sent: 0.8295705434085892
train_count_tok: 203621.0
train_total_correct_tok: 187049.0
train_accuracy_tok: 0.9186135025365753
train_label=0_precision_sent: 0.6503496503496503
train_label=0_recall_sent: 0.3836369886558955
train_label=0_f-score_sent: 0.48259459459459453
train_label=1_precision_sent: 0.8545233265720081
train_label=1_recall_sent: 0.9461013295005389
train_label=1_f-score_sent: 0.897983544357761
train_precision_macro_sent: 0.7524364884608292
train_recall_macro_sent: 0.6648691590782172
train_f-score_macro_sent: 0.6902890694761777
train_precision_micro_sent: 0.8295705434085892
train_recall_micro_sent: 0.8295705434085892
train_f-score_micro_sent: 0.829570543408589
train_label=O_precision_tok: 0.9498638566527574
train_label=O_recall_tok: 0.9812593614737761
train_label=O_f-score_tok: 0.9653064006659686
train_label=LOC_precision_tok: 0.7056587220353853
train_label=LOC_recall_tok: 0.5816560202482826
train_label=LOC_f-score_tok: 0.6376849894291755
train_label=MISC_precision_tok: 0.6023288637967537
train_label=MISC_recall_tok: 0.37165251469627697
train_label=MISC_f-score_tok: 0.45967416184192805
train_label=ORG_precision_tok: 0.6858844399391789
train_label=ORG_recall_tok: 0.5399501246882793
train_label=ORG_f-score_tok: 0.6042306189652286
train_label=PER_precision_tok: 0.8004230663110458
train_label=PER_recall_tok: 0.7820812365204889
train_label=PER_f-score_tok: 0.7911458570064998
train_precision_macro_tok: 0.7488317897470242
train_recall_macro_tok: 0.6513198515254207
train_f-score_macro_tok: 0.6916084055817601
train_precision_micro_tok: 0.9186135025365753
train_recall_micro_tok: 0.9186135025365753
train_f-score_micro_tok: 0.9186135025365754
train_time: 141.21416926383972
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.6503    0.3836    0.4826      2909
           1     0.8545    0.9461    0.8980     11132

   micro avg     0.8296    0.8296    0.8296     14041
   macro avg     0.7524    0.6649    0.6903     14041
weighted avg     0.8122    0.8296    0.8119     14041

F1-macro sent:  0.6902890694761777
F1-micro sent:  0.829570543408589
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9499    0.9813    0.9653    169578
         LOC     0.7057    0.5817    0.6377      8297
        MISC     0.6023    0.3717    0.4597      4593
         ORG     0.6859    0.5400    0.6042     10025
         PER     0.8004    0.7821    0.7911     11128

   micro avg     0.9186    0.9186    0.9186    203621
   macro avg     0.7488    0.6513    0.6916    203621
weighted avg     0.9109    0.9186    0.9133    203621

F1-macro tok:  0.6916084055817601
F1-micro tok:  0.9186135025365754
**************************************************
dev_cost_sum: 6277.928883552551
dev_cost_avg: 1.9316704257084774
dev_count_sent: 3250.0
dev_total_correct_sent: 3002.0
dev_accuracy_sent: 0.9236923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 49888.0
dev_accuracy_tok: 0.9713017405864257
dev_label=0_precision_sent: 0.8488576449912126
dev_label=0_recall_sent: 0.7488372093023256
dev_label=0_f-score_sent: 0.7957166392092255
dev_label=1_precision_sent: 0.9395747855277882
dev_label=1_recall_sent: 0.9669865642994242
dev_label=1_f-score_sent: 0.9530836171017782
dev_precision_macro_sent: 0.8942162152595003
dev_recall_macro_sent: 0.8579118868008748
dev_f-score_macro_sent: 0.8744001281555018
dev_precision_micro_sent: 0.9236923076923077
dev_recall_micro_sent: 0.9236923076923077
dev_f-score_micro_sent: 0.9236923076923077
dev_label=O_precision_tok: 0.9862490450725745
dev_label=O_recall_tok: 0.996351645267663
dev_label=O_f-score_tok: 0.9912746056121736
dev_label=LOC_precision_tok: 0.9015263417035942
dev_label=LOC_recall_tok: 0.8744030563514804
dev_label=LOC_f-score_tok: 0.8877575757575757
dev_label=MISC_precision_tok: 0.8877005347593583
dev_label=MISC_recall_tok: 0.6545741324921136
dev_label=MISC_f-score_tok: 0.7535179300953246
dev_label=ORG_precision_tok: 0.8609566184649611
dev_label=ORG_recall_tok: 0.739961759082218
dev_label=ORG_f-score_tok: 0.7958868894601543
dev_label=PER_precision_tok: 0.9044398706262864
dev_label=PER_recall_tok: 0.9768180374722134
dev_label=PER_f-score_tok: 0.9392366412213742
dev_precision_macro_tok: 0.9081744821253549
dev_recall_macro_tok: 0.8484217261331377
dev_f-score_macro_tok: 0.8735347284293205
dev_precision_micro_tok: 0.9713017405864257
dev_recall_micro_tok: 0.9713017405864257
dev_f-score_micro_tok: 0.9713017405864257
dev_time: 13.457407236099243
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8489    0.7488    0.7957       645
           1     0.9396    0.9670    0.9531      2605

   micro avg     0.9237    0.9237    0.9237      3250
   macro avg     0.8942    0.8579    0.8744      3250
weighted avg     0.9216    0.9237    0.9219      3250

F1-macro sent:  0.8744001281555018
F1-micro sent:  0.9236923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9862    0.9964    0.9913     42759
         LOC     0.9015    0.8744    0.8878      2094
        MISC     0.8877    0.6546    0.7535      1268
         ORG     0.8610    0.7400    0.7959      2092
         PER     0.9044    0.9768    0.9392      3149

   micro avg     0.9713    0.9713    0.9713     51362
   macro avg     0.9082    0.8484    0.8735     51362
weighted avg     0.9702    0.9713    0.9700     51362

F1-macro tok:  0.8735347284293205
F1-micro tok:  0.9713017405864257
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 26997.788791656494
train_cost_avg: 1.922782479286126
train_count_sent: 14041.0
train_total_correct_sent: 12640.0
train_accuracy_sent: 0.9002207819955843
train_count_tok: 203621.0
train_total_correct_tok: 196320.0
train_accuracy_tok: 0.9641441698056684
train_label=0_precision_sent: 0.7830330330330331
train_label=0_recall_sent: 0.7170849089034033
train_label=0_f-score_sent: 0.7486093665889109
train_label=1_precision_sent: 0.9276610705809968
train_label=1_recall_sent: 0.9480776140855193
train_label=1_f-score_sent: 0.9377582300413169
train_precision_macro_sent: 0.855347051807015
train_recall_macro_sent: 0.8325812614944612
train_f-score_macro_sent: 0.8431837983151138
train_precision_micro_sent: 0.9002207819955843
train_recall_micro_sent: 0.9002207819955843
train_f-score_micro_sent: 0.9002207819955843
train_label=O_precision_tok: 0.9882838894666643
train_label=O_recall_tok: 0.9918680489214403
train_label=O_f-score_tok: 0.99007272545332
train_label=LOC_precision_tok: 0.8461259956553222
train_label=LOC_recall_tok: 0.84500421839219
train_label=LOC_f-score_tok: 0.8455647349695471
train_label=MISC_precision_tok: 0.7697585768742058
train_label=MISC_recall_tok: 0.6594818201611148
train_label=MISC_f-score_tok: 0.7103658536585366
train_label=ORG_precision_tok: 0.7877734614598242
train_label=ORG_recall_tok: 0.7686783042394015
train_label=ORG_f-score_tok: 0.778108749432019
train_label=PER_precision_tok: 0.9080962800875274
train_label=PER_recall_tok: 0.932332854061826
train_label=PER_f-score_tok: 0.9200549815989004
train_precision_macro_tok: 0.8600076407087087
train_recall_macro_tok: 0.8394730491551945
train_f-score_macro_tok: 0.8488334090224647
train_precision_micro_tok: 0.9641441698056684
train_recall_micro_tok: 0.9641441698056684
train_f-score_micro_tok: 0.9641441698056684
train_time: 140.56973266601562
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.7830    0.7171    0.7486      2909
           1     0.9277    0.9481    0.9378     11132

   micro avg     0.9002    0.9002    0.9002     14041
   macro avg     0.8553    0.8326    0.8432     14041
weighted avg     0.8977    0.9002    0.8986     14041

F1-macro sent:  0.8431837983151138
F1-micro sent:  0.9002207819955843
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9883    0.9919    0.9901    169578
         LOC     0.8461    0.8450    0.8456      8297
        MISC     0.7698    0.6595    0.7104      4593
         ORG     0.7878    0.7687    0.7781     10025
         PER     0.9081    0.9323    0.9201     11128

   micro avg     0.9641    0.9641    0.9641    203621
   macro avg     0.8600    0.8395    0.8488    203621
weighted avg     0.9633    0.9641    0.9636    203621

F1-macro tok:  0.8488334090224647
F1-micro tok:  0.9641441698056684
**************************************************
dev_cost_sum: 5317.545258998871
dev_cost_avg: 1.6361677719996526
dev_count_sent: 3250.0
dev_total_correct_sent: 3085.0
dev_accuracy_sent: 0.9492307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50168.0
dev_accuracy_tok: 0.9767532416961956
dev_label=0_precision_sent: 0.8761755485893417
dev_label=0_recall_sent: 0.8666666666666667
dev_label=0_f-score_sent: 0.8713951675759938
dev_label=1_precision_sent: 0.9670750382848392
dev_label=1_recall_sent: 0.9696737044145873
dev_label=1_f-score_sent: 0.968372627947096
dev_precision_macro_sent: 0.9216252934370904
dev_recall_macro_sent: 0.918170185540627
dev_f-score_macro_sent: 0.9198838977615449
dev_precision_micro_sent: 0.9492307692307692
dev_recall_micro_sent: 0.9492307692307692
dev_f-score_micro_sent: 0.9492307692307692
dev_label=O_precision_tok: 0.992669374795723
dev_label=O_recall_tok: 0.9944105334549451
dev_label=O_f-score_tok: 0.9935391912890074
dev_label=LOC_precision_tok: 0.9193468579910935
dev_label=LOC_recall_tok: 0.8872970391595033
dev_label=LOC_f-score_tok: 0.903037667071689
dev_label=MISC_precision_tok: 0.9346195069667739
dev_label=MISC_recall_tok: 0.6876971608832808
dev_label=MISC_f-score_tok: 0.7923671058609724
dev_label=ORG_precision_tok: 0.7962883038411739
dev_label=ORG_recall_tok: 0.8819311663479924
dev_label=ORG_f-score_tok: 0.8369244726695396
dev_label=PER_precision_tok: 0.9435062941357077
dev_label=PER_recall_tok: 0.9758653540806606
dev_label=PER_f-score_tok: 0.9594130502653763
dev_precision_macro_tok: 0.9172860675460944
dev_recall_macro_tok: 0.8854402507852764
dev_f-score_macro_tok: 0.897056297431317
dev_precision_micro_tok: 0.9767532416961956
dev_recall_micro_tok: 0.9767532416961956
dev_f-score_micro_tok: 0.9767532416961956
dev_time: 13.109250783920288
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8762    0.8667    0.8714       645
           1     0.9671    0.9697    0.9684      2605

   micro avg     0.9492    0.9492    0.9492      3250
   macro avg     0.9216    0.9182    0.9199      3250
weighted avg     0.9490    0.9492    0.9491      3250

F1-macro sent:  0.9198838977615449
F1-micro sent:  0.9492307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9927    0.9944    0.9935     42759
         LOC     0.9193    0.8873    0.9030      2094
        MISC     0.9346    0.6877    0.7924      1268
         ORG     0.7963    0.8819    0.8369      2092
         PER     0.9435    0.9759    0.9594      3149

   micro avg     0.9768    0.9768    0.9768     51362
   macro avg     0.9173    0.8854    0.8971     51362
weighted avg     0.9772    0.9768    0.9764     51362

F1-macro tok:  0.897056297431317
F1-micro tok:  0.9767532416961956
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 22277.18678855896
train_cost_avg: 1.586581211349545
train_count_sent: 14041.0
train_total_correct_sent: 12922.0
train_accuracy_sent: 0.9203048215939036
train_count_tok: 203621.0
train_total_correct_tok: 197583.0
train_accuracy_tok: 0.9703468699200967
train_label=0_precision_sent: 0.8182788051209103
train_label=0_recall_sent: 0.790993468545892
train_label=0_f-score_sent: 0.8044048243314106
train_label=1_precision_sent: 0.9458544839255499
train_label=1_recall_sent: 0.954096298957959
train_label=1_f-score_sent: 0.9499575153168462
train_precision_macro_sent: 0.8820666445232301
train_recall_macro_sent: 0.8725448837519255
train_f-score_macro_sent: 0.8771811698241284
train_precision_micro_sent: 0.9203048215939036
train_recall_micro_sent: 0.9203048215939036
train_f-score_micro_sent: 0.9203048215939036
train_label=O_precision_tok: 0.990249378463998
train_label=O_recall_tok: 0.9935486914576184
train_label=O_f-score_tok: 0.9918962913685054
train_label=LOC_precision_tok: 0.8689646889262551
train_label=LOC_recall_tok: 0.8720019284078583
train_label=LOC_f-score_tok: 0.8704806593274379
train_label=MISC_precision_tok: 0.8047381546134663
train_label=MISC_recall_tok: 0.7025908991944263
train_label=MISC_f-score_tok: 0.7502034174125305
train_label=ORG_precision_tok: 0.8287985325588505
train_label=ORG_recall_tok: 0.8112718204488778
train_label=ORG_f-score_tok: 0.8199415263635448
train_label=PER_precision_tok: 0.9271780386618413
train_label=PER_recall_tok: 0.9439252336448598
train_label=PER_f-score_tok: 0.9354766887830075
train_precision_macro_tok: 0.8839857586448823
train_recall_macro_tok: 0.8646677146307281
train_f-score_macro_tok: 0.8735997166510053
train_precision_micro_tok: 0.9703468699200967
train_recall_micro_tok: 0.9703468699200967
train_f-score_micro_tok: 0.9703468699200967
train_time: 140.22009706497192
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8183    0.7910    0.8044      2909
           1     0.9459    0.9541    0.9500     11132

   micro avg     0.9203    0.9203    0.9203     14041
   macro avg     0.8821    0.8725    0.8772     14041
weighted avg     0.9194    0.9203    0.9198     14041

F1-macro sent:  0.8771811698241284
F1-micro sent:  0.9203048215939036
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9902    0.9935    0.9919    169578
         LOC     0.8690    0.8720    0.8705      8297
        MISC     0.8047    0.7026    0.7502      4593
         ORG     0.8288    0.8113    0.8199     10025
         PER     0.9272    0.9439    0.9355     11128

   micro avg     0.9703    0.9703    0.9703    203621
   macro avg     0.8840    0.8647    0.8736    203621
weighted avg     0.9697    0.9703    0.9699    203621

F1-macro tok:  0.8735997166510053
F1-micro tok:  0.9703468699200967
**************************************************
dev_cost_sum: 4678.093363761902
dev_cost_avg: 1.4394133426959699
dev_count_sent: 3250.0
dev_total_correct_sent: 3083.0
dev_accuracy_sent: 0.9486153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50351.0
dev_accuracy_tok: 0.9803161870643666
dev_label=0_precision_sent: 0.8292011019283747
dev_label=0_recall_sent: 0.9333333333333333
dev_label=0_f-score_sent: 0.8781911013858498
dev_label=1_precision_sent: 0.9829635499207607
dev_label=1_recall_sent: 0.9523992322456813
dev_label=1_f-score_sent: 0.9674400467927472
dev_precision_macro_sent: 0.9060823259245677
dev_recall_macro_sent: 0.9428662827895073
dev_f-score_macro_sent: 0.9228155740892985
dev_precision_micro_sent: 0.9486153846153846
dev_recall_micro_sent: 0.9486153846153846
dev_f-score_micro_sent: 0.9486153846153846
dev_label=O_precision_tok: 0.9916009399502106
dev_label=O_recall_tok: 0.9967492223859304
dev_label=O_f-score_tok: 0.9941684161418242
dev_label=LOC_precision_tok: 0.9179245283018868
dev_label=LOC_recall_tok: 0.9293218720152817
dev_label=LOC_f-score_tok: 0.9235880398671096
dev_label=MISC_precision_tok: 0.895264116575592
dev_label=MISC_recall_tok: 0.7752365930599369
dev_label=MISC_f-score_tok: 0.830938292476754
dev_label=ORG_precision_tok: 0.8914050437467833
dev_label=ORG_recall_tok: 0.8279158699808795
dev_label=ORG_f-score_tok: 0.8584882280049566
dev_label=PER_precision_tok: 0.953416149068323
dev_label=PER_recall_tok: 0.9749126706891077
dev_label=PER_f-score_tok: 0.9640445909875962
dev_precision_macro_tok: 0.9299221555285591
dev_recall_macro_tok: 0.9008272456262272
dev_f-score_macro_tok: 0.9142455134956482
dev_precision_micro_tok: 0.9803161870643666
dev_recall_micro_tok: 0.9803161870643666
dev_f-score_micro_tok: 0.9803161870643666
dev_time: 13.02244758605957
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8292    0.9333    0.8782       645
           1     0.9830    0.9524    0.9674      2605

   micro avg     0.9486    0.9486    0.9486      3250
   macro avg     0.9061    0.9429    0.9228      3250
weighted avg     0.9524    0.9486    0.9497      3250

F1-macro sent:  0.9228155740892985
F1-micro sent:  0.9486153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9916    0.9967    0.9942     42759
         LOC     0.9179    0.9293    0.9236      2094
        MISC     0.8953    0.7752    0.8309      1268
         ORG     0.8914    0.8279    0.8585      2092
         PER     0.9534    0.9749    0.9640      3149

   micro avg     0.9803    0.9803    0.9803     51362
   macro avg     0.9299    0.9008    0.9142     51362
weighted avg     0.9798    0.9803    0.9799     51362

F1-macro tok:  0.9142455134956482
F1-micro tok:  0.9803161870643666
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 19283.080028533936
train_cost_avg: 1.3733409321653682
train_count_sent: 14041.0
train_total_correct_sent: 13157.0
train_accuracy_sent: 0.9370415212591696
train_count_tok: 203621.0
train_total_correct_tok: 198341.0
train_accuracy_tok: 0.9740694722057155
train_label=0_precision_sent: 0.8407943453382699
train_label=0_recall_sent: 0.8587143348229632
train_label=0_f-score_sent: 0.8496598639455782
train_label=1_precision_sent: 0.9628726287262873
train_label=1_recall_sent: 0.9575098814229249
train_label=1_f-score_sent: 0.9601837672281777
train_precision_macro_sent: 0.9018334870322786
train_recall_macro_sent: 0.9081121081229441
train_f-score_macro_sent: 0.9049218155868779
train_precision_micro_sent: 0.9370415212591696
train_recall_micro_sent: 0.9370415212591696
train_f-score_micro_sent: 0.9370415212591696
train_label=O_precision_tok: 0.9913977103680228
train_label=O_recall_tok: 0.9942799183856397
train_label=O_f-score_tok: 0.9928367226165837
train_label=LOC_precision_tok: 0.8888221153846154
train_label=LOC_recall_tok: 0.8912860069904784
train_label=LOC_f-score_tok: 0.8900523560209425
train_label=MISC_precision_tok: 0.8157578669228921
train_label=MISC_recall_tok: 0.7393860222077073
train_label=MISC_f-score_tok: 0.7756966651439011
train_label=ORG_precision_tok: 0.8562365701422285
train_label=ORG_recall_tok: 0.834713216957606
train_label=ORG_f-score_tok: 0.8453379129204971
train_label=PER_precision_tok: 0.9362493359305826
train_label=PER_recall_tok: 0.950215672178289
train_label=PER_f-score_tok: 0.9431808045669431
train_precision_macro_tok: 0.8976927197496682
train_recall_macro_tok: 0.8819761673439441
train_f-score_macro_tok: 0.8894208922537736
train_precision_micro_tok: 0.9740694722057155
train_recall_micro_tok: 0.9740694722057155
train_f-score_micro_tok: 0.9740694722057155
train_time: 140.33809661865234
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8408    0.8587    0.8497      2909
           1     0.9629    0.9575    0.9602     11132

   micro avg     0.9370    0.9370    0.9370     14041
   macro avg     0.9018    0.9081    0.9049     14041
weighted avg     0.9376    0.9370    0.9373     14041

F1-macro sent:  0.9049218155868779
F1-micro sent:  0.9370415212591696
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9914    0.9943    0.9928    169578
         LOC     0.8888    0.8913    0.8901      8297
        MISC     0.8158    0.7394    0.7757      4593
         ORG     0.8562    0.8347    0.8453     10025
         PER     0.9362    0.9502    0.9432     11128

   micro avg     0.9741    0.9741    0.9741    203621
   macro avg     0.8977    0.8820    0.8894    203621
weighted avg     0.9736    0.9741    0.9738    203621

F1-macro tok:  0.8894208922537736
F1-micro tok:  0.9740694722057155
**************************************************
dev_cost_sum: 4077.4555819034576
dev_cost_avg: 1.2546017175087563
dev_count_sent: 3250.0
dev_total_correct_sent: 3135.0
dev_accuracy_sent: 0.9646153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50440.0
dev_accuracy_tok: 0.9820489856314006
dev_label=0_precision_sent: 0.9358552631578947
dev_label=0_recall_sent: 0.8821705426356589
dev_label=0_f-score_sent: 0.9082202713487628
dev_label=1_precision_sent: 0.9712339137017411
dev_label=1_recall_sent: 0.9850287907869482
dev_label=1_f-score_sent: 0.9780827139317705
dev_precision_macro_sent: 0.9535445884298179
dev_recall_macro_sent: 0.9335996667113036
dev_f-score_macro_sent: 0.9431514926402667
dev_precision_micro_sent: 0.9646153846153847
dev_recall_micro_sent: 0.9646153846153847
dev_f-score_micro_sent: 0.9646153846153847
dev_label=O_precision_tok: 0.9913542659260465
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9944513090714103
dev_label=LOC_precision_tok: 0.9212121212121213
dev_label=LOC_recall_tok: 0.9436485195797517
dev_label=LOC_f-score_tok: 0.9322953526775183
dev_label=MISC_precision_tok: 0.8824546240276577
dev_label=MISC_recall_tok: 0.805205047318612
dev_label=MISC_f-score_tok: 0.842061855670103
dev_label=ORG_precision_tok: 0.9228723404255319
dev_label=ORG_recall_tok: 0.8293499043977055
dev_label=ORG_f-score_tok: 0.8736153071500503
dev_label=PER_precision_tok: 0.9682841738027276
dev_label=PER_recall_tok: 0.9695141314703081
dev_label=PER_f-score_tok: 0.9688987622976833
dev_precision_macro_tok: 0.9372355050788169
dev_recall_macro_tok: 0.9090570732556305
dev_f-score_macro_tok: 0.922264517373353
dev_precision_micro_tok: 0.9820489856314006
dev_recall_micro_tok: 0.9820489856314006
dev_f-score_micro_tok: 0.9820489856314006
dev_time: 12.994546890258789
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9359    0.8822    0.9082       645
           1     0.9712    0.9850    0.9781      2605

   micro avg     0.9646    0.9646    0.9646      3250
   macro avg     0.9535    0.9336    0.9432      3250
weighted avg     0.9642    0.9646    0.9642      3250

F1-macro sent:  0.9431514926402667
F1-micro sent:  0.9646153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9914    0.9976    0.9945     42759
         LOC     0.9212    0.9436    0.9323      2094
        MISC     0.8825    0.8052    0.8421      1268
         ORG     0.9229    0.8293    0.8736      2092
         PER     0.9683    0.9695    0.9689      3149

   micro avg     0.9820    0.9820    0.9820     51362
   macro avg     0.9372    0.9091    0.9223     51362
weighted avg     0.9816    0.9820    0.9817     51362

F1-macro tok:  0.922264517373353
F1-micro tok:  0.9820489856314006
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 17055.62499332428
train_cost_avg: 1.2147015877305234
train_count_sent: 14041.0
train_total_correct_sent: 13272.0
train_accuracy_sent: 0.9452318210953636
train_count_tok: 203621.0
train_total_correct_tok: 198941.0
train_accuracy_tok: 0.9770161230914297
train_label=0_precision_sent: 0.8646898432174506
train_label=0_recall_sent: 0.8721210037813681
train_label=0_f-score_sent: 0.8683895259284613
train_label=1_precision_sent: 0.9665076078148915
train_label=1_recall_sent: 0.9643370463528567
train_label=1_f-score_sent: 0.9654211070641666
train_precision_macro_sent: 0.915598725516171
train_recall_macro_sent: 0.9182290250671123
train_f-score_macro_sent: 0.9169053164963139
train_precision_micro_sent: 0.9452318210953636
train_recall_micro_sent: 0.9452318210953636
train_f-score_micro_sent: 0.9452318210953636
train_label=O_precision_tok: 0.9920849137043898
train_label=O_recall_tok: 0.9948755145124957
train_label=O_f-score_tok: 0.9934782544687942
train_label=LOC_precision_tok: 0.9022275737507526
train_label=LOC_recall_tok: 0.9030975051223333
train_label=LOC_f-score_tok: 0.9026623298397783
train_label=MISC_precision_tok: 0.8432534977472137
train_label=MISC_recall_tok: 0.7742216416285652
train_label=MISC_f-score_tok: 0.8072644721906925
train_label=ORG_precision_tok: 0.8695740778479722
train_label=ORG_recall_tok: 0.8512718204488778
train_label=ORG_f-score_tok: 0.8603256212510713
train_label=PER_precision_tok: 0.9482635796972395
train_label=PER_recall_tok: 0.9569554277498202
train_label=PER_f-score_tok: 0.9525896770730835
train_precision_macro_tok: 0.9110807285495136
train_recall_macro_tok: 0.8960843818924186
train_f-score_macro_tok: 0.903264070964684
train_precision_micro_tok: 0.9770161230914297
train_recall_micro_tok: 0.9770161230914297
train_f-score_micro_tok: 0.9770161230914297
train_time: 139.85940504074097
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8647    0.8721    0.8684      2909
           1     0.9665    0.9643    0.9654     11132

   micro avg     0.9452    0.9452    0.9452     14041
   macro avg     0.9156    0.9182    0.9169     14041
weighted avg     0.9454    0.9452    0.9453     14041

F1-macro sent:  0.9169053164963139
F1-micro sent:  0.9452318210953636
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9921    0.9949    0.9935    169578
         LOC     0.9022    0.9031    0.9027      8297
        MISC     0.8433    0.7742    0.8073      4593
         ORG     0.8696    0.8513    0.8603     10025
         PER     0.9483    0.9570    0.9526     11128

   micro avg     0.9770    0.9770    0.9770    203621
   macro avg     0.9111    0.8961    0.9033    203621
weighted avg     0.9766    0.9770    0.9768    203621

F1-macro tok:  0.903264070964684
F1-micro tok:  0.9770161230914297
**************************************************
dev_cost_sum: 3880.2508454322815
dev_cost_avg: 1.1939233370560867
dev_count_sent: 3250.0
dev_total_correct_sent: 3139.0
dev_accuracy_sent: 0.9658461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50476.0
dev_accuracy_tok: 0.9827498929169425
dev_label=0_precision_sent: 0.9033232628398792
dev_label=0_recall_sent: 0.9271317829457364
dev_label=0_f-score_sent: 0.9150726855394034
dev_label=1_precision_sent: 0.981839258114374
dev_label=1_recall_sent: 0.9754318618042227
dev_label=1_f-score_sent: 0.9786250722125939
dev_precision_macro_sent: 0.9425812604771266
dev_recall_macro_sent: 0.9512818223749795
dev_f-score_macro_sent: 0.9468488788759986
dev_precision_micro_sent: 0.9658461538461538
dev_recall_micro_sent: 0.9658461538461538
dev_f-score_micro_sent: 0.9658461538461538
dev_label=O_precision_tok: 0.9942591771487247
dev_label=O_recall_tok: 0.9963984190462827
dev_label=O_f-score_tok: 0.9953276486391778
dev_label=LOC_precision_tok: 0.9347308242020009
dev_label=LOC_recall_tok: 0.9369627507163324
dev_label=LOC_f-score_tok: 0.9358454567135702
dev_label=MISC_precision_tok: 0.8285498489425982
dev_label=MISC_recall_tok: 0.8651419558359621
dev_label=MISC_f-score_tok: 0.8464506172839505
dev_label=ORG_precision_tok: 0.9392778993435449
dev_label=ORG_recall_tok: 0.8207456978967496
dev_label=ORG_f-score_tok: 0.8760204081632654
dev_label=PER_precision_tok: 0.9493865030674846
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9658293025432984
dev_precision_macro_tok: 0.9292408505408705
dev_recall_macro_tok: 0.9204201044894751
dev_f-score_macro_tok: 0.9238946866686526
dev_precision_micro_tok: 0.9827498929169425
dev_recall_micro_tok: 0.9827498929169425
dev_f-score_micro_tok: 0.9827498929169425
dev_time: 13.059005737304688
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9033    0.9271    0.9151       645
           1     0.9818    0.9754    0.9786      2605

   micro avg     0.9658    0.9658    0.9658      3250
   macro avg     0.9426    0.9513    0.9468      3250
weighted avg     0.9663    0.9658    0.9660      3250

F1-macro sent:  0.9468488788759986
F1-micro sent:  0.9658461538461538
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9943    0.9964    0.9953     42759
         LOC     0.9347    0.9370    0.9358      2094
        MISC     0.8285    0.8651    0.8465      1268
         ORG     0.9393    0.8207    0.8760      2092
         PER     0.9494    0.9829    0.9658      3149

   micro avg     0.9827    0.9827    0.9827     51362
   macro avg     0.9292    0.9204    0.9239     51362
weighted avg     0.9828    0.9827    0.9826     51362

F1-macro tok:  0.9238946866686526
F1-micro tok:  0.9827498929169425
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 15422.118467330933
train_cost_avg: 1.0983632552760438
train_count_sent: 14041.0
train_total_correct_sent: 13415.0
train_accuracy_sent: 0.9554162808916744
train_count_tok: 203621.0
train_total_correct_tok: 199368.0
train_accuracy_tok: 0.9791131563050962
train_label=0_precision_sent: 0.8926728586171311
train_label=0_recall_sent: 0.892059126847714
train_label=0_f-score_sent: 0.8923658872077029
train_label=1_precision_sent: 0.9717980959223999
train_label=1_recall_sent: 0.9719726913402803
train_label=1_f-score_sent: 0.9718853857899937
train_precision_macro_sent: 0.9322354772697654
train_recall_macro_sent: 0.9320159090939972
train_f-score_macro_sent: 0.9321256364988484
train_precision_micro_sent: 0.9554162808916744
train_recall_micro_sent: 0.9554162808916744
train_f-score_micro_sent: 0.9554162808916744
train_label=O_precision_tok: 0.9929579122004024
train_label=O_recall_tok: 0.9953000978900565
train_label=O_f-score_tok: 0.9941276254874013
train_label=LOC_precision_tok: 0.9110440555220277
train_label=LOC_recall_tok: 0.9097264071351091
train_label=LOC_f-score_tok: 0.9103847545531298
train_label=MISC_precision_tok: 0.8554981203007519
train_label=MISC_recall_tok: 0.7927280644458959
train_label=MISC_f-score_tok: 0.8229178438241609
train_label=ORG_precision_tok: 0.8814213197969543
train_label=ORG_recall_tok: 0.8660349127182045
train_label=ORG_f-score_tok: 0.8736603773584906
train_label=PER_precision_tok: 0.9523640241734803
train_label=PER_recall_tok: 0.9629762760603882
train_label=PER_f-score_tok: 0.9576407506702412
train_precision_macro_tok: 0.9186570863987233
train_recall_macro_tok: 0.9053531516499309
train_f-score_macro_tok: 0.9117462703786847
train_precision_micro_tok: 0.9791131563050962
train_recall_micro_tok: 0.9791131563050962
train_f-score_micro_tok: 0.9791131563050962
train_time: 114.12906312942505
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8927    0.8921    0.8924      2909
           1     0.9718    0.9720    0.9719     11132

   micro avg     0.9554    0.9554    0.9554     14041
   macro avg     0.9322    0.9320    0.9321     14041
weighted avg     0.9554    0.9554    0.9554     14041

F1-macro sent:  0.9321256364988484
F1-micro sent:  0.9554162808916744
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9930    0.9953    0.9941    169578
         LOC     0.9110    0.9097    0.9104      8297
        MISC     0.8555    0.7927    0.8229      4593
         ORG     0.8814    0.8660    0.8737     10025
         PER     0.9524    0.9630    0.9576     11128

   micro avg     0.9791    0.9791    0.9791    203621
   macro avg     0.9187    0.9054    0.9117    203621
weighted avg     0.9788    0.9791    0.9789    203621

F1-macro tok:  0.9117462703786847
F1-micro tok:  0.9791131563050962
**************************************************
dev_cost_sum: 3386.6052074432373
dev_cost_avg: 1.042032371520996
dev_count_sent: 3250.0
dev_total_correct_sent: 3148.0
dev_accuracy_sent: 0.9686153846153847
dev_count_tok: 51362.0
dev_total_correct_tok: 50583.0
dev_accuracy_tok: 0.9848331451267474
dev_label=0_precision_sent: 0.9070464767616192
dev_label=0_recall_sent: 0.937984496124031
dev_label=0_f-score_sent: 0.9222560975609756
dev_label=1_precision_sent: 0.9845141308555942
dev_label=1_recall_sent: 0.9761996161228407
dev_label=1_f-score_sent: 0.9803392444101774
dev_precision_macro_sent: 0.9457803038086068
dev_recall_macro_sent: 0.9570920561234358
dev_f-score_macro_sent: 0.9512976709855765
dev_precision_micro_sent: 0.9686153846153847
dev_recall_micro_sent: 0.9686153846153847
dev_f-score_micro_sent: 0.9686153846153847
dev_label=O_precision_tok: 0.9935240402534476
dev_label=O_recall_tok: 0.9974508290652261
dev_label=O_f-score_tok: 0.9954835622673217
dev_label=LOC_precision_tok: 0.9507959479015919
dev_label=LOC_recall_tok: 0.9412607449856734
dev_label=LOC_f-score_tok: 0.9460043196544277
dev_label=MISC_precision_tok: 0.9128521126760564
dev_label=MISC_recall_tok: 0.8178233438485805
dev_label=MISC_f-score_tok: 0.8627287853577371
dev_label=ORG_precision_tok: 0.9215686274509803
dev_label=ORG_recall_tok: 0.8761950286806883
dev_label=ORG_f-score_tok: 0.8983092379318793
dev_label=PER_precision_tok: 0.9555006180469716
dev_label=PER_recall_tok: 0.9818990155604954
dev_label=PER_f-score_tok: 0.9685199686765857
dev_precision_macro_tok: 0.9468482692658096
dev_recall_macro_tok: 0.9229257924281328
dev_f-score_macro_tok: 0.9342091747775904
dev_precision_micro_tok: 0.9848331451267474
dev_recall_micro_tok: 0.9848331451267474
dev_f-score_micro_tok: 0.9848331451267474
dev_time: 5.835313320159912
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9070    0.9380    0.9223       645
           1     0.9845    0.9762    0.9803      2605

   micro avg     0.9686    0.9686    0.9686      3250
   macro avg     0.9458    0.9571    0.9513      3250
weighted avg     0.9691    0.9686    0.9688      3250

F1-macro sent:  0.9512976709855765
F1-micro sent:  0.9686153846153847
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9935    0.9975    0.9955     42759
         LOC     0.9508    0.9413    0.9460      2094
        MISC     0.9129    0.8178    0.8627      1268
         ORG     0.9216    0.8762    0.8983      2092
         PER     0.9555    0.9819    0.9685      3149

   micro avg     0.9848    0.9848    0.9848     51362
   macro avg     0.9468    0.9229    0.9342     51362
weighted avg     0.9845    0.9848    0.9846     51362

F1-macro tok:  0.9342091747775904
F1-micro tok:  0.9848331451267474
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 14060.055993556976
train_cost_avg: 1.0013571678339845
train_count_sent: 14041.0
train_total_correct_sent: 13436.0
train_accuracy_sent: 0.956911900861762
train_count_tok: 203621.0
train_total_correct_tok: 199762.0
train_accuracy_tok: 0.9810481237200486
train_label=0_precision_sent: 0.8923705722070845
train_label=0_recall_sent: 0.9006531454107941
train_label=0_f-score_sent: 0.8964927288280582
train_label=1_precision_sent: 0.9739756866276452
train_label=1_recall_sent: 0.9716133668702839
train_label=1_f-score_sent: 0.9727930925934254
train_precision_macro_sent: 0.9331731294173649
train_recall_macro_sent: 0.936133256140539
train_f-score_macro_sent: 0.9346429107107418
train_precision_micro_sent: 0.956911900861762
train_recall_micro_sent: 0.956911900861762
train_f-score_micro_sent: 0.956911900861762
train_label=O_precision_tok: 0.9936201142964763
train_label=O_recall_tok: 0.995559565509677
train_label=O_f-score_tok: 0.9945888944201103
train_label=LOC_precision_tok: 0.9221202608065685
train_label=LOC_recall_tok: 0.9204531758466916
train_label=LOC_f-score_tok: 0.9212859641715424
train_label=MISC_precision_tok: 0.8670506912442396
train_label=MISC_recall_tok: 0.8192902242543
train_label=MISC_f-score_tok: 0.8424941229150341
train_label=ORG_precision_tok: 0.8906882591093117
train_label=ORG_recall_tok: 0.8778054862842892
train_label=ORG_f-score_tok: 0.8841999497613665
train_label=PER_precision_tok: 0.9578055307760928
train_label=PER_recall_tok: 0.964863407620417
train_label=PER_f-score_tok: 0.9613215149073329
train_precision_macro_tok: 0.9262569712465378
train_recall_macro_tok: 0.915594371903075
train_f-score_macro_tok: 0.9207780892350772
train_precision_micro_tok: 0.9810481237200486
train_recall_micro_tok: 0.9810481237200486
train_f-score_micro_tok: 0.9810481237200486
train_time: 77.21242880821228
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8924    0.9007    0.8965      2909
           1     0.9740    0.9716    0.9728     11132

   micro avg     0.9569    0.9569    0.9569     14041
   macro avg     0.9332    0.9361    0.9346     14041
weighted avg     0.9571    0.9569    0.9570     14041

F1-macro sent:  0.9346429107107418
F1-micro sent:  0.956911900861762
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9936    0.9956    0.9946    169578
         LOC     0.9221    0.9205    0.9213      8297
        MISC     0.8671    0.8193    0.8425      4593
         ORG     0.8907    0.8778    0.8842     10025
         PER     0.9578    0.9649    0.9613     11128

   micro avg     0.9810    0.9810    0.9810    203621
   macro avg     0.9263    0.9156    0.9208    203621
weighted avg     0.9808    0.9810    0.9809    203621

F1-macro tok:  0.9207780892350772
F1-micro tok:  0.9810481237200486
**************************************************
dev_cost_sum: 3559.1748464107513
dev_cost_avg: 1.0951307219725388
dev_count_sent: 3250.0
dev_total_correct_sent: 3184.0
dev_accuracy_sent: 0.9796923076923076
dev_count_tok: 51362.0
dev_total_correct_tok: 50533.0
dev_accuracy_tok: 0.983859662785717
dev_label=0_precision_sent: 0.9646869983948636
dev_label=0_recall_sent: 0.931782945736434
dev_label=0_f-score_sent: 0.94794952681388
dev_label=1_precision_sent: 0.9832508564902931
dev_label=1_recall_sent: 0.9915547024952015
dev_label=1_f-score_sent: 0.9873853211009174
dev_precision_macro_sent: 0.9739689274425783
dev_recall_macro_sent: 0.9616688241158178
dev_f-score_macro_sent: 0.9676674239573987
dev_precision_micro_sent: 0.9796923076923076
dev_recall_micro_sent: 0.9796923076923076
dev_f-score_micro_sent: 0.9796923076923076
dev_label=O_precision_tok: 0.9946807269673145
dev_label=O_recall_tok: 0.9971000257255782
dev_label=O_f-score_tok: 0.9958889070565975
dev_label=LOC_precision_tok: 0.9746031746031746
dev_label=LOC_recall_tok: 0.8796561604584527
dev_label=LOC_f-score_tok: 0.924698795180723
dev_label=MISC_precision_tok: 0.9213085764809903
dev_label=MISC_recall_tok: 0.8217665615141956
dev_label=MISC_f-score_tok: 0.8686952897040433
dev_label=ORG_precision_tok: 0.8342612419700214
dev_label=ORG_recall_tok: 0.9311663479923518
dev_label=ORG_f-score_tok: 0.8800542127851818
dev_label=PER_precision_tok: 0.9755011135857461
dev_label=PER_recall_tok: 0.9736424261670371
dev_label=PER_f-score_tok: 0.9745708836617928
dev_precision_macro_tok: 0.9400709667214493
dev_recall_macro_tok: 0.9206663043715231
dev_f-score_macro_tok: 0.9287816176776676
dev_precision_micro_tok: 0.983859662785717
dev_recall_micro_tok: 0.983859662785717
dev_f-score_micro_tok: 0.983859662785717
dev_time: 5.831260442733765
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9647    0.9318    0.9479       645
           1     0.9833    0.9916    0.9874      2605

   micro avg     0.9797    0.9797    0.9797      3250
   macro avg     0.9740    0.9617    0.9677      3250
weighted avg     0.9796    0.9797    0.9796      3250

F1-macro sent:  0.9676674239573987
F1-micro sent:  0.9796923076923076
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9971    0.9959     42759
         LOC     0.9746    0.8797    0.9247      2094
        MISC     0.9213    0.8218    0.8687      1268
         ORG     0.8343    0.9312    0.8801      2092
         PER     0.9755    0.9736    0.9746      3149

   micro avg     0.9839    0.9839    0.9839     51362
   macro avg     0.9401    0.9207    0.9288     51362
weighted avg     0.9843    0.9839    0.9838     51362

F1-macro tok:  0.9287816176776676
F1-micro tok:  0.983859662785717
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 12877.765362739563
train_cost_avg: 0.917154430791223
train_count_sent: 14041.0
train_total_correct_sent: 13527.0
train_accuracy_sent: 0.9633929207321416
train_count_tok: 203621.0
train_total_correct_tok: 200048.0
train_accuracy_tok: 0.9824526939755722
train_label=0_precision_sent: 0.9066213921901528
train_label=0_recall_sent: 0.9178411825369542
train_label=0_f-score_sent: 0.9121967885206695
train_label=1_precision_sent: 0.9784607065609229
train_label=1_recall_sent: 0.9752964426877471
train_label=1_f-score_sent: 0.9768760122368184
train_precision_macro_sent: 0.9425410493755378
train_recall_macro_sent: 0.9465688126123506
train_f-score_macro_sent: 0.944536400378744
train_precision_micro_sent: 0.9633929207321416
train_recall_micro_sent: 0.9633929207321416
train_f-score_micro_sent: 0.9633929207321416
train_label=O_precision_tok: 0.9941898796769408
train_label=O_recall_tok: 0.9959369729563976
train_label=O_f-score_tok: 0.9950626594472299
train_label=LOC_precision_tok: 0.9248701534001691
train_label=LOC_recall_tok: 0.9228636856695192
train_label=LOC_f-score_tok: 0.9238658301158301
train_label=MISC_precision_tok: 0.8723210214318285
train_label=MISC_recall_tok: 0.8330067494012627
train_label=MISC_f-score_tok: 0.8522107138879608
train_label=ORG_precision_tok: 0.9010711398544866
train_label=ORG_recall_tok: 0.8894763092269327
train_label=ORG_f-score_tok: 0.895236182922544
train_label=PER_precision_tok: 0.9619992846924177
train_label=PER_recall_tok: 0.9668404025880661
train_label=PER_f-score_tok: 0.9644137683757619
train_precision_macro_tok: 0.9308902958111686
train_recall_macro_tok: 0.9216248239684356
train_f-score_macro_tok: 0.9261578309498653
train_precision_micro_tok: 0.9824526939755722
train_recall_micro_tok: 0.9824526939755722
train_f-score_micro_tok: 0.9824526939755722
train_time: 77.04734539985657
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9066    0.9178    0.9122      2909
           1     0.9785    0.9753    0.9769     11132

   micro avg     0.9634    0.9634    0.9634     14041
   macro avg     0.9425    0.9466    0.9445     14041
weighted avg     0.9636    0.9634    0.9635     14041

F1-macro sent:  0.944536400378744
F1-micro sent:  0.9633929207321416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9942    0.9959    0.9951    169578
         LOC     0.9249    0.9229    0.9239      8297
        MISC     0.8723    0.8330    0.8522      4593
         ORG     0.9011    0.8895    0.8952     10025
         PER     0.9620    0.9668    0.9644     11128

   micro avg     0.9825    0.9825    0.9825    203621
   macro avg     0.9309    0.9216    0.9262    203621
weighted avg     0.9823    0.9825    0.9823    203621

F1-macro tok:  0.9261578309498653
F1-micro tok:  0.9824526939755722
**************************************************
dev_cost_sum: 3334.9684705734253
dev_cost_avg: 1.0261441447918231
dev_count_sent: 3250.0
dev_total_correct_sent: 3099.0
dev_accuracy_sent: 0.9535384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50620.0
dev_accuracy_tok: 0.9855535220591098
dev_label=0_precision_sent: 0.9959839357429718
dev_label=0_recall_sent: 0.7689922480620155
dev_label=0_f-score_sent: 0.8678915135608049
dev_label=1_precision_sent: 0.9458575581395349
dev_label=1_recall_sent: 0.9992322456813819
dev_label=1_f-score_sent: 0.9718125816688445
dev_precision_macro_sent: 0.9709207469412533
dev_recall_macro_sent: 0.8841122468716986
dev_f-score_macro_sent: 0.9198520476148246
dev_precision_micro_sent: 0.9535384615384616
dev_recall_micro_sent: 0.9535384615384616
dev_f-score_micro_sent: 0.9535384615384616
dev_label=O_precision_tok: 0.9955367574893677
dev_label=O_recall_tok: 0.996351645267663
dev_label=O_f-score_tok: 0.9959440346919454
dev_label=LOC_precision_tok: 0.9351073762838469
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9457034938621341
dev_label=MISC_precision_tok: 0.9057724957555179
dev_label=MISC_recall_tok: 0.8414826498422713
dev_label=MISC_f-score_tok: 0.8724448078495504
dev_label=ORG_precision_tok: 0.9288597376387487
dev_label=ORG_recall_tok: 0.880019120458891
dev_label=ORG_f-score_tok: 0.9037800687285223
dev_label=PER_precision_tok: 0.9510104102878139
dev_label=PER_recall_tok: 0.9863448713877422
dev_label=PER_f-score_tok: 0.9683554169914265
dev_precision_macro_tok: 0.943257355491059
dev_recall_macro_tok: 0.9321481578688685
dev_f-score_macro_tok: 0.9372455644247157
dev_precision_micro_tok: 0.9855535220591098
dev_recall_micro_tok: 0.9855535220591098
dev_f-score_micro_tok: 0.9855535220591098
dev_time: 5.782463788986206
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9960    0.7690    0.8679       645
           1     0.9459    0.9992    0.9718      2605

   micro avg     0.9535    0.9535    0.9535      3250
   macro avg     0.9709    0.8841    0.9199      3250
weighted avg     0.9558    0.9535    0.9512      3250

F1-macro sent:  0.9198520476148246
F1-micro sent:  0.9535384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9964    0.9959     42759
         LOC     0.9351    0.9565    0.9457      2094
        MISC     0.9058    0.8415    0.8724      1268
         ORG     0.9289    0.8800    0.9038      2092
         PER     0.9510    0.9863    0.9684      3149

   micro avg     0.9856    0.9856    0.9856     51362
   macro avg     0.9433    0.9321    0.9372     51362
weighted avg     0.9854    0.9856    0.9854     51362

F1-macro tok:  0.9372455644247157
F1-micro tok:  0.9855535220591098
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 11712.889958620071
train_cost_avg: 0.8341920061690814
train_count_sent: 14041.0
train_total_correct_sent: 13552.0
train_accuracy_sent: 0.9651734206965316
train_count_tok: 203621.0
train_total_correct_tok: 200379.0
train_accuracy_tok: 0.9840782630475245
train_label=0_precision_sent: 0.9138166894664843
train_label=0_recall_sent: 0.9185287040220007
train_label=0_f-score_sent: 0.9161666380936053
train_label=1_precision_sent: 0.9786812989115768
train_label=1_recall_sent: 0.9773625583902263
train_label=1_f-score_sent: 0.9780214841116456
train_precision_macro_sent: 0.9462489941890306
train_recall_macro_sent: 0.9479456312061135
train_f-score_macro_sent: 0.9470940611026255
train_precision_micro_sent: 0.9651734206965316
train_recall_micro_sent: 0.9651734206965316
train_f-score_micro_sent: 0.9651734206965316
train_label=O_precision_tok: 0.9947004269100544
train_label=O_recall_tok: 0.9961492646451781
train_label=O_f-score_tok: 0.9954243185829235
train_label=LOC_precision_tok: 0.9320178077247022
train_label=LOC_recall_tok: 0.9335904543811016
train_label=LOC_f-score_tok: 0.9328034682080925
train_label=MISC_precision_tok: 0.8833938294010889
train_label=MISC_recall_tok: 0.8478118876551274
train_label=MISC_f-score_tok: 0.8652371958671259
train_label=ORG_precision_tok: 0.9118092736640064
train_label=ORG_recall_tok: 0.9003491271820449
train_label=ORG_f-score_tok: 0.9060429632603895
train_label=PER_precision_tok: 0.9651100375738056
train_label=PER_recall_tok: 0.9694464414090582
train_label=PER_f-score_tok: 0.9672733793598136
train_precision_macro_tok: 0.9374062750547315
train_recall_macro_tok: 0.9294694350545019
train_f-score_macro_tok: 0.933356265055669
train_precision_micro_tok: 0.9840782630475245
train_recall_micro_tok: 0.9840782630475245
train_f-score_micro_tok: 0.9840782630475245
train_time: 76.83909392356873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9138    0.9185    0.9162      2909
           1     0.9787    0.9774    0.9780     11132

   micro avg     0.9652    0.9652    0.9652     14041
   macro avg     0.9462    0.9479    0.9471     14041
weighted avg     0.9652    0.9652    0.9652     14041

F1-macro sent:  0.9470940611026255
F1-micro sent:  0.9651734206965316
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9961    0.9954    169578
         LOC     0.9320    0.9336    0.9328      8297
        MISC     0.8834    0.8478    0.8652      4593
         ORG     0.9118    0.9003    0.9060     10025
         PER     0.9651    0.9694    0.9673     11128

   micro avg     0.9841    0.9841    0.9841    203621
   macro avg     0.9374    0.9295    0.9334    203621
weighted avg     0.9839    0.9841    0.9840    203621

F1-macro tok:  0.933356265055669
F1-micro tok:  0.9840782630475245
**************************************************
dev_cost_sum: 3132.9898974895477
dev_cost_avg: 0.9639968915352455
dev_count_sent: 3250.0
dev_total_correct_sent: 3192.0
dev_accuracy_sent: 0.9821538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50619.0
dev_accuracy_tok: 0.9855340524122892
dev_label=0_precision_sent: 0.9681020733652312
dev_label=0_recall_sent: 0.9410852713178295
dev_label=0_f-score_sent: 0.9544025157232704
dev_label=1_precision_sent: 0.9855127716355319
dev_label=1_recall_sent: 0.9923224568138196
dev_label=1_f-score_sent: 0.9889058913542463
dev_precision_macro_sent: 0.9768074225003816
dev_recall_macro_sent: 0.9667038640658245
dev_f-score_macro_sent: 0.9716542035387583
dev_precision_micro_sent: 0.9821538461538462
dev_recall_micro_sent: 0.9821538461538462
dev_f-score_micro_sent: 0.9821538461538462
dev_label=O_precision_tok: 0.9936872510424188
dev_label=O_recall_tok: 0.9976379241797049
dev_label=O_f-score_tok: 0.9956586686583886
dev_label=LOC_precision_tok: 0.9455847255369928
dev_label=LOC_recall_tok: 0.94603629417383
dev_label=LOC_f-score_tok: 0.9458104559560754
dev_label=MISC_precision_tok: 0.8844589096826688
dev_label=MISC_recall_tok: 0.8572555205047319
dev_label=MISC_f-score_tok: 0.8706447737284742
dev_label=ORG_precision_tok: 0.9395203336809176
dev_label=ORG_recall_tok: 0.861376673040153
dev_label=ORG_f-score_tok: 0.8987531172069826
dev_label=PER_precision_tok: 0.9686618614854278
dev_label=PER_recall_tok: 0.9815814544299778
dev_label=PER_f-score_tok: 0.9750788643533124
dev_precision_macro_tok: 0.9463826162856851
dev_recall_macro_tok: 0.9287775732656796
dev_f-score_macro_tok: 0.9371891759806467
dev_precision_micro_tok: 0.9855340524122892
dev_recall_micro_tok: 0.9855340524122892
dev_f-score_micro_tok: 0.9855340524122892
dev_time: 5.745145320892334
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9681    0.9411    0.9544       645
           1     0.9855    0.9923    0.9889      2605

   micro avg     0.9822    0.9822    0.9822      3250
   macro avg     0.9768    0.9667    0.9717      3250
weighted avg     0.9821    0.9822    0.9821      3250

F1-macro sent:  0.9716542035387583
F1-micro sent:  0.9821538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9937    0.9976    0.9957     42759
         LOC     0.9456    0.9460    0.9458      2094
        MISC     0.8845    0.8573    0.8706      1268
         ORG     0.9395    0.8614    0.8988      2092
         PER     0.9687    0.9816    0.9751      3149

   micro avg     0.9855    0.9855    0.9855     51362
   macro avg     0.9464    0.9288    0.9372     51362
weighted avg     0.9853    0.9855    0.9853     51362

F1-macro tok:  0.9371891759806467
F1-micro tok:  0.9855340524122892
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 11002.796443462372
train_cost_avg: 0.7836191470310072
train_count_sent: 14041.0
train_total_correct_sent: 13643.0
train_accuracy_sent: 0.9716544405669112
train_count_tok: 203621.0
train_total_correct_tok: 200557.0
train_accuracy_tok: 0.9849524361436197
train_label=0_precision_sent: 0.926605504587156
train_label=0_recall_sent: 0.9374355448607768
train_label=0_f-score_sent: 0.931989063568011
train_label=1_precision_sent: 0.9836006487655433
train_label=1_recall_sent: 0.9805964786201941
train_label=1_f-score_sent: 0.9820962663067926
train_precision_macro_sent: 0.9551030766763496
train_recall_macro_sent: 0.9590160117404855
train_f-score_macro_sent: 0.9570426649374018
train_precision_micro_sent: 0.9716544405669112
train_recall_micro_sent: 0.9716544405669112
train_f-score_micro_sent: 0.9716544405669112
train_label=O_precision_tok: 0.9950359203862914
train_label=O_recall_tok: 0.9964559081956386
train_label=O_f-score_tok: 0.9957454080460109
train_label=LOC_precision_tok: 0.9369641347663326
train_label=LOC_recall_tok: 0.9351572857659395
train_label=LOC_f-score_tok: 0.9360598383399686
train_label=MISC_precision_tok: 0.8924852874603894
train_label=MISC_recall_tok: 0.8584802961027651
train_label=MISC_f-score_tok: 0.8751525912773277
train_label=ORG_precision_tok: 0.9135814889336016
train_label=ORG_recall_tok: 0.9058354114713217
train_label=ORG_f-score_tok: 0.9096919609316303
train_label=PER_precision_tok: 0.9672997670668338
train_label=PER_recall_tok: 0.970255212077642
train_label=PER_f-score_tok: 0.9687752355316286
train_precision_macro_tok: 0.9410733197226897
train_recall_macro_tok: 0.9332368227226613
train_f-score_macro_tok: 0.9370850068253131
train_precision_micro_tok: 0.9849524361436197
train_recall_micro_tok: 0.9849524361436197
train_f-score_micro_tok: 0.9849524361436197
train_time: 76.6464729309082
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9266    0.9374    0.9320      2909
           1     0.9836    0.9806    0.9821     11132

   micro avg     0.9717    0.9717    0.9717     14041
   macro avg     0.9551    0.9590    0.9570     14041
weighted avg     0.9718    0.9717    0.9717     14041

F1-macro sent:  0.9570426649374018
F1-micro sent:  0.9716544405669112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9950    0.9965    0.9957    169578
         LOC     0.9370    0.9352    0.9361      8297
        MISC     0.8925    0.8585    0.8752      4593
         ORG     0.9136    0.9058    0.9097     10025
         PER     0.9673    0.9703    0.9688     11128

   micro avg     0.9850    0.9850    0.9850    203621
   macro avg     0.9411    0.9332    0.9371    203621
weighted avg     0.9848    0.9850    0.9849    203621

F1-macro tok:  0.9370850068253131
F1-micro tok:  0.9849524361436197
**************************************************
dev_cost_sum: 2983.553577721119
dev_cost_avg: 0.918016485452652
dev_count_sent: 3250.0
dev_total_correct_sent: 3164.0
dev_accuracy_sent: 0.9735384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50680.0
dev_accuracy_tok: 0.9867217008683462
dev_label=0_precision_sent: 0.9912126537785588
dev_label=0_recall_sent: 0.8744186046511628
dev_label=0_f-score_sent: 0.929159802306425
dev_label=1_precision_sent: 0.969787392763894
dev_label=1_recall_sent: 0.9980806142034548
dev_label=1_f-score_sent: 0.9837306091562618
dev_precision_macro_sent: 0.9805000232712264
dev_recall_macro_sent: 0.9362496094273088
dev_f-score_macro_sent: 0.9564452057313434
dev_precision_micro_sent: 0.9735384615384616
dev_recall_micro_sent: 0.9735384615384616
dev_f-score_micro_sent: 0.9735384615384616
dev_label=O_precision_tok: 0.9955389466308536
dev_label=O_recall_tok: 0.9968427699431699
dev_label=O_f-score_tok: 0.9961904316731717
dev_label=LOC_precision_tok: 0.9590163934426229
dev_label=LOC_recall_tok: 0.9498567335243553
dev_label=LOC_f-score_tok: 0.9544145873320538
dev_label=MISC_precision_tok: 0.8630451415455241
dev_label=MISC_recall_tok: 0.889589905362776
dev_label=MISC_f-score_tok: 0.876116504854369
dev_label=ORG_precision_tok: 0.9431934493346981
dev_label=ORG_recall_tok: 0.8809751434034416
dev_label=ORG_f-score_tok: 0.9110232328225407
dev_label=PER_precision_tok: 0.9638854296388543
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9734318503379972
dev_precision_macro_tok: 0.9449358721185106
dev_recall_macro_tok: 0.9400867624632617
dev_f-score_macro_tok: 0.9422353214040264
dev_precision_micro_tok: 0.9867217008683462
dev_recall_micro_tok: 0.9867217008683462
dev_f-score_micro_tok: 0.9867217008683462
dev_time: 5.8421361446380615
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9912    0.8744    0.9292       645
           1     0.9698    0.9981    0.9837      2605

   micro avg     0.9735    0.9735    0.9735      3250
   macro avg     0.9805    0.9362    0.9564      3250
weighted avg     0.9740    0.9735    0.9729      3250

F1-macro sent:  0.9564452057313434
F1-micro sent:  0.9735384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9968    0.9962     42759
         LOC     0.9590    0.9499    0.9544      2094
        MISC     0.8630    0.8896    0.8761      1268
         ORG     0.9432    0.8810    0.9110      2092
         PER     0.9639    0.9832    0.9734      3149

   micro avg     0.9867    0.9867    0.9867     51362
   macro avg     0.9449    0.9401    0.9422     51362
weighted avg     0.9867    0.9867    0.9867     51362

F1-macro tok:  0.9422353214040264
F1-micro tok:  0.9867217008683462
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 9965.781221628189
train_cost_avg: 0.7097629244091012
train_count_sent: 14041.0
train_total_correct_sent: 13705.0
train_accuracy_sent: 0.9760700804785984
train_count_tok: 203621.0
train_total_correct_tok: 200746.0
train_accuracy_tok: 0.9858806311726197
train_label=0_precision_sent: 0.9398290598290598
train_label=0_recall_sent: 0.9449982811962874
train_label=0_f-score_sent: 0.9424065821049022
train_label=1_precision_sent: 0.9856063332133861
train_label=1_recall_sent: 0.9841897233201581
train_label=1_f-score_sent: 0.9848975188781014
train_precision_macro_sent: 0.962717696521223
train_recall_macro_sent: 0.9645940022582227
train_f-score_macro_sent: 0.9636520504915018
train_precision_micro_sent: 0.9760700804785984
train_recall_micro_sent: 0.9760700804785984
train_f-score_micro_sent: 0.9760700804785984
train_label=O_precision_tok: 0.9951588965582228
train_label=O_recall_tok: 0.9964382172215736
train_label=O_f-score_tok: 0.9957981459982203
train_label=LOC_precision_tok: 0.940426044048622
train_label=LOC_recall_tok: 0.9417861877787151
train_label=LOC_f-score_tok: 0.941105624473082
train_label=MISC_precision_tok: 0.8993440398099978
train_label=MISC_recall_tok: 0.865665142608317
train_label=MISC_f-score_tok: 0.8821832704681606
train_label=ORG_precision_tok: 0.9214343271555198
train_label=ORG_recall_tok: 0.9125187032418952
train_label=ORG_f-score_tok: 0.9169548438831253
train_label=PER_precision_tok: 0.9701799946270261
train_label=PER_recall_tok: 0.9735801581595974
train_label=PER_f-score_tok: 0.9718771024893473
train_precision_macro_tok: 0.9453086604398777
train_recall_macro_tok: 0.9379976818020197
train_f-score_macro_tok: 0.9415837974623871
train_precision_micro_tok: 0.9858806311726197
train_recall_micro_tok: 0.9858806311726197
train_f-score_micro_tok: 0.9858806311726197
train_time: 76.79624009132385
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9398    0.9450    0.9424      2909
           1     0.9856    0.9842    0.9849     11132

   micro avg     0.9761    0.9761    0.9761     14041
   macro avg     0.9627    0.9646    0.9637     14041
weighted avg     0.9761    0.9761    0.9761     14041

F1-macro sent:  0.9636520504915018
F1-micro sent:  0.9760700804785984
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9964    0.9958    169578
         LOC     0.9404    0.9418    0.9411      8297
        MISC     0.8993    0.8657    0.8822      4593
         ORG     0.9214    0.9125    0.9170     10025
         PER     0.9702    0.9736    0.9719     11128

   micro avg     0.9859    0.9859    0.9859    203621
   macro avg     0.9453    0.9380    0.9416    203621
weighted avg     0.9858    0.9859    0.9858    203621

F1-macro tok:  0.9415837974623871
F1-micro tok:  0.9858806311726197
**************************************************
dev_cost_sum: 2861.2676773667336
dev_cost_avg: 0.8803900545743796
dev_count_sent: 3250.0
dev_total_correct_sent: 3202.0
dev_accuracy_sent: 0.9852307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50702.0
dev_accuracy_tok: 0.9871500330983995
dev_label=0_precision_sent: 0.9557251908396946
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9630769230769232
dev_label=1_precision_sent: 0.9926782273603083
dev_label=1_recall_sent: 0.9888675623800384
dev_label=1_f-score_sent: 0.9907692307692307
dev_precision_macro_sent: 0.9742017091000015
dev_recall_macro_sent: 0.9797050990194766
dev_f-score_macro_sent: 0.976923076923077
dev_precision_micro_sent: 0.9852307692307692
dev_recall_micro_sent: 0.9852307692307692
dev_f-score_micro_sent: 0.9852307692307692
dev_label=O_precision_tok: 0.9951698711965652
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9962973777959471
dev_label=LOC_precision_tok: 0.9683638161146811
dev_label=LOC_recall_tok: 0.9355300859598854
dev_label=LOC_f-score_tok: 0.9516638328880253
dev_label=MISC_precision_tok: 0.9135593220338983
dev_label=MISC_recall_tok: 0.8501577287066246
dev_label=MISC_f-score_tok: 0.880718954248366
dev_label=ORG_precision_tok: 0.9052729818012133
dev_label=ORG_recall_tok: 0.9273422562141491
dev_label=ORG_f-score_tok: 0.9161747343565526
dev_label=PER_precision_tok: 0.9734177215189873
dev_label=PER_recall_tok: 0.9768180374722134
dev_label=PER_f-score_tok: 0.9751149152005072
dev_precision_macro_tok: 0.9511567425330691
dev_recall_macro_tok: 0.9374551101057577
dev_f-score_macro_tok: 0.9439939628978797
dev_precision_micro_tok: 0.9871500330983995
dev_recall_micro_tok: 0.9871500330983995
dev_f-score_micro_tok: 0.9871500330983995
dev_time: 5.762160301208496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9557    0.9705    0.9631       645
           1     0.9927    0.9889    0.9908      2605

   micro avg     0.9852    0.9852    0.9852      3250
   macro avg     0.9742    0.9797    0.9769      3250
weighted avg     0.9853    0.9852    0.9853      3250

F1-macro sent:  0.976923076923077
F1-micro sent:  0.9852307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9974    0.9963     42759
         LOC     0.9684    0.9355    0.9517      2094
        MISC     0.9136    0.8502    0.8807      1268
         ORG     0.9053    0.9273    0.9162      2092
         PER     0.9734    0.9768    0.9751      3149

   micro avg     0.9872    0.9872    0.9872     51362
   macro avg     0.9512    0.9375    0.9440     51362
weighted avg     0.9871    0.9872    0.9871     51362

F1-macro tok:  0.9439939628978797
F1-micro tok:  0.9871500330983995
**************************************************
Best epoch: 10
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 9565.352495670319
train_cost_avg: 0.6812443911167523
train_count_sent: 14041.0
train_total_correct_sent: 13698.0
train_accuracy_sent: 0.9755715404885692
train_count_tok: 203621.0
train_total_correct_tok: 200892.0
train_accuracy_tok: 0.9865976495548101
train_label=0_precision_sent: 0.938782489740082
train_label=0_recall_sent: 0.9436232382261945
train_label=0_f-score_sent: 0.9411966398079891
train_label=1_precision_sent: 0.9852478186561122
train_label=1_recall_sent: 0.9839202299676608
train_label=1_f-score_sent: 0.9845835767899681
train_precision_macro_sent: 0.9620151541980971
train_recall_macro_sent: 0.9637717340969276
train_f-score_macro_sent: 0.9628901082989786
train_precision_micro_sent: 0.9755715404885692
train_recall_micro_sent: 0.9755715404885692
train_f-score_micro_sent: 0.9755715404885692
train_label=O_precision_tok: 0.9955989701472312
train_label=O_recall_tok: 0.9965089811178337
train_label=O_f-score_tok: 0.9960537677823591
train_label=LOC_precision_tok: 0.9466505733252867
train_label=LOC_recall_tok: 0.9452814270218152
train_label=LOC_f-score_tok: 0.9459655047642022
train_label=MISC_precision_tok: 0.8982182628062361
train_label=MISC_recall_tok: 0.8780753320269976
train_label=MISC_f-score_tok: 0.888032588351866
train_label=ORG_precision_tok: 0.9240341194179629
train_label=ORG_recall_tok: 0.918503740648379
train_label=ORG_f-score_tok: 0.9212606303151576
train_label=PER_precision_tok: 0.9707570864729099
train_label=PER_recall_tok: 0.9725017972681524
train_label=PER_f-score_tok: 0.9716286586460765
train_precision_macro_tok: 0.9470518024339254
train_recall_macro_tok: 0.9421742556166356
train_f-score_macro_tok: 0.9445882299719323
train_precision_micro_tok: 0.9865976495548101
train_recall_micro_tok: 0.9865976495548101
train_f-score_micro_tok: 0.9865976495548101
train_time: 76.62330746650696
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9388    0.9436    0.9412      2909
           1     0.9852    0.9839    0.9846     11132

   micro avg     0.9756    0.9756    0.9756     14041
   macro avg     0.9620    0.9638    0.9629     14041
weighted avg     0.9756    0.9756    0.9756     14041

F1-macro sent:  0.9628901082989786
F1-micro sent:  0.9755715404885692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9965    0.9961    169578
         LOC     0.9467    0.9453    0.9460      8297
        MISC     0.8982    0.8781    0.8880      4593
         ORG     0.9240    0.9185    0.9213     10025
         PER     0.9708    0.9725    0.9716     11128

   micro avg     0.9866    0.9866    0.9866    203621
   macro avg     0.9471    0.9422    0.9446    203621
weighted avg     0.9865    0.9866    0.9866    203621

F1-macro tok:  0.9445882299719323
F1-micro tok:  0.9865976495548101
**************************************************
dev_cost_sum: 2895.4047821760178
dev_cost_avg: 0.8908937791310824
dev_count_sent: 3250.0
dev_total_correct_sent: 3157.0
dev_accuracy_sent: 0.9713846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50730.0
dev_accuracy_tok: 0.9876951832093765
dev_label=0_precision_sent: 0.8801652892561983
dev_label=0_recall_sent: 0.9906976744186047
dev_label=0_f-score_sent: 0.9321663019693656
dev_label=1_precision_sent: 0.9976228209191759
dev_label=1_recall_sent: 0.9666026871401152
dev_label=1_f-score_sent: 0.9818678104893742
dev_precision_macro_sent: 0.9388940550876871
dev_recall_macro_sent: 0.97865018077936
dev_f-score_macro_sent: 0.9570170562293698
dev_precision_micro_sent: 0.9713846153846154
dev_recall_micro_sent: 0.9713846153846154
dev_f-score_micro_sent: 0.9713846153846154
dev_label=O_precision_tok: 0.9946153846153846
dev_label=O_recall_tok: 0.9978951799621132
dev_label=O_f-score_tok: 0.9962525829159807
dev_label=LOC_precision_tok: 0.9491046182846371
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.9554079696394687
dev_label=MISC_precision_tok: 0.9088649544324772
dev_label=MISC_recall_tok: 0.8651419558359621
dev_label=MISC_f-score_tok: 0.8864646464646464
dev_label=ORG_precision_tok: 0.9446122860020141
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.920058852378617
dev_label=PER_precision_tok: 0.9768033047346679
dev_label=PER_recall_tok: 0.9761829152111782
dev_label=PER_f-score_tok: 0.9764930114358322
dev_precision_macro_tok: 0.9548001096138362
dev_recall_macro_tok: 0.9395530358985058
dev_f-score_macro_tok: 0.946935412566909
dev_precision_micro_tok: 0.9876951832093765
dev_recall_micro_tok: 0.9876951832093765
dev_f-score_micro_tok: 0.9876951832093765
dev_time: 5.825060129165649
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.8802    0.9907    0.9322       645
           1     0.9976    0.9666    0.9819      2605

   micro avg     0.9714    0.9714    0.9714      3250
   macro avg     0.9389    0.9787    0.9570      3250
weighted avg     0.9743    0.9714    0.9720      3250

F1-macro sent:  0.9570170562293698
F1-micro sent:  0.9713846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9946    0.9979    0.9963     42759
         LOC     0.9491    0.9618    0.9554      2094
        MISC     0.9089    0.8651    0.8865      1268
         ORG     0.9446    0.8967    0.9201      2092
         PER     0.9768    0.9762    0.9765      3149

   micro avg     0.9877    0.9877    0.9877     51362
   macro avg     0.9548    0.9396    0.9469     51362
weighted avg     0.9875    0.9877    0.9876     51362

F1-macro tok:  0.946935412566909
F1-micro tok:  0.9876951832093765
**************************************************
Best epoch: 10
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 8763.116777658463
train_cost_avg: 0.6241091644226524
train_count_sent: 14041.0
train_total_correct_sent: 13719.0
train_accuracy_sent: 0.9770671604586568
train_count_tok: 203621.0
train_total_correct_tok: 201180.0
train_accuracy_tok: 0.988012041979953
train_label=0_precision_sent: 0.9416182997610106
train_label=0_recall_sent: 0.9480921278789962
train_label=0_f-score_sent: 0.9448441247002398
train_label=1_precision_sent: 0.9864110871130309
train_label=1_recall_sent: 0.9846388789076536
train_label=1_f-score_sent: 0.9855241862974284
train_precision_macro_sent: 0.9640146934370208
train_recall_macro_sent: 0.9663655033933249
train_f-score_macro_sent: 0.9651841554988341
train_precision_micro_sent: 0.9770671604586568
train_recall_micro_sent: 0.9770671604586568
train_f-score_micro_sent: 0.9770671604586568
train_label=O_precision_tok: 0.9961288954094709
train_label=O_recall_tok: 0.9969571524608145
train_label=O_f-score_tok: 0.9965428518377705
train_label=LOC_precision_tok: 0.9509957754978877
train_label=LOC_recall_tok: 0.9496203447029047
train_label=LOC_f-score_tok: 0.9503075624170788
train_label=MISC_precision_tok: 0.9091720598080786
train_label=MISC_recall_tok: 0.8870019595035924
train_label=MISC_f-score_tok: 0.8979501873484681
train_label=ORG_precision_tok: 0.932509792106056
train_label=ORG_recall_tok: 0.9261845386533666
train_label=ORG_f-score_tok: 0.9293364027624862
train_label=PER_precision_tok: 0.9732534215940603
train_label=PER_recall_tok: 0.9777138749101366
train_label=PER_f-score_tok: 0.9754785493342897
train_precision_macro_tok: 0.9524119888831105
train_recall_macro_tok: 0.9474955740461629
train_f-score_macro_tok: 0.9499231107400187
train_precision_micro_tok: 0.988012041979953
train_recall_micro_tok: 0.988012041979953
train_f-score_micro_tok: 0.988012041979953
train_time: 76.98789548873901
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9416    0.9481    0.9448      2909
           1     0.9864    0.9846    0.9855     11132

   micro avg     0.9771    0.9771    0.9771     14041
   macro avg     0.9640    0.9664    0.9652     14041
weighted avg     0.9771    0.9771    0.9771     14041

F1-macro sent:  0.9651841554988341
F1-micro sent:  0.9770671604586568
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9970    0.9965    169578
         LOC     0.9510    0.9496    0.9503      8297
        MISC     0.9092    0.8870    0.8980      4593
         ORG     0.9325    0.9262    0.9293     10025
         PER     0.9733    0.9777    0.9755     11128

   micro avg     0.9880    0.9880    0.9880    203621
   macro avg     0.9524    0.9475    0.9499    203621
weighted avg     0.9879    0.9880    0.9880    203621

F1-macro tok:  0.9499231107400187
F1-micro tok:  0.988012041979953
**************************************************
dev_cost_sum: 2767.9604048132896
dev_cost_avg: 0.8516801245579353
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50684.0
dev_accuracy_tok: 0.9867995794556287
dev_label=0_precision_sent: 0.9735202492211839
dev_label=0_recall_sent: 0.9689922480620154
dev_label=0_f-score_sent: 0.9712509712509713
dev_label=1_precision_sent: 0.9923312883435583
dev_label=1_recall_sent: 0.9934740882917467
dev_label=1_f-score_sent: 0.9929023594859007
dev_precision_macro_sent: 0.9829257687823711
dev_recall_macro_sent: 0.9812331681768811
dev_f-score_macro_sent: 0.982076665368436
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9957249982479501
dev_label=O_recall_tok: 0.9968427699431699
dev_label=O_f-score_tok: 0.9962835705770984
dev_label=LOC_precision_tok: 0.9358437935843794
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9484098939929329
dev_label=MISC_precision_tok: 0.8793375394321766
dev_label=MISC_recall_tok: 0.8793375394321766
dev_label=MISC_f-score_tok: 0.8793375394321766
dev_label=ORG_precision_tok: 0.9498189342990171
dev_label=ORG_recall_tok: 0.8776290630975143
dev_label=ORG_f-score_tok: 0.9122981366459627
dev_label=PER_precision_tok: 0.9665938182953481
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9748110831234257
dev_precision_macro_tok: 0.9454638167717743
dev_recall_macro_tok: 0.9396593368262718
dev_f-score_macro_tok: 0.9422280447543192
dev_precision_micro_tok: 0.9867995794556287
dev_recall_micro_tok: 0.9867995794556287
dev_f-score_micro_tok: 0.9867995794556287
dev_time: 5.817368507385254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9735    0.9690    0.9713       645
           1     0.9923    0.9935    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9829    0.9812    0.9821      3250
weighted avg     0.9886    0.9886    0.9886      3250

F1-macro sent:  0.982076665368436
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9957    0.9968    0.9963     42759
         LOC     0.9358    0.9613    0.9484      2094
        MISC     0.8793    0.8793    0.8793      1268
         ORG     0.9498    0.8776    0.9123      2092
         PER     0.9666    0.9832    0.9748      3149

   micro avg     0.9868    0.9868    0.9868     51362
   macro avg     0.9455    0.9397    0.9422     51362
weighted avg     0.9868    0.9868    0.9867     51362

F1-macro tok:  0.9422280447543192
F1-micro tok:  0.9867995794556287
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 8304.195061445236
train_cost_avg: 0.5914247604476345
train_count_sent: 14041.0
train_total_correct_sent: 13746.0
train_accuracy_sent: 0.978990100420198
train_count_tok: 203621.0
train_total_correct_tok: 201274.0
train_accuracy_tok: 0.9884736839520482
train_label=0_precision_sent: 0.9482167352537723
train_label=0_recall_sent: 0.9504984530766587
train_label=0_f-score_sent: 0.9493562231759657
train_label=1_precision_sent: 0.9870561797752809
train_label=1_recall_sent: 0.9864355012576357
train_label=1_f-score_sent: 0.9867457429123422
train_precision_macro_sent: 0.9676364575145266
train_recall_macro_sent: 0.9684669771671472
train_f-score_macro_sent: 0.9680509830441539
train_precision_micro_sent: 0.978990100420198
train_recall_micro_sent: 0.978990100420198
train_f-score_micro_sent: 0.978990100420198
train_label=O_precision_tok: 0.9962761538325565
train_label=O_recall_tok: 0.9970927832619797
train_label=O_f-score_tok: 0.9966843012717547
train_label=LOC_precision_tok: 0.9509874759152216
train_label=LOC_recall_tok: 0.9517898035434494
train_label=LOC_f-score_tok: 0.9513884705740618
train_label=MISC_precision_tok: 0.9124249833296288
train_label=MISC_recall_tok: 0.8937513607663836
train_label=MISC_f-score_tok: 0.9029916410030797
train_label=ORG_precision_tok: 0.9364138623807132
train_label=ORG_recall_tok: 0.9298753117206983
train_label=ORG_f-score_tok: 0.9331331331331332
train_label=PER_precision_tok: 0.974789162031222
train_label=PER_recall_tok: 0.9763659237958303
train_label=PER_f-score_tok: 0.975576905809464
train_precision_macro_tok: 0.9541783274978684
train_recall_macro_tok: 0.9497750366176682
train_f-score_macro_tok: 0.9519548903582986
train_precision_micro_tok: 0.9884736839520482
train_recall_micro_tok: 0.9884736839520482
train_f-score_micro_tok: 0.9884736839520482
train_time: 77.0457239151001
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9482    0.9505    0.9494      2909
           1     0.9871    0.9864    0.9867     11132

   micro avg     0.9790    0.9790    0.9790     14041
   macro avg     0.9676    0.9685    0.9681     14041
weighted avg     0.9790    0.9790    0.9790     14041

F1-macro sent:  0.9680509830441539
F1-micro sent:  0.978990100420198
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9971    0.9967    169578
         LOC     0.9510    0.9518    0.9514      8297
        MISC     0.9124    0.8938    0.9030      4593
         ORG     0.9364    0.9299    0.9331     10025
         PER     0.9748    0.9764    0.9756     11128

   micro avg     0.9885    0.9885    0.9885    203621
   macro avg     0.9542    0.9498    0.9520    203621
weighted avg     0.9884    0.9885    0.9884    203621

F1-macro tok:  0.9519548903582986
F1-micro tok:  0.9884736839520482
**************************************************
dev_cost_sum: 2709.4189989566803
dev_cost_avg: 0.8336673842943632
dev_count_sent: 3250.0
dev_total_correct_sent: 3211.0
dev_accuracy_sent: 0.988
dev_count_tok: 51362.0
dev_total_correct_tok: 50743.0
dev_accuracy_tok: 0.9879482886180445
dev_label=0_precision_sent: 0.9749216300940439
dev_label=0_recall_sent: 0.9643410852713178
dev_label=0_f-score_sent: 0.9696024941543259
dev_label=1_precision_sent: 0.9911944869831547
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.99252443933295
dev_precision_macro_sent: 0.9830580585385993
dev_recall_macro_sent: 0.9790995253611867
dev_f-score_macro_sent: 0.981063466743638
dev_precision_micro_sent: 0.988
dev_recall_micro_sent: 0.988
dev_f-score_micro_sent: 0.988
dev_label=O_precision_tok: 0.9960517708625362
dev_label=O_recall_tok: 0.9971000257255782
dev_label=O_f-score_tok: 0.9965756226406275
dev_label=LOC_precision_tok: 0.9550827423167849
dev_label=LOC_recall_tok: 0.9646609360076409
dev_label=LOC_f-score_tok: 0.959847944880019
dev_label=MISC_precision_tok: 0.8879173290937997
dev_label=MISC_recall_tok: 0.8809148264984227
dev_label=MISC_f-score_tok: 0.8844022169437846
dev_label=ORG_precision_tok: 0.9388059701492537
dev_label=ORG_recall_tok: 0.9020076481835564
dev_label=ORG_f-score_tok: 0.9200390053632375
dev_label=PER_precision_tok: 0.9713385826771653
dev_label=PER_recall_tok: 0.9793585265163544
dev_label=PER_f-score_tok: 0.9753320683111953
dev_precision_macro_tok: 0.9498392790199078
dev_recall_macro_tok: 0.9448083925863106
dev_f-score_macro_tok: 0.9472393716277727
dev_precision_micro_tok: 0.9879482886180445
dev_recall_micro_tok: 0.9879482886180445
dev_f-score_micro_tok: 0.9879482886180445
dev_time: 5.726459741592407
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9749    0.9643    0.9696       645
           1     0.9912    0.9939    0.9925      2605

   micro avg     0.9880    0.9880    0.9880      3250
   macro avg     0.9831    0.9791    0.9811      3250
weighted avg     0.9880    0.9880    0.9880      3250

F1-macro sent:  0.981063466743638
F1-micro sent:  0.988
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9971    0.9966     42759
         LOC     0.9551    0.9647    0.9598      2094
        MISC     0.8879    0.8809    0.8844      1268
         ORG     0.9388    0.9020    0.9200      2092
         PER     0.9713    0.9794    0.9753      3149

   micro avg     0.9879    0.9879    0.9879     51362
   macro avg     0.9498    0.9448    0.9472     51362
weighted avg     0.9879    0.9879    0.9879     51362

F1-macro tok:  0.9472393716277727
F1-micro tok:  0.9879482886180445
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 7661.580779910088
train_cost_avg: 0.545657772232041
train_count_sent: 14041.0
train_total_correct_sent: 13775.0
train_accuracy_sent: 0.9810554803788903
train_count_tok: 203621.0
train_total_correct_tok: 201456.0
train_accuracy_tok: 0.9893675013873815
train_label=0_precision_sent: 0.9549053356282272
train_label=0_recall_sent: 0.9535922997593674
train_label=0_f-score_sent: 0.9542483660130718
train_label=1_precision_sent: 0.9878771551724138
train_label=1_recall_sent: 0.9882321236076177
train_label=1_f-score_sent: 0.9880546075085324
train_precision_macro_sent: 0.9713912454003205
train_recall_macro_sent: 0.9709122116834925
train_f-score_macro_sent: 0.9711514867608021
train_precision_micro_sent: 0.9810554803788903
train_recall_micro_sent: 0.9810554803788903
train_f-score_micro_sent: 0.9810554803788903
train_label=O_precision_tok: 0.9964996641091822
train_label=O_recall_tok: 0.997204826097725
train_label=O_f-score_tok: 0.9968521203975524
train_label=LOC_precision_tok: 0.9571445768628867
train_label=LOC_recall_tok: 0.9582981800650837
train_label=LOC_f-score_tok: 0.9577210310768489
train_label=MISC_precision_tok: 0.9238521836506159
train_label=MISC_recall_tok: 0.8981058131939909
train_label=MISC_f-score_tok: 0.9107970854493267
train_label=ORG_precision_tok: 0.9391905429773593
train_label=ORG_recall_tok: 0.9351620947630923
train_label=ORG_f-score_tok: 0.9371719898035688
train_label=PER_precision_tok: 0.9760050138776972
train_label=PER_recall_tok: 0.9796010064701653
train_label=PER_f-score_tok: 0.9777997039960533
train_precision_macro_tok: 0.9585383962955483
train_recall_macro_tok: 0.9536743841180115
train_f-score_macro_tok: 0.9560683861446699
train_precision_micro_tok: 0.9893675013873815
train_recall_micro_tok: 0.9893675013873815
train_f-score_micro_tok: 0.9893675013873815
train_time: 76.20555901527405
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9549    0.9536    0.9542      2909
           1     0.9879    0.9882    0.9881     11132

   micro avg     0.9811    0.9811    0.9811     14041
   macro avg     0.9714    0.9709    0.9712     14041
weighted avg     0.9810    0.9811    0.9811     14041

F1-macro sent:  0.9711514867608021
F1-micro sent:  0.9810554803788903
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9972    0.9969    169578
         LOC     0.9571    0.9583    0.9577      8297
        MISC     0.9239    0.8981    0.9108      4593
         ORG     0.9392    0.9352    0.9372     10025
         PER     0.9760    0.9796    0.9778     11128

   micro avg     0.9894    0.9894    0.9894    203621
   macro avg     0.9585    0.9537    0.9561    203621
weighted avg     0.9893    0.9894    0.9893    203621

F1-macro tok:  0.9560683861446699
F1-micro tok:  0.9893675013873815
**************************************************
dev_cost_sum: 2908.555109232664
dev_cost_avg: 0.8949400336100505
dev_count_sent: 3250.0
dev_total_correct_sent: 3206.0
dev_accuracy_sent: 0.9864615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50772.0
dev_accuracy_tok: 0.988512908375842
dev_label=0_precision_sent: 0.9559939301972686
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9662576687116565
dev_label=1_precision_sent: 0.9942107294480895
dev_label=1_recall_sent: 0.9888675623800384
dev_label=1_f-score_sent: 0.9915319476520401
dev_precision_macro_sent: 0.9751023298226791
dev_recall_macro_sent: 0.982805874213275
dev_f-score_macro_sent: 0.9788948081818483
dev_precision_micro_sent: 0.9864615384615385
dev_recall_micro_sent: 0.9864615384615385
dev_f-score_micro_sent: 0.9864615384615385
dev_label=O_precision_tok: 0.9956117828299332
dev_label=O_recall_tok: 0.9975443766224654
dev_label=O_f-score_tok: 0.9965771427903879
dev_label=LOC_precision_tok: 0.9558404558404558
dev_label=LOC_recall_tok: 0.9613180515759312
dev_label=LOC_f-score_tok: 0.9585714285714286
dev_label=MISC_precision_tok: 0.9008064516129032
dev_label=MISC_recall_tok: 0.8809148264984227
dev_label=MISC_f-score_tok: 0.890749601275917
dev_label=ORG_precision_tok: 0.937866927592955
dev_label=ORG_recall_tok: 0.9163479923518164
dev_label=ORG_f-score_tok: 0.9269825918762089
dev_label=PER_precision_tok: 0.981150159744409
dev_label=PER_recall_tok: 0.9752302318196253
dev_label=PER_f-score_tok: 0.9781812390508043
dev_precision_macro_tok: 0.9542551555241312
dev_recall_macro_tok: 0.9462710957736522
dev_f-score_macro_tok: 0.9502124007129493
dev_precision_micro_tok: 0.988512908375842
dev_recall_micro_tok: 0.988512908375842
dev_f-score_micro_tok: 0.9885129083758422
dev_time: 5.854691743850708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9560    0.9767    0.9663       645
           1     0.9942    0.9889    0.9915      2605

   micro avg     0.9865    0.9865    0.9865      3250
   macro avg     0.9751    0.9828    0.9789      3250
weighted avg     0.9866    0.9865    0.9865      3250

F1-macro sent:  0.9788948081818483
F1-micro sent:  0.9864615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9975    0.9966     42759
         LOC     0.9558    0.9613    0.9586      2094
        MISC     0.9008    0.8809    0.8907      1268
         ORG     0.9379    0.9163    0.9270      2092
         PER     0.9812    0.9752    0.9782      3149

   micro avg     0.9885    0.9885    0.9885     51362
   macro avg     0.9543    0.9463    0.9502     51362
weighted avg     0.9884    0.9885    0.9885     51362

F1-macro tok:  0.9502124007129493
F1-micro tok:  0.9885129083758422
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 7428.526878356934
train_cost_avg: 0.5290596736953873
train_count_sent: 14041.0
train_total_correct_sent: 13766.0
train_accuracy_sent: 0.98041450039171
train_count_tok: 203621.0
train_total_correct_tok: 201586.0
train_accuracy_tok: 0.9900059424126195
train_label=0_precision_sent: 0.9488752556237219
train_label=0_recall_sent: 0.9570299071845996
train_label=0_f-score_sent: 0.952935136060243
train_label=1_precision_sent: 0.988745835959305
train_label=1_recall_sent: 0.9865253323751347
train_label=1_f-score_sent: 0.9876343360762625
train_precision_macro_sent: 0.9688105457915135
train_recall_macro_sent: 0.9717776197798671
train_f-score_macro_sent: 0.9702847360682527
train_precision_micro_sent: 0.98041450039171
train_recall_micro_sent: 0.98041450039171
train_f-score_micro_sent: 0.98041450039171
train_label=O_precision_tok: 0.9966945946901403
train_label=O_recall_tok: 0.9975409546049605
train_label=O_f-score_tok: 0.9971175950486295
train_label=LOC_precision_tok: 0.9570980959267293
train_label=LOC_recall_tok: 0.9572134506448113
train_label=LOC_f-score_tok: 0.9571557698101838
train_label=MISC_precision_tok: 0.9342984409799554
train_label=MISC_recall_tok: 0.9133463966906161
train_label=MISC_f-score_tok: 0.9237036221512717
train_label=ORG_precision_tok: 0.9418499548056644
train_label=ORG_recall_tok: 0.9354613466334165
train_label=ORG_f-score_tok: 0.9386447803022719
train_label=PER_precision_tok: 0.9781244396629012
train_label=PER_recall_tok: 0.9804097771387491
train_label=PER_f-score_tok: 0.9792657750650751
train_precision_macro_tok: 0.9616131052130781
train_recall_macro_tok: 0.9567943851425106
train_f-score_macro_tok: 0.9591775084754864
train_precision_micro_tok: 0.9900059424126195
train_recall_micro_tok: 0.9900059424126195
train_f-score_micro_tok: 0.9900059424126195
train_time: 80.91188883781433
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9489    0.9570    0.9529      2909
           1     0.9887    0.9865    0.9876     11132

   micro avg     0.9804    0.9804    0.9804     14041
   macro avg     0.9688    0.9718    0.9703     14041
weighted avg     0.9805    0.9804    0.9804     14041

F1-macro sent:  0.9702847360682527
F1-micro sent:  0.98041450039171
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9975    0.9971    169578
         LOC     0.9571    0.9572    0.9572      8297
        MISC     0.9343    0.9133    0.9237      4593
         ORG     0.9418    0.9355    0.9386     10025
         PER     0.9781    0.9804    0.9793     11128

   micro avg     0.9900    0.9900    0.9900    203621
   macro avg     0.9616    0.9568    0.9592    203621
weighted avg     0.9900    0.9900    0.9900    203621

F1-macro tok:  0.9591775084754864
F1-micro tok:  0.9900059424126195
**************************************************
dev_cost_sum: 2730.839440599084
dev_cost_avg: 0.8402582894151027
dev_count_sent: 3250.0
dev_total_correct_sent: 3207.0
dev_accuracy_sent: 0.9867692307692307
dev_count_tok: 51362.0
dev_total_correct_tok: 50727.0
dev_accuracy_tok: 0.9876367742689147
dev_label=0_precision_sent: 0.9616564417177914
dev_label=0_recall_sent: 0.9720930232558139
dev_label=0_f-score_sent: 0.9668465690053971
dev_label=1_precision_sent: 0.9930715935334873
dev_label=1_recall_sent: 0.9904030710172744
dev_label=1_f-score_sent: 0.9917355371900827
dev_precision_macro_sent: 0.9773640176256393
dev_recall_macro_sent: 0.9812480471365441
dev_f-score_macro_sent: 0.9792910530977399
dev_precision_micro_sent: 0.9867692307692307
dev_recall_micro_sent: 0.9867692307692307
dev_f-score_micro_sent: 0.9867692307692307
dev_label=O_precision_tok: 0.9960054195477481
dev_label=O_recall_tok: 0.9971467995041979
dev_label=O_f-score_tok: 0.9965757827199737
dev_label=LOC_precision_tok: 0.9427107591988821
dev_label=LOC_recall_tok: 0.9665711556829035
dev_label=LOC_f-score_tok: 0.9544918651261496
dev_label=MISC_precision_tok: 0.8900316455696202
dev_label=MISC_recall_tok: 0.887223974763407
dev_label=MISC_f-score_tok: 0.8886255924170616
dev_label=ORG_precision_tok: 0.9573804573804574
dev_label=ORG_recall_tok: 0.8804971319311663
dev_label=ORG_f-score_tok: 0.9173306772908366
dev_label=PER_precision_tok: 0.9627213420316869
dev_label=PER_recall_tok: 0.9841219434741187
dev_label=PER_f-score_tok: 0.9733040201005025
dev_precision_macro_tok: 0.949769924745679
dev_recall_macro_tok: 0.9431122010711587
dev_f-score_macro_tok: 0.9460655875309048
dev_precision_micro_tok: 0.9876367742689147
dev_recall_micro_tok: 0.9876367742689147
dev_f-score_micro_tok: 0.9876367742689147
dev_time: 13.526700496673584
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9617    0.9721    0.9668       645
           1     0.9931    0.9904    0.9917      2605

   micro avg     0.9868    0.9868    0.9868      3250
   macro avg     0.9774    0.9812    0.9793      3250
weighted avg     0.9868    0.9868    0.9868      3250

F1-macro sent:  0.9792910530977399
F1-micro sent:  0.9867692307692307
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9971    0.9966     42759
         LOC     0.9427    0.9666    0.9545      2094
        MISC     0.8900    0.8872    0.8886      1268
         ORG     0.9574    0.8805    0.9173      2092
         PER     0.9627    0.9841    0.9733      3149

   micro avg     0.9876    0.9876    0.9876     51362
   macro avg     0.9498    0.9431    0.9461     51362
weighted avg     0.9876    0.9876    0.9875     51362

F1-macro tok:  0.9460655875309048
F1-micro tok:  0.9876367742689147
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 6949.08903670311
train_cost_avg: 0.4949141112957133
train_count_sent: 14041.0
train_total_correct_sent: 13819.0
train_accuracy_sent: 0.9841891603162168
train_count_tok: 203621.0
train_total_correct_tok: 201652.0
train_accuracy_tok: 0.9903300740100481
train_label=0_precision_sent: 0.9577512776831346
train_label=0_recall_sent: 0.966311447232726
train_label=0_f-score_sent: 0.9620123203285421
train_label=1_precision_sent: 0.9911759409328291
train_label=1_recall_sent: 0.9888609414301114
train_label=1_f-score_sent: 0.9900170878676139
train_precision_macro_sent: 0.9744636093079819
train_recall_macro_sent: 0.9775861943314187
train_f-score_macro_sent: 0.976014704098078
train_precision_micro_sent: 0.9841891603162168
train_recall_micro_sent: 0.9841891603162168
train_f-score_micro_sent: 0.9841891603162168
train_label=O_precision_tok: 0.9969877564975448
train_label=O_recall_tok: 0.9973581478729552
train_label=O_f-score_tok: 0.9971729177905718
train_label=LOC_precision_tok: 0.9578364052523792
train_label=LOC_recall_tok: 0.9582981800650837
train_label=LOC_f-score_tok: 0.958067237016508
train_label=MISC_precision_tok: 0.9295494699646644
train_label=MISC_recall_tok: 0.9163945133899413
train_label=MISC_f-score_tok: 0.9229251178598838
train_label=ORG_precision_tok: 0.9450736694397114
train_label=ORG_recall_tok: 0.9405486284289277
train_label=ORG_f-score_tok: 0.9428057194280571
train_label=PER_precision_tok: 0.9784320744585645
train_label=PER_recall_tok: 0.9824766355140186
train_label=PER_f-score_tok: 0.9804501838400143
train_precision_macro_tok: 0.9615758751225728
train_recall_macro_tok: 0.9590152210541852
train_f-score_macro_tok: 0.960284235187007
train_precision_micro_tok: 0.9903300740100481
train_recall_micro_tok: 0.9903300740100481
train_f-score_micro_tok: 0.9903300740100481
train_time: 145.99396014213562
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9578    0.9663    0.9620      2909
           1     0.9912    0.9889    0.9900     11132

   micro avg     0.9842    0.9842    0.9842     14041
   macro avg     0.9745    0.9776    0.9760     14041
weighted avg     0.9843    0.9842    0.9842     14041

F1-macro sent:  0.976014704098078
F1-micro sent:  0.9841891603162168
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9974    0.9972    169578
         LOC     0.9578    0.9583    0.9581      8297
        MISC     0.9295    0.9164    0.9229      4593
         ORG     0.9451    0.9405    0.9428     10025
         PER     0.9784    0.9825    0.9805     11128

   micro avg     0.9903    0.9903    0.9903    203621
   macro avg     0.9616    0.9590    0.9603    203621
weighted avg     0.9903    0.9903    0.9903    203621

F1-macro tok:  0.960284235187007
F1-micro tok:  0.9903300740100481
**************************************************
dev_cost_sum: 2793.214329391718
dev_cost_avg: 0.8594505628897594
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50768.0
dev_accuracy_tok: 0.9884350297885597
dev_label=0_precision_sent: 0.978125
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9743190661478599
dev_label=1_precision_sent: 0.9927203065134099
dev_label=1_recall_sent: 0.9946257197696737
dev_label=1_f-score_sent: 0.9936720997123681
dev_precision_macro_sent: 0.985422653256705
dev_recall_macro_sent: 0.9825841777142943
dev_f-score_macro_sent: 0.983995582930114
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9952406504444392
dev_label=O_recall_tok: 0.9976613110690147
dev_label=O_f-score_tok: 0.9964495106397888
dev_label=LOC_precision_tok: 0.967992240543162
dev_label=LOC_recall_tok: 0.9531996179560649
dev_label=LOC_f-score_tok: 0.960538979788258
dev_label=MISC_precision_tok: 0.9239222316145393
dev_label=MISC_recall_tok: 0.86198738170347
dev_label=MISC_f-score_tok: 0.8918808649530804
dev_label=ORG_precision_tok: 0.9309178743961353
dev_label=ORG_recall_tok: 0.9211281070745698
dev_label=ORG_f-score_tok: 0.9259971167707832
dev_label=PER_precision_tok: 0.9714195979899497
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9767882520132639
dev_precision_macro_tok: 0.9578985189976452
dev_recall_macro_tok: 0.9432385988988266
dev_f-score_macro_tok: 0.9503309448330348
dev_precision_micro_tok: 0.9884350297885597
dev_recall_micro_tok: 0.9884350297885597
dev_f-score_micro_tok: 0.9884350297885597
dev_time: 12.18623685836792
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9781    0.9705    0.9743       645
           1     0.9927    0.9946    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9854    0.9826    0.9840      3250
weighted avg     0.9898    0.9898    0.9898      3250

F1-macro sent:  0.983995582930114
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9952    0.9977    0.9964     42759
         LOC     0.9680    0.9532    0.9605      2094
        MISC     0.9239    0.8620    0.8919      1268
         ORG     0.9309    0.9211    0.9260      2092
         PER     0.9714    0.9822    0.9768      3149

   micro avg     0.9884    0.9884    0.9884     51362
   macro avg     0.9579    0.9432    0.9503     51362
weighted avg     0.9883    0.9884    0.9883     51362

F1-macro tok:  0.9503309448330348
F1-micro tok:  0.9884350297885597
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 6481.696152687073
train_cost_avg: 0.46162639076184553
train_count_sent: 14041.0
train_total_correct_sent: 13822.0
train_accuracy_sent: 0.9844028203119436
train_count_tok: 203621.0
train_total_correct_tok: 201760.0
train_accuracy_tok: 0.9908604711694766
train_label=0_precision_sent: 0.9618818681318682
train_label=0_recall_sent: 0.962873839807494
train_label=0_f-score_sent: 0.9623775983507988
train_label=1_precision_sent: 0.990295624045287
train_label=1_recall_sent: 0.9900287459575997
train_label=1_f-score_sent: 0.9901621670185525
train_precision_macro_sent: 0.9760887460885777
train_recall_macro_sent: 0.9764512928825468
train_f-score_macro_sent: 0.9762698826846756
train_precision_micro_sent: 0.9844028203119436
train_recall_micro_sent: 0.9844028203119436
train_f-score_micro_sent: 0.9844028203119436
train_label=O_precision_tok: 0.9970356662973527
train_label=O_recall_tok: 0.9976588944320608
train_label=O_f-score_tok: 0.9973471830031068
train_label=LOC_precision_tok: 0.96282886797007
train_label=LOC_recall_tok: 0.961552368325901
train_label=LOC_f-score_tok: 0.9621901947777846
train_label=MISC_precision_tok: 0.9326390427653446
train_label=MISC_recall_tok: 0.9163945133899413
train_label=MISC_f-score_tok: 0.9244454206018011
train_label=ORG_precision_tok: 0.9477320516671673
train_label=ORG_recall_tok: 0.9441396508728179
train_label=ORG_f-score_tok: 0.9459324405356785
train_label=PER_precision_tok: 0.9799121155053359
train_label=PER_recall_tok: 0.9819374550682962
train_label=PER_f-score_tok: 0.9809237398446968
train_precision_macro_tok: 0.9640295488410541
train_recall_macro_tok: 0.9603365764178035
train_f-score_macro_tok: 0.9621677957526135
train_precision_micro_tok: 0.9908604711694766
train_recall_micro_tok: 0.9908604711694766
train_f-score_micro_tok: 0.9908604711694766
train_time: 149.35014009475708
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9619    0.9629    0.9624      2909
           1     0.9903    0.9900    0.9902     11132

   micro avg     0.9844    0.9844    0.9844     14041
   macro avg     0.9761    0.9765    0.9763     14041
weighted avg     0.9844    0.9844    0.9844     14041

F1-macro sent:  0.9762698826846756
F1-micro sent:  0.9844028203119436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9970    0.9977    0.9973    169578
         LOC     0.9628    0.9616    0.9622      8297
        MISC     0.9326    0.9164    0.9244      4593
         ORG     0.9477    0.9441    0.9459     10025
         PER     0.9799    0.9819    0.9809     11128

   micro avg     0.9909    0.9909    0.9909    203621
   macro avg     0.9640    0.9603    0.9622    203621
weighted avg     0.9908    0.9909    0.9908    203621

F1-macro tok:  0.9621677957526135
F1-micro tok:  0.9908604711694766
**************************************************
dev_cost_sum: 2675.3730796575546
dev_cost_avg: 0.8231917168177091
dev_count_sent: 3250.0
dev_total_correct_sent: 3183.0
dev_accuracy_sent: 0.9793846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50751.0
dev_accuracy_tok: 0.9881040457926094
dev_label=0_precision_sent: 0.9164265129682997
dev_label=0_recall_sent: 0.986046511627907
dev_label=0_f-score_sent: 0.9499626587005228
dev_label=1_precision_sent: 0.9964788732394366
dev_label=1_recall_sent: 0.9777351247600767
dev_label=1_f-score_sent: 0.9870180197636116
dev_precision_macro_sent: 0.9564526931038682
dev_recall_macro_sent: 0.9818908181939918
dev_f-score_macro_sent: 0.9684903392320672
dev_precision_micro_sent: 0.9793846153846154
dev_recall_micro_sent: 0.9793846153846154
dev_f-score_micro_sent: 0.9793846153846154
dev_label=O_precision_tok: 0.9955173701905118
dev_label=O_recall_tok: 0.9972169601721275
dev_label=O_f-score_tok: 0.9963664403967707
dev_label=LOC_precision_tok: 0.9540719696969697
dev_label=LOC_recall_tok: 0.9622731614135626
dev_label=LOC_f-score_tok: 0.958155016642891
dev_label=MISC_precision_tok: 0.8986432561851556
dev_label=MISC_recall_tok: 0.88801261829653
dev_label=MISC_f-score_tok: 0.8932963109877033
dev_label=ORG_precision_tok: 0.9561224489795919
dev_label=ORG_recall_tok: 0.8957934990439771
dev_label=ORG_f-score_tok: 0.9249753208292202
dev_label=PER_precision_tok: 0.9659906396255851
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9745042492917848
dev_precision_macro_tok: 0.9540691369355627
dev_recall_macro_tok: 0.9452930998017525
dev_f-score_macro_tok: 0.949459467629674
dev_precision_micro_tok: 0.9881040457926094
dev_recall_micro_tok: 0.9881040457926094
dev_f-score_micro_tok: 0.9881040457926094
dev_time: 9.777780055999756
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9164    0.9860    0.9500       645
           1     0.9965    0.9777    0.9870      2605

   micro avg     0.9794    0.9794    0.9794      3250
   macro avg     0.9565    0.9819    0.9685      3250
weighted avg     0.9806    0.9794    0.9797      3250

F1-macro sent:  0.9684903392320672
F1-micro sent:  0.9793846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9972    0.9964     42759
         LOC     0.9541    0.9623    0.9582      2094
        MISC     0.8986    0.8880    0.8933      1268
         ORG     0.9561    0.8958    0.9250      2092
         PER     0.9660    0.9832    0.9745      3149

   micro avg     0.9881    0.9881    0.9881     51362
   macro avg     0.9541    0.9453    0.9495     51362
weighted avg     0.9880    0.9881    0.9880     51362

F1-macro tok:  0.949459467629674
F1-micro tok:  0.9881040457926094
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 6021.1715886592865
train_cost_avg: 0.42882783196775776
train_count_sent: 14041.0
train_total_correct_sent: 13835.0
train_accuracy_sent: 0.9853286802934264
train_count_tok: 203621.0
train_total_correct_tok: 201872.0
train_accuracy_tok: 0.9914105126681433
train_label=0_precision_sent: 0.9620512820512821
train_label=0_recall_sent: 0.9673427294602956
train_label=0_f-score_sent: 0.9646897497428866
train_label=1_precision_sent: 0.991453760345448
train_label=1_recall_sent: 0.9900287459575997
train_label=1_f-score_sent: 0.9907407407407408
train_precision_macro_sent: 0.976752521198365
train_recall_macro_sent: 0.9786857377089477
train_f-score_macro_sent: 0.9777152452418136
train_precision_micro_sent: 0.9853286802934264
train_recall_micro_sent: 0.9853286802934264
train_f-score_micro_sent: 0.9853286802934264
train_label=O_precision_tok: 0.997188577490938
train_label=O_recall_tok: 0.9977001733715458
train_label=O_f-score_tok: 0.9974443098310061
train_label=LOC_precision_tok: 0.9638758004107768
train_label=LOC_recall_tok: 0.961552368325901
train_label=LOC_f-score_tok: 0.9627126825147821
train_label=MISC_precision_tok: 0.9365810840465219
train_label=MISC_recall_tok: 0.9292401480513826
train_label=MISC_f-score_tok: 0.932896174863388
train_label=ORG_precision_tok: 0.9524764387407259
train_label=ORG_recall_tok: 0.9476309226932669
train_label=ORG_f-score_tok: 0.9500475023751187
train_label=PER_precision_tok: 0.9811625403659849
train_label=PER_recall_tok: 0.9829259525521208
train_label=PER_f-score_tok: 0.9820434548392889
train_precision_macro_tok: 0.9662568882109894
train_recall_macro_tok: 0.9638099129988433
train_f-score_macro_tok: 0.9650288248847169
train_precision_micro_tok: 0.9914105126681433
train_recall_micro_tok: 0.9914105126681433
train_f-score_micro_tok: 0.9914105126681433
train_time: 149.1298108100891
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9621    0.9673    0.9647      2909
           1     0.9915    0.9900    0.9907     11132

   micro avg     0.9853    0.9853    0.9853     14041
   macro avg     0.9768    0.9787    0.9777     14041
weighted avg     0.9854    0.9853    0.9853     14041

F1-macro sent:  0.9777152452418136
F1-micro sent:  0.9853286802934264
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9977    0.9974    169578
         LOC     0.9639    0.9616    0.9627      8297
        MISC     0.9366    0.9292    0.9329      4593
         ORG     0.9525    0.9476    0.9500     10025
         PER     0.9812    0.9829    0.9820     11128

   micro avg     0.9914    0.9914    0.9914    203621
   macro avg     0.9663    0.9638    0.9650    203621
weighted avg     0.9914    0.9914    0.9914    203621

F1-macro tok:  0.9650288248847169
F1-micro tok:  0.9914105126681433
**************************************************
dev_cost_sum: 2689.5927390903234
dev_cost_avg: 0.8275669966431765
dev_count_sent: 3250.0
dev_total_correct_sent: 3201.0
dev_accuracy_sent: 0.9849230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50789.0
dev_accuracy_tok: 0.9888438923717924
dev_label=0_precision_sent: 0.9474474474474475
dev_label=0_recall_sent: 0.9782945736434109
dev_label=0_f-score_sent: 0.9626239511823036
dev_label=1_precision_sent: 0.9945820433436533
dev_label=1_recall_sent: 0.9865642994241842
dev_label=1_f-score_sent: 0.9905569473887069
dev_precision_macro_sent: 0.9710147453955504
dev_recall_macro_sent: 0.9824294365337976
dev_f-score_macro_sent: 0.9765904492855053
dev_precision_micro_sent: 0.9849230769230769
dev_recall_micro_sent: 0.9849230769230769
dev_f-score_micro_sent: 0.9849230769230769
dev_label=O_precision_tok: 0.9964936066761729
dev_label=O_recall_tok: 0.9969597043897191
dev_label=O_f-score_tok: 0.9967266010428114
dev_label=LOC_precision_tok: 0.9599045346062053
dev_label=LOC_recall_tok: 0.9603629417383
dev_label=LOC_f-score_tok: 0.9601336834566724
dev_label=MISC_precision_tok: 0.9027113237639554
dev_label=MISC_recall_tok: 0.8927444794952681
dev_label=MISC_f-score_tok: 0.8977002379064234
dev_label=ORG_precision_tok: 0.9403422982885086
dev_label=ORG_recall_tok: 0.9192160611854685
dev_label=ORG_f-score_tok: 0.9296591733139957
dev_label=PER_precision_tok: 0.9702100972091565
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9763332281476806
dev_precision_macro_tok: 0.9539323721087996
dev_recall_macro_tok: 0.9503634649260573
dev_f-score_macro_tok: 0.9521105847735167
dev_precision_micro_tok: 0.9888438923717924
dev_recall_micro_tok: 0.9888438923717924
dev_f-score_micro_tok: 0.9888438923717924
dev_time: 11.5671706199646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9474    0.9783    0.9626       645
           1     0.9946    0.9866    0.9906      2605

   micro avg     0.9849    0.9849    0.9849      3250
   macro avg     0.9710    0.9824    0.9766      3250
weighted avg     0.9852    0.9849    0.9850      3250

F1-macro sent:  0.9765904492855053
F1-micro sent:  0.9849230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9970    0.9967     42759
         LOC     0.9599    0.9604    0.9601      2094
        MISC     0.9027    0.8927    0.8977      1268
         ORG     0.9403    0.9192    0.9297      2092
         PER     0.9702    0.9825    0.9763      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9539    0.9504    0.9521     51362
weighted avg     0.9888    0.9888    0.9888     51362

F1-macro tok:  0.9521105847735167
F1-micro tok:  0.9888438923717924
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 5964.41785800457
train_cost_avg: 0.4247858313513688
train_count_sent: 14041.0
train_total_correct_sent: 13828.0
train_accuracy_sent: 0.9848301403033972
train_count_tok: 203621.0
train_total_correct_tok: 201891.0
train_accuracy_tok: 0.9915038232795242
train_label=0_precision_sent: 0.9600682593856655
train_label=0_recall_sent: 0.9669989687177725
train_label=0_f-score_sent: 0.9635211508820004
train_label=1_precision_sent: 0.991359913599136
train_label=1_recall_sent: 0.9894897592526051
train_label=1_f-score_sent: 0.9904239536033809
train_precision_macro_sent: 0.9757140864924008
train_recall_macro_sent: 0.9782443639851888
train_f-score_macro_sent: 0.9769725522426906
train_precision_micro_sent: 0.9848301403033972
train_recall_micro_sent: 0.9848301403033972
train_f-score_micro_sent: 0.9848301403033972
train_label=O_precision_tok: 0.997235810691342
train_label=O_recall_tok: 0.997776834259161
train_label=O_f-score_tok: 0.9975062491156912
train_label=LOC_precision_tok: 0.9647895815748221
train_label=LOC_recall_tok: 0.9643244546221525
train_label=LOC_f-score_tok: 0.9645569620253165
train_label=MISC_precision_tok: 0.939027074620295
train_label=MISC_recall_tok: 0.9288047028086218
train_label=MISC_f-score_tok: 0.9338879159369528
train_label=ORG_precision_tok: 0.9514194322271091
train_label=ORG_recall_tok: 0.949426433915212
train_label=ORG_f-score_tok: 0.9504218882620201
train_label=PER_precision_tok: 0.981459814598146
train_label=PER_recall_tok: 0.979960460100647
train_label=PER_f-score_tok: 0.9807095642789694
train_precision_macro_tok: 0.9667863427423429
train_recall_macro_tok: 0.9640585771411588
train_f-score_macro_tok: 0.96541651592379
train_precision_micro_tok: 0.9915038232795242
train_recall_micro_tok: 0.9915038232795242
train_f-score_micro_tok: 0.9915038232795242
train_time: 146.84054708480835
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9601    0.9670    0.9635      2909
           1     0.9914    0.9895    0.9904     11132

   micro avg     0.9848    0.9848    0.9848     14041
   macro avg     0.9757    0.9782    0.9770     14041
weighted avg     0.9849    0.9848    0.9849     14041

F1-macro sent:  0.9769725522426906
F1-micro sent:  0.9848301403033972
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9972    0.9978    0.9975    169578
         LOC     0.9648    0.9643    0.9646      8297
        MISC     0.9390    0.9288    0.9339      4593
         ORG     0.9514    0.9494    0.9504     10025
         PER     0.9815    0.9800    0.9807     11128

   micro avg     0.9915    0.9915    0.9915    203621
   macro avg     0.9668    0.9641    0.9654    203621
weighted avg     0.9915    0.9915    0.9915    203621

F1-macro tok:  0.96541651592379
F1-micro tok:  0.9915038232795242
**************************************************
dev_cost_sum: 2876.5927563756704
dev_cost_avg: 0.8851054635002062
dev_count_sent: 3250.0
dev_total_correct_sent: 3205.0
dev_accuracy_sent: 0.9861538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50765.0
dev_accuracy_tok: 0.9883766208480979
dev_label=0_precision_sent: 0.9424778761061947
dev_label=0_recall_sent: 0.9906976744186047
dev_label=0_f-score_sent: 0.9659863945578232
dev_label=1_precision_sent: 0.9976671850699844
dev_label=1_recall_sent: 0.9850287907869482
dev_label=1_f-score_sent: 0.9913077071663124
dev_precision_macro_sent: 0.9700725305880895
dev_recall_macro_sent: 0.9878632326027764
dev_f-score_macro_sent: 0.9786470508620678
dev_precision_micro_sent: 0.9861538461538462
dev_recall_micro_sent: 0.9861538461538462
dev_f-score_micro_sent: 0.9861538461538462
dev_label=O_precision_tok: 0.994663373027895
dev_label=O_recall_tok: 0.9981992095231413
dev_label=O_f-score_tok: 0.9964281545465157
dev_label=LOC_precision_tok: 0.9481792717086834
dev_label=LOC_recall_tok: 0.9699140401146131
dev_label=LOC_f-score_tok: 0.9589235127478754
dev_label=MISC_precision_tok: 0.9326424870466321
dev_label=MISC_recall_tok: 0.8517350157728707
dev_label=MISC_f-score_tok: 0.8903544929925804
dev_label=ORG_precision_tok: 0.9553299492385787
dev_label=ORG_recall_tok: 0.8996175908221797
dev_label=ORG_f-score_tok: 0.9266371245691778
dev_label=PER_precision_tok: 0.9713926438226973
dev_label=PER_recall_tok: 0.9812638932994602
dev_label=PER_f-score_tok: 0.976303317535545
dev_precision_macro_tok: 0.9604415449688973
dev_recall_macro_tok: 0.9401459499064531
dev_f-score_macro_tok: 0.9497293204783389
dev_precision_micro_tok: 0.9883766208480979
dev_recall_micro_tok: 0.9883766208480979
dev_f-score_micro_tok: 0.9883766208480979
dev_time: 13.914758443832397
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9425    0.9907    0.9660       645
           1     0.9977    0.9850    0.9913      2605

   micro avg     0.9862    0.9862    0.9862      3250
   macro avg     0.9701    0.9879    0.9786      3250
weighted avg     0.9867    0.9862    0.9863      3250

F1-macro sent:  0.9786470508620678
F1-micro sent:  0.9861538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9982    0.9964     42759
         LOC     0.9482    0.9699    0.9589      2094
        MISC     0.9326    0.8517    0.8904      1268
         ORG     0.9553    0.8996    0.9266      2092
         PER     0.9714    0.9813    0.9763      3149

   micro avg     0.9884    0.9884    0.9884     51362
   macro avg     0.9604    0.9401    0.9497     51362
weighted avg     0.9882    0.9884    0.9882     51362

F1-macro tok:  0.9497293204783389
F1-micro tok:  0.9883766208480979
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 5648.957307398319
train_cost_avg: 0.4023187313865337
train_count_sent: 14041.0
train_total_correct_sent: 13862.0
train_accuracy_sent: 0.9872516202549676
train_count_tok: 203621.0
train_total_correct_tok: 202052.0
train_accuracy_tok: 0.9922945079338575
train_label=0_precision_sent: 0.9668262653898769
train_label=0_recall_sent: 0.9718116191130973
train_label=0_f-score_sent: 0.9693125321446939
train_label=1_precision_sent: 0.9926239093280561
train_label=1_recall_sent: 0.9912863816025871
train_label=1_f-score_sent: 0.9919546945930153
train_precision_macro_sent: 0.9797250873589665
train_recall_macro_sent: 0.9815490003578422
train_f-score_macro_sent: 0.9806336133688547
train_precision_micro_sent: 0.9872516202549676
train_recall_micro_sent: 0.9872516202549676
train_f-score_micro_sent: 0.9872516202549676
train_label=O_precision_tok: 0.9974360485677237
train_label=O_recall_tok: 0.9979183620516813
train_label=O_f-score_tok: 0.997677147017728
train_label=LOC_precision_tok: 0.9687046882551957
train_label=LOC_recall_tok: 0.9662528624804146
train_label=LOC_f-score_tok: 0.9674772219875702
train_label=MISC_precision_tok: 0.9434294519040282
train_label=MISC_recall_tok: 0.933159155236229
train_label=MISC_f-score_tok: 0.9382661996497373
train_label=ORG_precision_tok: 0.9573829531812725
train_label=ORG_recall_tok: 0.9546134663341646
train_label=ORG_f-score_tok: 0.9559962039858149
train_label=PER_precision_tok: 0.9827740893594115
train_label=PER_recall_tok: 0.9843637670740475
train_label=PER_f-score_tok: 0.9835682858938674
train_precision_macro_tok: 0.9699454462535263
train_recall_macro_tok: 0.9672615226353074
train_f-score_macro_tok: 0.9685970117069436
train_precision_micro_tok: 0.9922945079338575
train_recall_micro_tok: 0.9922945079338575
train_f-score_micro_tok: 0.9922945079338575
train_time: 144.41335129737854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9668    0.9718    0.9693      2909
           1     0.9926    0.9913    0.9920     11132

   micro avg     0.9873    0.9873    0.9873     14041
   macro avg     0.9797    0.9815    0.9806     14041
weighted avg     0.9873    0.9873    0.9873     14041

F1-macro sent:  0.9806336133688547
F1-micro sent:  0.9872516202549676
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9974    0.9979    0.9977    169578
         LOC     0.9687    0.9663    0.9675      8297
        MISC     0.9434    0.9332    0.9383      4593
         ORG     0.9574    0.9546    0.9560     10025
         PER     0.9828    0.9844    0.9836     11128

   micro avg     0.9923    0.9923    0.9923    203621
   macro avg     0.9699    0.9673    0.9686    203621
weighted avg     0.9923    0.9923    0.9923    203621

F1-macro tok:  0.9685970117069436
F1-micro tok:  0.9922945079338575
**************************************************
dev_cost_sum: 2882.4555042758584
dev_cost_avg: 0.8869093859310333
dev_count_sent: 3250.0
dev_total_correct_sent: 3206.0
dev_accuracy_sent: 0.9864615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50775.0
dev_accuracy_tok: 0.9885713173163039
dev_label=0_precision_sent: 0.9854604200323102
dev_label=0_recall_sent: 0.9457364341085271
dev_label=0_f-score_sent: 0.9651898734177214
dev_label=1_precision_sent: 0.9866970733561383
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9915966386554622
dev_precision_macro_sent: 0.9860787466942242
dev_recall_macro_sent: 0.971140769837373
dev_f-score_macro_sent: 0.9783932560365918
dev_precision_micro_sent: 0.9864615384615385
dev_recall_micro_sent: 0.9864615384615385
dev_f-score_micro_sent: 0.9864615384615385
dev_label=O_precision_tok: 0.9954735294803891
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9966362213553224
dev_label=LOC_precision_tok: 0.9583732057416268
dev_label=LOC_recall_tok: 0.9565425023877746
dev_label=LOC_f-score_tok: 0.9574569789674952
dev_label=MISC_precision_tok: 0.9328743545611016
dev_label=MISC_recall_tok: 0.8548895899053628
dev_label=MISC_f-score_tok: 0.8921810699588478
dev_label=ORG_precision_tok: 0.9342359767891683
dev_label=ORG_recall_tok: 0.9235181644359465
dev_label=ORG_f-score_tok: 0.928846153846154
dev_label=PER_precision_tok: 0.9710964498900408
dev_label=PER_recall_tok: 0.9815814544299778
dev_label=PER_f-score_tok: 0.976310802274163
dev_precision_macro_tok: 0.9584107032924652
dev_recall_macro_tok: 0.9428666687127871
dev_f-score_macro_tok: 0.9502862452803965
dev_precision_micro_tok: 0.9885713173163039
dev_recall_micro_tok: 0.9885713173163039
dev_f-score_micro_tok: 0.9885713173163039
dev_time: 13.646202564239502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9855    0.9457    0.9652       645
           1     0.9867    0.9965    0.9916      2605

   micro avg     0.9865    0.9865    0.9865      3250
   macro avg     0.9861    0.9711    0.9784      3250
weighted avg     0.9865    0.9865    0.9864      3250

F1-macro sent:  0.9783932560365918
F1-micro sent:  0.9864615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9955    0.9978    0.9966     42759
         LOC     0.9584    0.9565    0.9575      2094
        MISC     0.9329    0.8549    0.8922      1268
         ORG     0.9342    0.9235    0.9288      2092
         PER     0.9711    0.9816    0.9763      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9584    0.9429    0.9503     51362
weighted avg     0.9884    0.9886    0.9885     51362

F1-macro tok:  0.9502862452803965
F1-micro tok:  0.9885713173163039
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 5075.069012075663
train_cost_avg: 0.36144640781110055
train_count_sent: 14041.0
train_total_correct_sent: 13860.0
train_accuracy_sent: 0.9871091802578164
train_count_tok: 203621.0
train_total_correct_tok: 202145.0
train_accuracy_tok: 0.9927512388211432
train_label=0_precision_sent: 0.9696969696969697
train_label=0_recall_sent: 0.968030250945342
train_label=0_f-score_sent: 0.9688628935145365
train_label=1_precision_sent: 0.9916494567657358
train_label=1_recall_sent: 0.9920948616600791
train_label=1_f-score_sent: 0.9918721092101127
train_precision_macro_sent: 0.9806732132313527
train_recall_macro_sent: 0.9800625563027106
train_f-score_macro_sent: 0.9803675013623245
train_precision_micro_sent: 0.9871091802578164
train_recall_micro_sent: 0.9871091802578164
train_f-score_micro_sent: 0.9871091802578164
train_label=O_precision_tok: 0.9976774756400205
train_label=O_recall_tok: 0.9980598898442015
train_label=O_f-score_tok: 0.9978686461038673
train_label=LOC_precision_tok: 0.9678584326471651
train_label=LOC_recall_tok: 0.9690249487766662
train_label=LOC_f-score_tok: 0.9684413394362804
train_label=MISC_precision_tok: 0.9537405931828242
train_label=MISC_recall_tok: 0.9381667755279773
train_label=MISC_f-score_tok: 0.9458895840193172
train_label=ORG_precision_tok: 0.9581627558662007
train_label=ORG_recall_tok: 0.9572069825436409
train_label=ORG_f-score_tok: 0.957684630738523
train_label=PER_precision_tok: 0.9832106302747351
train_label=PER_recall_tok: 0.9840941768511862
train_label=PER_f-score_tok: 0.983652205155843
train_precision_macro_tok: 0.972129977522189
train_recall_macro_tok: 0.9693105547087344
train_f-score_macro_tok: 0.9707072810907661
train_precision_micro_tok: 0.9927512388211432
train_recall_micro_tok: 0.9927512388211432
train_f-score_micro_tok: 0.9927512388211432
train_time: 145.07535982131958
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9697    0.9680    0.9689      2909
           1     0.9916    0.9921    0.9919     11132

   micro avg     0.9871    0.9871    0.9871     14041
   macro avg     0.9807    0.9801    0.9804     14041
weighted avg     0.9871    0.9871    0.9871     14041

F1-macro sent:  0.9803675013623245
F1-micro sent:  0.9871091802578164
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9977    0.9981    0.9979    169578
         LOC     0.9679    0.9690    0.9684      8297
        MISC     0.9537    0.9382    0.9459      4593
         ORG     0.9582    0.9572    0.9577     10025
         PER     0.9832    0.9841    0.9837     11128

   micro avg     0.9928    0.9928    0.9928    203621
   macro avg     0.9721    0.9693    0.9707    203621
weighted avg     0.9927    0.9928    0.9927    203621

F1-macro tok:  0.9707072810907661
F1-micro tok:  0.9927512388211432
**************************************************
dev_cost_sum: 2856.577468007803
dev_cost_avg: 0.8789469132331701
dev_count_sent: 3250.0
dev_total_correct_sent: 3222.0
dev_accuracy_sent: 0.9913846153846154
dev_count_tok: 51362.0
dev_total_correct_tok: 50762.0
dev_accuracy_tok: 0.988318211907636
dev_label=0_precision_sent: 0.9827856025039123
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9781931464174455
dev_label=1_precision_sent: 0.9934890846418997
dev_label=1_recall_sent: 0.9957773512476008
dev_label=1_f-score_sent: 0.9946319018404908
dev_precision_macro_sent: 0.988137343572906
dev_recall_macro_sent: 0.984710381050157
dev_f-score_macro_sent: 0.9864125241289681
dev_precision_micro_sent: 0.9913846153846154
dev_recall_micro_sent: 0.9913846153846154
dev_f-score_micro_sent: 0.9913846153846154
dev_label=O_precision_tok: 0.995356867869059
dev_label=O_recall_tok: 0.9976846979583246
dev_label=O_f-score_tok: 0.9965194234857156
dev_label=LOC_precision_tok: 0.9599618684461392
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.9608778625954199
dev_label=MISC_precision_tok: 0.8894117647058823
dev_label=MISC_recall_tok: 0.8943217665615142
dev_label=MISC_f-score_tok: 0.8918600078647266
dev_label=ORG_precision_tok: 0.9606625258799172
dev_label=ORG_recall_tok: 0.887189292543021
dev_label=ORG_f-score_tok: 0.9224652087475149
dev_label=PER_precision_tok: 0.9687304565353346
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.9762092327083662
dev_precision_macro_tok: 0.9548246966872664
dev_recall_macro_tok: 0.9449591491802416
dev_f-score_macro_tok: 0.9495863470803487
dev_precision_micro_tok: 0.988318211907636
dev_recall_micro_tok: 0.988318211907636
dev_f-score_micro_tok: 0.988318211907636
dev_time: 13.806682109832764
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9828    0.9736    0.9782       645
           1     0.9935    0.9958    0.9946      2605

   micro avg     0.9914    0.9914    0.9914      3250
   macro avg     0.9881    0.9847    0.9864      3250
weighted avg     0.9914    0.9914    0.9914      3250

F1-macro sent:  0.9864125241289681
F1-micro sent:  0.9913846153846154
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9977    0.9965     42759
         LOC     0.9600    0.9618    0.9609      2094
        MISC     0.8894    0.8943    0.8919      1268
         ORG     0.9607    0.8872    0.9225      2092
         PER     0.9687    0.9838    0.9762      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9548    0.9450    0.9496     51362
weighted avg     0.9883    0.9883    0.9882     51362

F1-macro tok:  0.9495863470803487
F1-micro tok:  0.988318211907636
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 4998.866379618645
train_cost_avg: 0.35601925643605475
train_count_sent: 14041.0
train_total_correct_sent: 13851.0
train_accuracy_sent: 0.986468200270636
train_count_tok: 203621.0
train_total_correct_tok: 202174.0
train_accuracy_tok: 0.9928936602806194
train_label=0_precision_sent: 0.9670216420474064
train_label=0_recall_sent: 0.9676864902028188
train_label=0_f-score_sent: 0.9673539518900344
train_label=1_precision_sent: 0.9915543575920934
train_label=1_recall_sent: 0.9913762127200862
train_label=1_f-score_sent: 0.9914652771538944
train_precision_macro_sent: 0.9792879998197499
train_recall_macro_sent: 0.9795313514614525
train_f-score_macro_sent: 0.9794096145219644
train_precision_micro_sent: 0.986468200270636
train_recall_micro_sent: 0.986468200270636
train_f-score_micro_sent: 0.986468200270636
train_label=O_precision_tok: 0.9977184832335046
train_label=O_recall_tok: 0.9979891259479413
train_label=O_f-score_tok: 0.9978537862394679
train_label=LOC_precision_tok: 0.9702050663449939
train_label=LOC_recall_tok: 0.9693865252500904
train_label=LOC_f-score_tok: 0.9697956230783144
train_label=MISC_precision_tok: 0.9480035103115402
train_label=MISC_recall_tok: 0.9407794469845417
train_label=MISC_f-score_tok: 0.9443776636433178
train_label=ORG_precision_tok: 0.9593447208071122
train_label=ORG_recall_tok: 0.958004987531172
train_label=ORG_f-score_tok: 0.958674386105011
train_label=PER_precision_tok: 0.9848267193391992
train_label=PER_recall_tok: 0.9857117181883537
train_label=PER_f-score_tok: 0.98526902003054
train_precision_macro_tok: 0.97201970000727
train_recall_macro_tok: 0.9703743607804197
train_f-score_macro_tok: 0.9711940958193301
train_precision_micro_tok: 0.9928936602806194
train_recall_micro_tok: 0.9928936602806194
train_f-score_micro_tok: 0.9928936602806194
train_time: 145.84832906723022
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9670    0.9677    0.9674      2909
           1     0.9916    0.9914    0.9915     11132

   micro avg     0.9865    0.9865    0.9865     14041
   macro avg     0.9793    0.9795    0.9794     14041
weighted avg     0.9865    0.9865    0.9865     14041

F1-macro sent:  0.9794096145219644
F1-micro sent:  0.986468200270636
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9977    0.9980    0.9979    169578
         LOC     0.9702    0.9694    0.9698      8297
        MISC     0.9480    0.9408    0.9444      4593
         ORG     0.9593    0.9580    0.9587     10025
         PER     0.9848    0.9857    0.9853     11128

   micro avg     0.9929    0.9929    0.9929    203621
   macro avg     0.9720    0.9704    0.9712    203621
weighted avg     0.9929    0.9929    0.9929    203621

F1-macro tok:  0.9711940958193301
F1-micro tok:  0.9928936602806194
**************************************************
dev_cost_sum: 2990.496866032481
dev_cost_avg: 0.9201528818561481
dev_count_sent: 3250.0
dev_total_correct_sent: 3215.0
dev_accuracy_sent: 0.9892307692307692
dev_count_tok: 51362.0
dev_total_correct_tok: 50777.0
dev_accuracy_tok: 0.9886102566099451
dev_label=0_precision_sent: 0.9750778816199377
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9728049728049727
dev_label=1_precision_sent: 0.9927147239263804
dev_label=1_recall_sent: 0.9938579654510556
dev_label=1_f-score_sent: 0.9932860157299059
dev_precision_macro_sent: 0.9838963027731591
dev_recall_macro_sent: 0.9822003005549852
dev_f-score_macro_sent: 0.9830454942674394
dev_precision_micro_sent: 0.9892307692307692
dev_recall_micro_sent: 0.9892307692307692
dev_f-score_micro_sent: 0.9892307692307692
dev_label=O_precision_tok: 0.9956122949097953
dev_label=O_recall_tok: 0.9976613110690147
dev_label=O_f-score_tok: 0.9966357498306192
dev_label=LOC_precision_tok: 0.9530516431924883
dev_label=LOC_recall_tok: 0.9694364851957975
dev_label=LOC_f-score_tok: 0.9611742424242424
dev_label=MISC_precision_tok: 0.9032258064516129
dev_label=MISC_recall_tok: 0.8832807570977917
dev_label=MISC_f-score_tok: 0.8931419457735247
dev_label=ORG_precision_tok: 0.9585253456221198
dev_label=ORG_recall_tok: 0.8948374760994264
dev_label=ORG_f-score_tok: 0.9255871446229914
dev_label=PER_precision_tok: 0.9699248120300752
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9765021290017347
dev_precision_macro_tok: 0.9560679804412183
dev_recall_macro_tok: 0.9456770579089191
dev_f-score_macro_tok: 0.9506082423306225
dev_precision_micro_tok: 0.9886102566099451
dev_recall_micro_tok: 0.9886102566099451
dev_f-score_micro_tok: 0.9886102566099451
dev_time: 14.062427282333374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9751    0.9705    0.9728       645
           1     0.9927    0.9939    0.9933      2605

   micro avg     0.9892    0.9892    0.9892      3250
   macro avg     0.9839    0.9822    0.9830      3250
weighted avg     0.9892    0.9892    0.9892      3250

F1-macro sent:  0.9830454942674394
F1-micro sent:  0.9892307692307692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9956    0.9977    0.9966     42759
         LOC     0.9531    0.9694    0.9612      2094
        MISC     0.9032    0.8833    0.8931      1268
         ORG     0.9585    0.8948    0.9256      2092
         PER     0.9699    0.9832    0.9765      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9561    0.9457    0.9506     51362
weighted avg     0.9885    0.9886    0.9885     51362

F1-macro tok:  0.9506082423306225
F1-micro tok:  0.9886102566099451
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 4566.176618218422
train_cost_avg: 0.3252030922454542
train_count_sent: 14041.0
train_total_correct_sent: 13886.0
train_accuracy_sent: 0.988960900220782
train_count_tok: 203621.0
train_total_correct_tok: 202268.0
train_accuracy_tok: 0.9933553022527146
train_label=0_precision_sent: 0.9758120248790602
train_label=0_recall_sent: 0.9707803368855277
train_label=0_f-score_sent: 0.9732896777528863
train_label=1_precision_sent: 0.9923746299452768
train_label=1_recall_sent: 0.9937118217750629
train_label=1_f-score_sent: 0.993042775708066
train_precision_macro_sent: 0.9840933274121685
train_recall_macro_sent: 0.9822460793302953
train_f-score_macro_sent: 0.9831662267304762
train_precision_micro_sent: 0.988960900220782
train_recall_micro_sent: 0.988960900220782
train_f-score_micro_sent: 0.988960900220782
train_label=O_precision_tok: 0.9980367302420187
train_label=O_recall_tok: 0.9982544905589168
train_label=O_f-score_tok: 0.9981455985235543
train_label=LOC_precision_tok: 0.9713356618089847
train_label=LOC_recall_tok: 0.9720380860552007
train_label=LOC_f-score_tok: 0.9716867469879518
train_label=MISC_precision_tok: 0.951021304634307
train_label=MISC_recall_tok: 0.942738950576965
train_label=MISC_f-score_tok: 0.9468620161819375
train_label=ORG_precision_tok: 0.9629666700030027
train_label=ORG_recall_tok: 0.9597007481296758
train_label=ORG_f-score_tok: 0.9613309352517986
train_label=PER_precision_tok: 0.983062998476566
train_label=PER_recall_tok: 0.9858015815959741
train_label=PER_f-score_tok: 0.9844303854264818
train_precision_macro_tok: 0.9732846730329758
train_recall_macro_tok: 0.9717067713833465
train_f-score_macro_tok: 0.9724911364743448
train_precision_micro_tok: 0.9933553022527146
train_recall_micro_tok: 0.9933553022527146
train_f-score_micro_tok: 0.9933553022527146
train_time: 146.01267957687378
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9758    0.9708    0.9733      2909
           1     0.9924    0.9937    0.9930     11132

   micro avg     0.9890    0.9890    0.9890     14041
   macro avg     0.9841    0.9822    0.9832     14041
weighted avg     0.9889    0.9890    0.9890     14041

F1-macro sent:  0.9831662267304762
F1-micro sent:  0.988960900220782
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9983    0.9981    169578
         LOC     0.9713    0.9720    0.9717      8297
        MISC     0.9510    0.9427    0.9469      4593
         ORG     0.9630    0.9597    0.9613     10025
         PER     0.9831    0.9858    0.9844     11128

   micro avg     0.9934    0.9934    0.9934    203621
   macro avg     0.9733    0.9717    0.9725    203621
weighted avg     0.9933    0.9934    0.9933    203621

F1-macro tok:  0.9724911364743448
F1-micro tok:  0.9933553022527146
**************************************************
dev_cost_sum: 2909.1200841516256
dev_cost_avg: 0.895113872046654
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50783.0
dev_accuracy_tok: 0.9887270744908687
dev_label=0_precision_sent: 0.9828125
dev_label=0_recall_sent: 0.9751937984496124
dev_label=0_f-score_sent: 0.978988326848249
dev_label=1_precision_sent: 0.9938697318007663
dev_label=1_recall_sent: 0.9957773512476008
dev_label=1_f-score_sent: 0.9948226270373922
dev_precision_macro_sent: 0.9883411159003832
dev_recall_macro_sent: 0.9854855748486067
dev_f-score_macro_sent: 0.9869054769428206
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9954275049574245
dev_label=O_recall_tok: 0.9978951799621132
dev_label=O_f-score_tok: 0.9966598150051388
dev_label=LOC_precision_tok: 0.954331450094162
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9611190137505927
dev_label=MISC_precision_tok: 0.9
dev_label=MISC_recall_tok: 0.887223974763407
dev_label=MISC_f-score_tok: 0.8935663224781574
dev_label=ORG_precision_tok: 0.9591628381827463
dev_label=ORG_recall_tok: 0.8981835564053537
dev_label=ORG_f-score_tok: 0.9276721797087139
dev_label=PER_precision_tok: 0.9743994943109987
dev_label=PER_recall_tok: 0.9790409653858367
dev_label=PER_f-score_tok: 0.9767147156660858
dev_precision_macro_tok: 0.9566642575090663
dev_recall_macro_tok: 0.9460694993912122
dev_f-score_macro_tok: 0.9511464093217377
dev_precision_micro_tok: 0.9887270744908687
dev_recall_micro_tok: 0.9887270744908687
dev_f-score_micro_tok: 0.9887270744908687
dev_time: 13.814733743667603
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9828    0.9752    0.9790       645
           1     0.9939    0.9958    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9883    0.9855    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9869054769428206
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9979    0.9967     42759
         LOC     0.9543    0.9680    0.9611      2094
        MISC     0.9000    0.8872    0.8936      1268
         ORG     0.9592    0.8982    0.9277      2092
         PER     0.9744    0.9790    0.9767      3149

   micro avg     0.9887    0.9887    0.9887     51362
   macro avg     0.9567    0.9461    0.9511     51362
weighted avg     0.9886    0.9887    0.9886     51362

F1-macro tok:  0.9511464093217377
F1-micro tok:  0.9887270744908687
**************************************************
Best epoch: 23
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 4615.205400049686
train_cost_avg: 0.3286949220176402
train_count_sent: 14041.0
train_total_correct_sent: 13897.0
train_accuracy_sent: 0.9897443202051136
train_count_tok: 203621.0
train_total_correct_tok: 202267.0
train_accuracy_tok: 0.9933503911679051
train_label=0_precision_sent: 0.9755761953904368
train_label=0_recall_sent: 0.9749054657958062
train_label=0_f-score_sent: 0.9752407152682255
train_label=1_precision_sent: 0.9934435063768636
train_label=1_recall_sent: 0.9936219906575637
train_label=1_f-score_sent: 0.9935327405012127
train_precision_macro_sent: 0.9845098508836503
train_recall_macro_sent: 0.984263728226685
train_f-score_macro_sent: 0.9843867278847191
train_precision_micro_sent: 0.9897443202051136
train_recall_micro_sent: 0.9897443202051136
train_f-score_micro_sent: 0.9897443202051136
train_label=O_precision_tok: 0.9978599978776839
train_label=O_recall_tok: 0.9981424477231716
train_label=O_f-score_tok: 0.9980012028160045
train_label=LOC_precision_tok: 0.9725779173713457
train_label=LOC_recall_tok: 0.9703507291792214
train_label=LOC_f-score_tok: 0.9714630467571643
train_label=MISC_precision_tok: 0.9488636363636364
train_label=MISC_recall_tok: 0.9453516220335293
train_label=MISC_f-score_tok: 0.9471043734322173
train_label=ORG_precision_tok: 0.9633413461538461
train_label=ORG_recall_tok: 0.9594014962593517
train_label=ORG_f-score_tok: 0.9613673846768954
train_label=PER_precision_tok: 0.9853007080756476
train_label=PER_recall_tok: 0.9878684399712437
train_label=PER_f-score_tok: 0.9865829032981827
train_precision_macro_tok: 0.973588721168432
train_recall_macro_tok: 0.9722229470333035
train_f-score_macro_tok: 0.9729037821960927
train_precision_micro_tok: 0.9933503911679051
train_recall_micro_tok: 0.9933503911679051
train_f-score_micro_tok: 0.9933503911679051
train_time: 146.3547134399414
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9756    0.9749    0.9752      2909
           1     0.9934    0.9936    0.9935     11132

   micro avg     0.9897    0.9897    0.9897     14041
   macro avg     0.9845    0.9843    0.9844     14041
weighted avg     0.9897    0.9897    0.9897     14041

F1-macro sent:  0.9843867278847191
F1-micro sent:  0.9897443202051136
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9979    0.9981    0.9980    169578
         LOC     0.9726    0.9704    0.9715      8297
        MISC     0.9489    0.9454    0.9471      4593
         ORG     0.9633    0.9594    0.9614     10025
         PER     0.9853    0.9879    0.9866     11128

   micro avg     0.9934    0.9934    0.9934    203621
   macro avg     0.9736    0.9722    0.9729    203621
weighted avg     0.9933    0.9934    0.9933    203621

F1-macro tok:  0.9729037821960927
F1-micro tok:  0.9933503911679051
**************************************************
dev_cost_sum: 2934.6219111159444
dev_cost_avg: 0.9029605880356752
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50778.0
dev_accuracy_tok: 0.9886297262567657
dev_label=0_precision_sent: 0.9722222222222222
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9744779582366588
dev_label=1_precision_sent: 0.9942352036894696
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9936623775686576
dev_precision_macro_sent: 0.9832287129558459
dev_recall_macro_sent: 0.9849171985894747
dev_f-score_macro_sent: 0.9840701679026582
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9960299852875926
dev_label=O_recall_tok: 0.9974742159545359
dev_label=O_f-score_tok: 0.9967515774713718
dev_label=LOC_precision_tok: 0.946021405304793
dev_label=LOC_recall_tok: 0.9708691499522445
dev_label=LOC_f-score_tok: 0.9582842328541127
dev_label=MISC_precision_tok: 0.9068273092369478
dev_label=MISC_recall_tok: 0.8903785488958991
dev_label=MISC_f-score_tok: 0.8985276561878233
dev_label=ORG_precision_tok: 0.958120531154239
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.9264197530864198
dev_label=PER_precision_tok: 0.9686422075885858
dev_label=PER_recall_tok: 0.9809463321689426
dev_label=PER_f-score_tok: 0.9747554433575261
dev_precision_macro_tok: 0.9551282877144315
dev_recall_macro_tok: 0.94728355379203
dev_f-score_macro_tok: 0.9509477325914506
dev_precision_micro_tok: 0.9886297262567657
dev_recall_micro_tok: 0.9886297262567657
dev_f-score_micro_tok: 0.9886297262567657
dev_time: 13.71701955795288
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9722    0.9767    0.9745       645
           1     0.9942    0.9931    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9832    0.9849    0.9841      3250
weighted avg     0.9899    0.9898    0.9899      3250

F1-macro sent:  0.9840701679026582
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9975    0.9968     42759
         LOC     0.9460    0.9709    0.9583      2094
        MISC     0.9068    0.8904    0.8985      1268
         ORG     0.9581    0.8967    0.9264      2092
         PER     0.9686    0.9809    0.9748      3149

   micro avg     0.9886    0.9886    0.9886     51362
   macro avg     0.9551    0.9473    0.9509     51362
weighted avg     0.9886    0.9886    0.9885     51362

F1-macro tok:  0.9509477325914506
F1-micro tok:  0.9886297262567657
**************************************************
Best epoch: 23
**************************************************

EPOCH: 25
Learning rate: 0.900000
train_cost_sum: 4096.119601249695
train_cost_avg: 0.2917256321664906
train_count_sent: 14041.0
train_total_correct_sent: 13894.0
train_accuracy_sent: 0.9895306602093868
train_count_tok: 203621.0
train_total_correct_tok: 202467.0
train_accuracy_tok: 0.9943326081298098
train_label=0_precision_sent: 0.9745704467353952
train_label=0_recall_sent: 0.9749054657958062
train_label=0_f-score_sent: 0.9747379274789483
train_label=1_precision_sent: 0.9934417392866769
train_label=1_recall_sent: 0.9933524973050665
train_label=1_f-score_sent: 0.993397116291605
train_precision_macro_sent: 0.984006093011036
train_recall_macro_sent: 0.9841289815504364
train_f-score_macro_sent: 0.9840675218852766
train_precision_micro_sent: 0.9895306602093868
train_recall_micro_sent: 0.9895306602093868
train_f-score_micro_sent: 0.9895306602093868
train_label=O_precision_tok: 0.9981900079002912
train_label=O_recall_tok: 0.9984019153427921
train_label=O_f-score_tok: 0.9982959503761881
train_label=LOC_precision_tok: 0.9751926782273603
train_label=LOC_recall_tok: 0.976015427262866
train_label=LOC_f-score_tok: 0.9756038792843804
train_label=MISC_precision_tok: 0.9623762376237623
train_label=MISC_recall_tok: 0.9523187459177008
train_label=MISC_f-score_tok: 0.9573210768220616
train_label=ORG_precision_tok: 0.9681031896810319
train_label=ORG_recall_tok: 0.9657855361596009
train_label=ORG_f-score_tok: 0.9669429741336262
train_label=PER_precision_tok: 0.9864658958501389
train_label=PER_recall_tok: 0.9890366642703091
train_label=PER_f-score_tok: 0.9877496073592102
train_precision_macro_tok: 0.9780656018565169
train_recall_macro_tok: 0.9763116577906539
train_f-score_macro_tok: 0.9771826975950934
train_precision_micro_tok: 0.9943326081298098
train_recall_micro_tok: 0.9943326081298098
train_f-score_micro_tok: 0.9943326081298098
train_time: 145.16844534873962
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9746    0.9749    0.9747      2909
           1     0.9934    0.9934    0.9934     11132

   micro avg     0.9895    0.9895    0.9895     14041
   macro avg     0.9840    0.9841    0.9841     14041
weighted avg     0.9895    0.9895    0.9895     14041

F1-macro sent:  0.9840675218852766
F1-micro sent:  0.9895306602093868
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9984    0.9983    169578
         LOC     0.9752    0.9760    0.9756      8297
        MISC     0.9624    0.9523    0.9573      4593
         ORG     0.9681    0.9658    0.9669     10025
         PER     0.9865    0.9890    0.9877     11128

   micro avg     0.9943    0.9943    0.9943    203621
   macro avg     0.9781    0.9763    0.9772    203621
weighted avg     0.9943    0.9943    0.9943    203621

F1-macro tok:  0.9771826975950934
F1-micro tok:  0.9943326081298098
**************************************************
dev_cost_sum: 2952.1693381890655
dev_cost_avg: 0.9083597963658663
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50788.0
dev_accuracy_tok: 0.9888244227249717
dev_label=0_precision_sent: 0.9708141321044547
dev_label=0_recall_sent: 0.9798449612403101
dev_label=0_f-score_sent: 0.9753086419753086
dev_label=1_precision_sent: 0.9949980761831474
dev_label=1_recall_sent: 0.9927063339731286
dev_label=1_f-score_sent: 0.9938508839354343
dev_precision_macro_sent: 0.982906104143801
dev_recall_macro_sent: 0.9862756476067194
dev_f-score_macro_sent: 0.9845797629553714
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.996261594897077
dev_label=O_recall_tok: 0.9971935732828177
dev_label=O_f-score_tok: 0.9967273662310947
dev_label=LOC_precision_tok: 0.9591836734693877
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9621518686027136
dev_label=MISC_precision_tok: 0.9122664500406173
dev_label=MISC_recall_tok: 0.8856466876971609
dev_label=MISC_f-score_tok: 0.8987595038015205
dev_label=ORG_precision_tok: 0.943069306930693
dev_label=ORG_recall_tok: 0.9106118546845124
dev_label=ORG_f-score_tok: 0.926556420233463
dev_label=PER_precision_tok: 0.9672386895475819
dev_label=PER_recall_tok: 0.9844395046046364
dev_label=PER_f-score_tok: 0.9757632987094744
dev_precision_macro_tok: 0.9556039429770713
dev_recall_macro_tok: 0.9486060222391167
dev_f-score_macro_tok: 0.9519916915156532
dev_precision_micro_tok: 0.9888244227249717
dev_recall_micro_tok: 0.9888244227249717
dev_f-score_micro_tok: 0.9888244227249717
dev_time: 13.677869319915771
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9708    0.9798    0.9753       645
           1     0.9950    0.9927    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9829    0.9863    0.9846      3250
weighted avg     0.9902    0.9902    0.9902      3250

F1-macro sent:  0.9845797629553714
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9972    0.9967     42759
         LOC     0.9592    0.9651    0.9622      2094
        MISC     0.9123    0.8856    0.8988      1268
         ORG     0.9431    0.9106    0.9266      2092
         PER     0.9672    0.9844    0.9758      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9556    0.9486    0.9520     51362
weighted avg     0.9887    0.9888    0.9888     51362

F1-macro tok:  0.9519916915156532
F1-micro tok:  0.9888244227249717
**************************************************
Best epoch: 23
**************************************************

EPOCH: 26
Learning rate: 0.900000
train_cost_sum: 4158.599299252033
train_cost_avg: 0.2961754361692211
train_count_sent: 14041.0
train_total_correct_sent: 13887.0
train_accuracy_sent: 0.9890321202193576
train_count_tok: 203621.0
train_total_correct_tok: 202419.0
train_accuracy_tok: 0.9940968760589527
train_label=0_precision_sent: 0.9728801922416752
train_label=0_recall_sent: 0.9742179443107597
train_label=0_f-score_sent: 0.9735486087255238
train_label=1_precision_sent: 0.9932602444284687
train_label=1_recall_sent: 0.992903341717571
train_label=1_f-score_sent: 0.9930817610062894
train_precision_macro_sent: 0.9830702183350719
train_recall_macro_sent: 0.9835606430141653
train_f-score_macro_sent: 0.9833151848659066
train_precision_micro_sent: 0.9890321202193576
train_recall_micro_sent: 0.9890321202193576
train_f-score_micro_sent: 0.9890321202193576
train_label=O_precision_tok: 0.9980249038983091
train_label=O_recall_tok: 0.9982250056021418
train_label=O_f-score_tok: 0.9981249447212477
train_label=LOC_precision_tok: 0.9752105896510229
train_label=LOC_recall_tok: 0.9767385802097144
train_label=LOC_f-score_tok: 0.9759739868730053
train_label=MISC_precision_tok: 0.9574841113302652
train_label=MISC_recall_tok: 0.951230132810799
train_label=MISC_f-score_tok: 0.9543468763652251
train_label=ORG_precision_tok: 0.9683873549419768
train_label=ORG_recall_tok: 0.9655860349127182
train_label=ORG_f-score_tok: 0.9669846661005943
train_label=PER_precision_tok: 0.9864452423698384
train_label=PER_recall_tok: 0.987508986340762
train_label=PER_f-score_tok: 0.9869768277348662
train_precision_macro_tok: 0.9771104404382825
train_recall_macro_tok: 0.9758577479752271
train_f-score_macro_tok: 0.9764814603589876
train_precision_micro_tok: 0.9940968760589527
train_recall_micro_tok: 0.9940968760589527
train_f-score_micro_tok: 0.9940968760589527
train_time: 145.58191585540771
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9729    0.9742    0.9735      2909
           1     0.9933    0.9929    0.9931     11132

   micro avg     0.9890    0.9890    0.9890     14041
   macro avg     0.9831    0.9836    0.9833     14041
weighted avg     0.9890    0.9890    0.9890     14041

F1-macro sent:  0.9833151848659066
F1-micro sent:  0.9890321202193576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9982    0.9981    169578
         LOC     0.9752    0.9767    0.9760      8297
        MISC     0.9575    0.9512    0.9543      4593
         ORG     0.9684    0.9656    0.9670     10025
         PER     0.9864    0.9875    0.9870     11128

   micro avg     0.9941    0.9941    0.9941    203621
   macro avg     0.9771    0.9759    0.9765    203621
weighted avg     0.9941    0.9941    0.9941    203621

F1-macro tok:  0.9764814603589876
F1-micro tok:  0.9940968760589527
**************************************************
dev_cost_sum: 3042.8983586095273
dev_cost_avg: 0.9362764180337008
dev_count_sent: 3250.0
dev_total_correct_sent: 3179.0
dev_accuracy_sent: 0.9781538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50788.0
dev_accuracy_tok: 0.9888244227249717
dev_label=0_precision_sent: 0.91
dev_label=0_recall_sent: 0.9875968992248062
dev_label=0_f-score_sent: 0.9472118959107807
dev_label=1_precision_sent: 0.9968627450980392
dev_label=1_recall_sent: 0.9758157389635317
dev_label=1_f-score_sent: 0.9862269641125121
dev_precision_macro_sent: 0.9534313725490196
dev_recall_macro_sent: 0.9817063190941689
dev_f-score_macro_sent: 0.9667194300116464
dev_precision_micro_sent: 0.9781538461538462
dev_recall_micro_sent: 0.9781538461538462
dev_f-score_micro_sent: 0.9781538461538462
dev_label=O_precision_tok: 0.9951039820945631
dev_label=O_recall_tok: 0.9981992095231413
dev_label=O_f-score_tok: 0.9966491926539094
dev_label=LOC_precision_tok: 0.9652509652509652
dev_label=LOC_recall_tok: 0.9551098376313276
dev_label=LOC_f-score_tok: 0.9601536245799328
dev_label=MISC_precision_tok: 0.9158415841584159
dev_label=MISC_recall_tok: 0.8753943217665615
dev_label=MISC_f-score_tok: 0.8951612903225807
dev_label=ORG_precision_tok: 0.9464019851116625
dev_label=ORG_recall_tok: 0.9115678776290631
dev_label=ORG_f-score_tok: 0.9286583881178475
dev_label=PER_precision_tok: 0.9741406496373384
dev_label=PER_recall_tok: 0.9809463321689426
dev_label=PER_f-score_tok: 0.9775316455696204
dev_precision_macro_tok: 0.9593478332505889
dev_recall_macro_tok: 0.9442435157438073
dev_f-score_macro_tok: 0.9516308282487781
dev_precision_micro_tok: 0.9888244227249717
dev_recall_micro_tok: 0.9888244227249717
dev_f-score_micro_tok: 0.9888244227249717
dev_time: 13.615032434463501
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9100    0.9876    0.9472       645
           1     0.9969    0.9758    0.9862      2605

   micro avg     0.9782    0.9782    0.9782      3250
   macro avg     0.9534    0.9817    0.9667      3250
weighted avg     0.9796    0.9782    0.9785      3250

F1-macro sent:  0.9667194300116464
F1-micro sent:  0.9781538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9951    0.9982    0.9966     42759
         LOC     0.9653    0.9551    0.9602      2094
        MISC     0.9158    0.8754    0.8952      1268
         ORG     0.9464    0.9116    0.9287      2092
         PER     0.9741    0.9809    0.9775      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9593    0.9442    0.9516     51362
weighted avg     0.9887    0.9888    0.9887     51362

F1-macro tok:  0.9516308282487781
F1-micro tok:  0.9888244227249717
**************************************************
Best epoch: 23
**************************************************

EPOCH: 27
Learning rate: 0.900000
train_cost_sum: 4006.0367217063904
train_cost_avg: 0.28530992961373053
train_count_sent: 14041.0
train_total_correct_sent: 13891.0
train_accuracy_sent: 0.98931700021366
train_count_tok: 203621.0
train_total_correct_tok: 202452.0
train_accuracy_tok: 0.994258941857667
train_label=0_precision_sent: 0.9713016740690127
train_label=0_recall_sent: 0.9773117909934685
train_label=0_f-score_sent: 0.9742974640164496
train_label=1_precision_sent: 0.9940615439985604
train_label=1_recall_sent: 0.9924541861300754
train_label=1_f-score_sent: 0.9932572147801851
train_precision_macro_sent: 0.9826816090337865
train_recall_macro_sent: 0.984882988561772
train_f-score_macro_sent: 0.9837773393983174
train_precision_micro_sent: 0.98931700021366
train_recall_micro_sent: 0.98931700021366
train_f-score_micro_sent: 0.98931700021366
train_label=O_precision_tok: 0.9980488782523608
train_label=O_recall_tok: 0.9984490912736322
train_label=O_f-score_tok: 0.9982489446501427
train_label=LOC_precision_tok: 0.9764663287472846
train_label=LOC_recall_tok: 0.9751717488248764
train_label=LOC_f-score_tok: 0.9758186094192848
train_label=MISC_precision_tok: 0.9608015855538428
train_label=MISC_recall_tok: 0.9499237970825168
train_label=MISC_f-score_tok: 0.9553317276111233
train_label=ORG_precision_tok: 0.967735490959944
train_label=ORG_recall_tok: 0.9663840399002493
train_label=ORG_f-score_tok: 0.9670592932721102
train_label=PER_precision_tok: 0.9872497081799407
train_label=PER_recall_tok: 0.9880481667864845
train_label=PER_f-score_tok: 0.9876487761059959
train_precision_macro_tok: 0.9780603983386745
train_recall_macro_tok: 0.9755953687735518
train_f-score_macro_tok: 0.9768214702117314
train_precision_micro_tok: 0.994258941857667
train_recall_micro_tok: 0.994258941857667
train_f-score_micro_tok: 0.994258941857667
train_time: 144.13429713249207
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9713    0.9773    0.9743      2909
           1     0.9941    0.9925    0.9933     11132

   micro avg     0.9893    0.9893    0.9893     14041
   macro avg     0.9827    0.9849    0.9838     14041
weighted avg     0.9893    0.9893    0.9893     14041

F1-macro sent:  0.9837773393983174
F1-micro sent:  0.98931700021366
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9980    0.9984    0.9982    169578
         LOC     0.9765    0.9752    0.9758      8297
        MISC     0.9608    0.9499    0.9553      4593
         ORG     0.9677    0.9664    0.9671     10025
         PER     0.9872    0.9880    0.9876     11128

   micro avg     0.9943    0.9943    0.9943    203621
   macro avg     0.9781    0.9756    0.9768    203621
weighted avg     0.9942    0.9943    0.9943    203621

F1-macro tok:  0.9768214702117314
F1-micro tok:  0.994258941857667
**************************************************
dev_cost_sum: 2888.6252822726965
dev_cost_avg: 0.8888077791608296
dev_count_sent: 3250.0
dev_total_correct_sent: 3224.0
dev_accuracy_sent: 0.992
dev_count_tok: 51362.0
dev_total_correct_tok: 50789.0
dev_accuracy_tok: 0.9888438923717924
dev_label=0_precision_sent: 0.982839313572543
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.979782270606532
dev_label=1_precision_sent: 0.9942506707550786
dev_label=1_recall_sent: 0.9957773512476008
dev_label=1_f-score_sent: 0.9950134253931722
dev_precision_macro_sent: 0.9885449921638108
dev_recall_macro_sent: 0.9862607686470561
dev_f-score_macro_sent: 0.9873978479998521
dev_precision_micro_sent: 0.992
dev_recall_micro_sent: 0.992
dev_f-score_micro_sent: 0.992
dev_label=O_precision_tok: 0.9962138032579989
dev_label=O_recall_tok: 0.9968661568324797
dev_label=O_f-score_tok: 0.9965398732845486
dev_label=LOC_precision_tok: 0.959144893111639
dev_label=LOC_recall_tok: 0.9641833810888252
dev_label=LOC_f-score_tok: 0.9616575375089307
dev_label=MISC_precision_tok: 0.8981846882399369
dev_label=MISC_recall_tok: 0.8974763406940063
dev_label=MISC_f-score_tok: 0.8978303747534516
dev_label=ORG_precision_tok: 0.9426470588235294
dev_label=ORG_recall_tok: 0.9192160611854685
dev_label=ORG_f-score_tok: 0.930784123910939
dev_label=PER_precision_tok: 0.9750237116661398
dev_label=PER_recall_tok: 0.9793585265163544
dev_label=PER_f-score_tok: 0.9771863117870723
dev_precision_macro_tok: 0.9542428310198486
dev_recall_macro_tok: 0.9514200932634269
dev_f-score_macro_tok: 0.9527996442489884
dev_precision_micro_tok: 0.9888438923717924
dev_recall_micro_tok: 0.9888438923717924
dev_f-score_micro_tok: 0.9888438923717924
dev_time: 13.79356074333191
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9828    0.9767    0.9798       645
           1     0.9943    0.9958    0.9950      2605

   micro avg     0.9920    0.9920    0.9920      3250
   macro avg     0.9885    0.9863    0.9874      3250
weighted avg     0.9920    0.9920    0.9920      3250

F1-macro sent:  0.9873978479998521
F1-micro sent:  0.992
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9969    0.9965     42759
         LOC     0.9591    0.9642    0.9617      2094
        MISC     0.8982    0.8975    0.8978      1268
         ORG     0.9426    0.9192    0.9308      2092
         PER     0.9750    0.9794    0.9772      3149

   micro avg     0.9888    0.9888    0.9888     51362
   macro avg     0.9542    0.9514    0.9528     51362
weighted avg     0.9888    0.9888    0.9888     51362

F1-macro tok:  0.9527996442489884
F1-micro tok:  0.9888438923717924
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 0.900000
train_cost_sum: 3827.5554939210415
train_cost_avg: 0.27259849682508663
train_count_sent: 14041.0
train_total_correct_sent: 13914.0
train_accuracy_sent: 0.9909550601808989
train_count_tok: 203621.0
train_total_correct_tok: 202519.0
train_accuracy_tok: 0.994587984539905
train_label=0_precision_sent: 0.9753930280246069
train_label=0_recall_sent: 0.9810931591612237
train_label=0_f-score_sent: 0.9782347900599828
train_label=1_precision_sent: 0.9950517318938371
train_label=1_recall_sent: 0.9935321595400647
train_label=1_f-score_sent: 0.9942913651278823
train_precision_macro_sent: 0.985222379959222
train_recall_macro_sent: 0.9873126593506443
train_f-score_macro_sent: 0.9862630775939325
train_precision_micro_sent: 0.9909550601808989
train_recall_micro_sent: 0.9909550601808989
train_f-score_micro_sent: 0.9909550601808989
train_label=O_precision_tok: 0.9982078747398766
train_label=O_recall_tok: 0.9985198551698923
train_label=O_f-score_tok: 0.99836384058206
train_label=LOC_precision_tok: 0.9775660354601375
train_label=LOC_recall_tok: 0.9768591057008558
train_label=LOC_f-score_tok: 0.9772124427296841
train_label=MISC_precision_tok: 0.9604916593503073
train_label=MISC_recall_tok: 0.9527541911604616
train_label=MISC_f-score_tok: 0.9566072794840967
train_label=ORG_precision_tok: 0.9710086973907828
train_label=ORG_recall_tok: 0.9688778054862843
train_label=ORG_f-score_tok: 0.969942081086479
train_label=PER_precision_tok: 0.9872531418312388
train_label=PER_recall_tok: 0.9883177570093458
train_label=PER_f-score_tok: 0.9877851625651158
train_precision_macro_tok: 0.9789054817544687
train_recall_macro_tok: 0.977065742905368
train_f-score_macro_tok: 0.9779821612894871
train_precision_micro_tok: 0.994587984539905
train_recall_micro_tok: 0.994587984539905
train_f-score_micro_tok: 0.994587984539905
train_time: 145.83200430870056
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9754    0.9811    0.9782      2909
           1     0.9951    0.9935    0.9943     11132

   micro avg     0.9910    0.9910    0.9910     14041
   macro avg     0.9852    0.9873    0.9863     14041
weighted avg     0.9910    0.9910    0.9910     14041

F1-macro sent:  0.9862630775939325
F1-micro sent:  0.9909550601808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9982    0.9985    0.9984    169578
         LOC     0.9776    0.9769    0.9772      8297
        MISC     0.9605    0.9528    0.9566      4593
         ORG     0.9710    0.9689    0.9699     10025
         PER     0.9873    0.9883    0.9878     11128

   micro avg     0.9946    0.9946    0.9946    203621
   macro avg     0.9789    0.9771    0.9780    203621
weighted avg     0.9946    0.9946    0.9946    203621

F1-macro tok:  0.9779821612894871
F1-micro tok:  0.994587984539905
**************************************************
dev_cost_sum: 2972.484748326242
dev_cost_avg: 0.9146106917926898
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50782.0
dev_accuracy_tok: 0.9887076048440482
dev_label=0_precision_sent: 0.9722222222222222
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9744779582366588
dev_label=1_precision_sent: 0.9942352036894696
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9936623775686576
dev_precision_macro_sent: 0.9832287129558459
dev_recall_macro_sent: 0.9849171985894747
dev_f-score_macro_sent: 0.9840701679026582
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9964701482070223
dev_label=O_recall_tok: 0.9969129306110994
dev_label=O_f-score_tok: 0.9966914902322972
dev_label=LOC_precision_tok: 0.9552309142318567
dev_label=LOC_recall_tok: 0.9680038204393505
dev_label=LOC_f-score_tok: 0.9615749525616698
dev_label=MISC_precision_tok: 0.8744292237442922
dev_label=MISC_recall_tok: 0.9061514195583596
dev_label=MISC_f-score_tok: 0.8900077459333849
dev_label=ORG_precision_tok: 0.9579107505070994
dev_label=ORG_recall_tok: 0.902963671128107
dev_label=ORG_f-score_tok: 0.9296259842519685
dev_label=PER_precision_tok: 0.9729219143576826
dev_label=PER_recall_tok: 0.9812638932994602
dev_label=PER_f-score_tok: 0.9770750988142292
dev_precision_macro_tok: 0.9513925902095905
dev_recall_macro_tok: 0.9510591470072753
dev_f-score_macro_tok: 0.9509950543587099
dev_precision_micro_tok: 0.9887076048440482
dev_recall_micro_tok: 0.9887076048440482
dev_f-score_micro_tok: 0.9887076048440482
dev_time: 13.808953285217285
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9722    0.9767    0.9745       645
           1     0.9942    0.9931    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9832    0.9849    0.9841      3250
weighted avg     0.9899    0.9898    0.9899      3250

F1-macro sent:  0.9840701679026582
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9965    0.9969    0.9967     42759
         LOC     0.9552    0.9680    0.9616      2094
        MISC     0.8744    0.9062    0.8900      1268
         ORG     0.9579    0.9030    0.9296      2092
         PER     0.9729    0.9813    0.9771      3149

   micro avg     0.9887    0.9887    0.9887     51362
   macro avg     0.9514    0.9511    0.9510     51362
weighted avg     0.9888    0.9887    0.9887     51362

F1-macro tok:  0.9509950543587099
F1-micro tok:  0.9887076048440482
**************************************************
Best epoch: 27
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 3654.6553951501846
train_cost_avg: 0.2602845520369051
train_count_sent: 14041.0
train_total_correct_sent: 13909.0
train_accuracy_sent: 0.9905989601880208
train_count_tok: 203621.0
train_total_correct_tok: 202559.0
train_accuracy_tok: 0.9947844279322859
train_label=0_precision_sent: 0.9760027425437093
train_label=0_recall_sent: 0.9786868339635614
train_label=0_f-score_sent: 0.9773429454170958
train_label=1_precision_sent: 0.9944264653002517
train_label=1_recall_sent: 0.9937118217750629
train_label=1_f-score_sent: 0.9940690150970525
train_precision_macro_sent: 0.9852146039219805
train_recall_macro_sent: 0.9861993278693122
train_f-score_macro_sent: 0.9857059802570741
train_precision_micro_sent: 0.9905989601880208
train_recall_micro_sent: 0.9905989601880208
train_f-score_micro_sent: 0.9905989601880208
train_label=O_precision_tok: 0.9983313679245283
train_label=O_recall_tok: 0.9984608852563422
train_label=O_f-score_tok: 0.9983961223900135
train_label=LOC_precision_tok: 0.9771579706660255
train_label=LOC_recall_tok: 0.9796311919971074
train_label=LOC_f-score_tok: 0.9783930183569064
train_label=MISC_precision_tok: 0.9651468654099079
train_label=MISC_recall_tok: 0.9586327019377313
train_label=MISC_f-score_tok: 0.9618787547788094
train_label=ORG_precision_tok: 0.9707058588282343
train_label=ORG_recall_tok: 0.9684788029925187
train_label=ORG_f-score_tok: 0.9695910520796924
train_label=PER_precision_tok: 0.9877008708142562
train_label=PER_recall_tok: 0.9886772106398275
train_label=PER_f-score_tok: 0.9881887995688687
train_precision_macro_tok: 0.9798085867285906
train_recall_macro_tok: 0.9787761585647055
train_f-score_macro_tok: 0.9792895494348581
train_precision_micro_tok: 0.9947844279322859
train_recall_micro_tok: 0.9947844279322859
train_f-score_micro_tok: 0.9947844279322859
train_time: 144.63471579551697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9760    0.9787    0.9773      2909
           1     0.9944    0.9937    0.9941     11132

   micro avg     0.9906    0.9906    0.9906     14041
   macro avg     0.9852    0.9862    0.9857     14041
weighted avg     0.9906    0.9906    0.9906     14041

F1-macro sent:  0.9857059802570741
F1-micro sent:  0.9905989601880208
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9983    0.9985    0.9984    169578
         LOC     0.9772    0.9796    0.9784      8297
        MISC     0.9651    0.9586    0.9619      4593
         ORG     0.9707    0.9685    0.9696     10025
         PER     0.9877    0.9887    0.9882     11128

   micro avg     0.9948    0.9948    0.9948    203621
   macro avg     0.9798    0.9788    0.9793    203621
weighted avg     0.9948    0.9948    0.9948    203621

F1-macro tok:  0.9792895494348581
F1-micro tok:  0.9947844279322859
**************************************************
dev_cost_sum: 3111.945721644908
dev_cost_avg: 0.9575217605061256
dev_count_sent: 3250.0
dev_total_correct_sent: 3214.0
dev_accuracy_sent: 0.9889230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50810.0
dev_accuracy_tok: 0.9892527549550251
dev_label=0_precision_sent: 0.9841017488076311
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.9717425431711146
dev_label=1_precision_sent: 0.990080122090805
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9931113662456946
dev_precision_macro_sent: 0.9870909354492181
dev_recall_macro_sent: 0.977925575443765
dev_f-score_macro_sent: 0.9824269547084046
dev_precision_micro_sent: 0.9889230769230769
dev_recall_micro_sent: 0.9889230769230769
dev_f-score_micro_sent: 0.9889230769230769
dev_label=O_precision_tok: 0.9959150326797386
dev_label=O_recall_tok: 0.9978016324048739
dev_label=O_f-score_tok: 0.9968574399233636
dev_label=LOC_precision_tok: 0.9596582819174181
dev_label=LOC_recall_tok: 0.9656160458452722
dev_label=LOC_f-score_tok: 0.9626279457272078
dev_label=MISC_precision_tok: 0.9214876033057852
dev_label=MISC_recall_tok: 0.8793375394321766
dev_label=MISC_f-score_tok: 0.8999192897497982
dev_label=ORG_precision_tok: 0.9502734957732472
dev_label=ORG_recall_tok: 0.9134799235181644
dev_label=ORG_f-score_tok: 0.9315135266877894
dev_label=PER_precision_tok: 0.969630557294928
dev_label=PER_recall_tok: 0.9834868212130835
dev_label=PER_f-score_tok: 0.9765095380734669
dev_precision_macro_tok: 0.9593929941942234
dev_recall_macro_tok: 0.9479443924827141
dev_f-score_macro_tok: 0.9534855480323252
dev_precision_micro_tok: 0.9892527549550251
dev_recall_micro_tok: 0.9892527549550251
dev_f-score_micro_tok: 0.9892527549550251
dev_time: 13.531723499298096
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9841    0.9597    0.9717       645
           1     0.9901    0.9962    0.9931      2605

   micro avg     0.9889    0.9889    0.9889      3250
   macro avg     0.9871    0.9779    0.9824      3250
weighted avg     0.9889    0.9889    0.9889      3250

F1-macro sent:  0.9824269547084046
F1-micro sent:  0.9889230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9978    0.9969     42759
         LOC     0.9597    0.9656    0.9626      2094
        MISC     0.9215    0.8793    0.8999      1268
         ORG     0.9503    0.9135    0.9315      2092
         PER     0.9696    0.9835    0.9765      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9594    0.9479    0.9535     51362
weighted avg     0.9891    0.9893    0.9892     51362

F1-macro tok:  0.9534855480323252
F1-micro tok:  0.9892527549550251
**************************************************
Best epoch: 27
**************************************************

EPOCH: 30
Learning rate: 0.900000
train_cost_sum: 3517.1612364649773
train_cost_avg: 0.25049221825119133
train_count_sent: 14041.0
train_total_correct_sent: 13927.0
train_accuracy_sent: 0.9918809201623816
train_count_tok: 203621.0
train_total_correct_tok: 202613.0
train_accuracy_tok: 0.9950496265120002
train_label=0_precision_sent: 0.9794168096054888
train_label=0_recall_sent: 0.981436919903747
train_label=0_f-score_sent: 0.9804258241758241
train_label=1_precision_sent: 0.995146503685062
train_label=1_recall_sent: 0.9946101329500538
train_label=1_f-score_sent: 0.9948782460239015
train_precision_macro_sent: 0.9872816566452753
train_recall_macro_sent: 0.9880235264269004
train_f-score_macro_sent: 0.9876520350998628
train_precision_micro_sent: 0.9918809201623816
train_recall_micro_sent: 0.9918809201623816
train_f-score_micro_sent: 0.9918809201623816
train_label=O_precision_tok: 0.9984023110482254
train_label=O_recall_tok: 0.9986495889797026
train_label=O_f-score_tok: 0.9985259347048036
train_label=LOC_precision_tok: 0.9796262808921037
train_label=LOC_recall_tok: 0.9793901410148247
train_label=LOC_f-score_tok: 0.9795081967213115
train_label=MISC_precision_tok: 0.9627029398859148
train_label=MISC_recall_tok: 0.9553668626170259
train_label=MISC_f-score_tok: 0.9590208720358431
train_label=ORG_precision_tok: 0.9735735735735735
train_label=ORG_recall_tok: 0.9701745635910225
train_label=ORG_f-score_tok: 0.971871096677492
train_label=PER_precision_tok: 0.9879906793332138
train_label=PER_recall_tok: 0.9906542056074766
train_label=PER_f-score_tok: 0.9893206497352597
train_precision_macro_tok: 0.9804591569466062
train_recall_macro_tok: 0.9788470723620104
train_f-score_macro_tok: 0.9796493499749419
train_precision_micro_tok: 0.9950496265120002
train_recall_micro_tok: 0.9950496265120002
train_f-score_micro_tok: 0.9950496265120002
train_time: 145.05869364738464
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9794    0.9814    0.9804      2909
           1     0.9951    0.9946    0.9949     11132

   micro avg     0.9919    0.9919    0.9919     14041
   macro avg     0.9873    0.9880    0.9877     14041
weighted avg     0.9919    0.9919    0.9919     14041

F1-macro sent:  0.9876520350998628
F1-micro sent:  0.9918809201623816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9986    0.9985    169578
         LOC     0.9796    0.9794    0.9795      8297
        MISC     0.9627    0.9554    0.9590      4593
         ORG     0.9736    0.9702    0.9719     10025
         PER     0.9880    0.9907    0.9893     11128

   micro avg     0.9950    0.9950    0.9950    203621
   macro avg     0.9805    0.9788    0.9796    203621
weighted avg     0.9950    0.9950    0.9950    203621

F1-macro tok:  0.9796493499749419
F1-micro tok:  0.9950496265120002
**************************************************
dev_cost_sum: 3206.3401736840606
dev_cost_avg: 0.9865662072874033
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50799.0
dev_accuracy_tok: 0.9890385888399984
dev_label=0_precision_sent: 0.9842022116903634
dev_label=0_recall_sent: 0.9658914728682171
dev_label=0_f-score_sent: 0.9749608763693272
dev_label=1_precision_sent: 0.9915934275888422
dev_label=1_recall_sent: 0.9961612284069098
dev_label=1_f-score_sent: 0.9938720796629644
dev_precision_macro_sent: 0.9878978196396028
dev_recall_macro_sent: 0.9810263506375634
dev_f-score_macro_sent: 0.9844164780161457
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.9960546282245827
dev_label=O_recall_tok: 0.9978250192941837
dev_label=O_f-score_tok: 0.9969390377830222
dev_label=LOC_precision_tok: 0.9459459459459459
dev_label=LOC_recall_tok: 0.9694364851957975
dev_label=LOC_f-score_tok: 0.9575471698113208
dev_label=MISC_precision_tok: 0.9150485436893204
dev_label=MISC_recall_tok: 0.8919558359621451
dev_label=MISC_f-score_tok: 0.9033546325878594
dev_label=ORG_precision_tok: 0.9610655737704918
dev_label=ORG_recall_tok: 0.8967495219885278
dev_label=ORG_f-score_tok: 0.9277942631058358
dev_label=PER_precision_tok: 0.9696210460382085
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9763481551561023
dev_precision_macro_tok: 0.95754714753371
dev_recall_macro_tok: 0.9478272245046441
dev_f-score_macro_tok: 0.9523966516888281
dev_precision_micro_tok: 0.9890385888399984
dev_recall_micro_tok: 0.9890385888399984
dev_f-score_micro_tok: 0.9890385888399984
dev_time: 14.01574158668518
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9842    0.9659    0.9750       645
           1     0.9916    0.9962    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9879    0.9810    0.9844      3250
weighted avg     0.9901    0.9902    0.9901      3250

F1-macro sent:  0.9844164780161457
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9961    0.9978    0.9969     42759
         LOC     0.9459    0.9694    0.9575      2094
        MISC     0.9150    0.8920    0.9034      1268
         ORG     0.9611    0.8967    0.9278      2092
         PER     0.9696    0.9832    0.9763      3149

   micro avg     0.9890    0.9890    0.9890     51362
   macro avg     0.9575    0.9478    0.9524     51362
weighted avg     0.9890    0.9890    0.9889     51362

F1-macro tok:  0.9523966516888281
F1-micro tok:  0.9890385888399984
**************************************************
Best epoch: 27
**************************************************

EPOCH: 31
Learning rate: 0.900000
train_cost_sum: 3393.336212128401
train_cost_avg: 0.2416734001943167
train_count_sent: 14041.0
train_total_correct_sent: 13930.0
train_accuracy_sent: 0.9920945801581084
train_count_tok: 203621.0
train_total_correct_tok: 202622.0
train_accuracy_tok: 0.995093826275286
train_label=0_precision_sent: 0.9791095890410959
train_label=0_recall_sent: 0.9828119628738398
train_label=0_f-score_sent: 0.9809572825527534
train_label=1_precision_sent: 0.9955040014387195
train_label=1_recall_sent: 0.9945203018325548
train_label=1_f-score_sent: 0.9950119085067183
train_precision_macro_sent: 0.9873067952399077
train_recall_macro_sent: 0.9886661323531973
train_f-score_macro_sent: 0.9879845955297358
train_precision_micro_sent: 0.9920945801581084
train_recall_micro_sent: 0.9920945801581084
train_f-score_micro_sent: 0.9920945801581084
train_label=O_precision_tok: 0.9983845101646148
train_label=O_recall_tok: 0.9985611341093774
train_label=O_f-score_tok: 0.998472814326063
train_label=LOC_precision_tok: 0.9800288739172281
train_label=LOC_recall_tok: 0.9818006508376521
train_label=LOC_f-score_tok: 0.9809139623095912
train_label=MISC_precision_tok: 0.9681248626071665
train_label=MISC_recall_tok: 0.9588504245591117
train_label=MISC_f-score_tok: 0.963465324874207
train_label=ORG_precision_tok: 0.9727972797279728
train_label=ORG_recall_tok: 0.9702743142144639
train_label=ORG_f-score_tok: 0.9715341590091889
train_label=PER_precision_tok: 0.9872679996413521
train_label=PER_recall_tok: 0.9894859813084113
train_label=PER_f-score_tok: 0.9883757461514295
train_precision_macro_tok: 0.9813207052116668
train_recall_macro_tok: 0.9797945010058033
train_f-score_macro_tok: 0.980552401334096
train_precision_micro_tok: 0.995093826275286
train_recall_micro_tok: 0.995093826275286
train_f-score_micro_tok: 0.995093826275286
train_time: 146.7516143321991
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9791    0.9828    0.9810      2909
           1     0.9955    0.9945    0.9950     11132

   micro avg     0.9921    0.9921    0.9921     14041
   macro avg     0.9873    0.9887    0.9880     14041
weighted avg     0.9921    0.9921    0.9921     14041

F1-macro sent:  0.9879845955297358
F1-micro sent:  0.9920945801581084
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9984    0.9986    0.9985    169578
         LOC     0.9800    0.9818    0.9809      8297
        MISC     0.9681    0.9589    0.9635      4593
         ORG     0.9728    0.9703    0.9715     10025
         PER     0.9873    0.9895    0.9884     11128

   micro avg     0.9951    0.9951    0.9951    203621
   macro avg     0.9813    0.9798    0.9806    203621
weighted avg     0.9951    0.9951    0.9951    203621

F1-macro tok:  0.980552401334096
F1-micro tok:  0.995093826275286
**************************************************
dev_cost_sum: 3247.2353387624025
dev_cost_avg: 0.9991493350038162
dev_count_sent: 3250.0
dev_total_correct_sent: 3227.0
dev_accuracy_sent: 0.9929230769230769
dev_count_tok: 51362.0
dev_total_correct_tok: 50810.0
dev_accuracy_tok: 0.9892527549550251
dev_label=0_precision_sent: 0.9829192546583851
dev_label=0_recall_sent: 0.9813953488372092
dev_label=0_f-score_sent: 0.9821567106283942
dev_label=1_precision_sent: 0.9953952417498081
dev_label=1_recall_sent: 0.9957773512476008
dev_label=1_f-score_sent: 0.9955862598349645
dev_precision_macro_sent: 0.9891572482040967
dev_recall_macro_sent: 0.988586350042405
dev_f-score_macro_sent: 0.9888714852316793
dev_precision_micro_sent: 0.9929230769230769
dev_recall_micro_sent: 0.9929230769230769
dev_f-score_micro_sent: 0.9929230769230769
dev_label=O_precision_tok: 0.9961704611792177
dev_label=O_recall_tok: 0.9977080848476344
dev_label=O_f-score_tok: 0.9969386801271265
dev_label=LOC_precision_tok: 0.9495091164095372
dev_label=LOC_recall_tok: 0.9699140401146131
dev_label=LOC_f-score_tok: 0.959603118355776
dev_label=MISC_precision_tok: 0.9105560032232071
dev_label=MISC_recall_tok: 0.8911671924290221
dev_label=MISC_f-score_tok: 0.9007572738142687
dev_label=ORG_precision_tok: 0.9571788413098237
dev_label=ORG_recall_tok: 0.9082217973231358
dev_label=ORG_f-score_tok: 0.9320578857002697
dev_label=PER_precision_tok: 0.9735182849936949
dev_label=PER_recall_tok: 0.9806287710384249
dev_label=PER_f-score_tok: 0.977060591678532
dev_precision_macro_tok: 0.957386541423096
dev_recall_macro_tok: 0.9495279771505661
dev_f-score_macro_tok: 0.9532835099351946
dev_precision_micro_tok: 0.9892527549550251
dev_recall_micro_tok: 0.9892527549550251
dev_f-score_micro_tok: 0.9892527549550251
dev_time: 11.878399848937988
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9829    0.9814    0.9822       645
           1     0.9954    0.9958    0.9956      2605

   micro avg     0.9929    0.9929    0.9929      3250
   macro avg     0.9892    0.9886    0.9889      3250
weighted avg     0.9929    0.9929    0.9929      3250

F1-macro sent:  0.9888714852316793
F1-micro sent:  0.9929230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9977    0.9969     42759
         LOC     0.9495    0.9699    0.9596      2094
        MISC     0.9106    0.8912    0.9008      1268
         ORG     0.9572    0.9082    0.9321      2092
         PER     0.9735    0.9806    0.9771      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9574    0.9495    0.9533     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9532835099351946
F1-micro tok:  0.9892527549550251
**************************************************
Best epoch: 31
**************************************************

EPOCH: 32
Learning rate: 0.900000
train_cost_sum: 3489.4020262658596
train_cost_avg: 0.24851520734035037
train_count_sent: 14041.0
train_total_correct_sent: 13948.0
train_accuracy_sent: 0.9933765401324692
train_count_tok: 203621.0
train_total_correct_tok: 202624.0
train_accuracy_tok: 0.995103648444905
train_label=0_precision_sent: 0.9821917808219178
train_label=0_recall_sent: 0.9859058095565486
train_label=0_f-score_sent: 0.9840452907874422
train_label=1_precision_sent: 0.99631328117975
train_label=1_recall_sent: 0.9953287818900467
train_label=1_f-score_sent: 0.9958207882083315
train_precision_macro_sent: 0.989252531000834
train_recall_macro_sent: 0.9906172957232977
train_f-score_macro_sent: 0.9899330394978869
train_precision_micro_sent: 0.9933765401324692
train_recall_micro_sent: 0.9933765401324692
train_f-score_micro_sent: 0.9933765401324692
train_label=O_precision_tok: 0.9984612572883934
train_label=O_recall_tok: 0.9987026619018976
train_label=O_f-score_tok: 0.9985819450054098
train_label=LOC_precision_tok: 0.9773766546329723
train_label=LOC_recall_tok: 0.9789080390502591
train_label=LOC_f-score_tok: 0.9781417474558921
train_label=MISC_precision_tok: 0.9642151481888035
train_label=MISC_recall_tok: 0.9562377531025473
train_label=MISC_f-score_tok: 0.9602098819414078
train_label=ORG_precision_tok: 0.9737868934467233
train_label=ORG_recall_tok: 0.9708728179551123
train_label=ORG_f-score_tok: 0.9723276723276723
train_label=PER_precision_tok: 0.9889606892837911
train_label=PER_recall_tok: 0.9902048885693745
train_label=PER_f-score_tok: 0.989582397844634
train_precision_macro_tok: 0.9805601285681368
train_recall_macro_tok: 0.9789852321158381
train_f-score_macro_tok: 0.9797687289150032
train_precision_micro_tok: 0.995103648444905
train_recall_micro_tok: 0.995103648444905
train_f-score_micro_tok: 0.995103648444905
train_time: 149.86830258369446
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9822    0.9859    0.9840      2909
           1     0.9963    0.9953    0.9958     11132

   micro avg     0.9934    0.9934    0.9934     14041
   macro avg     0.9893    0.9906    0.9899     14041
weighted avg     0.9934    0.9934    0.9934     14041

F1-macro sent:  0.9899330394978869
F1-micro sent:  0.9933765401324692
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9985    0.9987    0.9986    169578
         LOC     0.9774    0.9789    0.9781      8297
        MISC     0.9642    0.9562    0.9602      4593
         ORG     0.9738    0.9709    0.9723     10025
         PER     0.9890    0.9902    0.9896     11128

   micro avg     0.9951    0.9951    0.9951    203621
   macro avg     0.9806    0.9790    0.9798    203621
weighted avg     0.9951    0.9951    0.9951    203621

F1-macro tok:  0.9797687289150032
F1-micro tok:  0.995103648444905
**************************************************
dev_cost_sum: 3058.5609442293644
dev_cost_avg: 0.9410956751474967
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50817.0
dev_accuracy_tok: 0.9893890424827694
dev_label=0_precision_sent: 0.985691573926868
dev_label=0_recall_sent: 0.9612403100775194
dev_label=0_f-score_sent: 0.9733124018838304
dev_label=1_precision_sent: 0.9904616558565433
dev_label=1_recall_sent: 0.9965451055662188
dev_label=1_f-score_sent: 0.9934940681209337
dev_precision_macro_sent: 0.9880766148917057
dev_recall_macro_sent: 0.9788927078218691
dev_f-score_macro_sent: 0.983403235002382
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9960074713985524
dev_label=O_recall_tok: 0.9976613110690147
dev_label=O_f-score_tok: 0.9968337052658636
dev_label=LOC_precision_tok: 0.965832531280077
dev_label=LOC_recall_tok: 0.9584527220630372
dev_label=LOC_f-score_tok: 0.9621284755512942
dev_label=MISC_precision_tok: 0.9310924369747899
dev_label=MISC_recall_tok: 0.8738170347003155
dev_label=MISC_f-score_tok: 0.9015459723352318
dev_label=ORG_precision_tok: 0.936988936988937
dev_label=ORG_recall_tok: 0.9311663479923518
dev_label=ORG_f-score_tok: 0.9340685686885639
dev_label=PER_precision_tok: 0.9717425431711146
dev_label=PER_recall_tok: 0.9828516989520483
dev_label=PER_f-score_tok: 0.9772655509946321
dev_precision_macro_tok: 0.9603327839626943
dev_recall_macro_tok: 0.9487898229553535
dev_f-score_macro_tok: 0.9543684545671172
dev_precision_micro_tok: 0.9893890424827694
dev_recall_micro_tok: 0.9893890424827694
dev_f-score_micro_tok: 0.9893890424827694
dev_time: 9.488061428070068
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9857    0.9612    0.9733       645
           1     0.9905    0.9965    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9881    0.9789    0.9834      3250
weighted avg     0.9895    0.9895    0.9895      3250

F1-macro sent:  0.983403235002382
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9960    0.9977    0.9968     42759
         LOC     0.9658    0.9585    0.9621      2094
        MISC     0.9311    0.8738    0.9015      1268
         ORG     0.9370    0.9312    0.9341      2092
         PER     0.9717    0.9829    0.9773      3149

   micro avg     0.9894    0.9894    0.9894     51362
   macro avg     0.9603    0.9488    0.9544     51362
weighted avg     0.9893    0.9894    0.9893     51362

F1-macro tok:  0.9543684545671172
F1-micro tok:  0.9893890424827694
**************************************************
Best epoch: 31
**************************************************

EPOCH: 33
Learning rate: 0.900000
train_cost_sum: 3087.391868442297
train_cost_avg: 0.2198840444727795
train_count_sent: 14041.0
train_total_correct_sent: 13955.0
train_accuracy_sent: 0.9938750801224984
train_count_tok: 203621.0
train_total_correct_tok: 202705.0
train_accuracy_tok: 0.9955014463144765
train_label=0_precision_sent: 0.9862211505339304
train_label=0_recall_sent: 0.9841870058439326
train_label=0_f-score_sent: 0.9852030282174811
train_label=1_precision_sent: 0.9958699946130365
train_label=1_recall_sent: 0.996406755300036
train_label=1_f-score_sent: 0.996138302649304
train_precision_macro_sent: 0.9910455725734835
train_recall_macro_sent: 0.9902968805719843
train_f-score_macro_sent: 0.9906706654333925
train_precision_micro_sent: 0.9938750801224984
train_recall_micro_sent: 0.9938750801224984
train_f-score_micro_sent: 0.9938750801224984
train_label=O_precision_tok: 0.9985967891233469
train_label=O_recall_tok: 0.9987911167722228
train_label=O_f-score_tok: 0.9986939434946297
train_label=LOC_precision_tok: 0.9825027150959333
train_label=LOC_recall_tok: 0.9813185488730867
train_label=LOC_f-score_tok: 0.9819102749638206
train_label=MISC_precision_tok: 0.9691263411429822
train_label=MISC_recall_tok: 0.9636403222294796
train_label=MISC_f-score_tok: 0.9663755458515283
train_label=ORG_precision_tok: 0.9736263736263736
train_label=ORG_recall_tok: 0.9721695760598503
train_label=ORG_f-score_tok: 0.9728974294983778
train_label=PER_precision_tok: 0.988516059572941
train_label=PER_recall_tok: 0.9901150251617541
train_label=PER_f-score_tok: 0.9893148962916404
train_precision_macro_tok: 0.9824736557123155
train_recall_macro_tok: 0.9812069178192786
train_f-score_macro_tok: 0.9818384180199994
train_precision_micro_tok: 0.9955014463144765
train_recall_micro_tok: 0.9955014463144765
train_f-score_micro_tok: 0.9955014463144765
train_time: 149.2311029434204
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9862    0.9842    0.9852      2909
           1     0.9959    0.9964    0.9961     11132

   micro avg     0.9939    0.9939    0.9939     14041
   macro avg     0.9910    0.9903    0.9907     14041
weighted avg     0.9939    0.9939    0.9939     14041

F1-macro sent:  0.9906706654333925
F1-micro sent:  0.9938750801224984
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9986    0.9988    0.9987    169578
         LOC     0.9825    0.9813    0.9819      8297
        MISC     0.9691    0.9636    0.9664      4593
         ORG     0.9736    0.9722    0.9729     10025
         PER     0.9885    0.9901    0.9893     11128

   micro avg     0.9955    0.9955    0.9955    203621
   macro avg     0.9825    0.9812    0.9818    203621
weighted avg     0.9955    0.9955    0.9955    203621

F1-macro tok:  0.9818384180199994
F1-micro tok:  0.9955014463144765
**************************************************
dev_cost_sum: 3215.744685329497
dev_cost_avg: 0.9894599031783067
dev_count_sent: 3250.0
dev_total_correct_sent: 3217.0
dev_accuracy_sent: 0.9898461538461538
dev_count_tok: 51362.0
dev_total_correct_tok: 50805.0
dev_accuracy_tok: 0.9891554067209221
dev_label=0_precision_sent: 0.9722222222222222
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.9744779582366588
dev_label=1_precision_sent: 0.9942352036894696
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9936623775686576
dev_precision_macro_sent: 0.9832287129558459
dev_recall_macro_sent: 0.9849171985894747
dev_f-score_macro_sent: 0.9840701679026582
dev_precision_micro_sent: 0.9898461538461538
dev_recall_micro_sent: 0.9898461538461538
dev_f-score_micro_sent: 0.9898461538461539
dev_label=O_precision_tok: 0.9967269836816758
dev_label=O_recall_tok: 0.9970766388362684
dev_label=O_f-score_tok: 0.9969017805993009
dev_label=LOC_precision_tok: 0.961520190023753
dev_label=LOC_recall_tok: 0.9665711556829035
dev_label=LOC_f-score_tok: 0.9640390569183139
dev_label=MISC_precision_tok: 0.8862595419847328
dev_label=MISC_recall_tok: 0.9156151419558359
dev_label=MISC_f-score_tok: 0.9006982156710628
dev_label=ORG_precision_tok: 0.9531013615733737
dev_label=ORG_recall_tok: 0.9034416826003824
dev_label=ORG_f-score_tok: 0.9276073619631902
dev_label=PER_precision_tok: 0.9705329153605016
dev_label=PER_recall_tok: 0.9831692600825659
dev_label=PER_f-score_tok: 0.9768102224325603
dev_precision_macro_tok: 0.9536281985248074
dev_recall_macro_tok: 0.9531747758315913
dev_f-score_macro_tok: 0.9532113275168858
dev_precision_micro_tok: 0.9891554067209221
dev_recall_micro_tok: 0.9891554067209221
dev_f-score_micro_tok: 0.9891554067209221
dev_time: 11.712769031524658
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9722    0.9767    0.9745       645
           1     0.9942    0.9931    0.9937      2605

   micro avg     0.9898    0.9898    0.9898      3250
   macro avg     0.9832    0.9849    0.9841      3250
weighted avg     0.9899    0.9898    0.9899      3250

F1-macro sent:  0.9840701679026582
F1-micro sent:  0.9898461538461539
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9967    0.9971    0.9969     42759
         LOC     0.9615    0.9666    0.9640      2094
        MISC     0.8863    0.9156    0.9007      1268
         ORG     0.9531    0.9034    0.9276      2092
         PER     0.9705    0.9832    0.9768      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9536    0.9532    0.9532     51362
weighted avg     0.9892    0.9892    0.9891     51362

F1-macro tok:  0.9532113275168858
F1-micro tok:  0.9891554067209221
**************************************************
Best epoch: 31
**************************************************

EPOCH: 34
Learning rate: 0.900000
train_cost_sum: 3084.8762635588646
train_cost_avg: 0.21970488309656466
train_count_sent: 14041.0
train_total_correct_sent: 13943.0
train_accuracy_sent: 0.9930204401395912
train_count_tok: 203621.0
train_total_correct_tok: 202681.0
train_accuracy_tok: 0.9953835802790478
train_label=0_precision_sent: 0.9824922760041195
train_label=0_recall_sent: 0.9838432451014094
train_label=0_f-score_sent: 0.9831672964616971
train_label=1_precision_sent: 0.9957764198418404
train_label=1_recall_sent: 0.9954186130075459
train_label=1_f-score_sent: 0.9955974842767296
train_precision_macro_sent: 0.9891343479229799
train_recall_macro_sent: 0.9896309290544776
train_f-score_macro_sent: 0.9893823903692134
train_precision_micro_sent: 0.9930204401395912
train_recall_micro_sent: 0.9930204401395912
train_f-score_micro_sent: 0.9930204401395912
train_label=O_precision_tok: 0.9985613037889598
train_label=O_recall_tok: 0.9986790739364776
train_label=O_f-score_tok: 0.9986201853904758
train_label=LOC_precision_tok: 0.9781092133750301
train_label=LOC_recall_tok: 0.9801132939616729
train_label=LOC_f-score_tok: 0.9791102281620613
train_label=MISC_precision_tok: 0.9670980478175039
train_label=MISC_recall_tok: 0.9599390376660135
train_label=MISC_f-score_tok: 0.9635052447552448
train_label=ORG_precision_tok: 0.9747605746209098
train_label=ORG_recall_tok: 0.9746633416458853
train_label=ORG_f-score_tok: 0.9747119557085141
train_label=PER_precision_tok: 0.9900233686859609
train_label=PER_recall_tok: 0.9898454349388929
train_label=PER_f-score_tok: 0.989934393816842
train_precision_macro_tok: 0.9817105016576729
train_recall_macro_tok: 0.9806480364297885
train_f-score_macro_tok: 0.9811764015666276
train_precision_micro_tok: 0.9953835802790478
train_recall_micro_tok: 0.9953835802790478
train_f-score_micro_tok: 0.9953835802790478
train_time: 146.05769610404968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9825    0.9838    0.9832      2909
           1     0.9958    0.9954    0.9956     11132

   micro avg     0.9930    0.9930    0.9930     14041
   macro avg     0.9891    0.9896    0.9894     14041
weighted avg     0.9930    0.9930    0.9930     14041

F1-macro sent:  0.9893823903692134
F1-micro sent:  0.9930204401395912
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9986    0.9987    0.9986    169578
         LOC     0.9781    0.9801    0.9791      8297
        MISC     0.9671    0.9599    0.9635      4593
         ORG     0.9748    0.9747    0.9747     10025
         PER     0.9900    0.9898    0.9899     11128

   micro avg     0.9954    0.9954    0.9954    203621
   macro avg     0.9817    0.9806    0.9812    203621
weighted avg     0.9954    0.9954    0.9954    203621

F1-macro tok:  0.9811764015666276
F1-micro tok:  0.9953835802790478
**************************************************
dev_cost_sum: 3458.0235175825655
dev_cost_avg: 1.064007236179251
dev_count_sent: 3250.0
dev_total_correct_sent: 3218.0
dev_accuracy_sent: 0.9901538461538462
dev_count_tok: 51362.0
dev_total_correct_tok: 50760.0
dev_accuracy_tok: 0.9882792726139947
dev_label=0_precision_sent: 0.9766718506998445
dev_label=0_recall_sent: 0.9736434108527132
dev_label=0_f-score_sent: 0.9751552795031057
dev_label=1_precision_sent: 0.9934790947449176
dev_label=1_recall_sent: 0.9942418426103646
dev_label=1_f-score_sent: 0.9938603223330775
dev_precision_macro_sent: 0.985075472722381
dev_recall_macro_sent: 0.983942626731539
dev_f-score_macro_sent: 0.9845078009180916
dev_precision_micro_sent: 0.9901538461538462
dev_recall_micro_sent: 0.9901538461538462
dev_f-score_micro_sent: 0.9901538461538462
dev_label=O_precision_tok: 0.995404283114823
dev_label=O_recall_tok: 0.9978951799621132
dev_label=O_f-score_tok: 0.9966481751824817
dev_label=LOC_precision_tok: 0.9442638179284719
dev_label=LOC_recall_tok: 0.9708691499522445
dev_label=LOC_f-score_tok: 0.9573816811867201
dev_label=MISC_precision_tok: 0.9266441821247892
dev_label=MISC_recall_tok: 0.8667192429022083
dev_label=MISC_f-score_tok: 0.8956805215973921
dev_label=ORG_precision_tok: 0.9538461538461539
dev_label=ORG_recall_tok: 0.8891013384321224
dev_label=ORG_f-score_tok: 0.9203364670954973
dev_label=PER_precision_tok: 0.9663236669784846
dev_label=PER_recall_tok: 0.9841219434741187
dev_label=PER_f-score_tok: 0.9751415984896161
dev_precision_macro_tok: 0.9572964207985445
dev_recall_macro_tok: 0.9417413709445615
dev_f-score_macro_tok: 0.9490376887103414
dev_precision_micro_tok: 0.9882792726139947
dev_recall_micro_tok: 0.9882792726139947
dev_f-score_micro_tok: 0.9882792726139947
dev_time: 13.999702215194702
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9767    0.9736    0.9752       645
           1     0.9935    0.9942    0.9939      2605

   micro avg     0.9902    0.9902    0.9902      3250
   macro avg     0.9851    0.9839    0.9845      3250
weighted avg     0.9901    0.9902    0.9901      3250

F1-macro sent:  0.9845078009180916
F1-micro sent:  0.9901538461538462
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9954    0.9979    0.9966     42759
         LOC     0.9443    0.9709    0.9574      2094
        MISC     0.9266    0.8667    0.8957      1268
         ORG     0.9538    0.8891    0.9203      2092
         PER     0.9663    0.9841    0.9751      3149

   micro avg     0.9883    0.9883    0.9883     51362
   macro avg     0.9573    0.9417    0.9490     51362
weighted avg     0.9881    0.9883    0.9881     51362

F1-macro tok:  0.9490376887103414
F1-micro tok:  0.9882792726139947
**************************************************
Best epoch: 31
**************************************************

EPOCH: 35
Learning rate: 0.900000
train_cost_sum: 3037.863056153059
train_cost_avg: 0.2163566025320888
train_count_sent: 14041.0
train_total_correct_sent: 13952.0
train_accuracy_sent: 0.9936614201267716
train_count_tok: 203621.0
train_total_correct_tok: 202727.0
train_accuracy_tok: 0.9956094901802859
train_label=0_precision_sent: 0.9835390946502057
train_label=0_recall_sent: 0.9859058095565486
train_label=0_f-score_sent: 0.9847210300429183
train_label=1_precision_sent: 0.996314606741573
train_label=1_recall_sent: 0.9956881063600431
train_label=1_f-score_sent: 0.9960012580311811
train_precision_macro_sent: 0.9899268506958894
train_recall_macro_sent: 0.9907969579582958
train_f-score_macro_sent: 0.9903611440370497
train_precision_micro_sent: 0.9936614201267716
train_recall_micro_sent: 0.9936614201267716
train_f-score_micro_sent: 0.9936614201267716
train_label=O_precision_tok: 0.9984907974013417
train_label=O_recall_tok: 0.9987734257981578
train_label=O_f-score_tok: 0.9986320916026934
train_label=LOC_precision_tok: 0.9821643769583032
train_label=LOC_recall_tok: 0.9822827528022177
train_label=LOC_f-score_tok: 0.9822235613136486
train_label=MISC_precision_tok: 0.9725817065145865
train_label=MISC_recall_tok: 0.9653821032005225
train_label=MISC_f-score_tok: 0.9689685314685315
train_label=ORG_precision_tok: 0.9759072278316505
train_label=ORG_recall_tok: 0.9737655860349127
train_label=ORG_f-score_tok: 0.9748352306770521
train_label=PER_precision_tok: 0.9888639425235743
train_label=PER_recall_tok: 0.9894859813084113
train_label=PER_f-score_tok: 0.9891748641243319
train_precision_macro_tok: 0.9836016102458913
train_recall_macro_tok: 0.9819379698288444
train_f-score_macro_tok: 0.9827668558372515
train_precision_micro_tok: 0.9956094901802859
train_recall_micro_tok: 0.9956094901802859
train_f-score_micro_tok: 0.9956094901802859
train_time: 146.28623628616333
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9835    0.9859    0.9847      2909
           1     0.9963    0.9957    0.9960     11132

   micro avg     0.9937    0.9937    0.9937     14041
   macro avg     0.9899    0.9908    0.9904     14041
weighted avg     0.9937    0.9937    0.9937     14041

F1-macro sent:  0.9903611440370497
F1-micro sent:  0.9936614201267716
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9985    0.9988    0.9986    169578
         LOC     0.9822    0.9823    0.9822      8297
        MISC     0.9726    0.9654    0.9690      4593
         ORG     0.9759    0.9738    0.9748     10025
         PER     0.9889    0.9895    0.9892     11128

   micro avg     0.9956    0.9956    0.9956    203621
   macro avg     0.9836    0.9819    0.9828    203621
weighted avg     0.9956    0.9956    0.9956    203621

F1-macro tok:  0.9827668558372515
F1-micro tok:  0.9956094901802859
**************************************************
dev_cost_sum: 3443.289589870721
dev_cost_avg: 1.0594737199602218
dev_count_sent: 3250.0
dev_total_correct_sent: 3213.0
dev_accuracy_sent: 0.9886153846153846
dev_count_tok: 51362.0
dev_total_correct_tok: 50805.0
dev_accuracy_tok: 0.9891554067209221
dev_label=0_precision_sent: 0.9720496894409938
dev_label=0_recall_sent: 0.9705426356589147
dev_label=0_f-score_sent: 0.9712955779674165
dev_label=1_precision_sent: 0.9927091327705295
dev_label=1_recall_sent: 0.9930902111324377
dev_label=1_f-score_sent: 0.9928996353866821
dev_precision_macro_sent: 0.9823794111057617
dev_recall_macro_sent: 0.9818164233956762
dev_f-score_macro_sent: 0.9820976066770493
dev_precision_micro_sent: 0.9886153846153846
dev_recall_micro_sent: 0.9886153846153846
dev_f-score_micro_sent: 0.9886153846153846
dev_label=O_precision_tok: 0.9963090148807437
dev_label=O_recall_tok: 0.9974274421759162
dev_label=O_f-score_tok: 0.9968679148259824
dev_label=LOC_precision_tok: 0.9534992954438704
dev_label=LOC_recall_tok: 0.9694364851957975
dev_label=LOC_f-score_tok: 0.961401847028179
dev_label=MISC_precision_tok: 0.8995290423861853
dev_label=MISC_recall_tok: 0.9037854889589906
dev_label=MISC_f-score_tok: 0.901652242328875
dev_label=ORG_precision_tok: 0.9573604060913705
dev_label=ORG_recall_tok: 0.9015296367112811
dev_label=ORG_f-score_tok: 0.9286065977351059
dev_label=PER_precision_tok: 0.9723444374607165
dev_label=PER_recall_tok: 0.9825341378215307
dev_label=PER_f-score_tok: 0.9774127310061602
dev_precision_macro_tok: 0.9558084392525773
dev_recall_macro_tok: 0.9509426381727032
dev_f-score_macro_tok: 0.9531882665848606
dev_precision_micro_tok: 0.9891554067209221
dev_recall_micro_tok: 0.9891554067209221
dev_f-score_micro_tok: 0.9891554067209221
dev_time: 13.653712272644043
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9720    0.9705    0.9713       645
           1     0.9927    0.9931    0.9929      2605

   micro avg     0.9886    0.9886    0.9886      3250
   macro avg     0.9824    0.9818    0.9821      3250
weighted avg     0.9886    0.9886    0.9886      3250

F1-macro sent:  0.9820976066770493
F1-micro sent:  0.9886153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9963    0.9974    0.9969     42759
         LOC     0.9535    0.9694    0.9614      2094
        MISC     0.8995    0.9038    0.9017      1268
         ORG     0.9574    0.9015    0.9286      2092
         PER     0.9723    0.9825    0.9774      3149

   micro avg     0.9892    0.9892    0.9892     51362
   macro avg     0.9558    0.9509    0.9532     51362
weighted avg     0.9891    0.9892    0.9891     51362

F1-macro tok:  0.9531882665848606
F1-micro tok:  0.9891554067209221
**************************************************
Best epoch: 31
**************************************************

EPOCH: 36
Learning rate: 0.810000
train_cost_sum: 2505.30165399611
train_cost_avg: 0.17842758022905134
train_count_sent: 14041.0
train_total_correct_sent: 13957.0
train_accuracy_sent: 0.9940175201196496
train_count_tok: 203621.0
train_total_correct_tok: 202862.0
train_accuracy_tok: 0.9962724866295716
train_label=0_precision_sent: 0.9845626072041166
train_label=0_recall_sent: 0.9865933310415951
train_label=0_f-score_sent: 0.985576923076923
train_label=1_precision_sent: 0.9964946971058781
train_label=1_recall_sent: 0.9959575997125404
train_label=1_f-score_sent: 0.9962260760176117
train_precision_macro_sent: 0.9905286521549974
train_recall_macro_sent: 0.9912754653770677
train_f-score_macro_sent: 0.9909014995472674
train_precision_micro_sent: 0.9940175201196496
train_recall_micro_sent: 0.9940175201196496
train_f-score_micro_sent: 0.9940175201196496
train_label=O_precision_tok: 0.9988089903540011
train_label=O_recall_tok: 0.9989621295215181
train_label=O_f-score_tok: 0.9988855540683172
train_label=LOC_precision_tok: 0.9843260188087775
train_label=LOC_recall_tok: 0.983970109678197
train_label=LOC_f-score_tok: 0.9841480320655777
train_label=MISC_precision_tok: 0.9750219106047326
train_label=MISC_recall_tok: 0.9688656651426083
train_label=MISC_f-score_tok: 0.9719340395325979
train_label=ORG_precision_tok: 0.9780461031833151
train_label=ORG_recall_tok: 0.9776558603491272
train_label=ORG_f-score_tok: 0.9778509428314877
train_label=PER_precision_tok: 0.9916502065002694
train_label=PER_recall_tok: 0.9925413371675054
train_label=PER_f-score_tok: 0.9920955717237042
train_precision_macro_tok: 0.985570645890219
train_recall_macro_tok: 0.9843990203717912
train_f-score_macro_tok: 0.9849828280443369
train_precision_micro_tok: 0.9962724866295716
train_recall_micro_tok: 0.9962724866295716
train_f-score_micro_tok: 0.9962724866295716
train_time: 145.0365924835205
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9846    0.9866    0.9856      2909
           1     0.9965    0.9960    0.9962     11132

   micro avg     0.9940    0.9940    0.9940     14041
   macro avg     0.9905    0.9913    0.9909     14041
weighted avg     0.9940    0.9940    0.9940     14041

F1-macro sent:  0.9909014995472674
F1-micro sent:  0.9940175201196496
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9990    0.9989    169578
         LOC     0.9843    0.9840    0.9841      8297
        MISC     0.9750    0.9689    0.9719      4593
         ORG     0.9780    0.9777    0.9779     10025
         PER     0.9917    0.9925    0.9921     11128

   micro avg     0.9963    0.9963    0.9963    203621
   macro avg     0.9856    0.9844    0.9850    203621
weighted avg     0.9963    0.9963    0.9963    203621

F1-macro tok:  0.9849828280443369
F1-micro tok:  0.9962724866295716
**************************************************
dev_cost_sum: 3351.4902449976653
dev_cost_avg: 1.0312277676915893
dev_count_sent: 3250.0
dev_total_correct_sent: 3223.0
dev_accuracy_sent: 0.9916923076923077
dev_count_tok: 51362.0
dev_total_correct_tok: 50813.0
dev_accuracy_tok: 0.9893111638954869
dev_label=0_precision_sent: 0.9813084112149533
dev_label=0_recall_sent: 0.9767441860465116
dev_label=0_f-score_sent: 0.979020979020979
dev_label=1_precision_sent: 0.9942484662576687
dev_label=1_recall_sent: 0.9953934740882917
dev_label=1_f-score_sent: 0.9948206407059275
dev_precision_macro_sent: 0.987778438736311
dev_recall_macro_sent: 0.9860688300674016
dev_f-score_macro_sent: 0.9869208098634532
dev_precision_micro_sent: 0.9916923076923077
dev_recall_micro_sent: 0.9916923076923077
dev_f-score_micro_sent: 0.9916923076923077
dev_label=O_precision_tok: 0.9959384701570925
dev_label=O_recall_tok: 0.9978484061834936
dev_label=O_f-score_tok: 0.996892523364486
dev_label=LOC_precision_tok: 0.957919621749409
dev_label=LOC_recall_tok: 0.9675262655205349
dev_label=LOC_f-score_tok: 0.9626989783796626
dev_label=MISC_precision_tok: 0.9042298483639266
dev_label=MISC_recall_tok: 0.8935331230283912
dev_label=MISC_f-score_tok: 0.8988496628322095
dev_label=ORG_precision_tok: 0.958502024291498
dev_label=ORG_recall_tok: 0.9053537284894837
dev_label=ORG_f-score_tok: 0.9311701081612587
dev_label=PER_precision_tok: 0.9735599622285175
dev_label=PER_recall_tok: 0.982216576691013
dev_label=PER_f-score_tok: 0.9778691116029087
dev_precision_macro_tok: 0.9580299853580886
dev_recall_macro_tok: 0.9492956199825834
dev_f-score_macro_tok: 0.9534960768681049
dev_precision_micro_tok: 0.9893111638954869
dev_recall_micro_tok: 0.9893111638954869
dev_f-score_micro_tok: 0.9893111638954869
dev_time: 13.605876684188843
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9813    0.9767    0.9790       645
           1     0.9942    0.9954    0.9948      2605

   micro avg     0.9917    0.9917    0.9917      3250
   macro avg     0.9878    0.9861    0.9869      3250
weighted avg     0.9917    0.9917    0.9917      3250

F1-macro sent:  0.9869208098634532
F1-micro sent:  0.9916923076923077
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9959    0.9978    0.9969     42759
         LOC     0.9579    0.9675    0.9627      2094
        MISC     0.9042    0.8935    0.8988      1268
         ORG     0.9585    0.9054    0.9312      2092
         PER     0.9736    0.9822    0.9779      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9580    0.9493    0.9535     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9534960768681049
F1-micro tok:  0.9893111638954869
**************************************************
Best epoch: 31
**************************************************

EPOCH: 37
Learning rate: 0.729000
train_cost_sum: 2653.71747225523
train_cost_avg: 0.18899775459406237
train_count_sent: 14041.0
train_total_correct_sent: 13949.0
train_accuracy_sent: 0.9934477601310447
train_count_tok: 203621.0
train_total_correct_tok: 202819.0
train_accuracy_tok: 0.9960613099827621
train_label=0_precision_sent: 0.9838543455857094
train_label=0_recall_sent: 0.9845307665864558
train_label=0_f-score_sent: 0.984192439862543
train_label=1_precision_sent: 0.9959568733153639
train_label=1_recall_sent: 0.9957779374775422
train_label=1_f-score_sent: 0.9958673973587279
train_precision_macro_sent: 0.9899056094505366
train_recall_macro_sent: 0.990154352031999
train_f-score_macro_sent: 0.9900299186106354
train_precision_micro_sent: 0.9934477601310447
train_recall_micro_sent: 0.9934477601310447
train_f-score_micro_sent: 0.9934477601310447
train_label=O_precision_tok: 0.9987616756297764
train_label=O_recall_tok: 0.9987970137635778
train_label=O_f-score_tok: 0.9987793443840997
train_label=LOC_precision_tok: 0.9837408165723233
train_label=LOC_recall_tok: 0.9844522116427624
train_label=LOC_f-score_tok: 0.9840963855421686
train_label=MISC_precision_tok: 0.9714472537053183
train_label=MISC_recall_tok: 0.9703897234922708
train_label=MISC_f-score_tok: 0.9709182006317395
train_label=ORG_precision_tok: 0.9781328007988018
train_label=ORG_recall_tok: 0.9771571072319202
train_label=ORG_f-score_tok: 0.9776447105788423
train_label=PER_precision_tok: 0.9903872068996497
train_label=PER_recall_tok: 0.9906542056074766
train_label=PER_f-score_tok: 0.9905206882609282
train_precision_macro_tok: 0.984493950721174
train_recall_macro_tok: 0.9842900523476017
train_f-score_macro_tok: 0.9843918658795555
train_precision_micro_tok: 0.9960613099827621
train_recall_micro_tok: 0.9960613099827621
train_f-score_micro_tok: 0.9960613099827621
train_time: 144.52620363235474
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9839    0.9845    0.9842      2909
           1     0.9960    0.9958    0.9959     11132

   micro avg     0.9934    0.9934    0.9934     14041
   macro avg     0.9899    0.9902    0.9900     14041
weighted avg     0.9934    0.9934    0.9934     14041

F1-macro sent:  0.9900299186106354
F1-micro sent:  0.9934477601310447
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9988    0.9988    0.9988    169578
         LOC     0.9837    0.9845    0.9841      8297
        MISC     0.9714    0.9704    0.9709      4593
         ORG     0.9781    0.9772    0.9776     10025
         PER     0.9904    0.9907    0.9905     11128

   micro avg     0.9961    0.9961    0.9961    203621
   macro avg     0.9845    0.9843    0.9844    203621
weighted avg     0.9961    0.9961    0.9961    203621

F1-macro tok:  0.9843918658795555
F1-micro tok:  0.9960613099827621
**************************************************
dev_cost_sum: 3189.2662417702377
dev_cost_avg: 0.9813126897754577
dev_count_sent: 3250.0
dev_total_correct_sent: 3216.0
dev_accuracy_sent: 0.9895384615384616
dev_count_tok: 51362.0
dev_total_correct_tok: 50813.0
dev_accuracy_tok: 0.9893111638954869
dev_label=0_precision_sent: 0.9872408293460925
dev_label=0_recall_sent: 0.9596899224806201
dev_label=0_f-score_sent: 0.9732704402515724
dev_label=1_precision_sent: 0.9900876858558902
dev_label=1_recall_sent: 0.9969289827255279
dev_label=1_f-score_sent: 0.9934965570007651
dev_precision_macro_sent: 0.9886642576009914
dev_recall_macro_sent: 0.978309452603074
dev_f-score_macro_sent: 0.9833834986261687
dev_precision_micro_sent: 0.9895384615384616
dev_recall_micro_sent: 0.9895384615384616
dev_f-score_micro_sent: 0.9895384615384616
dev_label=O_precision_tok: 0.9958443256367754
dev_label=O_recall_tok: 0.9975677635117753
dev_label=O_f-score_tok: 0.9967052995607066
dev_label=LOC_precision_tok: 0.9628394473558838
dev_label=LOC_recall_tok: 0.9651384909264565
dev_label=LOC_f-score_tok: 0.9639875983782495
dev_label=MISC_precision_tok: 0.9231404958677686
dev_label=MISC_recall_tok: 0.8809148264984227
dev_label=MISC_f-score_tok: 0.9015334947538338
dev_label=ORG_precision_tok: 0.9442542787286063
dev_label=ORG_recall_tok: 0.9230401529636711
dev_label=ORG_f-score_tok: 0.9335267101764564
dev_label=PER_precision_tok: 0.9729133858267717
dev_label=PER_recall_tok: 0.9809463321689426
dev_label=PER_f-score_tok: 0.9769133459835547
dev_precision_macro_tok: 0.9597983866831612
dev_recall_macro_tok: 0.9495215132138537
dev_f-score_macro_tok: 0.9545332897705603
dev_precision_micro_tok: 0.9893111638954869
dev_recall_micro_tok: 0.9893111638954869
dev_f-score_micro_tok: 0.9893111638954869
dev_time: 13.597549200057983
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9872    0.9597    0.9733       645
           1     0.9901    0.9969    0.9935      2605

   micro avg     0.9895    0.9895    0.9895      3250
   macro avg     0.9887    0.9783    0.9834      3250
weighted avg     0.9895    0.9895    0.9895      3250

F1-macro sent:  0.9833834986261687
F1-micro sent:  0.9895384615384616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9976    0.9967     42759
         LOC     0.9628    0.9651    0.9640      2094
        MISC     0.9231    0.8809    0.9015      1268
         ORG     0.9443    0.9230    0.9335      2092
         PER     0.9729    0.9809    0.9769      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9598    0.9495    0.9545     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9545332897705603
F1-micro tok:  0.9893111638954869
**************************************************
Best epoch: 31
**************************************************

EPOCH: 38
Learning rate: 0.656100
train_cost_sum: 2328.013494089246
train_cost_avg: 0.16580111773301373
train_count_sent: 14041.0
train_total_correct_sent: 13974.0
train_accuracy_sent: 0.9952282600954347
train_count_tok: 203621.0
train_total_correct_tok: 202926.0
train_accuracy_tok: 0.9965867960573811
train_label=0_precision_sent: 0.9876458476321208
train_label=0_recall_sent: 0.9893434169817806
train_label=0_f-score_sent: 0.9884939034861754
train_label=1_precision_sent: 0.9972139840028759
train_label=1_recall_sent: 0.9967660797700323
train_label=1_f-score_sent: 0.9969899815804844
train_precision_macro_sent: 0.9924299158174983
train_recall_macro_sent: 0.9930547483759065
train_f-score_macro_sent: 0.9927419425333299
train_precision_micro_sent: 0.9952282600954347
train_recall_micro_sent: 0.9952282600954347
train_f-score_micro_sent: 0.9952282600954347
train_label=O_precision_tok: 0.9989798686212306
train_label=O_recall_tok: 0.9990269964264232
train_label=O_f-score_tok: 0.9990034319680154
train_label=LOC_precision_tok: 0.9836341756919375
train_label=LOC_recall_tok: 0.9851753645896107
train_label=LOC_f-score_tok: 0.9844041669175648
train_label=MISC_precision_tok: 0.9774764924557183
train_label=MISC_recall_tok: 0.9732201175702155
train_label=MISC_f-score_tok: 0.9753436613571895
train_label=ORG_precision_tok: 0.9806309904153354
train_label=ORG_recall_tok: 0.9797506234413965
train_label=ORG_f-score_tok: 0.9801906092510353
train_label=PER_precision_tok: 0.9920079022988506
train_label=PER_recall_tok: 0.9927210639827462
train_label=PER_f-score_tok: 0.9923643550125764
train_precision_macro_tok: 0.9865458858966145
train_recall_macro_tok: 0.9859788332020785
train_f-score_macro_tok: 0.9862612449012763
train_precision_micro_tok: 0.9965867960573811
train_recall_micro_tok: 0.9965867960573811
train_f-score_micro_tok: 0.9965867960573811
train_time: 145.70476293563843
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9876    0.9893    0.9885      2909
           1     0.9972    0.9968    0.9970     11132

   micro avg     0.9952    0.9952    0.9952     14041
   macro avg     0.9924    0.9931    0.9927     14041
weighted avg     0.9952    0.9952    0.9952     14041

F1-macro sent:  0.9927419425333299
F1-micro sent:  0.9952282600954347
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9990    0.9990    0.9990    169578
         LOC     0.9836    0.9852    0.9844      8297
        MISC     0.9775    0.9732    0.9753      4593
         ORG     0.9806    0.9798    0.9802     10025
         PER     0.9920    0.9927    0.9924     11128

   micro avg     0.9966    0.9966    0.9966    203621
   macro avg     0.9865    0.9860    0.9863    203621
weighted avg     0.9966    0.9966    0.9966    203621

F1-macro tok:  0.9862612449012763
F1-micro tok:  0.9965867960573811
**************************************************
dev_cost_sum: 3301.3981176707894
dev_cost_avg: 1.0158148054371658
dev_count_sent: 3250.0
dev_total_correct_sent: 3219.0
dev_accuracy_sent: 0.9904615384615385
dev_count_tok: 51362.0
dev_total_correct_tok: 50824.0
dev_accuracy_tok: 0.9895253300105136
dev_label=0_precision_sent: 0.9796875
dev_label=0_recall_sent: 0.9720930232558139
dev_label=0_f-score_sent: 0.9758754863813228
dev_label=1_precision_sent: 0.993103448275862
dev_label=1_recall_sent: 0.9950095969289827
dev_label=1_f-score_sent: 0.9940556088207095
dev_precision_macro_sent: 0.986395474137931
dev_recall_macro_sent: 0.9835513100923983
dev_f-score_macro_sent: 0.9849655476010162
dev_precision_micro_sent: 0.9904615384615385
dev_recall_micro_sent: 0.9904615384615385
dev_f-score_micro_sent: 0.9904615384615385
dev_label=O_precision_tok: 0.9957759626604434
dev_label=O_recall_tok: 0.9978951799621132
dev_label=O_f-score_tok: 0.9968344449765795
dev_label=LOC_precision_tok: 0.9673390970220941
dev_label=LOC_recall_tok: 0.9617956064947469
dev_label=LOC_f-score_tok: 0.96455938697318
dev_label=MISC_precision_tok: 0.921681780708986
dev_label=MISC_recall_tok: 0.8817034700315457
dev_label=MISC_f-score_tok: 0.9012494961708988
dev_label=ORG_precision_tok: 0.9468765371372356
dev_label=ORG_recall_tok: 0.9201720841300192
dev_label=ORG_f-score_tok: 0.9333333333333333
dev_label=PER_precision_tok: 0.9729899497487438
dev_label=PER_recall_tok: 0.9838043823436011
dev_label=PER_f-score_tok: 0.978367282488552
dev_precision_macro_tok: 0.9609326654555005
dev_recall_macro_tok: 0.9490741445924054
dev_f-score_macro_tok: 0.9548687887885088
dev_precision_micro_tok: 0.9895253300105136
dev_recall_micro_tok: 0.9895253300105136
dev_f-score_micro_tok: 0.9895253300105136
dev_time: 13.938742876052856
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9797    0.9721    0.9759       645
           1     0.9931    0.9950    0.9941      2605

   micro avg     0.9905    0.9905    0.9905      3250
   macro avg     0.9864    0.9836    0.9850      3250
weighted avg     0.9904    0.9905    0.9904      3250

F1-macro sent:  0.9849655476010162
F1-micro sent:  0.9904615384615385
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9958    0.9979    0.9968     42759
         LOC     0.9673    0.9618    0.9646      2094
        MISC     0.9217    0.8817    0.9012      1268
         ORG     0.9469    0.9202    0.9333      2092
         PER     0.9730    0.9838    0.9784      3149

   micro avg     0.9895    0.9895    0.9895     51362
   macro avg     0.9609    0.9491    0.9549     51362
weighted avg     0.9894    0.9895    0.9894     51362

F1-macro tok:  0.9548687887885088
F1-micro tok:  0.9895253300105136
**************************************************
Best epoch: 31
**************************************************

test0_cost_sum: 3247.2353387624025
test0_cost_avg: 0.9991493350038162
test0_count_sent: 3250.0
test0_total_correct_sent: 3227.0
test0_accuracy_sent: 0.9929230769230769
test0_count_tok: 51362.0
test0_total_correct_tok: 50810.0
test0_accuracy_tok: 0.9892527549550251
test0_label=0_precision_sent: 0.9829192546583851
test0_label=0_recall_sent: 0.9813953488372092
test0_label=0_f-score_sent: 0.9821567106283942
test0_label=1_precision_sent: 0.9953952417498081
test0_label=1_recall_sent: 0.9957773512476008
test0_label=1_f-score_sent: 0.9955862598349645
test0_precision_macro_sent: 0.9891572482040967
test0_recall_macro_sent: 0.988586350042405
test0_f-score_macro_sent: 0.9888714852316793
test0_precision_micro_sent: 0.9929230769230769
test0_recall_micro_sent: 0.9929230769230769
test0_f-score_micro_sent: 0.9929230769230769
test0_label=O_precision_tok: 0.9961704611792177
test0_label=O_recall_tok: 0.9977080848476344
test0_label=O_f-score_tok: 0.9969386801271265
test0_label=LOC_precision_tok: 0.9495091164095372
test0_label=LOC_recall_tok: 0.9699140401146131
test0_label=LOC_f-score_tok: 0.959603118355776
test0_label=MISC_precision_tok: 0.9105560032232071
test0_label=MISC_recall_tok: 0.8911671924290221
test0_label=MISC_f-score_tok: 0.9007572738142687
test0_label=ORG_precision_tok: 0.9571788413098237
test0_label=ORG_recall_tok: 0.9082217973231358
test0_label=ORG_f-score_tok: 0.9320578857002697
test0_label=PER_precision_tok: 0.9735182849936949
test0_label=PER_recall_tok: 0.9806287710384249
test0_label=PER_f-score_tok: 0.977060591678532
test0_precision_macro_tok: 0.957386541423096
test0_recall_macro_tok: 0.9495279771505661
test0_f-score_macro_tok: 0.9532835099351946
test0_precision_micro_tok: 0.9892527549550251
test0_recall_micro_tok: 0.9892527549550251
test0_f-score_micro_tok: 0.9892527549550251
test0_time: 13.892489433288574
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9829    0.9814    0.9822       645
           1     0.9954    0.9958    0.9956      2605

   micro avg     0.9929    0.9929    0.9929      3250
   macro avg     0.9892    0.9886    0.9889      3250
weighted avg     0.9929    0.9929    0.9929      3250

F1-macro sent:  0.9888714852316793
F1-micro sent:  0.9929230769230769
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9962    0.9977    0.9969     42759
         LOC     0.9495    0.9699    0.9596      2094
        MISC     0.9106    0.8912    0.9008      1268
         ORG     0.9572    0.9082    0.9321      2092
         PER     0.9735    0.9806    0.9771      3149

   micro avg     0.9893    0.9893    0.9893     51362
   macro avg     0.9574    0.9495    0.9533     51362
weighted avg     0.9892    0.9893    0.9892     51362

F1-macro tok:  0.9532835099351946
F1-micro tok:  0.9892527549550251
**************************************************
test1_cost_sum: 6035.308258295059
test1_cost_avg: 1.7478448474645407
test1_count_sent: 3453.0
test1_total_correct_sent: 3362.0
test1_accuracy_sent: 0.9736461048363741
test1_count_tok: 46435.0
test1_total_correct_tok: 45446.0
test1_accuracy_tok: 0.9787014105739206
test1_label=0_precision_sent: 0.9675925925925926
test1_label=0_recall_sent: 0.8995695839311334
test1_label=0_f-score_sent: 0.9323420074349443
test1_label=1_precision_sent: 0.9750445632798574
test1_label=1_recall_sent: 0.9923802612481858
test1_label=1_f-score_sent: 0.9836360366840496
test1_precision_macro_sent: 0.971318577936225
test1_recall_macro_sent: 0.9459749225896597
test1_f-score_macro_sent: 0.957989022059497
test1_precision_micro_sent: 0.9736461048363741
test1_recall_micro_sent: 0.9736461048363741
test1_f-score_micro_sent: 0.9736461048363741
test1_label=O_precision_tok: 0.9946914225941422
test1_label=O_recall_tok: 0.992537118701563
test1_label=O_f-score_tok: 0.993613102934838
test1_label=LOC_precision_tok: 0.8865318204242724
test1_label=LOC_recall_tok: 0.9335064935064935
test1_label=LOC_f-score_tok: 0.9094129554655871
test1_label=MISC_precision_tok: 0.7708978328173375
test1_label=MISC_recall_tok: 0.8137254901960784
test1_label=MISC_f-score_tok: 0.7917329093799682
test1_label=ORG_precision_tok: 0.8975953565505804
test1_label=ORG_recall_tok: 0.8673878205128205
test1_label=ORG_f-score_tok: 0.8822330888345559
test1_label=PER_precision_tok: 0.9687836383207751
test1_label=PER_recall_tok: 0.9736747205192932
test1_label=PER_f-score_tok: 0.9712230215827339
test1_precision_macro_tok: 0.9037000141414214
test1_recall_macro_tok: 0.9161663286872497
test1_f-score_macro_tok: 0.9096430156395365
test1_precision_micro_tok: 0.9787014105739206
test1_recall_micro_tok: 0.9787014105739206
test1_f-score_micro_tok: 0.9787014105739206
test1_time: 13.297482013702393
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           0     0.9676    0.8996    0.9323       697
           1     0.9750    0.9924    0.9836      2756

   micro avg     0.9736    0.9736    0.9736      3453
   macro avg     0.9713    0.9460    0.9580      3453
weighted avg     0.9735    0.9736    0.9733      3453

F1-macro sent:  0.957989022059497
F1-micro sent:  0.9736461048363741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9947    0.9925    0.9936     38323
         LOC     0.8865    0.9335    0.9094      1925
        MISC     0.7709    0.8137    0.7917       918
         ORG     0.8976    0.8674    0.8822      2496
         PER     0.9688    0.9737    0.9712      2773

   micro avg     0.9787    0.9787    0.9787     46435
   macro avg     0.9037    0.9162    0.9096     46435
weighted avg     0.9790    0.9787    0.9788     46435

F1-macro tok:  0.9096430156395365
F1-micro tok:  0.9787014105739206
**************************************************
