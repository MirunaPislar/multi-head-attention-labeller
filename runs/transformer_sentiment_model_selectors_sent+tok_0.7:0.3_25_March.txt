to_write_filename: runs/transformer_sentiment_model_selectors_sent+tok_0.7:0.3_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:dev_f-score_macro_tok:high
model_selector_ratio: 0.7:0.3
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.0
maximum_gap_threshold: 0.0
sentence_composition: attention
random_seed: 100
{'O': 0, 'N': 1, 'P': 2}
{'O': 0, 'N': 1, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 427626.7840576172
train_cost_avg: 50.04995131760501
train_count_sent: 8544.0
train_total_correct_sent: 4266.0
train_accuracy_sent: 0.49929775280898875
train_count_tok: 163566.0
train_total_correct_tok: 125834.0
train_accuracy_tok: 0.7693163615910397
train_label=O_precision_sent: 0.2052401746724891
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.050728548300053966
train_label=N_precision_sent: 0.483757239989927
train_label=N_recall_sent: 0.5803625377643504
train_label=N_f-score_sent: 0.5276747699491827
train_label=P_precision_sent: 0.5290055248618785
train_label=P_recall_sent: 0.6365650969529086
train_label=P_f-score_sent: 0.5778224792557205
train_precision_macro_sent: 0.4060009798414315
train_recall_macro_sent: 0.41528950713892215
train_f-score_macro_sent: 0.3854085991683191
train_precision_micro_sent: 0.49929775280898875
train_recall_micro_sent: 0.49929775280898875
train_f-score_micro_sent: 0.49929775280898875
train_label=O_precision_tok: 0.7967790014634771
train_label=O_recall_tok: 0.9501154028645645
train_label=O_f-score_tok: 0.8667175303715007
train_label=N_precision_tok: 0.4972470750172058
train_label=N_recall_tok: 0.2034924658498803
train_label=N_f-score_tok: 0.28879784151094234
train_label=P_precision_tok: 0.5064893953782843
train_label=P_recall_tok: 0.19186952872047008
train_label=P_f-score_tok: 0.2783092711775961
train_precision_macro_tok: 0.6001718239529891
train_recall_macro_tok: 0.4484924658116383
train_f-score_macro_tok: 0.4779415476866797
train_precision_micro_tok: 0.7693163615910397
train_recall_micro_tok: 0.7693163615910397
train_f-score_micro_tok: 0.7693163615910398
train_time: 95.8350682258606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2052    0.0289    0.0507      1624
           N     0.4838    0.5804    0.5277      3310
           P     0.5290    0.6366    0.5778      3610

   micro avg     0.4993    0.4993    0.4993      8544
   macro avg     0.4060    0.4153    0.3854      8544
weighted avg     0.4499    0.4993    0.4582      8544

F1-macro sent:  0.3854085991683191
F1-micro sent:  0.49929775280898875
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7968    0.9501    0.8667    124347
           N     0.4972    0.2035    0.2888     14202
           P     0.5065    0.1919    0.2783     25017

   micro avg     0.7693    0.7693    0.7693    163566
   macro avg     0.6002    0.4485    0.4779    163566
weighted avg     0.7264    0.7693    0.7265    163566

F1-macro tok:  0.4779415476866797
F1-micro tok:  0.7693163615910398
**************************************************
dev_cost_sum: 50537.81896972656
dev_cost_avg: 45.90174293344828
dev_count_sent: 1101.0
dev_total_correct_sent: 585.0
dev_accuracy_sent: 0.5313351498637602
dev_count_tok: 21274.0
dev_total_correct_tok: 17475.0
dev_accuracy_tok: 0.8214252138760929
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.7162162162162162
dev_label=N_recall_sent: 0.37149532710280375
dev_label=N_f-score_sent: 0.48923076923076914
dev_label=P_precision_sent: 0.48464163822525597
dev_label=P_recall_sent: 0.9594594594594594
dev_label=P_f-score_sent: 0.6439909297052154
dev_precision_macro_sent: 0.4002859514804908
dev_recall_macro_sent: 0.44365159552075434
dev_f-score_macro_sent: 0.3777405663119948
dev_precision_micro_sent: 0.5313351498637602
dev_recall_micro_sent: 0.5313351498637602
dev_f-score_micro_sent: 0.5313351498637602
dev_label=O_precision_tok: 0.8311151174505541
dev_label=O_recall_tok: 0.9672323356988584
dev_label=O_f-score_tok: 0.8940223591147617
dev_label=N_precision_tok: 0.7242841993637328
dev_label=N_recall_tok: 0.36779752288637585
dev_label=N_f-score_tok: 0.4878571428571428
dev_label=P_precision_tok: 0.7595108695652174
dev_label=P_recall_tok: 0.3480697384806974
dev_label=P_f-score_tok: 0.47736976942783943
dev_precision_macro_tok: 0.771636728793168
dev_recall_macro_tok: 0.5610331990219772
dev_f-score_macro_tok: 0.619749757133248
dev_precision_micro_tok: 0.8214252138760929
dev_recall_micro_tok: 0.8214252138760929
dev_f-score_micro_tok: 0.8214252138760929
dev_time: 5.520326375961304
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.7162    0.3715    0.4892       428
           P     0.4846    0.9595    0.6440       444

   micro avg     0.5313    0.5313    0.5313      1101
   macro avg     0.4003    0.4437    0.3777      1101
weighted avg     0.4739    0.5313    0.4499      1101

F1-macro sent:  0.3777405663119948
F1-micro sent:  0.5313351498637602
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8311    0.9672    0.8940     16205
           N     0.7243    0.3678    0.4879      1857
           P     0.7595    0.3481    0.4774      3212

   micro avg     0.8214    0.8214    0.8214     21274
   macro avg     0.7716    0.5610    0.6197     21274
weighted avg     0.8110    0.8214    0.7957     21274

F1-macro tok:  0.619749757133248
F1-micro tok:  0.8214252138760929
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 378358.3143310547
train_cost_avg: 44.2835105724549
train_count_sent: 8544.0
train_total_correct_sent: 4876.0
train_accuracy_sent: 0.5706928838951311
train_count_tok: 163566.0
train_total_correct_tok: 132305.0
train_accuracy_tok: 0.8088783732560556
train_label=O_precision_sent: 0.17142857142857143
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007233273056057866
train_label=N_precision_sent: 0.5468120407679545
train_label=N_recall_sent: 0.6969788519637462
train_label=N_f-score_sent: 0.6128303891619074
train_label=P_precision_sent: 0.5974358974358974
train_label=P_recall_sent: 0.7099722991689751
train_label=P_f-score_sent: 0.648860759493671
train_precision_macro_sent: 0.4385588365441411
train_recall_macro_sent: 0.4702152441378365
train_f-score_macro_sent: 0.4229748072372121
train_precision_micro_sent: 0.5706928838951311
train_recall_micro_sent: 0.5706928838951311
train_f-score_micro_sent: 0.5706928838951311
train_label=O_precision_tok: 0.8321324684288743
train_label=O_recall_tok: 0.9501395288989682
train_label=O_f-score_tok: 0.8872292811871075
train_label=N_precision_tok: 0.637933073193804
train_label=N_recall_tok: 0.3798760737924236
train_label=N_f-score_tok: 0.4761904761904762
train_label=P_precision_tok: 0.6675045703839122
train_label=P_recall_tok: 0.3502818083703082
train_label=P_f-score_tok: 0.4594573338576484
train_precision_macro_tok: 0.7125233706688635
train_recall_macro_tok: 0.5600991370205667
train_f-score_macro_tok: 0.6076256970784107
train_precision_micro_tok: 0.8088783732560556
train_recall_micro_tok: 0.8088783732560556
train_f-score_micro_tok: 0.8088783732560556
train_time: 94.33303093910217
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1714    0.0037    0.0072      1624
           N     0.5468    0.6970    0.6128      3310
           P     0.5974    0.7100    0.6489      3610

   micro avg     0.5707    0.5707    0.5707      8544
   macro avg     0.4386    0.4702    0.4230      8544
weighted avg     0.4969    0.5707    0.5129      8544

F1-macro sent:  0.4229748072372121
F1-micro sent:  0.5706928838951311
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8321    0.9501    0.8872    124347
           N     0.6379    0.3799    0.4762     14202
           P     0.6675    0.3503    0.4595     25017

   micro avg     0.8089    0.8089    0.8089    163566
   macro avg     0.7125    0.5601    0.6076    163566
weighted avg     0.7901    0.8089    0.7861    163566

F1-macro tok:  0.6076256970784107
F1-micro tok:  0.8088783732560556
**************************************************
dev_cost_sum: 49169.61096191406
dev_cost_avg: 44.659047195198966
dev_count_sent: 1101.0
dev_total_correct_sent: 574.0
dev_accuracy_sent: 0.5213442325158947
dev_count_tok: 21274.0
dev_total_correct_tok: 17709.0
dev_accuracy_tok: 0.8324245557958071
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.45154419595314166
dev_label=N_recall_sent: 0.9906542056074766
dev_label=N_f-score_sent: 0.62033650329188
dev_label=P_precision_sent: 0.9259259259259259
dev_label=P_recall_sent: 0.33783783783783783
dev_label=P_f-score_sent: 0.49504950495049505
dev_precision_macro_sent: 0.4591567072930225
dev_recall_macro_sent: 0.44283068114843815
dev_f-score_macro_sent: 0.3717953360807917
dev_precision_micro_sent: 0.5213442325158947
dev_recall_micro_sent: 0.5213442325158947
dev_f-score_micro_sent: 0.5213442325158947
dev_label=O_precision_tok: 0.8430749340085115
dev_label=O_recall_tok: 0.9657513113236655
dev_label=O_f-score_tok: 0.9002531063046479
dev_label=N_precision_tok: 0.6844444444444444
dev_label=N_recall_tok: 0.4975767366720517
dev_label=N_f-score_tok: 0.5762394761459307
dev_label=P_precision_tok: 0.8339456282145481
dev_label=P_recall_tok: 0.35336239103362393
dev_label=P_f-score_tok: 0.49639186529630447
dev_precision_macro_tok: 0.7871550022225012
dev_recall_macro_tok: 0.6055634796764471
dev_f-score_macro_tok: 0.6576281492489611
dev_precision_micro_tok: 0.8324245557958071
dev_recall_micro_tok: 0.8324245557958071
dev_f-score_micro_tok: 0.8324245557958071
dev_time: 5.134357690811157
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4515    0.9907    0.6203       428
           P     0.9259    0.3378    0.4950       444

   micro avg     0.5213    0.5213    0.5213      1101
   macro avg     0.4592    0.4428    0.3718      1101
weighted avg     0.5489    0.5213    0.4408      1101

F1-macro sent:  0.3717953360807917
F1-micro sent:  0.5213442325158947
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8431    0.9658    0.9003     16205
           N     0.6844    0.4976    0.5762      1857
           P     0.8339    0.3534    0.4964      3212

   micro avg     0.8324    0.8324    0.8324     21274
   macro avg     0.7872    0.6056    0.6576     21274
weighted avg     0.8278    0.8324    0.8110     21274

F1-macro tok:  0.6576281492489611
F1-micro tok:  0.8324245557958071
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 368229.48010253906
train_cost_avg: 43.09801967492265
train_count_sent: 8544.0
train_total_correct_sent: 5075.0
train_accuracy_sent: 0.5939840823970037
train_count_tok: 163566.0
train_total_correct_tok: 135663.0
train_accuracy_tok: 0.8294083122409303
train_label=O_precision_sent: 0.17391304347826086
train_label=O_recall_sent: 0.0024630541871921183
train_label=O_f-score_sent: 0.004857316332726169
train_label=N_precision_sent: 0.565530039434006
train_label=N_recall_sent: 0.7365558912386707
train_label=N_f-score_sent: 0.6398110484188427
train_label=P_precision_sent: 0.62541567695962
train_label=P_recall_sent: 0.7293628808864266
train_label=P_f-score_sent: 0.6734015345268541
train_precision_macro_sent: 0.45495291995729564
train_recall_macro_sent: 0.4894606087707632
train_f-score_macro_sent: 0.43935663309280765
train_precision_micro_sent: 0.5939840823970037
train_recall_micro_sent: 0.5939840823970037
train_f-score_micro_sent: 0.5939840823970037
train_label=O_precision_tok: 0.849874232315487
train_label=O_recall_tok: 0.9537343080251233
train_label=O_f-score_tok: 0.8988138997309486
train_label=N_precision_tok: 0.6756520790134235
train_label=N_recall_tok: 0.4359245176735671
train_label=N_f-score_tok: 0.52993794136529
train_label=P_precision_tok: 0.7320323014804845
train_label=P_recall_tok: 0.43482431946276534
train_label=P_f-score_tok: 0.5455776512776789
train_precision_macro_tok: 0.7525195376031316
train_recall_macro_tok: 0.6081610483871519
train_f-score_macro_tok: 0.6581098307913058
train_precision_micro_tok: 0.8294083122409303
train_recall_micro_tok: 0.8294083122409303
train_f-score_micro_tok: 0.8294083122409304
train_time: 94.91116547584534
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1739    0.0025    0.0049      1624
           N     0.5655    0.7366    0.6398      3310
           P     0.6254    0.7294    0.6734      3610

   micro avg     0.5940    0.5940    0.5940      8544
   macro avg     0.4550    0.4895    0.4394      8544
weighted avg     0.5164    0.5940    0.5333      8544

F1-macro sent:  0.43935663309280765
F1-micro sent:  0.5939840823970037
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8499    0.9537    0.8988    124347
           N     0.6757    0.4359    0.5299     14202
           P     0.7320    0.4348    0.5456     25017

   micro avg     0.8294    0.8294    0.8294    163566
   macro avg     0.7525    0.6082    0.6581    163566
weighted avg     0.8167    0.8294    0.8128    163566

F1-macro tok:  0.6581098307913058
F1-micro tok:  0.8294083122409304
**************************************************
dev_cost_sum: 48104.294860839844
dev_cost_avg: 43.691457639273246
dev_count_sent: 1101.0
dev_total_correct_sent: 672.0
dev_accuracy_sent: 0.6103542234332425
dev_count_tok: 21274.0
dev_total_correct_tok: 18224.0
dev_accuracy_tok: 0.8566325091661182
dev_label=O_precision_sent: 0.3953488372093023
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.12500000000000003
dev_label=N_precision_sent: 0.6244725738396625
dev_label=N_recall_sent: 0.6915887850467289
dev_label=N_f-score_sent: 0.6563192904656319
dev_label=P_precision_sent: 0.6147260273972602
dev_label=P_recall_sent: 0.8085585585585585
dev_label=P_f-score_sent: 0.6984435797665369
dev_precision_macro_sent: 0.5448491461487417
dev_recall_macro_sent: 0.5247943838218498
dev_f-score_macro_sent: 0.4932542900773896
dev_precision_micro_sent: 0.6103542234332425
dev_recall_micro_sent: 0.6103542234332425
dev_f-score_micro_sent: 0.6103542234332425
dev_label=O_precision_tok: 0.8714373705134666
dev_label=O_recall_tok: 0.9603825979635915
dev_label=O_f-score_tok: 0.913750587130108
dev_label=N_precision_tok: 0.7218543046357616
dev_label=N_recall_tok: 0.46957458266020463
dev_label=N_f-score_tok: 0.569004893964111
dev_label=P_precision_tok: 0.8106026280018124
dev_label=P_recall_tok: 0.5569738480697385
dev_label=P_f-score_tok: 0.6602694224026573
dev_precision_macro_tok: 0.8012981010503468
dev_recall_macro_tok: 0.6623103428978449
dev_f-score_macro_tok: 0.7143416344989588
dev_precision_micro_tok: 0.8566325091661182
dev_recall_micro_tok: 0.8566325091661182
dev_f-score_micro_tok: 0.8566325091661182
dev_time: 5.136263847351074
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3953    0.0742    0.1250       229
           N     0.6245    0.6916    0.6563       428
           P     0.6147    0.8086    0.6984       444

   micro avg     0.6104    0.6104    0.6104      1101
   macro avg     0.5448    0.5248    0.4933      1101
weighted avg     0.5729    0.6104    0.5628      1101

F1-macro sent:  0.4932542900773896
F1-micro sent:  0.6103542234332425
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8714    0.9604    0.9138     16205
           N     0.7219    0.4696    0.5690      1857
           P     0.8106    0.5570    0.6603      3212

   micro avg     0.8566    0.8566    0.8566     21274
   macro avg     0.8013    0.6623    0.7143     21274
weighted avg     0.8492    0.8566    0.8454     21274

F1-macro tok:  0.7143416344989588
F1-micro tok:  0.8566325091661182
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 361427.4364013672
train_cost_avg: 42.30190032787537
train_count_sent: 8544.0
train_total_correct_sent: 5149.0
train_accuracy_sent: 0.6026451310861424
train_count_tok: 163566.0
train_total_correct_tok: 137690.0
train_accuracy_tok: 0.8418008632600907
train_label=O_precision_sent: 0.18181818181818182
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002446483180428135
train_label=N_precision_sent: 0.5784807093218308
train_label=N_recall_sent: 0.7293051359516616
train_label=N_f-score_sent: 0.6451957770947481
train_label=P_precision_sent: 0.626834862385321
train_label=P_recall_sent: 0.7570637119113574
train_label=P_f-score_sent: 0.6858218318695106
train_precision_macro_sent: 0.4623779178417779
train_recall_macro_sent: 0.49586679165220504
train_f-score_macro_sent: 0.44448803071489557
train_precision_micro_sent: 0.6026451310861424
train_recall_micro_sent: 0.6026451310861424
train_f-score_micro_sent: 0.6026451310861424
train_label=O_precision_tok: 0.8601919557937524
train_label=O_recall_tok: 0.9564444658898084
train_label=O_f-score_tok: 0.9057682934259428
train_label=N_precision_tok: 0.6956244011497924
train_label=N_recall_tok: 0.4600760456273764
train_label=N_f-score_tok: 0.5538461538461539
train_label=P_precision_tok: 0.7682880844645551
train_label=P_recall_tok: 0.48866770595994724
train_label=P_f-score_tok: 0.5973759437073958
train_precision_macro_tok: 0.7747014804693667
train_recall_macro_tok: 0.6350627391590441
train_f-score_macro_tok: 0.6856634636598308
train_precision_micro_tok: 0.8418008632600907
train_recall_micro_tok: 0.8418008632600907
train_f-score_micro_tok: 0.8418008632600907
train_time: 95.30021524429321
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1818    0.0012    0.0024      1624
           N     0.5785    0.7293    0.6452      3310
           P     0.6268    0.7571    0.6858      3610

   micro avg     0.6026    0.6026    0.6026      8544
   macro avg     0.4624    0.4959    0.4445      8544
weighted avg     0.5235    0.6026    0.5402      8544

F1-macro sent:  0.44448803071489557
F1-micro sent:  0.6026451310861424
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8602    0.9564    0.9058    124347
           N     0.6956    0.4601    0.5538     14202
           P     0.7683    0.4887    0.5974     25017

   micro avg     0.8418    0.8418    0.8418    163566
   macro avg     0.7747    0.6351    0.6857    163566
weighted avg     0.8318    0.8418    0.8280    163566

F1-macro tok:  0.6856634636598308
F1-micro tok:  0.8418008632600907
**************************************************
dev_cost_sum: 47318.61804199219
dev_cost_avg: 42.977854715705895
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18387.0
dev_accuracy_tok: 0.8642944439221585
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6398390342052314
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.6875675675675675
dev_label=P_precision_sent: 0.6135986733001658
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7067812798471824
dev_precision_macro_sent: 0.7511459025017991
dev_recall_macro_sent: 0.5268969332553384
dev_f-score_macro_sent: 0.4676814998628876
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.8709070796460177
dev_label=O_recall_tok: 0.9716754088244369
dev_label=O_f-score_tok: 0.9185358028292256
dev_label=N_precision_tok: 0.7646536412078153
dev_label=N_recall_tok: 0.46365105008077545
dev_label=N_f-score_tok: 0.577271203486423
dev_label=P_precision_tok: 0.8607350096711799
dev_label=P_recall_tok: 0.5541718555417185
dev_label=P_f-score_tok: 0.6742424242424242
dev_precision_macro_tok: 0.832098576841671
dev_recall_macro_tok: 0.6631661048156436
dev_f-score_macro_tok: 0.7233498101860243
dev_precision_micro_tok: 0.8642944439221585
dev_recall_micro_tok: 0.8642944439221585
dev_f-score_micro_tok: 0.8642944439221585
dev_time: 5.245175123214722
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6398    0.7430    0.6876       428
           P     0.6136    0.8333    0.7068       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.7511    0.5269    0.4677      1101
weighted avg     0.7042    0.6258    0.5541      1101

F1-macro sent:  0.4676814998628876
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8709    0.9717    0.9185     16205
           N     0.7647    0.4637    0.5773      1857
           P     0.8607    0.5542    0.6742      3212

   micro avg     0.8643    0.8643    0.8643     21274
   macro avg     0.8321    0.6632    0.7233     21274
weighted avg     0.8601    0.8643    0.8519     21274

F1-macro tok:  0.7233498101860243
F1-micro tok:  0.8642944439221585
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 355299.16760253906
train_cost_avg: 41.5846404029189
train_count_sent: 8544.0
train_total_correct_sent: 5214.0
train_accuracy_sent: 0.610252808988764
train_count_tok: 163566.0
train_total_correct_tok: 139262.0
train_accuracy_tok: 0.8514116625704609
train_label=O_precision_sent: 0.3125
train_label=O_recall_sent: 0.009236453201970444
train_label=O_f-score_sent: 0.01794258373205742
train_label=N_precision_sent: 0.5805698271835591
train_label=N_recall_sent: 0.7510574018126889
train_label=N_f-score_sent: 0.6548998946259221
train_label=P_precision_sent: 0.6438063597532037
train_label=P_recall_sent: 0.7515235457063711
train_label=P_f-score_sent: 0.6935071574642128
train_precision_macro_sent: 0.5122920623122543
train_recall_macro_sent: 0.5039391335736768
train_f-score_macro_sent: 0.45544987860739744
train_precision_micro_sent: 0.610252808988764
train_recall_micro_sent: 0.610252808988764
train_f-score_micro_sent: 0.610252808988764
train_label=O_precision_tok: 0.8667053490480507
train_label=O_recall_tok: 0.9609962443806445
train_label=O_f-score_tok: 0.9114185689987871
train_label=N_precision_tok: 0.7115241635687732
train_label=N_recall_tok: 0.4716941275876637
train_label=N_f-score_tok: 0.5673032137866791
train_label=P_precision_tok: 0.8027770951093635
train_label=P_recall_tok: 0.5222848463045129
train_label=P_f-score_tok: 0.6328433390647324
train_precision_macro_tok: 0.7936688692420625
train_recall_macro_tok: 0.6516584060909404
train_f-score_macro_tok: 0.703855040616733
train_precision_micro_tok: 0.8514116625704609
train_recall_micro_tok: 0.8514116625704609
train_f-score_micro_tok: 0.8514116625704609
train_time: 94.58799767494202
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3125    0.0092    0.0179      1624
           N     0.5806    0.7511    0.6549      3310
           P     0.6438    0.7515    0.6935      3610

   micro avg     0.6103    0.6103    0.6103      8544
   macro avg     0.5123    0.5039    0.4554      8544
weighted avg     0.5563    0.6103    0.5501      8544

F1-macro sent:  0.45544987860739744
F1-micro sent:  0.610252808988764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8667    0.9610    0.9114    124347
           N     0.7115    0.4717    0.5673     14202
           P     0.8028    0.5223    0.6328     25017

   micro avg     0.8514    0.8514    0.8514    163566
   macro avg     0.7937    0.6517    0.7039    163566
weighted avg     0.8435    0.8514    0.8389    163566

F1-macro tok:  0.703855040616733
F1-micro tok:  0.8514116625704609
**************************************************
dev_cost_sum: 46680.257385253906
dev_cost_avg: 42.39805393756031
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18519.0
dev_accuracy_tok: 0.8704992009025101
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5909090909090909
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.6973180076628352
dev_label=P_precision_sent: 0.6701030927835051
dev_label=P_recall_sent: 0.7319819819819819
dev_label=P_f-score_sent: 0.6996770721205596
dev_precision_macro_sent: 0.42033739456419866
dev_recall_macro_sent: 0.5274830905672027
dev_f-score_macro_sent: 0.465665026594465
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.8802378414764122
dev_label=O_recall_tok: 0.968343103980253
dev_label=O_f-score_tok: 0.9221908791725435
dev_label=N_precision_tok: 0.7390636991557943
dev_label=N_recall_tok: 0.518578352180937
dev_label=N_f-score_tok: 0.6094936708860759
dev_label=P_precision_tok: 0.8694029850746269
dev_label=P_recall_tok: 0.5803237858032378
dev_label=P_f-score_tok: 0.6960418222554144
dev_precision_macro_tok: 0.8295681752356111
dev_recall_macro_tok: 0.689081747321476
dev_f-score_macro_tok: 0.7425754574380113
dev_precision_micro_tok: 0.8704992009025101
dev_recall_micro_tok: 0.8704992009025101
dev_f-score_micro_tok: 0.87049920090251
dev_time: 5.087465047836304
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5909    0.8505    0.6973       428
           P     0.6701    0.7320    0.6997       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.4203    0.5275    0.4657      1101
weighted avg     0.4999    0.6258    0.5532      1101

F1-macro sent:  0.465665026594465
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8802    0.9683    0.9222     16205
           N     0.7391    0.5186    0.6095      1857
           P     0.8694    0.5803    0.6960      3212

   micro avg     0.8705    0.8705    0.8705     21274
   macro avg     0.8296    0.6891    0.7426     21274
weighted avg     0.8663    0.8705    0.8608     21274

F1-macro tok:  0.7425754574380113
F1-micro tok:  0.87049920090251
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 350669.6403808594
train_cost_avg: 41.042794988396466
train_count_sent: 8544.0
train_total_correct_sent: 5232.0
train_accuracy_sent: 0.6123595505617978
train_count_tok: 163566.0
train_total_correct_tok: 140282.0
train_accuracy_tok: 0.8576476773901667
train_label=O_precision_sent: 0.29850746268656714
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.023654642223536373
train_label=N_precision_sent: 0.5808720112517581
train_label=N_recall_sent: 0.7486404833836858
train_label=N_f-score_sent: 0.6541710665258712
train_label=P_precision_sent: 0.6492519591545951
train_label=P_recall_sent: 0.7573407202216067
train_label=P_f-score_sent: 0.6991433320547245
train_precision_macro_sent: 0.5095438110309735
train_recall_macro_sent: 0.5060988248470845
train_f-score_macro_sent: 0.458989680268044
train_precision_micro_sent: 0.6123595505617978
train_recall_micro_sent: 0.6123595505617978
train_f-score_micro_sent: 0.6123595505617978
train_label=O_precision_tok: 0.8718357424632808
train_label=O_recall_tok: 0.9633123436834021
train_label=O_f-score_tok: 0.915294126636637
train_label=N_precision_tok: 0.7261756138160632
train_label=N_recall_tok: 0.4914800732291227
train_label=N_f-score_tok: 0.586209792558999
train_label=P_precision_tok: 0.816243961352657
train_label=P_recall_tok: 0.5403125874405404
train_label=P_f-score_tok: 0.6502152632465065
train_precision_macro_tok: 0.8047517725440003
train_recall_macro_tok: 0.6650350014510217
train_f-score_macro_tok: 0.7172397274807142
train_precision_micro_tok: 0.8576476773901667
train_recall_micro_tok: 0.8576476773901667
train_f-score_micro_tok: 0.8576476773901666
train_time: 94.70554280281067
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2985    0.0123    0.0237      1624
           N     0.5809    0.7486    0.6542      3310
           P     0.6493    0.7573    0.6991      3610

   micro avg     0.6124    0.6124    0.6124      8544
   macro avg     0.5095    0.5061    0.4590      8544
weighted avg     0.5561    0.6124    0.5533      8544

F1-macro sent:  0.458989680268044
F1-micro sent:  0.6123595505617978
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8718    0.9633    0.9153    124347
           N     0.7262    0.4915    0.5862     14202
           P     0.8162    0.5403    0.6502     25017

   micro avg     0.8576    0.8576    0.8576    163566
   macro avg     0.8048    0.6650    0.7172    163566
weighted avg     0.8507    0.8576    0.8462    163566

F1-macro tok:  0.7172397274807142
F1-micro tok:  0.8576476773901666
**************************************************
dev_cost_sum: 46260.576416015625
dev_cost_avg: 42.01687231245742
dev_count_sent: 1101.0
dev_total_correct_sent: 685.0
dev_accuracy_sent: 0.6221616712079927
dev_count_tok: 21274.0
dev_total_correct_tok: 18578.0
dev_accuracy_tok: 0.8732725392497884
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5993091537132987
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.689175769612711
dev_label=P_precision_sent: 0.6475095785440613
dev_label=P_recall_sent: 0.7612612612612613
dev_label=P_f-score_sent: 0.6997929606625258
dev_precision_macro_sent: 0.41560624408578667
dev_recall_macro_sent: 0.5240029749375544
dev_f-score_macro_sent: 0.4629895767584123
dev_precision_micro_sent: 0.6221616712079927
dev_recall_micro_sent: 0.6221616712079927
dev_f-score_micro_sent: 0.6221616712079927
dev_label=O_precision_tok: 0.8757115225200331
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9239650145772595
dev_label=N_precision_tok: 0.7927461139896373
dev_label=N_recall_tok: 0.49434571890145396
dev_label=N_f-score_tok: 0.608955223880597
dev_label=P_precision_tok: 0.8975754576942108
dev_label=P_recall_tok: 0.5647571606475716
dev_label=P_f-score_tok: 0.6932925664055036
dev_precision_macro_tok: 0.855344364734627
dev_recall_macro_tok: 0.6789830744233664
dev_f-score_macro_tok: 0.7420709349544534
dev_precision_micro_tok: 0.8732725392497884
dev_recall_micro_tok: 0.8732725392497884
dev_f-score_micro_tok: 0.8732725392497884
dev_time: 5.0912926197052
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5993    0.8107    0.6892       428
           P     0.6475    0.7613    0.6998       444

   micro avg     0.6222    0.6222    0.6222      1101
   macro avg     0.4156    0.5240    0.4630      1101
weighted avg     0.4941    0.6222    0.5501      1101

F1-macro sent:  0.4629895767584123
F1-micro sent:  0.6221616712079927
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8757    0.9778    0.9240     16205
           N     0.7927    0.4943    0.6090      1857
           P     0.8976    0.5648    0.6933      3212

   micro avg     0.8733    0.8733    0.8733     21274
   macro avg     0.8553    0.6790    0.7421     21274
weighted avg     0.8718    0.8733    0.8616     21274

F1-macro tok:  0.7420709349544534
F1-micro tok:  0.8732725392497884
**************************************************
Best epoch: 2
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 346460.6280517578
train_cost_avg: 40.55016714088926
train_count_sent: 8544.0
train_total_correct_sent: 5310.0
train_accuracy_sent: 0.6214887640449438
train_count_tok: 163566.0
train_total_correct_tok: 141045.0
train_accuracy_tok: 0.8623124610249073
train_label=O_precision_sent: 0.38596491228070173
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.026174895895300417
train_label=N_precision_sent: 0.584632768361582
train_label=N_recall_sent: 0.781570996978852
train_label=N_f-score_sent: 0.6689075630252102
train_label=P_precision_sent: 0.6649433776464796
train_label=P_recall_sent: 0.7481994459833795
train_label=P_f-score_sent: 0.7041188738269031
train_precision_macro_sent: 0.5451803527629211
train_recall_macro_sent: 0.514439080330596
train_f-score_macro_sent: 0.4664004442491379
train_precision_micro_sent: 0.6214887640449438
train_recall_micro_sent: 0.6214887640449438
train_f-score_micro_sent: 0.6214887640449438
train_label=O_precision_tok: 0.875400293244436
train_label=O_recall_tok: 0.9650896282178099
train_label=O_f-score_tok: 0.9180596249913936
train_label=N_precision_tok: 0.7326067026586534
train_label=N_recall_tok: 0.5064075482326433
train_label=N_f-score_tok: 0.59885923643782
train_label=P_precision_tok: 0.8310526947545313
train_label=P_recall_tok: 0.5535036175400727
train_label=P_f-score_tok: 0.6644593200412677
train_precision_macro_tok: 0.8130198968858736
train_recall_macro_tok: 0.6750002646635087
train_f-score_macro_tok: 0.7271260604901605
train_precision_micro_tok: 0.8623124610249073
train_recall_micro_tok: 0.8623124610249073
train_f-score_micro_tok: 0.8623124610249073
train_time: 100.126953125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3860    0.0135    0.0262      1624
           N     0.5846    0.7816    0.6689      3310
           P     0.6649    0.7482    0.7041      3610

   micro avg     0.6215    0.6215    0.6215      8544
   macro avg     0.5452    0.5144    0.4664      8544
weighted avg     0.5808    0.6215    0.5616      8544

F1-macro sent:  0.4664004442491379
F1-micro sent:  0.6214887640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8754    0.9651    0.9181    124347
           N     0.7326    0.5064    0.5989     14202
           P     0.8311    0.5535    0.6645     25017

   micro avg     0.8623    0.8623    0.8623    163566
   macro avg     0.8130    0.6750    0.7271    163566
weighted avg     0.8562    0.8623    0.8516    163566

F1-macro tok:  0.7271260604901605
F1-micro tok:  0.8623124610249073
**************************************************
dev_cost_sum: 45942.70104980469
dev_cost_avg: 41.72815717511779
dev_count_sent: 1101.0
dev_total_correct_sent: 667.0
dev_accuracy_sent: 0.6058128973660308
dev_count_tok: 21274.0
dev_total_correct_tok: 18701.0
dev_accuracy_tok: 0.8790542446178434
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.7171428571428572
dev_label=N_recall_sent: 0.5864485981308412
dev_label=N_f-score_sent: 0.6452442159383034
dev_label=P_precision_sent: 0.5519568151147098
dev_label=P_recall_sent: 0.9211711711711712
dev_label=P_f-score_sent: 0.690295358649789
dev_precision_macro_sent: 0.656366557419189
dev_recall_macro_sent: 0.5127291516305107
dev_f-score_macro_sent: 0.464705660148611
dev_precision_micro_sent: 0.6058128973660308
dev_recall_micro_sent: 0.6058128973660308
dev_f-score_micro_sent: 0.6058128973660308
dev_label=O_precision_tok: 0.8795107372149656
dev_label=O_recall_tok: 0.9806232644245603
dev_label=O_f-score_tok: 0.9273188807516121
dev_label=N_precision_tok: 0.844574780058651
dev_label=N_recall_tok: 0.46526655896607433
dev_label=N_f-score_tok: 0.6
dev_label=P_precision_tok: 0.891433806688044
dev_label=P_recall_tok: 0.6058530510585305
dev_label=P_f-score_tok: 0.7214087117701575
dev_precision_macro_tok: 0.8718397746538868
dev_recall_macro_tok: 0.683914291483055
dev_f-score_macro_tok: 0.7495758641739232
dev_precision_micro_tok: 0.8790542446178434
dev_recall_micro_tok: 0.8790542446178434
dev_f-score_micro_tok: 0.8790542446178434
dev_time: 8.427935600280762
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.7171    0.5864    0.6452       428
           P     0.5520    0.9212    0.6903       444

   micro avg     0.6058    0.6058    0.6058      1101
   macro avg     0.6564    0.5127    0.4647      1101
weighted avg     0.6470    0.6058    0.5414      1101

F1-macro sent:  0.464705660148611
F1-micro sent:  0.6058128973660308
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8795    0.9806    0.9273     16205
           N     0.8446    0.4653    0.6000      1857
           P     0.8914    0.6059    0.7214      3212

   micro avg     0.8791    0.8791    0.8791     21274
   macro avg     0.8718    0.6839    0.7496     21274
weighted avg     0.8783    0.8791    0.8677     21274

F1-macro tok:  0.7495758641739232
F1-micro tok:  0.8790542446178434
**************************************************
Best epoch: 2
**************************************************

EPOCH: 7
Learning rate: 0.900000
train_cost_sum: 342270.59197998047
train_cost_avg: 40.05976029728236
train_count_sent: 8544.0
train_total_correct_sent: 5383.0
train_accuracy_sent: 0.6300327715355806
train_count_tok: 163566.0
train_total_correct_tok: 141786.0
train_accuracy_tok: 0.8668427423792231
train_label=O_precision_sent: 0.4051724137931034
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.054022988505747126
train_label=N_precision_sent: 0.6074993912831751
train_label=N_recall_sent: 0.7537764350453172
train_label=N_f-score_sent: 0.6727787515167858
train_label=P_precision_sent: 0.6574866928951631
train_label=P_recall_sent: 0.7869806094182825
train_label=P_f-score_sent: 0.7164292018660949
train_precision_macro_sent: 0.5567194993238139
train_recall_macro_sent: 0.5232326437210357
train_f-score_macro_sent: 0.48107698062954257
train_precision_micro_sent: 0.6300327715355806
train_recall_micro_sent: 0.6300327715355806
train_f-score_micro_sent: 0.6300327715355806
train_label=O_precision_tok: 0.8792046468755029
train_label=O_recall_tok: 0.9665050222361617
train_label=O_f-score_tok: 0.9207902206933012
train_label=N_precision_tok: 0.7437462477486492
train_label=N_recall_tok: 0.5233769891564568
train_label=N_f-score_tok: 0.6143990742271449
train_label=P_precision_tok: 0.8396136983054864
train_label=P_recall_tok: 0.5664548107287045
train_label=P_f-score_tok: 0.676500775748896
train_precision_macro_tok: 0.8208548643098794
train_recall_macro_tok: 0.6854456073737744
train_f-score_macro_tok: 0.7372300235564474
train_precision_micro_tok: 0.8668427423792231
train_recall_micro_tok: 0.8668427423792231
train_f-score_micro_tok: 0.8668427423792231
train_time: 144.69615125656128
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4052    0.0289    0.0540      1624
           N     0.6075    0.7538    0.6728      3310
           P     0.6575    0.7870    0.7164      3610

   micro avg     0.6300    0.6300    0.6300      8544
   macro avg     0.5567    0.5232    0.4811      8544
weighted avg     0.5902    0.6300    0.5736      8544

F1-macro sent:  0.48107698062954257
F1-micro sent:  0.6300327715355806
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8792    0.9665    0.9208    124347
           N     0.7437    0.5234    0.6144     14202
           P     0.8396    0.5665    0.6765     25017

   micro avg     0.8668    0.8668    0.8668    163566
   macro avg     0.8209    0.6854    0.7372    163566
weighted avg     0.8614    0.8668    0.8568    163566

F1-macro tok:  0.7372300235564474
F1-micro tok:  0.8668427423792231
**************************************************
dev_cost_sum: 45429.421875
dev_cost_avg: 41.26196355585831
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 18741.0
dev_accuracy_tok: 0.8809344740058287
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5735735735735735
dev_label=N_recall_sent: 0.8925233644859814
dev_label=N_f-score_sent: 0.6983546617915906
dev_label=P_precision_sent: 0.7218390804597701
dev_label=P_recall_sent: 0.7072072072072072
dev_label=P_f-score_sent: 0.7144482366325369
dev_precision_macro_sent: 0.43180421801111457
dev_recall_macro_sent: 0.5332435238977294
dev_f-score_macro_sent: 0.47093429947470916
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.8840321141837645
dev_label=O_recall_tok: 0.9784634372107375
dev_label=O_f-score_tok: 0.9288538707126329
dev_label=N_precision_tok: 0.7690014903129657
dev_label=N_recall_tok: 0.555735056542811
dev_label=N_f-score_tok: 0.6452016255079712
dev_label=P_precision_tok: 0.9283567134268537
dev_label=P_recall_tok: 0.5768991282689913
dev_label=P_f-score_tok: 0.7115975422427034
dev_precision_macro_tok: 0.8604634393078613
dev_recall_macro_tok: 0.7036992073408466
dev_f-score_macro_tok: 0.7618843461544359
dev_precision_micro_tok: 0.8809344740058287
dev_recall_micro_tok: 0.8809344740058287
dev_f-score_micro_tok: 0.8809344740058287
dev_time: 8.348841905593872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5736    0.8925    0.6984       428
           P     0.7218    0.7072    0.7144       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.4318    0.5332    0.4709      1101
weighted avg     0.5141    0.6322    0.5596      1101

F1-macro sent:  0.47093429947470916
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8840    0.9785    0.9289     16205
           N     0.7690    0.5557    0.6452      1857
           P     0.9284    0.5769    0.7116      3212

   micro avg     0.8809    0.8809    0.8809     21274
   macro avg     0.8605    0.7037    0.7619     21274
weighted avg     0.8807    0.8809    0.8713     21274

F1-macro tok:  0.7618843461544359
F1-micro tok:  0.8809344740058287
**************************************************
Best epoch: 2
**************************************************

EPOCH: 8
Learning rate: 0.810000
train_cost_sum: 339079.25817871094
train_cost_avg: 39.686242764362234
train_count_sent: 8544.0
train_total_correct_sent: 5417.0
train_accuracy_sent: 0.6340121722846442
train_count_tok: 163566.0
train_total_correct_tok: 142486.0
train_accuracy_tok: 0.8711223603927467
train_label=O_precision_sent: 0.39090909090909093
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.04959630911188004
train_label=N_precision_sent: 0.6010650613567956
train_label=N_recall_sent: 0.7842900302114804
train_label=N_f-score_sent: 0.68056101717132
train_label=P_precision_sent: 0.6750911300121507
train_label=P_recall_sent: 0.7695290858725762
train_label=P_f-score_sent: 0.7192233009708738
train_precision_macro_sent: 0.5556884274260124
train_recall_macro_sent: 0.5267656495321239
train_f-score_macro_sent: 0.483126875751358
train_precision_micro_sent: 0.6340121722846442
train_recall_micro_sent: 0.6340121722846442
train_f-score_micro_sent: 0.6340121722846442
train_label=O_precision_tok: 0.882008815475406
train_label=O_recall_tok: 0.968764827458644
train_label=O_f-score_tok: 0.9233534540576794
train_label=N_precision_tok: 0.7550695825049701
train_label=N_recall_tok: 0.5348542458808618
train_label=N_f-score_tok: 0.6261643722693925
train_label=P_precision_tok: 0.8522566162570888
train_label=P_recall_tok: 0.5766878522604629
train_label=P_f-score_tok: 0.6879008225056621
train_precision_macro_tok: 0.829778338079155
train_recall_macro_tok: 0.6934356418666563
train_f-score_macro_tok: 0.745806216277578
train_precision_micro_tok: 0.8711223603927467
train_recall_micro_tok: 0.8711223603927467
train_f-score_micro_tok: 0.8711223603927467
train_time: 143.7708969116211
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3909    0.0265    0.0496      1624
           N     0.6011    0.7843    0.6806      3310
           P     0.6751    0.7695    0.7192      3610

   micro avg     0.6340    0.6340    0.6340      8544
   macro avg     0.5557    0.5268    0.4831      8544
weighted avg     0.5924    0.6340    0.5770      8544

F1-macro sent:  0.483126875751358
F1-micro sent:  0.6340121722846442
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8820    0.9688    0.9234    124347
           N     0.7551    0.5349    0.6262     14202
           P     0.8523    0.5767    0.6879     25017

   micro avg     0.8711    0.8711    0.8711    163566
   macro avg     0.8298    0.6934    0.7458    163566
weighted avg     0.8664    0.8711    0.8615    163566

F1-macro tok:  0.745806216277578
F1-micro tok:  0.8711223603927467
**************************************************
dev_cost_sum: 45135.32354736328
dev_cost_avg: 40.99484427553431
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18796.0
dev_accuracy_tok: 0.8835197894143085
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6071428571428571
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.702755905511811
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.7147335423197492
dev_precision_macro_sent: 0.4246031746031746
dev_recall_macro_sent: 0.5347941399343269
dev_f-score_macro_sent: 0.47249648261052
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8882092148829901
dev_label=O_recall_tok: 0.9766738660907127
dev_label=O_f-score_tok: 0.9303432870914649
dev_label=N_precision_tok: 0.7563559322033898
dev_label=N_recall_tok: 0.5767366720516963
dev_label=N_f-score_tok: 0.6544454628780936
dev_label=P_precision_tok: 0.9308484551250613
dev_label=P_recall_tok: 0.5909090909090909
dev_label=P_f-score_tok: 0.7229099219196344
dev_precision_macro_tok: 0.8584712007371471
dev_recall_macro_tok: 0.7147732096838334
dev_f-score_macro_tok: 0.769232890629731
dev_precision_micro_tok: 0.8835197894143085
dev_recall_micro_tok: 0.8835197894143085
dev_f-score_micro_tok: 0.8835197894143085
dev_time: 8.277064561843872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6071    0.8341    0.7028       428
           P     0.6667    0.7703    0.7147       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.4246    0.5348    0.4725      1101
weighted avg     0.5049    0.6349    0.5614      1101

F1-macro sent:  0.47249648261052
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8882    0.9767    0.9303     16205
           N     0.7564    0.5767    0.6544      1857
           P     0.9308    0.5909    0.7229      3212

   micro avg     0.8835    0.8835    0.8835     21274
   macro avg     0.8585    0.7148    0.7692     21274
weighted avg     0.8831    0.8835    0.8749     21274

F1-macro tok:  0.769232890629731
F1-micro tok:  0.8835197894143085
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 0.810000
train_cost_sum: 336538.8950805664
train_cost_avg: 39.38891562272547
train_count_sent: 8544.0
train_total_correct_sent: 5462.0
train_accuracy_sent: 0.6392790262172284
train_count_tok: 163566.0
train_total_correct_tok: 142803.0
train_accuracy_tok: 0.873060415978871
train_label=O_precision_sent: 0.5277777777777778
train_label=O_recall_sent: 0.011699507389162561
train_label=O_f-score_sent: 0.02289156626506024
train_label=N_precision_sent: 0.5988213961922031
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.6842786842786843
train_label=P_precision_sent: 0.683837890625
train_label=P_recall_sent: 0.7759002770083102
train_label=P_f-score_sent: 0.7269660005190761
train_precision_macro_sent: 0.6034790215316602
train_recall_macro_sent: 0.5285956985252401
train_f-score_macro_sent: 0.4780454170209403
train_precision_micro_sent: 0.6392790262172284
train_recall_micro_sent: 0.6392790262172284
train_f-score_micro_sent: 0.6392790262172284
train_label=O_precision_tok: 0.8841548908056525
train_label=O_recall_tok: 0.9686120292407537
train_label=O_f-score_tok: 0.9244584989945199
train_label=N_precision_tok: 0.7571931884908985
train_label=N_recall_tok: 0.5447824250105618
train_label=N_f-score_tok: 0.6336609336609336
train_label=P_precision_tok: 0.8539391461776558
train_label=P_recall_tok: 0.584482551864732
train_label=P_f-score_tok: 0.6939724727100142
train_precision_macro_tok: 0.8317624084914023
train_recall_macro_tok: 0.6992923353720158
train_f-score_macro_tok: 0.7506973017884891
train_precision_micro_tok: 0.873060415978871
train_recall_micro_tok: 0.873060415978871
train_f-score_micro_tok: 0.873060415978871
train_time: 143.59300589561462
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5278    0.0117    0.0229      1624
           N     0.5988    0.7982    0.6843      3310
           P     0.6838    0.7759    0.7270      3610

   micro avg     0.6393    0.6393    0.6393      8544
   macro avg     0.6035    0.5286    0.4780      8544
weighted avg     0.6212    0.6393    0.5766      8544

F1-macro sent:  0.4780454170209403
F1-micro sent:  0.6392790262172284
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8842    0.9686    0.9245    124347
           N     0.7572    0.5448    0.6337     14202
           P     0.8539    0.5845    0.6940     25017

   micro avg     0.8731    0.8731    0.8731    163566
   macro avg     0.8318    0.6993    0.7507    163566
weighted avg     0.8685    0.8731    0.8640    163566

F1-macro tok:  0.7506973017884891
F1-micro tok:  0.873060415978871
**************************************************
dev_cost_sum: 44867.99334716797
dev_cost_avg: 40.75203755419434
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18838.0
dev_accuracy_tok: 0.8854940302716932
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6301115241635687
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7018633540372671
dev_label=P_precision_sent: 0.6481149012567325
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7212787212787212
dev_precision_macro_sent: 0.6482976973623226
dev_recall_macro_sent: 0.5408621289125718
dev_f-score_macro_sent: 0.48572820950249246
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8848633029562125
dev_label=O_recall_tok: 0.9826596729404504
dev_label=O_f-score_tok: 0.9312008420806409
dev_label=N_precision_tok: 0.8202247191011236
dev_label=N_recall_tok: 0.5110393107162089
dev_label=N_f-score_tok: 0.6297279362972793
dev_label=P_precision_tok: 0.9264497878359265
dev_label=P_recall_tok: 0.6117683686176837
dev_label=P_f-score_tok: 0.7369210575660979
dev_precision_macro_tok: 0.8771792699644209
dev_recall_macro_tok: 0.7018224507581143
dev_f-score_macro_tok: 0.7659499453146728
dev_precision_micro_tok: 0.8854940302716932
dev_recall_micro_tok: 0.8854940302716932
dev_f-score_micro_tok: 0.8854940302716932
dev_time: 8.083709239959717
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6301    0.7921    0.7019       428
           P     0.6481    0.8131    0.7213       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6483    0.5409    0.4857      1101
weighted avg     0.6450    0.6394    0.5708      1101

F1-macro sent:  0.48572820950249246
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8849    0.9827    0.9312     16205
           N     0.8202    0.5110    0.6297      1857
           P     0.9264    0.6118    0.7369      3212

   micro avg     0.8855    0.8855    0.8855     21274
   macro avg     0.8772    0.7018    0.7659     21274
weighted avg     0.8855    0.8855    0.8756     21274

F1-macro tok:  0.7659499453146728
F1-micro tok:  0.8854940302716932
**************************************************
Best epoch: 9
**************************************************

EPOCH: 10
Learning rate: 0.810000
train_cost_sum: 334205.20037841797
train_cost_avg: 39.115777197848544
train_count_sent: 8544.0
train_total_correct_sent: 5498.0
train_accuracy_sent: 0.6434925093632958
train_count_tok: 163566.0
train_total_correct_tok: 143170.0
train_accuracy_tok: 0.8753041585659611
train_label=O_precision_sent: 0.4574468085106383
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.05005820721769499
train_label=N_precision_sent: 0.6054775916704391
train_label=N_recall_sent: 0.8081570996978852
train_label=N_f-score_sent: 0.692287784679089
train_label=P_precision_sent: 0.689484126984127
train_label=P_recall_sent: 0.7700831024930748
train_label=P_f-score_sent: 0.7275582308296258
train_precision_macro_sent: 0.5841361757217348
train_recall_macro_sent: 0.5349060115677584
train_f-score_macro_sent: 0.4899680742421366
train_precision_micro_sent: 0.6434925093632958
train_recall_micro_sent: 0.6434925093632958
train_f-score_micro_sent: 0.6434925093632958
train_label=O_precision_tok: 0.8860397604086282
train_label=O_recall_tok: 0.9695368605595631
train_label=O_f-score_tok: 0.9259097123020444
train_label=N_precision_tok: 0.7558444077990105
train_label=N_recall_tok: 0.5486551189973243
train_label=N_f-score_tok: 0.6357961731467504
train_label=P_precision_tok: 0.8619706840390879
train_label=P_recall_tok: 0.5923571971059679
train_label=P_f-score_tok: 0.7021725224478191
train_precision_macro_tok: 0.8346182840822421
train_recall_macro_tok: 0.7035163922209517
train_f-score_macro_tok: 0.754626135965538
train_precision_micro_tok: 0.8753041585659611
train_recall_micro_tok: 0.8753041585659611
train_f-score_micro_tok: 0.8753041585659611
train_time: 143.68587589263916
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4574    0.0265    0.0501      1624
           N     0.6055    0.8082    0.6923      3310
           P     0.6895    0.7701    0.7276      3610

   micro avg     0.6435    0.6435    0.6435      8544
   macro avg     0.5841    0.5349    0.4900      8544
weighted avg     0.6128    0.6435    0.5851      8544

F1-macro sent:  0.4899680742421366
F1-micro sent:  0.6434925093632958
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8860    0.9695    0.9259    124347
           N     0.7558    0.5487    0.6358     14202
           P     0.8620    0.5924    0.7022     25017

   micro avg     0.8753    0.8753    0.8753    163566
   macro avg     0.8346    0.7035    0.7546    163566
weighted avg     0.8711    0.8753    0.8665    163566

F1-macro tok:  0.754626135965538
F1-micro tok:  0.8753041585659611
**************************************************
dev_cost_sum: 44502.792541503906
dev_cost_avg: 40.420338366488565
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18908.0
dev_accuracy_tok: 0.8887844317006675
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6123499142367067
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7062314540059347
dev_label=P_precision_sent: 0.6627906976744186
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.7124999999999999
dev_precision_macro_sent: 0.7583802039703751
dev_recall_macro_sent: 0.5377053480857097
dev_f-score_macro_sent: 0.47868249044065064
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8947874808987493
dev_label=O_recall_tok: 0.9756248071582845
dev_label=O_f-score_tok: 0.9334592903111532
dev_label=N_precision_tok: 0.7746580273578114
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.662969808995687
dev_label=P_precision_tok: 0.9124548736462094
dev_label=P_recall_tok: 0.6295143212951432
dev_label=P_f-score_tok: 0.7450257921886514
dev_precision_macro_tok: 0.8606334606342566
dev_recall_macro_tok: 0.7281894384379851
dev_f-score_macro_tok: 0.7804849638318304
dev_precision_micro_tok: 0.8887844317006675
dev_recall_micro_tok: 0.8887844317006675
dev_f-score_micro_tok: 0.8887844317006675
dev_time: 8.40197229385376
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6123    0.8341    0.7062       428
           P     0.6628    0.7703    0.7125       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.7584    0.5377    0.4787      1101
weighted avg     0.7133    0.6367    0.5655      1101

F1-macro sent:  0.47868249044065064
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9756    0.9335     16205
           N     0.7747    0.5794    0.6630      1857
           P     0.9125    0.6295    0.7450      3212

   micro avg     0.8888    0.8888    0.8888     21274
   macro avg     0.8606    0.7282    0.7805     21274
weighted avg     0.8870    0.8888    0.8814     21274

F1-macro tok:  0.7804849638318304
F1-micro tok:  0.8887844317006675
**************************************************
Best epoch: 9
**************************************************

EPOCH: 11
Learning rate: 0.810000
train_cost_sum: 331885.31842041016
train_cost_avg: 38.84425543310044
train_count_sent: 8544.0
train_total_correct_sent: 5528.0
train_accuracy_sent: 0.647003745318352
train_count_tok: 163566.0
train_total_correct_tok: 143629.0
train_accuracy_tok: 0.8781103652348288
train_label=O_precision_sent: 0.37349397590361444
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03632103104862332
train_label=N_precision_sent: 0.6152041295166588
train_label=N_recall_sent: 0.7921450151057402
train_label=N_f-score_sent: 0.6925515055467513
train_label=P_precision_sent: 0.6846868301976661
train_label=P_recall_sent: 0.796398891966759
train_label=P_f-score_sent: 0.7363298757843514
train_precision_macro_sent: 0.5577949785393131
train_recall_macro_sent: 0.5358775256744127
train_f-score_macro_sent: 0.4884008041265753
train_precision_micro_sent: 0.647003745318352
train_recall_micro_sent: 0.647003745318352
train_f-score_micro_sent: 0.647003745318352
train_label=O_precision_tok: 0.8886187307972856
train_label=O_recall_tok: 0.9699148350985548
train_label=O_f-score_tok: 0.9274887530280309
train_label=N_precision_tok: 0.7654191330914646
train_label=N_recall_tok: 0.5644979580340798
train_label=N_f-score_tok: 0.6497811638839358
train_label=P_precision_tok: 0.8639530197478266
train_label=P_recall_tok: 0.5998321141623696
train_label=P_f-score_tok: 0.7080639833907422
train_precision_macro_tok: 0.8393302945455255
train_recall_macro_tok: 0.7114149690983348
train_f-score_macro_tok: 0.7617779667675696
train_precision_micro_tok: 0.8781103652348288
train_recall_micro_tok: 0.8781103652348288
train_f-score_micro_tok: 0.8781103652348289
train_time: 145.13001084327698
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3735    0.0191    0.0363      1624
           N     0.6152    0.7921    0.6926      3310
           P     0.6847    0.7964    0.7363      3610

   micro avg     0.6470    0.6470    0.6470      8544
   macro avg     0.5578    0.5359    0.4884      8544
weighted avg     0.5986    0.6470    0.5863      8544

F1-macro sent:  0.4884008041265753
F1-micro sent:  0.647003745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8886    0.9699    0.9275    124347
           N     0.7654    0.5645    0.6498     14202
           P     0.8640    0.5998    0.7081     25017

   micro avg     0.8781    0.8781    0.8781    163566
   macro avg     0.8393    0.7114    0.7618    163566
weighted avg     0.8741    0.8781    0.8698    163566

F1-macro tok:  0.7617779667675696
F1-micro tok:  0.8781103652348289
**************************************************
dev_cost_sum: 44305.46502685547
dev_cost_avg: 40.24111264927836
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18926.0
dev_accuracy_tok: 0.8896305349252609
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5895865237366003
dev_label=N_recall_sent: 0.8995327102803738
dev_label=N_f-score_sent: 0.7123034227567068
dev_label=P_precision_sent: 0.7165178571428571
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.7197309417040358
dev_precision_macro_sent: 0.4353681269598191
dev_recall_macro_sent: 0.5408352277511156
dev_f-score_macro_sent: 0.4773447881535809
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8929536244934714
dev_label=O_recall_tok: 0.9790805307004011
dev_label=O_f-score_tok: 0.9340358520001177
dev_label=N_precision_tok: 0.7998442367601246
dev_label=N_recall_tok: 0.5530425417339795
dev_label=N_f-score_tok: 0.6539318688315823
dev_label=P_precision_tok: 0.914941494149415
dev_label=P_recall_tok: 0.6329389788293898
dev_label=P_f-score_tok: 0.7482517482517481
dev_precision_macro_tok: 0.8692464518010037
dev_recall_macro_tok: 0.7216873504212568
dev_f-score_macro_tok: 0.7787398230278161
dev_precision_micro_tok: 0.8896305349252609
dev_recall_micro_tok: 0.8896305349252609
dev_f-score_micro_tok: 0.8896305349252609
dev_time: 8.385091543197632
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5896    0.8995    0.7123       428
           P     0.7165    0.7230    0.7197       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.4354    0.5408    0.4773      1101
weighted avg     0.5181    0.6412    0.5671      1101

F1-macro sent:  0.4773447881535809
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8930    0.9791    0.9340     16205
           N     0.7998    0.5530    0.6539      1857
           P     0.9149    0.6329    0.7483      3212

   micro avg     0.8896    0.8896    0.8896     21274
   macro avg     0.8692    0.7217    0.7787     21274
weighted avg     0.8881    0.8896    0.8815     21274

F1-macro tok:  0.7787398230278161
F1-micro tok:  0.8896305349252609
**************************************************
Best epoch: 9
**************************************************

EPOCH: 12
Learning rate: 0.810000
train_cost_sum: 329887.68267822266
train_cost_avg: 38.61044975166464
train_count_sent: 8544.0
train_total_correct_sent: 5549.0
train_accuracy_sent: 0.6494616104868914
train_count_tok: 163566.0
train_total_correct_tok: 143854.0
train_accuracy_tok: 0.8794859567391756
train_label=O_precision_sent: 0.5882352941176471
train_label=O_recall_sent: 0.012315270935960592
train_label=O_f-score_sent: 0.024125452352231604
train_label=N_precision_sent: 0.6150617859640942
train_label=N_recall_sent: 0.7969788519637462
train_label=N_f-score_sent: 0.694301881826556
train_label=P_precision_sent: 0.6849087893864013
train_label=P_recall_sent: 0.8008310249307479
train_label=P_f-score_sent: 0.7383475929000127
train_precision_macro_sent: 0.6294019564893808
train_recall_macro_sent: 0.5367083826101515
train_f-score_macro_sent: 0.4855916423596001
train_precision_micro_sent: 0.6494616104868914
train_recall_micro_sent: 0.6494616104868914
train_f-score_micro_sent: 0.6494616104868914
train_label=O_precision_tok: 0.8898941857464144
train_label=O_recall_tok: 0.9705340699815838
train_label=O_f-score_tok: 0.928466468176118
train_label=N_precision_tok: 0.7693110647181628
train_label=N_recall_tok: 0.5708350936487818
train_label=N_f-score_tok: 0.6553759094583669
train_label=P_precision_tok: 0.8651007867685063
train_label=P_recall_tok: 0.6021505376344086
train_label=P_f-score_tok: 0.7100636342210701
train_precision_macro_tok: 0.8414353457443612
train_recall_macro_tok: 0.7145065670882581
train_f-score_macro_tok: 0.764635337285185
train_precision_micro_tok: 0.8794859567391756
train_recall_micro_tok: 0.8794859567391756
train_f-score_micro_tok: 0.8794859567391756
train_time: 144.9799485206604
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5882    0.0123    0.0241      1624
           N     0.6151    0.7970    0.6943      3310
           P     0.6849    0.8008    0.7383      3610

   micro avg     0.6495    0.6495    0.6495      8544
   macro avg     0.6294    0.5367    0.4856      8544
weighted avg     0.6395    0.6495    0.5855      8544

F1-macro sent:  0.4855916423596001
F1-micro sent:  0.6494616104868914
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8899    0.9705    0.9285    124347
           N     0.7693    0.5708    0.6554     14202
           P     0.8651    0.6022    0.7101     25017

   micro avg     0.8795    0.8795    0.8795    163566
   macro avg     0.8414    0.7145    0.7646    163566
weighted avg     0.8756    0.8795    0.8714    163566

F1-macro tok:  0.764635337285185
F1-micro tok:  0.8794859567391756
**************************************************
dev_cost_sum: 44027.343322753906
dev_cost_avg: 39.988504380339606
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 18964.0
dev_accuracy_tok: 0.8914167528438469
dev_label=O_precision_sent: 0.6875
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08979591836734695
dev_label=N_precision_sent: 0.6220338983050847
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7210216110019646
dev_label=P_precision_sent: 0.6868686868686869
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.7241746538871139
dev_precision_macro_sent: 0.6654675283912571
dev_recall_macro_sent: 0.5570924452592003
dev_f-score_macro_sent: 0.5116640610854751
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.8962979735084343
dev_label=O_recall_tok: 0.9771058315334773
dev_label=O_f-score_tok: 0.9349591095627529
dev_label=N_precision_tok: 0.8006042296072508
dev_label=N_recall_tok: 0.5708131394722671
dev_label=N_f-score_tok: 0.6664570889657341
dev_label=P_precision_tok: 0.9063047285464098
dev_label=P_recall_tok: 0.6444582814445828
dev_label=P_f-score_tok: 0.7532751091703057
dev_precision_macro_tok: 0.8677356438873649
dev_recall_macro_tok: 0.7307924174834425
dev_f-score_macro_tok: 0.7848971025662642
dev_precision_micro_tok: 0.8914167528438469
dev_recall_micro_tok: 0.8914167528438469
dev_f-score_micro_tok: 0.8914167528438469
dev_time: 8.29593825340271
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6875    0.0480    0.0898       229
           N     0.6220    0.8575    0.7210       428
           P     0.6869    0.7658    0.7242       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.6655    0.5571    0.5117      1101
weighted avg     0.6618    0.6521    0.5910      1101

F1-macro sent:  0.5116640610854751
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8963    0.9771    0.9350     16205
           N     0.8006    0.5708    0.6665      1857
           P     0.9063    0.6445    0.7533      3212

   micro avg     0.8914    0.8914    0.8914     21274
   macro avg     0.8677    0.7308    0.7849     21274
weighted avg     0.8895    0.8914    0.8841     21274

F1-macro tok:  0.7848971025662642
F1-micro tok:  0.8914167528438469
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 0.810000
train_cost_sum: 328083.8153076172
train_cost_avg: 38.39932295267055
train_count_sent: 8544.0
train_total_correct_sent: 5586.0
train_accuracy_sent: 0.6537921348314607
train_count_tok: 163566.0
train_total_correct_tok: 143991.0
train_accuracy_tok: 0.8803235391218224
train_label=O_precision_sent: 0.43478260869565216
train_label=O_recall_sent: 0.024630541871921183
train_label=O_f-score_sent: 0.046620046620046623
train_label=N_precision_sent: 0.6196955719557196
train_label=N_recall_sent: 0.8117824773413898
train_label=N_f-score_sent: 0.7028511640073241
train_label=P_precision_sent: 0.6946064139941691
train_label=P_recall_sent: 0.7919667590027701
train_label=P_f-score_sent: 0.740098369143153
train_precision_macro_sent: 0.5830281982151803
train_recall_macro_sent: 0.5427932594053604
train_f-score_macro_sent: 0.4965231932568412
train_precision_micro_sent: 0.6537921348314607
train_recall_micro_sent: 0.6537921348314607
train_f-score_micro_sent: 0.6537921348314607
train_label=O_precision_tok: 0.8910964215812992
train_label=O_recall_tok: 0.9702686836031428
train_label=O_f-score_tok: 0.9289987757082028
train_label=N_precision_tok: 0.7679197045734305
train_label=N_recall_tok: 0.5710463315026053
train_label=N_f-score_tok: 0.655009489964867
train_label=P_precision_tok: 0.8649063032367973
train_label=P_recall_tok: 0.6088259983211416
train_label=P_f-score_tok: 0.7146174959532691
train_precision_macro_tok: 0.8413074764638423
train_recall_macro_tok: 0.7167136711422967
train_f-score_macro_tok: 0.7662085872087796
train_precision_micro_tok: 0.8803235391218224
train_recall_micro_tok: 0.8803235391218224
train_f-score_micro_tok: 0.8803235391218224
train_time: 143.40556049346924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4348    0.0246    0.0466      1624
           N     0.6197    0.8118    0.7029      3310
           P     0.6946    0.7920    0.7401      3610

   micro avg     0.6538    0.6538    0.6538      8544
   macro avg     0.5830    0.5428    0.4965      8544
weighted avg     0.6162    0.6538    0.5939      8544

F1-macro sent:  0.4965231932568412
F1-micro sent:  0.6537921348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8911    0.9703    0.9290    124347
           N     0.7679    0.5710    0.6550     14202
           P     0.8649    0.6088    0.7146     25017

   micro avg     0.8803    0.8803    0.8803    163566
   macro avg     0.8413    0.7167    0.7662    163566
weighted avg     0.8764    0.8803    0.8724    163566

F1-macro tok:  0.7662085872087796
F1-micro tok:  0.8803235391218224
**************************************************
dev_cost_sum: 43939.52734375
dev_cost_avg: 39.90874418142597
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 18967.0
dev_accuracy_tok: 0.8915577700479459
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6723044397463002
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7058823529411765
dev_label=P_precision_sent: 0.6178343949044586
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7238805970149252
dev_precision_macro_sent: 0.4300462782169196
dev_recall_macro_sent: 0.5389548426931604
dev_f-score_macro_sent: 0.47658764998536723
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8953048194813267
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9347569608305804
dev_label=N_precision_tok: 0.8160377358490566
dev_label=N_recall_tok: 0.5589660743134087
dev_label=N_f-score_tok: 0.663470757430489
dev_label=P_precision_tok: 0.9044724272687799
dev_label=P_recall_tok: 0.6485056039850561
dev_label=P_f-score_tok: 0.7553943789664552
dev_precision_macro_tok: 0.8719383275330544
dev_recall_macro_tok: 0.7284393406731796
dev_f-score_macro_tok: 0.7845406990758415
dev_precision_micro_tok: 0.8915577700479459
dev_recall_micro_tok: 0.8915577700479459
dev_f-score_micro_tok: 0.8915577700479459
dev_time: 8.5354163646698
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6723    0.7430    0.7059       428
           P     0.6178    0.8739    0.7239       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.4300    0.5390    0.4766      1101
weighted avg     0.5105    0.6412    0.5663      1101

F1-macro sent:  0.47658764998536723
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8953    0.9778    0.9348     16205
           N     0.8160    0.5590    0.6635      1857
           P     0.9045    0.6485    0.7554      3212

   micro avg     0.8916    0.8916    0.8916     21274
   macro avg     0.8719    0.7284    0.7845     21274
weighted avg     0.8898    0.8916    0.8840     21274

F1-macro tok:  0.7845406990758415
F1-micro tok:  0.8915577700479459
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 0.810000
train_cost_sum: 326005.02044677734
train_cost_avg: 38.15601831071832
train_count_sent: 8544.0
train_total_correct_sent: 5577.0
train_accuracy_sent: 0.6527387640449438
train_count_tok: 163566.0
train_total_correct_tok: 144324.0
train_accuracy_tok: 0.8823594145482557
train_label=O_precision_sent: 0.5217391304347826
train_label=O_recall_sent: 0.022167487684729065
train_label=O_f-score_sent: 0.042528056704075605
train_label=N_precision_sent: 0.6141069397042094
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.700584036340039
train_label=P_precision_sent: 0.6965686274509804
train_label=P_recall_sent: 0.7872576177285319
train_label=P_f-score_sent: 0.7391417425227568
train_precision_macro_sent: 0.6108048991966574
train_recall_macro_sent: 0.5416109867993851
train_f-score_macro_sent: 0.49408461185562375
train_precision_micro_sent: 0.6527387640449438
train_recall_micro_sent: 0.6527387640449438
train_f-score_micro_sent: 0.6527387640449438
train_label=O_precision_tok: 0.8927343062346058
train_label=O_recall_tok: 0.9706305741191987
train_label=O_f-score_tok: 0.9300542489905373
train_label=N_precision_tok: 0.7728508484109872
train_label=N_recall_tok: 0.5804816223067174
train_label=N_f-score_tok: 0.6629940890264989
train_label=P_precision_tok: 0.8691108349339057
train_label=P_recall_tok: 0.6149818123675901
train_label=P_f-score_tok: 0.7202883962639575
train_precision_macro_tok: 0.8448986631931662
train_recall_macro_tok: 0.7220313362645022
train_f-score_macro_tok: 0.7711122447603312
train_precision_micro_tok: 0.8823594145482557
train_recall_micro_tok: 0.8823594145482557
train_f-score_micro_tok: 0.8823594145482557
train_time: 145.07189774513245
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5217    0.0222    0.0425      1624
           N     0.6141    0.8154    0.7006      3310
           P     0.6966    0.7873    0.7391      3610

   micro avg     0.6527    0.6527    0.6527      8544
   macro avg     0.6108    0.5416    0.4941      8544
weighted avg     0.6314    0.6527    0.5918      8544

F1-macro sent:  0.49408461185562375
F1-micro sent:  0.6527387640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8927    0.9706    0.9301    124347
           N     0.7729    0.5805    0.6630     14202
           P     0.8691    0.6150    0.7203     25017

   micro avg     0.8824    0.8824    0.8824    163566
   macro avg     0.8449    0.7220    0.7711    163566
weighted avg     0.8787    0.8824    0.8748    163566

F1-macro tok:  0.7711122447603312
F1-micro tok:  0.8823594145482557
**************************************************
dev_cost_sum: 43662.239807128906
dev_cost_avg: 39.656893557791925
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 18991.0
dev_accuracy_tok: 0.8926859076807371
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6072013093289689
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7141482194417709
dev_label=P_precision_sent: 0.6958333333333333
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7229437229437228
dev_precision_macro_sent: 0.6676782142207673
dev_recall_macro_sent: 0.549880789249438
dev_f-score_macro_sent: 0.4985564494144114
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.8988636363636363
dev_label=O_recall_tok: 0.9762419006479481
dev_label=O_f-score_tok: 0.9359562194941575
dev_label=N_precision_tok: 0.7702888583218707
dev_label=N_recall_tok: 0.6031233171782445
dev_label=N_f-score_tok: 0.6765327695560254
dev_label=P_precision_tok: 0.9238738738738739
dev_label=P_recall_tok: 0.6385429638854296
dev_label=P_f-score_tok: 0.7551546391752577
dev_precision_macro_tok: 0.864342122853127
dev_recall_macro_tok: 0.7393027272372074
dev_f-score_macro_tok: 0.7892145427418136
dev_precision_micro_tok: 0.8926859076807371
dev_recall_micro_tok: 0.8926859076807371
dev_f-score_micro_tok: 0.8926859076807371
dev_time: 8.354444742202759
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6072    0.8668    0.7141       428
           P     0.6958    0.7523    0.7229       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.6677    0.5499    0.4986      1101
weighted avg     0.6622    0.6467    0.5813      1101

F1-macro sent:  0.4985564494144114
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9762    0.9360     16205
           N     0.7703    0.6031    0.6765      1857
           P     0.9239    0.6385    0.7552      3212

   micro avg     0.8927    0.8927    0.8927     21274
   macro avg     0.8643    0.7393    0.7892     21274
weighted avg     0.8914    0.8927    0.8860     21274

F1-macro tok:  0.7892145427418136
F1-micro tok:  0.8926859076807371
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 0.810000
train_cost_sum: 324231.4012451172
train_cost_avg: 37.94843179367008
train_count_sent: 8544.0
train_total_correct_sent: 5627.0
train_accuracy_sent: 0.6585908239700374
train_count_tok: 163566.0
train_total_correct_tok: 144620.0
train_accuracy_tok: 0.8841690815939743
train_label=O_precision_sent: 0.38571428571428573
train_label=O_recall_sent: 0.0332512315270936
train_label=O_f-score_sent: 0.06122448979591837
train_label=N_precision_sent: 0.6239612188365651
train_label=N_recall_sent: 0.8166163141993957
train_label=N_f-score_sent: 0.707406438105208
train_label=P_precision_sent: 0.7048133595284872
train_label=P_recall_sent: 0.7950138504155124
train_label=P_f-score_sent: 0.7472012496745639
train_precision_macro_sent: 0.571496288026446
train_recall_macro_sent: 0.5482937987140005
train_f-score_macro_sent: 0.5052773925252301
train_precision_micro_sent: 0.6585908239700374
train_recall_micro_sent: 0.6585908239700374
train_f-score_micro_sent: 0.6585908239700374
train_label=O_precision_tok: 0.8945672464369314
train_label=O_recall_tok: 0.9711774308990164
train_label=O_f-score_tok: 0.931299475983543
train_label=N_precision_tok: 0.777954078775434
train_label=N_recall_tok: 0.5868891705393606
train_label=N_f-score_tok: 0.6690480012843153
train_label=P_precision_tok: 0.8692876344086021
train_label=P_recall_tok: 0.6204580884998201
train_label=P_f-score_tok: 0.7240920859282066
train_precision_macro_tok: 0.8472696532069892
train_recall_macro_tok: 0.7261748966460657
train_f-score_macro_tok: 0.7748131877320216
train_precision_micro_tok: 0.8841690815939743
train_recall_micro_tok: 0.8841690815939743
train_f-score_micro_tok: 0.8841690815939743
train_time: 145.2578146457672
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3857    0.0333    0.0612      1624
           N     0.6240    0.8166    0.7074      3310
           P     0.7048    0.7950    0.7472      3610

   micro avg     0.6586    0.6586    0.6586      8544
   macro avg     0.5715    0.5483    0.5053      8544
weighted avg     0.6128    0.6586    0.6014      8544

F1-macro sent:  0.5052773925252301
F1-micro sent:  0.6585908239700374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8946    0.9712    0.9313    124347
           N     0.7780    0.5869    0.6690     14202
           P     0.8693    0.6205    0.7241     25017

   micro avg     0.8842    0.8842    0.8842    163566
   macro avg     0.8473    0.7262    0.7748    163566
weighted avg     0.8806    0.8842    0.8768    163566

F1-macro tok:  0.7748131877320216
F1-micro tok:  0.8841690815939743
**************************************************
dev_cost_sum: 43611.888732910156
dev_cost_avg: 39.61116142861958
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 18989.0
dev_accuracy_tok: 0.8925918962113378
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6387900355871886
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7252525252525254
dev_label=P_precision_sent: 0.6766917293233082
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.7377049180327868
dev_precision_macro_sent: 0.6765891597320705
dev_recall_macro_sent: 0.5571433062250514
dev_f-score_macro_sent: 0.5017767748804148
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8950008454038212
dev_label=O_recall_tok: 0.9799444615859303
dev_label=O_f-score_tok: 0.9355484859196418
dev_label=N_precision_tok: 0.8183229813664596
dev_label=N_recall_tok: 0.5675821217016693
dev_label=N_f-score_tok: 0.6702702702702703
dev_label=P_precision_tok: 0.9161836825679893
dev_label=P_recall_tok: 0.6397882938978829
dev_label=P_f-score_tok: 0.7534372135655363
dev_precision_macro_tok: 0.8765025031127567
dev_recall_macro_tok: 0.7291049590618274
dev_f-score_macro_tok: 0.7864186565851495
dev_precision_micro_tok: 0.8925918962113378
dev_recall_micro_tok: 0.8925918962113378
dev_f-score_micro_tok: 0.8925918962113378
dev_time: 8.447749614715576
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6388    0.8388    0.7253       428
           P     0.6767    0.8108    0.7377       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6766    0.5571    0.5018      1101
weighted avg     0.6698    0.6576    0.5882      1101

F1-macro sent:  0.5017767748804148
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9799    0.9355     16205
           N     0.8183    0.5676    0.6703      1857
           P     0.9162    0.6398    0.7534      3212

   micro avg     0.8926    0.8926    0.8926     21274
   macro avg     0.8765    0.7291    0.7864     21274
weighted avg     0.8915    0.8926    0.8849     21274

F1-macro tok:  0.7864186565851495
F1-micro tok:  0.8925918962113378
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 0.810000
train_cost_sum: 322540.00048828125
train_cost_avg: 37.75046822194303
train_count_sent: 8544.0
train_total_correct_sent: 5598.0
train_accuracy_sent: 0.6551966292134831
train_count_tok: 163566.0
train_total_correct_tok: 144947.0
train_accuracy_tok: 0.8861682745802918
train_label=O_precision_sent: 0.391812865497076
train_label=O_recall_sent: 0.04125615763546798
train_label=O_f-score_sent: 0.0746518105849582
train_label=N_precision_sent: 0.6234911792014856
train_label=N_recall_sent: 0.8114803625377643
train_label=N_f-score_sent: 0.7051719611446573
train_label=P_precision_sent: 0.6998769987699877
train_label=P_recall_sent: 0.7880886426592798
train_label=P_f-score_sent: 0.7413680781758958
train_precision_macro_sent: 0.5717270144895163
train_recall_macro_sent: 0.5469417209441707
train_f-score_macro_sent: 0.5070639499685038
train_precision_micro_sent: 0.6551966292134831
train_recall_micro_sent: 0.6551966292134831
train_f-score_micro_sent: 0.6551966292134831
train_label=O_precision_tok: 0.8960409991693367
train_label=O_recall_tok: 0.9715956154953477
train_label=O_f-score_tok: 0.9322900389306232
train_label=N_precision_tok: 0.7850848715332529
train_label=N_recall_tok: 0.595972398253767
train_label=N_f-score_tok: 0.6775807549133409
train_label=P_precision_tok: 0.8727232217456693
train_label=P_recall_tok: 0.6262941199984011
train_label=P_f-score_tok: 0.7292529671864091
train_precision_macro_tok: 0.8512830308160863
train_recall_macro_tok: 0.7312873779158386
train_f-score_macro_tok: 0.7797079203434577
train_precision_micro_tok: 0.8861682745802918
train_recall_micro_tok: 0.8861682745802918
train_f-score_micro_tok: 0.8861682745802918
train_time: 144.77741408348083
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3918    0.0413    0.0747      1624
           N     0.6235    0.8115    0.7052      3310
           P     0.6999    0.7881    0.7414      3610

   micro avg     0.6552    0.6552    0.6552      8544
   macro avg     0.5717    0.5469    0.5071      8544
weighted avg     0.6117    0.6552    0.6006      8544

F1-macro sent:  0.5070639499685038
F1-micro sent:  0.6551966292134831
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8960    0.9716    0.9323    124347
           N     0.7851    0.5960    0.6776     14202
           P     0.8727    0.6263    0.7293     25017

   micro avg     0.8862    0.8862    0.8862    163566
   macro avg     0.8513    0.7313    0.7797    163566
weighted avg     0.8828    0.8862    0.8791    163566

F1-macro tok:  0.7797079203434577
F1-micro tok:  0.8861682745802918
**************************************************
dev_cost_sum: 43440.523864746094
dev_cost_avg: 39.45551668006003
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 19004.0
dev_accuracy_tok: 0.8932969822318323
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.5874233128834356
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7092592592592594
dev_label=P_precision_sent: 0.7191780821917808
dev_label=P_recall_sent: 0.7094594594594594
dev_label=P_f-score_sent: 0.7142857142857142
dev_precision_macro_sent: 0.6476550104796176
dev_recall_macro_sent: 0.544962319377697
dev_f-score_macro_sent: 0.4939594356261023
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.8959390862944162
dev_label=O_recall_tok: 0.9802530083307621
dev_label=O_f-score_tok: 0.9362015618093413
dev_label=N_precision_tok: 0.7958579881656804
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6706138984107198
dev_label=P_precision_tok: 0.9320255474452555
dev_label=P_recall_tok: 0.636052303860523
dev_label=P_f-score_tok: 0.7561065877128053
dev_precision_macro_tok: 0.8746075406351173
dev_recall_macro_tok: 0.7319114996839376
dev_f-score_macro_tok: 0.7876406826442889
dev_precision_micro_tok: 0.8932969822318323
dev_recall_micro_tok: 0.8932969822318323
dev_f-score_micro_tok: 0.8932969822318322
dev_time: 8.332209825515747
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.5874    0.8949    0.7093       428
           P     0.7192    0.7095    0.7143       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.6477    0.5450    0.4940      1101
weighted avg     0.6507    0.6403    0.5759      1101

F1-macro sent:  0.4939594356261023
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9803    0.9362     16205
           N     0.7959    0.5794    0.6706      1857
           P     0.9320    0.6361    0.7561      3212

   micro avg     0.8933    0.8933    0.8933     21274
   macro avg     0.8746    0.7319    0.7876     21274
weighted avg     0.8927    0.8933    0.8858     21274

F1-macro tok:  0.7876406826442889
F1-micro tok:  0.8932969822318322
**************************************************
Best epoch: 12
**************************************************

EPOCH: 17
Learning rate: 0.729000
train_cost_sum: 320562.98809814453
train_cost_avg: 37.519076322348376
train_count_sent: 8544.0
train_total_correct_sent: 5631.0
train_accuracy_sent: 0.6590589887640449
train_count_tok: 163566.0
train_total_correct_tok: 145063.0
train_accuracy_tok: 0.8868774684225328
train_label=O_precision_sent: 0.40804597701149425
train_label=O_recall_sent: 0.0437192118226601
train_label=O_f-score_sent: 0.07897664071190212
train_label=N_precision_sent: 0.6338942307692308
train_label=N_recall_sent: 0.7966767371601209
train_label=N_f-score_sent: 0.7060240963855422
train_label=P_precision_sent: 0.6942992874109264
train_label=P_recall_sent: 0.8096952908587257
train_label=P_f-score_sent: 0.7475703324808183
train_precision_macro_sent: 0.5787464983972171
train_recall_macro_sent: 0.5500304132805023
train_f-score_macro_sent: 0.5108570231927542
train_precision_micro_sent: 0.6590589887640449
train_recall_micro_sent: 0.6590589887640449
train_f-score_micro_sent: 0.6590589887640449
train_label=O_precision_tok: 0.8976158960096375
train_label=O_recall_tok: 0.9707190362453457
train_label=O_f-score_tok: 0.9327372972054045
train_label=N_precision_tok: 0.7792952745151598
train_label=N_recall_tok: 0.6026615969581749
train_label=N_f-score_tok: 0.6796902918403812
train_label=P_precision_tok: 0.8723838975095256
train_label=P_recall_tok: 0.6314905864012471
train_label=P_f-score_tok: 0.7326438807216065
train_precision_macro_tok: 0.8497650226781076
train_recall_macro_tok: 0.7349570732015892
train_f-score_macro_tok: 0.781690489922464
train_precision_micro_tok: 0.8868774684225328
train_recall_micro_tok: 0.8868774684225328
train_f-score_micro_tok: 0.8868774684225328
train_time: 145.19763779640198
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4080    0.0437    0.0790      1624
           N     0.6339    0.7967    0.7060      3310
           P     0.6943    0.8097    0.7476      3610

   micro avg     0.6591    0.6591    0.6591      8544
   macro avg     0.5787    0.5500    0.5109      8544
weighted avg     0.6165    0.6591    0.6044      8544

F1-macro sent:  0.5108570231927542
F1-micro sent:  0.6590589887640449
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8976    0.9707    0.9327    124347
           N     0.7793    0.6027    0.6797     14202
           P     0.8724    0.6315    0.7326     25017

   micro avg     0.8869    0.8869    0.8869    163566
   macro avg     0.8498    0.7350    0.7817    163566
weighted avg     0.8835    0.8869    0.8802    163566

F1-macro tok:  0.781690489922464
F1-micro tok:  0.8868774684225328
**************************************************
dev_cost_sum: 43358.198974609375
dev_cost_avg: 39.38074384614839
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 19016.0
dev_accuracy_tok: 0.8938610510482279
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05042016806722689
dev_label=N_precision_sent: 0.595879556259905
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7101038715769594
dev_label=P_precision_sent: 0.7071583514099783
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7204419889502762
dev_precision_macro_sent: 0.6565681914455167
dev_recall_macro_sent: 0.5463132601646253
dev_f-score_macro_sent: 0.4936553428648209
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.8922999496728736
dev_label=O_recall_tok: 0.9846960814563407
dev_label=O_f-score_tok: 0.9362238911053743
dev_label=N_precision_tok: 0.8352272727272727
dev_label=N_recall_tok: 0.5541195476575121
dev_label=N_f-score_tok: 0.6662350275169959
dev_label=P_precision_tok: 0.9402501157943493
dev_label=P_recall_tok: 0.6320049813200498
dev_label=P_f-score_tok: 0.7559113759076522
dev_precision_macro_tok: 0.8892591127314985
dev_recall_macro_tok: 0.7236068701446342
dev_f-score_macro_tok: 0.7861234315100075
dev_precision_micro_tok: 0.8938610510482279
dev_recall_micro_tok: 0.8938610510482279
dev_f-score_micro_tok: 0.8938610510482279
dev_time: 8.397042512893677
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0262    0.0504       229
           N     0.5959    0.8785    0.7101       428
           P     0.7072    0.7342    0.7204       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6566    0.5463    0.4937      1101
weighted avg     0.6555    0.6431    0.5771      1101

F1-macro sent:  0.4936553428648209
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8923    0.9847    0.9362     16205
           N     0.8352    0.5541    0.6662      1857
           P     0.9403    0.6320    0.7559      3212

   micro avg     0.8939    0.8939    0.8939     21274
   macro avg     0.8893    0.7236    0.7861     21274
weighted avg     0.8946    0.8939    0.8854     21274

F1-macro tok:  0.7861234315100075
F1-micro tok:  0.8938610510482279
**************************************************
Best epoch: 12
**************************************************

EPOCH: 18
Learning rate: 0.656100
train_cost_sum: 319097.37927246094
train_cost_avg: 37.34753970885545
train_count_sent: 8544.0
train_total_correct_sent: 5617.0
train_accuracy_sent: 0.6574204119850188
train_count_tok: 163566.0
train_total_correct_tok: 145397.0
train_accuracy_tok: 0.8889194575889855
train_label=O_precision_sent: 0.3285024154589372
train_label=O_recall_sent: 0.08374384236453201
train_label=O_f-score_sent: 0.13346418056918546
train_label=N_precision_sent: 0.6530559835644582
train_label=N_recall_sent: 0.7682779456193354
train_label=N_f-score_sent: 0.7059966685174903
train_label=P_precision_sent: 0.6935788479697829
train_label=P_recall_sent: 0.8138504155124654
train_label=P_f-score_sent: 0.7489166454244203
train_precision_macro_sent: 0.5583790823310594
train_recall_macro_sent: 0.5552907344987776
train_f-score_macro_sent: 0.529459164837032
train_precision_micro_sent: 0.6574204119850188
train_recall_micro_sent: 0.6574204119850188
train_f-score_micro_sent: 0.6574204119850188
train_label=O_precision_tok: 0.899007706269154
train_label=O_recall_tok: 0.9719494639999356
train_label=O_f-score_tok: 0.9340567193362779
train_label=N_precision_tok: 0.7845222813130387
train_label=N_recall_tok: 0.6024503591043515
train_label=N_f-score_tok: 0.6815357654930698
train_label=P_precision_tok: 0.8769754170324846
train_label=P_recall_tok: 0.6388455850021985
train_label=P_f-score_tok: 0.739205846303277
train_precision_macro_tok: 0.8535018015382257
train_recall_macro_tok: 0.7377484693688285
train_f-score_macro_tok: 0.7849327770442082
train_precision_micro_tok: 0.8889194575889855
train_recall_micro_tok: 0.8889194575889855
train_f-score_micro_tok: 0.8889194575889855
train_time: 145.9984393119812
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3285    0.0837    0.1335      1624
           N     0.6531    0.7683    0.7060      3310
           P     0.6936    0.8139    0.7489      3610

   micro avg     0.6574    0.6574    0.6574      8544
   macro avg     0.5584    0.5553    0.5295      8544
weighted avg     0.6085    0.6574    0.6153      8544

F1-macro sent:  0.529459164837032
F1-micro sent:  0.6574204119850188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9719    0.9341    124347
           N     0.7845    0.6025    0.6815     14202
           P     0.8770    0.6388    0.7392     25017

   micro avg     0.8889    0.8889    0.8889    163566
   macro avg     0.8535    0.7377    0.7849    163566
weighted avg     0.8857    0.8889    0.8823    163566

F1-macro tok:  0.7849327770442082
F1-micro tok:  0.8889194575889855
**************************************************
dev_cost_sum: 43138.571533203125
dev_cost_avg: 39.18126388120175
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19032.0
dev_accuracy_tok: 0.894613142803422
dev_label=O_precision_sent: 0.4166666666666667
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11320754716981132
dev_label=N_precision_sent: 0.605475040257649
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7168732125834129
dev_label=P_precision_sent: 0.7162162162162162
dev_label=P_recall_sent: 0.7162162162162162
dev_label=P_f-score_sent: 0.7162162162162162
dev_precision_macro_sent: 0.579452641046844
dev_recall_macro_sent: 0.5534076908398421
dev_f-score_macro_sent: 0.5154323253231468
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.9041850852517366
dev_label=O_recall_tok: 0.9719222462203023
dev_label=O_f-score_tok: 0.936830835117773
dev_label=N_precision_tok: 0.7774018944519621
dev_label=N_recall_tok: 0.6187399030694669
dev_label=N_f-score_tok: 0.6890554722638681
dev_label=P_precision_tok: 0.8973496003365586
dev_label=P_recall_tok: 0.6640722291407223
dev_label=P_f-score_tok: 0.7632850241545894
dev_precision_macro_tok: 0.8596455266800858
dev_recall_macro_tok: 0.7515781261434972
dev_f-score_macro_tok: 0.7963904438454102
dev_precision_micro_tok: 0.894613142803422
dev_recall_micro_tok: 0.894613142803422
dev_f-score_micro_tok: 0.894613142803422
dev_time: 8.229538440704346
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4167    0.0655    0.1132       229
           N     0.6055    0.8785    0.7169       428
           P     0.7162    0.7162    0.7162       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.5795    0.5534    0.5154      1101
weighted avg     0.6109    0.6440    0.5911      1101

F1-macro sent:  0.5154323253231468
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9719    0.9368     16205
           N     0.7774    0.6187    0.6891      1857
           P     0.8973    0.6641    0.7633      3212

   micro avg     0.8946    0.8946    0.8946     21274
   macro avg     0.8596    0.7516    0.7964     21274
weighted avg     0.8921    0.8946    0.8890     21274

F1-macro tok:  0.7963904438454102
F1-micro tok:  0.894613142803422
**************************************************
Best epoch: 18
**************************************************

EPOCH: 19
Learning rate: 0.656100
train_cost_sum: 317553.67791748047
train_cost_avg: 37.16686305213957
train_count_sent: 8544.0
train_total_correct_sent: 5627.0
train_accuracy_sent: 0.6585908239700374
train_count_tok: 163566.0
train_total_correct_tok: 145572.0
train_accuracy_tok: 0.8899893620923663
train_label=O_precision_sent: 0.34718100890207715
train_label=O_recall_sent: 0.07204433497536945
train_label=O_f-score_sent: 0.11932687404385518
train_label=N_precision_sent: 0.6373256373256373
train_label=N_recall_sent: 0.8006042296072508
train_label=N_f-score_sent: 0.7096946973754685
train_label=P_precision_sent: 0.706347246233638
train_label=P_recall_sent: 0.7922437673130194
train_label=P_f-score_sent: 0.7468337903120512
train_precision_macro_sent: 0.5636179641537842
train_recall_macro_sent: 0.5549641106318798
train_f-score_macro_sent: 0.525285120577125
train_precision_micro_sent: 0.6585908239700374
train_recall_micro_sent: 0.6585908239700374
train_f-score_micro_sent: 0.6585908239700374
train_label=O_precision_tok: 0.9003793440106127
train_label=O_recall_tok: 0.971571489460944
train_label=O_f-score_tok: 0.9346216628114774
train_label=N_precision_tok: 0.7835434999546403
train_label=N_recall_tok: 0.6081537811575835
train_label=N_f-score_tok: 0.684796828543112
train_label=P_precision_tok: 0.8779677630145938
train_label=P_recall_tok: 0.6444817524083624
train_label=P_f-score_tok: 0.7433208086489477
train_precision_macro_tok: 0.853963535659949
train_recall_macro_tok: 0.7414023410089632
train_f-score_macro_tok: 0.7875797666678457
train_precision_micro_tok: 0.8899893620923663
train_recall_micro_tok: 0.8899893620923663
train_f-score_micro_tok: 0.8899893620923663
train_time: 145.65673923492432
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3472    0.0720    0.1193      1624
           N     0.6373    0.8006    0.7097      3310
           P     0.7063    0.7922    0.7468      3610

   micro avg     0.6586    0.6586    0.6586      8544
   macro avg     0.5636    0.5550    0.5253      8544
weighted avg     0.6113    0.6586    0.6132      8544

F1-macro sent:  0.525285120577125
F1-micro sent:  0.6585908239700374
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9004    0.9716    0.9346    124347
           N     0.7835    0.6082    0.6848     14202
           P     0.8780    0.6445    0.7433     25017

   micro avg     0.8900    0.8900    0.8900    163566
   macro avg     0.8540    0.7414    0.7876    163566
weighted avg     0.8868    0.8900    0.8837    163566

F1-macro tok:  0.7875797666678457
F1-micro tok:  0.8899893620923663
**************************************************
dev_cost_sum: 43092.279296875
dev_cost_avg: 39.13921825329246
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19067.0
dev_accuracy_tok: 0.8962583435179092
dev_label=O_precision_sent: 0.4090909090909091
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07171314741035857
dev_label=N_precision_sent: 0.6263157894736842
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7154308617234468
dev_label=P_precision_sent: 0.6836935166994106
dev_label=P_recall_sent: 0.7837837837837838
dev_label=P_f-score_sent: 0.7303252885624343
dev_precision_macro_sent: 0.5730334050880014
dev_recall_macro_sent: 0.5523990811200541
dev_f-score_macro_sent: 0.5058230992320799
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.9037240432469539
dev_label=O_recall_tok: 0.9748842949706881
dev_label=O_f-score_tok: 0.937956421065131
dev_label=N_precision_tok: 0.7992831541218638
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.6857318573185731
dev_label=P_precision_tok: 0.8982485404503753
dev_label=P_recall_tok: 0.6706102117061021
dev_label=P_f-score_tok: 0.7679144385026737
dev_precision_macro_tok: 0.867085245939731
dev_recall_macro_tok: 0.7486417696820679
dev_f-score_macro_tok: 0.7972009056287925
dev_precision_micro_tok: 0.8962583435179092
dev_recall_micro_tok: 0.8962583435179092
dev_f-score_micro_tok: 0.8962583435179092
dev_time: 8.372565031051636
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4091    0.0393    0.0717       229
           N     0.6263    0.8341    0.7154       428
           P     0.6837    0.7838    0.7303       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.5730    0.5524    0.5058      1101
weighted avg     0.6043    0.6485    0.5875      1101

F1-macro sent:  0.5058230992320799
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9037    0.9749    0.9380     16205
           N     0.7993    0.6004    0.6857      1857
           P     0.8982    0.6706    0.7679      3212

   micro avg     0.8963    0.8963    0.8963     21274
   macro avg     0.8671    0.7486    0.7972     21274
weighted avg     0.8938    0.8963    0.8903     21274

F1-macro tok:  0.7972009056287925
F1-micro tok:  0.8962583435179092
**************************************************
Best epoch: 18
**************************************************

EPOCH: 20
Learning rate: 0.656100
train_cost_sum: 316416.6255493164
train_cost_avg: 37.033781080210254
train_count_sent: 8544.0
train_total_correct_sent: 5613.0
train_accuracy_sent: 0.6569522471910112
train_count_tok: 163566.0
train_total_correct_tok: 145776.0
train_accuracy_tok: 0.8912365650563076
train_label=O_precision_sent: 0.35058823529411764
train_label=O_recall_sent: 0.0917487684729064
train_label=O_f-score_sent: 0.14543679843826257
train_label=N_precision_sent: 0.6463629499119053
train_label=N_recall_sent: 0.7758308157099698
train_label=N_f-score_sent: 0.7052038994919675
train_label=P_precision_sent: 0.6985045827303425
train_label=P_recall_sent: 0.8022160664819945
train_label=P_f-score_sent: 0.7467766890149562
train_precision_macro_sent: 0.5651519226454552
train_recall_macro_sent: 0.5565985502216235
train_f-score_macro_sent: 0.5324724623150621
train_precision_micro_sent: 0.6569522471910112
train_recall_micro_sent: 0.6569522471910112
train_f-score_micro_sent: 0.6569522471910112
train_label=O_precision_tok: 0.9016452154448796
train_label=O_recall_tok: 0.9718207918164491
train_label=O_f-score_tok: 0.9354186986205935
train_label=N_precision_tok: 0.7903692976104272
train_label=N_recall_tok: 0.6148429798619913
train_label=N_f-score_tok: 0.6916435643564356
train_label=P_precision_tok: 0.8760612123506192
train_label=P_recall_tok: 0.64759963225007
train_label=P_f-score_tok: 0.7447023672718915
train_precision_macro_tok: 0.8560252418019753
train_recall_macro_tok: 0.7447544679761702
train_f-score_macro_tok: 0.7905882100829734
train_precision_micro_tok: 0.8912365650563076
train_recall_micro_tok: 0.8912365650563076
train_f-score_micro_tok: 0.8912365650563076
train_time: 145.1166443824768
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3506    0.0917    0.1454      1624
           N     0.6464    0.7758    0.7052      3310
           P     0.6985    0.8022    0.7468      3610

   micro avg     0.6570    0.6570    0.6570      8544
   macro avg     0.5652    0.5566    0.5325      8544
weighted avg     0.6122    0.6570    0.6164      8544

F1-macro sent:  0.5324724623150621
F1-micro sent:  0.6569522471910112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9016    0.9718    0.9354    124347
           N     0.7904    0.6148    0.6916     14202
           P     0.8761    0.6476    0.7447     25017

   micro avg     0.8912    0.8912    0.8912    163566
   macro avg     0.8560    0.7448    0.7906    163566
weighted avg     0.8881    0.8912    0.8851    163566

F1-macro tok:  0.7905882100829734
F1-micro tok:  0.8912365650563076
**************************************************
dev_cost_sum: 42983.18865966797
dev_cost_avg: 39.04013502240506
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 19069.0
dev_accuracy_tok: 0.8963523549873085
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.7160804020100503
dev_label=N_recall_sent: 0.6658878504672897
dev_label=N_f-score_sent: 0.6900726392251816
dev_label=P_precision_sent: 0.5895953757225434
dev_label=P_recall_sent: 0.918918918918919
dev_label=P_f-score_sent: 0.7183098591549296
dev_precision_macro_sent: 0.7079525319714707
dev_recall_macro_sent: 0.5413693598099589
dev_f-score_macro_sent: 0.4944608327933704
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.907177861055059
dev_label=O_recall_tok: 0.9709966059858068
dev_label=O_f-score_tok: 0.9380029806259313
dev_label=N_precision_tok: 0.7771043771043771
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.6906044284859365
dev_label=P_precision_tok: 0.8919803600654664
dev_label=P_recall_tok: 0.6787048567870486
dev_label=P_f-score_tok: 0.7708628005657708
dev_precision_macro_tok: 0.8587541994083009
dev_recall_macro_tok: 0.7570446268837179
dev_f-score_macro_tok: 0.7998234032258796
dev_precision_micro_tok: 0.8963523549873085
dev_recall_micro_tok: 0.8963523549873085
dev_f-score_micro_tok: 0.8963523549873085
dev_time: 8.22372055053711
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.7161    0.6659    0.6901       428
           P     0.5896    0.9189    0.7183       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.7080    0.5414    0.4945      1101
weighted avg     0.6863    0.6376    0.5735      1101

F1-macro sent:  0.4944608327933704
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9072    0.9710    0.9380     16205
           N     0.7771    0.6214    0.6906      1857
           P     0.8920    0.6787    0.7709      3212

   micro avg     0.8964    0.8964    0.8964     21274
   macro avg     0.8588    0.7570    0.7998     21274
weighted avg     0.8935    0.8964    0.8912     21274

F1-macro tok:  0.7998234032258796
F1-micro tok:  0.8963523549873085
**************************************************
Best epoch: 18
**************************************************

EPOCH: 21
Learning rate: 0.656100
train_cost_sum: 315054.58447265625
train_cost_avg: 36.87436616018917
train_count_sent: 8544.0
train_total_correct_sent: 5733.0
train_accuracy_sent: 0.670997191011236
train_count_tok: 163566.0
train_total_correct_tok: 145936.0
train_accuracy_tok: 0.8922147634593987
train_label=O_precision_sent: 0.40816326530612246
train_label=O_recall_sent: 0.08620689655172414
train_label=O_f-score_sent: 0.1423487544483986
train_label=N_precision_sent: 0.6553265458157437
train_label=N_recall_sent: 0.7972809667673716
train_label=N_f-score_sent: 0.7193675889328064
train_label=P_precision_sent: 0.7077144226161955
train_label=P_recall_sent: 0.8182825484764543
train_label=P_f-score_sent: 0.7589928057553957
train_precision_macro_sent: 0.5904014112460206
train_recall_macro_sent: 0.56725680393185
train_f-score_macro_sent: 0.5402363830455336
train_precision_micro_sent: 0.670997191011236
train_recall_micro_sent: 0.670997191011236
train_f-score_micro_sent: 0.670997191011236
train_label=O_precision_tok: 0.9024246361552305
train_label=O_recall_tok: 0.9718770858967245
train_label=O_f-score_tok: 0.9358640770684261
train_label=N_precision_tok: 0.7916741431903822
train_label=N_recall_tok: 0.6213209407125757
train_label=N_f-score_tok: 0.6962284992898848
train_label=P_precision_tok: 0.8788845052153704
train_label=P_recall_tok: 0.6500379741775593
train_label=P_f-score_tok: 0.7473345588235294
train_precision_macro_tok: 0.8576610948536612
train_recall_macro_tok: 0.7477453335956198
train_f-score_macro_tok: 0.7931423783939469
train_precision_micro_tok: 0.8922147634593987
train_recall_micro_tok: 0.8922147634593987
train_f-score_micro_tok: 0.8922147634593987
train_time: 145.15191388130188
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4082    0.0862    0.1423      1624
           N     0.6553    0.7973    0.7194      3310
           P     0.7077    0.8183    0.7590      3610

   micro avg     0.6710    0.6710    0.6710      8544
   macro avg     0.5904    0.5673    0.5402      8544
weighted avg     0.6305    0.6710    0.6264      8544

F1-macro sent:  0.5402363830455336
F1-micro sent:  0.670997191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9024    0.9719    0.9359    124347
           N     0.7917    0.6213    0.6962     14202
           P     0.8789    0.6500    0.7473     25017

   micro avg     0.8922    0.8922    0.8922    163566
   macro avg     0.8577    0.7477    0.7931    163566
weighted avg     0.8892    0.8922    0.8862    163566

F1-macro tok:  0.7931423783939469
F1-micro tok:  0.8922147634593987
**************************************************
dev_cost_sum: 42854.51965332031
dev_cost_avg: 38.92326943989129
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19085.0
dev_accuracy_tok: 0.8971044467425026
dev_label=O_precision_sent: 0.6538461538461539
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.13333333333333336
dev_label=N_precision_sent: 0.6705202312138728
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7349524815205913
dev_label=P_precision_sent: 0.6672661870503597
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7420000000000001
dev_precision_macro_sent: 0.6638775240367955
dev_recall_macro_sent: 0.5743018351984601
dev_f-score_macro_sent: 0.5367619382846417
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9008921975336706
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9379918348026745
dev_label=N_precision_tok: 0.8126377663482733
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6873834679925419
dev_label=P_precision_tok: 0.9179620034542314
dev_label=P_recall_tok: 0.661892901618929
dev_label=P_f-score_tok: 0.7691751085383501
dev_precision_macro_tok: 0.8771639891120584
dev_recall_macro_tok: 0.7452518288320945
dev_f-score_macro_tok: 0.7981834704445222
dev_precision_micro_tok: 0.8971044467425026
dev_recall_micro_tok: 0.8971044467425026
dev_f-score_micro_tok: 0.8971044467425026
dev_time: 8.532846450805664
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6538    0.0742    0.1333       229
           N     0.6705    0.8131    0.7350       428
           P     0.6673    0.8356    0.7420       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6639    0.5743    0.5368      1101
weighted avg     0.6657    0.6685    0.6127      1101

F1-macro sent:  0.5367619382846417
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9783    0.9380     16205
           N     0.8126    0.5956    0.6874      1857
           P     0.9180    0.6619    0.7692      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8772    0.7453    0.7982     21274
weighted avg     0.8958    0.8971    0.8906     21274

F1-macro tok:  0.7981834704445222
F1-micro tok:  0.8971044467425026
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.656100
train_cost_sum: 313687.85272216797
train_cost_avg: 36.714402238081455
train_count_sent: 8544.0
train_total_correct_sent: 5710.0
train_accuracy_sent: 0.6683052434456929
train_count_tok: 163566.0
train_total_correct_tok: 146214.0
train_accuracy_tok: 0.8939143831847695
train_label=O_precision_sent: 0.4085603112840467
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.1116427432216906
train_label=N_precision_sent: 0.6398104265402843
train_label=N_recall_sent: 0.8157099697885196
train_label=N_f-score_sent: 0.7171314741035857
train_label=P_precision_sent: 0.7142857142857143
train_label=P_recall_sent: 0.8047091412742382
train_label=P_f-score_sent: 0.756806044027615
train_precision_macro_sent: 0.5875521507033484
train_recall_macro_sent: 0.561691427825517
train_f-score_macro_sent: 0.5285267537842971
train_precision_micro_sent: 0.6683052434456929
train_recall_micro_sent: 0.6683052434456929
train_f-score_micro_sent: 0.6683052434456929
train_label=O_precision_tok: 0.9041538565112991
train_label=O_recall_tok: 0.9720379261260826
train_label=O_f-score_tok: 0.9368678060690617
train_label=N_precision_tok: 0.7928756361039193
train_label=N_recall_tok: 0.6253344599352204
train_label=N_f-score_tok: 0.6992087548714719
train_label=P_precision_tok: 0.8812225671769618
train_label=P_recall_tok: 0.658072510692729
train_label=P_f-score_tok: 0.7534726195107441
train_precision_macro_tok: 0.85941735326406
train_recall_macro_tok: 0.7518149655846772
train_f-score_macro_tok: 0.7965163934837592
train_precision_micro_tok: 0.8939143831847695
train_recall_micro_tok: 0.8939143831847695
train_f-score_micro_tok: 0.8939143831847695
train_time: 144.9886989593506
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4086    0.0647    0.1116      1624
           N     0.6398    0.8157    0.7171      3310
           P     0.7143    0.8047    0.7568      3610

   micro avg     0.6683    0.6683    0.6683      8544
   macro avg     0.5876    0.5617    0.5285      8544
weighted avg     0.6273    0.6683    0.6188      8544

F1-macro sent:  0.5285267537842971
F1-micro sent:  0.6683052434456929
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9720    0.9369    124347
           N     0.7929    0.6253    0.6992     14202
           P     0.8812    0.6581    0.7535     25017

   micro avg     0.8939    0.8939    0.8939    163566
   macro avg     0.8594    0.7518    0.7965    163566
weighted avg     0.8910    0.8939    0.8882    163566

F1-macro tok:  0.7965163934837592
F1-micro tok:  0.8939143831847695
**************************************************
dev_cost_sum: 42757.06652832031
dev_cost_avg: 38.83475615651255
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19093.0
dev_accuracy_tok: 0.8974804926200997
dev_label=O_precision_sent: 0.48148148148148145
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10156250000000001
dev_label=N_precision_sent: 0.6593406593406593
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7392197125256673
dev_label=P_precision_sent: 0.6837121212121212
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7427983539094649
dev_precision_macro_sent: 0.6081780873447541
dev_recall_macro_sent: 0.5703177057807104
dev_f-score_macro_sent: 0.5278601888117107
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9038340666247643
dev_label=O_recall_tok: 0.9761184819500154
dev_label=O_f-score_tok: 0.9385866017919657
dev_label=N_precision_tok: 0.8151447661469933
dev_label=N_recall_tok: 0.5912762520193862
dev_label=N_f-score_tok: 0.6853932584269663
dev_label=P_precision_tok: 0.8973619126133553
dev_label=P_recall_tok: 0.6777708592777086
dev_label=P_f-score_tok: 0.7722596665484214
dev_precision_macro_tok: 0.8721135817950376
dev_recall_macro_tok: 0.74838853108237
dev_f-score_macro_tok: 0.7987465089224511
dev_precision_micro_tok: 0.8974804926200997
dev_recall_micro_tok: 0.8974804926200997
dev_f-score_micro_tok: 0.8974804926200998
dev_time: 8.35239577293396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4815    0.0568    0.1016       229
           N     0.6593    0.8411    0.7392       428
           P     0.6837    0.8131    0.7428       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6082    0.5703    0.5279      1101
weighted avg     0.6322    0.6667    0.6080      1101

F1-macro sent:  0.5278601888117107
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9038    0.9761    0.9386     16205
           N     0.8151    0.5913    0.6854      1857
           P     0.8974    0.6778    0.7723      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8721    0.7484    0.7987     21274
weighted avg     0.8951    0.8975    0.8914     21274

F1-macro tok:  0.7987465089224511
F1-micro tok:  0.8974804926200998
**************************************************
Best epoch: 21
**************************************************

EPOCH: 23
Learning rate: 0.656100
train_cost_sum: 312513.75134277344
train_cost_avg: 36.57698400547442
train_count_sent: 8544.0
train_total_correct_sent: 5787.0
train_accuracy_sent: 0.6773174157303371
train_count_tok: 163566.0
train_total_correct_tok: 146296.0
train_accuracy_tok: 0.8944157098663537
train_label=O_precision_sent: 0.39622641509433965
train_label=O_recall_sent: 0.07758620689655173
train_label=O_f-score_sent: 0.12976313079299692
train_label=N_precision_sent: 0.6605092361457813
train_label=N_recall_sent: 0.7993957703927492
train_label=N_f-score_sent: 0.723346090759978
train_label=P_precision_sent: 0.7144549763033176
train_label=P_recall_sent: 0.8351800554016621
train_label=P_f-score_sent: 0.7701149425287356
train_precision_macro_sent: 0.5903968758478128
train_recall_macro_sent: 0.5707206775636543
train_f-score_macro_sent: 0.5410747213605701
train_precision_micro_sent: 0.6773174157303371
train_recall_micro_sent: 0.6773174157303371
train_f-score_micro_sent: 0.6773174157303371
train_label=O_precision_tok: 0.9045423586734427
train_label=O_recall_tok: 0.9719172959540641
train_label=O_f-score_tok: 0.9370202670222829
train_label=N_precision_tok: 0.8000715947735815
train_label=N_recall_tok: 0.6294888043937473
train_label=N_f-score_tok: 0.7046027742749053
train_label=P_precision_tok: 0.8785071607304478
train_label=P_recall_tok: 0.6595914777950993
train_label=P_f-score_tok: 0.7534703196347031
train_precision_macro_tok: 0.8610403713924907
train_recall_macro_tok: 0.7536658593809702
train_f-score_macro_tok: 0.7983644536439637
train_precision_micro_tok: 0.8944157098663537
train_recall_micro_tok: 0.8944157098663537
train_f-score_micro_tok: 0.8944157098663537
train_time: 145.92002511024475
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3962    0.0776    0.1298      1624
           N     0.6605    0.7994    0.7233      3310
           P     0.7145    0.8352    0.7701      3610

   micro avg     0.6773    0.6773    0.6773      8544
   macro avg     0.5904    0.5707    0.5411      8544
weighted avg     0.6331    0.6773    0.6303      8544

F1-macro sent:  0.5410747213605701
F1-micro sent:  0.6773174157303371
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9045    0.9719    0.9370    124347
           N     0.8001    0.6295    0.7046     14202
           P     0.8785    0.6596    0.7535     25017

   micro avg     0.8944    0.8944    0.8944    163566
   macro avg     0.8610    0.7537    0.7984    163566
weighted avg     0.8915    0.8944    0.8888    163566

F1-macro tok:  0.7983644536439637
F1-micro tok:  0.8944157098663537
**************************************************
dev_cost_sum: 42708.49621582031
dev_cost_avg: 38.79064143126277
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19076.0
dev_accuracy_tok: 0.8966813951302058
dev_label=O_precision_sent: 0.6190476190476191
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.104
dev_label=N_precision_sent: 0.665406427221172
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.735632183908046
dev_label=P_precision_sent: 0.6787658802177858
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7517587939698492
dev_precision_macro_sent: 0.6544066421621924
dev_recall_macro_sent: 0.5738469359454544
dev_f-score_macro_sent: 0.5304636592926317
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9038791623755579
dev_label=O_recall_tok: 0.9748842949706881
dev_label=O_f-score_tok: 0.9380399608110916
dev_label=N_precision_tok: 0.7856645789839944
dev_label=N_recall_tok: 0.6079698438341411
dev_label=N_f-score_tok: 0.6854887674559805
dev_label=P_precision_tok: 0.9109792284866469
dev_label=P_recall_tok: 0.6690535491905355
dev_label=P_f-score_tok: 0.7714952432238379
dev_precision_macro_tok: 0.8668409899487332
dev_recall_macro_tok: 0.7506358959984549
dev_f-score_macro_tok: 0.7983413238303033
dev_precision_micro_tok: 0.8966813951302058
dev_recall_micro_tok: 0.8966813951302058
dev_f-score_micro_tok: 0.8966813951302058
dev_time: 8.348129034042358
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6190    0.0568    0.1040       229
           N     0.6654    0.8224    0.7356       428
           P     0.6788    0.8423    0.7518       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6544    0.5738    0.5305      1101
weighted avg     0.6612    0.6712    0.6108      1101

F1-macro sent:  0.5304636592926317
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9039    0.9749    0.9380     16205
           N     0.7857    0.6080    0.6855      1857
           P     0.9110    0.6691    0.7715      3212

   micro avg     0.8967    0.8967    0.8967     21274
   macro avg     0.8668    0.7506    0.7983     21274
weighted avg     0.8946    0.8967    0.8908     21274

F1-macro tok:  0.7983413238303033
F1-micro tok:  0.8966813951302058
**************************************************
Best epoch: 21
**************************************************

EPOCH: 24
Learning rate: 0.656100
train_cost_sum: 311272.00408935547
train_cost_avg: 36.431648418697975
train_count_sent: 8544.0
train_total_correct_sent: 5799.0
train_accuracy_sent: 0.6787219101123596
train_count_tok: 163566.0
train_total_correct_tok: 146683.0
train_accuracy_tok: 0.8967817272538302
train_label=O_precision_sent: 0.46688741721854304
train_label=O_recall_sent: 0.08682266009852217
train_label=O_f-score_sent: 0.14641744548286606
train_label=N_precision_sent: 0.6476010399432758
train_label=N_recall_sent: 0.8277945619335347
train_label=N_f-score_sent: 0.7266940724041904
train_label=P_precision_sent: 0.7274993767140364
train_label=P_recall_sent: 0.8083102493074792
train_label=P_f-score_sent: 0.765778769190395
train_precision_macro_sent: 0.6139959446252851
train_recall_macro_sent: 0.5743091571131788
train_f-score_macro_sent: 0.5462967623591505
train_precision_micro_sent: 0.6787219101123596
train_recall_micro_sent: 0.6787219101123596
train_f-score_micro_sent: 0.6787219101123596
train_label=O_precision_tok: 0.9070534937445621
train_label=O_recall_tok: 0.972536530837093
train_label=O_f-score_tok: 0.938654330522255
train_label=N_precision_tok: 0.8
train_label=N_recall_tok: 0.6379383185466836
train_label=N_f-score_tok: 0.7098366435538841
train_label=P_precision_tok: 0.8823280647037056
train_label=P_recall_tok: 0.6671863133069513
train_label=P_f-score_tok: 0.7598215505075796
train_precision_macro_tok: 0.8631271861494226
train_recall_macro_tok: 0.7592203875635759
train_f-score_macro_tok: 0.8027708415279062
train_precision_micro_tok: 0.8967817272538302
train_recall_micro_tok: 0.8967817272538302
train_f-score_micro_tok: 0.8967817272538302
train_time: 145.2385652065277
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4669    0.0868    0.1464      1624
           N     0.6476    0.8278    0.7267      3310
           P     0.7275    0.8083    0.7658      3610

   micro avg     0.6787    0.6787    0.6787      8544
   macro avg     0.6140    0.5743    0.5463      8544
weighted avg     0.6470    0.6787    0.6329      8544

F1-macro sent:  0.5462967623591505
F1-micro sent:  0.6787219101123596
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9071    0.9725    0.9387    124347
           N     0.8000    0.6379    0.7098     14202
           P     0.8823    0.6672    0.7598     25017

   micro avg     0.8968    0.8968    0.8968    163566
   macro avg     0.8631    0.7592    0.8028    163566
weighted avg     0.8940    0.8968    0.8914    163566

F1-macro tok:  0.8027708415279062
F1-micro tok:  0.8967817272538302
**************************************************
dev_cost_sum: 42630.77551269531
dev_cost_avg: 38.720050420250054
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19073.0
dev_accuracy_tok: 0.896540377926107
dev_label=O_precision_sent: 0.6111111111111112
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08906882591093117
dev_label=N_precision_sent: 0.6277128547579299
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7322297955209348
dev_label=P_precision_sent: 0.7169421487603306
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7478448275862069
dev_precision_macro_sent: 0.6519220382097907
dev_recall_macro_sent: 0.5693570463088481
dev_f-score_macro_sent: 0.5230478163393576
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9105327368849125
dev_label=O_recall_tok: 0.967170626349892
dev_label=O_f-score_tok: 0.9379974863845831
dev_label=N_precision_tok: 0.765359477124183
dev_label=N_recall_tok: 0.6305869682283253
dev_label=N_f-score_tok: 0.6914673752583408
dev_label=P_precision_tok: 0.8806795732911893
dev_label=P_recall_tok: 0.6939601494396015
dev_label=P_f-score_tok: 0.7762493470311685
dev_precision_macro_tok: 0.8521905957667616
dev_recall_macro_tok: 0.7639059146726064
dev_f-score_macro_tok: 0.8019047362246975
dev_precision_micro_tok: 0.896540377926107
dev_recall_micro_tok: 0.896540377926107
dev_f-score_micro_tok: 0.896540377926107
dev_time: 8.543108940124512
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6111    0.0480    0.0891       229
           N     0.6277    0.8785    0.7322       428
           P     0.7169    0.7815    0.7478       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6519    0.5694    0.5230      1101
weighted avg     0.6602    0.6667    0.6048      1101

F1-macro sent:  0.5230478163393576
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9105    0.9672    0.9380     16205
           N     0.7654    0.6306    0.6915      1857
           P     0.8807    0.6940    0.7762      3212

   micro avg     0.8965    0.8965    0.8965     21274
   macro avg     0.8522    0.7639    0.8019     21274
weighted avg     0.8934    0.8965    0.8921     21274

F1-macro tok:  0.8019047362246975
F1-micro tok:  0.896540377926107
**************************************************
Best epoch: 21
**************************************************

EPOCH: 25
Learning rate: 0.656100
train_cost_sum: 310232.70794677734
train_cost_avg: 36.310007952572256
train_count_sent: 8544.0
train_total_correct_sent: 5768.0
train_accuracy_sent: 0.6750936329588015
train_count_tok: 163566.0
train_total_correct_tok: 146776.0
train_accuracy_tok: 0.897350305075627
train_label=O_precision_sent: 0.4883720930232558
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.0935412026726058
train_label=N_precision_sent: 0.6486101211689237
train_label=N_recall_sent: 0.824773413897281
train_label=N_f-score_sent: 0.7261603936693708
train_label=P_precision_sent: 0.7095844343021859
train_label=P_recall_sent: 0.8182825484764543
train_label=P_f-score_sent: 0.7600668982374886
train_precision_macro_sent: 0.6155222161647885
train_recall_macro_sent: 0.56492670010159
train_f-score_macro_sent: 0.526589498193155
train_precision_micro_sent: 0.6750936329588015
train_recall_micro_sent: 0.6750936329588015
train_f-score_micro_sent: 0.6750936329588015
train_label=O_precision_tok: 0.9083156130951934
train_label=O_recall_tok: 0.9721585562981013
train_label=O_f-score_tok: 0.9391533363891328
train_label=N_precision_tok: 0.7997374179431073
train_label=N_recall_tok: 0.643360090128151
train_label=N_f-score_tok: 0.7130760526007727
train_label=P_precision_tok: 0.8792904377033693
train_label=P_recall_tok: 0.6697046008714075
train_label=P_f-score_tok: 0.7603185768419142
train_precision_macro_tok: 0.86244782291389
train_recall_macro_tok: 0.7617410824325533
train_f-score_macro_tok: 0.8041826552772732
train_precision_micro_tok: 0.897350305075627
train_recall_micro_tok: 0.897350305075627
train_f-score_micro_tok: 0.8973503050756271
train_time: 145.34126138687134
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4884    0.0517    0.0935      1624
           N     0.6486    0.8248    0.7262      3310
           P     0.7096    0.8183    0.7601      3610

   micro avg     0.6751    0.6751    0.6751      8544
   macro avg     0.6155    0.5649    0.5266      8544
weighted avg     0.6439    0.6751    0.6202      8544

F1-macro sent:  0.526589498193155
F1-micro sent:  0.6750936329588015
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9722    0.9392    124347
           N     0.7997    0.6434    0.7131     14202
           P     0.8793    0.6697    0.7603     25017

   micro avg     0.8974    0.8974    0.8974    163566
   macro avg     0.8624    0.7617    0.8042    163566
weighted avg     0.8944    0.8974    0.8922    163566

F1-macro tok:  0.8041826552772732
F1-micro tok:  0.8973503050756271
**************************************************
dev_cost_sum: 42624.63427734375
dev_cost_avg: 38.71447254981267
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19147.0
dev_accuracy_tok: 0.9000188022938799
dev_label=O_precision_sent: 0.6923076923076923
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0743801652892562
dev_label=N_precision_sent: 0.6635859519408502
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.740970072239422
dev_label=P_precision_sent: 0.676416819012797
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7467204843592332
dev_precision_macro_sent: 0.6774368210871131
dev_recall_macro_sent: 0.5704732300353245
dev_f-score_macro_sent: 0.5206902406293038
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9045662100456621
dev_label=O_recall_tok: 0.9779697624190065
dev_label=O_f-score_tok: 0.9398369162342475
dev_label=N_precision_tok: 0.8059701492537313
dev_label=N_recall_tok: 0.6106623586429726
dev_label=N_f-score_tok: 0.6948529411764706
dev_label=P_precision_tok: 0.9224541968470388
dev_label=P_recall_tok: 0.6740348692403487
dev_label=P_f-score_tok: 0.7789170714157222
dev_precision_macro_tok: 0.8776635187154774
dev_recall_macro_tok: 0.754222330100776
dev_f-score_macro_tok: 0.8045356429421467
dev_precision_micro_tok: 0.9000188022938799
dev_recall_micro_tok: 0.9000188022938799
dev_f-score_micro_tok: 0.9000188022938799
dev_time: 8.173991680145264
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6923    0.0393    0.0744       229
           N     0.6636    0.8388    0.7410       428
           P     0.6764    0.8333    0.7467       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6774    0.5705    0.5207      1101
weighted avg     0.6747    0.6703    0.6046      1101

F1-macro sent:  0.5206902406293038
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9780    0.9398     16205
           N     0.8060    0.6107    0.6949      1857
           P     0.9225    0.6740    0.7789      3212

   micro avg     0.9000    0.9000    0.9000     21274
   macro avg     0.8777    0.7542    0.8045     21274
weighted avg     0.8987    0.9000    0.8942     21274

F1-macro tok:  0.8045356429421467
F1-micro tok:  0.9000188022938799
**************************************************
Best epoch: 21
**************************************************

EPOCH: 26
Learning rate: 0.590490
train_cost_sum: 308986.3063354492
train_cost_avg: 36.16412761416775
train_count_sent: 8544.0
train_total_correct_sent: 5864.0
train_accuracy_sent: 0.6863295880149812
train_count_tok: 163566.0
train_total_correct_tok: 146894.0
train_accuracy_tok: 0.8980717263979067
train_label=O_precision_sent: 0.4978902953586498
train_label=O_recall_sent: 0.07266009852216748
train_label=O_f-score_sent: 0.12681354110693174
train_label=N_precision_sent: 0.6544897478199387
train_label=N_recall_sent: 0.8389728096676737
train_label=N_f-score_sent: 0.735336952204422
train_label=P_precision_sent: 0.7305610236220472
train_label=P_recall_sent: 0.8224376731301939
train_label=P_f-score_sent: 0.7737816002084963
train_precision_macro_sent: 0.6276470222668786
train_recall_macro_sent: 0.5780235271066784
train_f-score_macro_sent: 0.54531069783995
train_precision_micro_sent: 0.6863295880149812
train_recall_micro_sent: 0.6863295880149812
train_f-score_micro_sent: 0.6863295880149812
train_label=O_precision_tok: 0.9086747350221754
train_label=O_recall_tok: 0.9721263882522296
train_label=O_f-score_tok: 0.9393302431841228
train_label=N_precision_tok: 0.803557346885131
train_label=N_recall_tok: 0.6457541191381495
train_label=N_f-score_tok: 0.7160648057778646
train_label=P_precision_tok: 0.8807195523714898
train_label=P_recall_tok: 0.6732222088979494
train_label=P_f-score_tok: 0.7631173538740372
train_precision_macro_tok: 0.8643172114262655
train_recall_macro_tok: 0.7637009054294429
train_f-score_macro_tok: 0.8061708009453415
train_precision_micro_tok: 0.8980717263979067
train_recall_micro_tok: 0.8980717263979067
train_f-score_micro_tok: 0.8980717263979067
train_time: 145.48867988586426
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4979    0.0727    0.1268      1624
           N     0.6545    0.8390    0.7353      3310
           P     0.7306    0.8224    0.7738      3610

   micro avg     0.6863    0.6863    0.6863      8544
   macro avg     0.6276    0.5780    0.5453      8544
weighted avg     0.6569    0.6863    0.6359      8544

F1-macro sent:  0.54531069783995
F1-micro sent:  0.6863295880149812
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9087    0.9721    0.9393    124347
           N     0.8036    0.6458    0.7161     14202
           P     0.8807    0.6732    0.7631     25017

   micro avg     0.8981    0.8981    0.8981    163566
   macro avg     0.8643    0.7637    0.8062    163566
weighted avg     0.8953    0.8981    0.8930    163566

F1-macro tok:  0.8061708009453415
F1-micro tok:  0.8980717263979067
**************************************************
dev_cost_sum: 42565.870056152344
dev_cost_avg: 38.66109905190949
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19090.0
dev_accuracy_tok: 0.8973394754160008
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08163265306122448
dev_label=N_precision_sent: 0.6270903010033445
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.7309941520467838
dev_label=P_precision_sent: 0.7104722792607803
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7432867883995703
dev_precision_macro_sent: 0.6541875267547083
dev_recall_macro_sent: 0.566371875283029
dev_f-score_macro_sent: 0.5186378645025261
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9101560234325156
dev_label=O_recall_tok: 0.968343103980253
dev_label=O_f-score_tok: 0.9383483824672607
dev_label=N_precision_tok: 0.7735099337748345
dev_label=N_recall_tok: 0.6289714593430263
dev_label=N_f-score_tok: 0.6937926937926938
dev_label=P_precision_tok: 0.8838684106222751
dev_label=P_recall_tok: 0.6942714819427148
dev_label=P_f-score_tok: 0.7776809067131647
dev_precision_macro_tok: 0.8558447892765417
dev_recall_macro_tok: 0.7638620150886647
dev_f-score_macro_tok: 0.8032739943243731
dev_precision_micro_tok: 0.8973394754160008
dev_recall_micro_tok: 0.8973394754160008
dev_f-score_micro_tok: 0.8973394754160007
dev_time: 8.18948483467102
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0437    0.0816       229
           N     0.6271    0.8762    0.7310       428
           P     0.7105    0.7793    0.7433       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6542    0.5664    0.5186      1101
weighted avg     0.6603    0.6639    0.6009      1101

F1-macro sent:  0.5186378645025261
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9102    0.9683    0.9383     16205
           N     0.7735    0.6290    0.6938      1857
           P     0.8839    0.6943    0.7777      3212

   micro avg     0.8973    0.8973    0.8973     21274
   macro avg     0.8558    0.7639    0.8033     21274
weighted avg     0.8943    0.8973    0.8927     21274

F1-macro tok:  0.8032739943243731
F1-micro tok:  0.8973394754160007
**************************************************
Best epoch: 21
**************************************************

EPOCH: 27
Learning rate: 0.531441
train_cost_sum: 307708.10540771484
train_cost_avg: 36.01452544565951
train_count_sent: 8544.0
train_total_correct_sent: 5816.0
train_accuracy_sent: 0.6807116104868914
train_count_tok: 163566.0
train_total_correct_tok: 147264.0
train_accuracy_tok: 0.9003338102050549
train_label=O_precision_sent: 0.4605263157894737
train_label=O_recall_sent: 0.06465517241379311
train_label=O_f-score_sent: 0.11339092872570194
train_label=N_precision_sent: 0.6494117647058824
train_label=N_recall_sent: 0.8338368580060423
train_label=N_f-score_sent: 0.7301587301587301
train_label=P_precision_sent: 0.7257747171667487
train_label=P_recall_sent: 0.8174515235457064
train_label=P_f-score_sent: 0.7688900468994267
train_precision_macro_sent: 0.6119042658873682
train_recall_macro_sent: 0.5719811846551807
train_f-score_macro_sent: 0.5374799019279529
train_precision_micro_sent: 0.6807116104868914
train_recall_micro_sent: 0.6807116104868914
train_f-score_micro_sent: 0.6807116104868914
train_label=O_precision_tok: 0.9108781916615841
train_label=O_recall_tok: 0.9728501692843414
train_label=O_f-score_tok: 0.9408447856148455
train_label=N_precision_tok: 0.8099571266077522
train_label=N_recall_tok: 0.6518096042810871
train_label=N_f-score_tok: 0.7223284304162927
train_label=P_precision_tok: 0.8813243662700465
train_label=P_recall_tok: 0.6809769356837351
train_label=P_f-score_tok: 0.7683045076329853
train_precision_macro_tok: 0.8673865615131277
train_recall_macro_tok: 0.7685455697497212
train_f-score_macro_tok: 0.8104925745547078
train_precision_micro_tok: 0.9003338102050549
train_recall_micro_tok: 0.9003338102050549
train_f-score_micro_tok: 0.9003338102050549
train_time: 145.66530752182007
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4605    0.0647    0.1134      1624
           N     0.6494    0.8338    0.7302      3310
           P     0.7258    0.8175    0.7689      3610

   micro avg     0.6807    0.6807    0.6807      8544
   macro avg     0.6119    0.5720    0.5375      8544
weighted avg     0.6458    0.6807    0.6293      8544

F1-macro sent:  0.5374799019279529
F1-micro sent:  0.6807116104868914
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9109    0.9729    0.9408    124347
           N     0.8100    0.6518    0.7223     14202
           P     0.8813    0.6810    0.7683     25017

   micro avg     0.9003    0.9003    0.9003    163566
   macro avg     0.8674    0.7685    0.8105    163566
weighted avg     0.8976    0.9003    0.8955    163566

F1-macro tok:  0.8104925745547078
F1-micro tok:  0.9003338102050549
**************************************************
dev_cost_sum: 42489.58837890625
dev_cost_avg: 38.59181505804382
dev_count_sent: 1101.0
dev_total_correct_sent: 737.0
dev_accuracy_sent: 0.6693914623069936
dev_count_tok: 21274.0
dev_total_correct_tok: 19119.0
dev_accuracy_tok: 0.8987026417222901
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11155378486055777
dev_label=N_precision_sent: 0.6458333333333334
dev_label=N_recall_sent: 0.8691588785046729
dev_label=N_f-score_sent: 0.7410358565737053
dev_label=P_precision_sent: 0.6978131212723658
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7412882787750792
dev_precision_macro_sent: 0.6600033636564452
dev_recall_macro_sent: 0.5736115967414176
dev_f-score_macro_sent: 0.5312926400697807
dev_precision_micro_sent: 0.6693914623069936
dev_recall_micro_sent: 0.6693914623069936
dev_f-score_micro_sent: 0.6693914623069936
dev_label=O_precision_tok: 0.9083414999711765
dev_label=O_recall_tok: 0.9723542116630669
dev_label=O_f-score_tok: 0.9392584644730567
dev_label=N_precision_tok: 0.7748518762343647
dev_label=N_recall_tok: 0.633817985998923
dev_label=N_f-score_tok: 0.6972748815165878
dev_label=P_precision_tok: 0.907392026578073
dev_label=P_recall_tok: 0.6802615193026152
dev_label=P_f-score_tok: 0.7775800711743772
dev_precision_macro_tok: 0.8635284675945382
dev_recall_macro_tok: 0.7621445723215351
dev_f-score_macro_tok: 0.8047044723880074
dev_precision_micro_tok: 0.8987026417222901
dev_recall_micro_tok: 0.8987026417222901
dev_f-score_micro_tok: 0.8987026417222901
dev_time: 8.251402616500854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0611    0.1116       229
           N     0.6458    0.8692    0.7410       428
           P     0.6978    0.7905    0.7413       444

   micro avg     0.6694    0.6694    0.6694      1101
   macro avg     0.6600    0.5736    0.5313      1101
weighted avg     0.6648    0.6694    0.6102      1101

F1-macro sent:  0.5312926400697807
F1-micro sent:  0.6693914623069936
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9083    0.9724    0.9393     16205
           N     0.7749    0.6338    0.6973      1857
           P     0.9074    0.6803    0.7776      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8635    0.7621    0.8047     21274
weighted avg     0.8965    0.8987    0.8937     21274

F1-macro tok:  0.8047044723880074
F1-micro tok:  0.8987026417222901
**************************************************
Best epoch: 21
**************************************************

EPOCH: 28
Learning rate: 0.478297
train_cost_sum: 306505.7335205078
train_cost_avg: 35.87379839893584
train_count_sent: 8544.0
train_total_correct_sent: 5872.0
train_accuracy_sent: 0.6872659176029963
train_count_tok: 163566.0
train_total_correct_tok: 147390.0
train_accuracy_tok: 0.9011041414474891
train_label=O_precision_sent: 0.48034934497816595
train_label=O_recall_sent: 0.06773399014778325
train_label=O_f-score_sent: 0.11872638963842418
train_label=N_precision_sent: 0.6557377049180327
train_label=N_recall_sent: 0.8459214501510574
train_label=N_f-score_sent: 0.7387862796833773
train_label=P_precision_sent: 0.7322620519159456
train_label=P_recall_sent: 0.8204986149584488
train_label=P_f-score_sent: 0.7738732854343566
train_precision_macro_sent: 0.6227830339373814
train_recall_macro_sent: 0.5780513517524298
train_f-score_macro_sent: 0.5437953182520526
train_precision_micro_sent: 0.6872659176029963
train_recall_micro_sent: 0.6872659176029963
train_f-score_micro_sent: 0.6872659176029963
train_label=O_precision_tok: 0.9118895565826478
train_label=O_recall_tok: 0.97262499296324
train_label=O_f-score_tok: 0.941278562978644
train_label=N_precision_tok: 0.8073742246726395
train_label=N_recall_tok: 0.6599070553443177
train_label=N_f-score_tok: 0.7262301433552886
train_label=P_precision_tok: 0.8833876558538983
train_label=P_recall_tok: 0.6825358756045888
train_label=P_f-score_tok: 0.7700807288143237
train_precision_macro_tok: 0.8675504790363952
train_recall_macro_tok: 0.7716893079707156
train_f-score_macro_tok: 0.8125298117160854
train_precision_micro_tok: 0.9011041414474891
train_recall_micro_tok: 0.9011041414474891
train_f-score_micro_tok: 0.9011041414474892
train_time: 145.4008915424347
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4803    0.0677    0.1187      1624
           N     0.6557    0.8459    0.7388      3310
           P     0.7323    0.8205    0.7739      3610

   micro avg     0.6873    0.6873    0.6873      8544
   macro avg     0.6228    0.5781    0.5438      8544
weighted avg     0.6547    0.6873    0.6358      8544

F1-macro sent:  0.5437953182520526
F1-micro sent:  0.6872659176029963
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9726    0.9413    124347
           N     0.8074    0.6599    0.7262     14202
           P     0.8834    0.6825    0.7701     25017

   micro avg     0.9011    0.9011    0.9011    163566
   macro avg     0.8676    0.7717    0.8125    163566
weighted avg     0.8985    0.9011    0.8964    163566

F1-macro tok:  0.8125298117160854
F1-micro tok:  0.9011041414474892
**************************************************
dev_cost_sum: 42395.73388671875
dev_cost_avg: 38.50657028766462
dev_count_sent: 1101.0
dev_total_correct_sent: 735.0
dev_accuracy_sent: 0.667574931880109
dev_count_tok: 21274.0
dev_total_correct_tok: 19139.0
dev_accuracy_tok: 0.8996427564162828
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11067193675889327
dev_label=N_precision_sent: 0.6679462571976967
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7334035827186512
dev_label=P_precision_sent: 0.670863309352518
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.746
dev_precision_macro_sent: 0.6407142999611827
dev_recall_macro_sent: 0.5714365244728873
dev_f-score_macro_sent: 0.5300251731591815
dev_precision_micro_sent: 0.667574931880109
dev_recall_micro_sent: 0.667574931880109
dev_f-score_micro_sent: 0.667574931880109
dev_label=O_precision_tok: 0.9070141200780623
dev_label=O_recall_tok: 0.9751311323665536
dev_label=O_f-score_tok: 0.9398400095161626
dev_label=N_precision_tok: 0.7860998650472335
dev_label=N_recall_tok: 0.6273559504577275
dev_label=N_f-score_tok: 0.6978137166816413
dev_label=P_precision_tok: 0.9164556962025316
dev_label=P_recall_tok: 0.676214196762142
dev_label=P_f-score_tok: 0.7782156932998926
dev_precision_macro_tok: 0.8698565604426092
dev_recall_macro_tok: 0.7595670931954744
dev_f-score_macro_tok: 0.8052898064992321
dev_precision_micro_tok: 0.8996427564162828
dev_recall_micro_tok: 0.8996427564162828
dev_f-score_micro_tok: 0.8996427564162828
dev_time: 8.460856676101685
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0611    0.1107       229
           N     0.6679    0.8131    0.7334       428
           P     0.6709    0.8401    0.7460       444

   micro avg     0.6676    0.6676    0.6676      1101
   macro avg     0.6407    0.5714    0.5300      1101
weighted avg     0.6515    0.6676    0.6090      1101

F1-macro sent:  0.5300251731591815
F1-micro sent:  0.667574931880109
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9070    0.9751    0.9398     16205
           N     0.7861    0.6274    0.6978      1857
           P     0.9165    0.6762    0.7782      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8699    0.7596    0.8053     21274
weighted avg     0.8979    0.8996    0.8943     21274

F1-macro tok:  0.8052898064992321
F1-micro tok:  0.8996427564162828
**************************************************
Best epoch: 21
**************************************************

test0_cost_sum: 42854.51953125
test0_cost_avg: 38.92326932901907
test0_count_sent: 1101.0
test0_total_correct_sent: 736.0
test0_accuracy_sent: 0.6684831970935513
test0_count_tok: 21274.0
test0_total_correct_tok: 19085.0
test0_accuracy_tok: 0.8971044467425026
test0_label=O_precision_sent: 0.6538461538461539
test0_label=O_recall_sent: 0.07423580786026202
test0_label=O_f-score_sent: 0.13333333333333336
test0_label=N_precision_sent: 0.6705202312138728
test0_label=N_recall_sent: 0.8130841121495327
test0_label=N_f-score_sent: 0.7349524815205913
test0_label=P_precision_sent: 0.6672661870503597
test0_label=P_recall_sent: 0.8355855855855856
test0_label=P_f-score_sent: 0.7420000000000001
test0_precision_macro_sent: 0.6638775240367955
test0_recall_macro_sent: 0.5743018351984601
test0_f-score_macro_sent: 0.5367619382846417
test0_precision_micro_sent: 0.6684831970935513
test0_recall_micro_sent: 0.6684831970935513
test0_f-score_micro_sent: 0.6684831970935513
test0_label=O_precision_tok: 0.9008921975336706
test0_label=O_recall_tok: 0.9782783091638383
test0_label=O_f-score_tok: 0.9379918348026745
test0_label=N_precision_tok: 0.8126377663482733
test0_label=N_recall_tok: 0.5955842757135165
test0_label=N_f-score_tok: 0.6873834679925419
test0_label=P_precision_tok: 0.9179620034542314
test0_label=P_recall_tok: 0.661892901618929
test0_label=P_f-score_tok: 0.7691751085383501
test0_precision_macro_tok: 0.8771639891120584
test0_recall_macro_tok: 0.7452518288320945
test0_f-score_macro_tok: 0.7981834704445222
test0_precision_micro_tok: 0.8971044467425026
test0_recall_micro_tok: 0.8971044467425026
test0_f-score_micro_tok: 0.8971044467425026
test0_time: 8.335767269134521
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6538    0.0742    0.1333       229
           N     0.6705    0.8131    0.7350       428
           P     0.6673    0.8356    0.7420       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6639    0.5743    0.5368      1101
weighted avg     0.6657    0.6685    0.6127      1101

F1-macro sent:  0.5367619382846417
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9783    0.9380     16205
           N     0.8126    0.5956    0.6874      1857
           P     0.9180    0.6619    0.7692      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8772    0.7453    0.7982     21274
weighted avg     0.8958    0.8971    0.8906     21274

F1-macro tok:  0.7981834704445222
F1-micro tok:  0.8971044467425026
**************************************************
test1_cost_sum: 82982.78845214844
test1_cost_avg: 37.548773055270786
test1_count_sent: 2210.0
test1_total_correct_sent: 1537.0
test1_accuracy_sent: 0.6954751131221719
test1_count_tok: 42405.0
test1_total_correct_tok: 37747.0
test1_accuracy_tok: 0.8901544629171089
test1_label=O_precision_sent: 0.4305555555555556
test1_label=O_recall_sent: 0.07969151670951156
test1_label=O_f-score_sent: 0.13449023861171364
test1_label=N_precision_sent: 0.7127344521224087
test1_label=N_recall_sent: 0.7916666666666666
test1_label=N_f-score_sent: 0.7501298701298701
test1_label=P_precision_sent: 0.6968888888888889
test1_label=P_recall_sent: 0.8624862486248625
test1_label=P_f-score_sent: 0.7708947885939037
test1_precision_macro_sent: 0.6133929655222844
test1_recall_macro_sent: 0.5779481440003469
test1_f-score_macro_sent: 0.5518382991118291
test1_precision_micro_sent: 0.6954751131221719
test1_recall_micro_sent: 0.6954751131221719
test1_f-score_micro_sent: 0.6954751131221719
test1_label=O_precision_tok: 0.8923133839892996
test1_label=O_recall_tok: 0.9799049940621288
test1_label=O_f-score_tok: 0.9340602052519474
test1_label=N_precision_tok: 0.8118811881188119
test1_label=N_recall_tok: 0.5888297872340426
test1_label=N_f-score_tok: 0.6825959611530754
test1_label=P_precision_tok: 0.9204670632297863
test1_label=P_recall_tok: 0.62855423499323
test1_label=P_f-score_tok: 0.7470051850527446
test1_precision_macro_tok: 0.8748872117792993
test1_recall_macro_tok: 0.7324296720964671
test1_f-score_macro_tok: 0.7878871171525891
test1_precision_micro_tok: 0.8901544629171089
test1_recall_micro_tok: 0.8901544629171089
test1_f-score_micro_tok: 0.8901544629171089
test1_time: 17.018963098526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4306    0.0797    0.1345       389
           N     0.7127    0.7917    0.7501       912
           P     0.6969    0.8625    0.7709       909

   micro avg     0.6955    0.6955    0.6955      2210
   macro avg     0.6134    0.5779    0.5518      2210
weighted avg     0.6565    0.6955    0.6503      2210

F1-macro sent:  0.5518382991118291
F1-micro sent:  0.6954751131221719
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8923    0.9799    0.9341     31998
           N     0.8119    0.5888    0.6826      3760
           P     0.9205    0.6286    0.7470      6647

   micro avg     0.8902    0.8902    0.8902     42405
   macro avg     0.8749    0.7324    0.7879     42405
weighted avg     0.8896    0.8902    0.8824     42405

F1-macro tok:  0.7878871171525891
F1-micro tok:  0.8901544629171089
**************************************************
