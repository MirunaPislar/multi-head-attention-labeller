to_write_filename: runs/transformer_sentiment_sent+word+LM_loss_reduce_max_token_scores.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 423090.4307861328
train_cost_avg: 49.51901109388258
train_count_sent: 8544.0
train_total_correct_sent: 3556.0
train_accuracy_sent: 0.41619850187265917
train_count_tok: 163566.0
train_total_correct_tok: 126004.0
train_accuracy_tok: 0.770355697394324
train_label=O_precision_sent: 0.19402985074626866
train_label=O_recall_sent: 0.008004926108374385
train_label=O_f-score_sent: 0.01537551744529864
train_label=N_precision_sent: 0.399055817828381
train_label=N_recall_sent: 0.4341389728096677
train_label=N_f-score_sent: 0.4158587758645637
train_label=P_precision_sent: 0.43191140278917145
train_label=P_recall_sent: 0.5833795013850416
train_label=P_f-score_sent: 0.49634692434598154
train_precision_macro_sent: 0.3416656904546071
train_recall_macro_sent: 0.34184113343436123
train_f-score_macro_sent: 0.30919373921861465
train_precision_micro_sent: 0.41619850187265917
train_recall_micro_sent: 0.41619850187265917
train_f-score_micro_sent: 0.41619850187265917
train_label=O_precision_tok: 0.7852451682756206
train_label=O_recall_tok: 0.974024302958656
train_label=O_f-score_tok: 0.8695062242451219
train_label=N_precision_tok: 0.501708605156881
train_label=N_recall_tok: 0.11371637797493311
train_label=N_f-score_tok: 0.18540841513116352
train_label=P_precision_tok: 0.5358663609564362
train_label=P_recall_tok: 0.1307910620777871
train_label=P_f-score_tok: 0.21026250682774794
train_precision_macro_tok: 0.6076067114629793
train_recall_macro_tok: 0.40617724767045876
train_f-score_macro_tok: 0.42172571540134446
train_precision_micro_tok: 0.770355697394324
train_recall_micro_tok: 0.770355697394324
train_f-score_micro_tok: 0.770355697394324
train_time: 144.88739323616028
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1940    0.0080    0.0154      1624
           N     0.3991    0.4341    0.4159      3310
           P     0.4319    0.5834    0.4963      3610

   micro avg     0.4162    0.4162    0.4162      8544
   macro avg     0.3417    0.3418    0.3092      8544
weighted avg     0.3740    0.4162    0.3737      8544

F1-macro sent:  0.30919373921861465
F1-micro sent:  0.41619850187265917
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7852    0.9740    0.8695    124347
           N     0.5017    0.1137    0.1854     14202
           P     0.5359    0.1308    0.2103     25017

   micro avg     0.7704    0.7704    0.7704    163566
   macro avg     0.6076    0.4062    0.4217    163566
weighted avg     0.7225    0.7704    0.7093    163566

F1-macro tok:  0.42172571540134446
F1-micro tok:  0.770355697394324
**************************************************
dev_cost_sum: 50411.013671875
dev_cost_avg: 45.786570092529516
dev_count_sent: 1101.0
dev_total_correct_sent: 466.0
dev_accuracy_sent: 0.4232515894641235
dev_count_tok: 21274.0
dev_total_correct_tok: 17521.0
dev_accuracy_tok: 0.823587477672276
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.675
dev_label=N_recall_sent: 0.0630841121495327
dev_label=N_f-score_sent: 0.11538461538461538
dev_label=P_precision_sent: 0.413760603204524
dev_label=P_recall_sent: 0.9887387387387387
dev_label=P_f-score_sent: 0.5833887043189369
dev_precision_macro_sent: 0.3629202010681747
dev_recall_macro_sent: 0.35060761696275716
dev_f-score_macro_sent: 0.23292443990118408
dev_precision_micro_sent: 0.4232515894641235
dev_recall_micro_sent: 0.4232515894641235
dev_f-score_micro_sent: 0.4232515894641235
dev_label=O_precision_tok: 0.8403265924083486
dev_label=O_recall_tok: 0.9590249922863314
dev_label=O_f-score_tok: 0.8957606847459582
dev_label=N_precision_tok: 0.6735218508997429
dev_label=N_recall_tok: 0.42326332794830374
dev_label=N_f-score_tok: 0.5198412698412698
dev_label=P_precision_tok: 0.7402355858648481
dev_label=P_recall_tok: 0.3717310087173101
dev_label=P_f-score_tok: 0.49492227979274606
dev_precision_macro_tok: 0.7513613430576465
dev_recall_macro_tok: 0.5846731096506484
dev_f-score_macro_tok: 0.6368414114599914
dev_precision_micro_tok: 0.823587477672276
dev_recall_micro_tok: 0.823587477672276
dev_f-score_micro_tok: 0.823587477672276
dev_time: 8.64147400856018
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6750    0.0631    0.1154       428
           P     0.4138    0.9887    0.5834       444

   micro avg     0.4233    0.4233    0.4233      1101
   macro avg     0.3629    0.3506    0.2329      1101
weighted avg     0.4293    0.4233    0.2801      1101

F1-macro sent:  0.23292443990118408
F1-micro sent:  0.4232515894641235
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8403    0.9590    0.8958     16205
           N     0.6735    0.4233    0.5198      1857
           P     0.7402    0.3717    0.4949      3212

   micro avg     0.8236    0.8236    0.8236     21274
   macro avg     0.7514    0.5847    0.6368     21274
weighted avg     0.8107    0.8236    0.8024     21274

F1-macro tok:  0.6368414114599914
F1-micro tok:  0.823587477672276
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 374863.53356933594
train_cost_avg: 43.87447724360205
train_count_sent: 8544.0
train_total_correct_sent: 4456.0
train_accuracy_sent: 0.5215355805243446
train_count_tok: 163566.0
train_total_correct_tok: 134400.0
train_accuracy_tok: 0.8216866585965299
train_label=O_precision_sent: 0.34375
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013285024154589374
train_label=N_precision_sent: 0.5106267029972752
train_label=N_recall_sent: 0.5661631419939577
train_label=N_f-score_sent: 0.5369627507163324
train_label=P_precision_sent: 0.5309789343246593
train_label=P_recall_sent: 0.7121883656509695
train_label=P_f-score_sent: 0.6083767155702792
train_precision_macro_sent: 0.4617852124406448
train_recall_macro_sent: 0.42837496888656856
train_f-score_macro_sent: 0.38620816348040027
train_precision_micro_sent: 0.5215355805243446
train_recall_micro_sent: 0.5215355805243446
train_f-score_micro_sent: 0.5215355805243446
train_label=O_precision_tok: 0.8428325802142836
train_label=O_recall_tok: 0.9539996944035642
train_label=O_f-score_tok: 0.89497727229861
train_label=N_precision_tok: 0.6542833087770995
train_label=N_recall_tok: 0.4377552457400366
train_label=N_f-score_tok: 0.5245528180897738
train_label=P_precision_tok: 0.7176329227996395
train_label=P_recall_tok: 0.38198025342766917
train_label=P_f-score_tok: 0.4985782485065087
train_precision_macro_tok: 0.7382496039303409
train_recall_macro_tok: 0.5912450645237567
train_f-score_macro_tok: 0.6393694462982975
train_precision_micro_tok: 0.8216866585965299
train_recall_micro_tok: 0.8216866585965299
train_f-score_micro_tok: 0.8216866585965299
train_time: 142.97058844566345
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3438    0.0068    0.0133      1624
           N     0.5106    0.5662    0.5370      3310
           P     0.5310    0.7122    0.6084      3610

   micro avg     0.5215    0.5215    0.5215      8544
   macro avg     0.4618    0.4284    0.3862      8544
weighted avg     0.4875    0.5215    0.4676      8544

F1-macro sent:  0.38620816348040027
F1-micro sent:  0.5215355805243446
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8428    0.9540    0.8950    124347
           N     0.6543    0.4378    0.5246     14202
           P     0.7176    0.3820    0.4986     25017

   micro avg     0.8217    0.8217    0.8217    163566
   macro avg     0.7382    0.5912    0.6394    163566
weighted avg     0.8073    0.8217    0.8022    163566

F1-macro tok:  0.6393694462982975
F1-micro tok:  0.8216866585965299
**************************************************
dev_cost_sum: 48766.597412109375
dev_cost_avg: 44.29300400736546
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 17903.0
dev_accuracy_tok: 0.8415436683275359
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.5609022556390978
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.6825251601097896
dev_label=P_precision_sent: 0.6889400921658986
dev_label=P_recall_sent: 0.6734234234234234
dev_label=P_f-score_sent: 0.6810933940774486
dev_precision_macro_sent: 0.5832807826016655
dev_recall_macro_sent: 0.5164285209177671
dev_f-score_macro_sent: 0.45742552094841565
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.8487104780403583
dev_label=O_recall_tok: 0.970688059240975
dev_label=O_f-score_tok: 0.9056104090503468
dev_label=N_precision_tok: 0.710691823899371
dev_label=N_recall_tok: 0.4868066774367259
dev_label=N_f-score_tok: 0.5778203899009268
dev_label=P_precision_tok: 0.864441416893733
dev_label=P_recall_tok: 0.3950809464508095
dev_label=P_f-score_tok: 0.5423076923076923
dev_precision_macro_tok: 0.8079479062778208
dev_recall_macro_tok: 0.6175252277095035
dev_f-score_macro_tok: 0.6752461637529886
dev_precision_micro_tok: 0.8415436683275359
dev_recall_micro_tok: 0.8415436683275359
dev_f-score_micro_tok: 0.841543668327536
dev_time: 8.27470588684082
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.5609    0.8715    0.6825       428
           P     0.6889    0.6734    0.6811       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.5833    0.5164    0.4574      1101
weighted avg     0.5999    0.6113    0.5418      1101

F1-macro sent:  0.45742552094841565
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8487    0.9707    0.9056     16205
           N     0.7107    0.4868    0.5778      1857
           P     0.8644    0.3951    0.5423      3212

   micro avg     0.8415    0.8415    0.8415     21274
   macro avg     0.8079    0.6175    0.6752     21274
weighted avg     0.8390    0.8415    0.8221     21274

F1-macro tok:  0.6752461637529886
F1-micro tok:  0.841543668327536
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 363259.3251953125
train_cost_avg: 42.51630678784088
train_count_sent: 8544.0
train_total_correct_sent: 4920.0
train_accuracy_sent: 0.5758426966292135
train_count_tok: 163566.0
train_total_correct_tok: 138125.0
train_accuracy_tok: 0.8444603401684947
train_label=O_precision_sent: 0.48148148148148145
train_label=O_recall_sent: 0.02401477832512315
train_label=O_f-score_sent: 0.04574780058651026
train_label=N_precision_sent: 0.536353591160221
train_label=N_recall_sent: 0.7332326283987916
train_label=N_f-score_sent: 0.6195277600510529
train_label=P_precision_sent: 0.6231589639410868
train_label=P_recall_sent: 0.6797783933518006
train_label=P_f-score_sent: 0.6502384737678856
train_precision_macro_sent: 0.5469980121942631
train_recall_macro_sent: 0.47900860002523843
train_f-score_macro_sent: 0.4385046781351496
train_precision_micro_sent: 0.5758426966292135
train_recall_micro_sent: 0.5758426966292135
train_f-score_micro_sent: 0.5758426966292135
train_label=O_precision_tok: 0.8616821349061786
train_label=O_recall_tok: 0.9587042711122906
train_label=O_f-score_tok: 0.9076076819124841
train_label=N_precision_tok: 0.689905299214185
train_label=N_recall_tok: 0.48218560766089286
train_label=N_f-score_tok: 0.5676392572944298
train_label=P_precision_tok: 0.7889746272560816
train_label=P_recall_tok: 0.48227205500259823
train_label=P_f-score_tok: 0.5986256171078419
train_precision_macro_tok: 0.7801873537921485
train_recall_macro_tok: 0.6410539779252605
train_f-score_macro_tok: 0.6912908521049186
train_precision_micro_tok: 0.8444603401684947
train_recall_micro_tok: 0.8444603401684947
train_f-score_micro_tok: 0.8444603401684947
train_time: 142.43446826934814
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4815    0.0240    0.0457      1624
           N     0.5364    0.7332    0.6195      3310
           P     0.6232    0.6798    0.6502      3610

   micro avg     0.5758    0.5758    0.5758      8544
   macro avg     0.5470    0.4790    0.4385      8544
weighted avg     0.5626    0.5758    0.5234      8544

F1-macro sent:  0.4385046781351496
F1-micro sent:  0.5758426966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8617    0.9587    0.9076    124347
           N     0.6899    0.4822    0.5676     14202
           P     0.7890    0.4823    0.5986     25017

   micro avg     0.8445    0.8445    0.8445    163566
   macro avg     0.7802    0.6411    0.6913    163566
weighted avg     0.8356    0.8445    0.8308    163566

F1-macro tok:  0.6912908521049186
F1-micro tok:  0.8444603401684947
**************************************************
dev_cost_sum: 47514.72540283203
dev_cost_avg: 43.1559722096567
dev_count_sent: 1101.0
dev_total_correct_sent: 677.0
dev_accuracy_sent: 0.6148955495004541
dev_count_tok: 21274.0
dev_total_correct_tok: 18446.0
dev_accuracy_tok: 0.8670677822694369
dev_label=O_precision_sent: 0.3064516129032258
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.13058419243986255
dev_label=N_precision_sent: 0.6
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.6827794561933535
dev_label=P_precision_sent: 0.6729957805907173
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.6949891067538126
dev_precision_macro_sent: 0.5264824644979811
dev_recall_macro_sent: 0.5311646585164113
dev_f-score_macro_sent: 0.5027842517956762
dev_precision_micro_sent: 0.6148955495004541
dev_recall_micro_sent: 0.6148955495004541
dev_f-score_micro_sent: 0.6148955495004541
dev_label=O_precision_tok: 0.8791746317328236
dev_label=O_recall_tok: 0.9649490897871027
dev_label=O_f-score_tok: 0.9200670765790945
dev_label=N_precision_tok: 0.7208083832335329
dev_label=N_recall_tok: 0.518578352180937
dev_label=N_f-score_tok: 0.603194487942374
dev_label=P_precision_tok: 0.8578066914498141
dev_label=P_recall_tok: 0.574719800747198
dev_label=P_f-score_tok: 0.6882923191648023
dev_precision_macro_tok: 0.8192632354720569
dev_recall_macro_tok: 0.6860824142384124
dev_f-score_macro_tok: 0.7371846278954236
dev_precision_micro_tok: 0.8670677822694369
dev_recall_micro_tok: 0.8670677822694369
dev_f-score_micro_tok: 0.8670677822694369
dev_time: 8.234776020050049
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3065    0.0830    0.1306       229
           N     0.6000    0.7921    0.6828       428
           P     0.6730    0.7185    0.6950       444

   micro avg     0.6149    0.6149    0.6149      1101
   macro avg     0.5265    0.5312    0.5028      1101
weighted avg     0.5684    0.6149    0.5729      1101

F1-macro sent:  0.5027842517956762
F1-micro sent:  0.6148955495004541
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8792    0.9649    0.9201     16205
           N     0.7208    0.5186    0.6032      1857
           P     0.8578    0.5747    0.6883      3212

   micro avg     0.8671    0.8671    0.8671     21274
   macro avg     0.8193    0.6861    0.7372     21274
weighted avg     0.8621    0.8671    0.8574     21274

F1-macro tok:  0.7371846278954236
F1-micro tok:  0.8670677822694369
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 355534.6094970703
train_cost_avg: 41.612196804432386
train_count_sent: 8544.0
train_total_correct_sent: 5087.0
train_accuracy_sent: 0.5953885767790262
train_count_tok: 163566.0
train_total_correct_tok: 140242.0
train_accuracy_tok: 0.8574031277893939
train_label=O_precision_sent: 0.376
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.053744997141223556
train_label=N_precision_sent: 0.5678248453117563
train_label=N_recall_sent: 0.720845921450151
train_label=N_f-score_sent: 0.6352502662406816
train_label=P_precision_sent: 0.629357363054304
train_label=P_recall_sent: 0.7351800554016621
train_label=P_f-score_sent: 0.6781653251565095
train_precision_macro_sent: 0.5243940694553534
train_recall_macro_sent: 0.49498895451710684
train_f-score_macro_sent: 0.4557201961794715
train_precision_micro_sent: 0.5953885767790262
train_recall_micro_sent: 0.5953885767790262
train_f-score_micro_sent: 0.5953885767790262
train_label=O_precision_tok: 0.870804393943797
train_label=O_recall_tok: 0.9639235365549631
train_label=O_f-score_tok: 0.9150008969773771
train_label=N_precision_tok: 0.7181939730535842
train_label=N_recall_tok: 0.49169131108294606
train_label=N_f-score_tok: 0.5837408568443051
train_label=P_precision_tok: 0.8270880918575221
train_label=P_recall_tok: 0.5355558220410122
train_label=P_f-score_tok: 0.6501358695652174
train_precision_macro_tok: 0.8053621529516345
train_recall_macro_tok: 0.6637235565596404
train_f-score_macro_tok: 0.7162925411289666
train_precision_micro_tok: 0.8574031277893939
train_recall_micro_tok: 0.8574031277893939
train_f-score_micro_tok: 0.8574031277893939
train_time: 121.58810377120972
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3760    0.0289    0.0537      1624
           N     0.5678    0.7208    0.6353      3310
           P     0.6294    0.7352    0.6782      3610

   micro avg     0.5954    0.5954    0.5954      8544
   macro avg     0.5244    0.4950    0.4557      8544
weighted avg     0.5574    0.5954    0.5429      8544

F1-macro sent:  0.4557201961794715
F1-micro sent:  0.5953885767790262
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8708    0.9639    0.9150    124347
           N     0.7182    0.4917    0.5837     14202
           P     0.8271    0.5356    0.6501     25017

   micro avg     0.8574    0.8574    0.8574    163566
   macro avg     0.8054    0.6637    0.7163    163566
weighted avg     0.8509    0.8574    0.8457    163566

F1-macro tok:  0.7162925411289666
F1-micro tok:  0.8574031277893939
**************************************************
dev_cost_sum: 46798.68542480469
dev_cost_avg: 42.50561800618046
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 18577.0
dev_accuracy_tok: 0.8732255335150888
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0423728813559322
dev_label=N_precision_sent: 0.6498855835240275
dev_label=N_recall_sent: 0.6635514018691588
dev_label=N_f-score_sent: 0.6566473988439306
dev_label=P_precision_sent: 0.5844748858447488
dev_label=P_recall_sent: 0.8648648648648649
dev_label=P_f-score_sent: 0.6975476839237057
dev_precision_macro_sent: 0.6495487278848302
dev_recall_macro_sent: 0.5167501092897983
dev_f-score_macro_sent: 0.4655226547078562
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.8843614199446921
dev_label=O_recall_tok: 0.9669854983029929
dev_label=O_f-score_tok: 0.9238297370593089
dev_label=N_precision_tok: 0.76
dev_label=N_recall_tok: 0.5115778136779753
dev_label=N_f-score_tok: 0.6115223688445446
dev_label=P_precision_tok: 0.8490238611713666
dev_label=P_recall_tok: 0.6092777085927771
dev_label=P_f-score_tok: 0.7094435381547942
dev_precision_macro_tok: 0.8311284270386863
dev_recall_macro_tok: 0.695947006857915
dev_f-score_macro_tok: 0.7482652146862159
dev_precision_micro_tok: 0.8732255335150888
dev_recall_micro_tok: 0.8732255335150888
dev_f-score_micro_tok: 0.8732255335150888
dev_time: 5.041754722595215
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0218    0.0424       229
           N     0.6499    0.6636    0.6566       428
           P     0.5845    0.8649    0.6975       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.6495    0.5168    0.4655      1101
weighted avg     0.6369    0.6113    0.5454      1101

F1-macro sent:  0.4655226547078562
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8844    0.9670    0.9238     16205
           N     0.7600    0.5116    0.6115      1857
           P     0.8490    0.6093    0.7094      3212

   micro avg     0.8732    0.8732    0.8732     21274
   macro avg     0.8311    0.6959    0.7483     21274
weighted avg     0.8682    0.8732    0.8642     21274

F1-macro tok:  0.7482652146862159
F1-micro tok:  0.8732255335150888
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 349923.3347167969
train_cost_avg: 40.95544647902585
train_count_sent: 8544.0
train_total_correct_sent: 5212.0
train_accuracy_sent: 0.6100187265917603
train_count_tok: 163566.0
train_total_correct_tok: 141459.0
train_accuracy_tok: 0.8648435493929056
train_label=O_precision_sent: 0.49514563106796117
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05906195715112913
train_label=N_precision_sent: 0.5673946613721598
train_label=N_recall_sent: 0.7770392749244713
train_label=N_f-score_sent: 0.6558714777508607
train_label=P_precision_sent: 0.6624872057318322
train_label=P_recall_sent: 0.717174515235457
train_label=P_f-score_sent: 0.6887470071827614
train_precision_macro_sent: 0.5750091660573177
train_recall_macro_sent: 0.5085392436822093
train_f-score_macro_sent: 0.4678934806949171
train_precision_micro_sent: 0.6100187265917603
train_recall_micro_sent: 0.6100187265917603
train_f-score_micro_sent: 0.6100187265917603
train_label=O_precision_tok: 0.8766428305889042
train_label=O_recall_tok: 0.9671644671765302
train_label=O_f-score_tok: 0.9196815710385646
train_label=N_precision_tok: 0.7314562518922192
train_label=N_recall_tok: 0.5103506548373469
train_label=N_f-score_tok: 0.6012193604578824
train_label=P_precision_tok: 0.8468123861566484
train_label=P_recall_tok: 0.5575008993884158
train_label=P_f-score_tok: 0.672355195603442
train_precision_macro_tok: 0.8183038228792573
train_recall_macro_tok: 0.6783386738007643
train_f-score_macro_tok: 0.731085375699963
train_precision_micro_tok: 0.8648435493929056
train_recall_micro_tok: 0.8648435493929056
train_f-score_micro_tok: 0.8648435493929056
train_time: 94.73527383804321
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4951    0.0314    0.0591      1624
           N     0.5674    0.7770    0.6559      3310
           P     0.6625    0.7172    0.6887      3610

   micro avg     0.6100    0.6100    0.6100      8544
   macro avg     0.5750    0.5085    0.4679      8544
weighted avg     0.5938    0.6100    0.5563      8544

F1-macro sent:  0.4678934806949171
F1-micro sent:  0.6100187265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8766    0.9672    0.9197    124347
           N     0.7315    0.5104    0.6012     14202
           P     0.8468    0.5575    0.6724     25017

   micro avg     0.8648    0.8648    0.8648    163566
   macro avg     0.8183    0.6783    0.7311    163566
weighted avg     0.8595    0.8648    0.8542    163566

F1-macro tok:  0.731085375699963
F1-micro tok:  0.8648435493929056
**************************************************
dev_cost_sum: 46249.311279296875
dev_cost_avg: 42.006640580651116
dev_count_sent: 1101.0
dev_total_correct_sent: 680.0
dev_accuracy_sent: 0.6176203451407811
dev_count_tok: 21274.0
dev_total_correct_tok: 18703.0
dev_accuracy_tok: 0.8791482560872427
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5468531468531469
dev_label=N_recall_sent: 0.9135514018691588
dev_label=N_f-score_sent: 0.68416447944007
dev_label=P_precision_sent: 0.7493472584856397
dev_label=P_recall_sent: 0.6463963963963963
dev_label=P_f-score_sent: 0.6940749697702538
dev_precision_macro_sent: 0.6542890240018178
dev_recall_macro_sent: 0.5228938075732346
dev_f-score_macro_sent: 0.4651602761735562
dev_precision_micro_sent: 0.6176203451407811
dev_recall_micro_sent: 0.6176203451407811
dev_f-score_micro_sent: 0.6176203451407811
dev_label=O_precision_tok: 0.8854850474106492
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.9275890443164453
dev_label=N_precision_tok: 0.7678431372549019
dev_label=N_recall_tok: 0.5271943995691977
dev_label=N_f-score_tok: 0.6251596424010217
dev_label=P_precision_tok: 0.8924632352941176
dev_label=P_recall_tok: 0.6046077210460772
dev_label=P_f-score_tok: 0.7208611729769858
dev_precision_macro_tok: 0.8485971399865563
dev_recall_macro_tok: 0.7018996886675003
dev_f-score_macro_tok: 0.7578699532314843
dev_precision_micro_tok: 0.8791482560872427
dev_recall_micro_tok: 0.8791482560872427
dev_f-score_micro_tok: 0.8791482560872427
dev_time: 5.002660512924194
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5469    0.9136    0.6842       428
           P     0.7493    0.6464    0.6941       444

   micro avg     0.6176    0.6176    0.6176      1101
   macro avg     0.6543    0.5229    0.4652      1101
weighted avg     0.6534    0.6176    0.5494      1101

F1-macro sent:  0.4651602761735562
F1-micro sent:  0.6176203451407811
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8855    0.9739    0.9276     16205
           N     0.7678    0.5272    0.6252      1857
           P     0.8925    0.6046    0.7209      3212

   micro avg     0.8791    0.8791    0.8791     21274
   macro avg     0.8486    0.7019    0.7579     21274
weighted avg     0.8763    0.8791    0.8700     21274

F1-macro tok:  0.7578699532314843
F1-micro tok:  0.8791482560872427
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 345527.38525390625
train_cost_avg: 40.44093928533547
train_count_sent: 8544.0
train_total_correct_sent: 5204.0
train_accuracy_sent: 0.6090823970037453
train_count_tok: 163566.0
train_total_correct_tok: 142116.0
train_accuracy_tok: 0.8688602765855985
train_label=O_precision_sent: 0.39855072463768115
train_label=O_recall_sent: 0.033866995073891626
train_label=O_f-score_sent: 0.06242905788876277
train_label=N_precision_sent: 0.5861984881736162
train_label=N_recall_sent: 0.7262839879154078
train_label=N_f-score_sent: 0.6487653488058293
train_label=P_precision_sent: 0.6376306620209059
train_label=P_recall_sent: 0.760387811634349
train_label=P_f-score_sent: 0.6936197094125078
train_precision_macro_sent: 0.5407932916107344
train_recall_macro_sent: 0.5068462648745494
train_f-score_macro_sent: 0.46827137203569996
train_precision_micro_sent: 0.6090823970037453
train_recall_micro_sent: 0.6090823970037453
train_f-score_micro_sent: 0.6090823970037453
train_label=O_precision_tok: 0.8796172528395603
train_label=O_recall_tok: 0.9684511890113955
train_label=O_f-score_tok: 0.9218991624944497
train_label=N_precision_tok: 0.7465849738850944
train_label=N_recall_tok: 0.5233769891564568
train_label=N_f-score_tok: 0.6153655103899329
train_label=P_precision_tok: 0.8535767734211314
train_label=P_recall_tok: 0.5699724187552464
train_label=P_f-score_tok: 0.6835242797564833
train_precision_macro_tok: 0.8265930000485954
train_recall_macro_tok: 0.6872668656410329
train_f-score_macro_tok: 0.740262984213622
train_precision_micro_tok: 0.8688602765855985
train_recall_micro_tok: 0.8688602765855985
train_f-score_micro_tok: 0.8688602765855985
train_time: 93.9888904094696
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3986    0.0339    0.0624      1624
           N     0.5862    0.7263    0.6488      3310
           P     0.6376    0.7604    0.6936      3610

   micro avg     0.6091    0.6091    0.6091      8544
   macro avg     0.5408    0.5068    0.4683      8544
weighted avg     0.5723    0.6091    0.5563      8544

F1-macro sent:  0.46827137203569996
F1-micro sent:  0.6090823970037453
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8796    0.9685    0.9219    124347
           N     0.7466    0.5234    0.6154     14202
           P     0.8536    0.5700    0.6835     25017

   micro avg     0.8689    0.8689    0.8689    163566
   macro avg     0.8266    0.6873    0.7403    163566
weighted avg     0.8641    0.8689    0.8588    163566

F1-macro tok:  0.740262984213622
F1-micro tok:  0.8688602765855985
**************************************************
dev_cost_sum: 45729.730712890625
dev_cost_avg: 41.53472362660366
dev_count_sent: 1101.0
dev_total_correct_sent: 696.0
dev_accuracy_sent: 0.6321525885558583
dev_count_tok: 21274.0
dev_total_correct_tok: 18801.0
dev_accuracy_tok: 0.8837548180878068
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6162162162162163
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.6958290946083419
dev_label=P_precision_sent: 0.6477064220183486
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7138523761375126
dev_precision_macro_sent: 0.7546408794115216
dev_recall_macro_sent: 0.5328257592776223
dev_f-score_macro_sent: 0.47279237430658916
dev_precision_micro_sent: 0.6321525885558583
dev_recall_micro_sent: 0.6321525885558583
dev_f-score_micro_sent: 0.6321525885558583
dev_label=O_precision_tok: 0.884739536954586
dev_label=O_recall_tok: 0.9809935205183585
dev_label=O_f-score_tok: 0.9303836362040206
dev_label=N_precision_tok: 0.8092436974789916
dev_label=N_recall_tok: 0.518578352180937
dev_label=N_f-score_tok: 0.6320971447325238
dev_label=P_precision_tok: 0.917296786389414
dev_label=P_recall_tok: 0.6042963885429639
dev_label=P_f-score_tok: 0.7286036036036035
dev_precision_macro_tok: 0.8704266736076639
dev_recall_macro_tok: 0.7012894204140864
dev_f-score_macro_tok: 0.763694794846716
dev_precision_micro_tok: 0.8837548180878068
dev_recall_micro_tok: 0.8837548180878068
dev_f-score_micro_tok: 0.8837548180878068
dev_time: 5.064060211181641
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6162    0.7991    0.6958       428
           P     0.6477    0.7950    0.7139       444

   micro avg     0.6322    0.6322    0.6322      1101
   macro avg     0.7546    0.5328    0.4728      1101
weighted avg     0.7087    0.6322    0.5602      1101

F1-macro sent:  0.47279237430658916
F1-micro sent:  0.6321525885558583
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9810    0.9304     16205
           N     0.8092    0.5186    0.6321      1857
           P     0.9173    0.6043    0.7286      3212

   micro avg     0.8838    0.8838    0.8838     21274
   macro avg     0.8704    0.7013    0.7637     21274
weighted avg     0.8831    0.8838    0.8739     21274

F1-macro tok:  0.763694794846716
F1-micro tok:  0.8837548180878068
**************************************************
Best epoch: 2
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 341597.9006347656
train_cost_avg: 39.981027696016575
train_count_sent: 8544.0
train_total_correct_sent: 5387.0
train_accuracy_sent: 0.630500936329588
train_count_tok: 163566.0
train_total_correct_tok: 142783.0
train_accuracy_tok: 0.8729381411784846
train_label=O_precision_sent: 0.4375
train_label=O_recall_sent: 0.017241379310344827
train_label=O_f-score_sent: 0.03317535545023697
train_label=N_precision_sent: 0.5873956960913482
train_label=N_recall_sent: 0.8081570996978852
train_label=N_f-score_sent: 0.6803153611393692
train_label=P_precision_sent: 0.6836474783494652
train_label=P_recall_sent: 0.7434903047091412
train_label=P_f-score_sent: 0.7123142250530784
train_precision_macro_sent: 0.5695143914802712
train_recall_macro_sent: 0.5229629279057905
train_f-score_macro_sent: 0.47526831388089485
train_precision_micro_sent: 0.630500936329588
train_recall_micro_sent: 0.630500936329588
train_f-score_micro_sent: 0.630500936329588
train_label=O_precision_tok: 0.882485883970627
train_label=O_recall_tok: 0.9703249776834182
train_label=O_f-score_tok: 0.9243232683829303
train_label=N_precision_tok: 0.757068896853843
train_label=N_recall_tok: 0.5354175468243909
train_label=N_f-score_tok: 0.6272374824713355
train_label=P_precision_tok: 0.8645076794856531
train_label=P_recall_tok: 0.5804852700163888
train_label=P_f-score_tok: 0.6945832835107019
train_precision_macro_tok: 0.834687486770041
train_recall_macro_tok: 0.6954092648413993
train_f-score_macro_tok: 0.7487146781216558
train_precision_micro_tok: 0.8729381411784846
train_recall_micro_tok: 0.8729381411784846
train_f-score_micro_tok: 0.8729381411784846
train_time: 83.91947197914124
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4375    0.0172    0.0332      1624
           N     0.5874    0.8082    0.6803      3310
           P     0.6836    0.7435    0.7123      3610

   micro avg     0.6305    0.6305    0.6305      8544
   macro avg     0.5695    0.5230    0.4753      8544
weighted avg     0.5996    0.6305    0.5708      8544

F1-macro sent:  0.47526831388089485
F1-micro sent:  0.630500936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8825    0.9703    0.9243    124347
           N     0.7571    0.5354    0.6272     14202
           P     0.8645    0.5805    0.6946     25017

   micro avg     0.8729    0.8729    0.8729    163566
   macro avg     0.8347    0.6954    0.7487    163566
weighted avg     0.8688    0.8729    0.8634    163566

F1-macro tok:  0.7487146781216558
F1-micro tok:  0.8729381411784846
**************************************************
dev_cost_sum: 45410.52587890625
dev_cost_avg: 41.24480097993302
dev_count_sent: 1101.0
dev_total_correct_sent: 666.0
dev_accuracy_sent: 0.6049046321525886
dev_count_tok: 21274.0
dev_total_correct_tok: 18839.0
dev_accuracy_tok: 0.8855410360063928
dev_label=O_precision_sent: 0.8181818181818182
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.075
dev_label=N_precision_sent: 0.7032967032967034
dev_label=N_recall_sent: 0.5981308411214953
dev_label=N_f-score_sent: 0.6464646464646465
dev_label=P_precision_sent: 0.5523415977961432
dev_label=P_recall_sent: 0.9031531531531531
dev_label=P_f-score_sent: 0.6854700854700855
dev_precision_macro_sent: 0.6912733730915549
dev_recall_macro_sent: 0.5135284347727721
dev_f-score_macro_sent: 0.468978243978244
dev_precision_micro_sent: 0.6049046321525886
dev_recall_micro_sent: 0.6049046321525886
dev_f-score_micro_sent: 0.6049046321525886
dev_label=O_precision_tok: 0.8863306946147843
dev_label=O_recall_tok: 0.9811169392162913
dev_label=O_f-score_tok: 0.9313182790030168
dev_label=N_precision_tok: 0.8251996450754214
dev_label=N_recall_tok: 0.5008077544426495
dev_label=N_f-score_tok: 0.6233243967828419
dev_label=P_precision_tok: 0.9099139882299683
dev_label=P_recall_tok: 0.6257783312577833
dev_label=P_f-score_tok: 0.7415605976757056
dev_precision_macro_tok: 0.8738147759733913
dev_recall_macro_tok: 0.7025676749722414
dev_f-score_macro_tok: 0.7654010911538548
dev_precision_micro_tok: 0.8855410360063928
dev_recall_micro_tok: 0.8855410360063928
dev_f-score_micro_tok: 0.8855410360063928
dev_time: 2.3875386714935303
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8182    0.0393    0.0750       229
           N     0.7033    0.5981    0.6465       428
           P     0.5523    0.9032    0.6855       444

   micro avg     0.6049    0.6049    0.6049      1101
   macro avg     0.6913    0.5135    0.4690      1101
weighted avg     0.6663    0.6049    0.5433      1101

F1-macro sent:  0.468978243978244
F1-micro sent:  0.6049046321525886
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8863    0.9811    0.9313     16205
           N     0.8252    0.5008    0.6233      1857
           P     0.9099    0.6258    0.7416      3212

   micro avg     0.8855    0.8855    0.8855     21274
   macro avg     0.8738    0.7026    0.7654     21274
weighted avg     0.8846    0.8855    0.8758     21274

F1-macro tok:  0.7654010911538548
F1-micro tok:  0.8855410360063928
**************************************************
Best epoch: 2
**************************************************

EPOCH: 7
Learning rate: 0.900000
train_cost_sum: 337972.7854614258
train_cost_avg: 39.556739871421556
train_count_sent: 8544.0
train_total_correct_sent: 5402.0
train_accuracy_sent: 0.6322565543071161
train_count_tok: 163566.0
train_total_correct_tok: 143243.0
train_accuracy_tok: 0.8757504615873715
train_label=O_precision_sent: 0.5070422535211268
train_label=O_recall_sent: 0.04433497536945813
train_label=O_f-score_sent: 0.08154020385050961
train_label=N_precision_sent: 0.6033745247148289
train_label=N_recall_sent: 0.7670694864048339
train_label=N_f-score_sent: 0.6754455972333068
train_label=P_precision_sent: 0.6654744873628994
train_label=P_recall_sent: 0.7731301939058172
train_label=P_f-score_sent: 0.7152742183495643
train_precision_macro_sent: 0.5919637551996183
train_recall_macro_sent: 0.5281782185600363
train_f-score_macro_sent: 0.49075333981112684
train_precision_micro_sent: 0.6322565543071161
train_recall_micro_sent: 0.6322565543071161
train_f-score_micro_sent: 0.6322565543071161
train_label=O_precision_tok: 0.8854389014809761
train_label=O_recall_tok: 0.9707592463026852
train_label=O_f-score_tok: 0.926138194540349
train_label=N_precision_tok: 0.755926933540614
train_label=N_recall_tok: 0.5478101675820307
train_label=N_f-score_tok: 0.6352576141095777
train_label=P_precision_tok: 0.8705812924166421
train_label=P_recall_tok: 0.5896790182675781
train_label=P_f-score_tok: 0.7031123397359517
train_precision_macro_tok: 0.8373157091460773
train_recall_macro_tok: 0.702749477384098
train_f-score_macro_tok: 0.7548360494619595
train_precision_micro_tok: 0.8757504615873715
train_recall_micro_tok: 0.8757504615873715
train_f-score_micro_tok: 0.8757504615873715
train_time: 49.881736755371094
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5070    0.0443    0.0815      1624
           N     0.6034    0.7671    0.6754      3310
           P     0.6655    0.7731    0.7153      3610

   micro avg     0.6323    0.6323    0.6323      8544
   macro avg     0.5920    0.5282    0.4908      8544
weighted avg     0.6113    0.6323    0.5794      8544

F1-macro sent:  0.49075333981112684
F1-micro sent:  0.6322565543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8854    0.9708    0.9261    124347
           N     0.7559    0.5478    0.6353     14202
           P     0.8706    0.5897    0.7031     25017

   micro avg     0.8758    0.8758    0.8758    163566
   macro avg     0.8373    0.7027    0.7548    163566
weighted avg     0.8719    0.8758    0.8668    163566

F1-macro tok:  0.7548360494619595
F1-micro tok:  0.8757504615873715
**************************************************
dev_cost_sum: 44954.7626953125
dev_cost_avg: 40.830847134707085
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18891.0
dev_accuracy_tok: 0.8879853342107737
dev_label=O_precision_sent: 0.8333333333333334
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08298755186721991
dev_label=N_precision_sent: 0.6216216216216216
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7019328585961343
dev_label=P_precision_sent: 0.6591760299625468
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7198364008179958
dev_precision_macro_sent: 0.7047103283058339
dev_recall_macro_sent: 0.5475118938062251
dev_f-score_macro_sent: 0.50158560376045
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8897911183289466
dev_label=O_recall_tok: 0.9804998457266276
dev_label=O_f-score_tok: 0.93294580470906
dev_label=N_precision_tok: 0.7927300850734725
dev_label=N_recall_tok: 0.5519655358104469
dev_label=N_f-score_tok: 0.6507936507936507
dev_label=P_precision_tok: 0.9307909604519774
dev_label=P_recall_tok: 0.6155043586550436
dev_label=P_f-score_tok: 0.7410044977511244
dev_precision_macro_tok: 0.8711040546181322
dev_recall_macro_tok: 0.7159899133973727
dev_f-score_macro_tok: 0.7749146510846118
dev_precision_micro_tok: 0.8879853342107737
dev_recall_micro_tok: 0.8879853342107737
dev_f-score_micro_tok: 0.8879853342107739
dev_time: 2.4069161415100098
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8333    0.0437    0.0830       229
           N     0.6216    0.8061    0.7019       428
           P     0.6592    0.7928    0.7198       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7047    0.5475    0.5016      1101
weighted avg     0.6808    0.6421    0.5804      1101

F1-macro sent:  0.50158560376045
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8898    0.9805    0.9329     16205
           N     0.7927    0.5520    0.6508      1857
           P     0.9308    0.6155    0.7410      3212

   micro avg     0.8880    0.8880    0.8880     21274
   macro avg     0.8711    0.7160    0.7749     21274
weighted avg     0.8875    0.8880    0.8793     21274

F1-macro tok:  0.7749146510846118
F1-micro tok:  0.8879853342107739
**************************************************
Best epoch: 2
**************************************************

EPOCH: 8
Learning rate: 0.810000
train_cost_sum: 334890.04473876953
train_cost_avg: 39.19593220257134
train_count_sent: 8544.0
train_total_correct_sent: 5446.0
train_accuracy_sent: 0.6374063670411985
train_count_tok: 163566.0
train_total_correct_tok: 143753.0
train_accuracy_tok: 0.8788684689972244
train_label=O_precision_sent: 0.5161290322580645
train_label=O_recall_sent: 0.03940886699507389
train_label=O_f-score_sent: 0.07322654462242564
train_label=N_precision_sent: 0.6011467889908257
train_label=N_recall_sent: 0.7918429003021148
train_label=N_f-score_sent: 0.6834419817470666
train_label=P_precision_sent: 0.6800492610837439
train_label=P_recall_sent: 0.7648199445983379
train_label=P_f-score_sent: 0.7199478487614082
train_precision_macro_sent: 0.5991083607775447
train_recall_macro_sent: 0.5320239039651755
train_f-score_macro_sent: 0.49220545837696683
train_precision_micro_sent: 0.6374063670411985
train_recall_micro_sent: 0.6374063670411985
train_f-score_micro_sent: 0.6374063670411985
train_label=O_precision_tok: 0.8874696265627179
train_label=O_recall_tok: 0.9722148503783766
train_label=O_f-score_tok: 0.9279113321666512
train_label=N_precision_tok: 0.7698813921835505
train_label=N_recall_tok: 0.5575975214758485
train_label=N_f-score_tok: 0.646765762822607
train_label=P_precision_tok: 0.875901283779823
train_label=P_recall_tok: 0.59727385377943
train_label=P_f-score_tok: 0.7102386158380074
train_precision_macro_tok: 0.8444174341753637
train_recall_macro_tok: 0.709028741877885
train_f-score_macro_tok: 0.7616385702757551
train_precision_micro_tok: 0.8788684689972244
train_recall_micro_tok: 0.8788684689972244
train_f-score_micro_tok: 0.8788684689972244
train_time: 49.95755672454834
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5161    0.0394    0.0732      1624
           N     0.6011    0.7918    0.6834      3310
           P     0.6800    0.7648    0.7199      3610

   micro avg     0.6374    0.6374    0.6374      8544
   macro avg     0.5991    0.5320    0.4922      8544
weighted avg     0.6183    0.6374    0.5829      8544

F1-macro sent:  0.49220545837696683
F1-micro sent:  0.6374063670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8875    0.9722    0.9279    124347
           N     0.7699    0.5576    0.6468     14202
           P     0.8759    0.5973    0.7102     25017

   micro avg     0.8789    0.8789    0.8789    163566
   macro avg     0.8444    0.7090    0.7616    163566
weighted avg     0.8755    0.8789    0.8702    163566

F1-macro tok:  0.7616385702757551
F1-micro tok:  0.8788684689972244
**************************************************
dev_cost_sum: 44670.75909423828
dev_cost_avg: 40.57289654335902
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 18909.0
dev_accuracy_tok: 0.8888314374353671
dev_label=O_precision_sent: 0.7222222222222222
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.10526315789473685
dev_label=N_precision_sent: 0.6572008113590264
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.7035830618892508
dev_label=P_precision_sent: 0.6305084745762712
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7195357833655706
dev_precision_macro_sent: 0.6699771693858398
dev_recall_macro_sent: 0.5505385808613985
dev_f-score_macro_sent: 0.5094606677165193
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.8927505210386977
dev_label=O_recall_tok: 0.9780314717679729
dev_label=O_f-score_tok: 0.9334471994817127
dev_label=N_precision_tok: 0.7844444444444445
dev_label=N_recall_tok: 0.5702746365105008
dev_label=N_f-score_tok: 0.6604303086997194
dev_label=P_precision_tok: 0.9216950713956702
dev_label=P_recall_tok: 0.6229763387297634
dev_label=P_f-score_tok: 0.7434516069106446
dev_precision_macro_tok: 0.8662966789596042
dev_recall_macro_tok: 0.7237608156694124
dev_f-score_macro_tok: 0.7791097050306922
dev_precision_micro_tok: 0.8888314374353671
dev_recall_micro_tok: 0.8888314374353671
dev_f-score_micro_tok: 0.8888314374353671
dev_time: 2.4011571407318115
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7222    0.0568    0.1053       229
           N     0.6572    0.7570    0.7036       428
           P     0.6305    0.8378    0.7195       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.6700    0.5505    0.5095      1101
weighted avg     0.6600    0.6440    0.5856      1101

F1-macro sent:  0.5094606677165193
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8928    0.9780    0.9334     16205
           N     0.7844    0.5703    0.6604      1857
           P     0.9217    0.6230    0.7435      3212

   micro avg     0.8888    0.8888    0.8888     21274
   macro avg     0.8663    0.7238    0.7791     21274
weighted avg     0.8877    0.8888    0.8809     21274

F1-macro tok:  0.7791097050306922
F1-micro tok:  0.8888314374353671
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 0.810000
train_cost_sum: 332733.1784667969
train_cost_avg: 38.9434899890914
train_count_sent: 8544.0
train_total_correct_sent: 5472.0
train_accuracy_sent: 0.6404494382022472
train_count_tok: 163566.0
train_total_correct_tok: 143947.0
train_accuracy_tok: 0.8800545345609724
train_label=O_precision_sent: 0.4715909090909091
train_label=O_recall_sent: 0.05110837438423645
train_label=O_f-score_sent: 0.09222222222222222
train_label=N_precision_sent: 0.6012701292810161
train_label=N_recall_sent: 0.8009063444108762
train_label=N_f-score_sent: 0.6868765384117114
train_label=P_precision_sent: 0.6915887850467289
train_label=P_recall_sent: 0.7584487534626039
train_label=P_f-score_sent: 0.7234773417888757
train_precision_macro_sent: 0.5881499411395513
train_recall_macro_sent: 0.5368211574192389
train_f-score_macro_sent: 0.5008587008076031
train_precision_micro_sent: 0.6404494382022472
train_recall_micro_sent: 0.6404494382022472
train_f-score_micro_sent: 0.6404494382022472
train_label=O_precision_tok: 0.8888995123816809
train_label=O_recall_tok: 0.9719655480228715
train_label=O_f-score_tok: 0.9285785628126032
train_label=N_precision_tok: 0.7724197912640124
train_label=N_recall_tok: 0.5628080552034924
train_label=N_f-score_tok: 0.6511608961303462
train_label=P_precision_tok: 0.8749058025621703
train_label=P_recall_tok: 0.6033097493704281
train_label=P_f-score_tok: 0.7141572821046654
train_precision_macro_tok: 0.8454083687359546
train_recall_macro_tok: 0.7126944508655974
train_f-score_macro_tok: 0.7646322470158716
train_precision_micro_tok: 0.8800545345609724
train_recall_micro_tok: 0.8800545345609724
train_f-score_micro_tok: 0.8800545345609725
train_time: 49.87146592140198
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4716    0.0511    0.0922      1624
           N     0.6013    0.8009    0.6869      3310
           P     0.6916    0.7584    0.7235      3610

   micro avg     0.6404    0.6404    0.6404      8544
   macro avg     0.5881    0.5368    0.5009      8544
weighted avg     0.6148    0.6404    0.5893      8544

F1-macro sent:  0.5008587008076031
F1-micro sent:  0.6404494382022472
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8889    0.9720    0.9286    124347
           N     0.7724    0.5628    0.6512     14202
           P     0.8749    0.6033    0.7142     25017

   micro avg     0.8801    0.8801    0.8801    163566
   macro avg     0.8454    0.7127    0.7646    163566
weighted avg     0.8766    0.8801    0.8717    163566

F1-macro tok:  0.7646322470158716
F1-micro tok:  0.8800545345609725
**************************************************
dev_cost_sum: 44483.73388671875
dev_cost_avg: 40.4030280533322
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 18915.0
dev_accuracy_tok: 0.8891134718435649
dev_label=O_precision_sent: 0.2222222222222222
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.032388663967611336
dev_label=N_precision_sent: 0.6084656084656085
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.6934673366834171
dev_label=P_precision_sent: 0.6627906976744186
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.7124999999999999
dev_precision_macro_sent: 0.4978261761207497
dev_recall_macro_sent: 0.5312707618445692
dev_f-score_macro_sent: 0.47945200021700946
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8883684621389539
dev_label=O_recall_tok: 0.9831533477321814
dev_label=O_f-score_tok: 0.9333606725445971
dev_label=N_precision_tok: 0.8347676419965576
dev_label=N_recall_tok: 0.522347872913301
dev_label=N_f-score_tok: 0.6425968863862206
dev_label=P_precision_tok: 0.9242424242424242
dev_label=P_recall_tok: 0.6267123287671232
dev_label=P_f-score_tok: 0.7469387755102039
dev_precision_macro_tok: 0.882459509459312
dev_recall_macro_tok: 0.710737849804202
dev_f-score_macro_tok: 0.7742987781470072
dev_precision_micro_tok: 0.8891134718435649
dev_recall_micro_tok: 0.8891134718435649
dev_f-score_micro_tok: 0.8891134718435649
dev_time: 2.376178741455078
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2222    0.0175    0.0324       229
           N     0.6085    0.8061    0.6935       428
           P     0.6628    0.7703    0.7125       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.4978    0.5313    0.4795      1101
weighted avg     0.5500    0.6276    0.5636      1101

F1-macro sent:  0.47945200021700946
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8884    0.9832    0.9334     16205
           N     0.8348    0.5223    0.6426      1857
           P     0.9242    0.6267    0.7469      3212

   micro avg     0.8891    0.8891    0.8891     21274
   macro avg     0.8825    0.7107    0.7743     21274
weighted avg     0.8891    0.8891    0.8798     21274

F1-macro tok:  0.7742987781470072
F1-micro tok:  0.8891134718435649
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 0.810000
train_cost_sum: 330452.73126220703
train_cost_avg: 38.67658371514595
train_count_sent: 8544.0
train_total_correct_sent: 5527.0
train_accuracy_sent: 0.6468867041198502
train_count_tok: 163566.0
train_total_correct_tok: 144264.0
train_accuracy_tok: 0.8819925901470966
train_label=O_precision_sent: 0.40522875816993464
train_label=O_recall_sent: 0.038177339901477834
train_label=O_f-score_sent: 0.06978052898142939
train_label=N_precision_sent: 0.6148966165413534
train_label=N_recall_sent: 0.7906344410876133
train_label=N_f-score_sent: 0.6917790113666402
train_label=P_precision_sent: 0.6887545344619105
train_label=P_recall_sent: 0.7889196675900277
train_label=P_f-score_sent: 0.7354422207876048
train_precision_macro_sent: 0.5696266363910661
train_recall_macro_sent: 0.5392438161930396
train_f-score_macro_sent: 0.4990005870452248
train_precision_micro_sent: 0.6468867041198502
train_recall_micro_sent: 0.6468867041198502
train_f-score_micro_sent: 0.6468867041198502
train_label=O_precision_tok: 0.8904001707552238
train_label=O_recall_tok: 0.972890379341681
train_label=O_f-score_tok: 0.9298193025740352
train_label=N_precision_tok: 0.7766589950134254
train_label=N_recall_tok: 0.5702717927052527
train_label=N_f-score_tok: 0.6576532683719041
train_label=P_precision_tok: 0.8794511030050374
train_label=P_recall_tok: 0.6071471399448375
train_label=P_f-score_tok: 0.7183598183881953
train_precision_macro_tok: 0.8488367562578955
train_recall_macro_tok: 0.7167697706639237
train_f-score_macro_tok: 0.7686107964447116
train_precision_micro_tok: 0.8819925901470966
train_recall_micro_tok: 0.8819925901470966
train_f-score_micro_tok: 0.8819925901470966
train_time: 49.716731548309326
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4052    0.0382    0.0698      1624
           N     0.6149    0.7906    0.6918      3310
           P     0.6888    0.7889    0.7354      3610

   micro avg     0.6469    0.6469    0.6469      8544
   macro avg     0.5696    0.5392    0.4990      8544
weighted avg     0.6063    0.6469    0.5920      8544

F1-macro sent:  0.4990005870452248
F1-micro sent:  0.6468867041198502
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8904    0.9729    0.9298    124347
           N     0.7767    0.5703    0.6577     14202
           P     0.8795    0.6071    0.7184     25017

   micro avg     0.8820    0.8820    0.8820    163566
   macro avg     0.8488    0.7168    0.7686    163566
weighted avg     0.8788    0.8820    0.8738    163566

F1-macro tok:  0.7686107964447116
F1-micro tok:  0.8819925901470966
**************************************************
dev_cost_sum: 44154.34143066406
dev_cost_avg: 40.10385234392739
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 18947.0
dev_accuracy_tok: 0.8906176553539532
dev_label=O_precision_sent: 0.8888888888888888
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06722689075630252
dev_label=N_precision_sent: 0.6273764258555133
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.6918238993710693
dev_label=P_precision_sent: 0.6431095406360424
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7207920792079209
dev_precision_macro_sent: 0.7197916184601483
dev_recall_macro_sent: 0.541927451673197
dev_f-score_macro_sent: 0.49328095644509756
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8918418839360808
dev_label=O_recall_tok: 0.9815489046590559
dev_label=O_f-score_tok: 0.9345475910693303
dev_label=N_precision_tok: 0.8077519379844961
dev_label=N_recall_tok: 0.5611200861604739
dev_label=N_f-score_tok: 0.6622179853829043
dev_label=P_precision_tok: 0.9302000930665426
dev_label=P_recall_tok: 0.6223536737235368
dev_label=P_f-score_tok: 0.7457563887334453
dev_precision_macro_tok: 0.8765979716623731
dev_recall_macro_tok: 0.7216742215143556
dev_f-score_macro_tok: 0.7808406550618933
dev_precision_micro_tok: 0.8906176553539532
dev_recall_micro_tok: 0.8906176553539532
dev_f-score_micro_tok: 0.8906176553539532
dev_time: 2.393970251083374
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8889    0.0349    0.0672       229
           N     0.6274    0.7710    0.6918       428
           P     0.6431    0.8198    0.7208       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.7198    0.5419    0.4933      1101
weighted avg     0.6881    0.6376    0.5736      1101

F1-macro sent:  0.49328095644509756
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9815    0.9345     16205
           N     0.8078    0.5611    0.6622      1857
           P     0.9302    0.6224    0.7458      3212

   micro avg     0.8906    0.8906    0.8906     21274
   macro avg     0.8766    0.7217    0.7808     21274
weighted avg     0.8903    0.8906    0.8823     21274

F1-macro tok:  0.7808406550618933
F1-micro tok:  0.8906176553539532
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 0.810000
train_cost_sum: 328067.8337402344
train_cost_avg: 38.39745245087013
train_count_sent: 8544.0
train_total_correct_sent: 5549.0
train_accuracy_sent: 0.6494616104868914
train_count_tok: 163566.0
train_total_correct_tok: 144475.0
train_accuracy_tok: 0.883282589291173
train_label=O_precision_sent: 0.5555555555555556
train_label=O_recall_sent: 0.046182266009852216
train_label=O_f-score_sent: 0.08527572484366117
train_label=N_precision_sent: 0.5971594577146546
train_label=N_recall_sent: 0.8383685800604229
train_label=N_f-score_sent: 0.6974990574337061
train_label=P_precision_sent: 0.7174375332270069
train_label=P_recall_sent: 0.7476454293628809
train_label=P_f-score_sent: 0.7322300596852956
train_precision_macro_sent: 0.623384182165739
train_recall_macro_sent: 0.5440654251443854
train_f-score_macro_sent: 0.5050016139875543
train_precision_micro_sent: 0.6494616104868914
train_recall_micro_sent: 0.6494616104868914
train_f-score_micro_sent: 0.6494616104868914
train_label=O_precision_tok: 0.8922257312357958
train_label=O_recall_tok: 0.9724239426765423
train_label=O_f-score_tok: 0.9306001823981899
train_label=N_precision_tok: 0.7815308922319992
train_label=N_recall_tok: 0.5816082241937756
train_label=N_f-score_tok: 0.666908885390174
train_label=P_precision_tok: 0.8754650031477136
train_label=P_recall_tok: 0.6114642043410481
train_label=P_f-score_tok: 0.7200282419392798
train_precision_macro_tok: 0.8497405422051697
train_recall_macro_tok: 0.7218321237371219
train_f-score_macro_tok: 0.7725124365758812
train_precision_micro_tok: 0.883282589291173
train_recall_micro_tok: 0.883282589291173
train_f-score_micro_tok: 0.883282589291173
train_time: 49.91542172431946
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0462    0.0853      1624
           N     0.5972    0.8384    0.6975      3310
           P     0.7174    0.7476    0.7322      3610

   micro avg     0.6495    0.6495    0.6495      8544
   macro avg     0.6234    0.5441    0.5050      8544
weighted avg     0.6401    0.6495    0.5958      8544

F1-macro sent:  0.5050016139875543
F1-micro sent:  0.6494616104868914
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8922    0.9724    0.9306    124347
           N     0.7815    0.5816    0.6669     14202
           P     0.8755    0.6115    0.7200     25017

   micro avg     0.8833    0.8833    0.8833    163566
   macro avg     0.8497    0.7218    0.7725    163566
weighted avg     0.8801    0.8833    0.8755    163566

F1-macro tok:  0.7725124365758812
F1-micro tok:  0.883282589291173
**************************************************
dev_cost_sum: 43979.13317871094
dev_cost_avg: 39.944716783570335
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18994.0
dev_accuracy_tok: 0.892826924884836
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6323809523809524
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.6967471143756558
dev_label=P_precision_sent: 0.643979057591623
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7256637168141593
dev_precision_macro_sent: 0.7587866699908584
dev_recall_macro_sent: 0.5399608174472477
dev_f-score_macro_sent: 0.48275763338511074
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8924972004479284
dev_label=O_recall_tok: 0.9836470225239123
dev_label=O_f-score_tok: 0.9358579186848672
dev_label=N_precision_tok: 0.8264058679706602
dev_label=N_recall_tok: 0.5460420032310178
dev_label=N_f-score_tok: 0.6575875486381323
dev_label=P_precision_tok: 0.9327846364883402
dev_label=P_recall_tok: 0.635118306351183
dev_label=P_f-score_tok: 0.7556954991665124
dev_precision_macro_tok: 0.8838959016356429
dev_recall_macro_tok: 0.721602444035371
dev_f-score_macro_tok: 0.7830469888298373
dev_precision_micro_tok: 0.892826924884836
dev_recall_micro_tok: 0.892826924884836
dev_f-score_micro_tok: 0.892826924884836
dev_time: 2.386828899383545
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6324    0.7757    0.6967       428
           P     0.6440    0.8311    0.7257       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.7588    0.5400    0.4828      1101
weighted avg     0.7135    0.6394    0.5689      1101

F1-macro sent:  0.48275763338511074
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8925    0.9836    0.9359     16205
           N     0.8264    0.5460    0.6576      1857
           P     0.9328    0.6351    0.7557      3212

   micro avg     0.8928    0.8928    0.8928     21274
   macro avg     0.8839    0.7216    0.7830     21274
weighted avg     0.8928    0.8928    0.8844     21274

F1-macro tok:  0.7830469888298373
F1-micro tok:  0.892826924884836
**************************************************
Best epoch: 8
**************************************************

EPOCH: 12
Learning rate: 0.810000
train_cost_sum: 326276.3578491211
train_cost_avg: 38.18777596548702
train_count_sent: 8544.0
train_total_correct_sent: 5553.0
train_accuracy_sent: 0.6499297752808989
train_count_tok: 163566.0
train_total_correct_tok: 144671.0
train_accuracy_tok: 0.8844808823349596
train_label=O_precision_sent: 0.46524064171123
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.09607951408061843
train_label=N_precision_sent: 0.6108680635505411
train_label=N_recall_sent: 0.8015105740181269
train_label=N_f-score_sent: 0.6933228799163728
train_label=P_precision_sent: 0.7007972097658196
train_label=P_recall_sent: 0.779224376731302
train_label=P_f-score_sent: 0.7379328436516265
train_precision_macro_sent: 0.5923019716758636
train_recall_macro_sent: 0.5447687931069525
train_f-score_macro_sent: 0.5091117458828726
train_precision_micro_sent: 0.6499297752808989
train_recall_micro_sent: 0.6499297752808989
train_f-score_micro_sent: 0.6499297752808989
train_label=O_precision_tok: 0.8935105816978008
train_label=O_recall_tok: 0.9724159006650743
train_label=O_f-score_tok: 0.9312948878405699
train_label=N_precision_tok: 0.7800954073519784
train_label=N_recall_tok: 0.5872412336290663
train_label=N_f-score_tok: 0.6700678905716467
train_label=P_precision_tok: 0.8784407591041203
train_label=P_recall_tok: 0.6161410241036095
train_label=P_f-score_tok: 0.7242740343952634
train_precision_macro_tok: 0.8506822493846332
train_recall_macro_tok: 0.7252660527992502
train_f-score_macro_tok: 0.7752122709358268
train_precision_micro_tok: 0.8844808823349596
train_recall_micro_tok: 0.8844808823349596
train_f-score_micro_tok: 0.8844808823349596
train_time: 49.910786628723145
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4652    0.0536    0.0961      1624
           N     0.6109    0.8015    0.6933      3310
           P     0.7008    0.7792    0.7379      3610

   micro avg     0.6499    0.6499    0.6499      8544
   macro avg     0.5923    0.5448    0.5091      8544
weighted avg     0.6212    0.6499    0.5987      8544

F1-macro sent:  0.5091117458828726
F1-micro sent:  0.6499297752808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9724    0.9313    124347
           N     0.7801    0.5872    0.6701     14202
           P     0.8784    0.6161    0.7243     25017

   micro avg     0.8845    0.8845    0.8845    163566
   macro avg     0.8507    0.7253    0.7752    163566
weighted avg     0.8814    0.8845    0.8769    163566

F1-macro tok:  0.7752122709358268
F1-micro tok:  0.8844808823349596
**************************************************
dev_cost_sum: 43704.513244628906
dev_cost_avg: 39.6952890505258
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18995.0
dev_accuracy_tok: 0.8928739306195356
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11811023622047244
dev_label=N_precision_sent: 0.5987158908507223
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7098001902949572
dev_label=P_precision_sent: 0.7041942604856513
dev_label=P_recall_sent: 0.7184684684684685
dev_label=P_f-score_sent: 0.7112597547380156
dev_precision_macro_sent: 0.6343033837787911
dev_recall_macro_sent: 0.5518219929924619
dev_f-score_macro_sent: 0.5130567270844818
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8910775068355561
dev_label=O_recall_tok: 0.9854365936439371
dev_label=O_f-score_tok: 0.9358846627205064
dev_label=N_precision_tok: 0.8432026688907422
dev_label=N_recall_tok: 0.5444264943457189
dev_label=N_f-score_tok: 0.6616492146596857
dev_label=P_precision_tok: 0.935468895078923
dev_label=P_recall_tok: 0.6273349937733499
dev_label=P_f-score_tok: 0.7510249720462169
dev_precision_macro_tok: 0.8899163569350739
dev_recall_macro_tok: 0.7190660272543353
dev_f-score_macro_tok: 0.7828529498088029
dev_precision_micro_tok: 0.8928739306195356
dev_recall_micro_tok: 0.8928739306195356
dev_f-score_micro_tok: 0.8928739306195356
dev_time: 2.3736469745635986
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0655    0.1181       229
           N     0.5987    0.8715    0.7098       428
           P     0.7042    0.7185    0.7113       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.6343    0.5518    0.5131      1101
weighted avg     0.6415    0.6421    0.5873      1101

F1-macro sent:  0.5130567270844818
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8911    0.9854    0.9359     16205
           N     0.8432    0.5444    0.6616      1857
           P     0.9355    0.6273    0.7510      3212

   micro avg     0.8929    0.8929    0.8929     21274
   macro avg     0.8899    0.7191    0.7829     21274
weighted avg     0.8936    0.8929    0.8840     21274

F1-macro tok:  0.7828529498088029
F1-micro tok:  0.8928739306195356
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 0.810000
train_cost_sum: 324390.49420166016
train_cost_avg: 37.96705222397708
train_count_sent: 8544.0
train_total_correct_sent: 5567.0
train_accuracy_sent: 0.6515683520599251
train_count_tok: 163566.0
train_total_correct_tok: 145025.0
train_accuracy_tok: 0.8866451463017987
train_label=O_precision_sent: 0.44808743169398907
train_label=O_recall_sent: 0.050492610837438424
train_label=O_f-score_sent: 0.09075816270060874
train_label=N_precision_sent: 0.6050328227571116
train_label=N_recall_sent: 0.8353474320241692
train_label=N_f-score_sent: 0.7017766497461929
train_label=P_precision_sent: 0.7174887892376681
train_label=P_recall_sent: 0.7534626038781164
train_label=P_f-score_sent: 0.735035805972166
train_precision_macro_sent: 0.590203014562923
train_recall_macro_sent: 0.5464342155799079
train_f-score_macro_sent: 0.5091902061396559
train_precision_micro_sent: 0.6515683520599251
train_recall_micro_sent: 0.6515683520599251
train_f-score_micro_sent: 0.6515683520599251
train_label=O_precision_tok: 0.8949882786212404
train_label=O_recall_tok: 0.9732683538806727
train_label=O_f-score_tok: 0.9324883461108756
train_label=N_precision_tok: 0.7882297551789077
train_label=N_recall_tok: 0.5894240247852415
train_label=N_f-score_tok: 0.6744823140762226
train_label=P_precision_tok: 0.8819612932347797
train_label=P_recall_tok: 0.6248151257145141
train_label=P_f-score_tok: 0.7314459522695367
train_precision_macro_tok: 0.8550597756783093
train_recall_macro_tok: 0.7291691681268094
train_f-score_macro_tok: 0.7794722041522117
train_precision_micro_tok: 0.8866451463017987
train_recall_micro_tok: 0.8866451463017987
train_f-score_micro_tok: 0.8866451463017987
train_time: 49.77273154258728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4481    0.0505    0.0908      1624
           N     0.6050    0.8353    0.7018      3310
           P     0.7175    0.7535    0.7350      3610

   micro avg     0.6516    0.6516    0.6516      8544
   macro avg     0.5902    0.5464    0.5092      8544
weighted avg     0.6227    0.6516    0.5997      8544

F1-macro sent:  0.5091902061396559
F1-micro sent:  0.6515683520599251
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9733    0.9325    124347
           N     0.7882    0.5894    0.6745     14202
           P     0.8820    0.6248    0.7314     25017

   micro avg     0.8866    0.8866    0.8866    163566
   macro avg     0.8551    0.7292    0.7795    163566
weighted avg     0.8837    0.8866    0.8793    163566

F1-macro tok:  0.7794722041522117
F1-micro tok:  0.8866451463017987
**************************************************
dev_cost_sum: 43568.72961425781
dev_cost_avg: 39.57196150250483
dev_count_sent: 1101.0
dev_total_correct_sent: 706.0
dev_accuracy_sent: 0.6412352406902816
dev_count_tok: 21274.0
dev_total_correct_tok: 19048.0
dev_accuracy_tok: 0.8953652345586162
dev_label=O_precision_sent: 0.6363636363636364
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058333333333333334
dev_label=N_precision_sent: 0.66875
dev_label=N_recall_sent: 0.75
dev_label=N_f-score_sent: 0.7070484581497797
dev_label=P_precision_sent: 0.6196721311475409
dev_label=P_recall_sent: 0.8513513513513513
dev_label=P_f-score_sent: 0.7172675521821632
dev_precision_macro_sent: 0.6415952558370591
dev_recall_macro_sent: 0.5439730123136236
dev_f-score_macro_sent: 0.4942164478884254
dev_precision_micro_sent: 0.6412352406902816
dev_recall_micro_sent: 0.6412352406902816
dev_f-score_micro_sent: 0.6412352406902816
dev_label=O_precision_tok: 0.8981172612653361
dev_label=O_recall_tok: 0.9802530083307621
dev_label=O_f-score_tok: 0.9373893544199221
dev_label=N_precision_tok: 0.8275590551181102
dev_label=N_recall_tok: 0.5659666128163705
dev_label=N_f-score_tok: 0.6722097857371282
dev_label=P_precision_tok: 0.9115235217954252
dev_label=P_recall_tok: 0.6575342465753424
dev_label=P_f-score_tok: 0.7639717851329355
dev_precision_macro_tok: 0.8790666127262905
dev_recall_macro_tok: 0.7345846225741584
dev_f-score_macro_tok: 0.7911903084299953
dev_precision_micro_tok: 0.8953652345586162
dev_recall_micro_tok: 0.8953652345586162
dev_f-score_micro_tok: 0.8953652345586162
dev_time: 2.3722829818725586
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6364    0.0306    0.0583       229
           N     0.6687    0.7500    0.7070       428
           P     0.6197    0.8514    0.7173       444

   micro avg     0.6412    0.6412    0.6412      1101
   macro avg     0.6416    0.5440    0.4942      1101
weighted avg     0.6422    0.6412    0.5762      1101

F1-macro sent:  0.4942164478884254
F1-micro sent:  0.6412352406902816
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8981    0.9803    0.9374     16205
           N     0.8276    0.5660    0.6722      1857
           P     0.9115    0.6575    0.7640      3212

   micro avg     0.8954    0.8954    0.8954     21274
   macro avg     0.8791    0.7346    0.7912     21274
weighted avg     0.8940    0.8954    0.8881     21274

F1-macro tok:  0.7911903084299953
F1-micro tok:  0.8953652345586162
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 0.810000
train_cost_sum: 322482.7274169922
train_cost_avg: 37.743764913037474
train_count_sent: 8544.0
train_total_correct_sent: 5603.0
train_accuracy_sent: 0.6557818352059925
train_count_tok: 163566.0
train_total_correct_tok: 145258.0
train_accuracy_tok: 0.8880696477263
train_label=O_precision_sent: 0.49572649572649574
train_label=O_recall_sent: 0.03571428571428571
train_label=O_f-score_sent: 0.06662837449741528
train_label=N_precision_sent: 0.6156615661566157
train_label=N_recall_sent: 0.8265861027190332
train_label=N_f-score_sent: 0.7057002837245293
train_label=P_precision_sent: 0.7052473010293748
train_label=P_recall_sent: 0.7781163434903047
train_label=P_f-score_sent: 0.739892005794811
train_precision_macro_sent: 0.6055451209708287
train_recall_macro_sent: 0.5468055773078745
train_f-score_macro_sent: 0.5040735546722518
train_precision_micro_sent: 0.6557818352059925
train_recall_micro_sent: 0.6557818352059925
train_f-score_micro_sent: 0.6557818352059925
train_label=O_precision_tok: 0.8961847315249972
train_label=O_recall_tok: 0.9737910846260867
train_label=O_f-score_tok: 0.9333775273450449
train_label=N_precision_tok: 0.7885311311125545
train_label=N_recall_tok: 0.5983664272637657
train_label=N_f-score_tok: 0.6804115456983867
train_label=P_precision_tok: 0.886726264569424
train_label=P_recall_tok: 0.6264540112723348
train_label=P_f-score_tok: 0.7342062729849382
train_precision_macro_tok: 0.8571473757356586
train_recall_macro_tok: 0.732870507720729
train_f-score_macro_tok: 0.7826651153427898
train_precision_micro_tok: 0.8880696477263
train_recall_micro_tok: 0.8880696477263
train_f-score_micro_tok: 0.8880696477263
train_time: 49.550325870513916
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4957    0.0357    0.0666      1624
           N     0.6157    0.8266    0.7057      3310
           P     0.7052    0.7781    0.7399      3610

   micro avg     0.6558    0.6558    0.6558      8544
   macro avg     0.6055    0.5468    0.5041      8544
weighted avg     0.6307    0.6558    0.5987      8544

F1-macro sent:  0.5040735546722518
F1-micro sent:  0.6557818352059925
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8962    0.9738    0.9334    124347
           N     0.7885    0.5984    0.6804     14202
           P     0.8867    0.6265    0.7342     25017

   micro avg     0.8881    0.8881    0.8881    163566
   macro avg     0.8571    0.7329    0.7827    163566
weighted avg     0.8854    0.8881    0.8810    163566

F1-macro tok:  0.7826651153427898
F1-micro tok:  0.8880696477263
**************************************************
dev_cost_sum: 43365.40734863281
dev_cost_avg: 39.387290961519355
dev_count_sent: 1101.0
dev_total_correct_sent: 712.0
dev_accuracy_sent: 0.6466848319709355
dev_count_tok: 21274.0
dev_total_correct_tok: 19036.0
dev_accuracy_tok: 0.8948011657422206
dev_label=O_precision_sent: 0.56
dev_label=O_recall_sent: 0.0611353711790393
dev_label=O_f-score_sent: 0.11023622047244093
dev_label=N_precision_sent: 0.5882352941176471
dev_label=N_recall_sent: 0.9112149532710281
dev_label=N_f-score_sent: 0.7149404216315306
dev_label=P_precision_sent: 0.7457627118644068
dev_label=P_recall_sent: 0.6936936936936937
dev_label=P_f-score_sent: 0.7187864644107352
dev_precision_macro_sent: 0.6313326686606847
dev_recall_macro_sent: 0.5553480060479203
dev_f-score_macro_sent: 0.5146543688382356
dev_precision_micro_sent: 0.6466848319709355
dev_recall_micro_sent: 0.6466848319709355
dev_f-score_micro_sent: 0.6466848319709355
dev_label=O_precision_tok: 0.8961170512099044
dev_label=O_recall_tok: 0.9826596729404504
dev_label=O_f-score_tok: 0.9373951434878587
dev_label=N_precision_tok: 0.8133030990173847
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.6767295597484275
dev_label=P_precision_tok: 0.9335167354424576
dev_label=P_recall_tok: 0.6338729763387297
dev_label=P_f-score_tok: 0.7550528462822178
dev_precision_macro_tok: 0.8809789618899155
dev_recall_macro_tok: 0.7319872787132359
dev_f-score_macro_tok: 0.7897258498395013
dev_precision_micro_tok: 0.8948011657422206
dev_recall_micro_tok: 0.8948011657422206
dev_f-score_micro_tok: 0.8948011657422205
dev_time: 2.3871331214904785
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5600    0.0611    0.1102       229
           N     0.5882    0.9112    0.7149       428
           P     0.7458    0.6937    0.7188       444

   micro avg     0.6467    0.6467    0.6467      1101
   macro avg     0.6313    0.5553    0.5147      1101
weighted avg     0.6459    0.6467    0.5907      1101

F1-macro sent:  0.5146543688382356
F1-micro sent:  0.6466848319709355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9827    0.9374     16205
           N     0.8133    0.5794    0.6767      1857
           P     0.9335    0.6339    0.7551      3212

   micro avg     0.8948    0.8948    0.8948     21274
   macro avg     0.8810    0.7320    0.7897     21274
weighted avg     0.8945    0.8948    0.8871     21274

F1-macro tok:  0.7897258498395013
F1-micro tok:  0.8948011657422205
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 0.810000
train_cost_sum: 320725.9700317383
train_cost_avg: 37.53815192319034
train_count_sent: 8544.0
train_total_correct_sent: 5625.0
train_accuracy_sent: 0.6583567415730337
train_count_tok: 163566.0
train_total_correct_tok: 145344.0
train_accuracy_tok: 0.8885954293679615
train_label=O_precision_sent: 0.4271356783919598
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.09325287986834888
train_label=N_precision_sent: 0.614813147230977
train_label=N_recall_sent: 0.8250755287009064
train_label=N_f-score_sent: 0.7045923632610939
train_label=P_precision_sent: 0.719702792723546
train_label=P_recall_sent: 0.7781163434903047
train_label=P_f-score_sent: 0.7477705310794622
train_precision_macro_sent: 0.5872172061154942
train_recall_macro_sent: 0.5518439245563479
train_f-score_macro_sent: 0.515205258069635
train_precision_micro_sent: 0.6583567415730337
train_recall_micro_sent: 0.6583567415730337
train_f-score_micro_sent: 0.6583567415730337
train_label=O_precision_tok: 0.8972224487224154
train_label=O_recall_tok: 0.9733889840526913
train_label=O_f-score_tok: 0.93375506268081
train_label=N_precision_tok: 0.7907922714246094
train_label=N_recall_tok: 0.6023095338684692
train_label=N_f-score_tok: 0.68380031176306
train_label=P_precision_tok: 0.8826627815757032
train_label=P_recall_tok: 0.6296518367510093
train_label=P_f-score_tok: 0.7349928843058117
train_precision_macro_tok: 0.8568925005742427
train_recall_macro_tok: 0.7351167848907233
train_f-score_macro_tok: 0.7841827529165606
train_precision_micro_tok: 0.8885954293679615
train_recall_micro_tok: 0.8885954293679615
train_f-score_micro_tok: 0.8885954293679615
train_time: 49.76950764656067
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4271    0.0523    0.0933      1624
           N     0.6148    0.8251    0.7046      3310
           P     0.7197    0.7781    0.7478      3610

   micro avg     0.6584    0.6584    0.6584      8544
   macro avg     0.5872    0.5518    0.5152      8544
weighted avg     0.6235    0.6584    0.6066      8544

F1-macro sent:  0.515205258069635
F1-micro sent:  0.6583567415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9734    0.9338    124347
           N     0.7908    0.6023    0.6838     14202
           P     0.8827    0.6297    0.7350     25017

   micro avg     0.8886    0.8886    0.8886    163566
   macro avg     0.8569    0.7351    0.7842    163566
weighted avg     0.8858    0.8886    0.8817    163566

F1-macro tok:  0.7841827529165606
F1-micro tok:  0.8885954293679615
**************************************************
dev_cost_sum: 43238.67156982422
dev_cost_avg: 39.27218126232899
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 19065.0
dev_accuracy_tok: 0.8961643320485099
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04219409282700421
dev_label=N_precision_sent: 0.6445783132530121
dev_label=N_recall_sent: 0.75
dev_label=N_f-score_sent: 0.693304535637149
dev_label=P_precision_sent: 0.6319327731092437
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7237728585178056
dev_precision_macro_sent: 0.6338370287874185
dev_recall_macro_sent: 0.5395603026607394
dev_f-score_macro_sent: 0.48642382899398634
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8981021238138274
dev_label=O_recall_tok: 0.9811786485652576
dev_label=O_f-score_tok: 0.9378041227992568
dev_label=N_precision_tok: 0.833596214511041
dev_label=N_recall_tok: 0.5691976305869683
dev_label=N_f-score_tok: 0.6764800000000001
dev_label=P_precision_tok: 0.9157254561251086
dev_label=P_recall_tok: 0.6562889165628891
dev_label=P_f-score_tok: 0.7645992020311932
dev_precision_macro_tok: 0.8824745981499923
dev_recall_macro_tok: 0.7355550652383717
dev_f-score_macro_tok: 0.7929611082768168
dev_precision_micro_tok: 0.8961643320485099
dev_recall_micro_tok: 0.8961643320485099
dev_f-score_micro_tok: 0.89616433204851
dev_time: 2.3836753368377686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0218    0.0422       229
           N     0.6446    0.7500    0.6933       428
           P     0.6319    0.8468    0.7238       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.6338    0.5396    0.4864      1101
weighted avg     0.6354    0.6376    0.5702      1101

F1-macro sent:  0.48642382899398634
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8981    0.9812    0.9378     16205
           N     0.8336    0.5692    0.6765      1857
           P     0.9157    0.6563    0.7646      3212

   micro avg     0.8962    0.8962    0.8962     21274
   macro avg     0.8825    0.7356    0.7930     21274
weighted avg     0.8951    0.8962    0.8888     21274

F1-macro tok:  0.7929611082768168
F1-micro tok:  0.89616433204851
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 0.810000
train_cost_sum: 319021.4059448242
train_cost_avg: 37.33864769953467
train_count_sent: 8544.0
train_total_correct_sent: 5625.0
train_accuracy_sent: 0.6583567415730337
train_count_tok: 163566.0
train_total_correct_tok: 145662.0
train_accuracy_tok: 0.8905395986941052
train_label=O_precision_sent: 0.3975409836065574
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10385438972162742
train_label=N_precision_sent: 0.6093023255813953
train_label=N_recall_sent: 0.8311178247734139
train_label=N_f-score_sent: 0.7031309904153354
train_label=P_precision_sent: 0.7336856010568031
train_label=P_recall_sent: 0.7692520775623268
train_label=P_f-score_sent: 0.7510480054090601
train_precision_macro_sent: 0.5801763034149187
train_recall_macro_sent: 0.5533663221250499
train_f-score_macro_sent: 0.5193444618486743
train_precision_micro_sent: 0.6583567415730337
train_recall_micro_sent: 0.6583567415730337
train_f-score_micro_sent: 0.6583567415730337
train_label=O_precision_tok: 0.8991875594106464
train_label=O_recall_tok: 0.9737347905458114
train_label=O_f-score_tok: 0.9349775871321955
train_label=N_precision_tok: 0.7931318681318681
train_label=N_recall_tok: 0.6098436839881707
train_label=N_f-score_tok: 0.689515165989969
train_label=P_precision_tok: 0.8849360755975542
train_label=P_recall_tok: 0.6363672702562257
train_label=P_f-score_tok: 0.7403445950659195
train_precision_macro_tok: 0.8590851677133563
train_recall_macro_tok: 0.7399819149300693
train_f-score_macro_tok: 0.7882791160626947
train_precision_micro_tok: 0.8905395986941052
train_recall_micro_tok: 0.8905395986941052
train_f-score_micro_tok: 0.8905395986941052
train_time: 49.81866478919983
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3975    0.0597    0.1039      1624
           N     0.6093    0.8311    0.7031      3310
           P     0.7337    0.7693    0.7510      3610

   micro avg     0.6584    0.6584    0.6584      8544
   macro avg     0.5802    0.5534    0.5193      8544
weighted avg     0.6216    0.6584    0.6095      8544

F1-macro sent:  0.5193444618486743
F1-micro sent:  0.6583567415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8992    0.9737    0.9350    124347
           N     0.7931    0.6098    0.6895     14202
           P     0.8849    0.6364    0.7403     25017

   micro avg     0.8905    0.8905    0.8905    163566
   macro avg     0.8591    0.7400    0.7883    163566
weighted avg     0.8878    0.8905    0.8839    163566

F1-macro tok:  0.7882791160626947
F1-micro tok:  0.8905395986941052
**************************************************
dev_cost_sum: 43046.90704345703
dev_cost_avg: 39.09800821385743
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19097.0
dev_accuracy_tok: 0.8976685155588982
dev_label=O_precision_sent: 0.7142857142857143
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.0823045267489712
dev_label=N_precision_sent: 0.5984126984126984
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7126654064272212
dev_label=P_precision_sent: 0.7155361050328227
dev_label=P_recall_sent: 0.7364864864864865
dev_label=P_f-score_sent: 0.7258601553829078
dev_precision_macro_sent: 0.6760781725770785
dev_recall_macro_sent: 0.5536652434175187
dev_f-score_macro_sent: 0.5069433628530334
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8983251564879039
dev_label=O_recall_tok: 0.9830299290342487
dev_label=O_f-score_tok: 0.9387706995108727
dev_label=N_precision_tok: 0.8306513409961686
dev_label=N_recall_tok: 0.5837372105546581
dev_label=N_f-score_tok: 0.685641998734978
dev_label=P_precision_tok: 0.9315742397137746
dev_label=P_recall_tok: 0.6485056039850561
dev_label=P_f-score_tok: 0.7646842878120411
dev_precision_macro_tok: 0.8868502457326156
dev_recall_macro_tok: 0.7384242478579877
dev_f-score_macro_tok: 0.7963656620192973
dev_precision_micro_tok: 0.8976685155588982
dev_recall_micro_tok: 0.8976685155588982
dev_f-score_micro_tok: 0.8976685155588982
dev_time: 2.380840301513672
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7143    0.0437    0.0823       229
           N     0.5984    0.8808    0.7127       428
           P     0.7155    0.7365    0.7259       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.6761    0.5537    0.5069      1101
weighted avg     0.6697    0.6485    0.5869      1101

F1-macro sent:  0.5069433628530334
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8983    0.9830    0.9388     16205
           N     0.8307    0.5837    0.6856      1857
           P     0.9316    0.6485    0.7647      3212

   micro avg     0.8977    0.8977    0.8977     21274
   macro avg     0.8869    0.7384    0.7964     21274
weighted avg     0.8974    0.8977    0.8904     21274

F1-macro tok:  0.7963656620192973
F1-micro tok:  0.8976685155588982
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 0.810000
train_cost_sum: 317479.7670288086
train_cost_avg: 37.15821243314707
train_count_sent: 8544.0
train_total_correct_sent: 5648.0
train_accuracy_sent: 0.6610486891385767
train_count_tok: 163566.0
train_total_correct_tok: 145948.0
train_accuracy_tok: 0.8922881283396304
train_label=O_precision_sent: 0.48947368421052634
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.10253583241455347
train_label=N_precision_sent: 0.6347594875513657
train_label=N_recall_sent: 0.7933534743202417
train_label=N_f-score_sent: 0.7052504364173492
train_label=P_precision_sent: 0.6945695992411667
train_label=P_recall_sent: 0.8113573407202216
train_label=P_f-score_sent: 0.7484349048166602
train_precision_macro_sent: 0.606267590334353
train_recall_macro_sent: 0.5539922749642266
train_f-score_macro_sent: 0.5187403912161876
train_precision_micro_sent: 0.6610486891385767
train_recall_micro_sent: 0.6610486891385767
train_f-score_micro_sent: 0.6610486891385767
train_label=O_precision_tok: 0.9001477916657383
train_label=O_recall_tok: 0.974723957956364
train_label=O_f-score_tok: 0.9359526788058503
train_label=N_precision_tok: 0.8001659139091161
train_label=N_recall_tok: 0.6112519363469934
train_label=N_f-score_tok: 0.6930661450640693
train_label=P_precision_tok: 0.8890303298649546
train_label=P_recall_tok: 0.6420833832993564
train_label=P_f-score_tok: 0.7456423349193454
train_precision_macro_tok: 0.8631146784799363
train_recall_macro_tok: 0.7426864258675714
train_f-score_macro_tok: 0.7915537195964216
train_precision_micro_tok: 0.8922881283396304
train_recall_micro_tok: 0.8922881283396304
train_f-score_micro_tok: 0.8922881283396303
train_time: 49.969590187072754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4895    0.0573    0.1025      1624
           N     0.6348    0.7934    0.7053      3310
           P     0.6946    0.8114    0.7484      3610

   micro avg     0.6610    0.6610    0.6610      8544
   macro avg     0.6063    0.5540    0.5187      8544
weighted avg     0.6324    0.6610    0.6089      8544

F1-macro sent:  0.5187403912161876
F1-micro sent:  0.6610486891385767
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9001    0.9747    0.9360    124347
           N     0.8002    0.6113    0.6931     14202
           P     0.8890    0.6421    0.7456     25017

   micro avg     0.8923    0.8923    0.8923    163566
   macro avg     0.8631    0.7427    0.7916    163566
weighted avg     0.8898    0.8923    0.8858    163566

F1-macro tok:  0.7915537195964216
F1-micro tok:  0.8922881283396303
**************************************************
dev_cost_sum: 42982.841552734375
dev_cost_avg: 39.03981975725193
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19068.0
dev_accuracy_tok: 0.8963053492526089
dev_label=O_precision_sent: 0.6923076923076923
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0743801652892562
dev_label=N_precision_sent: 0.6693386773547094
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.720604099244876
dev_label=P_precision_sent: 0.6451612903225806
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7357212003872217
dev_precision_macro_sent: 0.6689358866616608
dev_recall_macro_sent: 0.5585103325584083
dev_f-score_macro_sent: 0.5102351549737846
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.8935195530726256
dev_label=O_recall_tok: 0.9869793273680962
dev_label=O_f-score_tok: 0.9379269901773932
dev_label=N_precision_tok: 0.8563074352548037
dev_label=N_recall_tok: 0.5519655358104469
dev_label=N_f-score_tok: 0.6712508185985593
dev_label=P_precision_tok: 0.9412034910427194
dev_label=P_recall_tok: 0.637920298879203
dev_label=P_f-score_tok: 0.7604379291148636
dev_precision_macro_tok: 0.8970101597900495
dev_recall_macro_tok: 0.7256217206859154
dev_f-score_macro_tok: 0.789871912630272
dev_precision_micro_tok: 0.8963053492526089
dev_recall_micro_tok: 0.8963053492526089
dev_f-score_micro_tok: 0.8963053492526089
dev_time: 2.3962371349334717
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6923    0.0393    0.0744       229
           N     0.6693    0.7804    0.7206       428
           P     0.6452    0.8559    0.7357       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6689    0.5585    0.5102      1101
weighted avg     0.6644    0.6567    0.5923      1101

F1-macro sent:  0.5102351549737846
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9870    0.9379     16205
           N     0.8563    0.5520    0.6713      1857
           P     0.9412    0.6379    0.7604      3212

   micro avg     0.8963    0.8963    0.8963     21274
   macro avg     0.8970    0.7256    0.7899     21274
weighted avg     0.8975    0.8963    0.8879     21274

F1-macro tok:  0.789871912630272
F1-micro tok:  0.8963053492526089
**************************************************
Best epoch: 14
**************************************************

EPOCH: 18
Learning rate: 0.810000
train_cost_sum: 315692.8704223633
train_cost_avg: 36.949071912729785
train_count_sent: 8544.0
train_total_correct_sent: 5701.0
train_accuracy_sent: 0.6672518726591761
train_count_tok: 163566.0
train_total_correct_tok: 146058.0
train_accuracy_tok: 0.8929606397417557
train_label=O_precision_sent: 0.5138121546961326
train_label=O_recall_sent: 0.05726600985221675
train_label=O_f-score_sent: 0.10304709141274238
train_label=N_precision_sent: 0.6351415094339623
train_label=N_recall_sent: 0.813595166163142
train_label=N_f-score_sent: 0.7133774834437087
train_label=P_precision_sent: 0.7070094591317002
train_label=P_recall_sent: 0.8074792243767313
train_label=P_f-score_sent: 0.7539118065433855
train_precision_macro_sent: 0.6186543744205985
train_recall_macro_sent: 0.5594468001306967
train_f-score_macro_sent: 0.5234454604666122
train_precision_micro_sent: 0.6672518726591761
train_recall_micro_sent: 0.6672518726591761
train_f-score_micro_sent: 0.6672518726591761
train_label=O_precision_tok: 0.9016322640216841
train_label=O_recall_tok: 0.9737428325572792
train_label=O_f-score_tok: 0.9363011765433673
train_label=N_precision_tok: 0.7993642143505904
train_label=N_recall_tok: 0.6197014504999296
train_label=N_f-score_tok: 0.6981596065365699
train_label=P_precision_tok: 0.8856219886114761
train_label=P_recall_tok: 0.6465603389695007
train_label=P_f-score_tok: 0.7474411404542408
train_precision_macro_tok: 0.8622061556612501
train_recall_macro_tok: 0.7466682073422365
train_f-score_macro_tok: 0.793967307844726
train_precision_micro_tok: 0.8929606397417557
train_recall_micro_tok: 0.8929606397417557
train_f-score_micro_tok: 0.8929606397417557
train_time: 50.01206374168396
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5138    0.0573    0.1030      1624
           N     0.6351    0.8136    0.7134      3310
           P     0.7070    0.8075    0.7539      3610

   micro avg     0.6673    0.6673    0.6673      8544
   macro avg     0.6187    0.5594    0.5234      8544
weighted avg     0.6424    0.6673    0.6145      8544

F1-macro sent:  0.5234454604666122
F1-micro sent:  0.6672518726591761
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9016    0.9737    0.9363    124347
           N     0.7994    0.6197    0.6982     14202
           P     0.8856    0.6466    0.7474     25017

   micro avg     0.8930    0.8930    0.8930    163566
   macro avg     0.8622    0.7467    0.7940    163566
weighted avg     0.8903    0.8930    0.8867    163566

F1-macro tok:  0.793967307844726
F1-micro tok:  0.8929606397417557
**************************************************
dev_cost_sum: 42762.90808105469
dev_cost_avg: 38.840061835653664
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19107.0
dev_accuracy_tok: 0.8981385729058945
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6239460370994941
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7247796278158669
dev_label=P_precision_sent: 0.7014028056112225
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7423117709437964
dev_precision_macro_sent: 0.7010422068294981
dev_recall_macro_sent: 0.5611139850620731
dev_f-score_macro_sent: 0.5086383093904759
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9003907356022425
dev_label=O_recall_tok: 0.9811786485652576
dev_label=O_f-score_tok: 0.9390503189227498
dev_label=N_precision_tok: 0.8154981549815498
dev_label=N_recall_tok: 0.5950457727517501
dev_label=N_f-score_tok: 0.6880448318804483
dev_label=P_precision_tok: 0.9300884955752212
dev_label=P_recall_tok: 0.6544209215442092
dev_label=P_f-score_tok: 0.7682748538011697
dev_precision_macro_tok: 0.8819924620530045
dev_recall_macro_tok: 0.7435484476204056
dev_f-score_macro_tok: 0.7984566682014559
dev_precision_micro_tok: 0.8981385729058945
dev_recall_micro_tok: 0.8981385729058945
dev_f-score_micro_tok: 0.8981385729058945
dev_time: 2.37030291557312
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6239    0.8645    0.7248       428
           P     0.7014    0.7883    0.7423       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7010    0.5611    0.5086      1101
weighted avg     0.6872    0.6603    0.5933      1101

F1-macro sent:  0.5086383093904759
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9004    0.9812    0.9391     16205
           N     0.8155    0.5950    0.6880      1857
           P     0.9301    0.6544    0.7683      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8820    0.7435    0.7985     21274
weighted avg     0.8975    0.8981    0.8914     21274

F1-macro tok:  0.7984566682014559
F1-micro tok:  0.8981385729058945
**************************************************
Best epoch: 14
**************************************************

EPOCH: 19
Learning rate: 0.729000
train_cost_sum: 314388.2904663086
train_cost_avg: 36.79638231113162
train_count_sent: 8544.0
train_total_correct_sent: 5698.0
train_accuracy_sent: 0.6669007490636704
train_count_tok: 163566.0
train_total_correct_tok: 146202.0
train_accuracy_tok: 0.8938410183045377
train_label=O_precision_sent: 0.5845070422535211
train_label=O_recall_sent: 0.05110837438423645
train_label=O_f-score_sent: 0.09399773499433749
train_label=N_precision_sent: 0.6359360301034808
train_label=N_recall_sent: 0.8169184290030211
train_label=N_f-score_sent: 0.7151547209732874
train_label=P_precision_sent: 0.7014457831325301
train_label=P_recall_sent: 0.8063711911357341
train_label=P_f-score_sent: 0.7502577319587629
train_precision_macro_sent: 0.6406296184965107
train_recall_macro_sent: 0.5581326648409972
train_f-score_macro_sent: 0.5198033959754625
train_precision_micro_sent: 0.6669007490636704
train_recall_micro_sent: 0.6669007490636704
train_f-score_micro_sent: 0.6669007490636704
train_label=O_precision_tok: 0.9024555549762786
train_label=O_recall_tok: 0.9744505295664552
train_label=O_f-score_tok: 0.9370722389352472
train_label=N_precision_tok: 0.7984742530197075
train_label=N_recall_tok: 0.6190677369384594
train_label=N_f-score_tok: 0.6974179986514893
train_label=P_precision_tok: 0.8880139982502188
train_label=P_recall_tok: 0.6491585721709238
train_label=P_f-score_tok: 0.7500288650271331
train_precision_macro_tok: 0.8629812687487349
train_recall_macro_tok: 0.7475589462252795
train_f-score_macro_tok: 0.7948397008712899
train_precision_micro_tok: 0.8938410183045377
train_recall_micro_tok: 0.8938410183045377
train_f-score_micro_tok: 0.8938410183045375
train_time: 49.58852410316467
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5845    0.0511    0.0940      1624
           N     0.6359    0.8169    0.7152      3310
           P     0.7014    0.8064    0.7503      3610

   micro avg     0.6669    0.6669    0.6669      8544
   macro avg     0.6406    0.5581    0.5198      8544
weighted avg     0.6538    0.6669    0.6119      8544

F1-macro sent:  0.5198033959754625
F1-micro sent:  0.6669007490636704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9025    0.9745    0.9371    124347
           N     0.7985    0.6191    0.6974     14202
           P     0.8880    0.6492    0.7500     25017

   micro avg     0.8938    0.8938    0.8938    163566
   macro avg     0.8630    0.7476    0.7948    163566
weighted avg     0.8912    0.8938    0.8877    163566

F1-macro tok:  0.7948397008712899
F1-micro tok:  0.8938410183045375
**************************************************
dev_cost_sum: 42675.691162109375
dev_cost_avg: 38.76084574215202
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19110.0
dev_accuracy_tok: 0.8982795901099934
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6392857142857142
dev_label=N_recall_sent: 0.8364485981308412
dev_label=N_f-score_sent: 0.7246963562753036
dev_label=P_precision_sent: 0.67984934086629
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7405128205128205
dev_precision_macro_sent: 0.7063783517173348
dev_recall_macro_sent: 0.5614820530034993
dev_f-score_macro_sent: 0.5107182611608949
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9045470124528733
dev_label=O_recall_tok: 0.9771675408824437
dev_label=O_f-score_tok: 0.9394559639286879
dev_label=N_precision_tok: 0.8228614685844058
dev_label=N_recall_tok: 0.5853527194399569
dev_label=N_f-score_tok: 0.6840780365009439
dev_label=P_precision_tok: 0.8941561095218635
dev_label=P_recall_tok: 0.6811955168119551
dev_label=P_f-score_tok: 0.7732814984979678
dev_precision_macro_tok: 0.8738548635197141
dev_recall_macro_tok: 0.7479052590447853
dev_f-score_macro_tok: 0.7989384996425332
dev_precision_micro_tok: 0.8982795901099934
dev_recall_micro_tok: 0.8982795901099934
dev_f-score_micro_tok: 0.8982795901099935
dev_time: 2.391238212585449
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6393    0.8364    0.7247       428
           P     0.6798    0.8131    0.7405       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7064    0.5615    0.5107      1101
weighted avg     0.6891    0.6603    0.5943      1101

F1-macro sent:  0.5107182611608949
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9045    0.9772    0.9395     16205
           N     0.8229    0.5854    0.6841      1857
           P     0.8942    0.6812    0.7733      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8739    0.7479    0.7989     21274
weighted avg     0.8958    0.8983    0.8921     21274

F1-macro tok:  0.7989384996425332
F1-micro tok:  0.8982795901099935
**************************************************
Best epoch: 14
**************************************************

EPOCH: 20
Learning rate: 0.656100
train_cost_sum: 312788.3187866211
train_cost_avg: 36.609119708171946
train_count_sent: 8544.0
train_total_correct_sent: 5764.0
train_accuracy_sent: 0.674625468164794
train_count_tok: 163566.0
train_total_correct_tok: 146562.0
train_accuracy_tok: 0.8960419647114926
train_label=O_precision_sent: 0.6028368794326241
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.0963172804532578
train_label=N_precision_sent: 0.631328036322361
train_label=N_recall_sent: 0.8401812688821753
train_label=N_f-score_sent: 0.7209332469215813
train_label=P_precision_sent: 0.7248624312156078
train_label=P_recall_sent: 0.8027700831024931
train_label=P_f-score_sent: 0.7618296529968454
train_precision_macro_sent: 0.6530091156568643
train_recall_macro_sent: 0.5650970844875003
train_f-score_macro_sent: 0.5263600601238948
train_precision_micro_sent: 0.674625468164794
train_recall_micro_sent: 0.674625468164794
train_f-score_micro_sent: 0.674625468164794
train_label=O_precision_tok: 0.9048251967563209
train_label=O_recall_tok: 0.9744987816352626
train_label=O_f-score_tok: 0.9383704587077814
train_label=N_precision_tok: 0.805042773525439
train_label=N_recall_tok: 0.6294888043937473
train_label=N_f-score_tok: 0.7065238866716719
train_label=P_precision_tok: 0.8871028642321592
train_label=P_recall_tok: 0.6573929727785106
train_label=P_f-score_tok: 0.755165763614657
train_precision_macro_tok: 0.8656569448379731
train_recall_macro_tok: 0.7537935196025067
train_f-score_macro_tok: 0.8000200363313702
train_precision_micro_tok: 0.8960419647114926
train_recall_micro_tok: 0.8960419647114926
train_f-score_micro_tok: 0.8960419647114926
train_time: 49.88377928733826
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6028    0.0523    0.0963      1624
           N     0.6313    0.8402    0.7209      3310
           P     0.7249    0.8028    0.7618      3610

   micro avg     0.6746    0.6746    0.6746      8544
   macro avg     0.6530    0.5651    0.5264      8544
weighted avg     0.6654    0.6746    0.6195      8544

F1-macro sent:  0.5263600601238948
F1-micro sent:  0.674625468164794
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9745    0.9384    124347
           N     0.8050    0.6295    0.7065     14202
           P     0.8871    0.6574    0.7552     25017

   micro avg     0.8960    0.8960    0.8960    163566
   macro avg     0.8657    0.7538    0.8000    163566
weighted avg     0.8935    0.8960    0.8902    163566

F1-macro tok:  0.8000200363313702
F1-micro tok:  0.8960419647114926
**************************************************
dev_cost_sum: 42542.88153076172
dev_cost_avg: 38.64021937398885
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19118.0
dev_accuracy_tok: 0.8986556359875905
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.05063291139240506
dev_label=N_precision_sent: 0.6523364485981309
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7248182762201454
dev_label=P_precision_sent: 0.6684587813620072
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7445109780439121
dev_precision_macro_sent: 0.6902650766533793
dev_recall_macro_sent: 0.560570508066733
dev_f-score_macro_sent: 0.5066540552188209
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9046449180140548
dev_label=O_recall_tok: 0.9771058315334773
dev_label=O_f-score_tok: 0.9394802420790317
dev_label=N_precision_tok: 0.7927424982554082
dev_label=N_recall_tok: 0.6117393645665051
dev_label=N_f-score_tok: 0.6905775075987842
dev_label=P_precision_tok: 0.9187339606501284
dev_label=P_recall_tok: 0.6687422166874222
dev_label=P_f-score_tok: 0.774054054054054
dev_precision_macro_tok: 0.872040458973197
dev_recall_macro_tok: 0.7525291375958015
dev_f-score_macro_tok: 0.8013706012439566
dev_precision_micro_tok: 0.8986556359875905
dev_recall_micro_tok: 0.8986556359875905
dev_f-score_micro_tok: 0.8986556359875905
dev_time: 2.39286470413208
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0262    0.0506       229
           N     0.6523    0.8154    0.7248       428
           P     0.6685    0.8401    0.7445       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6903    0.5606    0.5067      1101
weighted avg     0.6792    0.6612    0.5925      1101

F1-macro sent:  0.5066540552188209
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9046    0.9771    0.9395     16205
           N     0.7927    0.6117    0.6906      1857
           P     0.9187    0.6687    0.7741      3212

   micro avg     0.8987    0.8987    0.8987     21274
   macro avg     0.8720    0.7525    0.8014     21274
weighted avg     0.8970    0.8987    0.8928     21274

F1-macro tok:  0.8013706012439566
F1-micro tok:  0.8986556359875905
**************************************************
Best epoch: 14
**************************************************

EPOCH: 21
Learning rate: 0.590490
train_cost_sum: 311622.06451416016
train_cost_avg: 36.47261991036519
train_count_sent: 8544.0
train_total_correct_sent: 5812.0
train_accuracy_sent: 0.6802434456928839
train_count_tok: 163566.0
train_total_correct_tok: 146556.0
train_accuracy_tok: 0.8960052822713767
train_label=O_precision_sent: 0.5042372881355932
train_label=O_recall_sent: 0.07327586206896551
train_label=O_f-score_sent: 0.12795698924731183
train_label=N_precision_sent: 0.6542643150519449
train_label=N_recall_sent: 0.8181268882175227
train_label=N_f-score_sent: 0.7270774600617532
train_label=P_precision_sent: 0.7159990405372991
train_label=P_recall_sent: 0.8268698060941828
train_label=P_f-score_sent: 0.7674508291554184
train_precision_macro_sent: 0.624833547908279
train_recall_macro_sent: 0.5727575187935571
train_f-score_macro_sent: 0.5408284261548278
train_precision_micro_sent: 0.6802434456928839
train_recall_micro_sent: 0.6802434456928839
train_f-score_micro_sent: 0.6802434456928839
train_label=O_precision_tok: 0.905309913183929
train_label=O_recall_tok: 0.9736302443967285
train_label=O_f-score_tok: 0.9382279775881711
train_label=N_precision_tok: 0.801190899395663
train_label=N_recall_tok: 0.6347697507393325
train_label=N_f-score_tok: 0.7083366072130118
train_label=P_precision_tok: 0.8864553624280256
train_label=P_recall_tok: 0.6584722388775632
train_label=P_f-score_tok: 0.7556422018348624
train_precision_macro_tok: 0.8643187250025391
train_recall_macro_tok: 0.7556240780045415
train_f-score_macro_tok: 0.8007355955453485
train_precision_micro_tok: 0.8960052822713767
train_recall_micro_tok: 0.8960052822713767
train_f-score_micro_tok: 0.8960052822713767
train_time: 49.834092140197754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5042    0.0733    0.1280      1624
           N     0.6543    0.8181    0.7271      3310
           P     0.7160    0.8269    0.7675      3610

   micro avg     0.6802    0.6802    0.6802      8544
   macro avg     0.6248    0.5728    0.5408      8544
weighted avg     0.6518    0.6802    0.6303      8544

F1-macro sent:  0.5408284261548278
F1-micro sent:  0.6802434456928839
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9053    0.9736    0.9382    124347
           N     0.8012    0.6348    0.7083     14202
           P     0.8865    0.6585    0.7556     25017

   micro avg     0.8960    0.8960    0.8960    163566
   macro avg     0.8643    0.7556    0.8007    163566
weighted avg     0.8934    0.8960    0.8903    163566

F1-macro tok:  0.8007355955453485
F1-micro tok:  0.8960052822713767
**************************************************
dev_cost_sum: 42566.304260253906
dev_cost_avg: 38.66149342439047
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19126.0
dev_accuracy_tok: 0.8990316818651876
dev_label=O_precision_sent: 0.45454545454545453
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.11450381679389313
dev_label=N_precision_sent: 0.6837782340862423
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7278688524590164
dev_label=P_precision_sent: 0.6557659208261618
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7434146341463413
dev_precision_macro_sent: 0.5980298698192862
dev_recall_macro_sent: 0.5672158915639306
dev_f-score_macro_sent: 0.5285957677997503
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9014683372073247
dev_label=O_recall_tok: 0.981240357914224
dev_label=O_f-score_tok: 0.9396643422763266
dev_label=N_precision_tok: 0.8229088168801808
dev_label=N_recall_tok: 0.5880452342487884
dev_label=N_f-score_tok: 0.685929648241206
dev_label=P_precision_tok: 0.9241767764298093
dev_label=P_recall_tok: 0.6640722291407223
dev_label=P_f-score_tok: 0.7728260869565217
dev_precision_macro_tok: 0.8828513101724383
dev_recall_macro_tok: 0.7444526071012448
dev_f-score_macro_tok: 0.799473359158018
dev_precision_micro_tok: 0.8990316818651876
dev_recall_micro_tok: 0.8990316818651876
dev_f-score_micro_tok: 0.8990316818651876
dev_time: 2.384974479675293
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4545    0.0655    0.1145       229
           N     0.6838    0.7780    0.7279       428
           P     0.6558    0.8581    0.7434       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5980    0.5672    0.5286      1101
weighted avg     0.6248    0.6621    0.6066      1101

F1-macro sent:  0.5285957677997503
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9015    0.9812    0.9397     16205
           N     0.8229    0.5880    0.6859      1857
           P     0.9242    0.6641    0.7728      3212

   micro avg     0.8990    0.8990    0.8990     21274
   macro avg     0.8829    0.7445    0.7995     21274
weighted avg     0.8980    0.8990    0.8923     21274

F1-macro tok:  0.799473359158018
F1-micro tok:  0.8990316818651876
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.590490
train_cost_sum: 310503.37561035156
train_cost_avg: 36.341687220312686
train_count_sent: 8544.0
train_total_correct_sent: 5771.0
train_accuracy_sent: 0.6754447565543071
train_count_tok: 163566.0
train_total_correct_tok: 146894.0
train_accuracy_tok: 0.8980717263979067
train_label=O_precision_sent: 0.49230769230769234
train_label=O_recall_sent: 0.07881773399014778
train_label=O_f-score_sent: 0.13588110403397027
train_label=N_precision_sent: 0.6457334611697028
train_label=N_recall_sent: 0.8138972809667674
train_label=N_f-score_sent: 0.7201283079390537
train_label=P_precision_sent: 0.7171692607003891
train_label=P_recall_sent: 0.8168975069252078
train_label=P_f-score_sent: 0.7637917637917637
train_precision_macro_sent: 0.6184034713925947
train_recall_macro_sent: 0.5698708406273744
train_f-score_macro_sent: 0.5399337252549292
train_precision_micro_sent: 0.6754447565543071
train_recall_micro_sent: 0.6754447565543071
train_f-score_micro_sent: 0.6754447565543071
train_label=O_precision_tok: 0.9071078761737881
train_label=O_recall_tok: 0.9741851431880142
train_label=O_f-score_tok: 0.9394506939031909
train_label=N_precision_tok: 0.8031670205237085
train_label=N_recall_tok: 0.6392761582875651
train_label=N_f-score_tok: 0.7119109229200972
train_label=P_precision_tok: 0.8909188034188035
train_label=P_recall_tok: 0.6666666666666666
train_label=P_f-score_tok: 0.7626494729862588
train_precision_macro_tok: 0.8670645667054333
train_recall_macro_tok: 0.7600426560474153
train_f-score_macro_tok: 0.804670363269849
train_precision_micro_tok: 0.8980717263979067
train_recall_micro_tok: 0.8980717263979067
train_f-score_micro_tok: 0.8980717263979067
train_time: 49.50470328330994
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4923    0.0788    0.1359      1624
           N     0.6457    0.8139    0.7201      3310
           P     0.7172    0.8169    0.7638      3610

   micro avg     0.6754    0.6754    0.6754      8544
   macro avg     0.6184    0.5699    0.5399      8544
weighted avg     0.6468    0.6754    0.6275      8544

F1-macro sent:  0.5399337252549292
F1-micro sent:  0.6754447565543071
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9071    0.9742    0.9395    124347
           N     0.8032    0.6393    0.7119     14202
           P     0.8909    0.6667    0.7626     25017

   micro avg     0.8981    0.8981    0.8981    163566
   macro avg     0.8671    0.7600    0.8047    163566
weighted avg     0.8956    0.8981    0.8927    163566

F1-macro tok:  0.804670363269849
F1-micro tok:  0.8980717263979067
**************************************************
dev_cost_sum: 42410.30163574219
dev_cost_avg: 38.51980166734077
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19148.0
dev_accuracy_tok: 0.9000658080285795
dev_label=O_precision_sent: 0.5517241379310345
dev_label=O_recall_sent: 0.06986899563318777
dev_label=O_f-score_sent: 0.12403100775193798
dev_label=N_precision_sent: 0.6463195691202872
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7309644670050761
dev_label=P_precision_sent: 0.7029126213592233
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.7549530761209593
dev_precision_macro_sent: 0.6336521094701816
dev_recall_macro_sent: 0.5754352687585352
dev_f-score_macro_sent: 0.5366495169593245
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9020063477669463
dev_label=O_recall_tok: 0.9821042887997532
dev_label=O_f-score_tok: 0.9403527430647878
dev_label=N_precision_tok: 0.8334612432847276
dev_label=N_recall_tok: 0.5848142164781907
dev_label=N_f-score_tok: 0.6873417721518987
dev_label=P_precision_tok: 0.9226471852170176
dev_label=P_recall_tok: 0.6684308841843088
dev_label=P_f-score_tok: 0.7752301859541433
dev_precision_macro_tok: 0.8860382587562304
dev_recall_macro_tok: 0.7451164631540842
dev_f-score_macro_tok: 0.8009749003902766
dev_precision_micro_tok: 0.9000658080285795
dev_recall_micro_tok: 0.9000658080285795
dev_f-score_micro_tok: 0.9000658080285795
dev_time: 2.38228440284729
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5517    0.0699    0.1240       229
           N     0.6463    0.8411    0.7310       428
           P     0.7029    0.8153    0.7550       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6337    0.5754    0.5366      1101
weighted avg     0.6495    0.6703    0.6144      1101

F1-macro sent:  0.5366495169593245
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9020    0.9821    0.9404     16205
           N     0.8335    0.5848    0.6873      1857
           P     0.9226    0.6684    0.7752      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8860    0.7451    0.8010     21274
weighted avg     0.8991    0.9001    0.8933     21274

F1-macro tok:  0.8009749003902766
F1-micro tok:  0.9000658080285795
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.590490
train_cost_sum: 309207.7491455078
train_cost_avg: 36.19004554605662
train_count_sent: 8544.0
train_total_correct_sent: 5807.0
train_accuracy_sent: 0.6796582397003745
train_count_tok: 163566.0
train_total_correct_tok: 146991.0
train_accuracy_tok: 0.8986647591797806
train_label=O_precision_sent: 0.44715447154471544
train_label=O_recall_sent: 0.06773399014778325
train_label=O_f-score_sent: 0.11764705882352941
train_label=N_precision_sent: 0.6506024096385542
train_label=N_recall_sent: 0.83202416918429
train_label=N_f-score_sent: 0.7302134429272172
train_label=P_precision_sent: 0.7239852398523985
train_label=P_recall_sent: 0.8152354570637119
train_label=P_f-score_sent: 0.7669055374592834
train_precision_macro_sent: 0.6072473736785561
train_recall_macro_sent: 0.5716645387985951
train_f-score_macro_sent: 0.5382553464033434
train_precision_micro_sent: 0.6796582397003745
train_recall_micro_sent: 0.6796582397003745
train_f-score_micro_sent: 0.6796582397003745
train_label=O_precision_tok: 0.9078839853969729
train_label=O_recall_tok: 0.9739599668669128
train_label=O_f-score_tok: 0.9397619343224284
train_label=N_precision_tok: 0.8059780219780219
train_label=N_recall_tok: 0.6455428812843261
train_label=N_f-score_tok: 0.7168940845290691
train_label=P_precision_tok: 0.889326380759817
train_label=P_recall_tok: 0.6681056881320702
train_label=P_f-score_tok: 0.7630047248407933
train_precision_macro_tok: 0.8677294627116039
train_recall_macro_tok: 0.762536178761103
train_f-score_macro_tok: 0.8065535812307636
train_precision_micro_tok: 0.8986647591797806
train_recall_micro_tok: 0.8986647591797806
train_f-score_micro_tok: 0.8986647591797806
train_time: 50.022870779037476
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4472    0.0677    0.1176      1624
           N     0.6506    0.8320    0.7302      3310
           P     0.7240    0.8152    0.7669      3610

   micro avg     0.6797    0.6797    0.6797      8544
   macro avg     0.6072    0.5717    0.5383      8544
weighted avg     0.6429    0.6797    0.6293      8544

F1-macro sent:  0.5382553464033434
F1-micro sent:  0.6796582397003745
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9079    0.9740    0.9398    124347
           N     0.8060    0.6455    0.7169     14202
           P     0.8893    0.6681    0.7630     25017

   micro avg     0.8987    0.8987    0.8987    163566
   macro avg     0.8677    0.7625    0.8066    163566
weighted avg     0.8962    0.8987    0.8934    163566

F1-macro tok:  0.8065535812307636
F1-micro tok:  0.8986647591797806
**************************************************
dev_cost_sum: 42438.80895996094
dev_cost_avg: 38.545693878256984
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 19109.0
dev_accuracy_tok: 0.8982325843752937
dev_label=O_precision_sent: 0.34375
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.0842911877394636
dev_label=N_precision_sent: 0.7018779342723005
dev_label=N_recall_sent: 0.6985981308411215
dev_label=N_f-score_sent: 0.7002341920374707
dev_label=P_precision_sent: 0.6220839813374806
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.7359705611775529
dev_precision_macro_sent: 0.555903971869927
dev_recall_macro_sent: 0.5491779887466129
dev_f-score_macro_sent: 0.5068319803181623
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.9069072520399954
dev_label=O_recall_tok: 0.9738969453872262
dev_label=O_f-score_tok: 0.9392090933436487
dev_label=N_precision_tok: 0.8061737257717158
dev_label=N_recall_tok: 0.6047388260635433
dev_label=N_f-score_tok: 0.6910769230769231
dev_label=P_precision_tok: 0.8890681726502622
dev_label=P_recall_tok: 0.6861768368617683
dev_label=P_f-score_tok: 0.7745563169917413
dev_precision_macro_tok: 0.8673830501539911
dev_recall_macro_tok: 0.7549375361041792
dev_f-score_macro_tok: 0.8016141111374377
dev_precision_micro_tok: 0.8982325843752937
dev_recall_micro_tok: 0.8982325843752937
dev_f-score_micro_tok: 0.8982325843752937
dev_time: 2.3804996013641357
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3438    0.0480    0.0843       229
           N     0.7019    0.6986    0.7002       428
           P     0.6221    0.9009    0.7360       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.5559    0.5492    0.5068      1101
weighted avg     0.5952    0.6449    0.5865      1101

F1-macro sent:  0.5068319803181623
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9069    0.9739    0.9392     16205
           N     0.8062    0.6047    0.6911      1857
           P     0.8891    0.6862    0.7746      3212

   micro avg     0.8982    0.8982    0.8982     21274
   macro avg     0.8674    0.7549    0.8016     21274
weighted avg     0.8954    0.8982    0.8927     21274

F1-macro tok:  0.8016141111374377
F1-micro tok:  0.8982325843752937
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.590490
train_cost_sum: 308337.55419921875
train_cost_avg: 36.08819688661268
train_count_sent: 8544.0
train_total_correct_sent: 5830.0
train_accuracy_sent: 0.6823501872659176
train_count_tok: 163566.0
train_total_correct_tok: 147094.0
train_accuracy_tok: 0.8992944744017706
train_label=O_precision_sent: 0.4562043795620438
train_label=O_recall_sent: 0.0769704433497537
train_label=O_f-score_sent: 0.13171759747102213
train_label=N_precision_sent: 0.6539833531510107
train_label=N_recall_sent: 0.8308157099697885
train_label=N_f-score_sent: 0.7318695941450434
train_label=P_precision_sent: 0.7269372693726938
train_label=P_recall_sent: 0.8185595567867036
train_label=P_f-score_sent: 0.7700325732899024
train_precision_macro_sent: 0.6123750006952494
train_recall_macro_sent: 0.5754485700354152
train_f-score_macro_sent: 0.5445399216353226
train_precision_micro_sent: 0.6823501872659176
train_recall_micro_sent: 0.6823501872659176
train_f-score_micro_sent: 0.6823501872659176
train_label=O_precision_tok: 0.9086053367941725
train_label=O_recall_tok: 0.9740323449701239
train_label=O_f-score_tok: 0.9401819536732285
train_label=N_precision_tok: 0.8089233753637245
train_label=N_recall_tok: 0.645965356991973
train_label=N_f-score_tok: 0.7183181302117997
train_label=P_precision_tok: 0.8878672585077151
train_label=P_recall_tok: 0.6716232961586122
train_label=P_f-score_tok: 0.7647527366241096
train_precision_macro_tok: 0.868465323555204
train_recall_macro_tok: 0.7638736660402364
train_f-score_macro_tok: 0.8077509401697126
train_precision_micro_tok: 0.8992944744017706
train_recall_micro_tok: 0.8992944744017706
train_f-score_micro_tok: 0.8992944744017706
train_time: 49.73448300361633
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4562    0.0770    0.1317      1624
           N     0.6540    0.8308    0.7319      3310
           P     0.7269    0.8186    0.7700      3610

   micro avg     0.6824    0.6824    0.6824      8544
   macro avg     0.6124    0.5754    0.5445      8544
weighted avg     0.6472    0.6824    0.6339      8544

F1-macro sent:  0.5445399216353226
F1-micro sent:  0.6823501872659176
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9086    0.9740    0.9402    124347
           N     0.8089    0.6460    0.7183     14202
           P     0.8879    0.6716    0.7648     25017

   micro avg     0.8993    0.8993    0.8993    163566
   macro avg     0.8685    0.7639    0.8078    163566
weighted avg     0.8968    0.8993    0.8941    163566

F1-macro tok:  0.8077509401697126
F1-micro tok:  0.8992944744017706
**************************************************
dev_cost_sum: 42273.181701660156
dev_cost_avg: 38.395260401144554
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19163.0
dev_accuracy_tok: 0.900770894049074
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06666666666666667
dev_label=N_precision_sent: 0.6278260869565218
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7198404785643071
dev_label=P_precision_sent: 0.6893203883495146
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.740354535974974
dev_precision_macro_sent: 0.6814730675262545
dev_recall_macro_sent: 0.5593139970971257
dev_f-score_macro_sent: 0.508953893735316
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.904859568164986
dev_label=O_recall_tok: 0.9801295896328294
dev_label=O_f-score_tok: 0.9409917649149832
dev_label=N_precision_tok: 0.816400580551524
dev_label=N_recall_tok: 0.6058158319870759
dev_label=N_f-score_tok: 0.6955177743431221
dev_label=P_precision_tok: 0.9197609901835254
dev_label=P_recall_tok: 0.6709215442092155
dev_label=P_f-score_tok: 0.7758775877587759
dev_precision_macro_tok: 0.8803403796333451
dev_recall_macro_tok: 0.7522889886097069
dev_f-score_macro_tok: 0.8041290423389604
dev_precision_micro_tok: 0.900770894049074
dev_recall_micro_tok: 0.900770894049074
dev_f-score_micro_tok: 0.900770894049074
dev_time: 2.3870961666107178
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0349    0.0667       229
           N     0.6278    0.8435    0.7198       428
           P     0.6893    0.7995    0.7404       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6815    0.5593    0.5090      1101
weighted avg     0.6733    0.6576    0.5923      1101

F1-macro sent:  0.508953893735316
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9049    0.9801    0.9410     16205
           N     0.8164    0.6058    0.6955      1857
           P     0.9198    0.6709    0.7759      3212

   micro avg     0.9008    0.9008    0.9008     21274
   macro avg     0.8803    0.7523    0.8041     21274
weighted avg     0.8994    0.9008    0.8946     21274

F1-macro tok:  0.8041290423389604
F1-micro tok:  0.900770894049074
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.590490
train_cost_sum: 307140.49981689453
train_cost_avg: 35.94809220703353
train_count_sent: 8544.0
train_total_correct_sent: 5821.0
train_accuracy_sent: 0.6812968164794008
train_count_tok: 163566.0
train_total_correct_tok: 147301.0
train_accuracy_tok: 0.9005600185857696
train_label=O_precision_sent: 0.5166666666666667
train_label=O_recall_sent: 0.07635467980295567
train_label=O_f-score_sent: 0.13304721030042918
train_label=N_precision_sent: 0.6511850610485995
train_label=N_recall_sent: 0.8217522658610272
train_label=N_f-score_sent: 0.7265927607853613
train_label=P_precision_sent: 0.7213472255875939
train_label=P_recall_sent: 0.8246537396121884
train_label=P_f-score_sent: 0.7695489207703244
train_precision_macro_sent: 0.6297329844342867
train_recall_macro_sent: 0.5742535617587238
train_f-score_macro_sent: 0.5430629639520382
train_precision_micro_sent: 0.6812968164794008
train_recall_micro_sent: 0.6812968164794008
train_f-score_micro_sent: 0.6812968164794008
train_label=O_precision_tok: 0.9106478034251675
train_label=O_recall_tok: 0.9737026224999397
train_label=O_f-score_tok: 0.9411202313217051
train_label=N_precision_tok: 0.8060684872128305
train_label=N_recall_tok: 0.6546965216166737
train_label=N_f-score_tok: 0.7225395345222831
train_label=P_precision_tok: 0.8873859704309531
train_label=P_recall_tok: 0.6765799256505576
train_label=P_f-score_tok: 0.7677757365448731
train_precision_macro_tok: 0.8680340870229837
train_recall_macro_tok: 0.768326356589057
train_f-score_macro_tok: 0.810478500796287
train_precision_micro_tok: 0.9005600185857696
train_recall_micro_tok: 0.9005600185857696
train_f-score_micro_tok: 0.9005600185857696
train_time: 49.79561710357666
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5167    0.0764    0.1330      1624
           N     0.6512    0.8218    0.7266      3310
           P     0.7213    0.8247    0.7695      3610

   micro avg     0.6813    0.6813    0.6813      8544
   macro avg     0.6297    0.5743    0.5431      8544
weighted avg     0.6553    0.6813    0.6319      8544

F1-macro sent:  0.5430629639520382
F1-micro sent:  0.6812968164794008
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9106    0.9737    0.9411    124347
           N     0.8061    0.6547    0.7225     14202
           P     0.8874    0.6766    0.7678     25017

   micro avg     0.9006    0.9006    0.9006    163566
   macro avg     0.8680    0.7683    0.8105    163566
weighted avg     0.8980    0.9006    0.8956    163566

F1-macro tok:  0.810478500796287
F1-micro tok:  0.9005600185857696
**************************************************
dev_cost_sum: 42217.548278808594
dev_cost_avg: 38.344730498463754
dev_count_sent: 1101.0
dev_total_correct_sent: 734.0
dev_accuracy_sent: 0.6666666666666666
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.72
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.14173228346456695
dev_label=N_precision_sent: 0.70509977827051
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7235494880546075
dev_label=P_precision_sent: 0.6368
dev_label=P_recall_sent: 0.8963963963963963
dev_label=P_f-score_sent: 0.744621141253508
dev_precision_macro_sent: 0.6872999260901699
dev_recall_macro_sent: 0.5726632235631134
dev_f-score_macro_sent: 0.5366343042575609
dev_precision_micro_sent: 0.6666666666666666
dev_recall_micro_sent: 0.6666666666666666
dev_f-score_micro_sent: 0.6666666666666666
dev_label=O_precision_tok: 0.9051315714367258
dev_label=O_recall_tok: 0.9785251465597038
dev_label=O_f-score_tok: 0.9403985292373385
dev_label=N_precision_tok: 0.8037116345467523
dev_label=N_recall_tok: 0.6063543349488422
dev_label=N_f-score_tok: 0.6912216083486802
dev_label=P_precision_tok: 0.9201359388275276
dev_label=P_recall_tok: 0.674346201743462
dev_label=P_f-score_tok: 0.7782968020122171
dev_precision_macro_tok: 0.8763263816036687
dev_recall_macro_tok: 0.7530752277506693
dev_f-score_macro_tok: 0.8033056465327452
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 2.383333921432495
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7200    0.0786    0.1417       229
           N     0.7051    0.7430    0.7235       428
           P     0.6368    0.8964    0.7446       444

   micro avg     0.6667    0.6667    0.6667      1101
   macro avg     0.6873    0.5727    0.5366      1101
weighted avg     0.6807    0.6667    0.6110      1101

F1-macro sent:  0.5366343042575609
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9051    0.9785    0.9404     16205
           N     0.8037    0.6064    0.6912      1857
           P     0.9201    0.6743    0.7783      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8763    0.7531    0.8033     21274
weighted avg     0.8985    0.9001    0.8942     21274

F1-macro tok:  0.8033056465327452
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 22
**************************************************

EPOCH: 26
Learning rate: 0.590490
train_cost_sum: 306064.28826904297
train_cost_avg: 35.822131117631436
train_count_sent: 8544.0
train_total_correct_sent: 5855.0
train_accuracy_sent: 0.6852762172284644
train_count_tok: 163566.0
train_total_correct_tok: 147342.0
train_accuracy_tok: 0.9008106819265618
train_label=O_precision_sent: 0.46496815286624205
train_label=O_recall_sent: 0.08990147783251232
train_label=O_f-score_sent: 0.15067079463364294
train_label=N_precision_sent: 0.6616247865333008
train_label=N_recall_sent: 0.8193353474320242
train_label=N_f-score_sent: 0.7320826022405184
train_label=P_precision_sent: 0.7254901960784313
train_label=P_recall_sent: 0.8301939058171746
train_label=P_f-score_sent: 0.7743185634930887
train_precision_macro_sent: 0.6173610451593247
train_recall_macro_sent: 0.5798102436939038
train_f-score_macro_sent: 0.5523573201224167
train_precision_micro_sent: 0.6852762172284644
train_recall_micro_sent: 0.6852762172284644
train_f-score_micro_sent: 0.6852762172284644
train_label=O_precision_tok: 0.9107326869701916
train_label=O_recall_tok: 0.9737347905458114
train_label=O_f-score_tok: 0.9411805857844661
train_label=N_precision_tok: 0.8073867109054397
train_label=N_recall_tok: 0.6511054781016758
train_label=N_f-score_tok: 0.7208731241473398
train_label=P_precision_tok: 0.8878104779795449
train_label=P_recall_tok: 0.6800975336770996
train_label=P_f-score_tok: 0.7701953328353817
train_precision_macro_tok: 0.8686432919517254
train_recall_macro_tok: 0.7683126007748623
train_f-score_macro_tok: 0.8107496809223959
train_precision_micro_tok: 0.9008106819265618
train_recall_micro_tok: 0.9008106819265618
train_f-score_micro_tok: 0.9008106819265618
train_time: 49.89308190345764
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4650    0.0899    0.1507      1624
           N     0.6616    0.8193    0.7321      3310
           P     0.7255    0.8302    0.7743      3610

   micro avg     0.6853    0.6853    0.6853      8544
   macro avg     0.6174    0.5798    0.5524      8544
weighted avg     0.6512    0.6853    0.6394      8544

F1-macro sent:  0.5523573201224167
F1-micro sent:  0.6852762172284644
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9107    0.9737    0.9412    124347
           N     0.8074    0.6511    0.7209     14202
           P     0.8878    0.6801    0.7702     25017

   micro avg     0.9008    0.9008    0.9008    163566
   macro avg     0.8686    0.7683    0.8107    163566
weighted avg     0.8983    0.9008    0.8959    163566

F1-macro tok:  0.8107496809223959
F1-micro tok:  0.9008106819265618
**************************************************
dev_cost_sum: 42134.44989013672
dev_cost_avg: 38.26925512273998
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19152.0
dev_accuracy_tok: 0.900253830967378
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6273504273504273
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7245804540967424
dev_label=P_precision_sent: 0.6996047430830039
dev_label=P_recall_sent: 0.7972972972972973
dev_label=P_f-score_sent: 0.7452631578947368
dev_precision_macro_sent: 0.6756517234778103
dev_recall_macro_sent: 0.5617805394669452
dev_f-score_macro_sent: 0.5094736726164066
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9079944865609925
dev_label=O_recall_tok: 0.9756248071582845
dev_label=O_f-score_tok: 0.9405955320224888
dev_label=N_precision_tok: 0.8039631988676574
dev_label=N_recall_tok: 0.6117393645665051
dev_label=N_f-score_tok: 0.6948012232415902
dev_label=P_precision_tok: 0.9007758268681094
dev_label=P_recall_tok: 0.686799501867995
dev_label=P_f-score_tok: 0.7793676028970148
dev_precision_macro_tok: 0.8709111707655864
dev_recall_macro_tok: 0.7580545578642615
dev_f-score_macro_tok: 0.8049214527203645
dev_precision_micro_tok: 0.900253830967378
dev_recall_micro_tok: 0.900253830967378
dev_f-score_micro_tok: 0.900253830967378
dev_time: 2.4060328006744385
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6274    0.8575    0.7246       428
           P     0.6996    0.7973    0.7453       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6757    0.5618    0.5095      1101
weighted avg     0.6716    0.6612    0.5944      1101

F1-macro sent:  0.5094736726164066
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9756    0.9406     16205
           N     0.8040    0.6117    0.6948      1857
           P     0.9008    0.6868    0.7794      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8709    0.7581    0.8049     21274
weighted avg     0.8978    0.9003    0.8948     21274

F1-macro tok:  0.8049214527203645
F1-micro tok:  0.900253830967378
**************************************************
Best epoch: 22
**************************************************

EPOCH: 27
Learning rate: 0.531441
train_cost_sum: 304870.95782470703
train_cost_avg: 35.682462292217586
train_count_sent: 8544.0
train_total_correct_sent: 5872.0
train_accuracy_sent: 0.6872659176029963
train_count_tok: 163566.0
train_total_correct_tok: 147616.0
train_accuracy_tok: 0.9024858466918553
train_label=O_precision_sent: 0.52
train_label=O_recall_sent: 0.06403940886699508
train_label=O_f-score_sent: 0.11403508771929825
train_label=N_precision_sent: 0.6517586769159096
train_label=N_recall_sent: 0.8453172205438066
train_label=N_f-score_sent: 0.7360252531895304
train_label=P_precision_sent: 0.733152308072081
train_label=P_recall_sent: 0.8227146814404432
train_label=P_f-score_sent: 0.7753556976895967
train_precision_macro_sent: 0.6349703283293302
train_recall_macro_sent: 0.5773571036170817
train_f-score_macro_sent: 0.5418053461994751
train_precision_micro_sent: 0.6872659176029963
train_recall_micro_sent: 0.6872659176029963
train_f-score_micro_sent: 0.6872659176029963
train_label=O_precision_tok: 0.9119446681367642
train_label=O_recall_tok: 0.974458571577923
train_label=O_f-score_tok: 0.9421657893304511
train_label=N_precision_tok: 0.8138297872340425
train_label=N_recall_tok: 0.6571609632446135
train_label=N_f-score_tok: 0.7271523178807946
train_label=P_precision_tok: 0.88999843969418
train_label=P_recall_tok: 0.6840148698884758
train_label=P_f-score_tok: 0.7735286140493626
train_precision_macro_tok: 0.8719242983549956
train_recall_macro_tok: 0.7718781349036709
train_f-score_macro_tok: 0.8142822404202028
train_precision_micro_tok: 0.9024858466918553
train_recall_micro_tok: 0.9024858466918553
train_f-score_micro_tok: 0.9024858466918553
train_time: 49.86390495300293
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5200    0.0640    0.1140      1624
           N     0.6518    0.8453    0.7360      3310
           P     0.7332    0.8227    0.7754      3610

   micro avg     0.6873    0.6873    0.6873      8544
   macro avg     0.6350    0.5774    0.5418      8544
weighted avg     0.6611    0.6873    0.6344      8544

F1-macro sent:  0.5418053461994751
F1-micro sent:  0.6872659176029963
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9745    0.9422    124347
           N     0.8138    0.6572    0.7272     14202
           P     0.8900    0.6840    0.7735     25017

   micro avg     0.9025    0.9025    0.9025    163566
   macro avg     0.8719    0.7719    0.8143    163566
weighted avg     0.9001    0.9025    0.8977    163566

F1-macro tok:  0.8142822404202028
F1-micro tok:  0.9024858466918553
**************************************************
dev_cost_sum: 42175.04510498047
dev_cost_avg: 38.306126344214775
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.5151515151515151
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.1297709923664122
dev_label=N_precision_sent: 0.6355785837651122
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.730883813306852
dev_label=P_precision_sent: 0.7096114519427403
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7438370846730976
dev_precision_macro_sent: 0.6201138502864559
dev_recall_macro_sent: 0.571860141167981
dev_f-score_macro_sent: 0.534830630115454
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9069368131868132
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9410576951628707
dev_label=N_precision_tok: 0.8002773925104022
dev_label=N_recall_tok: 0.6214324178782983
dev_label=N_f-score_tok: 0.6996059411943013
dev_label=P_precision_tok: 0.9194915254237288
dev_label=P_recall_tok: 0.6755915317559154
dev_label=P_f-score_tok: 0.778894472361809
dev_precision_macro_tok: 0.8755685770403147
dev_recall_macro_tok: 0.7582900977850958
dev_f-score_macro_tok: 0.8065193695729936
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 2.382251024246216
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5152    0.0742    0.1298       229
           N     0.6356    0.8598    0.7309       428
           P     0.7096    0.7815    0.7438       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.6201    0.5719    0.5348      1101
weighted avg     0.6404    0.6649    0.6111      1101

F1-macro sent:  0.534830630115454
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9069    0.9778    0.9411     16205
           N     0.8003    0.6214    0.6996      1857
           P     0.9195    0.6756    0.7789      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8756    0.7583    0.8065     21274
weighted avg     0.8995    0.9011    0.8955     21274

F1-macro tok:  0.8065193695729936
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 22
**************************************************

EPOCH: 28
Learning rate: 0.478297
train_cost_sum: 303749.68591308594
train_cost_avg: 35.55122728383496
train_count_sent: 8544.0
train_total_correct_sent: 5914.0
train_accuracy_sent: 0.6921816479400749
train_count_tok: 163566.0
train_total_correct_tok: 147721.0
train_accuracy_tok: 0.9031277893938838
train_label=O_precision_sent: 0.5019607843137255
train_label=O_recall_sent: 0.07881773399014778
train_label=O_f-score_sent: 0.13624268227780734
train_label=N_precision_sent: 0.6641056422569027
train_label=N_recall_sent: 0.8356495468277946
train_label=N_f-score_sent: 0.7400668896321071
train_label=P_precision_sent: 0.7322987390882638
train_label=P_recall_sent: 0.8365650969529086
train_label=P_f-score_sent: 0.7809671580036204
train_precision_macro_sent: 0.632788388552964
train_recall_macro_sent: 0.5836774592569504
train_f-score_macro_sent: 0.552425576637845
train_precision_micro_sent: 0.6921816479400749
train_recall_micro_sent: 0.6921816479400749
train_f-score_micro_sent: 0.6921816479400749
train_label=O_precision_tok: 0.913862403481467
train_label=O_recall_tok: 0.9727375811237907
train_label=O_f-score_tok: 0.9423813326581095
train_label=N_precision_tok: 0.8105674481821271
train_label=N_recall_tok: 0.6718772003943106
train_label=N_f-score_tok: 0.7347347347347347
train_label=P_precision_tok: 0.8860876723605681
train_label=P_recall_tok: 0.6884118799216533
train_label=P_f-score_tok: 0.7748408431376961
train_precision_macro_tok: 0.870172508008054
train_recall_macro_tok: 0.7776755538132516
train_f-score_macro_tok: 0.8173189701768467
train_precision_micro_tok: 0.9031277893938838
train_recall_micro_tok: 0.9031277893938838
train_f-score_micro_tok: 0.9031277893938838
train_time: 49.657912254333496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5020    0.0788    0.1362      1624
           N     0.6641    0.8356    0.7401      3310
           P     0.7323    0.8366    0.7810      3610

   micro avg     0.6922    0.6922    0.6922      8544
   macro avg     0.6328    0.5837    0.5524      8544
weighted avg     0.6621    0.6922    0.6426      8544

F1-macro sent:  0.552425576637845
F1-micro sent:  0.6921816479400749
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9139    0.9727    0.9424    124347
           N     0.8106    0.6719    0.7347     14202
           P     0.8861    0.6884    0.7748     25017

   micro avg     0.9031    0.9031    0.9031    163566
   macro avg     0.8702    0.7777    0.8173    163566
weighted avg     0.9006    0.9031    0.8987    163566

F1-macro tok:  0.8173189701768467
F1-micro tok:  0.9031277893938838
**************************************************
dev_cost_sum: 42139.810546875
dev_cost_avg: 38.27412402077657
dev_count_sent: 1101.0
dev_total_correct_sent: 746.0
dev_accuracy_sent: 0.6775658492279746
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.6071428571428571
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.132295719844358
dev_label=N_precision_sent: 0.6524822695035462
dev_label=N_recall_sent: 0.8598130841121495
dev_label=N_f-score_sent: 0.7419354838709677
dev_label=P_precision_sent: 0.7092337917485265
dev_label=P_recall_sent: 0.8130630630630631
dev_label=P_f-score_sent: 0.7576075550891921
dev_precision_macro_sent: 0.6562863061316433
dev_recall_macro_sent: 0.5823706516784916
dev_f-score_macro_sent: 0.5439462529348392
dev_precision_micro_sent: 0.6775658492279746
dev_recall_micro_sent: 0.6775658492279746
dev_f-score_micro_sent: 0.6775658492279746
dev_label=O_precision_tok: 0.9057962730078885
dev_label=O_recall_tok: 0.9778463437210737
dev_label=O_f-score_tok: 0.9404433365975251
dev_label=N_precision_tok: 0.8129963898916968
dev_label=N_recall_tok: 0.6063543349488422
dev_label=N_f-score_tok: 0.6946329426280075
dev_label=P_precision_tok: 0.9089770354906054
dev_label=P_recall_tok: 0.6777708592777086
dev_label=P_f-score_tok: 0.7765293383270911
dev_precision_macro_tok: 0.8759232327967301
dev_recall_macro_tok: 0.7539905126492082
dev_f-score_macro_tok: 0.803868539184208
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 2.365605115890503
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6071    0.0742    0.1323       229
           N     0.6525    0.8598    0.7419       428
           P     0.7092    0.8131    0.7576       444

   micro avg     0.6776    0.6776    0.6776      1101
   macro avg     0.6563    0.5824    0.5439      1101
weighted avg     0.6659    0.6776    0.6215      1101

F1-macro sent:  0.5439462529348392
F1-micro sent:  0.6775658492279746
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9778    0.9404     16205
           N     0.8130    0.6064    0.6946      1857
           P     0.9090    0.6778    0.7765      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8759    0.7540    0.8039     21274
weighted avg     0.8982    0.9001    0.8942     21274

F1-macro tok:  0.803868539184208
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.478297
train_cost_sum: 303175.00408935547
train_cost_avg: 35.48396583442831
train_count_sent: 8544.0
train_total_correct_sent: 5908.0
train_accuracy_sent: 0.6914794007490637
train_count_tok: 163566.0
train_total_correct_tok: 147836.0
train_accuracy_tok: 0.9038308694961056
train_label=O_precision_sent: 0.5055350553505535
train_label=O_recall_sent: 0.08435960591133004
train_label=O_f-score_sent: 0.14459102902374668
train_label=N_precision_sent: 0.6516233018650702
train_label=N_recall_sent: 0.8549848942598187
train_label=N_f-score_sent: 0.7395792499673332
train_label=P_precision_sent: 0.7483460559796438
train_label=P_recall_sent: 0.8146814404432133
train_label=P_f-score_sent: 0.7801061007957562
train_precision_macro_sent: 0.6351681377317558
train_recall_macro_sent: 0.5846753135381207
train_f-score_macro_sent: 0.5547587932622786
train_precision_micro_sent: 0.6914794007490637
train_recall_micro_sent: 0.6914794007490637
train_f-score_micro_sent: 0.6914794007490637
train_label=O_precision_tok: 0.9146287070705543
train_label=O_recall_tok: 0.9729868834792958
train_label=O_f-score_tok: 0.9429056844927287
train_label=N_precision_tok: 0.8114844746916205
train_label=N_recall_tok: 0.6716659625404873
train_label=N_f-score_tok: 0.734984782524945
train_label=P_precision_tok: 0.8862775217613927
train_label=P_recall_tok: 0.6918895151297118
train_label=P_f-score_tok: 0.7771118144880688
train_precision_macro_tok: 0.8707969011745226
train_recall_macro_tok: 0.7788474537164983
train_f-score_macro_tok: 0.8183340938352476
train_precision_micro_tok: 0.9038308694961056
train_recall_micro_tok: 0.9038308694961056
train_f-score_micro_tok: 0.9038308694961056
train_time: 49.7850387096405
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5055    0.0844    0.1446      1624
           N     0.6516    0.8550    0.7396      3310
           P     0.7483    0.8147    0.7801      3610

   micro avg     0.6915    0.6915    0.6915      8544
   macro avg     0.6352    0.5847    0.5548      8544
weighted avg     0.6647    0.6915    0.6436      8544

F1-macro sent:  0.5547587932622786
F1-micro sent:  0.6914794007490637
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9146    0.9730    0.9429    124347
           N     0.8115    0.6717    0.7350     14202
           P     0.8863    0.6919    0.7771     25017

   micro avg     0.9038    0.9038    0.9038    163566
   macro avg     0.8708    0.7788    0.8183    163566
weighted avg     0.9013    0.9038    0.8995    163566

F1-macro tok:  0.8183340938352476
F1-micro tok:  0.9038308694961056
**************************************************
dev_cost_sum: 42025.585021972656
dev_cost_avg: 38.170376950020575
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19161.0
dev_accuracy_tok: 0.9006768825796747
dev_label=O_precision_sent: 0.42857142857142855
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13284132841328414
dev_label=N_precision_sent: 0.6699604743083004
dev_label=N_recall_sent: 0.7920560747663551
dev_label=N_f-score_sent: 0.7259100642398287
dev_label=P_precision_sent: 0.6781193490054249
dev_label=P_recall_sent: 0.8445945945945946
dev_label=P_f-score_sent: 0.7522567703109327
dev_precision_macro_sent: 0.5922170839617179
dev_recall_macro_sent: 0.571751096482762
dev_f-score_macro_sent: 0.5370027209880152
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9099452291726723
dev_label=O_recall_tok: 0.9739586547361926
dev_label=O_f-score_tok: 0.9408643815201193
dev_label=N_precision_tok: 0.8044537230340988
dev_label=N_recall_tok: 0.6225094238018309
dev_label=N_f-score_tok: 0.7018822100789314
dev_label=P_precision_tok: 0.891653290529695
dev_label=P_recall_tok: 0.6917808219178082
dev_label=P_f-score_tok: 0.7791023842917251
dev_precision_macro_tok: 0.8686840809121553
dev_recall_macro_tok: 0.7627496334852771
dev_f-score_macro_tok: 0.807282991963592
dev_precision_micro_tok: 0.9006768825796747
dev_recall_micro_tok: 0.9006768825796747
dev_f-score_micro_tok: 0.9006768825796747
dev_time: 2.3658323287963867
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0786    0.1328       229
           N     0.6700    0.7921    0.7259       428
           P     0.6781    0.8446    0.7523       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.5922    0.5718    0.5370      1101
weighted avg     0.6230    0.6649    0.6132      1101

F1-macro sent:  0.5370027209880152
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9099    0.9740    0.9409     16205
           N     0.8045    0.6225    0.7019      1857
           P     0.8917    0.6918    0.7791      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8687    0.7627    0.8073     21274
weighted avg     0.8980    0.9007    0.8956     21274

F1-macro tok:  0.807282991963592
F1-micro tok:  0.9006768825796747
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.478297
train_cost_sum: 302191.8165283203
train_cost_avg: 35.36889238393262
train_count_sent: 8544.0
train_total_correct_sent: 5933.0
train_accuracy_sent: 0.6944054307116105
train_count_tok: 163566.0
train_total_correct_tok: 148011.0
train_accuracy_tok: 0.9049007739994864
train_label=O_precision_sent: 0.4818181818181818
train_label=O_recall_sent: 0.0979064039408867
train_label=O_f-score_sent: 0.16274309109518936
train_label=N_precision_sent: 0.6627601052379813
train_label=N_recall_sent: 0.8371601208459214
train_label=N_f-score_sent: 0.7398211186757442
train_label=P_precision_sent: 0.7446069923134143
train_label=P_recall_sent: 0.8318559556786703
train_label=P_f-score_sent: 0.7858170875310742
train_precision_macro_sent: 0.6297284264565258
train_recall_macro_sent: 0.5889741601551595
train_f-score_macro_sent: 0.5627937657673359
train_precision_micro_sent: 0.6944054307116105
train_recall_micro_sent: 0.6944054307116105
train_f-score_micro_sent: 0.6944054307116105
train_label=O_precision_tok: 0.91563620953217
train_label=O_recall_tok: 0.9730351355481033
train_label=O_f-score_tok: 0.943463462370706
train_label=N_precision_tok: 0.8134517766497462
train_label=N_recall_tok: 0.6770173215040135
train_label=N_f-score_tok: 0.7389900853124279
train_label=P_precision_tok: 0.8876759844929606
train_label=P_recall_tok: 0.6956069872486709
train_label=P_f-score_tok: 0.7799914838304834
train_precision_macro_tok: 0.8722546568916255
train_recall_macro_tok: 0.7818864814335958
train_f-score_macro_tok: 0.8208150105045391
train_precision_micro_tok: 0.9049007739994864
train_recall_micro_tok: 0.9049007739994864
train_f-score_micro_tok: 0.9049007739994864
train_time: 49.79815411567688
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4818    0.0979    0.1627      1624
           N     0.6628    0.8372    0.7398      3310
           P     0.7446    0.8319    0.7858      3610

   micro avg     0.6944    0.6944    0.6944      8544
   macro avg     0.6297    0.5890    0.5628      8544
weighted avg     0.6629    0.6944    0.6496      8544

F1-macro sent:  0.5627937657673359
F1-micro sent:  0.6944054307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9156    0.9730    0.9435    124347
           N     0.8135    0.6770    0.7390     14202
           P     0.8877    0.6956    0.7800     25017

   micro avg     0.9049    0.9049    0.9049    163566
   macro avg     0.8723    0.7819    0.8208    163566
weighted avg     0.9025    0.9049    0.9007    163566

F1-macro tok:  0.8208150105045391
F1-micro tok:  0.9049007739994864
**************************************************
dev_cost_sum: 42069.28356933594
dev_cost_avg: 38.21006682046861
dev_count_sent: 1101.0
dev_total_correct_sent: 744.0
dev_accuracy_sent: 0.6757493188010899
dev_count_tok: 21274.0
dev_total_correct_tok: 19162.0
dev_accuracy_tok: 0.9007238883143743
dev_label=O_precision_sent: 0.7058823529411765
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0975609756097561
dev_label=N_precision_sent: 0.6605504587155964
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7399794450154163
dev_label=P_precision_sent: 0.6901669758812616
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7568667344862666
dev_precision_macro_sent: 0.6855332625126782
dev_recall_macro_sent: 0.5771203599632772
dev_f-score_macro_sent: 0.5314690517038131
dev_precision_micro_sent: 0.6757493188010899
dev_recall_micro_sent: 0.6757493188010899
dev_f-score_micro_sent: 0.6757493188010899
dev_label=O_precision_tok: 0.9058447123350283
dev_label=O_recall_tok: 0.978401727861771
dev_label=O_f-score_tok: 0.9407262370950515
dev_label=N_precision_tok: 0.8323262839879154
dev_label=N_recall_tok: 0.5934302638664513
dev_label=N_f-score_tok: 0.6928638792832443
dev_label=P_precision_tok: 0.9011033919084593
dev_label=P_recall_tok: 0.6864881693648817
dev_label=P_f-score_tok: 0.7792896271426047
dev_precision_macro_tok: 0.8797581294104676
dev_recall_macro_tok: 0.7527733870310346
dev_f-score_macro_tok: 0.8042932478403002
dev_precision_micro_tok: 0.9007238883143743
dev_recall_micro_tok: 0.9007238883143743
dev_f-score_micro_tok: 0.9007238883143743
dev_time: 2.3792355060577393
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7059    0.0524    0.0976       229
           N     0.6606    0.8411    0.7400       428
           P     0.6902    0.8378    0.7569       444

   micro avg     0.6757    0.6757    0.6757      1101
   macro avg     0.6855    0.5771    0.5315      1101
weighted avg     0.6819    0.6757    0.6132      1101

F1-macro sent:  0.5314690517038131
F1-micro sent:  0.6757493188010899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9784    0.9407     16205
           N     0.8323    0.5934    0.6929      1857
           P     0.9011    0.6865    0.7793      3212

   micro avg     0.9007    0.9007    0.9007     21274
   macro avg     0.8798    0.7528    0.8043     21274
weighted avg     0.8987    0.9007    0.8947     21274

F1-macro tok:  0.8042932478403002
F1-micro tok:  0.9007238883143743
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.478297
train_cost_sum: 301236.55194091797
train_cost_avg: 35.257087071736656
train_count_sent: 8544.0
train_total_correct_sent: 5928.0
train_accuracy_sent: 0.6938202247191011
train_count_tok: 163566.0
train_total_correct_tok: 148193.0
train_accuracy_tok: 0.9060134746830025
train_label=O_precision_sent: 0.4965277777777778
train_label=O_recall_sent: 0.08805418719211823
train_label=O_f-score_sent: 0.149581589958159
train_label=N_precision_sent: 0.6592993181283799
train_label=N_recall_sent: 0.8471299093655589
train_label=N_f-score_sent: 0.7415046939045352
train_label=P_precision_sent: 0.7446914813889582
train_label=P_recall_sent: 0.8257617728531856
train_label=P_f-score_sent: 0.7831341127019572
train_precision_macro_sent: 0.6335061924317053
train_recall_macro_sent: 0.5869819564702876
train_f-score_macro_sent: 0.5580734655215505
train_precision_micro_sent: 0.6938202247191011
train_recall_micro_sent: 0.6938202247191011
train_f-score_micro_sent: 0.6938202247191011
train_label=O_precision_tok: 0.9169003410382721
train_label=O_recall_tok: 0.9729627574448921
train_label=O_f-score_tok: 0.9441000089739638
train_label=N_precision_tok: 0.8180971728457762
train_label=N_recall_tok: 0.6805379524010703
train_label=N_f-score_tok: 0.7430043050430505
train_label=P_precision_tok: 0.8859206140793859
train_label=P_recall_tok: 0.7012431546548347
train_label=P_f-score_tok: 0.7828376358240925
train_precision_macro_tok: 0.8736393759878114
train_recall_macro_tok: 0.7849146215002657
train_f-score_macro_tok: 0.8233139832803689
train_precision_micro_tok: 0.9060134746830025
train_recall_micro_tok: 0.9060134746830025
train_f-score_micro_tok: 0.9060134746830025
train_time: 49.8479483127594
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4965    0.0881    0.1496      1624
           N     0.6593    0.8471    0.7415      3310
           P     0.7447    0.8258    0.7831      3610

   micro avg     0.6938    0.6938    0.6938      8544
   macro avg     0.6335    0.5870    0.5581      8544
weighted avg     0.6644    0.6938    0.6466      8544

F1-macro sent:  0.5580734655215505
F1-micro sent:  0.6938202247191011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9169    0.9730    0.9441    124347
           N     0.8181    0.6805    0.7430     14202
           P     0.8859    0.7012    0.7828     25017

   micro avg     0.9060    0.9060    0.9060    163566
   macro avg     0.8736    0.7849    0.8233    163566
weighted avg     0.9036    0.9060    0.9020    163566

F1-macro tok:  0.8233139832803689
F1-micro tok:  0.9060134746830025
**************************************************
dev_cost_sum: 42112.606872558594
dev_cost_avg: 38.24941586971716
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19175.0
dev_accuracy_tok: 0.9013349628654695
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1509433962264151
dev_label=N_precision_sent: 0.664179104477612
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7385892116182573
dev_label=P_precision_sent: 0.6899810964083176
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7502569373072971
dev_precision_macro_sent: 0.6365719188138285
dev_recall_macro_sent: 0.5803946725160455
dev_f-score_macro_sent: 0.5465965150506565
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.906258931123178
dev_label=O_recall_tok: 0.978401727861771
dev_label=O_f-score_tok: 0.9409495548961424
dev_label=N_precision_tok: 0.8270787343635025
dev_label=N_recall_tok: 0.6052773290253096
dev_label=N_f-score_tok: 0.6990049751243782
dev_label=P_precision_tok: 0.9074380165289256
dev_label=P_recall_tok: 0.6836861768368617
dev_label=P_f-score_tok: 0.7798295454545455
dev_precision_macro_tok: 0.8802585606718688
dev_recall_macro_tok: 0.7557884112413141
dev_f-score_macro_tok: 0.8065946918250221
dev_precision_micro_tok: 0.9013349628654695
dev_recall_micro_tok: 0.9013349628654695
dev_f-score_micro_tok: 0.9013349628654695
dev_time: 2.3787708282470703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0873    0.1509       229
           N     0.6642    0.8318    0.7386       428
           P     0.6900    0.8221    0.7503       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6366    0.5804    0.5466      1101
weighted avg     0.6520    0.6730    0.6211      1101

F1-macro sent:  0.5465965150506565
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9784    0.9409     16205
           N     0.8271    0.6053    0.6990      1857
           P     0.9074    0.6837    0.7798      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8803    0.7558    0.8066     21274
weighted avg     0.8995    0.9013    0.8955     21274

F1-macro tok:  0.8065946918250221
F1-micro tok:  0.9013349628654695
**************************************************
Best epoch: 31
**************************************************

EPOCH: 32
Learning rate: 0.478297
train_cost_sum: 300608.3972167969
train_cost_avg: 35.183567089980905
train_count_sent: 8544.0
train_total_correct_sent: 5962.0
train_accuracy_sent: 0.6977996254681648
train_count_tok: 163566.0
train_total_correct_tok: 148364.0
train_accuracy_tok: 0.9070589242263062
train_label=O_precision_sent: 0.5277777777777778
train_label=O_recall_sent: 0.08189655172413793
train_label=O_f-score_sent: 0.1417910447761194
train_label=N_precision_sent: 0.6574095682613769
train_label=N_recall_sent: 0.8510574018126889
train_label=N_f-score_sent: 0.7418038183015141
train_label=P_precision_sent: 0.7516845520339406
train_label=P_recall_sent: 0.8343490304709141
train_label=P_f-score_sent: 0.790862544308783
train_precision_macro_sent: 0.6456239660243651
train_recall_macro_sent: 0.589100994669247
train_f-score_macro_sent: 0.5581524691288055
train_precision_micro_sent: 0.6977996254681648
train_recall_micro_sent: 0.6977996254681648
train_f-score_micro_sent: 0.6977996254681648
train_label=O_precision_tok: 0.9184390969907285
train_label=O_recall_tok: 0.9726973710664512
train_label=O_f-score_tok: 0.944789876581784
train_label=N_precision_tok: 0.8159519439345904
train_label=N_recall_tok: 0.6886354034643009
train_label=N_f-score_tok: 0.7469069802963189
train_label=P_precision_tok: 0.8866093427867451
train_label=P_recall_tok: 0.7048007354998601
train_label=P_f-score_tok: 0.7853197933368964
train_precision_macro_tok: 0.873666794570688
train_recall_macro_tok: 0.788711170010204
train_f-score_macro_tok: 0.8256722167383331
train_precision_micro_tok: 0.9070589242263062
train_recall_micro_tok: 0.9070589242263062
train_f-score_micro_tok: 0.9070589242263062
train_time: 49.79531288146973
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5278    0.0819    0.1418      1624
           N     0.6574    0.8511    0.7418      3310
           P     0.7517    0.8343    0.7909      3610

   micro avg     0.6978    0.6978    0.6978      8544
   macro avg     0.6456    0.5891    0.5582      8544
weighted avg     0.6726    0.6978    0.6485      8544

F1-macro sent:  0.5581524691288055
F1-micro sent:  0.6977996254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9184    0.9727    0.9448    124347
           N     0.8160    0.6886    0.7469     14202
           P     0.8866    0.7048    0.7853     25017

   micro avg     0.9071    0.9071    0.9071    163566
   macro avg     0.8737    0.7887    0.8257    163566
weighted avg     0.9047    0.9071    0.9032    163566

F1-macro tok:  0.8256722167383331
F1-micro tok:  0.9070589242263062
**************************************************
dev_cost_sum: 42045.87194824219
dev_cost_avg: 38.188802859438866
dev_count_sent: 1101.0
dev_total_correct_sent: 733.0
dev_accuracy_sent: 0.6657584014532243
dev_count_tok: 21274.0
dev_total_correct_tok: 19169.0
dev_accuracy_tok: 0.9010529284572718
dev_label=O_precision_sent: 0.7
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05857740585774059
dev_label=N_precision_sent: 0.6291946308724832
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.732421875
dev_label=P_precision_sent: 0.7090909090909091
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7476038338658146
dev_precision_macro_sent: 0.6794285133211307
dev_recall_macro_sent: 0.5657588168097085
dev_f-score_macro_sent: 0.5128677049078517
dev_precision_micro_sent: 0.6657584014532243
dev_recall_micro_sent: 0.6657584014532243
dev_f-score_micro_sent: 0.6657584014532243
dev_label=O_precision_tok: 0.9084486818677847
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.9410399809614469
dev_label=N_precision_tok: 0.8133047210300429
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6986175115207373
dev_label=P_precision_tok: 0.8985801217038539
dev_label=P_recall_tok: 0.6896014943960149
dev_label=P_f-score_tok: 0.7803417297868591
dev_precision_macro_tok: 0.8734445082005605
dev_recall_macro_tok: 0.7593120448417784
dev_f-score_macro_tok: 0.8066664074230143
dev_precision_micro_tok: 0.9010529284572718
dev_recall_micro_tok: 0.9010529284572718
dev_f-score_micro_tok: 0.9010529284572718
dev_time: 2.4063477516174316
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7000    0.0306    0.0586       229
           N     0.6292    0.8762    0.7324       428
           P     0.7091    0.7905    0.7476       444

   micro avg     0.6658    0.6658    0.6658      1101
   macro avg     0.6794    0.5658    0.5129      1101
weighted avg     0.6761    0.6658    0.5984      1101

F1-macro sent:  0.5128677049078517
F1-micro sent:  0.6657584014532243
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9761    0.9410     16205
           N     0.8133    0.6123    0.6986      1857
           P     0.8986    0.6896    0.7803      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8734    0.7593    0.8067     21274
weighted avg     0.8987    0.9011    0.8956     21274

F1-macro tok:  0.8066664074230143
F1-micro tok:  0.9010529284572718
**************************************************
Best epoch: 31
**************************************************

EPOCH: 33
Learning rate: 0.478297
train_cost_sum: 299643.4968261719
train_cost_avg: 35.07063399182723
train_count_sent: 8544.0
train_total_correct_sent: 5952.0
train_accuracy_sent: 0.6966292134831461
train_count_tok: 163566.0
train_total_correct_tok: 148424.0
train_accuracy_tok: 0.9074257486274654
train_label=O_precision_sent: 0.46321525885558584
train_label=O_recall_sent: 0.10467980295566502
train_label=O_f-score_sent: 0.17076845806127575
train_label=N_precision_sent: 0.6653910547715858
train_label=N_recall_sent: 0.8404833836858006
train_label=N_f-score_sent: 0.7427579762381524
train_label=P_precision_sent: 0.7507507507507507
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.7888509071785432
train_precision_macro_sent: 0.6264523547926407
train_recall_macro_sent: 0.5920627057964626
train_f-score_macro_sent: 0.5674591138259905
train_precision_micro_sent: 0.6966292134831461
train_recall_micro_sent: 0.6966292134831461
train_f-score_micro_sent: 0.6966292134831461
train_label=O_precision_tok: 0.9188901720051055
train_label=O_recall_tok: 0.9726652030205795
train_label=O_f-score_tok: 0.9450133022881497
train_label=N_precision_tok: 0.8157016519272484
train_label=N_recall_tok: 0.6884241656104774
train_label=N_f-score_tok: 0.7466778677256759
train_label=P_precision_tok: 0.8869011826017238
train_label=P_recall_tok: 0.7074789143382499
train_label=P_f-score_tok: 0.787094478909568
train_precision_macro_tok: 0.8738310021780259
train_recall_macro_tok: 0.7895227609897689
train_f-score_macro_tok: 0.8262618829744645
train_precision_micro_tok: 0.9074257486274654
train_recall_micro_tok: 0.9074257486274654
train_f-score_micro_tok: 0.9074257486274654
train_time: 49.95002555847168
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4632    0.1047    0.1708      1624
           N     0.6654    0.8405    0.7428      3310
           P     0.7508    0.8310    0.7889      3610

   micro avg     0.6966    0.6966    0.6966      8544
   macro avg     0.6265    0.5921    0.5675      8544
weighted avg     0.6630    0.6966    0.6535      8544

F1-macro sent:  0.5674591138259905
F1-micro sent:  0.6966292134831461
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9189    0.9727    0.9450    124347
           N     0.8157    0.6884    0.7467     14202
           P     0.8869    0.7075    0.7871     25017

   micro avg     0.9074    0.9074    0.9074    163566
   macro avg     0.8738    0.7895    0.8263    163566
weighted avg     0.9050    0.9074    0.9036    163566

F1-macro tok:  0.8262618829744645
F1-micro tok:  0.9074257486274654
**************************************************
dev_cost_sum: 42139.223693847656
dev_cost_avg: 38.27359100258643
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19185.0
dev_accuracy_tok: 0.9018050202124659
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09486166007905138
dev_label=N_precision_sent: 0.6465364120781527
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.734611503531786
dev_label=P_precision_sent: 0.7042801556420234
dev_label=P_recall_sent: 0.8153153153153153
dev_label=P_f-score_sent: 0.7557411273486431
dev_precision_macro_sent: 0.6169388559067254
dev_recall_macro_sent: 0.5727281172532774
dev_f-score_macro_sent: 0.5284047636531601
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9080275229357798
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9413582998959726
dev_label=N_precision_tok: 0.8148148148148148
dev_label=N_recall_tok: 0.6160473882606354
dev_label=N_f-score_tok: 0.7016252683226004
dev_label=P_precision_tok: 0.9074074074074074
dev_label=P_recall_tok: 0.6864881693648817
dev_label=P_f-score_tok: 0.781637717121588
dev_precision_macro_tok: 0.8767499150526673
dev_recall_macro_tok: 0.7599216026189758
dev_f-score_macro_tok: 0.8082070951133872
dev_precision_micro_tok: 0.9018050202124659
dev_recall_micro_tok: 0.9018050202124659
dev_f-score_micro_tok: 0.9018050202124659
dev_time: 2.3720703125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0524    0.0949       229
           N     0.6465    0.8505    0.7346       428
           P     0.7043    0.8153    0.7557       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.6169    0.5727    0.5284      1101
weighted avg     0.6393    0.6703    0.6101      1101

F1-macro sent:  0.5284047636531601
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9080    0.9772    0.9414     16205
           N     0.8148    0.6160    0.7016      1857
           P     0.9074    0.6865    0.7816      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8767    0.7599    0.8082     21274
weighted avg     0.8998    0.9018    0.8963     21274

F1-macro tok:  0.8082070951133872
F1-micro tok:  0.9018050202124659
**************************************************
Best epoch: 31
**************************************************

EPOCH: 34
Learning rate: 0.478297
train_cost_sum: 299009.73321533203
train_cost_avg: 34.996457539247665
train_count_sent: 8544.0
train_total_correct_sent: 5957.0
train_accuracy_sent: 0.6972144194756554
train_count_tok: 163566.0
train_total_correct_tok: 148643.0
train_accuracy_tok: 0.9087646576916963
train_label=O_precision_sent: 0.4676470588235294
train_label=O_recall_sent: 0.0979064039408867
train_label=O_f-score_sent: 0.1619144602851324
train_label=N_precision_sent: 0.6646989374262101
train_label=N_recall_sent: 0.850453172205438
train_label=N_f-score_sent: 0.7461895294897283
train_label=P_precision_sent: 0.7515747039556563
train_label=P_recall_sent: 0.8263157894736842
train_label=P_f-score_sent: 0.7871750890618815
train_precision_macro_sent: 0.6279735667351319
train_recall_macro_sent: 0.5915584552066696
train_f-score_macro_sent: 0.5650930262789141
train_precision_micro_sent: 0.6972144194756554
train_recall_micro_sent: 0.6972144194756554
train_f-score_micro_sent: 0.6972144194756554
train_label=O_precision_tok: 0.9210197488723638
train_label=O_recall_tok: 0.9721344302636975
train_label=O_f-score_tok: 0.9458870478686986
train_label=N_precision_tok: 0.8167957804516235
train_label=N_recall_tok: 0.6978594564145895
train_label=N_f-score_tok: 0.7526579586877278
train_label=P_precision_tok: 0.8843638525564804
train_label=P_recall_tok: 0.7135148099292481
train_label=P_f-score_tok: 0.7898055352757682
train_precision_macro_tok: 0.8740597939601559
train_recall_macro_tok: 0.7945028988691784
train_f-score_macro_tok: 0.8294501806107316
train_precision_micro_tok: 0.9087646576916963
train_recall_micro_tok: 0.9087646576916963
train_f-score_micro_tok: 0.9087646576916963
train_time: 49.75741195678711
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4676    0.0979    0.1619      1624
           N     0.6647    0.8505    0.7462      3310
           P     0.7516    0.8263    0.7872      3610

   micro avg     0.6972    0.6972    0.6972      8544
   macro avg     0.6280    0.5916    0.5651      8544
weighted avg     0.6640    0.6972    0.6525      8544

F1-macro sent:  0.5650930262789141
F1-micro sent:  0.6972144194756554
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9210    0.9721    0.9459    124347
           N     0.8168    0.6979    0.7527     14202
           P     0.8844    0.7135    0.7898     25017

   micro avg     0.9088    0.9088    0.9088    163566
   macro avg     0.8741    0.7945    0.8295    163566
weighted avg     0.9064    0.9088    0.9052    163566

F1-macro tok:  0.8294501806107316
F1-micro tok:  0.9087646576916963
**************************************************
dev_cost_sum: 42053.65106201172
dev_cost_avg: 38.19586835786714
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19114.0
dev_accuracy_tok: 0.898467613048792
dev_label=O_precision_sent: 0.5588235294117647
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.14448669201520914
dev_label=N_precision_sent: 0.67578125
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7361702127659574
dev_label=P_precision_sent: 0.6792792792792792
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7547547547547546
dev_precision_macro_sent: 0.6379613528970146
dev_recall_macro_sent: 0.5801599154555935
dev_f-score_macro_sent: 0.545137219845307
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9095163806552262
dev_label=O_recall_tok: 0.9713668620796051
dev_label=O_f-score_tok: 0.9394246836953928
dev_label=N_precision_tok: 0.8272794662713121
dev_label=N_recall_tok: 0.6009693053311793
dev_label=N_f-score_tok: 0.6961946350592639
dev_label=P_precision_tok: 0.8621084797555386
dev_label=P_recall_tok: 0.7026774595267746
dev_label=P_f-score_tok: 0.7742710120068611
dev_precision_macro_tok: 0.866301442227359
dev_recall_macro_tok: 0.7583378756458531
dev_f-score_macro_tok: 0.8032967769205058
dev_precision_micro_tok: 0.898467613048792
dev_recall_micro_tok: 0.898467613048792
dev_f-score_micro_tok: 0.8984676130487919
dev_time: 2.374239206314087
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5588    0.0830    0.1445       229
           N     0.6758    0.8084    0.7362       428
           P     0.6793    0.8491    0.7548       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6380    0.5802    0.5451      1101
weighted avg     0.6529    0.6739    0.6206      1101

F1-macro sent:  0.545137219845307
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9095    0.9714    0.9394     16205
           N     0.8273    0.6010    0.6962      1857
           P     0.8621    0.7027    0.7743      3212

   micro avg     0.8985    0.8985    0.8985     21274
   macro avg     0.8663    0.7583    0.8033     21274
weighted avg     0.8952    0.8985    0.8933     21274

F1-macro tok:  0.8032967769205058
F1-micro tok:  0.8984676130487919
**************************************************
Best epoch: 31
**************************************************

EPOCH: 35
Learning rate: 0.478297
train_cost_sum: 298152.4020996094
train_cost_avg: 34.89611447795053
train_count_sent: 8544.0
train_total_correct_sent: 5933.0
train_accuracy_sent: 0.6944054307116105
train_count_tok: 163566.0
train_total_correct_tok: 148840.0
train_accuracy_tok: 0.9099690644755023
train_label=O_precision_sent: 0.4915254237288136
train_label=O_recall_sent: 0.10714285714285714
train_label=O_f-score_sent: 0.17593528816986856
train_label=N_precision_sent: 0.669677734375
train_label=N_recall_sent: 0.8287009063444108
train_label=N_f-score_sent: 0.7407507426411019
train_label=P_precision_sent: 0.7366878358573522
train_label=P_recall_sent: 0.8354570637119113
train_label=P_f-score_sent: 0.782969885773624
train_precision_macro_sent: 0.6326303313203886
train_recall_macro_sent: 0.5904336090663931
train_f-score_macro_sent: 0.5665519721948648
train_precision_micro_sent: 0.6944054307116105
train_recall_micro_sent: 0.6944054307116105
train_f-score_micro_sent: 0.6944054307116105
train_label=O_precision_tok: 0.9221276465922265
train_label=O_recall_tok: 0.9722952704930558
train_label=O_f-score_tok: 0.9465471954403643
train_label=N_precision_tok: 0.8193792706017947
train_label=N_recall_tok: 0.7008167863681172
train_label=N_f-score_tok: 0.7554745910660746
train_label=P_precision_tok: 0.8856551927906633
train_label=P_recall_tok: 0.7189111404245113
train_label=P_f-score_tok: 0.7936192745565263
train_precision_macro_tok: 0.8757207033282283
train_recall_macro_tok: 0.7973410657618948
train_f-score_macro_tok: 0.8318803536876551
train_precision_micro_tok: 0.9099690644755023
train_recall_micro_tok: 0.9099690644755023
train_f-score_micro_tok: 0.9099690644755023
train_time: 49.54624819755554
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4915    0.1071    0.1759      1624
           N     0.6697    0.8287    0.7408      3310
           P     0.7367    0.8355    0.7830      3610

   micro avg     0.6944    0.6944    0.6944      8544
   macro avg     0.6326    0.5904    0.5666      8544
weighted avg     0.6641    0.6944    0.6512      8544

F1-macro sent:  0.5665519721948648
F1-micro sent:  0.6944054307116105
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9221    0.9723    0.9465    124347
           N     0.8194    0.7008    0.7555     14202
           P     0.8857    0.7189    0.7936     25017

   micro avg     0.9100    0.9100    0.9100    163566
   macro avg     0.8757    0.7973    0.8319    163566
weighted avg     0.9076    0.9100    0.9066    163566

F1-macro tok:  0.8318803536876551
F1-micro tok:  0.9099690644755023
**************************************************
dev_cost_sum: 41946.95373535156
dev_cost_avg: 38.09895888769442
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.7058823529411765
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0975609756097561
dev_label=N_precision_sent: 0.6792079207920793
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7352625937834941
dev_label=P_precision_sent: 0.6666666666666666
dev_label=P_recall_sent: 0.8693693693693694
dev_label=P_f-score_sent: 0.7546432062561094
dev_precision_macro_sent: 0.6839189801333075
dev_recall_macro_sent: 0.5743909950843795
dev_f-score_macro_sent: 0.5291555918831198
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9093056755978104
dev_label=O_recall_tok: 0.9738352360382598
dev_label=O_f-score_tok: 0.9404648390941597
dev_label=N_precision_tok: 0.8131634819532909
dev_label=N_recall_tok: 0.6187399030694669
dev_label=N_f-score_tok: 0.7027522935779817
dev_label=P_precision_tok: 0.8858739026336792
dev_label=P_recall_tok: 0.6911581569115816
dev_label=P_f-score_tok: 0.776495278069255
dev_precision_macro_tok: 0.8694476867282601
dev_recall_macro_tok: 0.7612444320064361
dev_f-score_macro_tok: 0.8065708035804655
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 2.370525598526001
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7059    0.0524    0.0976       229
           N     0.6792    0.8014    0.7353       428
           P     0.6667    0.8694    0.7546       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6839    0.5744    0.5292      1101
weighted avg     0.6797    0.6730    0.6104      1101

F1-macro sent:  0.5291555918831198
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9093    0.9738    0.9405     16205
           N     0.8132    0.6187    0.7028      1857
           P     0.8859    0.6912    0.7765      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8694    0.7612    0.8066     21274
weighted avg     0.8974    0.9002    0.8950     21274

F1-macro tok:  0.8065708035804655
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 31
**************************************************

EPOCH: 36
Learning rate: 0.430467
train_cost_sum: 297030.17919921875
train_cost_avg: 34.764768164702566
train_count_sent: 8544.0
train_total_correct_sent: 5956.0
train_accuracy_sent: 0.6970973782771536
train_count_tok: 163566.0
train_total_correct_tok: 148967.0
train_accuracy_tok: 0.9107455094579558
train_label=O_precision_sent: 0.4666666666666667
train_label=O_recall_sent: 0.07758620689655173
train_label=O_f-score_sent: 0.133051742344245
train_label=N_precision_sent: 0.6695485110470701
train_label=N_recall_sent: 0.8422960725075529
train_label=N_f-score_sent: 0.7460529836767461
train_label=P_precision_sent: 0.7401459854014598
train_label=P_recall_sent: 0.8426592797783934
train_label=P_f-score_sent: 0.7880829015544042
train_precision_macro_sent: 0.6254537210383989
train_recall_macro_sent: 0.5875138530608327
train_f-score_macro_sent: 0.5557292091917985
train_precision_micro_sent: 0.6970973782771536
train_recall_micro_sent: 0.6970973782771536
train_f-score_micro_sent: 0.6970973782771536
train_label=O_precision_tok: 0.9232355794571719
train_label=O_recall_tok: 0.9719414219884678
train_label=O_f-score_tok: 0.9469626332985968
train_label=N_precision_tok: 0.8195901639344262
train_label=N_recall_tok: 0.7040557667934094
train_label=N_f-score_tok: 0.7574426179834861
train_label=P_precision_tok: 0.8851850041546507
train_label=P_recall_tok: 0.7239077427349403
train_label=P_f-score_tok: 0.7964640689594512
train_precision_macro_tok: 0.8760035825154162
train_recall_macro_tok: 0.7999683105056059
train_f-score_macro_tok: 0.833623106747178
train_precision_micro_tok: 0.9107455094579558
train_recall_micro_tok: 0.9107455094579558
train_f-score_micro_tok: 0.9107455094579558
train_time: 49.95687198638916
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4667    0.0776    0.1331      1624
           N     0.6695    0.8423    0.7461      3310
           P     0.7401    0.8427    0.7881      3610

   micro avg     0.6971    0.6971    0.6971      8544
   macro avg     0.6255    0.5875    0.5557      8544
weighted avg     0.6608    0.6971    0.6473      8544

F1-macro sent:  0.5557292091917985
F1-micro sent:  0.6970973782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9232    0.9719    0.9470    124347
           N     0.8196    0.7041    0.7574     14202
           P     0.8852    0.7239    0.7965     25017

   micro avg     0.9107    0.9107    0.9107    163566
   macro avg     0.8760    0.8000    0.8336    163566
weighted avg     0.9084    0.9107    0.9075    163566

F1-macro tok:  0.833623106747178
F1-micro tok:  0.9107455094579558
**************************************************
dev_cost_sum: 42128.31591796875
dev_cost_avg: 38.263683849199595
dev_count_sent: 1101.0
dev_total_correct_sent: 748.0
dev_accuracy_sent: 0.6793823796548593
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.6875
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.08979591836734695
dev_label=N_precision_sent: 0.6819923371647509
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7494736842105263
dev_label=P_precision_sent: 0.6767317939609236
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7567030784508442
dev_precision_macro_sent: 0.6820747103752248
dev_recall_macro_sent: 0.5793062478468347
dev_f-score_macro_sent: 0.5319908936762391
dev_precision_micro_sent: 0.6793823796548593
dev_recall_micro_sent: 0.6793823796548593
dev_f-score_micro_sent: 0.6793823796548593
dev_label=O_precision_tok: 0.9072684575290682
dev_label=O_recall_tok: 0.9774760876272756
dev_label=O_f-score_tok: 0.9410646387832701
dev_label=N_precision_tok: 0.8193736343772761
dev_label=N_recall_tok: 0.6058158319870759
dev_label=N_f-score_tok: 0.696594427244582
dev_label=P_precision_tok: 0.9037674037674037
dev_label=P_recall_tok: 0.6871108343711083
dev_label=P_f-score_tok: 0.7806862398302087
dev_precision_macro_tok: 0.8768031652245827
dev_recall_macro_tok: 0.7568009179951533
dev_f-score_macro_tok: 0.8061151019526869
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 2.4015138149261475
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6875    0.0480    0.0898       229
           N     0.6820    0.8318    0.7495       428
           P     0.6767    0.8581    0.7567       444

   micro avg     0.6794    0.6794    0.6794      1101
   macro avg     0.6821    0.5793    0.5320      1101
weighted avg     0.6810    0.6794    0.6152      1101

F1-macro sent:  0.5319908936762391
F1-micro sent:  0.6793823796548593
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9073    0.9775    0.9411     16205
           N     0.8194    0.6058    0.6966      1857
           P     0.9038    0.6871    0.7807      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8768    0.7568    0.8061     21274
weighted avg     0.8991    0.9012    0.8955     21274

F1-macro tok:  0.8061151019526869
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 31
**************************************************

EPOCH: 37
Learning rate: 0.387420
train_cost_sum: 296350.3462524414
train_cost_avg: 34.68519970183069
train_count_sent: 8544.0
train_total_correct_sent: 6039.0
train_accuracy_sent: 0.706811797752809
train_count_tok: 163566.0
train_total_correct_tok: 149076.0
train_accuracy_tok: 0.9114119071200616
train_label=O_precision_sent: 0.4923547400611621
train_label=O_recall_sent: 0.09913793103448276
train_label=O_f-score_sent: 0.16504356740133266
train_label=N_precision_sent: 0.6813641900121803
train_label=N_recall_sent: 0.8450151057401812
train_label=N_f-score_sent: 0.7544167228590695
train_label=P_precision_sent: 0.7492704280155642
train_label=P_recall_sent: 0.8534626038781163
train_label=P_f-score_sent: 0.797979797979798
train_precision_macro_sent: 0.6409964526963022
train_recall_macro_sent: 0.5992052135509268
train_f-score_macro_sent: 0.5724800294134
train_precision_micro_sent: 0.706811797752809
train_recall_micro_sent: 0.706811797752809
train_f-score_micro_sent: 0.706811797752809
train_label=O_precision_tok: 0.9246755235652208
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9473370413662716
train_label=N_precision_tok: 0.8183224755700326
train_label=N_recall_tok: 0.7075763976904661
train_label=N_f-score_tok: 0.7589305943659843
train_label=P_precision_tok: 0.882944275288773
train_label=P_recall_tok: 0.7302634208738058
train_label=P_f-score_tok: 0.7993786645663779
train_precision_macro_tok: 0.8753140914746754
train_recall_macro_tok: 0.8029923464686496
train_f-score_macro_tok: 0.8352154334328779
train_precision_micro_tok: 0.9114119071200616
train_recall_micro_tok: 0.9114119071200616
train_f-score_micro_tok: 0.9114119071200616
train_time: 49.701645374298096
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4924    0.0991    0.1650      1624
           N     0.6814    0.8450    0.7544      3310
           P     0.7493    0.8535    0.7980      3610

   micro avg     0.7068    0.7068    0.7068      8544
   macro avg     0.6410    0.5992    0.5725      8544
weighted avg     0.6741    0.7068    0.6608      8544

F1-macro sent:  0.5724800294134
F1-micro sent:  0.706811797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9247    0.9711    0.9473    124347
           N     0.8183    0.7076    0.7589     14202
           P     0.8829    0.7303    0.7994     25017

   micro avg     0.9114    0.9114    0.9114    163566
   macro avg     0.8753    0.8030    0.8352    163566
weighted avg     0.9091    0.9114    0.9083    163566

F1-macro tok:  0.8352154334328779
F1-micro tok:  0.9114119071200616
**************************************************
dev_cost_sum: 41911.485290527344
dev_cost_avg: 38.06674413308569
dev_count_sent: 1101.0
dev_total_correct_sent: 743.0
dev_accuracy_sent: 0.6748410535876476
dev_count_tok: 21274.0
dev_total_correct_tok: 19105.0
dev_accuracy_tok: 0.8980445614364952
dev_label=O_precision_sent: 0.5454545454545454
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.1374045801526718
dev_label=N_precision_sent: 0.6473684210526316
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7394789579158316
dev_label=P_precision_sent: 0.714859437751004
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7558386411889596
dev_precision_macro_sent: 0.635894134752727
dev_recall_macro_sent: 0.5808513181998062
dev_f-score_macro_sent: 0.5442407264191543
dev_precision_micro_sent: 0.6748410535876476
dev_recall_micro_sent: 0.6748410535876476
dev_f-score_micro_sent: 0.6748410535876476
dev_label=O_precision_tok: 0.9147354868913857
dev_label=O_recall_tok: 0.9645788336933045
dev_label=O_f-score_tok: 0.9389961853843151
dev_label=N_precision_tok: 0.768595041322314
dev_label=N_recall_tok: 0.6510500807754442
dev_label=N_f-score_tok: 0.7049562682215743
dev_label=P_precision_tok: 0.8668197474167624
dev_label=P_recall_tok: 0.7051681195516812
dev_label=P_f-score_tok: 0.7776824034334764
dev_precision_macro_tok: 0.8500500918768207
dev_recall_macro_tok: 0.7735990113401433
dev_f-score_macro_tok: 0.8072116190131219
dev_precision_micro_tok: 0.8980445614364952
dev_recall_micro_tok: 0.8980445614364952
dev_f-score_micro_tok: 0.8980445614364952
dev_time: 2.3906922340393066
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5455    0.0786    0.1374       229
           N     0.6474    0.8621    0.7395       428
           P     0.7149    0.8018    0.7558       444

   micro avg     0.6748    0.6748    0.6748      1101
   macro avg     0.6359    0.5809    0.5442      1101
weighted avg     0.6534    0.6748    0.6208      1101

F1-macro sent:  0.5442407264191543
F1-micro sent:  0.6748410535876476
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9646    0.9390     16205
           N     0.7686    0.6511    0.7050      1857
           P     0.8668    0.7052    0.7777      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8501    0.7736    0.8072     21274
weighted avg     0.8947    0.8980    0.8942     21274

F1-macro tok:  0.8072116190131219
F1-micro tok:  0.8980445614364952
**************************************************
Best epoch: 31
**************************************************

EPOCH: 38
Learning rate: 0.348678
train_cost_sum: 295436.6448364258
train_cost_avg: 34.57825899302736
train_count_sent: 8544.0
train_total_correct_sent: 6014.0
train_accuracy_sent: 0.7038857677902621
train_count_tok: 163566.0
train_total_correct_tok: 149466.0
train_accuracy_tok: 0.9137962657275962
train_label=O_precision_sent: 0.4845360824742268
train_label=O_recall_sent: 0.11576354679802955
train_label=O_f-score_sent: 0.18687872763419483
train_label=N_precision_sent: 0.6750605326876513
train_label=N_recall_sent: 0.8422960725075529
train_label=N_f-score_sent: 0.7494623655913979
train_label=P_precision_sent: 0.754595131644312
train_label=P_recall_sent: 0.8415512465373961
train_label=P_f-score_sent: 0.7957045573598742
train_precision_macro_sent: 0.6380639156020634
train_recall_macro_sent: 0.5998702886143262
train_f-score_macro_sent: 0.5773485501951556
train_precision_micro_sent: 0.7038857677902621
train_recall_micro_sent: 0.7038857677902621
train_f-score_micro_sent: 0.7038857677902621
train_label=O_precision_tok: 0.9269531070239757
train_label=O_recall_tok: 0.9719414219884678
train_label=O_f-score_tok: 0.9489143364124226
train_label=N_precision_tok: 0.8252592352559948
train_label=N_recall_tok: 0.7172933389663427
train_label=N_f-score_tok: 0.7674979281247646
train_label=P_precision_tok: 0.8839251439539347
train_label=P_recall_tok: 0.7363392892832874
train_label=P_f-score_tok: 0.8034106025252414
train_precision_macro_tok: 0.8787124954113018
train_recall_macro_tok: 0.8085246834126995
train_f-score_macro_tok: 0.8399409556874762
train_precision_micro_tok: 0.9137962657275962
train_recall_micro_tok: 0.9137962657275962
train_f-score_micro_tok: 0.9137962657275962
train_time: 49.875962257385254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4845    0.1158    0.1869      1624
           N     0.6751    0.8423    0.7495      3310
           P     0.7546    0.8416    0.7957      3610

   micro avg     0.7039    0.7039    0.7039      8544
   macro avg     0.6381    0.5999    0.5773      8544
weighted avg     0.6725    0.7039    0.6621      8544

F1-macro sent:  0.5773485501951556
F1-micro sent:  0.7038857677902621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9270    0.9719    0.9489    124347
           N     0.8253    0.7173    0.7675     14202
           P     0.8839    0.7363    0.8034     25017

   micro avg     0.9138    0.9138    0.9138    163566
   macro avg     0.8787    0.8085    0.8399    163566
weighted avg     0.9115    0.9138    0.9109    163566

F1-macro tok:  0.8399409556874762
F1-micro tok:  0.9137962657275962
**************************************************
dev_cost_sum: 42036.243408203125
dev_cost_avg: 38.18005759146514
dev_count_sent: 1101.0
dev_total_correct_sent: 739.0
dev_accuracy_sent: 0.6712079927338783
dev_count_tok: 21274.0
dev_total_correct_tok: 19149.0
dev_accuracy_tok: 0.9001128137632791
dev_label=O_precision_sent: 0.6071428571428571
dev_label=O_recall_sent: 0.07423580786026202
dev_label=O_f-score_sent: 0.132295719844358
dev_label=N_precision_sent: 0.6506238859180036
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7381193124368048
dev_label=P_precision_sent: 0.697265625
dev_label=P_recall_sent: 0.8040540540540541
dev_label=P_f-score_sent: 0.7468619246861925
dev_precision_macro_sent: 0.6516774560202868
dev_recall_macro_sent: 0.5770312000773576
dev_f-score_macro_sent: 0.5390923189891185
dev_precision_micro_sent: 0.6712079927338783
dev_recall_micro_sent: 0.6712079927338783
dev_f-score_micro_sent: 0.6712079927338783
dev_label=O_precision_tok: 0.9084421937043218
dev_label=O_recall_tok: 0.9741437827830917
dev_label=O_f-score_tok: 0.9401465070573523
dev_label=N_precision_tok: 0.8005540166204986
dev_label=N_recall_tok: 0.6225094238018309
dev_label=N_f-score_tok: 0.7003938200545289
dev_label=P_precision_tok: 0.8997146351406441
dev_label=P_recall_tok: 0.6871108343711083
dev_label=P_f-score_tok: 0.779170344218888
dev_precision_macro_tok: 0.8695702818218215
dev_recall_macro_tok: 0.761254680318677
dev_f-score_macro_tok: 0.806570223776923
dev_precision_micro_tok: 0.9001128137632791
dev_recall_micro_tok: 0.9001128137632791
dev_f-score_micro_tok: 0.9001128137632791
dev_time: 2.3725669384002686
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6071    0.0742    0.1323       229
           N     0.6506    0.8528    0.7381       428
           P     0.6973    0.8041    0.7469       444

   micro avg     0.6712    0.6712    0.6712      1101
   macro avg     0.6517    0.5770    0.5391      1101
weighted avg     0.6604    0.6712    0.6156      1101

F1-macro sent:  0.5390923189891185
F1-micro sent:  0.6712079927338783
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9084    0.9741    0.9401     16205
           N     0.8006    0.6225    0.7004      1857
           P     0.8997    0.6871    0.7792      3212

   micro avg     0.9001    0.9001    0.9001     21274
   macro avg     0.8696    0.7613    0.8066     21274
weighted avg     0.8977    0.9001    0.8949     21274

F1-macro tok:  0.806570223776923
F1-micro tok:  0.9001128137632791
**************************************************
Best epoch: 31
**************************************************

test0_cost_sum: 42112.60681152344
test0_cost_avg: 38.24941581428105
test0_count_sent: 1101.0
test0_total_correct_sent: 741.0
test0_accuracy_sent: 0.6730245231607629
test0_count_tok: 21274.0
test0_total_correct_tok: 19175.0
test0_accuracy_tok: 0.9013349628654695
test0_label=O_precision_sent: 0.5555555555555556
test0_label=O_recall_sent: 0.08733624454148471
test0_label=O_f-score_sent: 0.1509433962264151
test0_label=N_precision_sent: 0.664179104477612
test0_label=N_recall_sent: 0.8317757009345794
test0_label=N_f-score_sent: 0.7385892116182573
test0_label=P_precision_sent: 0.6899810964083176
test0_label=P_recall_sent: 0.8220720720720721
test0_label=P_f-score_sent: 0.7502569373072971
test0_precision_macro_sent: 0.6365719188138285
test0_recall_macro_sent: 0.5803946725160455
test0_f-score_macro_sent: 0.5465965150506565
test0_precision_micro_sent: 0.6730245231607629
test0_recall_micro_sent: 0.6730245231607629
test0_f-score_micro_sent: 0.6730245231607629
test0_label=O_precision_tok: 0.906258931123178
test0_label=O_recall_tok: 0.978401727861771
test0_label=O_f-score_tok: 0.9409495548961424
test0_label=N_precision_tok: 0.8270787343635025
test0_label=N_recall_tok: 0.6052773290253096
test0_label=N_f-score_tok: 0.6990049751243782
test0_label=P_precision_tok: 0.9074380165289256
test0_label=P_recall_tok: 0.6836861768368617
test0_label=P_f-score_tok: 0.7798295454545455
test0_precision_macro_tok: 0.8802585606718688
test0_recall_macro_tok: 0.7557884112413141
test0_f-score_macro_tok: 0.8065946918250221
test0_precision_micro_tok: 0.9013349628654695
test0_recall_micro_tok: 0.9013349628654695
test0_f-score_micro_tok: 0.9013349628654695
test0_time: 2.395094871520996
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0873    0.1509       229
           N     0.6642    0.8318    0.7386       428
           P     0.6900    0.8221    0.7503       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6366    0.5804    0.5466      1101
weighted avg     0.6520    0.6730    0.6211      1101

F1-macro sent:  0.5465965150506565
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9784    0.9409     16205
           N     0.8271    0.6053    0.6990      1857
           P     0.9074    0.6837    0.7798      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8803    0.7558    0.8066     21274
weighted avg     0.8995    0.9013    0.8955     21274

F1-macro tok:  0.8065946918250221
F1-micro tok:  0.9013349628654695
**************************************************
test1_cost_sum: 81652.01495361328
test1_cost_avg: 36.94661310118248
test1_count_sent: 2210.0
test1_total_correct_sent: 1543.0
test1_accuracy_sent: 0.6981900452488687
test1_count_tok: 42405.0
test1_total_correct_tok: 37949.0
test1_accuracy_tok: 0.8949180521164957
test1_label=O_precision_sent: 0.42857142857142855
test1_label=O_recall_sent: 0.10025706940874037
test1_label=O_f-score_sent: 0.1625
test1_label=N_precision_sent: 0.697282099343955
test1_label=N_recall_sent: 0.8157894736842105
test1_label=N_f-score_sent: 0.7518948964123295
test1_label=P_precision_sent: 0.7224334600760456
test1_label=P_recall_sent: 0.8360836083608361
test1_label=P_f-score_sent: 0.7751147373788883
test1_precision_macro_sent: 0.6160956626638098
test1_recall_macro_sent: 0.584043383817929
test1_f-score_macro_sent: 0.563169877930406
test1_precision_micro_sent: 0.6981900452488687
test1_recall_micro_sent: 0.6981900452488687
test1_f-score_micro_sent: 0.6981900452488687
test1_label=O_precision_tok: 0.8988976920427144
test1_label=O_recall_tok: 0.9786236639789987
test1_label=O_f-score_tok: 0.9370679594218511
test1_label=N_precision_tok: 0.8245741210583545
test1_label=N_recall_tok: 0.6050531914893617
test1_label=N_f-score_tok: 0.6979598097867771
test1_label=P_precision_tok: 0.9064449064449065
test1_label=P_recall_tok: 0.6559350082744095
test1_label=P_f-score_tok: 0.7611067469669198
test1_precision_macro_tok: 0.8766389065153252
test1_recall_macro_tok: 0.7465372879142566
test1_f-score_macro_tok: 0.7987115053918493
test1_precision_micro_tok: 0.8949180521164957
test1_recall_micro_tok: 0.8949180521164957
test1_f-score_micro_tok: 0.8949180521164957
test1_time: 4.881219148635864
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.1003    0.1625       389
           N     0.6973    0.8158    0.7519       912
           P     0.7224    0.8361    0.7751       909

   micro avg     0.6982    0.6982    0.6982      2210
   macro avg     0.6161    0.5840    0.5632      2210
weighted avg     0.6603    0.6982    0.6577      2210

F1-macro sent:  0.563169877930406
F1-micro sent:  0.6981900452488687
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9786    0.9371     31998
           N     0.8246    0.6051    0.6980      3760
           P     0.9064    0.6559    0.7611      6647

   micro avg     0.8949    0.8949    0.8949     42405
   macro avg     0.8766    0.7465    0.7987     42405
weighted avg     0.8935    0.8949    0.8883     42405

F1-macro tok:  0.7987115053918493
F1-micro tok:  0.8949180521164957
**************************************************
