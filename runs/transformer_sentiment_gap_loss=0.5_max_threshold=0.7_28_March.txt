to_write_filename: runs/transformer_sentiment_gap_loss=0.5_max_threshold=0.7_28_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.5
maximum_gap_threshold: 0.7
sentence_composition: attention
random_seed: 100
{'N': 1, 'P': 2, 'O': 0}
{'N': 1, 'P': 2, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-28 21:58:31.140815: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 21:58:31.287866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 7c1f:00:00.0
totalMemory: 11.17GiB freeMemory: 6.60GiB
2019-03-28 21:58:31.287910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-28 21:58:32.112635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-28 21:58:32.112677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-28 21:58:32.112692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-28 21:58:32.112894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 7c1f:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428978.6418457031
train_cost_avg: 50.20817437332668
train_count_sent: 8544.0
train_total_correct_sent: 4306.0
train_accuracy_sent: 0.5039794007490637
train_count_tok: 163566.0
train_total_correct_tok: 126136.0
train_accuracy_tok: 0.7711627110768742
train_label=O_precision_sent: 0.18106995884773663
train_label=O_recall_sent: 0.027093596059113302
train_label=O_f-score_sent: 0.0471344402785217
train_label=N_precision_sent: 0.49416342412451364
train_label=N_recall_sent: 0.5755287009063444
train_label=N_f-score_sent: 0.531751570132589
train_label=P_precision_sent: 0.5301394511920827
train_label=P_recall_sent: 0.6529085872576177
train_label=P_f-score_sent: 0.5851539225422044
train_precision_macro_sent: 0.40179094472144433
train_recall_macro_sent: 0.41851029474102514
train_f-score_macro_sent: 0.38801331098443836
train_precision_micro_sent: 0.5039794007490637
train_recall_micro_sent: 0.5039794007490637
train_f-score_micro_sent: 0.5039794007490637
train_label=O_precision_tok: 0.7949059597860074
train_label=O_recall_tok: 0.9547476014700796
train_label=O_f-score_tok: 0.8675255208295274
train_label=N_precision_tok: 0.5045479858919621
train_label=N_recall_tok: 0.19138149556400508
train_label=N_f-score_tok: 0.2775026800755526
train_label=P_precision_tok: 0.5321703670140462
train_label=P_recall_tok: 0.18779230123516008
train_label=P_f-score_tok: 0.2776185551780174
train_precision_macro_tok: 0.6105414375640051
train_recall_macro_tok: 0.4446404660897483
train_f-score_macro_tok: 0.47421558536103253
train_precision_micro_tok: 0.7711627110768742
train_recall_micro_tok: 0.7711627110768742
train_f-score_micro_tok: 0.7711627110768742
train_time: 253.94879531860352
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1811    0.0271    0.0471      1624
           N     0.4942    0.5755    0.5318      3310
           P     0.5301    0.6529    0.5852      3610

   micro avg     0.5040    0.5040    0.5040      8544
   macro avg     0.4018    0.4185    0.3880      8544
weighted avg     0.4499    0.5040    0.4622      8544

F1-macro sent:  0.38801331098443836
F1-micro sent:  0.5039794007490637
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7949    0.9547    0.8675    124347
           N     0.5045    0.1914    0.2775     14202
           P     0.5322    0.1878    0.2776     25017

   micro avg     0.7712    0.7712    0.7712    163566
   macro avg     0.6105    0.4446    0.4742    163566
weighted avg     0.7295    0.7712    0.7261    163566

F1-macro tok:  0.47421558536103253
F1-micro tok:  0.7711627110768742
**************************************************
dev_cost_sum: 50900.542907714844
dev_cost_avg: 46.23119246840585
dev_count_sent: 1101.0
dev_total_correct_sent: 633.0
dev_accuracy_sent: 0.5749318801089919
dev_count_tok: 21274.0
dev_total_correct_tok: 17507.0
dev_accuracy_tok: 0.8229293973864812
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6563380281690141
dev_label=N_recall_sent: 0.544392523364486
dev_label=N_f-score_sent: 0.5951468710089399
dev_label=P_precision_sent: 0.5361930294906166
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.6722689075630253
dev_precision_macro_sent: 0.3975103525532102
dev_recall_macro_sent: 0.4817644747551289
dev_f-score_macro_sent: 0.4224719261906551
dev_precision_micro_sent: 0.5749318801089919
dev_recall_micro_sent: 0.5749318801089919
dev_f-score_micro_sent: 0.5749318801089919
dev_label=O_precision_tok: 0.8446676546462484
dev_label=O_recall_tok: 0.9496451712434434
dev_label=O_f-score_tok: 0.8940855217290261
dev_label=N_precision_tok: 0.6354466858789626
dev_label=N_recall_tok: 0.47495961227786754
dev_label=N_f-score_tok: 0.5436055469953776
dev_label=P_precision_tok: 0.7414517096580684
dev_label=P_recall_tok: 0.3848069738480697
dev_label=P_f-score_tok: 0.5066612010657922
dev_precision_macro_tok: 0.7405220167277599
dev_recall_macro_tok: 0.6031372524564602
dev_f-score_macro_tok: 0.6481174232633986
dev_precision_micro_tok: 0.8229293973864812
dev_recall_micro_tok: 0.8229293973864812
dev_f-score_micro_tok: 0.8229293973864812
dev_time: 14.185348749160767
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6563    0.5444    0.5951       428
           P     0.5362    0.9009    0.6723       444

   micro avg     0.5749    0.5749    0.5749      1101
   macro avg     0.3975    0.4818    0.4225      1101
weighted avg     0.4714    0.5749    0.5025      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.4224719261906551
F1-micro sent:  0.5749318801089919
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8447    0.9496    0.8941     16205
           N     0.6354    0.4750    0.5436      1857
           P     0.7415    0.3848    0.5067      3212

   micro avg     0.8229    0.8229    0.8229     21274
   macro avg     0.7405    0.6031    0.6481     21274
weighted avg     0.8108    0.8229    0.8050     21274

F1-macro tok:  0.6481174232633986
F1-micro tok:  0.8229293973864812
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 380010.5997314453
train_cost_avg: 44.47689603598377
train_count_sent: 8544.0
train_total_correct_sent: 4864.0
train_accuracy_sent: 0.5692883895131086
train_count_tok: 163566.0
train_total_correct_tok: 132322.0
train_accuracy_tok: 0.8089823068363841
train_label=O_precision_sent: 0.2962962962962963
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009691096305269533
train_label=N_precision_sent: 0.5391769355963729
train_label=N_recall_sent: 0.7006042296072508
train_label=N_f-score_sent: 0.6093811588490343
train_label=P_precision_sent: 0.6017552182163188
train_label=P_recall_sent: 0.7027700831024931
train_label=P_f-score_sent: 0.6483516483516483
train_precision_macro_sent: 0.47907615003632936
train_recall_macro_sent: 0.4694334736947094
train_f-score_macro_sent: 0.4224746345019841
train_precision_micro_sent: 0.5692883895131086
train_recall_micro_sent: 0.5692883895131086
train_f-score_micro_sent: 0.5692883895131086
train_label=O_precision_tok: 0.8290995975855131
train_label=O_recall_tok: 0.9543776689425559
train_label=O_f-score_tok: 0.8873386346048161
train_label=N_precision_tok: 0.6483558019402798
train_label=N_recall_tok: 0.36234333192508095
train_label=N_f-score_tok: 0.46488097926735616
train_label=P_precision_tok: 0.6805411030176899
train_label=P_recall_tok: 0.3398489027461326
train_label=P_f-score_tok: 0.4533191149026926
train_precision_macro_tok: 0.7193321675144942
train_recall_macro_tok: 0.5521899678712565
train_f-score_macro_tok: 0.6018462429249549
train_precision_micro_tok: 0.8089823068363841
train_recall_micro_tok: 0.8089823068363841
train_f-score_micro_tok: 0.8089823068363841
train_time: 164.61578559875488
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2963    0.0049    0.0097      1624
           N     0.5392    0.7006    0.6094      3310
           P     0.6018    0.7028    0.6484      3610

   micro avg     0.5693    0.5693    0.5693      8544
   macro avg     0.4791    0.4694    0.4225      8544
weighted avg     0.5195    0.5693    0.5119      8544

F1-macro sent:  0.4224746345019841
F1-micro sent:  0.5692883895131086
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8291    0.9544    0.8873    124347
           N     0.6484    0.3623    0.4649     14202
           P     0.6805    0.3398    0.4533     25017

   micro avg     0.8090    0.8090    0.8090    163566
   macro avg     0.7193    0.5522    0.6018    163566
weighted avg     0.7907    0.8090    0.7843    163566

F1-macro tok:  0.6018462429249549
F1-micro tok:  0.8089823068363841
**************************************************
dev_cost_sum: 49360.82537841797
dev_cost_avg: 44.832720598018135
dev_count_sent: 1101.0
dev_total_correct_sent: 630.0
dev_accuracy_sent: 0.5722070844686649
dev_count_tok: 21274.0
dev_total_correct_tok: 17681.0
dev_accuracy_tok: 0.8311083952242173
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.49455864570737607
dev_label=N_recall_sent: 0.955607476635514
dev_label=N_f-score_sent: 0.651792828685259
dev_label=P_precision_sent: 0.8065693430656934
dev_label=P_recall_sent: 0.49774774774774777
dev_label=P_f-score_sent: 0.6155988857938719
dev_precision_macro_sent: 0.4337093295910231
dev_recall_macro_sent: 0.4844517414610873
dev_f-score_macro_sent: 0.42246390482637697
dev_precision_micro_sent: 0.5722070844686649
dev_recall_micro_sent: 0.5722070844686649
dev_f-score_micro_sent: 0.5722070844686649
dev_label=O_precision_tok: 0.8353071798667654
dev_label=O_recall_tok: 0.9749460043196544
dev_label=O_f-score_tok: 0.8997408810045845
dev_label=N_precision_tok: 0.730804810360777
dev_label=N_recall_tok: 0.4254173397953689
dev_label=N_f-score_tok: 0.537780803267529
dev_label=P_precision_tok: 0.8537920250195465
dev_label=P_recall_tok: 0.33997509339975096
dev_label=P_f-score_tok: 0.48630594522378096
dev_precision_macro_tok: 0.8066346717490296
dev_recall_macro_tok: 0.5801128125049247
dev_f-score_macro_tok: 0.6412758764986315
dev_precision_micro_tok: 0.8311083952242173
dev_recall_micro_tok: 0.8311083952242173
dev_f-score_micro_tok: 0.8311083952242173
dev_time: 7.659134387969971
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4946    0.9556    0.6518       428
           P     0.8066    0.4977    0.6156       444

   micro avg     0.5722    0.5722    0.5722      1101
   macro avg     0.4337    0.4845    0.4225      1101
weighted avg     0.5175    0.5722    0.5016      1101

F1-macro sent:  0.42246390482637697
F1-micro sent:  0.5722070844686649
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8353    0.9749    0.8997     16205
           N     0.7308    0.4254    0.5378      1857
           P     0.8538    0.3400    0.4863      3212

   micro avg     0.8311    0.8311    0.8311     21274
   macro avg     0.8066    0.5801    0.6413     21274
weighted avg     0.8290    0.8311    0.8057     21274

F1-macro tok:  0.6412758764986315
F1-micro tok:  0.8311083952242173
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 370159.5230102539
train_cost_avg: 43.323914210001625
train_count_sent: 8544.0
train_total_correct_sent: 5054.0
train_accuracy_sent: 0.5915262172284644
train_count_tok: 163566.0
train_total_correct_tok: 135471.0
train_accuracy_tok: 0.828234474157221
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007334963325183374
train_label=N_precision_sent: 0.5518409758301333
train_label=N_recall_sent: 0.7380664652567975
train_label=N_f-score_sent: 0.6315109215458188
train_label=P_precision_sent: 0.6345919610231425
train_label=P_recall_sent: 0.721606648199446
train_label=P_f-score_sent: 0.675307841866494
train_precision_macro_sent: 0.5621443122844253
train_recall_macro_sent: 0.4877892315790106
train_f-score_macro_sent: 0.43805124224583203
train_precision_micro_sent: 0.5915262172284644
train_recall_micro_sent: 0.5915262172284644
train_f-score_micro_sent: 0.5915262172284644
train_label=O_precision_tok: 0.8462933462293403
train_label=O_recall_tok: 0.9569913226696262
train_label=O_f-score_tok: 0.8982446340754607
train_label=N_precision_tok: 0.6815844823556906
train_label=N_recall_tok: 0.41071680045064074
train_label=N_f-score_tok: 0.5125659050966609
train_label=P_precision_tok: 0.7390247290914143
train_label=P_recall_tok: 0.42527081584522525
train_label=P_f-score_tok: 0.5398726308578388
train_precision_macro_tok: 0.7556341858921485
train_recall_macro_tok: 0.5976596463218307
train_f-score_macro_tok: 0.6502277233433201
train_precision_micro_tok: 0.828234474157221
train_recall_micro_tok: 0.828234474157221
train_f-score_micro_tok: 0.828234474157221
train_time: 146.3151319026947
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0037    0.0073      1624
           N     0.5518    0.7381    0.6315      3310
           P     0.6346    0.7216    0.6753      3610

   micro avg     0.5915    0.5915    0.5915      8544
   macro avg     0.5621    0.4878    0.4381      8544
weighted avg     0.5770    0.5915    0.5314      8544

F1-macro sent:  0.43805124224583203
F1-micro sent:  0.5915262172284644
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8463    0.9570    0.8982    124347
           N     0.6816    0.4107    0.5126     14202
           P     0.7390    0.4253    0.5399     25017

   micro avg     0.8282    0.8282    0.8282    163566
   macro avg     0.7556    0.5977    0.6502    163566
weighted avg     0.8156    0.8282    0.8099    163566

F1-macro tok:  0.6502277233433201
F1-micro tok:  0.828234474157221
**************************************************
dev_cost_sum: 48389.54577636719
dev_cost_avg: 43.95054112294931
dev_count_sent: 1101.0
dev_total_correct_sent: 675.0
dev_accuracy_sent: 0.6130790190735694
dev_count_tok: 21274.0
dev_total_correct_tok: 18175.0
dev_accuracy_tok: 0.8543292281658362
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.033898305084745756
dev_label=N_precision_sent: 0.6122047244094488
dev_label=N_recall_sent: 0.7266355140186916
dev_label=N_f-score_sent: 0.6645299145299145
dev_label=P_precision_sent: 0.6143344709897611
dev_label=P_recall_sent: 0.8108108108108109
dev_label=P_f-score_sent: 0.6990291262135923
dev_precision_macro_sent: 0.5993225889425938
dev_recall_macro_sent: 0.5183045245792665
dev_f-score_macro_sent: 0.46581911527608416
dev_precision_micro_sent: 0.6130790190735694
dev_recall_micro_sent: 0.6130790190735694
dev_f-score_micro_sent: 0.6130790190735694
dev_label=O_precision_tok: 0.8705750350631136
dev_label=O_recall_tok: 0.9576056772601049
dev_label=O_f-score_tok: 0.9120188069350573
dev_label=N_precision_tok: 0.7411764705882353
dev_label=N_recall_tok: 0.4410339256865913
dev_label=N_f-score_tok: 0.5530047265361242
dev_label=P_precision_tok: 0.7841296928327645
dev_label=P_recall_tok: 0.5722291407222914
dev_label=P_f-score_tok: 0.6616270698344132
dev_precision_macro_tok: 0.7986270661613711
dev_recall_macro_tok: 0.6569562478896626
dev_f-score_macro_tok: 0.7088835344351981
dev_precision_micro_tok: 0.8543292281658362
dev_recall_micro_tok: 0.8543292281658362
dev_f-score_micro_tok: 0.8543292281658362
dev_time: 7.557776927947998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0175    0.0339       229
           N     0.6122    0.7266    0.6645       428
           P     0.6143    0.8108    0.6990       444

   micro avg     0.6131    0.6131    0.6131      1101
   macro avg     0.5993    0.5183    0.4658      1101
weighted avg     0.6046    0.6131    0.5473      1101

F1-macro sent:  0.46581911527608416
F1-micro sent:  0.6130790190735694
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8706    0.9576    0.9120     16205
           N     0.7412    0.4410    0.5530      1857
           P     0.7841    0.5722    0.6616      3212

   micro avg     0.8543    0.8543    0.8543     21274
   macro avg     0.7986    0.6570    0.7089     21274
weighted avg     0.8462    0.8543    0.8429     21274

F1-macro tok:  0.7088835344351981
F1-micro tok:  0.8543292281658362
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 363127.90002441406
train_cost_avg: 42.50092462832561
train_count_sent: 8544.0
train_total_correct_sent: 5169.0
train_accuracy_sent: 0.6049859550561798
train_count_tok: 163566.0
train_total_correct_tok: 137828.0
train_accuracy_tok: 0.8426445593827568
train_label=O_precision_sent: 0.4696969696969697
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.03668639053254438
train_label=N_precision_sent: 0.579172610556348
train_label=N_recall_sent: 0.7359516616314199
train_label=N_f-score_sent: 0.6482171367748802
train_label=P_precision_sent: 0.6324906367041199
train_label=P_recall_sent: 0.7484764542936289
train_label=P_f-score_sent: 0.6856127886323269
train_precision_macro_sent: 0.5604534056524791
train_recall_macro_sent: 0.5011722619585959
train_f-score_macro_sent: 0.4568387719799172
train_precision_micro_sent: 0.6049859550561798
train_recall_micro_sent: 0.6049859550561798
train_f-score_micro_sent: 0.6049859550561798
train_label=O_precision_tok: 0.8586427748992516
train_label=O_recall_tok: 0.959548682316421
train_label=O_f-score_tok: 0.9062956928604253
train_label=N_precision_tok: 0.7024885615444705
train_label=N_recall_tok: 0.44324742993944516
train_label=N_f-score_tok: 0.5435392652074429
train_label=P_precision_tok: 0.7808245445829338
train_label=P_recall_tok: 0.48830795059359633
train_label=P_f-score_tok: 0.6008558359155969
train_precision_macro_tok: 0.7806519603422185
train_recall_macro_tok: 0.6303680209498208
train_f-score_macro_tok: 0.6835635979944884
train_precision_micro_tok: 0.8426445593827568
train_recall_micro_tok: 0.8426445593827568
train_f-score_micro_tok: 0.8426445593827568
train_time: 147.58606362342834
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4697    0.0191    0.0367      1624
           N     0.5792    0.7360    0.6482      3310
           P     0.6325    0.7485    0.6856      3610

   micro avg     0.6050    0.6050    0.6050      8544
   macro avg     0.5605    0.5012    0.4568      8544
weighted avg     0.5809    0.6050    0.5478      8544

F1-macro sent:  0.4568387719799172
F1-micro sent:  0.6049859550561798
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8586    0.9595    0.9063    124347
           N     0.7025    0.4432    0.5435     14202
           P     0.7808    0.4883    0.6009     25017

   micro avg     0.8426    0.8426    0.8426    163566
   macro avg     0.7807    0.6304    0.6836    163566
weighted avg     0.8332    0.8426    0.8281    163566

F1-macro tok:  0.6835635979944884
F1-micro tok:  0.8426445593827568
**************************************************
dev_cost_sum: 47711.76965332031
dev_cost_avg: 43.334940647884025
dev_count_sent: 1101.0
dev_total_correct_sent: 675.0
dev_accuracy_sent: 0.6130790190735694
dev_count_tok: 21274.0
dev_total_correct_tok: 18332.0
dev_accuracy_tok: 0.8617091285136786
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6441048034934498
dev_label=N_recall_sent: 0.6892523364485982
dev_label=N_f-score_sent: 0.6659142212189616
dev_label=P_precision_sent: 0.5909797822706065
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.6991720331186753
dev_precision_macro_sent: 0.41169486192135213
dev_recall_macro_sent: 0.5150360641014847
dev_f-score_macro_sent: 0.455028751445879
dev_precision_micro_sent: 0.6130790190735694
dev_recall_micro_sent: 0.6130790190735694
dev_f-score_micro_sent: 0.6130790190735694
dev_label=O_precision_tok: 0.8652656925518525
dev_label=O_recall_tok: 0.9756865165072508
dev_label=O_f-score_tok: 0.9171645687104821
dev_label=N_precision_tok: 0.8239277652370203
dev_label=N_recall_tok: 0.3931071620893915
dev_label=N_f-score_tok: 0.5322639445862195
dev_label=P_precision_tok: 0.8468085106382979
dev_label=P_recall_tok: 0.5575965130759651
dev_label=P_f-score_tok: 0.6724235029097052
dev_precision_macro_tok: 0.8453339894757236
dev_recall_macro_tok: 0.6421300638908692
dev_f-score_macro_tok: 0.7072840054021357
dev_precision_micro_tok: 0.8617091285136786
dev_recall_micro_tok: 0.8617091285136786
dev_f-score_micro_tok: 0.8617091285136786
dev_time: 7.188715696334839
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6441    0.6893    0.6659       428
           P     0.5910    0.8559    0.6992       444

   micro avg     0.6131    0.6131    0.6131      1101
   macro avg     0.4117    0.5150    0.4550      1101
weighted avg     0.4887    0.6131    0.5408      1101

F1-macro sent:  0.455028751445879
F1-micro sent:  0.6130790190735694
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8653    0.9757    0.9172     16205
           N     0.8239    0.3931    0.5323      1857
           P     0.8468    0.5576    0.6724      3212

   micro avg     0.8617    0.8617    0.8617     21274
   macro avg     0.8453    0.6421    0.7073     21274
weighted avg     0.8589    0.8617    0.8466     21274

F1-macro tok:  0.7072840054021357
F1-micro tok:  0.8617091285136786
**************************************************
Best epoch: 2
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 357417.0196533203
train_cost_avg: 41.83251634519198
train_count_sent: 8544.0
train_total_correct_sent: 5264.0
train_accuracy_sent: 0.6161048689138576
train_count_tok: 163566.0
train_total_correct_tok: 139331.0
train_accuracy_tok: 0.8518335106317939
train_label=O_precision_sent: 0.4791666666666667
train_label=O_recall_sent: 0.01416256157635468
train_label=O_f-score_sent: 0.027511961722488036
train_label=N_precision_sent: 0.5829450139794967
train_label=N_recall_sent: 0.7558912386706949
train_label=N_f-score_sent: 0.6582478295185478
train_label=P_precision_sent: 0.6515223596574691
train_label=P_recall_sent: 0.7587257617728532
train_label=P_f-score_sent: 0.701049398515485
train_precision_macro_sent: 0.5712113467678775
train_recall_macro_sent: 0.5095931873399676
train_f-score_macro_sent: 0.46226972991884024
train_precision_micro_sent: 0.6161048689138576
train_recall_micro_sent: 0.6161048689138576
train_f-score_micro_sent: 0.6161048689138576
train_label=O_precision_tok: 0.8666700462030908
train_label=O_recall_tok: 0.9624277224219322
train_label=O_f-score_tok: 0.9120423117519519
train_label=N_precision_tok: 0.7144246353322529
train_label=N_recall_tok: 0.465568229826785
train_label=N_f-score_tok: 0.5637549558767107
train_label=P_precision_tok: 0.803944530046225
train_label=P_recall_tok: 0.5214054442978775
train_label=P_f-score_tok: 0.6325590417535523
train_precision_macro_tok: 0.7950130705271895
train_recall_macro_tok: 0.6498004655155315
train_f-score_macro_tok: 0.7027854364607382
train_precision_micro_tok: 0.8518335106317939
train_recall_micro_tok: 0.8518335106317939
train_f-score_micro_tok: 0.8518335106317939
train_time: 147.77542686462402
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4792    0.0142    0.0275      1624
           N     0.5829    0.7559    0.6582      3310
           P     0.6515    0.7587    0.7010      3610

   micro avg     0.6161    0.6161    0.6161      8544
   macro avg     0.5712    0.5096    0.4623      8544
weighted avg     0.5922    0.6161    0.5564      8544

F1-macro sent:  0.46226972991884024
F1-micro sent:  0.6161048689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8667    0.9624    0.9120    124347
           N     0.7144    0.4656    0.5638     14202
           P     0.8039    0.5214    0.6326     25017

   micro avg     0.8518    0.8518    0.8518    163566
   macro avg     0.7950    0.6498    0.7028    163566
weighted avg     0.8439    0.8518    0.8391    163566

F1-macro tok:  0.7027854364607382
F1-micro tok:  0.8518335106317939
**************************************************
dev_cost_sum: 47046.90466308594
dev_cost_avg: 42.73106690561847
dev_count_sent: 1101.0
dev_total_correct_sent: 663.0
dev_accuracy_sent: 0.6021798365122616
dev_count_tok: 21274.0
dev_total_correct_tok: 18517.0
dev_accuracy_tok: 0.8704051894331108
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008695652173913044
dev_label=N_precision_sent: 0.6725
dev_label=N_recall_sent: 0.6285046728971962
dev_label=N_f-score_sent: 0.6497584541062802
dev_label=P_precision_sent: 0.5614285714285714
dev_label=P_recall_sent: 0.8851351351351351
dev_label=P_f-score_sent: 0.687062937062937
dev_precision_macro_sent: 0.744642857142857
dev_recall_macro_sent: 0.5060022067531352
dev_f-score_macro_sent: 0.44850568111437666
dev_precision_micro_sent: 0.6021798365122616
dev_recall_micro_sent: 0.6021798365122616
dev_f-score_micro_sent: 0.6021798365122616
dev_label=O_precision_tok: 0.8821905459462505
dev_label=O_recall_tok: 0.9662449861153964
dev_label=O_f-score_tok: 0.9223066501737643
dev_label=N_precision_tok: 0.7414965986394558
dev_label=N_recall_tok: 0.5282714054927302
dev_label=N_f-score_tok: 0.6169811320754717
dev_label=P_precision_tok: 0.8528610354223434
dev_label=P_recall_tok: 0.5846824408468244
dev_label=P_f-score_tok: 0.6937569264868858
dev_precision_macro_tok: 0.8255160600026832
dev_recall_macro_tok: 0.6930662774849837
dev_f-score_macro_tok: 0.7443482362453739
dev_precision_micro_tok: 0.8704051894331108
dev_recall_micro_tok: 0.8704051894331108
dev_f-score_micro_tok: 0.8704051894331108
dev_time: 7.032775640487671
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0044    0.0087       229
           N     0.6725    0.6285    0.6498       428
           P     0.5614    0.8851    0.6871       444

   micro avg     0.6022    0.6022    0.6022      1101
   macro avg     0.7446    0.5060    0.4485      1101
weighted avg     0.6958    0.6022    0.5315      1101

F1-macro sent:  0.44850568111437666
F1-micro sent:  0.6021798365122616
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8822    0.9662    0.9223     16205
           N     0.7415    0.5283    0.6170      1857
           P     0.8529    0.5847    0.6938      3212

   micro avg     0.8704    0.8704    0.8704     21274
   macro avg     0.8255    0.6931    0.7443     21274
weighted avg     0.8655    0.8704    0.8611     21274

F1-macro tok:  0.7443482362453739
F1-micro tok:  0.8704051894331108
**************************************************
Best epoch: 2
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 353096.853515625
train_cost_avg: 41.32687892270892
train_count_sent: 8544.0
train_total_correct_sent: 5302.0
train_accuracy_sent: 0.6205524344569289
train_count_tok: 163566.0
train_total_correct_tok: 140178.0
train_accuracy_tok: 0.8570118484281575
train_label=O_precision_sent: 0.5428571428571428
train_label=O_recall_sent: 0.011699507389162561
train_label=O_f-score_sent: 0.022905364677516575
train_label=N_precision_sent: 0.5959232613908872
train_label=N_recall_sent: 0.7507552870090635
train_label=N_f-score_sent: 0.6644385026737969
train_label=P_precision_sent: 0.6448490435584237
train_label=P_recall_sent: 0.7750692520775623
train_label=P_f-score_sent: 0.7039879230091836
train_precision_macro_sent: 0.5945431492688179
train_recall_macro_sent: 0.5125080154919295
train_f-score_macro_sent: 0.46377726345349907
train_precision_micro_sent: 0.6205524344569289
train_recall_micro_sent: 0.6205524344569289
train_f-score_micro_sent: 0.6205524344569289
train_label=O_precision_tok: 0.8707258591876771
train_label=O_recall_tok: 0.9637385702912012
train_label=O_f-score_tok: 0.9148742065143124
train_label=N_precision_tok: 0.7282665825712183
train_label=N_recall_tok: 0.4878186170961836
train_label=N_f-score_tok: 0.5842715580855998
train_label=P_precision_tok: 0.8166595628082567
train_label=P_recall_tok: 0.5361154414997802
train_label=P_f-score_tok: 0.6472972972972973
train_precision_macro_tok: 0.8052173348557173
train_recall_macro_tok: 0.6625575429623883
train_f-score_macro_tok: 0.7154810206324033
train_precision_micro_tok: 0.8570118484281575
train_recall_micro_tok: 0.8570118484281575
train_f-score_micro_tok: 0.8570118484281575
train_time: 147.35069489479065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5429    0.0117    0.0229      1624
           N     0.5959    0.7508    0.6644      3310
           P     0.6448    0.7751    0.7040      3610

   micro avg     0.6206    0.6206    0.6206      8544
   macro avg     0.5945    0.5125    0.4638      8544
weighted avg     0.6065    0.6206    0.5592      8544

F1-macro sent:  0.46377726345349907
F1-micro sent:  0.6205524344569289
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8707    0.9637    0.9149    124347
           N     0.7283    0.4878    0.5843     14202
           P     0.8167    0.5361    0.6473     25017

   micro avg     0.8570    0.8570    0.8570    163566
   macro avg     0.8052    0.6626    0.7155    163566
weighted avg     0.8501    0.8570    0.8452    163566

F1-macro tok:  0.7154810206324033
F1-micro tok:  0.8570118484281575
**************************************************
dev_cost_sum: 46573.69421386719
dev_cost_avg: 42.301266315955665
dev_count_sent: 1101.0
dev_total_correct_sent: 682.0
dev_accuracy_sent: 0.6194368755676658
dev_count_tok: 21274.0
dev_total_correct_tok: 18616.0
dev_accuracy_tok: 0.8750587571683746
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6477987421383647
dev_label=N_recall_sent: 0.7219626168224299
dev_label=N_f-score_sent: 0.6828729281767956
dev_label=P_precision_sent: 0.5977564102564102
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.6985018726591761
dev_precision_macro_sent: 0.41518505079825835
dev_recall_macro_sent: 0.5206842356375067
dev_f-score_macro_sent: 0.4604582669453239
dev_precision_micro_sent: 0.6194368755676658
dev_recall_micro_sent: 0.6194368755676658
dev_f-score_micro_sent: 0.6194368755676658
dev_label=O_precision_tok: 0.8815701185417133
dev_label=O_recall_tok: 0.9729095958037642
dev_label=O_f-score_tok: 0.9249904661327701
dev_label=N_precision_tok: 0.7879799666110183
dev_label=N_recall_tok: 0.5083467959073775
dev_label=N_f-score_tok: 0.6180032733224223
dev_label=P_precision_tok: 0.8695255474452555
dev_label=P_recall_tok: 0.5933997509339975
dev_label=P_f-score_tok: 0.7054034048852701
dev_precision_macro_tok: 0.846358544199329
dev_recall_macro_tok: 0.6915520475483797
dev_f-score_macro_tok: 0.7494657147801541
dev_precision_micro_tok: 0.8750587571683746
dev_recall_micro_tok: 0.8750587571683746
dev_f-score_micro_tok: 0.8750587571683746
dev_time: 6.957993984222412
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6478    0.7220    0.6829       428
           P     0.5978    0.8401    0.6985       444

   micro avg     0.6194    0.6194    0.6194      1101
   macro avg     0.4152    0.5207    0.4605      1101
weighted avg     0.4929    0.6194    0.5471      1101

F1-macro sent:  0.4604582669453239
F1-micro sent:  0.6194368755676658
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8816    0.9729    0.9250     16205
           N     0.7880    0.5083    0.6180      1857
           P     0.8695    0.5934    0.7054      3212

   micro avg     0.8751    0.8751    0.8751     21274
   macro avg     0.8464    0.6916    0.7495     21274
weighted avg     0.8716    0.8751    0.8650     21274

F1-macro tok:  0.7494657147801541
F1-micro tok:  0.8750587571683746
**************************************************
Best epoch: 2
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 349161.41131591797
train_cost_avg: 40.866270051020365
train_count_sent: 8544.0
train_total_correct_sent: 5319.0
train_accuracy_sent: 0.6225421348314607
train_count_tok: 163566.0
train_total_correct_tok: 140952.0
train_accuracy_tok: 0.8617438832031107
train_label=O_precision_sent: 0.4722222222222222
train_label=O_recall_sent: 0.020935960591133004
train_label=O_f-score_sent: 0.04009433962264151
train_label=N_precision_sent: 0.5879247015610652
train_label=N_recall_sent: 0.7737160120845922
train_label=N_f-score_sent: 0.6681450560918342
train_label=P_precision_sent: 0.6618075801749271
train_label=P_recall_sent: 0.7545706371191135
train_label=P_f-score_sent: 0.7051514367072224
train_precision_macro_sent: 0.5739848346527382
train_recall_macro_sent: 0.5164075365982795
train_f-score_macro_sent: 0.4711302774738993
train_precision_micro_sent: 0.6225421348314607
train_recall_micro_sent: 0.6225421348314607
train_f-score_micro_sent: 0.6225421348314607
train_label=O_precision_tok: 0.874941673957422
train_label=O_recall_tok: 0.9650976702292777
train_label=O_f-score_tok: 0.9178109954991645
train_label=N_precision_tok: 0.7385325808106722
train_label=N_recall_tok: 0.5067596113223489
train_label=N_f-score_tok: 0.6010773792124274
train_label=P_precision_tok: 0.8251605545885601
train_label=P_recall_tok: 0.549546308510213
train_label=P_f-score_tok: 0.6597245549210614
train_precision_macro_tok: 0.8128782697855513
train_recall_macro_tok: 0.6738011966872799
train_f-score_macro_tok: 0.7262043098775511
train_precision_micro_tok: 0.8617438832031107
train_recall_micro_tok: 0.8617438832031107
train_f-score_micro_tok: 0.8617438832031107
train_time: 147.43992614746094
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4722    0.0209    0.0401      1624
           N     0.5879    0.7737    0.6681      3310
           P     0.6618    0.7546    0.7052      3610

   micro avg     0.6225    0.6225    0.6225      8544
   macro avg     0.5740    0.5164    0.4711      8544
weighted avg     0.5971    0.6225    0.5644      8544

F1-macro sent:  0.4711302774738993
F1-micro sent:  0.6225421348314607
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8749    0.9651    0.9178    124347
           N     0.7385    0.5068    0.6011     14202
           P     0.8252    0.5495    0.6597     25017

   micro avg     0.8617    0.8617    0.8617    163566
   macro avg     0.8129    0.6738    0.7262    163566
weighted avg     0.8555    0.8617    0.8508    163566

F1-macro tok:  0.7262043098775511
F1-micro tok:  0.8617438832031107
**************************************************
dev_cost_sum: 46211.90417480469
dev_cost_avg: 41.97266500890526
dev_count_sent: 1101.0
dev_total_correct_sent: 689.0
dev_accuracy_sent: 0.6257947320617621
dev_count_tok: 21274.0
dev_total_correct_tok: 18710.0
dev_accuracy_tok: 0.87947729623014
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.6354581673306773
dev_label=N_recall_sent: 0.7453271028037384
dev_label=N_f-score_sent: 0.6860215053763441
dev_label=P_precision_sent: 0.6168067226890757
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7064485081809433
dev_precision_macro_sent: 0.6674216300065843
dev_recall_macro_sent: 0.528334705353846
dev_f-score_macro_sent: 0.4727403621728869
dev_precision_micro_sent: 0.6257947320617621
dev_recall_micro_sent: 0.6257947320617621
dev_f-score_micro_sent: 0.6257947320617621
dev_label=O_precision_tok: 0.8813860506441582
dev_label=O_recall_tok: 0.9794507867941993
dev_label=O_f-score_tok: 0.9278344488936954
dev_label=N_precision_tok: 0.8294930875576036
dev_label=N_recall_tok: 0.48465266558966075
dev_label=N_f-score_tok: 0.6118286879673691
dev_label=P_precision_tok: 0.8885832187070152
dev_label=P_recall_tok: 0.6033623910336239
dev_label=P_f-score_tok: 0.7187094381605784
dev_precision_macro_tok: 0.8664874523029257
dev_recall_macro_tok: 0.6891552811391612
dev_f-score_macro_tok: 0.7527908583405476
dev_precision_micro_tok: 0.87947729623014
dev_recall_micro_tok: 0.87947729623014
dev_f-score_micro_tok: 0.87947729623014
dev_time: 7.383944034576416
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.6355    0.7453    0.6860       428
           P     0.6168    0.8266    0.7064       444

   micro avg     0.6258    0.6258    0.6258      1101
   macro avg     0.6674    0.5283    0.4727      1101
weighted avg     0.6518    0.6258    0.5569      1101

F1-macro sent:  0.4727403621728869
F1-micro sent:  0.6257947320617621
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8814    0.9795    0.9278     16205
           N     0.8295    0.4847    0.6118      1857
           P     0.8886    0.6034    0.7187      3212

   micro avg     0.8795    0.8795    0.8795     21274
   macro avg     0.8665    0.6892    0.7528     21274
weighted avg     0.8779    0.8795    0.8687     21274

F1-macro tok:  0.7527908583405476
F1-micro tok:  0.87947729623014
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 345152.3112792969
train_cost_avg: 40.39704017782033
train_count_sent: 8544.0
train_total_correct_sent: 5373.0
train_accuracy_sent: 0.6288623595505618
train_count_tok: 163566.0
train_total_correct_tok: 141879.0
train_accuracy_tok: 0.8674113202010197
train_label=O_precision_sent: 0.4025974025974026
train_label=O_recall_sent: 0.019088669950738917
train_label=O_f-score_sent: 0.036449147560258674
train_label=N_precision_sent: 0.5896916497861805
train_label=N_recall_sent: 0.7915407854984894
train_label=N_f-score_sent: 0.6758674061653553
train_label=P_precision_sent: 0.6764413518886679
train_label=P_recall_sent: 0.754016620498615
train_label=P_f-score_sent: 0.713125491223474
train_precision_macro_sent: 0.5562434680907503
train_recall_macro_sent: 0.5215486919826144
train_f-score_macro_sent: 0.4751473483163626
train_precision_micro_sent: 0.6288623595505618
train_recall_micro_sent: 0.6288623595505618
train_f-score_micro_sent: 0.6288623595505618
train_label=O_precision_tok: 0.8794331427234304
train_label=O_recall_tok: 0.967180551199466
train_label=O_f-score_tok: 0.9212220558328003
train_label=N_precision_tok: 0.7425185780277164
train_label=N_recall_tok: 0.5206308970567526
train_label=N_f-score_tok: 0.6120860927152317
train_label=P_precision_tok: 0.8436572920374985
train_label=P_recall_tok: 0.5683735060159092
train_label=P_f-score_tok: 0.679181294929665
train_precision_macro_tok: 0.8218696709295484
train_recall_macro_tok: 0.685394984757376
train_f-score_macro_tok: 0.7374964811592323
train_precision_micro_tok: 0.8674113202010197
train_recall_micro_tok: 0.8674113202010197
train_f-score_micro_tok: 0.8674113202010197
train_time: 147.33150029182434
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4026    0.0191    0.0364      1624
           N     0.5897    0.7915    0.6759      3310
           P     0.6764    0.7540    0.7131      3610

   micro avg     0.6289    0.6289    0.6289      8544
   macro avg     0.5562    0.5215    0.4751      8544
weighted avg     0.5908    0.6289    0.5701      8544

F1-macro sent:  0.4751473483163626
F1-micro sent:  0.6288623595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8794    0.9672    0.9212    124347
           N     0.7425    0.5206    0.6121     14202
           P     0.8437    0.5684    0.6792     25017

   micro avg     0.8674    0.8674    0.8674    163566
   macro avg     0.8219    0.6854    0.7375    163566
weighted avg     0.8621    0.8674    0.8574    163566

F1-macro tok:  0.7374964811592323
F1-micro tok:  0.8674113202010197
**************************************************
dev_cost_sum: 45725.99328613281
dev_cost_avg: 41.531329051891746
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18784.0
dev_accuracy_tok: 0.8829557205979129
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07468879668049792
dev_label=N_precision_sent: 0.5637393767705382
dev_label=N_recall_sent: 0.9299065420560748
dev_label=N_f-score_sent: 0.7019400352733687
dev_label=P_precision_sent: 0.762402088772846
dev_label=P_recall_sent: 0.6576576576576577
dev_label=P_f-score_sent: 0.7061668681983072
dev_precision_macro_sent: 0.692047155181128
dev_recall_macro_sent: 0.5422885032524669
dev_f-score_macro_sent: 0.494265233384058
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8973726480036714
dev_label=O_recall_tok: 0.965319345880901
dev_label=O_f-score_tok: 0.9301067277105569
dev_label=N_precision_tok: 0.7221147646679562
dev_label=N_recall_tok: 0.6031233171782445
dev_label=N_f-score_tok: 0.6572769953051644
dev_label=P_precision_tok: 0.8821475338280227
dev_label=P_recall_tok: 0.6292029887920298
dev_label=P_f-score_tok: 0.7345084499363983
dev_precision_macro_tok: 0.8338783154998834
dev_recall_macro_tok: 0.7325485506170585
dev_f-score_macro_tok: 0.7739640576507064
dev_precision_micro_tok: 0.8829557205979129
dev_recall_micro_tok: 0.8829557205979129
dev_f-score_micro_tok: 0.8829557205979129
dev_time: 8.168598175048828
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0393    0.0747       229
           N     0.5637    0.9299    0.7019       428
           P     0.7624    0.6577    0.7062       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.6920    0.5423    0.4943      1101
weighted avg     0.6826    0.6349    0.5732      1101

F1-macro sent:  0.494265233384058
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8974    0.9653    0.9301     16205
           N     0.7221    0.6031    0.6573      1857
           P     0.8821    0.6292    0.7345      3212

   micro avg     0.8830    0.8830    0.8830     21274
   macro avg     0.8339    0.7325    0.7740     21274
weighted avg     0.8798    0.8830    0.8768     21274

F1-macro tok:  0.7739640576507064
F1-micro tok:  0.8829557205979129
**************************************************
Best epoch: 7
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 342076.56005859375
train_cost_avg: 40.03705056865564
train_count_sent: 8544.0
train_total_correct_sent: 5417.0
train_accuracy_sent: 0.6340121722846442
train_count_tok: 163566.0
train_total_correct_tok: 142216.0
train_accuracy_tok: 0.8694716505875304
train_label=O_precision_sent: 0.5108695652173914
train_label=O_recall_sent: 0.02894088669950739
train_label=O_f-score_sent: 0.05477855477855478
train_label=N_precision_sent: 0.5989354316130525
train_label=N_recall_sent: 0.7818731117824773
train_label=N_f-score_sent: 0.6782859389332982
train_label=P_precision_sent: 0.673444686516582
train_label=P_recall_sent: 0.7706371191135734
train_label=P_f-score_sent: 0.718770184730655
train_precision_macro_sent: 0.5944165611156753
train_recall_macro_sent: 0.5271503725318527
train_f-score_macro_sent: 0.48394489281416936
train_precision_micro_sent: 0.6340121722846442
train_recall_micro_sent: 0.6340121722846442
train_f-score_micro_sent: 0.6340121722846442
train_label=O_precision_tok: 0.8813053988718775
train_label=O_recall_tok: 0.9675102736696503
train_label=O_f-score_tok: 0.9223980955082669
train_label=N_precision_tok: 0.7454348040667259
train_label=N_recall_tok: 0.5317560906914519
train_label=N_f-score_tok: 0.6207208317922164
train_label=P_precision_tok: 0.8482717872968981
train_label=P_recall_tok: 0.5738897549666226
train_label=P_f-score_tok: 0.684612083353202
train_precision_macro_tok: 0.8250039967451673
train_recall_macro_tok: 0.6910520397759082
train_f-score_macro_tok: 0.7425770035512285
train_precision_micro_tok: 0.8694716505875304
train_recall_micro_tok: 0.8694716505875304
train_f-score_micro_tok: 0.8694716505875304
train_time: 146.39263916015625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5109    0.0289    0.0548      1624
           N     0.5989    0.7819    0.6783      3310
           P     0.6734    0.7706    0.7188      3610

   micro avg     0.6340    0.6340    0.6340      8544
   macro avg     0.5944    0.5272    0.4839      8544
weighted avg     0.6137    0.6340    0.5769      8544

F1-macro sent:  0.48394489281416936
F1-micro sent:  0.6340121722846442
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8813    0.9675    0.9224    124347
           N     0.7454    0.5318    0.6207     14202
           P     0.8483    0.5739    0.6846     25017

   micro avg     0.8695    0.8695    0.8695    163566
   macro avg     0.8250    0.6911    0.7426    163566
weighted avg     0.8645    0.8695    0.8598    163566

F1-macro tok:  0.7425770035512285
F1-micro tok:  0.8694716505875304
**************************************************
dev_cost_sum: 45399.13885498047
dev_cost_avg: 41.23445854221659
dev_count_sent: 1101.0
dev_total_correct_sent: 699.0
dev_accuracy_sent: 0.6348773841961853
dev_count_tok: 21274.0
dev_total_correct_tok: 18851.0
dev_accuracy_tok: 0.8861051048227884
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.6462167689161554
dev_label=N_recall_sent: 0.7383177570093458
dev_label=N_f-score_sent: 0.6892039258451472
dev_label=P_precision_sent: 0.6239737274220033
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7217473884140552
dev_precision_macro_sent: 0.756730165446053
dev_recall_macro_sent: 0.5357580165154748
dev_f-score_macro_sent: 0.47893779440823986
dev_precision_micro_sent: 0.6348773841961853
dev_recall_micro_sent: 0.6348773841961853
dev_f-score_micro_sent: 0.6348773841961853
dev_label=O_precision_tok: 0.8914243858462926
dev_label=O_recall_tok: 0.9763036099969146
dev_label=O_f-score_tok: 0.9319353223573763
dev_label=N_precision_tok: 0.7888293802601377
dev_label=N_recall_tok: 0.5551965535810447
dev_label=N_f-score_tok: 0.6517067003792668
dev_label=P_precision_tok: 0.9008562415502479
dev_label=P_recall_tok: 0.6223536737235368
dev_label=P_f-score_tok: 0.7361443564721046
dev_precision_macro_tok: 0.8603700025522261
dev_recall_macro_tok: 0.7179512791004986
dev_f-score_macro_tok: 0.7732621264029159
dev_precision_micro_tok: 0.8861051048227884
dev_recall_micro_tok: 0.8861051048227884
dev_f-score_micro_tok: 0.8861051048227884
dev_time: 8.311172008514404
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6462    0.7383    0.6892       428
           P     0.6240    0.8559    0.7217       444

   micro avg     0.6349    0.6349    0.6349      1101
   macro avg     0.7567    0.5358    0.4789      1101
weighted avg     0.7108    0.6349    0.5644      1101

F1-macro sent:  0.47893779440823986
F1-micro sent:  0.6348773841961853
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8914    0.9763    0.9319     16205
           N     0.7888    0.5552    0.6517      1857
           P     0.9009    0.6224    0.7361      3212

   micro avg     0.8861    0.8861    0.8861     21274
   macro avg     0.8604    0.7180    0.7733     21274
weighted avg     0.8839    0.8861    0.8779     21274

F1-macro tok:  0.7732621264029159
F1-micro tok:  0.8861051048227884
**************************************************
Best epoch: 7
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 338637.498046875
train_cost_avg: 39.63453862908181
train_count_sent: 8544.0
train_total_correct_sent: 5442.0
train_accuracy_sent: 0.636938202247191
train_count_tok: 163566.0
train_total_correct_tok: 142785.0
train_accuracy_tok: 0.8729503686585232
train_label=O_precision_sent: 0.44696969696969696
train_label=O_recall_sent: 0.03633004926108374
train_label=O_f-score_sent: 0.06719817767653757
train_label=N_precision_sent: 0.6028385295486273
train_label=N_recall_sent: 0.7827794561933534
train_label=N_f-score_sent: 0.6811251314405888
train_label=P_precision_sent: 0.6786582401555663
train_label=P_recall_sent: 0.7734072022160665
train_label=P_f-score_sent: 0.7229414810978767
train_precision_macro_sent: 0.5761554888912969
train_recall_macro_sent: 0.5308389025568346
train_f-score_macro_sent: 0.49042159673833435
train_precision_micro_sent: 0.636938202247191
train_recall_micro_sent: 0.636938202247191
train_f-score_micro_sent: 0.636938202247191
train_label=O_precision_tok: 0.8844049498769875
train_label=O_recall_tok: 0.9684592310228635
train_label=O_f-score_tok: 0.9245255496867707
train_label=N_precision_tok: 0.7562640148191478
train_label=N_recall_tok: 0.5461906773693846
train_label=N_f-score_tok: 0.6342859479128338
train_label=P_precision_tok: 0.8517848810079328
train_label=P_recall_tok: 0.5837230683135468
train_label=P_f-score_tok: 0.6927255046132682
train_precision_macro_tok: 0.8308179485680226
train_recall_macro_tok: 0.6994576589019316
train_f-score_macro_tok: 0.7505123340709576
train_precision_micro_tok: 0.8729503686585232
train_recall_micro_tok: 0.8729503686585232
train_f-score_micro_tok: 0.8729503686585232
train_time: 145.84059119224548
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4470    0.0363    0.0672      1624
           N     0.6028    0.7828    0.6811      3310
           P     0.6787    0.7734    0.7229      3610

   micro avg     0.6369    0.6369    0.6369      8544
   macro avg     0.5762    0.5308    0.4904      8544
weighted avg     0.6052    0.6369    0.5821      8544

F1-macro sent:  0.49042159673833435
F1-micro sent:  0.636938202247191
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8844    0.9685    0.9245    124347
           N     0.7563    0.5462    0.6343     14202
           P     0.8518    0.5837    0.6927     25017

   micro avg     0.8730    0.8730    0.8730    163566
   macro avg     0.8308    0.6995    0.7505    163566
weighted avg     0.8683    0.8730    0.8639    163566

F1-macro tok:  0.7505123340709576
F1-micro tok:  0.8729503686585232
**************************************************
dev_cost_sum: 45164.132080078125
dev_cost_avg: 41.02101006364952
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 18808.0
dev_accuracy_tok: 0.8840838582307041
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6439688715953308
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.70276008492569
dev_label=P_precision_sent: 0.6393162393162393
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7269193391642371
dev_precision_macro_sent: 0.7610950369705233
dev_recall_macro_sent: 0.541480150925933
dev_f-score_macro_sent: 0.4823318138019815
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8801188903566711
dev_label=O_recall_tok: 0.9867324899722308
dev_label=O_f-score_tok: 0.9303814040089606
dev_label=N_precision_tok: 0.8424908424908425
dev_label=N_recall_tok: 0.49542272482498656
dev_label=N_f-score_tok: 0.6239403187521194
dev_label=P_precision_tok: 0.94240317775571
dev_label=P_recall_tok: 0.5909090909090909
dev_label=P_f-score_tok: 0.72636815920398
dev_precision_macro_tok: 0.8883376368677413
dev_recall_macro_tok: 0.6910214352354361
dev_f-score_macro_tok: 0.7602299606550201
dev_precision_micro_tok: 0.8840838582307041
dev_recall_micro_tok: 0.8840838582307041
dev_f-score_micro_tok: 0.8840838582307041
dev_time: 8.250323057174683
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6440    0.7734    0.7028       428
           P     0.6393    0.8423    0.7269       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7611    0.5415    0.4823      1101
weighted avg     0.7161    0.6421    0.5699      1101

F1-macro sent:  0.4823318138019815
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8801    0.9867    0.9304     16205
           N     0.8425    0.4954    0.6239      1857
           P     0.9424    0.5909    0.7264      3212

   micro avg     0.8841    0.8841    0.8841     21274
   macro avg     0.8883    0.6910    0.7602     21274
weighted avg     0.8862    0.8841    0.8728     21274

F1-macro tok:  0.7602299606550201
F1-micro tok:  0.8840838582307041
**************************************************
Best epoch: 7
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 335752.0068359375
train_cost_avg: 39.296817279487065
train_count_sent: 8544.0
train_total_correct_sent: 5541.0
train_accuracy_sent: 0.6485252808988764
train_count_tok: 163566.0
train_total_correct_tok: 143356.0
train_accuracy_tok: 0.8764413142095545
train_label=O_precision_sent: 0.4375
train_label=O_recall_sent: 0.03017241379310345
train_label=O_f-score_sent: 0.05645161290322581
train_label=N_precision_sent: 0.6077460031524431
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.696426267578377
train_label=P_precision_sent: 0.6998246053620647
train_label=P_recall_sent: 0.7736842105263158
train_label=P_f-score_sent: 0.7349033021970794
train_precision_macro_sent: 0.5816902028381693
train_recall_macro_sent: 0.5397548264347711
train_f-score_macro_sent: 0.49592706089289407
train_precision_micro_sent: 0.6485252808988764
train_recall_micro_sent: 0.6485252808988764
train_f-score_micro_sent: 0.6485252808988764
train_label=O_precision_tok: 0.8872542886790648
train_label=O_recall_tok: 0.969552944582499
train_label=O_f-score_tok: 0.9265797685106906
train_label=N_precision_tok: 0.7598123683706682
train_label=N_recall_tok: 0.5588649485987889
train_label=N_f-score_tok: 0.6440279130152549
train_label=P_precision_tok: 0.8618829398456987
train_label=P_recall_tok: 0.5939161370268218
train_label=P_f-score_tok: 0.7032374100719425
train_precision_macro_tok: 0.8363165322984772
train_recall_macro_tok: 0.7074446767360364
train_f-score_macro_tok: 0.7579483638659626
train_precision_micro_tok: 0.8764413142095545
train_recall_micro_tok: 0.8764413142095545
train_f-score_micro_tok: 0.8764413142095545
train_time: 145.86338663101196
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4375    0.0302    0.0565      1624
           N     0.6077    0.8154    0.6964      3310
           P     0.6998    0.7737    0.7349      3610

   micro avg     0.6485    0.6485    0.6485      8544
   macro avg     0.5817    0.5398    0.4959      8544
weighted avg     0.6143    0.6485    0.5910      8544

F1-macro sent:  0.49592706089289407
F1-micro sent:  0.6485252808988764
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8873    0.9696    0.9266    124347
           N     0.7598    0.5589    0.6440     14202
           P     0.8619    0.5939    0.7032     25017

   micro avg     0.8764    0.8764    0.8764    163566
   macro avg     0.8363    0.7074    0.7579    163566
weighted avg     0.8723    0.8764    0.8679    163566

F1-macro tok:  0.7579483638659626
F1-micro tok:  0.8764413142095545
**************************************************
dev_cost_sum: 44698.709716796875
dev_cost_avg: 40.598283121523046
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18937.0
dev_accuracy_tok: 0.8901475980069569
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.5590778097982709
dev_label=N_recall_sent: 0.9065420560747663
dev_label=N_f-score_sent: 0.6916221033868093
dev_label=P_precision_sent: 0.7333333333333333
dev_label=P_recall_sent: 0.668918918918919
dev_label=P_f-score_sent: 0.6996466431095406
dev_precision_macro_sent: 0.7641370477105348
dev_recall_macro_sent: 0.5280648664826112
dev_f-score_macro_sent: 0.4695282546041224
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8949389968368731
dev_label=O_recall_tok: 0.977722925023141
dev_label=O_f-score_tok: 0.9345011648824795
dev_label=N_precision_tok: 0.7872185911401598
dev_label=N_recall_tok: 0.5837372105546581
dev_label=N_f-score_tok: 0.6703772418058133
dev_label=P_precision_tok: 0.9160966712266302
dev_label=P_recall_tok: 0.6254669987546699
dev_label=P_f-score_tok: 0.7433857539315448
dev_precision_macro_tok: 0.8660847530678878
dev_recall_macro_tok: 0.7289757114441563
dev_f-score_macro_tok: 0.7827547202066124
dev_precision_micro_tok: 0.8901475980069569
dev_recall_micro_tok: 0.8901475980069569
dev_f-score_micro_tok: 0.8901475980069569
dev_time: 8.610169887542725
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.5591    0.9065    0.6916       428
           P     0.7333    0.6689    0.6996       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.7641    0.5281    0.4695      1101
weighted avg     0.7211    0.6240    0.5546      1101

F1-macro sent:  0.4695282546041224
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8949    0.9777    0.9345     16205
           N     0.7872    0.5837    0.6704      1857
           P     0.9161    0.6255    0.7434      3212

   micro avg     0.8901    0.8901    0.8901     21274
   macro avg     0.8661    0.7290    0.7828     21274
weighted avg     0.8887    0.8901    0.8826     21274

F1-macro tok:  0.7827547202066124
F1-micro tok:  0.8901475980069569
**************************************************
Best epoch: 7
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 333209.9002685547
train_cost_avg: 38.9992860801211
train_count_sent: 8544.0
train_total_correct_sent: 5470.0
train_accuracy_sent: 0.6402153558052435
train_count_tok: 163566.0
train_total_correct_tok: 143605.0
train_accuracy_tok: 0.8779636354743651
train_label=O_precision_sent: 0.5154639175257731
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.058105752469494475
train_label=N_precision_sent: 0.5998183057006586
train_label=N_recall_sent: 0.7978851963746224
train_label=N_f-score_sent: 0.6848178400103722
train_label=P_precision_sent: 0.6871909000989119
train_label=P_recall_sent: 0.7698060941828255
train_label=P_f-score_sent: 0.726156258165665
train_precision_macro_sent: 0.6008243744417813
train_recall_macro_sent: 0.5328264892991165
train_f-score_macro_sent: 0.48969328354851055
train_precision_micro_sent: 0.6402153558052435
train_recall_micro_sent: 0.6402153558052435
train_f-score_micro_sent: 0.6402153558052435
train_label=O_precision_tok: 0.8889069016845239
train_label=O_recall_tok: 0.9701078433737846
train_label=O_f-score_tok: 0.9277339619231464
train_label=N_precision_tok: 0.7605137963843959
train_label=N_recall_tok: 0.5628080552034924
train_label=N_f-score_tok: 0.6468921981223698
train_label=P_precision_tok: 0.8635158501440923
train_label=P_recall_tok: 0.5988727665187672
train_label=P_f-score_tok: 0.7072485661009748
train_precision_macro_tok: 0.8376455160710039
train_recall_macro_tok: 0.7105962216986814
train_f-score_macro_tok: 0.760624908715497
train_precision_micro_tok: 0.8779636354743651
train_recall_micro_tok: 0.8779636354743651
train_f-score_micro_tok: 0.8779636354743651
train_time: 202.41468358039856
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5155    0.0308    0.0581      1624
           N     0.5998    0.7979    0.6848      3310
           P     0.6872    0.7698    0.7262      3610

   micro avg     0.6402    0.6402    0.6402      8544
   macro avg     0.6008    0.5328    0.4897      8544
weighted avg     0.6207    0.6402    0.5832      8544

F1-macro sent:  0.48969328354851055
F1-micro sent:  0.6402153558052435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8889    0.9701    0.9277    124347
           N     0.7605    0.5628    0.6469     14202
           P     0.8635    0.5989    0.7072     25017

   micro avg     0.8780    0.8780    0.8780    163566
   macro avg     0.8376    0.7106    0.7606    163566
weighted avg     0.8739    0.8780    0.8696    163566

F1-macro tok:  0.760624908715497
F1-micro tok:  0.8779636354743651
**************************************************
dev_cost_sum: 44453.254821777344
dev_cost_avg: 40.37534497890767
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 18945.0
dev_accuracy_tok: 0.890523643884554
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6388888888888888
dev_label=N_recall_sent: 0.8060747663551402
dev_label=N_f-score_sent: 0.7128099173553718
dev_label=P_precision_sent: 0.6565295169946332
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7318045862412763
dev_precision_macro_sent: 0.7651394686278407
dev_recall_macro_sent: 0.5471283224619551
dev_f-score_macro_sent: 0.48731017363755513
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.8935367638779417
dev_label=O_recall_tok: 0.979389077445233
dev_label=O_f-score_tok: 0.9344952453852269
dev_label=N_precision_tok: 0.8096
dev_label=N_recall_tok: 0.5449649973074852
dev_label=N_f-score_tok: 0.6514322497586096
dev_label=P_precision_tok: 0.9115826702033598
dev_label=P_recall_tok: 0.6419676214196762
dev_label=P_f-score_tok: 0.7533796127146511
dev_precision_macro_tok: 0.8715731446937672
dev_recall_macro_tok: 0.7221072320574647
dev_f-score_macro_tok: 0.7797690359528292
dev_precision_micro_tok: 0.890523643884554
dev_recall_micro_tok: 0.890523643884554
dev_f-score_micro_tok: 0.890523643884554
dev_time: 15.031467199325562
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6389    0.8061    0.7128       428
           P     0.6565    0.8266    0.7318       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.7651    0.5471    0.4873      1101
weighted avg     0.7211    0.6485    0.5758      1101

F1-macro sent:  0.48731017363755513
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9794    0.9345     16205
           N     0.8096    0.5450    0.6514      1857
           P     0.9116    0.6420    0.7534      3212

   micro avg     0.8905    0.8905    0.8905     21274
   macro avg     0.8716    0.7221    0.7798     21274
weighted avg     0.8889    0.8905    0.8824     21274

F1-macro tok:  0.7797690359528292
F1-micro tok:  0.890523643884554
**************************************************
Best epoch: 7
**************************************************

EPOCH: 12
Learning rate: 0.900000
train_cost_sum: 330781.33502197266
train_cost_avg: 38.71504389302115
train_count_sent: 8544.0
train_total_correct_sent: 5576.0
train_accuracy_sent: 0.6526217228464419
train_count_tok: 163566.0
train_total_correct_tok: 144053.0
train_accuracy_tok: 0.8807025910030202
train_label=O_precision_sent: 0.5648148148148148
train_label=O_recall_sent: 0.037561576354679806
train_label=O_f-score_sent: 0.07043879907621246
train_label=N_precision_sent: 0.6218527315914489
train_label=N_recall_sent: 0.7909365558912387
train_label=N_f-score_sent: 0.6962765957446809
train_label=P_precision_sent: 0.6855182205395173
train_label=P_recall_sent: 0.8024930747922437
train_label=P_f-score_sent: 0.7394078611536499
train_precision_macro_sent: 0.6240619223152604
train_recall_macro_sent: 0.5436637356793874
train_f-score_macro_sent: 0.5020410853248477
train_precision_micro_sent: 0.6526217228464419
train_recall_micro_sent: 0.6526217228464419
train_f-score_micro_sent: 0.6526217228464419
train_label=O_precision_tok: 0.8907965411403612
train_label=O_recall_tok: 0.970952254577915
train_label=O_f-score_tok: 0.9291488862295726
train_label=N_precision_tok: 0.7670114833444054
train_label=N_recall_tok: 0.5690747782002535
train_label=N_f-score_tok: 0.6533813007801448
train_label=P_precision_tok: 0.8709769622134568
train_label=P_recall_tok: 0.6090258624135588
train_label=P_f-score_tok: 0.7168195718654435
train_precision_macro_tok: 0.8429283288994078
train_recall_macro_tok: 0.716350965063909
train_f-score_macro_tok: 0.7664499196250536
train_precision_micro_tok: 0.8807025910030202
train_recall_micro_tok: 0.8807025910030202
train_f-score_micro_tok: 0.8807025910030202
train_time: 249.5644953250885
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5648    0.0376    0.0704      1624
           N     0.6219    0.7909    0.6963      3310
           P     0.6855    0.8025    0.7394      3610

   micro avg     0.6526    0.6526    0.6526      8544
   macro avg     0.6241    0.5437    0.5020      8544
weighted avg     0.6379    0.6526    0.5955      8544

F1-macro sent:  0.5020410853248477
F1-micro sent:  0.6526217228464419
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9710    0.9291    124347
           N     0.7670    0.5691    0.6534     14202
           P     0.8710    0.6090    0.7168     25017

   micro avg     0.8807    0.8807    0.8807    163566
   macro avg     0.8429    0.7164    0.7664    163566
weighted avg     0.8770    0.8807    0.8727    163566

F1-macro tok:  0.7664499196250536
F1-micro tok:  0.8807025910030202
**************************************************
dev_cost_sum: 44189.102294921875
dev_cost_avg: 40.13542442772196
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 18962.0
dev_accuracy_tok: 0.8913227413744477
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.12048192771084337
dev_label=N_precision_sent: 0.6335078534031413
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7252747252747251
dev_label=P_precision_sent: 0.6889763779527559
dev_label=P_recall_sent: 0.7882882882882883
dev_label=P_f-score_sent: 0.7352941176470589
dev_precision_macro_sent: 0.6908280771186325
dev_recall_macro_sent: 0.5673071042719657
dev_f-score_macro_sent: 0.5270169235442091
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.8925763701707098
dev_label=O_recall_tok: 0.9808701018204258
dev_label=O_f-score_tok: 0.9346426366389322
dev_label=N_precision_tok: 0.8387096774193549
dev_label=N_recall_tok: 0.5320409262250942
dev_label=N_f-score_tok: 0.6510708401976936
dev_label=P_precision_tok: 0.9086538461538461
dev_label=P_recall_tok: 0.6472602739726028
dev_label=P_f-score_tok: 0.756
dev_precision_macro_tok: 0.8799799645813037
dev_recall_macro_tok: 0.7200571006727076
dev_f-score_macro_tok: 0.7805711589455419
dev_precision_micro_tok: 0.8913227413744477
dev_recall_micro_tok: 0.8913227413744477
dev_f-score_micro_tok: 0.8913227413744476
dev_time: 15.441157579421997
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0655    0.1205       229
           N     0.6335    0.8481    0.7253       428
           P     0.6890    0.7883    0.7353       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6908    0.5673    0.5270      1101
weighted avg     0.6801    0.6612    0.6035      1101

F1-macro sent:  0.5270169235442091
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8926    0.9809    0.9346     16205
           N     0.8387    0.5320    0.6511      1857
           P     0.9087    0.6473    0.7560      3212

   micro avg     0.8913    0.8913    0.8913     21274
   macro avg     0.8800    0.7201    0.7806     21274
weighted avg     0.8903    0.8913    0.8829     21274

F1-macro tok:  0.7805711589455419
F1-micro tok:  0.8913227413744476
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 328406.7883300781
train_cost_avg: 38.43712410230315
train_count_sent: 8544.0
train_total_correct_sent: 5603.0
train_accuracy_sent: 0.6557818352059925
train_count_tok: 163566.0
train_total_correct_tok: 144246.0
train_accuracy_tok: 0.8818825428267488
train_label=O_precision_sent: 0.5038167938931297
train_label=O_recall_sent: 0.04064039408866995
train_label=O_f-score_sent: 0.07521367521367521
train_label=N_precision_sent: 0.6292459648277523
train_label=N_recall_sent: 0.7891238670694865
train_label=N_f-score_sent: 0.7001742393780994
train_label=P_precision_sent: 0.6862975129047395
train_label=P_recall_sent: 0.8102493074792244
train_label=P_f-score_sent: 0.743140243902439
train_precision_macro_sent: 0.6064534238752072
train_recall_macro_sent: 0.5466711895457936
train_f-score_macro_sent: 0.5061760528314045
train_precision_micro_sent: 0.6557818352059925
train_recall_micro_sent: 0.6557818352059925
train_f-score_micro_sent: 0.6557818352059925
train_label=O_precision_tok: 0.8924433007224675
train_label=O_recall_tok: 0.9705581960159875
train_label=O_f-score_tok: 0.9298630854694928
train_label=N_precision_tok: 0.7684507042253521
train_label=N_recall_tok: 0.5762568652302492
train_label=N_f-score_tok: 0.6586190246257846
train_label=P_precision_tok: 0.8694373763076053
train_label=P_recall_tok: 0.6146220570012392
train_label=P_f-score_tok: 0.7201536227811344
train_precision_macro_tok: 0.8434437937518083
train_recall_macro_tok: 0.7204790394158253
train_f-score_macro_tok: 0.7695452442921372
train_precision_micro_tok: 0.8818825428267488
train_recall_micro_tok: 0.8818825428267488
train_f-score_micro_tok: 0.8818825428267489
train_time: 249.00601387023926
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5038    0.0406    0.0752      1624
           N     0.6292    0.7891    0.7002      3310
           P     0.6863    0.8102    0.7431      3610

   micro avg     0.6558    0.6558    0.6558      8544
   macro avg     0.6065    0.5467    0.5062      8544
weighted avg     0.6295    0.6558    0.5995      8544

F1-macro sent:  0.5061760528314045
F1-micro sent:  0.6557818352059925
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8924    0.9706    0.9299    124347
           N     0.7685    0.5763    0.6586     14202
           P     0.8694    0.6146    0.7202     25017

   micro avg     0.8819    0.8819    0.8819    163566
   macro avg     0.8434    0.7205    0.7695    163566
weighted avg     0.8782    0.8819    0.8742    163566

F1-macro tok:  0.7695452442921372
F1-micro tok:  0.8818825428267489
**************************************************
dev_cost_sum: 44008.024963378906
dev_cost_avg: 39.97095818653852
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 19021.0
dev_accuracy_tok: 0.894096079721726
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017316017316017316
dev_label=N_precision_sent: 0.6129568106312292
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.716504854368932
dev_label=P_precision_sent: 0.6841046277665996
dev_label=P_recall_sent: 0.7657657657657657
dev_label=P_f-score_sent: 0.722635494155154
dev_precision_macro_sent: 0.7656871461326097
dev_recall_macro_sent: 0.5455496409767315
dev_f-score_macro_sent: 0.48548545528003445
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.9013465708090836
dev_label=O_recall_tok: 0.9748225856217216
dev_label=O_f-score_tok: 0.9366458154220154
dev_label=N_precision_tok: 0.7830056179775281
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.6796708320633953
dev_label=P_precision_tok: 0.907487091222031
dev_label=P_recall_tok: 0.6566002490660025
dev_label=P_f-score_tok: 0.761921965317919
dev_precision_macro_tok: 0.8639464266695476
dev_recall_macro_tok: 0.7439512123523792
dev_f-score_macro_tok: 0.7927462042677765
dev_precision_micro_tok: 0.894096079721726
dev_recall_micro_tok: 0.894096079721726
dev_f-score_micro_tok: 0.894096079721726
dev_time: 15.342820167541504
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0087    0.0173       229
           N     0.6130    0.8621    0.7165       428
           P     0.6841    0.7658    0.7226       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.7657    0.5455    0.4855      1101
weighted avg     0.7222    0.6458    0.5736      1101

F1-macro sent:  0.48548545528003445
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9013    0.9748    0.9366     16205
           N     0.7830    0.6004    0.6797      1857
           P     0.9075    0.6566    0.7619      3212

   micro avg     0.8941    0.8941    0.8941     21274
   macro avg     0.8639    0.7440    0.7927     21274
weighted avg     0.8919    0.8941    0.8878     21274

F1-macro tok:  0.7927462042677765
F1-micro tok:  0.894096079721726
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 326418.50354003906
train_cost_avg: 38.20441286751394
train_count_sent: 8544.0
train_total_correct_sent: 5607.0
train_accuracy_sent: 0.65625
train_count_tok: 163566.0
train_total_correct_tok: 144714.0
train_accuracy_tok: 0.8847437731557903
train_label=O_precision_sent: 0.5902777777777778
train_label=O_recall_sent: 0.05233990147783251
train_label=O_f-score_sent: 0.09615384615384615
train_label=N_precision_sent: 0.6137697516930023
train_label=N_recall_sent: 0.8214501510574018
train_label=N_f-score_sent: 0.7025839793281654
train_label=P_precision_sent: 0.7060453400503778
train_label=P_recall_sent: 0.7764542936288089
train_label=P_f-score_sent: 0.7395778364116096
train_precision_macro_sent: 0.6366976231737193
train_recall_macro_sent: 0.5500814487213478
train_f-score_macro_sent: 0.5127718872978737
train_precision_micro_sent: 0.65625
train_recall_micro_sent: 0.65625
train_f-score_micro_sent: 0.65625
train_label=O_precision_tok: 0.8943989930774072
train_label=O_recall_tok: 0.9714910693462648
train_label=O_f-score_tok: 0.9313524432177386
train_label=N_precision_tok: 0.7826573426573427
train_label=N_recall_tok: 0.5910435149978877
train_label=N_f-score_tok: 0.6734865808159827
train_label=P_precision_tok: 0.8729747974797479
train_label=P_recall_tok: 0.6202981972258864
train_label=P_f-score_tok: 0.7252588040100015
train_precision_macro_tok: 0.8500103777381659
train_recall_macro_tok: 0.727610927190013
train_f-score_macro_tok: 0.7766992760145742
train_precision_micro_tok: 0.8847437731557903
train_recall_micro_tok: 0.8847437731557903
train_f-score_micro_tok: 0.8847437731557903
train_time: 247.39474606513977
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5903    0.0523    0.0962      1624
           N     0.6138    0.8215    0.7026      3310
           P     0.7060    0.7765    0.7396      3610

   micro avg     0.6562    0.6562    0.6562      8544
   macro avg     0.6367    0.5501    0.5128      8544
weighted avg     0.6483    0.6562    0.6029      8544

F1-macro sent:  0.5127718872978737
F1-micro sent:  0.65625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9715    0.9314    124347
           N     0.7827    0.5910    0.6735     14202
           P     0.8730    0.6203    0.7253     25017

   micro avg     0.8847    0.8847    0.8847    163566
   macro avg     0.8500    0.7276    0.7767    163566
weighted avg     0.8814    0.8847    0.8774    163566

F1-macro tok:  0.7766992760145742
F1-micro tok:  0.8847437731557903
**************************************************
dev_cost_sum: 43795.9853515625
dev_cost_avg: 39.77836998325386
dev_count_sent: 1101.0
dev_total_correct_sent: 711.0
dev_accuracy_sent: 0.6457765667574932
dev_count_tok: 21274.0
dev_total_correct_tok: 19012.0
dev_accuracy_tok: 0.8936730281094294
dev_label=O_precision_sent: 0.6923076923076923
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.0743801652892562
dev_label=N_precision_sent: 0.5937007874015748
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7093132643461899
dev_label=P_precision_sent: 0.717439293598234
dev_label=P_recall_sent: 0.7319819819819819
dev_label=P_f-score_sent: 0.7246376811594202
dev_precision_macro_sent: 0.6678159244358337
dev_recall_macro_sent: 0.5507081378403257
dev_f-score_macro_sent: 0.5027770369316221
dev_precision_micro_sent: 0.6457765667574932
dev_recall_micro_sent: 0.6457765667574932
dev_f-score_micro_sent: 0.6457765667574932
dev_label=O_precision_tok: 0.8970604861503675
dev_label=O_recall_tok: 0.9792656587473002
dev_label=O_f-score_tok: 0.936362295323794
dev_label=N_precision_tok: 0.7905646890636169
dev_label=N_recall_tok: 0.5955842757135165
dev_label=N_f-score_tok: 0.6793611793611795
dev_label=P_precision_tok: 0.9322654462242563
dev_label=P_recall_tok: 0.6341843088418431
dev_label=P_f-score_tok: 0.7548638132295721
dev_precision_macro_tok: 0.8732968738127469
dev_recall_macro_tok: 0.7363447477675532
dev_f-score_macro_tok: 0.7901957626381818
dev_precision_micro_tok: 0.8936730281094294
dev_recall_micro_tok: 0.8936730281094294
dev_f-score_micro_tok: 0.8936730281094294
dev_time: 15.308747291564941
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6923    0.0393    0.0744       229
           N     0.5937    0.8808    0.7093       428
           P     0.7174    0.7320    0.7246       444

   micro avg     0.6458    0.6458    0.6458      1101
   macro avg     0.6678    0.5507    0.5028      1101
weighted avg     0.6641    0.6458    0.5834      1101

F1-macro sent:  0.5027770369316221
F1-micro sent:  0.6457765667574932
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8971    0.9793    0.9364     16205
           N     0.7906    0.5956    0.6794      1857
           P     0.9323    0.6342    0.7549      3212

   micro avg     0.8937    0.8937    0.8937     21274
   macro avg     0.8733    0.7363    0.7902     21274
weighted avg     0.8931    0.8937    0.8865     21274

F1-macro tok:  0.7901957626381818
F1-micro tok:  0.8936730281094294
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 324399.1446533203
train_cost_avg: 37.96806468320697
train_count_sent: 8544.0
train_total_correct_sent: 5629.0
train_accuracy_sent: 0.6588249063670412
train_count_tok: 163566.0
train_total_correct_tok: 144899.0
train_accuracy_tok: 0.8858748150593644
train_label=O_precision_sent: 0.49673202614379086
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.0855374226223973
train_label=N_precision_sent: 0.6319062425257116
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.7053797890802296
train_label=P_precision_sent: 0.6914489311163895
train_label=P_recall_sent: 0.8063711911357341
train_label=P_f-score_sent: 0.7445012787723785
train_precision_macro_sent: 0.6066957332619639
train_recall_macro_sent: 0.5504521772902107
train_f-score_macro_sent: 0.5118061634916685
train_precision_micro_sent: 0.6588249063670412
train_recall_micro_sent: 0.6588249063670412
train_f-score_micro_sent: 0.6588249063670412
train_label=O_precision_tok: 0.8964618526081307
train_label=O_recall_tok: 0.9709200865320434
train_label=O_f-score_tok: 0.9322065307193984
train_label=N_precision_tok: 0.7760335858355389
train_label=N_recall_tok: 0.5987184903534714
train_label=N_f-score_tok: 0.6759410151436862
train_label=P_precision_tok: 0.8734805397568863
train_label=P_recall_tok: 0.6261742015429508
train_label=P_f-score_tok: 0.7294358687807035
train_precision_macro_tok: 0.8486586594001854
train_recall_macro_tok: 0.7319375928094886
train_f-score_macro_tok: 0.7791944715479294
train_precision_micro_tok: 0.8858748150593644
train_recall_micro_tok: 0.8858748150593644
train_f-score_micro_tok: 0.8858748150593644
train_time: 248.527489900589
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4967    0.0468    0.0855      1624
           N     0.6319    0.7982    0.7054      3310
           P     0.6914    0.8064    0.7445      3610

   micro avg     0.6588    0.6588    0.6588      8544
   macro avg     0.6067    0.5505    0.5118      8544
weighted avg     0.6314    0.6588    0.6041      8544

F1-macro sent:  0.5118061634916685
F1-micro sent:  0.6588249063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8965    0.9709    0.9322    124347
           N     0.7760    0.5987    0.6759     14202
           P     0.8735    0.6262    0.7294     25017

   micro avg     0.8859    0.8859    0.8859    163566
   macro avg     0.8487    0.7319    0.7792    163566
weighted avg     0.8825    0.8859    0.8789    163566

F1-macro tok:  0.7791944715479294
F1-micro tok:  0.8858748150593644
**************************************************
dev_cost_sum: 43682.2060546875
dev_cost_avg: 39.67502820589237
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19015.0
dev_accuracy_tok: 0.8938140453135283
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06666666666666667
dev_label=N_precision_sent: 0.6485981308411215
dev_label=N_recall_sent: 0.8107476635514018
dev_label=N_f-score_sent: 0.7206645898234684
dev_label=P_precision_sent: 0.6648648648648648
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7387387387387387
dev_precision_macro_sent: 0.6802452409929045
dev_recall_macro_sent: 0.5589210808163588
dev_f-score_macro_sent: 0.5086899984096246
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.8979892381761541
dev_label=O_recall_tok: 0.9783400185128047
dev_label=O_f-score_tok: 0.9364441819255759
dev_label=N_precision_tok: 0.7927272727272727
dev_label=N_recall_tok: 0.5869682283252557
dev_label=N_f-score_tok: 0.6745049504950494
dev_label=P_precision_tok: 0.9229055258467023
dev_label=P_recall_tok: 0.6447696139476962
dev_label=P_f-score_tok: 0.7591642228739003
dev_precision_macro_tok: 0.8712073455833763
dev_recall_macro_tok: 0.7366926202619188
dev_f-score_macro_tok: 0.7900377850981752
dev_precision_micro_tok: 0.8938140453135283
dev_recall_micro_tok: 0.8938140453135283
dev_f-score_micro_tok: 0.8938140453135283
dev_time: 15.389211893081665
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0349    0.0667       229
           N     0.6486    0.8107    0.7207       428
           P     0.6649    0.8311    0.7387       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6802    0.5589    0.5087      1101
weighted avg     0.6715    0.6576    0.5919      1101

F1-macro sent:  0.5086899984096246
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8980    0.9783    0.9364     16205
           N     0.7927    0.5870    0.6745      1857
           P     0.9229    0.6448    0.7592      3212

   micro avg     0.8938    0.8938    0.8938     21274
   macro avg     0.8712    0.7367    0.7900     21274
weighted avg     0.8926    0.8938    0.8868     21274

F1-macro tok:  0.7900377850981752
F1-micro tok:  0.8938140453135283
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 322997.87615966797
train_cost_avg: 37.804058539286984
train_count_sent: 8544.0
train_total_correct_sent: 5645.0
train_accuracy_sent: 0.6606975655430711
train_count_tok: 163566.0
train_total_correct_tok: 145106.0
train_accuracy_tok: 0.8871403592433635
train_label=O_precision_sent: 0.46
train_label=O_recall_sent: 0.042487684729064036
train_label=O_f-score_sent: 0.0777903043968433
train_label=N_precision_sent: 0.6198010849909584
train_label=N_recall_sent: 0.8283987915407856
train_label=N_f-score_sent: 0.709076803723817
train_label=P_precision_sent: 0.7138539042821158
train_label=P_recall_sent: 0.7850415512465374
train_label=P_f-score_sent: 0.7477572559366755
train_precision_macro_sent: 0.5978849964243581
train_recall_macro_sent: 0.551976009172129
train_f-score_macro_sent: 0.5115414546857786
train_precision_micro_sent: 0.6606975655430711
train_recall_micro_sent: 0.6606975655430711
train_f-score_micro_sent: 0.6606975655430711
train_label=O_precision_tok: 0.8972117412876199
train_label=O_recall_tok: 0.9714508592889254
train_label=O_f-score_tok: 0.9328565967650385
train_label=N_precision_tok: 0.7810808331039545
train_label=N_recall_tok: 0.5994226165328826
train_label=N_f-score_tok: 0.6782996693358829
train_label=P_precision_tok: 0.8760468082746381
train_label=P_recall_tok: 0.6314106407642803
train_label=P_f-score_tok: 0.7338784612525553
train_precision_macro_tok: 0.8514464608887375
train_recall_macro_tok: 0.734094705528696
train_f-score_macro_tok: 0.781678242451159
train_precision_micro_tok: 0.8871403592433635
train_recall_micro_tok: 0.8871403592433635
train_f-score_micro_tok: 0.8871403592433635
train_time: 248.4814178943634
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4600    0.0425    0.0778      1624
           N     0.6198    0.8284    0.7091      3310
           P     0.7139    0.7850    0.7478      3610

   micro avg     0.6607    0.6607    0.6607      8544
   macro avg     0.5979    0.5520    0.5115      8544
weighted avg     0.6292    0.6607    0.6054      8544

F1-macro sent:  0.5115414546857786
F1-micro sent:  0.6606975655430711
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8972    0.9715    0.9329    124347
           N     0.7811    0.5994    0.6783     14202
           P     0.8760    0.6314    0.7339     25017

   micro avg     0.8871    0.8871    0.8871    163566
   macro avg     0.8514    0.7341    0.7817    163566
weighted avg     0.8839    0.8871    0.8803    163566

F1-macro tok:  0.781678242451159
F1-micro tok:  0.8871403592433635
**************************************************
dev_cost_sum: 43528.642639160156
dev_cost_avg: 39.535551897511496
dev_count_sent: 1101.0
dev_total_correct_sent: 691.0
dev_accuracy_sent: 0.6276112624886467
dev_count_tok: 21274.0
dev_total_correct_tok: 19056.0
dev_accuracy_tok: 0.8957412804362133
dev_label=O_precision_sent: 0.7333333333333333
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09016393442622951
dev_label=N_precision_sent: 0.5504087193460491
dev_label=N_recall_sent: 0.9439252336448598
dev_label=N_f-score_sent: 0.6953528399311532
dev_label=P_precision_sent: 0.7840909090909091
dev_label=P_recall_sent: 0.6216216216216216
dev_label=P_f-score_sent: 0.6934673366834171
dev_precision_macro_sent: 0.6892776539234305
dev_recall_macro_sent: 0.5378605965880993
dev_f-score_macro_sent: 0.4929947036802666
dev_precision_micro_sent: 0.6276112624886467
dev_recall_micro_sent: 0.6276112624886467
dev_f-score_micro_sent: 0.6276112624886467
dev_label=O_precision_tok: 0.8961404298413412
dev_label=O_recall_tok: 0.9829065103363159
dev_label=O_f-score_tok: 0.9375202330851408
dev_label=N_precision_tok: 0.816793893129771
dev_label=N_recall_tok: 0.57619816908993
dev_label=N_f-score_tok: 0.6757183454373225
dev_label=P_precision_tok: 0.9397260273972603
dev_label=P_recall_tok: 0.6407222914072229
dev_label=P_f-score_tok: 0.7619400222139947
dev_precision_macro_tok: 0.8842201167894576
dev_recall_macro_tok: 0.7332756569444897
dev_f-score_macro_tok: 0.791726200245486
dev_precision_micro_tok: 0.8957412804362133
dev_recall_micro_tok: 0.8957412804362133
dev_f-score_micro_tok: 0.8957412804362133
dev_time: 13.297832727432251
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7333    0.0480    0.0902       229
           N     0.5504    0.9439    0.6954       428
           P     0.7841    0.6216    0.6935       444

   micro avg     0.6276    0.6276    0.6276      1101
   macro avg     0.6893    0.5379    0.4930      1101
weighted avg     0.6827    0.6276    0.5687      1101

F1-macro sent:  0.4929947036802666
F1-micro sent:  0.6276112624886467
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8961    0.9829    0.9375     16205
           N     0.8168    0.5762    0.6757      1857
           P     0.9397    0.6407    0.7619      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8842    0.7333    0.7917     21274
weighted avg     0.8958    0.8957    0.8882     21274

F1-macro tok:  0.791726200245486
F1-micro tok:  0.8957412804362133
**************************************************
Best epoch: 12
**************************************************

EPOCH: 17
Learning rate: 0.810000
train_cost_sum: 320499.8629760742
train_cost_avg: 37.51168808240569
train_count_sent: 8544.0
train_total_correct_sent: 5720.0
train_accuracy_sent: 0.6694756554307116
train_count_tok: 163566.0
train_total_correct_tok: 145540.0
train_accuracy_tok: 0.8897937224117481
train_label=O_precision_sent: 0.5529411764705883
train_label=O_recall_sent: 0.05788177339901478
train_label=O_f-score_sent: 0.10479375696767002
train_label=N_precision_sent: 0.6233534271042643
train_label=N_recall_sent: 0.8435045317220544
train_label=N_f-score_sent: 0.716908460649634
train_label=P_precision_sent: 0.727599486521181
train_label=P_recall_sent: 0.7850415512465374
train_label=P_f-score_sent: 0.7552298467688208
train_precision_macro_sent: 0.6346313633653445
train_recall_macro_sent: 0.5621426187892022
train_f-score_macro_sent: 0.5256440214620416
train_precision_micro_sent: 0.6694756554307116
train_recall_micro_sent: 0.6694756554307116
train_f-score_micro_sent: 0.6694756554307116
train_label=O_precision_tok: 0.8997097782408097
train_label=O_recall_tok: 0.9723033125045236
train_label=O_f-score_tok: 0.9345990174972074
train_label=N_precision_tok: 0.7865333455646271
train_label=N_recall_tok: 0.6037177862272919
train_label=N_f-score_tok: 0.6831056049077799
train_label=P_precision_tok: 0.8784796281104731
train_label=P_recall_tok: 0.6420833832993564
train_label=P_f-score_tok: 0.7419056856496236
train_precision_macro_tok: 0.8549075839719699
train_recall_macro_tok: 0.7393681606770572
train_f-score_macro_tok: 0.786536769351537
train_precision_micro_tok: 0.8897937224117481
train_recall_micro_tok: 0.8897937224117481
train_f-score_micro_tok: 0.8897937224117481
train_time: 201.34246516227722
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5529    0.0579    0.1048      1624
           N     0.6234    0.8435    0.7169      3310
           P     0.7276    0.7850    0.7552      3610

   micro avg     0.6695    0.6695    0.6695      8544
   macro avg     0.6346    0.5621    0.5256      8544
weighted avg     0.6540    0.6695    0.6168      8544

F1-macro sent:  0.5256440214620416
F1-micro sent:  0.6694756554307116
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8997    0.9723    0.9346    124347
           N     0.7865    0.6037    0.6831     14202
           P     0.8785    0.6421    0.7419     25017

   micro avg     0.8898    0.8898    0.8898    163566
   macro avg     0.8549    0.7394    0.7865    163566
weighted avg     0.8866    0.8898    0.8833    163566

F1-macro tok:  0.786536769351537
F1-micro tok:  0.8897937224117481
**************************************************
dev_cost_sum: 43426.956115722656
dev_cost_avg: 39.443193565597326
dev_count_sent: 1101.0
dev_total_correct_sent: 718.0
dev_accuracy_sent: 0.6521344232515894
dev_count_tok: 21274.0
dev_total_correct_tok: 19051.0
dev_accuracy_tok: 0.895506251762715
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6041666666666666
dev_label=N_recall_sent: 0.8808411214953271
dev_label=N_f-score_sent: 0.7167300380228137
dev_label=P_precision_sent: 0.7136752136752137
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7324561403508772
dev_precision_macro_sent: 0.698539886039886
dev_recall_macro_sent: 0.5545536864456997
dev_f-score_macro_sent: 0.5026699025951519
dev_precision_micro_sent: 0.6521344232515894
dev_recall_micro_sent: 0.6521344232515894
dev_f-score_micro_sent: 0.6521344232515894
dev_label=O_precision_tok: 0.8944033198743832
dev_label=O_recall_tok: 0.9842024066646097
dev_label=O_f-score_tok: 0.9371566236742368
dev_label=N_precision_tok: 0.8431535269709544
dev_label=N_recall_tok: 0.5471190091545504
dev_label=N_f-score_tok: 0.6636185499673416
dev_label=P_precision_tok: 0.9324988824318283
dev_label=P_recall_tok: 0.6494396014943961
dev_label=P_f-score_tok: 0.7656450724903652
dev_precision_macro_tok: 0.8900185764257219
dev_recall_macro_tok: 0.7269203391045188
dev_f-score_macro_tok: 0.7888067487106479
dev_precision_micro_tok: 0.895506251762715
dev_recall_micro_tok: 0.895506251762715
dev_f-score_micro_tok: 0.895506251762715
dev_time: 10.475730657577515
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6042    0.8808    0.7167       428
           P     0.7137    0.7523    0.7325       444

   micro avg     0.6521    0.6521    0.6521      1101
   macro avg     0.6985    0.5546    0.5027      1101
weighted avg     0.6844    0.6521    0.5862      1101

F1-macro sent:  0.5026699025951519
F1-micro sent:  0.6521344232515894
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8944    0.9842    0.9372     16205
           N     0.8432    0.5471    0.6636      1857
           P     0.9325    0.6494    0.7656      3212

   micro avg     0.8955    0.8955    0.8955     21274
   macro avg     0.8900    0.7269    0.7888     21274
weighted avg     0.8957    0.8955    0.8874     21274

F1-macro tok:  0.7888067487106479
F1-micro tok:  0.895506251762715
**************************************************
Best epoch: 12
**************************************************

EPOCH: 18
Learning rate: 0.729000
train_cost_sum: 319093.72326660156
train_cost_avg: 37.34711180554793
train_count_sent: 8544.0
train_total_correct_sent: 5732.0
train_accuracy_sent: 0.670880149812734
train_count_tok: 163566.0
train_total_correct_tok: 145858.0
train_accuracy_tok: 0.8917378917378918
train_label=O_precision_sent: 0.4909090909090909
train_label=O_recall_sent: 0.049876847290640396
train_label=O_f-score_sent: 0.09055338177752935
train_label=N_precision_sent: 0.6268858365233055
train_label=N_recall_sent: 0.8410876132930514
train_label=N_f-score_sent: 0.7183589214294931
train_label=P_precision_sent: 0.7280345352971052
train_label=P_recall_sent: 0.7941828254847645
train_label=P_f-score_sent: 0.7596714361420244
train_precision_macro_sent: 0.6152764875765006
train_recall_macro_sent: 0.5617157620228187
train_f-score_macro_sent: 0.5228612464496822
train_precision_micro_sent: 0.670880149812734
train_recall_micro_sent: 0.670880149812734
train_f-score_micro_sent: 0.670880149812734
train_label=O_precision_tok: 0.9010757491159501
train_label=O_recall_tok: 0.9733809420412234
train_label=O_f-score_tok: 0.935833797241294
train_label=N_precision_tok: 0.7936377723088142
train_label=N_recall_tok: 0.6130826644134629
train_label=N_f-score_tok: 0.6917729313152982
train_label=P_precision_tok: 0.881992337164751
train_label=P_recall_tok: 0.6441219970420115
train_label=P_f-score_tok: 0.7445191396955206
train_precision_macro_tok: 0.8589019528631718
train_recall_macro_tok: 0.7435285344988992
train_f-score_macro_tok: 0.7907086227507042
train_precision_micro_tok: 0.8917378917378918
train_recall_micro_tok: 0.8917378917378918
train_f-score_micro_tok: 0.8917378917378918
train_time: 194.93305778503418
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4909    0.0499    0.0906      1624
           N     0.6269    0.8411    0.7184      3310
           P     0.7280    0.7942    0.7597      3610

   micro avg     0.6709    0.6709    0.6709      8544
   macro avg     0.6153    0.5617    0.5229      8544
weighted avg     0.6438    0.6709    0.6165      8544

F1-macro sent:  0.5228612464496822
F1-micro sent:  0.670880149812734
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9011    0.9734    0.9358    124347
           N     0.7936    0.6131    0.6918     14202
           P     0.8820    0.6441    0.7445     25017

   micro avg     0.8917    0.8917    0.8917    163566
   macro avg     0.8589    0.7435    0.7907    163566
weighted avg     0.8888    0.8917    0.8854    163566

F1-macro tok:  0.7907086227507042
F1-micro tok:  0.8917378917378918
**************************************************
dev_cost_sum: 43232.897216796875
dev_cost_avg: 39.26693661834412
dev_count_sent: 1101.0
dev_total_correct_sent: 714.0
dev_accuracy_sent: 0.6485013623978202
dev_count_tok: 21274.0
dev_total_correct_tok: 19068.0
dev_accuracy_tok: 0.8963053492526089
dev_label=O_precision_sent: 0.625
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.04219409282700421
dev_label=N_precision_sent: 0.5975232198142415
dev_label=N_recall_sent: 0.9018691588785047
dev_label=N_f-score_sent: 0.7188081936685288
dev_label=P_precision_sent: 0.7225950782997763
dev_label=P_recall_sent: 0.7274774774774775
dev_label=P_f-score_sent: 0.7250280583613917
dev_precision_macro_sent: 0.648372766038006
dev_recall_macro_sent: 0.5503935658304512
dev_f-score_macro_sent: 0.4953434482856416
dev_precision_micro_sent: 0.6485013623978202
dev_recall_micro_sent: 0.6485013623978202
dev_f-score_micro_sent: 0.6485013623978202
dev_label=O_precision_tok: 0.9006818181818181
dev_label=O_recall_tok: 0.978216599814872
dev_label=O_f-score_tok: 0.9378494305576098
dev_label=N_precision_tok: 0.7964285714285714
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.684679152594412
dev_label=P_precision_tok: 0.9239226033421284
dev_label=P_recall_tok: 0.6541095890410958
dev_label=P_f-score_tok: 0.7659496901203062
dev_precision_macro_tok: 0.873677664317506
dev_recall_macro_tok: 0.7442523304084604
dev_f-score_macro_tok: 0.7961594244241094
dev_precision_micro_tok: 0.8963053492526089
dev_recall_micro_tok: 0.8963053492526089
dev_f-score_micro_tok: 0.8963053492526089
dev_time: 11.981995820999146
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6250    0.0218    0.0422       229
           N     0.5975    0.9019    0.7188       428
           P     0.7226    0.7275    0.7250       444

   micro avg     0.6485    0.6485    0.6485      1101
   macro avg     0.6484    0.5504    0.4953      1101
weighted avg     0.6537    0.6485    0.5806      1101

F1-macro sent:  0.4953434482856416
F1-micro sent:  0.6485013623978202
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9007    0.9782    0.9378     16205
           N     0.7964    0.6004    0.6847      1857
           P     0.9239    0.6541    0.7659      3212

   micro avg     0.8963    0.8963    0.8963     21274
   macro avg     0.8737    0.7443    0.7962     21274
weighted avg     0.8951    0.8963    0.8898     21274

F1-macro tok:  0.7961594244241094
F1-micro tok:  0.8963053492526089
**************************************************
Best epoch: 12
**************************************************

EPOCH: 19
Learning rate: 0.656100
train_cost_sum: 317218.5015258789
train_cost_avg: 37.12763360555699
train_count_sent: 8544.0
train_total_correct_sent: 5687.0
train_accuracy_sent: 0.6656132958801498
train_count_tok: 163566.0
train_total_correct_tok: 146044.0
train_accuracy_tok: 0.8928750473814852
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.05541871921182266
train_label=O_f-score_sent: 0.09977827050997784
train_label=N_precision_sent: 0.6275415896487985
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.7111809374181722
train_label=P_precision_sent: 0.7138255698711595
train_label=P_recall_sent: 0.7980609418282548
train_label=P_f-score_sent: 0.7535966518441014
train_precision_macro_sent: 0.6137890531733193
train_recall_macro_sent: 0.558007822562201
train_f-score_macro_sent: 0.5215186199240839
train_precision_micro_sent: 0.6656132958801498
train_recall_micro_sent: 0.6656132958801498
train_f-score_micro_sent: 0.6656132958801498
train_label=O_precision_tok: 0.9030960006569763
train_label=O_recall_tok: 0.9728180012384697
train_label=O_f-score_tok: 0.9366613239177062
train_label=N_precision_tok: 0.7916704146802195
train_label=N_recall_tok: 0.6197014504999296
train_label=N_f-score_tok: 0.695209131482286
train_label=P_precision_tok: 0.8796886823046157
train_label=P_recall_tok: 0.6505975936363273
train_label=P_f-score_tok: 0.7479951285645351
train_precision_macro_tok: 0.8581516992139372
train_recall_macro_tok: 0.7477056817915756
train_f-score_macro_tok: 0.7932885279881757
train_precision_micro_tok: 0.8928750473814852
train_recall_micro_tok: 0.8928750473814852
train_f-score_micro_tok: 0.8928750473814852
train_time: 196.20713639259338
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0554    0.0998      1624
           N     0.6275    0.8205    0.7112      3310
           P     0.7138    0.7981    0.7536      3610

   micro avg     0.6656    0.6656    0.6656      8544
   macro avg     0.6138    0.5580    0.5215      8544
weighted avg     0.6398    0.6656    0.6129      8544

F1-macro sent:  0.5215186199240839
F1-micro sent:  0.6656132958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9031    0.9728    0.9367    124347
           N     0.7917    0.6197    0.6952     14202
           P     0.8797    0.6506    0.7480     25017

   micro avg     0.8929    0.8929    0.8929    163566
   macro avg     0.8582    0.7477    0.7933    163566
weighted avg     0.8898    0.8929    0.8868    163566

F1-macro tok:  0.7932885279881757
F1-micro tok:  0.8928750473814852
**************************************************
dev_cost_sum: 43165.883544921875
dev_cost_avg: 39.206070431355016
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19056.0
dev_accuracy_tok: 0.8957412804362133
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034334763948497854
dev_label=N_precision_sent: 0.6388384754990926
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7191011235955057
dev_label=P_precision_sent: 0.6758241758241759
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7454545454545456
dev_precision_macro_sent: 0.7715542171077562
dev_recall_macro_sent: 0.5569927455104781
dev_f-score_macro_sent: 0.49963014433284975
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9056603773584906
dev_label=O_recall_tok: 0.9715519901265042
dev_label=O_f-score_tok: 0.9374497603382059
dev_label=N_precision_tok: 0.8012866333095068
dev_label=N_recall_tok: 0.6036618201400108
dev_label=N_f-score_tok: 0.6885749385749386
dev_label=P_precision_tok: 0.8795664391810518
dev_label=P_recall_tok: 0.6821295143212951
dev_label=P_f-score_tok: 0.7683675258635806
dev_precision_macro_tok: 0.862171149949683
dev_recall_macro_tok: 0.7524477748626034
dev_f-score_macro_tok: 0.7981307415922417
dev_precision_micro_tok: 0.8957412804362133
dev_recall_micro_tok: 0.8957412804362133
dev_f-score_micro_tok: 0.8957412804362133
dev_time: 11.62488079071045
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0175    0.0343       229
           N     0.6388    0.8224    0.7191       428
           P     0.6758    0.8311    0.7455       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.7716    0.5570    0.4996      1101
weighted avg     0.7289    0.6585    0.5873      1101

F1-macro sent:  0.49963014433284975
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9057    0.9716    0.9374     16205
           N     0.8013    0.6037    0.6886      1857
           P     0.8796    0.6821    0.7684      3212

   micro avg     0.8957    0.8957    0.8957     21274
   macro avg     0.8622    0.7524    0.7981     21274
weighted avg     0.8926    0.8957    0.8902     21274

F1-macro tok:  0.7981307415922417
F1-micro tok:  0.8957412804362133
**************************************************
Best epoch: 12
**************************************************

test0_cost_sum: 44189.102294921875
test0_cost_avg: 40.13542442772196
test0_count_sent: 1101.0
test0_total_correct_sent: 728.0
test0_accuracy_sent: 0.6612170753860127
test0_count_tok: 21274.0
test0_total_correct_tok: 18962.0
test0_accuracy_tok: 0.8913227413744477
test0_label=O_precision_sent: 0.75
test0_label=O_recall_sent: 0.06550218340611354
test0_label=O_f-score_sent: 0.12048192771084337
test0_label=N_precision_sent: 0.6335078534031413
test0_label=N_recall_sent: 0.8481308411214953
test0_label=N_f-score_sent: 0.7252747252747251
test0_label=P_precision_sent: 0.6889763779527559
test0_label=P_recall_sent: 0.7882882882882883
test0_label=P_f-score_sent: 0.7352941176470589
test0_precision_macro_sent: 0.6908280771186325
test0_recall_macro_sent: 0.5673071042719657
test0_f-score_macro_sent: 0.5270169235442091
test0_precision_micro_sent: 0.6612170753860127
test0_recall_micro_sent: 0.6612170753860127
test0_f-score_micro_sent: 0.6612170753860127
test0_label=O_precision_tok: 0.8925763701707098
test0_label=O_recall_tok: 0.9808701018204258
test0_label=O_f-score_tok: 0.9346426366389322
test0_label=N_precision_tok: 0.8387096774193549
test0_label=N_recall_tok: 0.5320409262250942
test0_label=N_f-score_tok: 0.6510708401976936
test0_label=P_precision_tok: 0.9086538461538461
test0_label=P_recall_tok: 0.6472602739726028
test0_label=P_f-score_tok: 0.756
test0_precision_macro_tok: 0.8799799645813037
test0_recall_macro_tok: 0.7200571006727076
test0_f-score_macro_tok: 0.7805711589455419
test0_precision_micro_tok: 0.8913227413744477
test0_recall_micro_tok: 0.8913227413744477
test0_f-score_micro_tok: 0.8913227413744476
test0_time: 12.113219022750854
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0655    0.1205       229
           N     0.6335    0.8481    0.7253       428
           P     0.6890    0.7883    0.7353       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.6908    0.5673    0.5270      1101
weighted avg     0.6801    0.6612    0.6035      1101

F1-macro sent:  0.5270169235442091
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8926    0.9809    0.9346     16205
           N     0.8387    0.5320    0.6511      1857
           P     0.9087    0.6473    0.7560      3212

   micro avg     0.8913    0.8913    0.8913     21274
   macro avg     0.8800    0.7201    0.7806     21274
weighted avg     0.8903    0.8913    0.8829     21274

F1-macro tok:  0.7805711589455419
F1-micro tok:  0.8913227413744476
**************************************************
test1_cost_sum: 85786.68704605103
test1_cost_avg: 38.81750545070182
test1_count_sent: 2210.0
test1_total_correct_sent: 1509.0
test1_accuracy_sent: 0.6828054298642534
test1_count_tok: 42405.0
test1_total_correct_tok: 37426.0
test1_accuracy_tok: 0.8825846008725386
test1_label=O_precision_sent: 0.5588235294117647
test1_label=O_recall_sent: 0.04884318766066838
test1_label=O_f-score_sent: 0.08983451536643025
test1_label=N_precision_sent: 0.6597582037996546
test1_label=N_recall_sent: 0.8377192982456141
test1_label=N_f-score_sent: 0.7381642512077294
test1_label=P_precision_sent: 0.7131630648330058
test1_label=P_recall_sent: 0.7986798679867987
test1_label=P_f-score_sent: 0.7535028541774779
test1_precision_macro_sent: 0.643914932681475
test1_recall_macro_sent: 0.5617474512976938
test1_f-score_macro_sent: 0.5271672069172125
test1_precision_micro_sent: 0.6828054298642534
test1_recall_micro_sent: 0.6828054298642534
test1_f-score_micro_sent: 0.6828054298642534
test1_label=O_precision_tok: 0.8827214247591224
test1_label=O_recall_tok: 0.9820613788361773
test1_label=O_f-score_tok: 0.9297454029024957
test1_label=N_precision_tok: 0.8326931284677763
test1_label=N_recall_tok: 0.5188829787234043
test1_label=N_f-score_tok: 0.6393576929378995
test1_label=P_precision_tok: 0.907685413399059
test1_label=P_recall_tok: 0.6094478712200992
test1_label=P_f-score_tok: 0.7292529252925293
test1_precision_macro_tok: 0.8743666555419859
test1_recall_macro_tok: 0.7034640762598935
test1_f-score_macro_tok: 0.766118673710975
test1_precision_micro_tok: 0.8825846008725386
test1_recall_micro_tok: 0.8825846008725386
test1_f-score_micro_tok: 0.8825846008725386
test1_time: 23.968815088272095
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5588    0.0488    0.0898       389
           N     0.6598    0.8377    0.7382       912
           P     0.7132    0.7987    0.7535       909

   micro avg     0.6828    0.6828    0.6828      2210
   macro avg     0.6439    0.5617    0.5272      2210
weighted avg     0.6640    0.6828    0.6304      2210

F1-macro sent:  0.5271672069172125
F1-micro sent:  0.6828054298642534
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8827    0.9821    0.9297     31998
           N     0.8327    0.5189    0.6394      3760
           P     0.9077    0.6094    0.7293      6647

   micro avg     0.8826    0.8826    0.8826     42405
   macro avg     0.8744    0.7035    0.7661     42405
weighted avg     0.8822    0.8826    0.8726     42405

F1-macro tok:  0.766118673710975
F1-micro tok:  0.8825846008725386
**************************************************
