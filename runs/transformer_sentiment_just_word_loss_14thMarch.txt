debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: False
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.0
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.0
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 0.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'O': 0, 'N': 1}
{'P': 2, 'O': 0, 'N': 1}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 19:10:19.686979: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 19:10:25.305992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-14 19:10:25.306040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 19:10:48.357346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 19:10:48.357393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 19:10:48.357408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 19:10:48.357702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 7835707.
Parameter count without word embeddings: 2035207.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 99644.46481323242
train_cost_avg: 11.662507585818402
train_count_sent: 8544.0
train_total_correct_sent: 2890.0
train_accuracy_sent: 0.33824906367041196
train_count_tok: 163566.0
train_total_correct_tok: 127216.0
train_accuracy_tok: 0.7777655502977392
train_label=O_precision_sent: 0.18564593301435406
train_label=O_recall_sent: 0.23891625615763548
train_label=O_f-score_sent: 0.20893914916532044
train_label=N_precision_sent: 0.38542730677562137
train_label=N_recall_sent: 0.683987915407855
train_label=N_f-score_sent: 0.4930313588850174
train_label=P_precision_sent: 0.4103448275862069
train_label=P_recall_sent: 0.06592797783933518
train_label=P_f-score_sent: 0.11360381861575179
train_precision_macro_sent: 0.32713935579206077
train_recall_macro_sent: 0.32961071646827517
train_f-score_macro_sent: 0.27185810888869655
train_precision_micro_sent: 0.33824906367041196
train_recall_micro_sent: 0.33824906367041196
train_f-score_micro_sent: 0.33824906367041196
train_label=O_precision_tok: 0.8020484978134013
train_label=O_recall_tok: 0.9527933926833779
train_label=O_f-score_tok: 0.8709462812195614
train_label=N_precision_tok: 0.5437997724687145
train_label=N_recall_tok: 0.23560061963103787
train_label=N_f-score_tok: 0.3287644313436502
train_label=P_precision_tok: 0.5562661165549252
train_label=P_recall_tok: 0.21557341008114483
train_label=P_f-score_tok: 0.3107282784051625
train_precision_macro_tok: 0.6340381289456803
train_recall_macro_tok: 0.4679891407985202
train_f-score_macro_tok: 0.5034796636561247
train_precision_micro_tok: 0.7777655502977392
train_recall_micro_tok: 0.7777655502977392
train_f-score_micro_tok: 0.7777655502977392
train_time: 52.65759062767029
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1856    0.2389    0.2089      1624
           N     0.3854    0.6840    0.4930      3310
           P     0.4103    0.0659    0.1136      3610

   micro avg     0.3382    0.3382    0.3382      8544
   macro avg     0.3271    0.3296    0.2719      8544
weighted avg     0.3580    0.3382    0.2787      8544

F1-macro sent:  0.27185810888869655
F1-micro sent:  0.33824906367041196
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8020    0.9528    0.8709    124347
           N     0.5438    0.2356    0.3288     14202
           P     0.5563    0.2156    0.3107     25017

   micro avg     0.7778    0.7778    0.7778    163566
   macro avg     0.6340    0.4680    0.5035    163566
weighted avg     0.7420    0.7778    0.7382    163566

F1-macro tok:  0.5034796636561247
F1-micro tok:  0.7777655502977392
**************************************************
dev_cost_sum: 10252.843490600586
dev_cost_avg: 9.312301081381095
dev_count_sent: 1101.0
dev_total_correct_sent: 363.0
dev_accuracy_sent: 0.329700272479564
dev_count_tok: 21274.0
dev_total_correct_tok: 17535.0
dev_accuracy_tok: 0.8242455579580709
dev_label=O_precision_sent: 0.21453287197231835
dev_label=O_recall_sent: 0.27074235807860264
dev_label=O_f-score_sent: 0.23938223938223938
dev_label=N_precision_sent: 0.36991368680641185
dev_label=N_recall_sent: 0.7009345794392523
dev_label=N_f-score_sent: 0.48426150121065376
dev_label=P_precision_sent: 1.0
dev_label=P_recall_sent: 0.0022522522522522522
dev_label=P_f-score_sent: 0.00449438202247191
dev_precision_macro_sent: 0.5281488529262434
dev_recall_macro_sent: 0.3246430632567024
dev_f-score_macro_sent: 0.242712707538455
dev_precision_micro_sent: 0.329700272479564
dev_recall_micro_sent: 0.329700272479564
dev_f-score_micro_sent: 0.329700272479564
dev_label=O_precision_tok: 0.8500722141984224
dev_label=O_recall_tok: 0.9443381672323357
dev_label=O_f-score_tok: 0.8947291490045897
dev_label=N_precision_tok: 0.6118462507876496
dev_label=N_recall_tok: 0.5228863758750674
dev_label=N_f-score_tok: 0.5638792102206738
dev_label=P_precision_tok: 0.7483679525222552
dev_label=P_recall_tok: 0.3925902864259029
dev_label=P_f-score_tok: 0.5150091892995712
dev_precision_macro_tok: 0.7367621391694424
dev_recall_macro_tok: 0.6199382765111019
dev_f-score_macro_tok: 0.6578725161749449
dev_precision_micro_tok: 0.8242455579580709
dev_recall_micro_tok: 0.8242455579580709
dev_f-score_micro_tok: 0.8242455579580709
dev_time: 2.2862915992736816
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2145    0.2707    0.2394       229
           N     0.3699    0.7009    0.4843       428
           P     1.0000    0.0023    0.0045       444

   micro avg     0.3297    0.3297    0.3297      1101
   macro avg     0.5281    0.3246    0.2427      1101
weighted avg     0.5917    0.3297    0.2399      1101

F1-macro sent:  0.242712707538455
F1-micro sent:  0.329700272479564
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8501    0.9443    0.8947     16205
           N     0.6118    0.5229    0.5639      1857
           P     0.7484    0.3926    0.5150      3212

   micro avg     0.8242    0.8242    0.8242     21274
   macro avg     0.7368    0.6199    0.6579     21274
weighted avg     0.8139    0.8242    0.8085     21274

F1-macro tok:  0.6578725161749449
F1-micro tok:  0.8242455579580709
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 82000.23020935059
train_cost_avg: 9.597405221131856
train_count_sent: 8544.0
train_total_correct_sent: 3021.0
train_accuracy_sent: 0.3535814606741573
train_count_tok: 163566.0
train_total_correct_tok: 132909.0
train_accuracy_tok: 0.8125710722277246
train_label=O_precision_sent: 0.17136659436008678
train_label=O_recall_sent: 0.145935960591133
train_label=O_f-score_sent: 0.1576321915530429
train_label=N_precision_sent: 0.38762214983713356
train_label=N_recall_sent: 0.7909365558912387
train_label=N_f-score_sent: 0.5202702702702703
train_label=P_precision_sent: 0.40786240786240785
train_label=P_recall_sent: 0.04598337950138504
train_label=P_f-score_sent: 0.08264874284291761
train_precision_macro_sent: 0.3222837173532094
train_recall_macro_sent: 0.3276186319945856
train_f-score_macro_sent: 0.2535170682220769
train_precision_micro_sent: 0.3535814606741573
train_recall_micro_sent: 0.3535814606741573
train_f-score_micro_sent: 0.3535814606741573
train_label=O_precision_tok: 0.837252897068848
train_label=O_recall_tok: 0.9482496562040097
train_label=O_f-score_tok: 0.8893011890081793
train_label=N_precision_tok: 0.6405099461479283
train_label=N_recall_tok: 0.4103647373609351
train_label=N_f-score_tok: 0.500236041371615
train_label=P_precision_tok: 0.6724605793912725
train_label=P_recall_tok: 0.36651077267458126
train_label=P_f-score_tok: 0.4744385801510918
train_precision_macro_tok: 0.7167411408693495
train_recall_macro_tok: 0.575041722079842
train_f-score_macro_tok: 0.621325270176962
train_precision_micro_tok: 0.8125710722277246
train_recall_micro_tok: 0.8125710722277246
train_f-score_micro_tok: 0.8125710722277247
train_time: 45.33824157714844
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1714    0.1459    0.1576      1624
           N     0.3876    0.7909    0.5203      3310
           P     0.4079    0.0460    0.0826      3610

   micro avg     0.3536    0.3536    0.3536      8544
   macro avg     0.3223    0.3276    0.2535      8544
weighted avg     0.3551    0.3536    0.2664      8544

F1-macro sent:  0.2535170682220769
F1-micro sent:  0.3535814606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8373    0.9482    0.8893    124347
           N     0.6405    0.4104    0.5002     14202
           P     0.6725    0.3665    0.4744     25017

   micro avg     0.8126    0.8126    0.8126    163566
   macro avg     0.7167    0.5750    0.6213    163566
weighted avg     0.7950    0.8126    0.7921    163566

F1-macro tok:  0.621325270176962
F1-micro tok:  0.8125710722277247
**************************************************
dev_cost_sum: 9218.856643676758
dev_cost_avg: 8.373166797163268
dev_count_sent: 1101.0
dev_total_correct_sent: 424.0
dev_accuracy_sent: 0.3851044504995459
dev_count_tok: 21274.0
dev_total_correct_tok: 17830.0
dev_accuracy_tok: 0.8381122496944627
dev_label=O_precision_sent: 0.13636363636363635
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02390438247011952
dev_label=N_precision_sent: 0.39090064995357476
dev_label=N_recall_sent: 0.9836448598130841
dev_label=N_f-score_sent: 0.5594684385382059
dev_label=P_precision_sent: 0.0
dev_label=P_recall_sent: 0.0
dev_label=P_f-score_sent: 0.0
dev_precision_macro_sent: 0.17575476210573704
dev_recall_macro_sent: 0.33224843216476896
dev_f-score_macro_sent: 0.19445760700277515
dev_precision_micro_sent: 0.3851044504995459
dev_recall_micro_sent: 0.3851044504995459
dev_f-score_micro_sent: 0.3851044504995459
dev_label=O_precision_tok: 0.852720398882253
dev_label=O_recall_tok: 0.9603825979635915
dev_label=O_f-score_tok: 0.9033550034827026
dev_label=N_precision_tok: 0.6851716581446311
dev_label=N_recall_tok: 0.5051157781367798
dev_label=N_f-score_tok: 0.5815251084934904
dev_label=P_precision_tok: 0.8035066505441354
dev_label=P_recall_tok: 0.41376089663760895
dev_label=P_f-score_tok: 0.5462392108508014
dev_precision_macro_tok: 0.7804662358570065
dev_recall_macro_tok: 0.6264197575793268
dev_f-score_macro_tok: 0.6770397742756648
dev_precision_micro_tok: 0.8381122496944627
dev_recall_micro_tok: 0.8381122496944627
dev_f-score_micro_tok: 0.8381122496944627
dev_time: 1.9928829669952393
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1364    0.0131    0.0239       229
           N     0.3909    0.9836    0.5595       428
           P     0.0000    0.0000    0.0000       444

   micro avg     0.3851    0.3851    0.3851      1101
   macro avg     0.1758    0.3322    0.1945      1101
weighted avg     0.1803    0.3851    0.2225      1101

F1-macro sent:  0.19445760700277515
F1-micro sent:  0.3851044504995459
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8527    0.9604    0.9034     16205
           N     0.6852    0.5051    0.5815      1857
           P     0.8035    0.4138    0.5462      3212

   micro avg     0.8381    0.8381    0.8381     21274
   macro avg     0.7805    0.6264    0.6770     21274
weighted avg     0.8307    0.8381    0.8213     21274

F1-macro tok:  0.6770397742756648
F1-micro tok:  0.8381122496944627
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 76510.30267333984
train_cost_avg: 8.954857522628727
train_count_sent: 8544.0
train_total_correct_sent: 3206.0
train_accuracy_sent: 0.37523408239700373
train_count_tok: 163566.0
train_total_correct_tok: 135653.0
train_accuracy_tok: 0.8293471748407371
train_label=O_precision_sent: 0.19331742243436753
train_label=O_recall_sent: 0.09975369458128079
train_label=O_f-score_sent: 0.13160032493907392
train_label=N_precision_sent: 0.3937669376693767
train_label=N_recall_sent: 0.8779456193353474
train_label=N_f-score_sent: 0.5436856875584659
train_label=P_precision_sent: 0.4233128834355828
train_label=P_recall_sent: 0.03822714681440443
train_label=P_f-score_sent: 0.0701219512195122
train_precision_macro_sent: 0.3367990811797757
train_recall_macro_sent: 0.33864215357701094
train_f-score_macro_sent: 0.24846932123901735
train_precision_micro_sent: 0.37523408239700373
train_recall_micro_sent: 0.37523408239700373
train_f-score_micro_sent: 0.37523408239700373
train_label=O_precision_tok: 0.8509268110369215
train_label=O_recall_tok: 0.9521098217086058
train_label=O_f-score_tok: 0.8986792166388341
train_label=N_precision_tok: 0.6718980408679166
train_label=N_recall_tok: 0.44916208984650047
train_label=N_f-score_tok: 0.5384031060094531
train_label=P_precision_tok: 0.7284289443737867
train_label=P_recall_tok: 0.434984210736699
train_label=P_f-score_tok: 0.5446991690859946
train_precision_macro_tok: 0.750417932092875
train_recall_macro_tok: 0.6120853740972684
train_f-score_macro_tok: 0.660593830578094
train_precision_micro_tok: 0.8293471748407371
train_recall_micro_tok: 0.8293471748407371
train_f-score_micro_tok: 0.829347174840737
train_time: 44.97247505187988
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1933    0.0998    0.1316      1624
           N     0.3938    0.8779    0.5437      3310
           P     0.4233    0.0382    0.0701      3610

   micro avg     0.3752    0.3752    0.3752      8544
   macro avg     0.3368    0.3386    0.2485      8544
weighted avg     0.3682    0.3752    0.2653      8544

F1-macro sent:  0.24846932123901735
F1-micro sent:  0.37523408239700373
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8509    0.9521    0.8987    124347
           N     0.6719    0.4492    0.5384     14202
           P     0.7284    0.4350    0.5447     25017

   micro avg     0.8293    0.8293    0.8293    163566
   macro avg     0.7504    0.6121    0.6606    163566
weighted avg     0.8166    0.8293    0.8133    163566

F1-macro tok:  0.660593830578094
F1-micro tok:  0.829347174840737
**************************************************
dev_cost_sum: 8698.072746276855
dev_cost_avg: 7.90015689943402
dev_count_sent: 1101.0
dev_total_correct_sent: 421.0
dev_accuracy_sent: 0.3823796548592189
dev_count_tok: 21274.0
dev_total_correct_tok: 18345.0
dev_accuracy_tok: 0.8623202030647739
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.38461538461538464
dev_label=N_recall_sent: 0.9813084112149533
dev_label=N_f-score_sent: 0.5526315789473685
dev_label=P_precision_sent: 0.1111111111111111
dev_label=P_recall_sent: 0.0022522522522522522
dev_label=P_f-score_sent: 0.004415011037527594
dev_precision_macro_sent: 0.16524216524216526
dev_recall_macro_sent: 0.3278535544890685
dev_f-score_macro_sent: 0.18568219666163202
dev_precision_micro_sent: 0.3823796548592189
dev_recall_micro_sent: 0.3823796548592189
dev_f-score_micro_sent: 0.3823796548592189
dev_label=O_precision_tok: 0.8733258928571429
dev_label=O_recall_tok: 0.9657513113236655
dev_label=O_f-score_tok: 0.9172161172161173
dev_label=N_precision_tok: 0.7617360496014172
dev_label=N_recall_tok: 0.4631125471190092
dev_label=N_f-score_tok: 0.5760214333556598
dev_label=P_precision_tok: 0.8247191011235955
dev_label=P_recall_tok: 0.5712951432129514
dev_label=P_f-score_tok: 0.6750045981239654
dev_precision_macro_tok: 0.819927014527385
dev_recall_macro_tok: 0.6667196672185419
dev_f-score_macro_tok: 0.7227473828985809
dev_precision_micro_tok: 0.8623202030647739
dev_recall_micro_tok: 0.8623202030647739
dev_f-score_micro_tok: 0.8623202030647739
dev_time: 1.9828150272369385
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3846    0.9813    0.5526       428
           P     0.1111    0.0023    0.0044       444

   micro avg     0.3824    0.3824    0.3824      1101
   macro avg     0.1652    0.3279    0.1857      1101
weighted avg     0.1943    0.3824    0.2166      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.18568219666163202
F1-micro sent:  0.3823796548592189
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8733    0.9658    0.9172     16205
           N     0.7617    0.4631    0.5760      1857
           P     0.8247    0.5713    0.6750      3212

   micro avg     0.8623    0.8623    0.8623     21274
   macro avg     0.8199    0.6667    0.7227     21274
weighted avg     0.8562    0.8623    0.8509     21274

F1-macro tok:  0.7227473828985809
F1-micro tok:  0.8623202030647739
**************************************************
Best epoch: 0
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 72605.82893371582
train_cost_avg: 8.497873236624043
train_count_sent: 8544.0
train_total_correct_sent: 3141.0
train_accuracy_sent: 0.367626404494382
train_count_tok: 163566.0
train_total_correct_tok: 137967.0
train_accuracy_tok: 0.8434943692454422
train_label=O_precision_sent: 0.20754716981132076
train_label=O_recall_sent: 0.15578817733990147
train_label=O_f-score_sent: 0.17798100597959904
train_label=N_precision_sent: 0.3945830363506771
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.5361743341404358
train_label=P_precision_sent: 0.3870967741935484
train_label=P_recall_sent: 0.0332409972299169
train_label=P_f-score_sent: 0.061224489795918366
train_precision_macro_sent: 0.32974232678518206
train_recall_macro_sent: 0.34176098366828783
train_f-score_macro_sent: 0.25845994330531774
train_precision_micro_sent: 0.367626404494382
train_recall_micro_sent: 0.367626404494382
train_f-score_micro_sent: 0.367626404494382
train_label=O_precision_tok: 0.8632538875163493
train_label=O_recall_tok: 0.9553990043989803
train_label=O_f-score_tok: 0.9069921020586562
train_label=N_precision_tok: 0.6974012474012474
train_label=N_recall_tok: 0.47239825376707506
train_label=N_f-score_tok: 0.5632608513139116
train_label=P_precision_tok: 0.7630160480215608
train_label=P_recall_tok: 0.4979413998481033
train_label=P_f-score_tok: 0.6026171298647897
train_precision_macro_tok: 0.7745570609797192
train_recall_macro_tok: 0.6419128860047195
train_f-score_macro_tok: 0.6909566944124524
train_precision_micro_tok: 0.8434943692454422
train_recall_micro_tok: 0.8434943692454422
train_f-score_micro_tok: 0.8434943692454422
train_time: 45.16639471054077
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2075    0.1558    0.1780      1624
           N     0.3946    0.8363    0.5362      3310
           P     0.3871    0.0332    0.0612      3610

   micro avg     0.3676    0.3676    0.3676      8544
   macro avg     0.3297    0.3418    0.2585      8544
weighted avg     0.3559    0.3676    0.2674      8544

F1-macro sent:  0.25845994330531774
F1-micro sent:  0.367626404494382
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8633    0.9554    0.9070    124347
           N     0.6974    0.4724    0.5633     14202
           P     0.7630    0.4979    0.6026     25017

   micro avg     0.8435    0.8435    0.8435    163566
   macro avg     0.7746    0.6419    0.6910    163566
weighted avg     0.8335    0.8435    0.8306    163566

F1-macro tok:  0.6909566944124524
F1-micro tok:  0.8434943692454422
**************************************************
dev_cost_sum: 8330.526901245117
dev_cost_avg: 7.566327794046428
dev_count_sent: 1101.0
dev_total_correct_sent: 423.0
dev_accuracy_sent: 0.38419618528610355
dev_count_tok: 21274.0
dev_total_correct_tok: 18470.0
dev_accuracy_tok: 0.8681959199022281
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.3884297520661157
dev_label=N_recall_sent: 0.9883177570093458
dev_label=N_f-score_sent: 0.5576796308503625
dev_label=P_precision_sent: 0.0
dev_label=P_recall_sent: 0.0
dev_label=P_f-score_sent: 0.0
dev_precision_macro_sent: 0.12947658402203857
dev_recall_macro_sent: 0.3294392523364486
dev_f-score_macro_sent: 0.18589321028345418
dev_precision_micro_sent: 0.38419618528610355
dev_recall_micro_sent: 0.38419618528610355
dev_f-score_micro_sent: 0.38419618528610355
dev_label=O_precision_tok: 0.881410437235543
dev_label=O_recall_tok: 0.9640851589015735
dev_label=O_f-score_tok: 0.9208959622752725
dev_label=N_precision_tok: 0.7569558101472995
dev_label=N_recall_tok: 0.498115239633818
dev_label=N_f-score_tok: 0.6008444300097434
dev_label=P_precision_tok: 0.8259561667382896
dev_label=P_recall_tok: 0.5983810709838107
dev_label=P_f-score_tok: 0.6939880844917855
dev_precision_macro_tok: 0.8214408047070441
dev_recall_macro_tok: 0.686860489839734
dev_f-score_macro_tok: 0.7385761589256005
dev_precision_micro_tok: 0.8681959199022281
dev_recall_micro_tok: 0.8681959199022281
dev_f-score_micro_tok: 0.8681959199022281
dev_time: 2.084864616394043
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3884    0.9883    0.5577       428
           P     0.0000    0.0000    0.0000       444

   micro avg     0.3842    0.3842    0.3842      1101
   macro avg     0.1295    0.3294    0.1859      1101
weighted avg     0.1510    0.3842    0.2168      1101

F1-macro sent:  0.18589321028345418
F1-micro sent:  0.38419618528610355
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8814    0.9641    0.9209     16205
           N     0.7570    0.4981    0.6008      1857
           P     0.8260    0.5984    0.6940      3212

   micro avg     0.8682    0.8682    0.8682     21274
   macro avg     0.8214    0.6869    0.7386     21274
weighted avg     0.8622    0.8682    0.8587     21274

F1-macro tok:  0.7385761589256005
F1-micro tok:  0.8681959199022281
**************************************************
Best epoch: 0
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 69038.19557189941
train_cost_avg: 8.080313152141786
train_count_sent: 8544.0
train_total_correct_sent: 3179.0
train_accuracy_sent: 0.3720739700374532
train_count_tok: 163566.0
train_total_correct_tok: 139459.0
train_accuracy_tok: 0.8526160693542668
train_label=O_precision_sent: 0.19175027870680045
train_label=O_recall_sent: 0.10591133004926108
train_label=O_f-score_sent: 0.13645378817929393
train_label=N_precision_sent: 0.3913448735019973
train_label=N_recall_sent: 0.8879154078549849
train_label=N_f-score_sent: 0.5432532347504622
train_label=P_precision_sent: 0.49635036496350365
train_label=P_recall_sent: 0.018836565096952907
train_label=P_f-score_sent: 0.03629570322925006
train_precision_macro_sent: 0.35981517239076716
train_recall_macro_sent: 0.33755443433373294
train_f-score_macro_sent: 0.2386675753863354
train_precision_micro_sent: 0.3720739700374532
train_recall_micro_sent: 0.3720739700374532
train_f-score_micro_sent: 0.37207397003745324
train_label=O_precision_tok: 0.8708088514718348
train_label=O_recall_tok: 0.9582700024930235
train_label=O_f-score_tok: 0.9124483599621721
train_label=N_precision_tok: 0.7075892857142857
train_label=N_recall_tok: 0.4910575975214759
train_label=N_f-score_tok: 0.5797655665475102
train_label=P_precision_tok: 0.7897949508119
train_label=P_recall_tok: 0.5327177519286885
train_label=P_f-score_tok: 0.6362703205939223
train_precision_macro_tok: 0.7893976959993402
train_recall_macro_tok: 0.6606817839810627
train_f-score_macro_tok: 0.7094947490345348
train_precision_micro_tok: 0.8526160693542668
train_recall_micro_tok: 0.8526160693542668
train_f-score_micro_tok: 0.8526160693542668
train_time: 45.205204486846924
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1918    0.1059    0.1365      1624
           N     0.3913    0.8879    0.5433      3310
           P     0.4964    0.0188    0.0363      3610

   micro avg     0.3721    0.3721    0.3721      8544
   macro avg     0.3598    0.3376    0.2387      8544
weighted avg     0.3978    0.3721    0.2517      8544

F1-macro sent:  0.2386675753863354
F1-micro sent:  0.37207397003745324
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8708    0.9583    0.9124    124347
           N     0.7076    0.4911    0.5798     14202
           P     0.7898    0.5327    0.6363     25017

   micro avg     0.8526    0.8526    0.8526    163566
   macro avg     0.7894    0.6607    0.7095    163566
weighted avg     0.8442    0.8526    0.8413    163566

F1-macro tok:  0.7094947490345348
F1-micro tok:  0.8526160693542668
**************************************************
dev_cost_sum: 7936.716400146484
dev_cost_avg: 7.208643415210249
dev_count_sent: 1101.0
dev_total_correct_sent: 427.0
dev_accuracy_sent: 0.38782924613987285
dev_count_tok: 21274.0
dev_total_correct_tok: 18561.0
dev_accuracy_tok: 0.8724734417598947
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.38904109589041097
dev_label=N_recall_sent: 0.9953271028037384
dev_label=N_f-score_sent: 0.5594221930400526
dev_label=P_precision_sent: 0.5
dev_label=P_recall_sent: 0.0022522522522522522
dev_label=P_f-score_sent: 0.004484304932735426
dev_precision_macro_sent: 0.2963470319634703
dev_recall_macro_sent: 0.3325264516853302
dev_f-score_macro_sent: 0.187968832657596
dev_precision_micro_sent: 0.38782924613987285
dev_recall_micro_sent: 0.38782924613987285
dev_f-score_micro_sent: 0.38782924613987285
dev_label=O_precision_tok: 0.8828661488235956
dev_label=O_recall_tok: 0.9679111385374884
dev_label=O_f-score_tok: 0.9234346942980777
dev_label=N_precision_tok: 0.75
dev_label=N_recall_tok: 0.5218093699515347
dev_label=N_f-score_tok: 0.6154334709431566
dev_label=P_precision_tok: 0.8605595667870036
dev_label=P_recall_tok: 0.5937110834371109
dev_label=P_f-score_tok: 0.7026529108327193
dev_precision_macro_tok: 0.8311419052035331
dev_recall_macro_tok: 0.6944771973087113
dev_f-score_macro_tok: 0.7471736920246513
dev_precision_micro_tok: 0.8724734417598947
dev_recall_micro_tok: 0.8724734417598947
dev_f-score_micro_tok: 0.8724734417598948
dev_time: 1.9745032787322998
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3890    0.9953    0.5594       428
           P     0.5000    0.0023    0.0045       444

   micro avg     0.3878    0.3878    0.3878      1101
   macro avg     0.2963    0.3325    0.1880      1101
weighted avg     0.3529    0.3878    0.2193      1101

F1-macro sent:  0.187968832657596
F1-micro sent:  0.38782924613987285
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8829    0.9679    0.9234     16205
           N     0.7500    0.5218    0.6154      1857
           P     0.8606    0.5937    0.7027      3212

   micro avg     0.8725    0.8725    0.8725     21274
   macro avg     0.8311    0.6945    0.7472     21274
weighted avg     0.8679    0.8725    0.8632     21274

F1-macro tok:  0.7471736920246513
F1-micro tok:  0.8724734417598948
**************************************************
Best epoch: 0
**************************************************

EPOCH: 5
Learning rate: 0.900000
train_cost_sum: 66589.84313964844
train_cost_avg: 7.7937550491161565
train_count_sent: 8544.0
train_total_correct_sent: 3185.0
train_accuracy_sent: 0.37277621722846443
train_count_tok: 163566.0
train_total_correct_tok: 140436.0
train_accuracy_tok: 0.8585891933531419
train_label=O_precision_sent: 0.19316493313521546
train_label=O_recall_sent: 0.08004926108374384
train_label=O_f-score_sent: 0.11319111885067479
train_label=N_precision_sent: 0.3876994939665239
train_label=N_recall_sent: 0.9027190332326284
train_label=N_f-score_sent: 0.5424344195334484
train_label=P_precision_sent: 0.40853658536585363
train_label=P_recall_sent: 0.0185595567867036
train_label=P_f-score_sent: 0.03550609432962373
train_precision_macro_sent: 0.3298003374891976
train_recall_macro_sent: 0.333775950367692
train_f-score_macro_sent: 0.2303772109045823
train_precision_micro_sent: 0.37277621722846443
train_recall_micro_sent: 0.37277621722846443
train_f-score_micro_sent: 0.37277621722846443
train_label=O_precision_tok: 0.8753288629951266
train_label=O_recall_tok: 0.9605619757613775
train_label=O_f-score_tok: 0.9159669020943091
train_label=N_precision_tok: 0.7222892778113056
train_label=N_recall_tok: 0.5056330094352908
train_label=N_f-score_tok: 0.5948475811795891
train_label=P_precision_tok: 0.8044731784029355
train_label=P_recall_tok: 0.5521045688931526
train_label=P_f-score_tok: 0.6548143934006542
train_precision_macro_tok: 0.8006971064031226
train_recall_macro_tok: 0.6727665180299404
train_f-score_macro_tok: 0.7218762922248508
train_precision_micro_tok: 0.8585891933531419
train_recall_micro_tok: 0.8585891933531419
train_f-score_micro_tok: 0.8585891933531419
train_time: 45.21934676170349
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1932    0.0800    0.1132      1624
           N     0.3877    0.9027    0.5424      3310
           P     0.4085    0.0186    0.0355      3610

   micro avg     0.3728    0.3728    0.3728      8544
   macro avg     0.3298    0.3338    0.2304      8544
weighted avg     0.3595    0.3728    0.2467      8544

F1-macro sent:  0.2303772109045823
F1-micro sent:  0.37277621722846443
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8753    0.9606    0.9160    124347
           N     0.7223    0.5056    0.5948     14202
           P     0.8045    0.5521    0.6548     25017

   micro avg     0.8586    0.8586    0.8586    163566
   macro avg     0.8007    0.6728    0.7219    163566
weighted avg     0.8512    0.8586    0.8481    163566

F1-macro tok:  0.7218762922248508
F1-micro tok:  0.8585891933531419
**************************************************
dev_cost_sum: 7790.697357177734
dev_cost_avg: 7.076019397981593
dev_count_sent: 1101.0
dev_total_correct_sent: 428.0
dev_accuracy_sent: 0.3887375113533152
dev_count_tok: 21274.0
dev_total_correct_tok: 18650.0
dev_accuracy_tok: 0.8766569521481621
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.3887375113533152
dev_label=N_recall_sent: 1.0
dev_label=N_f-score_sent: 0.5598430346631786
dev_label=P_precision_sent: 0.0
dev_label=P_recall_sent: 0.0
dev_label=P_f-score_sent: 0.0
dev_precision_macro_sent: 0.12957917045110506
dev_recall_macro_sent: 0.3333333333333333
dev_f-score_macro_sent: 0.1866143448877262
dev_precision_micro_sent: 0.3887375113533152
dev_recall_micro_sent: 0.3887375113533152
dev_f-score_micro_sent: 0.3887375113533152
dev_label=O_precision_tok: 0.8829918262232672
dev_label=O_recall_tok: 0.9732798518975625
dev_label=O_f-score_tok: 0.9259400592949187
dev_label=N_precision_tok: 0.8036332179930796
dev_label=N_recall_tok: 0.5002692514808832
dev_label=N_f-score_tok: 0.6166611350813145
dev_label=P_precision_tok: 0.8639184397163121
dev_label=P_recall_tok: 0.6067870485678705
dev_label=P_f-score_tok: 0.7128749085588881
dev_precision_macro_tok: 0.8501811613108864
dev_recall_macro_tok: 0.6934453839821053
dev_f-score_macro_tok: 0.7518253676450405
dev_precision_micro_tok: 0.8766569521481621
dev_recall_micro_tok: 0.8766569521481621
dev_f-score_micro_tok: 0.8766569521481621
dev_time: 1.9906985759735107
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3887    1.0000    0.5598       428
           P     0.0000    0.0000    0.0000       444

   micro avg     0.3887    0.3887    0.3887      1101
   macro avg     0.1296    0.3333    0.1866      1101
weighted avg     0.1511    0.3887    0.2176      1101

F1-macro sent:  0.1866143448877262
F1-micro sent:  0.3887375113533152
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8830    0.9733    0.9259     16205
           N     0.8036    0.5003    0.6167      1857
           P     0.8639    0.6068    0.7129      3212

   micro avg     0.8767    0.8767    0.8767     21274
   macro avg     0.8502    0.6934    0.7518     21274
weighted avg     0.8732    0.8767    0.8668     21274

F1-macro tok:  0.7518253676450405
F1-micro tok:  0.8766569521481621
**************************************************
Best epoch: 0
**************************************************

EPOCH: 6
Learning rate: 0.810000
train_cost_sum: 64370.02355957031
train_cost_avg: 7.533944705005888
train_count_sent: 8544.0
train_total_correct_sent: 3202.0
train_accuracy_sent: 0.37476591760299627
train_count_tok: 163566.0
train_total_correct_tok: 141447.0
train_accuracy_tok: 0.8647701845126737
train_label=O_precision_sent: 0.1765704584040747
train_label=O_recall_sent: 0.06403940886699508
train_label=O_f-score_sent: 0.09399005874378673
train_label=N_precision_sent: 0.387778780456362
train_label=N_recall_sent: 0.908761329305136
train_label=N_f-score_sent: 0.5435980843950483
train_label=P_precision_sent: 0.45454545454545453
train_label=P_recall_sent: 0.024930747922437674
train_label=P_f-score_sent: 0.04726890756302521
train_precision_macro_sent: 0.33963156446863046
train_recall_macro_sent: 0.33257716203152293
train_f-score_macro_sent: 0.22828568356728676
train_precision_micro_sent: 0.37476591760299627
train_recall_micro_sent: 0.37476591760299627
train_f-score_micro_sent: 0.37476591760299627
train_label=O_precision_tok: 0.8799276832172149
train_label=O_recall_tok: 0.9628700330526672
train_label=O_f-score_tok: 0.9195322850066241
train_label=N_precision_tok: 0.7397721644378406
train_label=N_recall_tok: 0.5258414307843966
train_label=N_f-score_tok: 0.6147260978721654
train_label=P_precision_tok: 0.8187668792736884
train_label=P_recall_tok: 0.5695726905704122
train_label=P_f-score_tok: 0.6718057520037718
train_precision_macro_tok: 0.8128222423095813
train_recall_macro_tok: 0.6860947181358252
train_f-score_macro_tok: 0.7353547116275204
train_precision_micro_tok: 0.8647701845126737
train_recall_micro_tok: 0.8647701845126737
train_f-score_micro_tok: 0.8647701845126737
train_time: 45.02068114280701
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1766    0.0640    0.0940      1624
           N     0.3878    0.9088    0.5436      3310
           P     0.4545    0.0249    0.0473      3610

   micro avg     0.3748    0.3748    0.3748      8544
   macro avg     0.3396    0.3326    0.2283      8544
weighted avg     0.3758    0.3748    0.2484      8544

F1-macro sent:  0.22828568356728676
F1-micro sent:  0.37476591760299627
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8799    0.9629    0.9195    124347
           N     0.7398    0.5258    0.6147     14202
           P     0.8188    0.5696    0.6718     25017

   micro avg     0.8648    0.8648    0.8648    163566
   macro avg     0.8128    0.6861    0.7354    163566
weighted avg     0.8584    0.8648    0.8552    163566

F1-macro tok:  0.7353547116275204
F1-micro tok:  0.8647701845126737
**************************************************
dev_cost_sum: 7655.115158081055
dev_cost_avg: 6.952874802980068
dev_count_sent: 1101.0
dev_total_correct_sent: 428.0
dev_accuracy_sent: 0.3887375113533152
dev_count_tok: 21274.0
dev_total_correct_tok: 18704.0
dev_accuracy_tok: 0.8791952618219423
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.3887375113533152
dev_label=N_recall_sent: 1.0
dev_label=N_f-score_sent: 0.5598430346631786
dev_label=P_precision_sent: 0.0
dev_label=P_recall_sent: 0.0
dev_label=P_f-score_sent: 0.0
dev_precision_macro_sent: 0.12957917045110506
dev_recall_macro_sent: 0.3333333333333333
dev_f-score_macro_sent: 0.1866143448877262
dev_precision_micro_sent: 0.3887375113533152
dev_recall_micro_sent: 0.3887375113533152
dev_f-score_micro_sent: 0.3887375113533152
dev_label=O_precision_tok: 0.8854786219279542
dev_label=O_recall_tok: 0.9738352360382598
dev_label=O_f-score_tok: 0.9275575278455345
dev_label=N_precision_tok: 0.8117854001759015
dev_label=N_recall_tok: 0.4970382337102854
dev_label=N_f-score_tok: 0.616566466265865
dev_label=P_precision_tok: 0.8639308855291576
dev_label=P_recall_tok: 0.6226650062266501
dev_label=P_f-score_tok: 0.7237199203908088
dev_precision_macro_tok: 0.8537316358776712
dev_recall_macro_tok: 0.6978461586583985
dev_f-score_macro_tok: 0.7559479715007361
dev_precision_micro_tok: 0.8791952618219423
dev_recall_micro_tok: 0.8791952618219423
dev_f-score_micro_tok: 0.8791952618219423
dev_time: 1.9691507816314697
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3887    1.0000    0.5598       428
           P     0.0000    0.0000    0.0000       444

   micro avg     0.3887    0.3887    0.3887      1101
   macro avg     0.1296    0.3333    0.1866      1101
weighted avg     0.1511    0.3887    0.2176      1101

F1-macro sent:  0.1866143448877262
F1-micro sent:  0.3887375113533152
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8855    0.9738    0.9276     16205
           N     0.8118    0.4970    0.6166      1857
           P     0.8639    0.6227    0.7237      3212

   micro avg     0.8792    0.8792    0.8792     21274
   macro avg     0.8537    0.6978    0.7559     21274
weighted avg     0.8758    0.8792    0.8696     21274

F1-macro tok:  0.7559479715007361
F1-micro tok:  0.8791952618219423
**************************************************
Best epoch: 0
**************************************************

EPOCH: 7
Learning rate: 0.729000
train_cost_sum: 63135.078216552734
train_cost_avg: 7.389405221974805
train_count_sent: 8544.0
train_total_correct_sent: 3245.0
train_accuracy_sent: 0.3797986891385768
train_count_tok: 163566.0
train_total_correct_tok: 141927.0
train_accuracy_tok: 0.8677047797219472
train_label=O_precision_sent: 0.1565934065934066
train_label=O_recall_sent: 0.035098522167487683
train_label=O_f-score_sent: 0.05734406438631791
train_label=N_precision_sent: 0.38846775195725114
train_label=N_recall_sent: 0.9444108761329305
train_label=N_f-score_sent: 0.5504974905344722
train_label=P_precision_sent: 0.46616541353383456
train_label=P_recall_sent: 0.017174515235457065
train_label=P_f-score_sent: 0.033128506545551696
train_precision_macro_sent: 0.33707552402816415
train_recall_macro_sent: 0.33222797117862507
train_f-score_macro_sent: 0.21365668715544725
train_precision_micro_sent: 0.3797986891385768
train_recall_micro_sent: 0.3797986891385768
train_f-score_micro_sent: 0.37979868913857673
train_label=O_precision_tok: 0.8819186563816723
train_label=O_recall_tok: 0.9645025613806525
train_label=O_f-score_tok: 0.9213637655663022
train_label=N_precision_tok: 0.7453648915187376
train_label=N_recall_tok: 0.5321785663990988
train_label=N_f-score_tok: 0.6209843069591653
train_label=P_precision_tok: 0.8279896759392028
train_label=P_recall_tok: 0.5770476076268137
train_label=P_f-score_tok: 0.6801092999151983
train_precision_macro_tok: 0.8184244079465376
train_recall_macro_tok: 0.6912429118021883
train_f-score_macro_tok: 0.7408191241468886
train_precision_micro_tok: 0.8677047797219472
train_recall_micro_tok: 0.8677047797219472
train_f-score_micro_tok: 0.8677047797219472
train_time: 45.1129949092865
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1566    0.0351    0.0573      1624
           N     0.3885    0.9444    0.5505      3310
           P     0.4662    0.0172    0.0331      3610

   micro avg     0.3798    0.3798    0.3798      8544
   macro avg     0.3371    0.3322    0.2137      8544
weighted avg     0.3772    0.3798    0.2382      8544

F1-macro sent:  0.21365668715544725
F1-micro sent:  0.37979868913857673
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8819    0.9645    0.9214    124347
           N     0.7454    0.5322    0.6210     14202
           P     0.8280    0.5770    0.6801     25017

   micro avg     0.8677    0.8677    0.8677    163566
   macro avg     0.8184    0.6912    0.7408    163566
weighted avg     0.8618    0.8677    0.8584    163566

F1-macro tok:  0.7408191241468886
F1-micro tok:  0.8677047797219472
**************************************************
dev_cost_sum: 7471.132392883301
dev_cost_avg: 6.785769657478021
dev_count_sent: 1101.0
dev_total_correct_sent: 428.0
dev_accuracy_sent: 0.3887375113533152
dev_count_tok: 21274.0
dev_total_correct_tok: 18757.0
dev_accuracy_tok: 0.8816865657610229
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.3887375113533152
dev_label=N_recall_sent: 1.0
dev_label=N_f-score_sent: 0.5598430346631786
dev_label=P_precision_sent: 0.0
dev_label=P_recall_sent: 0.0
dev_label=P_f-score_sent: 0.0
dev_precision_macro_sent: 0.12957917045110506
dev_recall_macro_sent: 0.3333333333333333
dev_f-score_macro_sent: 0.1866143448877262
dev_precision_micro_sent: 0.3887375113533152
dev_recall_micro_sent: 0.3887375113533152
dev_f-score_micro_sent: 0.3887375113533152
dev_label=O_precision_tok: 0.8907753254102999
dev_label=O_recall_tok: 0.9713051527306387
dev_label=O_f-score_tok: 0.9292988929889299
dev_label=N_precision_tok: 0.7484276729559748
dev_label=N_recall_tok: 0.5767366720516963
dev_label=N_f-score_tok: 0.6514598540145985
dev_label=P_precision_tok: 0.8955361251725725
dev_label=P_recall_tok: 0.6058530510585305
dev_label=P_f-score_tok: 0.722748375116063
dev_precision_macro_tok: 0.8449130411796157
dev_recall_macro_tok: 0.7179649586136218
dev_f-score_macro_tok: 0.7678357073731972
dev_precision_micro_tok: 0.8816865657610229
dev_recall_micro_tok: 0.8816865657610229
dev_f-score_micro_tok: 0.8816865657610229
dev_time: 2.010537624359131
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.3887    1.0000    0.5598       428
           P     0.0000    0.0000    0.0000       444

   micro avg     0.3887    0.3887    0.3887      1101
   macro avg     0.1296    0.3333    0.1866      1101
weighted avg     0.1511    0.3887    0.2176      1101

F1-macro sent:  0.1866143448877262
F1-micro sent:  0.3887375113533152
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9713    0.9293     16205
           N     0.7484    0.5767    0.6515      1857
           P     0.8955    0.6059    0.7227      3212

   micro avg     0.8817    0.8817    0.8817     21274
   macro avg     0.8449    0.7180    0.7678     21274
weighted avg     0.8791    0.8817    0.8739     21274

F1-macro tok:  0.7678357073731972
F1-micro tok:  0.8816865657610229
**************************************************
Best epoch: 0
**************************************************

test0_cost_sum: 10252.843490600586
test0_cost_avg: 9.312301081381095
test0_count_sent: 1101.0
test0_total_correct_sent: 363.0
test0_accuracy_sent: 0.329700272479564
test0_count_tok: 21274.0
test0_total_correct_tok: 17535.0
test0_accuracy_tok: 0.8242455579580709
test0_label=O_precision_sent: 0.21453287197231835
test0_label=O_recall_sent: 0.27074235807860264
test0_label=O_f-score_sent: 0.23938223938223938
test0_label=N_precision_sent: 0.36991368680641185
test0_label=N_recall_sent: 0.7009345794392523
test0_label=N_f-score_sent: 0.48426150121065376
test0_label=P_precision_sent: 1.0
test0_label=P_recall_sent: 0.0022522522522522522
test0_label=P_f-score_sent: 0.00449438202247191
test0_precision_macro_sent: 0.5281488529262434
test0_recall_macro_sent: 0.3246430632567024
test0_f-score_macro_sent: 0.242712707538455
test0_precision_micro_sent: 0.329700272479564
test0_recall_micro_sent: 0.329700272479564
test0_f-score_micro_sent: 0.329700272479564
test0_label=O_precision_tok: 0.8500722141984224
test0_label=O_recall_tok: 0.9443381672323357
test0_label=O_f-score_tok: 0.8947291490045897
test0_label=N_precision_tok: 0.6118462507876496
test0_label=N_recall_tok: 0.5228863758750674
test0_label=N_f-score_tok: 0.5638792102206738
test0_label=P_precision_tok: 0.7483679525222552
test0_label=P_recall_tok: 0.3925902864259029
test0_label=P_f-score_tok: 0.5150091892995712
test0_precision_macro_tok: 0.7367621391694424
test0_recall_macro_tok: 0.6199382765111019
test0_f-score_macro_tok: 0.6578725161749449
test0_precision_micro_tok: 0.8242455579580709
test0_recall_micro_tok: 0.8242455579580709
test0_f-score_micro_tok: 0.8242455579580709
test0_time: 2.0390028953552246
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2145    0.2707    0.2394       229
           N     0.3699    0.7009    0.4843       428
           P     1.0000    0.0023    0.0045       444

   micro avg     0.3297    0.3297    0.3297      1101
   macro avg     0.5281    0.3246    0.2427      1101
weighted avg     0.5917    0.3297    0.2399      1101

F1-macro sent:  0.242712707538455
F1-micro sent:  0.329700272479564
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8501    0.9443    0.8947     16205
           N     0.6118    0.5229    0.5639      1857
           P     0.7484    0.3926    0.5150      3212

   micro avg     0.8242    0.8242    0.8242     21274
   macro avg     0.7368    0.6199    0.6579     21274
weighted avg     0.8139    0.8242    0.8085     21274

F1-macro tok:  0.6578725161749449
F1-micro tok:  0.8242455579580709
**************************************************
test1_cost_sum: 20728.032021522522
test1_cost_avg: 9.379200009738698
test1_count_sent: 2210.0
test1_total_correct_sent: 789.0
test1_accuracy_sent: 0.3570135746606335
test1_count_tok: 42405.0
test1_total_correct_tok: 34852.0
test1_accuracy_tok: 0.8218842117674803
test1_label=O_precision_sent: 0.2268041237113402
test1_label=O_recall_sent: 0.3393316195372751
test1_label=O_f-score_sent: 0.2718846549948507
test1_label=N_precision_sent: 0.4031960663798402
test1_label=N_recall_sent: 0.7192982456140351
test1_label=N_f-score_sent: 0.5167388735722726
test1_label=P_precision_sent: 1.0
test1_label=P_recall_sent: 0.0011001100110011
test1_label=P_f-score_sent: 0.002197802197802198
test1_precision_macro_sent: 0.5433333966970602
test1_recall_macro_sent: 0.3532433250541038
test1_f-score_macro_sent: 0.26360711025497513
test1_precision_micro_sent: 0.3570135746606335
test1_recall_micro_sent: 0.3570135746606335
test1_f-score_micro_sent: 0.3570135746606335
test1_label=O_precision_tok: 0.8436059747903826
test1_label=O_recall_tok: 0.9495905994124633
test1_label=O_f-score_tok: 0.8934662432368854
test1_label=N_precision_tok: 0.6382569689202179
test1_label=N_recall_tok: 0.5297872340425532
test1_label=N_f-score_tok: 0.5789856125563145
test1_label=P_precision_tok: 0.7578077158603796
test1_label=P_recall_tok: 0.37234842786219347
test1_label=P_f-score_tok: 0.4993442953697165
test1_precision_macro_tok: 0.7465568865236599
test1_recall_macro_tok: 0.6172420871057366
test1_f-score_macro_tok: 0.6572653837209721
test1_precision_micro_tok: 0.8218842117674803
test1_recall_micro_tok: 0.8218842117674803
test1_f-score_micro_tok: 0.8218842117674803
test1_time: 4.066210508346558
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2268    0.3393    0.2719       389
           N     0.4032    0.7193    0.5167       912
           P     1.0000    0.0011    0.0022       909

   micro avg     0.3570    0.3570    0.3570      2210
   macro avg     0.5433    0.3532    0.2636      2210
weighted avg     0.6176    0.3570    0.2620      2210

F1-macro sent:  0.26360711025497513
F1-micro sent:  0.3570135746606335
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8436    0.9496    0.8935     31998
           N     0.6383    0.5298    0.5790      3760
           P     0.7578    0.3723    0.4993      6647

   micro avg     0.8219    0.8219    0.8219     42405
   macro avg     0.7466    0.6172    0.6573     42405
weighted avg     0.8119    0.8219    0.8038     42405

F1-macro tok:  0.6572653837209721
F1-micro tok:  0.8218842117674803
**************************************************
