to_write_filename: runs/transformer_sentiment_gap_loss=0.1_max_threshold=0.5_25_March.txt
debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
model_selector_ratio: 1
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
residual_connection: False
token_scoring_method: sum
attention_loss_between_all: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
gap_objective_weight: 0.1
maximum_gap_threshold: 0.5
sentence_composition: attention
random_seed: 100
{'O': 0, 'N': 1, 'P': 2}
{'O': 0, 'N': 1, 'P': 2}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
n_preloaded_embeddings: 17568
Parameter count: 9033357.
Parameter count without word embeddings: 3232857.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 428005.33654785156
train_cost_avg: 50.09425755475791
train_count_sent: 8544.0
train_total_correct_sent: 4359.0
train_accuracy_sent: 0.5101825842696629
train_count_tok: 163566.0
train_total_correct_tok: 125960.0
train_accuracy_tok: 0.770086692833474
train_label=O_precision_sent: 0.1794871794871795
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.04520990312163617
train_label=N_precision_sent: 0.5024051309460181
train_label=N_recall_sent: 0.56797583081571
train_label=N_f-score_sent: 0.5331820760068066
train_label=P_precision_sent: 0.533493870402802
train_label=P_recall_sent: 0.6750692520775623
train_label=P_f-score_sent: 0.5959892394228418
train_precision_macro_sent: 0.4051287269453332
train_recall_macro_sent: 0.4229690506195965
train_f-score_macro_sent: 0.3914604061837615
train_precision_micro_sent: 0.5101825842696629
train_recall_micro_sent: 0.5101825842696629
train_f-score_micro_sent: 0.5101825842696629
train_label=O_precision_tok: 0.7968701496767576
train_label=O_recall_tok: 0.9496409241879579
train_label=O_f-score_tok: 0.8665739561814533
train_label=N_precision_tok: 0.4968564442892071
train_label=N_recall_tok: 0.20032389804252923
train_label=N_f-score_tok: 0.28552790044158977
train_label=P_precision_tok: 0.5210275533457635
train_label=P_recall_tok: 0.20106327697165927
train_label=P_f-score_tok: 0.29015603818753427
train_precision_macro_tok: 0.6049180491039094
train_recall_macro_tok: 0.4503426997340488
train_f-score_macro_tok: 0.48075263160352577
train_precision_micro_tok: 0.770086692833474
train_recall_micro_tok: 0.770086692833474
train_f-score_micro_tok: 0.770086692833474
train_time: 147.94821953773499
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1795    0.0259    0.0452      1624
           N     0.5024    0.5680    0.5332      3310
           P     0.5335    0.6751    0.5960      3610

   micro avg     0.5102    0.5102    0.5102      8544
   macro avg     0.4051    0.4230    0.3915      8544
weighted avg     0.4542    0.5102    0.4670      8544

F1-macro sent:  0.3914604061837615
F1-micro sent:  0.5101825842696629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7969    0.9496    0.8666    124347
           N     0.4969    0.2003    0.2855     14202
           P     0.5210    0.2011    0.2902     25017

   micro avg     0.7701    0.7701    0.7701    163566
   macro avg     0.6049    0.4503    0.4808    163566
weighted avg     0.7286    0.7701    0.7280    163566

F1-macro tok:  0.48075263160352577
F1-micro tok:  0.770086692833474
**************************************************
dev_cost_sum: 50947.09216308594
dev_cost_avg: 46.27347153777106
dev_count_sent: 1101.0
dev_total_correct_sent: 660.0
dev_accuracy_sent: 0.5994550408719346
dev_count_tok: 21274.0
dev_total_correct_tok: 17467.0
dev_accuracy_tok: 0.8210491679984958
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5357142857142857
dev_label=N_recall_sent: 0.8761682242990654
dev_label=N_f-score_sent: 0.6648936170212766
dev_label=P_precision_sent: 0.7107231920199502
dev_label=P_recall_sent: 0.6418918918918919
dev_label=P_f-score_sent: 0.6745562130177515
dev_precision_macro_sent: 0.4154791592447453
dev_recall_macro_sent: 0.5060200387303191
dev_f-score_macro_sent: 0.446483276679676
dev_precision_micro_sent: 0.5994550408719346
dev_recall_micro_sent: 0.5994550408719346
dev_f-score_micro_sent: 0.5994550408719346
dev_label=O_precision_tok: 0.843844338328119
dev_label=O_recall_tok: 0.9487195310089479
dev_label=O_f-score_tok: 0.8932140367185685
dev_label=N_precision_tok: 0.6113333333333333
dev_label=N_recall_tok: 0.4938072159396877
dev_label=N_f-score_tok: 0.5463211200476616
dev_label=P_precision_tok: 0.7562700964630225
dev_label=P_recall_tok: 0.36612702366127026
dev_label=P_f-score_tok: 0.49339207048458156
dev_precision_macro_tok: 0.7371492560414916
dev_recall_macro_tok: 0.6028845902033019
dev_f-score_macro_tok: 0.6443090757502705
dev_precision_micro_tok: 0.8210491679984958
dev_recall_micro_tok: 0.8210491679984958
dev_f-score_micro_tok: 0.8210491679984958
dev_time: 8.984687089920044
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5357    0.8762    0.6649       428
           P     0.7107    0.6419    0.6746       444

   micro avg     0.5995    0.5995    0.5995      1101
   macro avg     0.4155    0.5060    0.4465      1101
weighted avg     0.4949    0.5995    0.5305      1101

F1-macro sent:  0.446483276679676
F1-micro sent:  0.5994550408719346
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8438    0.9487    0.8932     16205
           N     0.6113    0.4938    0.5463      1857
           P     0.7563    0.3661    0.4934      3212

   micro avg     0.8210    0.8210    0.8210     21274
   macro avg     0.7371    0.6029    0.6443     21274
weighted avg     0.8103    0.8210    0.8026     21274

F1-macro tok:  0.6443090757502705
F1-micro tok:  0.8210491679984958
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 379500.1057128906
train_cost_avg: 44.41714720422409
train_count_sent: 8544.0
train_total_correct_sent: 4845.0
train_accuracy_sent: 0.567064606741573
train_count_tok: 163566.0
train_total_correct_tok: 132004.0
train_accuracy_tok: 0.8070381375102406
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.0036742192284139616
train_label=N_precision_sent: 0.5385867038586704
train_label=N_recall_sent: 0.7
train_label=N_f-score_sent: 0.6087756174461377
train_label=P_precision_sent: 0.5965036617056461
train_label=P_recall_sent: 0.6994459833795014
train_label=P_f-score_sent: 0.6438862680096902
train_precision_macro_sent: 0.4894745662992166
train_recall_macro_sent: 0.46709775800663184
train_f-score_macro_sent: 0.41877870156141395
train_precision_micro_sent: 0.567064606741573
train_recall_micro_sent: 0.567064606741573
train_f-score_micro_sent: 0.567064606741573
train_label=O_precision_tok: 0.8305102621975657
train_label=O_recall_tok: 0.949890226543463
train_label=O_f-score_tok: 0.8861978932204915
train_label=N_precision_tok: 0.6352517985611511
train_label=N_recall_tok: 0.3730460498521335
train_label=N_f-score_tok: 0.47005589566143197
train_label=P_precision_tok: 0.6605151864667436
train_label=P_recall_tok: 0.3433665107726746
train_label=P_f-score_tok: 0.45184366945452636
train_precision_macro_tok: 0.7087590824084868
train_recall_macro_tok: 0.5554342623894237
train_f-score_macro_tok: 0.6026991527788166
train_precision_micro_tok: 0.8070381375102406
train_recall_micro_tok: 0.8070381375102406
train_f-score_micro_tok: 0.8070381375102406
train_time: 175.28406023979187
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0018    0.0037      1624
           N     0.5386    0.7000    0.6088      3310
           P     0.5965    0.6994    0.6439      3610

   micro avg     0.5671    0.5671    0.5671      8544
   macro avg     0.4895    0.4671    0.4188      8544
weighted avg     0.5240    0.5671    0.5086      8544

F1-macro sent:  0.41877870156141395
F1-micro sent:  0.567064606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8305    0.9499    0.8862    124347
           N     0.6353    0.3730    0.4701     14202
           P     0.6605    0.3434    0.4518     25017

   micro avg     0.8070    0.8070    0.8070    163566
   macro avg     0.7088    0.5554    0.6027    163566
weighted avg     0.7876    0.8070    0.7836    163566

F1-macro tok:  0.6026991527788166
F1-micro tok:  0.8070381375102406
**************************************************
dev_cost_sum: 49222.92077636719
dev_cost_avg: 44.707466645201805
dev_count_sent: 1101.0
dev_total_correct_sent: 636.0
dev_accuracy_sent: 0.5776566757493188
dev_count_tok: 21274.0
dev_total_correct_tok: 17700.0
dev_accuracy_tok: 0.8320015041835104
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.4923258559622196
dev_label=N_recall_sent: 0.9742990654205608
dev_label=N_f-score_sent: 0.6541176470588235
dev_label=P_precision_sent: 0.8622047244094488
dev_label=P_recall_sent: 0.49324324324324326
dev_label=P_f-score_sent: 0.6275071633237823
dev_precision_macro_sent: 0.4515101934572228
dev_recall_macro_sent: 0.4891807695546013
dev_f-score_macro_sent: 0.42720827012753526
dev_precision_micro_sent: 0.5776566757493188
dev_recall_micro_sent: 0.5776566757493188
dev_f-score_micro_sent: 0.5776566757493188
dev_label=O_precision_tok: 0.8404773371862793
dev_label=O_recall_tok: 0.9692070348657822
dev_label=O_f-score_tok: 0.9002636707554741
dev_label=N_precision_tok: 0.6943802925327175
dev_label=N_recall_tok: 0.4857296715131933
dev_label=N_f-score_tok: 0.5716096324461344
dev_label=P_precision_tok: 0.8478260869565217
dev_label=P_recall_tok: 0.33997509339975096
dev_label=P_f-score_tok: 0.48533333333333334
dev_precision_macro_tok: 0.7942279055585061
dev_recall_macro_tok: 0.5983039332595755
dev_f-score_macro_tok: 0.652402212178314
dev_precision_micro_tok: 0.8320015041835104
dev_recall_micro_tok: 0.8320015041835104
dev_f-score_micro_tok: 0.8320015041835104
dev_time: 11.782134532928467
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.4923    0.9743    0.6541       428
           P     0.8622    0.4932    0.6275       444

   micro avg     0.5777    0.5777    0.5777      1101
   macro avg     0.4515    0.4892    0.4272      1101
weighted avg     0.5391    0.5777    0.5073      1101

F1-macro sent:  0.42720827012753526
F1-micro sent:  0.5776566757493188
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8405    0.9692    0.9003     16205
           N     0.6944    0.4857    0.5716      1857
           P     0.8478    0.3400    0.4853      3212

   micro avg     0.8320    0.8320    0.8320     21274
   macro avg     0.7942    0.5983    0.6524     21274
weighted avg     0.8288    0.8320    0.8089     21274

F1-macro tok:  0.652402212178314
F1-micro tok:  0.8320015041835104
**************************************************
Best epoch: 0
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 369183.0247192383
train_cost_avg: 43.20962367968613
train_count_sent: 8544.0
train_total_correct_sent: 5059.0
train_accuracy_sent: 0.5921114232209738
train_count_tok: 163566.0
train_total_correct_tok: 135520.0
train_accuracy_tok: 0.8285340474181676
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5588633288227334
train_label=N_recall_sent: 0.7486404833836858
train_label=N_f-score_sent: 0.6399793388429752
train_label=P_precision_sent: 0.6293586930017069
train_label=P_recall_sent: 0.7149584487534626
train_label=P_f-score_sent: 0.6694332771365581
train_precision_macro_sent: 0.3960740072748134
train_recall_macro_sent: 0.48786631071238284
train_f-score_macro_sent: 0.43647087199317774
train_precision_micro_sent: 0.5921114232209738
train_recall_micro_sent: 0.5921114232209738
train_f-score_micro_sent: 0.5921114232209738
train_label=O_precision_tok: 0.8484985049429875
train_label=O_recall_tok: 0.9539031902659493
train_label=O_f-score_tok: 0.8981188077579777
train_label=N_precision_tok: 0.6821869096566285
train_label=N_recall_tok: 0.4322630615406281
train_label=N_f-score_tok: 0.5292013275289859
train_label=P_precision_tok: 0.7287619305489745
train_label=P_recall_tok: 0.430347363792621
train_label=P_f-score_tok: 0.5411409901985423
train_precision_macro_tok: 0.7531491150495301
train_recall_macro_tok: 0.6055045385330661
train_f-score_macro_tok: 0.6561537084951686
train_precision_micro_tok: 0.8285340474181676
train_recall_micro_tok: 0.8285340474181676
train_f-score_micro_tok: 0.8285340474181675
train_time: 198.08236718177795
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5589    0.7486    0.6400      3310
           P     0.6294    0.7150    0.6694      3610

   micro avg     0.5921    0.5921    0.5921      8544
   macro avg     0.3961    0.4879    0.4365      8544
weighted avg     0.4824    0.5921    0.5308      8544

F1-macro sent:  0.43647087199317774
F1-micro sent:  0.5921114232209738
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8485    0.9539    0.8981    124347
           N     0.6822    0.4323    0.5292     14202
           P     0.7288    0.4303    0.5411     25017

   micro avg     0.8285    0.8285    0.8285    163566
   macro avg     0.7531    0.6055    0.6562    163566
weighted avg     0.8157    0.8285    0.8115    163566

F1-macro tok:  0.6561537084951686
F1-micro tok:  0.8285340474181675
**************************************************
dev_cost_sum: 48118.43444824219
dev_cost_avg: 43.70430013464322
dev_count_sent: 1101.0
dev_total_correct_sent: 680.0
dev_accuracy_sent: 0.6176203451407811
dev_count_tok: 21274.0
dev_total_correct_tok: 18239.0
dev_accuracy_tok: 0.8573375951866128
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5868465430016864
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.6816846229187072
dev_label=P_precision_sent: 0.6561264822134387
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.6989473684210525
dev_precision_macro_sent: 0.41432434173837507
dev_recall_macro_sent: 0.5202772866324268
dev_f-score_macro_sent: 0.4602106637799199
dev_precision_micro_sent: 0.6176203451407811
dev_recall_micro_sent: 0.6176203451407811
dev_f-score_micro_sent: 0.6176203451407811
dev_label=O_precision_tok: 0.8649243466299863
dev_label=O_recall_tok: 0.9700709657513114
dev_label=O_f-score_tok: 0.9144851657940664
dev_label=N_precision_tok: 0.7745490981963928
dev_label=N_recall_tok: 0.41626278944534195
dev_label=N_f-score_tok: 0.5415061295971979
dev_label=P_precision_tok: 0.8310328415040457
dev_label=P_recall_tok: 0.5435865504358655
dev_label=P_f-score_tok: 0.6572557876905702
dev_precision_macro_tok: 0.8235020954434749
dev_recall_macro_tok: 0.6433067685441729
dev_f-score_macro_tok: 0.7044156943606116
dev_precision_micro_tok: 0.8573375951866128
dev_recall_micro_tok: 0.8573375951866128
dev_f-score_micro_tok: 0.8573375951866128
dev_time: 11.786634922027588
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5868    0.8131    0.6817       428
           P     0.6561    0.7477    0.6989       444

   micro avg     0.6176    0.6176    0.6176      1101
   macro avg     0.4143    0.5203    0.4602      1101
weighted avg     0.4927    0.6176    0.5469      1101

F1-macro sent:  0.4602106637799199
F1-micro sent:  0.6176203451407811
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8649    0.9701    0.9145     16205
           N     0.7745    0.4163    0.5415      1857
           P     0.8310    0.5436    0.6573      3212

   micro avg     0.8573    0.8573    0.8573     21274
   macro avg     0.8235    0.6433    0.7044     21274
weighted avg     0.8519    0.8573    0.8431     21274

F1-macro tok:  0.7044156943606116
F1-micro tok:  0.8573375951866128
**************************************************
Best epoch: 2
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 362098.99572753906
train_cost_avg: 42.38050043627564
train_count_sent: 8544.0
train_total_correct_sent: 5134.0
train_accuracy_sent: 0.6008895131086143
train_count_tok: 163566.0
train_total_correct_tok: 137496.0
train_accuracy_tok: 0.8406147976963427
train_label=O_precision_sent: 0.2
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002447980416156671
train_label=N_precision_sent: 0.5666666666666667
train_label=N_recall_sent: 0.7395770392749245
train_label=N_f-score_sent: 0.6416775884665793
train_label=P_precision_sent: 0.6369245372567631
train_label=P_recall_sent: 0.7434903047091412
train_label=P_f-score_sent: 0.6860940695296524
train_precision_macro_sent: 0.4678637346411432
train_recall_macro_sent: 0.49476629035922065
train_f-score_macro_sent: 0.4434065461374628
train_precision_micro_sent: 0.6008895131086143
train_recall_micro_sent: 0.6008895131086143
train_f-score_micro_sent: 0.6008895131086143
train_label=O_precision_tok: 0.8593071560163277
train_label=O_recall_tok: 0.9565248860044875
train_label=O_f-score_tok: 0.9053135537102016
train_label=N_precision_tok: 0.6924831631544645
train_label=N_recall_tok: 0.44888043937473593
train_label=N_f-score_tok: 0.5446855775803143
train_label=P_precision_tok: 0.7638758231420508
train_label=P_recall_tok: 0.48686892912819285
train_label=P_f-score_tok: 0.5946975245349347
train_precision_macro_tok: 0.7718887141042808
train_recall_macro_tok: 0.6307580848358054
train_f-score_macro_tok: 0.6815655519418168
train_precision_micro_tok: 0.8406147976963427
train_recall_micro_tok: 0.8406147976963427
train_f-score_micro_tok: 0.8406147976963428
train_time: 195.91601419448853
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2000    0.0012    0.0024      1624
           N     0.5667    0.7396    0.6417      3310
           P     0.6369    0.7435    0.6861      3610

   micro avg     0.6009    0.6009    0.6009      8544
   macro avg     0.4679    0.4948    0.4434      8544
weighted avg     0.5267    0.6009    0.5389      8544

F1-macro sent:  0.4434065461374628
F1-micro sent:  0.6008895131086143
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8593    0.9565    0.9053    124347
           N     0.6925    0.4489    0.5447     14202
           P     0.7639    0.4869    0.5947     25017

   micro avg     0.8406    0.8406    0.8406    163566
   macro avg     0.7719    0.6308    0.6816    163566
weighted avg     0.8302    0.8406    0.8265    163566

F1-macro tok:  0.6815655519418168
F1-micro tok:  0.8406147976963428
**************************************************
dev_cost_sum: 47405.774169921875
dev_cost_avg: 43.05701559484276
dev_count_sent: 1101.0
dev_total_correct_sent: 686.0
dev_accuracy_sent: 0.623069936421435
dev_count_tok: 21274.0
dev_total_correct_tok: 18376.0
dev_accuracy_tok: 0.8637773808404625
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6014362657091562
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.6802030456852791
dev_label=P_precision_sent: 0.6452205882352942
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7105263157894738
dev_precision_macro_sent: 0.41555228464815014
dev_recall_macro_sent: 0.5244169403047908
dev_f-score_macro_sent: 0.46357645382491763
dev_precision_micro_sent: 0.623069936421435
dev_recall_micro_sent: 0.623069936421435
dev_f-score_micro_sent: 0.623069936421435
dev_label=O_precision_tok: 0.8705947441217151
dev_label=O_recall_tok: 0.9710583153347733
dev_label=O_f-score_tok: 0.9180863477246208
dev_label=N_precision_tok: 0.7954319761668321
dev_label=N_recall_tok: 0.43134087237479807
dev_label=N_f-score_tok: 0.5593575418994413
dev_label=P_precision_tok: 0.8389598540145985
dev_label=P_recall_tok: 0.5725404732254047
dev_label=P_f-score_tok: 0.6806069578090302
dev_precision_macro_tok: 0.8349955247677152
dev_recall_macro_tok: 0.6583132203116587
dev_f-score_macro_tok: 0.7193502824776975
dev_precision_micro_tok: 0.8637773808404625
dev_recall_micro_tok: 0.8637773808404625
dev_f-score_micro_tok: 0.8637773808404625
dev_time: 9.703083515167236
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6014    0.7827    0.6802       428
           P     0.6452    0.7905    0.7105       444

   micro avg     0.6231    0.6231    0.6231      1101
   macro avg     0.4156    0.5244    0.4636      1101
weighted avg     0.4940    0.6231    0.5510      1101

F1-macro sent:  0.46357645382491763
F1-micro sent:  0.623069936421435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8706    0.9711    0.9181     16205
           N     0.7954    0.4313    0.5594      1857
           P     0.8390    0.5725    0.6806      3212

   micro avg     0.8638    0.8638    0.8638     21274
   macro avg     0.8350    0.6583    0.7194     21274
weighted avg     0.8593    0.8638    0.8509     21274

F1-macro tok:  0.7193502824776975
F1-micro tok:  0.8637773808404625
**************************************************
Best epoch: 3
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 356289.8439941406
train_cost_avg: 41.70059035511945
train_count_sent: 8544.0
train_total_correct_sent: 5184.0
train_accuracy_sent: 0.6067415730337079
train_count_tok: 163566.0
train_total_correct_tok: 139002.0
train_accuracy_tok: 0.8498220901654379
train_label=O_precision_sent: 0.2978723404255319
train_label=O_recall_sent: 0.008620689655172414
train_label=O_f-score_sent: 0.016756433273488927
train_label=N_precision_sent: 0.5802176999526739
train_label=N_recall_sent: 0.740785498489426
train_label=N_f-score_sent: 0.6507430997876859
train_label=P_precision_sent: 0.6363849215640365
train_label=P_recall_sent: 0.7529085872576178
train_label=P_f-score_sent: 0.6897601827179293
train_precision_macro_sent: 0.5048249873140808
train_recall_macro_sent: 0.5007715918007387
train_f-score_macro_sent: 0.4524199052597013
train_precision_micro_sent: 0.6067415730337079
train_recall_micro_sent: 0.6067415730337079
train_f-score_micro_sent: 0.6067415730337079
train_label=O_precision_tok: 0.8664734973094268
train_label=O_recall_tok: 0.9595406403049531
train_label=O_f-score_tok: 0.9106353749284488
train_label=N_precision_tok: 0.7147435897435898
train_label=N_recall_tok: 0.4710604140261935
train_label=N_f-score_tok: 0.5678635090399796
train_label=P_precision_tok: 0.7874931830576258
train_label=P_recall_tok: 0.5194867490106727
train_label=P_f-score_tok: 0.6260115606936415
train_precision_macro_tok: 0.7895700900368808
train_recall_macro_tok: 0.6500292677806064
train_f-score_macro_tok: 0.7015034815540232
train_precision_micro_tok: 0.8498220901654379
train_recall_micro_tok: 0.8498220901654379
train_f-score_micro_tok: 0.8498220901654379
train_time: 145.63666152954102
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2979    0.0086    0.0168      1624
           N     0.5802    0.7408    0.6507      3310
           P     0.6364    0.7529    0.6898      3610

   micro avg     0.6067    0.6067    0.6067      8544
   macro avg     0.5048    0.5008    0.4524      8544
weighted avg     0.5503    0.6067    0.5467      8544

F1-macro sent:  0.4524199052597013
F1-micro sent:  0.6067415730337079
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8665    0.9595    0.9106    124347
           N     0.7147    0.4711    0.5679     14202
           P     0.7875    0.5195    0.6260     25017

   micro avg     0.8498    0.8498    0.8498    163566
   macro avg     0.7896    0.6500    0.7015    163566
weighted avg     0.8412    0.8498    0.8373    163566

F1-macro tok:  0.7015034815540232
F1-micro tok:  0.8498220901654379
**************************************************
dev_cost_sum: 46777.34991455078
dev_cost_avg: 42.4862397044058
dev_count_sent: 1101.0
dev_total_correct_sent: 673.0
dev_accuracy_sent: 0.6112624886466849
dev_count_tok: 21274.0
dev_total_correct_tok: 18490.0
dev_accuracy_tok: 0.8691360345962207
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6635294117647059
dev_label=N_recall_sent: 0.6588785046728972
dev_label=N_f-score_sent: 0.6611957796014069
dev_label=P_precision_sent: 0.5784023668639053
dev_label=P_recall_sent: 0.8806306306306306
dev_label=P_f-score_sent: 0.6982142857142858
dev_precision_macro_sent: 0.4139772595428704
dev_recall_macro_sent: 0.5131697117678425
dev_f-score_macro_sent: 0.4531366884385642
dev_precision_micro_sent: 0.6112624886466849
dev_recall_micro_sent: 0.6112624886466849
dev_f-score_micro_sent: 0.6112624886466849
dev_label=O_precision_tok: 0.8775897693639358
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.921376641651032
dev_label=N_precision_tok: 0.7393658159319412
dev_label=N_recall_tok: 0.5148088314485729
dev_label=N_f-score_tok: 0.606984126984127
dev_label=P_precision_tok: 0.8770491803278688
dev_label=P_recall_tok: 0.5663138231631383
dev_label=P_f-score_tok: 0.6882330684827846
dev_precision_macro_tok: 0.831334921874582
dev_recall_macro_tok: 0.6836283578727302
dev_f-score_macro_tok: 0.7388646123726478
dev_precision_micro_tok: 0.8691360345962207
dev_recall_micro_tok: 0.8691360345962207
dev_f-score_micro_tok: 0.8691360345962207
dev_time: 8.136973857879639
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6635    0.6589    0.6612       428
           P     0.5784    0.8806    0.6982       444

   micro avg     0.6113    0.6113    0.6113      1101
   macro avg     0.4140    0.5132    0.4531      1101
weighted avg     0.4912    0.6113    0.5386      1101

F1-macro sent:  0.4531366884385642
F1-micro sent:  0.6112624886466849
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8776    0.9698    0.9214     16205
           N     0.7394    0.5148    0.6070      1857
           P     0.8770    0.5663    0.6882      3212

   micro avg     0.8691    0.8691    0.8691     21274
   macro avg     0.8313    0.6836    0.7389     21274
weighted avg     0.8654    0.8691    0.8587     21274

F1-macro tok:  0.7388646123726478
F1-micro tok:  0.8691360345962207
**************************************************
Best epoch: 3
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 351276.22424316406
train_cost_avg: 41.1137902906325
train_count_sent: 8544.0
train_total_correct_sent: 5291.0
train_accuracy_sent: 0.6192649812734082
train_count_tok: 163566.0
train_total_correct_tok: 140217.0
train_accuracy_tok: 0.8572502842889109
train_label=O_precision_sent: 0.4186046511627907
train_label=O_recall_sent: 0.011083743842364532
train_label=O_f-score_sent: 0.021595680863827234
train_label=N_precision_sent: 0.5893571933129268
train_label=N_recall_sent: 0.7561933534743203
train_label=N_f-score_sent: 0.6624321820828372
train_label=P_precision_sent: 0.6511518570756935
train_label=P_recall_sent: 0.7673130193905817
train_label=P_f-score_sent: 0.7044760935910477
train_precision_macro_sent: 0.553037900517137
train_recall_macro_sent: 0.5115300389024222
train_f-score_macro_sent: 0.4628346521792374
train_precision_micro_sent: 0.6192649812734082
train_recall_micro_sent: 0.6192649812734082
train_f-score_micro_sent: 0.6192649812734082
train_label=O_precision_tok: 0.8727795536483193
train_label=O_recall_tok: 0.96174415144716
train_label=O_f-score_tok: 0.9151046987209654
train_label=N_precision_tok: 0.7193109139674025
train_label=N_recall_tok: 0.4909871849035347
train_label=N_f-score_tok: 0.5836123200535654
train_label=P_precision_tok: 0.810326409495549
train_label=P_recall_tok: 0.5457888635727706
train_label=P_f-score_tok: 0.6522559533761675
train_precision_macro_tok: 0.8008056257037569
train_recall_macro_tok: 0.6661733999744884
train_f-score_macro_tok: 0.7169909907168995
train_precision_micro_tok: 0.8572502842889109
train_recall_micro_tok: 0.8572502842889109
train_f-score_micro_tok: 0.857250284288911
train_time: 178.9592969417572
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4186    0.0111    0.0216      1624
           N     0.5894    0.7562    0.6624      3310
           P     0.6512    0.7673    0.7045      3610

   micro avg     0.6193    0.6193    0.6193      8544
   macro avg     0.5530    0.5115    0.4628      8544
weighted avg     0.5830    0.6193    0.5584      8544

F1-macro sent:  0.4628346521792374
F1-micro sent:  0.6192649812734082
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8728    0.9617    0.9151    124347
           N     0.7193    0.4910    0.5836     14202
           P     0.8103    0.5458    0.6523     25017

   micro avg     0.8573    0.8573    0.8573    163566
   macro avg     0.8008    0.6662    0.7170    163566
weighted avg     0.8499    0.8573    0.8461    163566

F1-macro tok:  0.7169909907168995
F1-micro tok:  0.857250284288911
**************************************************
dev_cost_sum: 46266.363525390625
dev_cost_avg: 42.02212854258912
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18625.0
dev_accuracy_tok: 0.8754818087806713
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5850891410048622
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.6909090909090909
dev_label=P_precision_sent: 0.6797520661157025
dev_label=P_recall_sent: 0.740990990990991
dev_label=P_f-score_sent: 0.709051724137931
dev_precision_macro_sent: 0.42161373570685495
dev_recall_macro_sent: 0.5281496449720748
dev_f-score_macro_sent: 0.466653605015674
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8805820371299549
dev_label=O_recall_tok: 0.974699166923789
dev_label=O_f-score_tok: 0.9252533536406773
dev_label=N_precision_tok: 0.7713390759592795
dev_label=N_recall_tok: 0.5304254173397954
dev_label=N_f-score_tok: 0.6285896617740907
dev_label=P_precision_tok: 0.8956310679611651
dev_label=P_recall_tok: 0.5744084682440846
dev_label=P_f-score_tok: 0.6999241274658572
dev_precision_macro_tok: 0.8491840603501332
dev_recall_macro_tok: 0.693177684169223
dev_f-score_macro_tok: 0.7512557142935418
dev_precision_micro_tok: 0.8754818087806713
dev_recall_micro_tok: 0.8754818087806713
dev_f-score_micro_tok: 0.8754818087806714
dev_time: 11.773046255111694
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5851    0.8435    0.6909       428
           P     0.6798    0.7410    0.7091       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4216    0.5281    0.4667      1101
weighted avg     0.5016    0.6267    0.5545      1101

F1-macro sent:  0.466653605015674
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9747    0.9253     16205
           N     0.7713    0.5304    0.6286      1857
           P     0.8956    0.5744    0.6999      3212

   micro avg     0.8755    0.8755    0.8755     21274
   macro avg     0.8492    0.6932    0.7513     21274
weighted avg     0.8733    0.8755    0.8653     21274

F1-macro tok:  0.7512557142935418
F1-micro tok:  0.8754818087806714
**************************************************
Best epoch: 5
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 347414.2663574219
train_cost_avg: 40.661782111121475
train_count_sent: 8544.0
train_total_correct_sent: 5339.0
train_accuracy_sent: 0.6248829588014981
train_count_tok: 163566.0
train_total_correct_tok: 141042.0
train_accuracy_tok: 0.8622941198048494
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.009732360097323601
train_label=N_precision_sent: 0.6090954274353877
train_label=N_recall_sent: 0.7404833836858006
train_label=N_f-score_sent: 0.6683937823834197
train_label=P_precision_sent: 0.64
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.7102342786683108
train_precision_macro_sent: 0.549698475811796
train_recall_macro_sent: 0.5143978085260635
train_f-score_macro_sent: 0.4627868070496847
train_precision_micro_sent: 0.6248829588014981
train_recall_micro_sent: 0.6248829588014981
train_f-score_micro_sent: 0.6248829588014981
train_label=O_precision_tok: 0.8766378660735842
train_label=O_recall_tok: 0.9636340241421184
train_label=O_f-score_tok: 0.9180796371353924
train_label=N_precision_tok: 0.733099297893681
train_label=N_recall_tok: 0.5146458245317561
train_label=N_f-score_tok: 0.6047492967069337
train_label=P_precision_tok: 0.8225205511857591
train_label=P_recall_tok: 0.5559419594675621
train_label=P_f-score_tok: 0.6634546582073176
train_precision_macro_tok: 0.8107525717176748
train_recall_macro_tok: 0.6780739360471455
train_f-score_macro_tok: 0.7287611973498813
train_precision_micro_tok: 0.8622941198048494
train_recall_micro_tok: 0.8622941198048494
train_f-score_micro_tok: 0.8622941198048494
train_time: 198.42912769317627
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0049    0.0097      1624
           N     0.6091    0.7405    0.6684      3310
           P     0.6400    0.7978    0.7102      3610

   micro avg     0.6249    0.6249    0.6249      8544
   macro avg     0.5497    0.5144    0.4628      8544
weighted avg     0.5824    0.6249    0.5609      8544

F1-macro sent:  0.4627868070496847
F1-micro sent:  0.6248829588014981
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8766    0.9636    0.9181    124347
           N     0.7331    0.5146    0.6047     14202
           P     0.8225    0.5559    0.6635     25017

   micro avg     0.8623    0.8623    0.8623    163566
   macro avg     0.8108    0.6781    0.7288    163566
weighted avg     0.8559    0.8623    0.8519    163566

F1-macro tok:  0.7287611973498813
F1-micro tok:  0.8622941198048494
**************************************************
dev_cost_sum: 46008.15490722656
dev_cost_avg: 41.787606636899696
dev_count_sent: 1101.0
dev_total_correct_sent: 684.0
dev_accuracy_sent: 0.6212534059945504
dev_count_tok: 21274.0
dev_total_correct_tok: 18666.0
dev_accuracy_tok: 0.8774090439033562
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6565874730021598
dev_label=N_recall_sent: 0.7102803738317757
dev_label=N_f-score_sent: 0.6823793490460157
dev_label=P_precision_sent: 0.5956112852664577
dev_label=P_recall_sent: 0.8558558558558559
dev_label=P_f-score_sent: 0.7024029574861369
dev_precision_macro_sent: 0.4173995860895392
dev_recall_macro_sent: 0.5220454098958772
dev_f-score_macro_sent: 0.46159410217738417
dev_precision_micro_sent: 0.6212534059945504
dev_recall_micro_sent: 0.6212534059945504
dev_f-score_micro_sent: 0.6212534059945504
dev_label=O_precision_tok: 0.8820017853157778
dev_label=O_recall_tok: 0.9755630978093182
dev_label=O_f-score_tok: 0.926426206451991
dev_label=N_precision_tok: 0.8267045454545454
dev_label=N_recall_tok: 0.4701130856219709
dev_label=N_f-score_tok: 0.5993820803295572
dev_label=P_precision_tok: 0.8648648648648649
dev_label=P_recall_tok: 0.6176836861768369
dev_label=P_f-score_tok: 0.7206683617871414
dev_precision_macro_tok: 0.8578570652117294
dev_recall_macro_tok: 0.6877866232027087
dev_f-score_macro_tok: 0.7488255495228966
dev_precision_micro_tok: 0.8774090439033562
dev_recall_micro_tok: 0.8774090439033562
dev_f-score_micro_tok: 0.8774090439033562
dev_time: 11.860312700271606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6566    0.7103    0.6824       428
           P     0.5956    0.8559    0.7024       444

   micro avg     0.6213    0.6213    0.6213      1101
   macro avg     0.4174    0.5220    0.4616      1101
weighted avg     0.4954    0.6213    0.5485      1101

F1-macro sent:  0.46159410217738417
F1-micro sent:  0.6212534059945504
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8820    0.9756    0.9264     16205
           N     0.8267    0.4701    0.5994      1857
           P     0.8649    0.6177    0.7207      3212

   micro avg     0.8774    0.8774    0.8774     21274
   macro avg     0.8579    0.6878    0.7488     21274
weighted avg     0.8746    0.8774    0.8668     21274

F1-macro tok:  0.7488255495228966
F1-micro tok:  0.8774090439033562
**************************************************
Best epoch: 5
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 343409.2692871094
train_cost_avg: 40.19303245401561
train_count_sent: 8544.0
train_total_correct_sent: 5411.0
train_accuracy_sent: 0.6333099250936329
train_count_tok: 163566.0
train_total_correct_tok: 141805.0
train_accuracy_tok: 0.8669589034395901
train_label=O_precision_sent: 0.5208333333333334
train_label=O_recall_sent: 0.01539408866995074
train_label=O_f-score_sent: 0.029904306220095697
train_label=N_precision_sent: 0.6046078659529904
train_label=N_recall_sent: 0.7848942598187311
train_label=N_f-score_sent: 0.6830550808465886
train_label=P_precision_sent: 0.6639676113360324
train_label=P_recall_sent: 0.7722991689750692
train_label=P_f-score_sent: 0.7140478934562684
train_precision_macro_sent: 0.5964696035407854
train_recall_macro_sent: 0.5241958391545837
train_f-score_macro_sent: 0.47566909350765085
train_precision_micro_sent: 0.6333099250936329
train_recall_micro_sent: 0.6333099250936329
train_f-score_micro_sent: 0.6333099250936329
train_label=O_precision_tok: 0.8803913371909675
train_label=O_recall_tok: 0.9653952246535904
train_label=O_f-score_tok: 0.9209359416954354
train_label=N_precision_tok: 0.7412831241283124
train_label=N_recall_tok: 0.5239402900999859
train_label=N_f-score_tok: 0.613943894389439
train_label=P_precision_tok: 0.8337700145560407
train_label=P_recall_tok: 0.5724107606827358
train_label=P_f-score_tok: 0.6788016685627607
train_precision_macro_tok: 0.8184814919584401
train_recall_macro_tok: 0.6872487584787708
train_f-score_macro_tok: 0.737893834882545
train_precision_micro_tok: 0.8669589034395901
train_recall_micro_tok: 0.8669589034395901
train_f-score_micro_tok: 0.8669589034395901
train_time: 198.1818630695343
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5208    0.0154    0.0299      1624
           N     0.6046    0.7849    0.6831      3310
           P     0.6640    0.7723    0.7140      3610

   micro avg     0.6333    0.6333    0.6333      8544
   macro avg     0.5965    0.5242    0.4757      8544
weighted avg     0.6138    0.6333    0.5720      8544

F1-macro sent:  0.47566909350765085
F1-micro sent:  0.6333099250936329
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9654    0.9209    124347
           N     0.7413    0.5239    0.6139     14202
           P     0.8338    0.5724    0.6788     25017

   micro avg     0.8670    0.8670    0.8670    163566
   macro avg     0.8185    0.6872    0.7379    163566
weighted avg     0.8612    0.8670    0.8572    163566

F1-macro tok:  0.737893834882545
F1-micro tok:  0.8669589034395901
**************************************************
dev_cost_sum: 45463.42565917969
dev_cost_avg: 41.292848010154124
dev_count_sent: 1101.0
dev_total_correct_sent: 690.0
dev_accuracy_sent: 0.6267029972752044
dev_count_tok: 21274.0
dev_total_correct_tok: 18778.0
dev_accuracy_tok: 0.8826736861897151
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5680473372781065
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.6956521739130435
dev_label=P_precision_sent: 0.72
dev_label=P_recall_sent: 0.6891891891891891
dev_label=P_f-score_sent: 0.7042577675489067
dev_precision_macro_sent: 0.4293491124260355
dev_recall_macro_sent: 0.5287951502904774
dev_f-score_macro_sent: 0.4666366471539834
dev_precision_micro_sent: 0.6267029972752044
dev_recall_micro_sent: 0.6267029972752044
dev_f-score_micro_sent: 0.6267029972752044
dev_label=O_precision_tok: 0.8891202791692464
dev_label=O_recall_tok: 0.9748225856217216
dev_label=O_f-score_tok: 0.9300011774402449
dev_label=N_precision_tok: 0.7674074074074074
dev_label=N_recall_tok: 0.5578890683898762
dev_label=N_f-score_tok: 0.6460866853757407
dev_label=P_precision_tok: 0.9017153453871117
dev_label=P_recall_tok: 0.6055417185554172
dev_label=P_f-score_tok: 0.724529707580555
dev_precision_macro_tok: 0.8527476773212551
dev_recall_macro_tok: 0.7127511241890049
dev_f-score_macro_tok: 0.7668725234655135
dev_precision_micro_tok: 0.8826736861897151
dev_recall_micro_tok: 0.8826736861897151
dev_f-score_micro_tok: 0.8826736861897151
dev_time: 11.911860227584839
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5680    0.8972    0.6957       428
           P     0.7200    0.6892    0.7043       444

   micro avg     0.6267    0.6267    0.6267      1101
   macro avg     0.4293    0.5288    0.4666      1101
weighted avg     0.5112    0.6267    0.5544      1101

F1-macro sent:  0.4666366471539834
F1-micro sent:  0.6267029972752044
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8891    0.9748    0.9300     16205
           N     0.7674    0.5579    0.6461      1857
           P     0.9017    0.6055    0.7245      3212

   micro avg     0.8827    0.8827    0.8827     21274
   macro avg     0.8527    0.7128    0.7669     21274
weighted avg     0.8804    0.8827    0.8742     21274

F1-macro tok:  0.7668725234655135
F1-micro tok:  0.8826736861897151
**************************************************
Best epoch: 5
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 340164.43688964844
train_cost_avg: 39.813253381279075
train_count_sent: 8544.0
train_total_correct_sent: 5332.0
train_accuracy_sent: 0.6240636704119851
train_count_tok: 163566.0
train_total_correct_tok: 142377.0
train_accuracy_tok: 0.8704559627306409
train_label=O_precision_sent: 0.2807017543859649
train_label=O_recall_sent: 0.009852216748768473
train_label=O_f-score_sent: 0.01903628792385485
train_label=N_precision_sent: 0.5917366946778712
train_label=N_recall_sent: 0.7658610271903323
train_label=N_f-score_sent: 0.6676323413220964
train_label=P_precision_sent: 0.6616702355460385
train_label=P_recall_sent: 0.7703601108033241
train_label=P_f-score_sent: 0.7118904390119032
train_precision_macro_sent: 0.5113695615366248
train_recall_macro_sent: 0.5153577849141416
train_f-score_macro_sent: 0.46618635608595144
train_precision_micro_sent: 0.6240636704119851
train_recall_micro_sent: 0.6240636704119851
train_f-score_micro_sent: 0.6240636704119851
train_label=O_precision_tok: 0.8825929649716353
train_label=O_recall_tok: 0.9671564251650623
train_label=O_f-score_tok: 0.9229417362475442
train_label=N_precision_tok: 0.7476148323005803
train_label=N_recall_tok: 0.5352063089705675
train_label=N_f-score_tok: 0.6238253518814888
train_label=P_precision_tok: 0.8468316022873147
train_label=P_recall_tok: 0.5801255146500379
train_label=P_f-score_tok: 0.6885541454157277
train_precision_macro_tok: 0.8256797998531767
train_recall_macro_tok: 0.6941627495952226
train_f-score_macro_tok: 0.7451070778482536
train_precision_micro_tok: 0.8704559627306409
train_recall_micro_tok: 0.8704559627306409
train_f-score_micro_tok: 0.8704559627306409
train_time: 179.51559019088745
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2807    0.0099    0.0190      1624
           N     0.5917    0.7659    0.6676      3310
           P     0.6617    0.7704    0.7119      3610

   micro avg     0.6241    0.6241    0.6241      8544
   macro avg     0.5114    0.5154    0.4662      8544
weighted avg     0.5622    0.6241    0.5631      8544

F1-macro sent:  0.46618635608595144
F1-micro sent:  0.6240636704119851
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8826    0.9672    0.9229    124347
           N     0.7476    0.5352    0.6238     14202
           P     0.8468    0.5801    0.6886     25017

   micro avg     0.8705    0.8705    0.8705    163566
   macro avg     0.8257    0.6942    0.7451    163566
weighted avg     0.8654    0.8705    0.8611    163566

F1-macro tok:  0.7451070778482536
F1-micro tok:  0.8704559627306409
**************************************************
dev_cost_sum: 45178.549560546875
dev_cost_avg: 41.03410495962477
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18809.0
dev_accuracy_tok: 0.8841308639654037
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025751072961373387
dev_label=N_precision_sent: 0.5864197530864198
dev_label=N_recall_sent: 0.8878504672897196
dev_label=N_f-score_sent: 0.7063197026022306
dev_label=P_precision_sent: 0.7126948775055679
dev_label=P_recall_sent: 0.7207207207207207
dev_label=P_f-score_sent: 0.7166853303471444
dev_precision_macro_sent: 0.6830382101973292
dev_recall_macro_sent: 0.5405572082305543
dev_f-score_macro_sent: 0.4829187019702495
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.8879237881759596
dev_label=O_recall_tok: 0.9777846343721074
dev_label=O_f-score_tok: 0.930690161527166
dev_label=N_precision_tok: 0.7795216741405082
dev_label=N_recall_tok: 0.5616585891222402
dev_label=N_f-score_tok: 0.6528951486697966
dev_label=P_precision_tok: 0.9186991869918699
dev_label=P_recall_tok: 0.5980697384806973
dev_label=P_f-score_tok: 0.7244955685461059
dev_precision_macro_tok: 0.8620482164361126
dev_recall_macro_tok: 0.7125043206583483
dev_f-score_macro_tok: 0.7693602929143561
dev_precision_micro_tok: 0.8841308639654037
dev_recall_micro_tok: 0.8841308639654037
dev_f-score_micro_tok: 0.8841308639654037
dev_time: 8.277488946914673
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0131    0.0258       229
           N     0.5864    0.8879    0.7063       428
           P     0.7127    0.7207    0.7167       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.6830    0.5406    0.4829      1101
weighted avg     0.6714    0.6385    0.5689      1101

F1-macro sent:  0.4829187019702495
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8879    0.9778    0.9307     16205
           N     0.7795    0.5617    0.6529      1857
           P     0.9187    0.5981    0.7245      3212

   micro avg     0.8841    0.8841    0.8841     21274
   macro avg     0.8620    0.7125    0.7694     21274
weighted avg     0.8831    0.8841    0.8753     21274

F1-macro tok:  0.7693602929143561
F1-micro tok:  0.8841308639654037
**************************************************
Best epoch: 8
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 337059.28302001953
train_cost_avg: 39.449822450844984
train_count_sent: 8544.0
train_total_correct_sent: 5435.0
train_accuracy_sent: 0.6361189138576779
train_count_tok: 163566.0
train_total_correct_tok: 142806.0
train_accuracy_tok: 0.8730787571989289
train_label=O_precision_sent: 0.425
train_label=O_recall_sent: 0.020935960591133004
train_label=O_f-score_sent: 0.03990610328638498
train_label=N_precision_sent: 0.6048215551878988
train_label=N_recall_sent: 0.7731117824773414
train_label=N_f-score_sent: 0.6786898289351544
train_label=P_precision_sent: 0.6713914481455233
train_label=P_recall_sent: 0.7872576177285319
train_label=P_f-score_sent: 0.7247226826469463
train_precision_macro_sent: 0.5670710011111407
train_recall_macro_sent: 0.5271017869323354
train_f-score_macro_sent: 0.48110620495616185
train_precision_micro_sent: 0.6361189138576779
train_recall_micro_sent: 0.6361189138576779
train_f-score_micro_sent: 0.6361189138576779
train_label=O_precision_tok: 0.8846724877991415
train_label=O_recall_tok: 0.9679767103347889
train_label=O_f-score_tok: 0.924451715226015
train_label=N_precision_tok: 0.7570230198985564
train_label=N_recall_tok: 0.5464723278411492
train_label=N_f-score_tok: 0.634742782366893
train_label=P_precision_tok: 0.8506200023177657
train_label=P_recall_tok: 0.586800975336771
train_label=P_f-score_tok: 0.6945002956830277
train_precision_macro_tok: 0.8307718366718212
train_recall_macro_tok: 0.700416671170903
train_f-score_macro_tok: 0.7512315977586453
train_precision_micro_tok: 0.8730787571989289
train_recall_micro_tok: 0.8730787571989289
train_f-score_micro_tok: 0.8730787571989289
train_time: 145.419780254364
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4250    0.0209    0.0399      1624
           N     0.6048    0.7731    0.6787      3310
           P     0.6714    0.7873    0.7247      3610

   micro avg     0.6361    0.6361    0.6361      8544
   macro avg     0.5671    0.5271    0.4811      8544
weighted avg     0.5988    0.6361    0.5767      8544

F1-macro sent:  0.48110620495616185
F1-micro sent:  0.6361189138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8847    0.9680    0.9245    124347
           N     0.7570    0.5465    0.6347     14202
           P     0.8506    0.5868    0.6945     25017

   micro avg     0.8731    0.8731    0.8731    163566
   macro avg     0.8308    0.7004    0.7512    163566
weighted avg     0.8684    0.8731    0.8641    163566

F1-macro tok:  0.7512315977586453
F1-micro tok:  0.8730787571989289
**************************************************
dev_cost_sum: 44945.885192871094
dev_cost_avg: 40.822784008057305
dev_count_sent: 1101.0
dev_total_correct_sent: 692.0
dev_accuracy_sent: 0.628519527702089
dev_count_tok: 21274.0
dev_total_correct_tok: 18787.0
dev_accuracy_tok: 0.8830967378020118
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.5569620253164557
dev_label=N_recall_sent: 0.9252336448598131
dev_label=N_f-score_sent: 0.6953467954345918
dev_label=P_precision_sent: 0.7603092783505154
dev_label=P_recall_sent: 0.6644144144144144
dev_label=P_f-score_sent: 0.7091346153846154
dev_precision_macro_sent: 0.6057571012223236
dev_recall_macro_sent: 0.5313382905004339
dev_f-score_macro_sent: 0.47104647315907194
dev_precision_micro_sent: 0.628519527702089
dev_recall_micro_sent: 0.628519527702089
dev_f-score_micro_sent: 0.628519527702089
dev_label=O_precision_tok: 0.8804479752841222
dev_label=O_recall_tok: 0.9848195001542733
dev_label=O_f-score_tok: 0.9297136698610585
dev_label=N_precision_tok: 0.8254799301919721
dev_label=N_recall_tok: 0.5094238018309101
dev_label=N_f-score_tok: 0.6300366300366301
dev_label=P_precision_tok: 0.9400599400599401
dev_label=P_recall_tok: 0.5859277708592777
dev_label=P_f-score_tok: 0.7219025700038358
dev_precision_macro_tok: 0.8819959485120115
dev_recall_macro_tok: 0.6933903576148204
dev_f-score_macro_tok: 0.7605509566338414
dev_precision_micro_tok: 0.8830967378020118
dev_recall_micro_tok: 0.8830967378020118
dev_f-score_micro_tok: 0.8830967378020118
dev_time: 8.436851978302002
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.5570    0.9252    0.6953       428
           P     0.7603    0.6644    0.7091       444

   micro avg     0.6285    0.6285    0.6285      1101
   macro avg     0.6058    0.5313    0.4710      1101
weighted avg     0.6271    0.6285    0.5581      1101

F1-macro sent:  0.47104647315907194
F1-micro sent:  0.628519527702089
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8804    0.9848    0.9297     16205
           N     0.8255    0.5094    0.6300      1857
           P     0.9401    0.5859    0.7219      3212

   micro avg     0.8831    0.8831    0.8831     21274
   macro avg     0.8820    0.6934    0.7606     21274
weighted avg     0.8847    0.8831    0.8722     21274

F1-macro tok:  0.7605509566338414
F1-micro tok:  0.8830967378020118
**************************************************
Best epoch: 8
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 333939.06927490234
train_cost_avg: 39.08462889453445
train_count_sent: 8544.0
train_total_correct_sent: 5438.0
train_accuracy_sent: 0.6364700374531835
train_count_tok: 163566.0
train_total_correct_tok: 143361.0
train_accuracy_tok: 0.8764718829096512
train_label=O_precision_sent: 0.3178294573643411
train_label=O_recall_sent: 0.025246305418719212
train_label=O_f-score_sent: 0.04677695379349686
train_label=N_precision_sent: 0.6107015457788347
train_label=N_recall_sent: 0.7758308157099698
train_label=N_f-score_sent: 0.6834331337325349
train_label=P_precision_sent: 0.6719714964370547
train_label=P_recall_sent: 0.7836565096952909
train_label=P_f-score_sent: 0.7235294117647059
train_precision_macro_sent: 0.5335008331934102
train_recall_macro_sent: 0.5282445436079933
train_f-score_macro_sent: 0.4845798330969126
train_precision_micro_sent: 0.6364700374531835
train_recall_micro_sent: 0.6364700374531835
train_f-score_micro_sent: 0.6364700374531835
train_label=O_precision_tok: 0.887743000051565
train_label=O_recall_tok: 0.9691588860205714
train_label=O_f-score_tok: 0.9266661027766457
train_label=N_precision_tok: 0.7601536245799327
train_label=N_recall_tok: 0.5574566962399662
train_label=N_f-score_tok: 0.6432140390786855
train_label=P_precision_tok: 0.8581609195402299
train_label=P_recall_tok: 0.5968741255945956
train_label=P_f-score_tok: 0.704057335502275
train_precision_macro_tok: 0.8353525147239093
train_recall_macro_tok: 0.7078299026183777
train_f-score_macro_tok: 0.757979159119202
train_precision_micro_tok: 0.8764718829096512
train_recall_micro_tok: 0.8764718829096512
train_f-score_micro_tok: 0.8764718829096512
train_time: 145.07482409477234
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3178    0.0252    0.0468      1624
           N     0.6107    0.7758    0.6834      3310
           P     0.6720    0.7837    0.7235      3610

   micro avg     0.6365    0.6365    0.6365      8544
   macro avg     0.5335    0.5282    0.4846      8544
weighted avg     0.5809    0.6365    0.5794      8544

F1-macro sent:  0.4845798330969126
F1-micro sent:  0.6364700374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8877    0.9692    0.9267    124347
           N     0.7602    0.5575    0.6432     14202
           P     0.8582    0.5969    0.7041     25017

   micro avg     0.8765    0.8765    0.8765    163566
   macro avg     0.8354    0.7078    0.7580    163566
weighted avg     0.8721    0.8765    0.8680    163566

F1-macro tok:  0.757979159119202
F1-micro tok:  0.8764718829096512
**************************************************
dev_cost_sum: 44526.78369140625
dev_cost_avg: 40.44212869337534
dev_count_sent: 1101.0
dev_total_correct_sent: 703.0
dev_accuracy_sent: 0.6385104450499546
dev_count_tok: 21274.0
dev_total_correct_tok: 18932.0
dev_accuracy_tok: 0.8899125693334586
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.6382978723404256
dev_label=N_recall_sent: 0.7710280373831776
dev_label=N_f-score_sent: 0.6984126984126985
dev_label=P_precision_sent: 0.6385542168674698
dev_label=P_recall_sent: 0.8355855855855856
dev_label=P_f-score_sent: 0.7239024390243903
dev_precision_macro_sent: 0.6478395852915207
dev_recall_macro_sent: 0.5384490824743039
dev_f-score_macro_sent: 0.4798521722491446
dev_precision_micro_sent: 0.6385104450499546
dev_recall_micro_sent: 0.6385104450499546
dev_f-score_micro_sent: 0.6385104450499546
dev_label=O_precision_tok: 0.891175151379233
dev_label=O_recall_tok: 0.9808701018204258
dev_label=O_f-score_tok: 0.9338738579947711
dev_label=N_precision_tok: 0.8144
dev_label=N_recall_tok: 0.5481960150780829
dev_label=N_f-score_tok: 0.6552944962986804
dev_label=P_precision_tok: 0.9227605118829981
dev_label=P_recall_tok: 0.6285803237858032
dev_label=P_f-score_tok: 0.7477777777777777
dev_precision_macro_tok: 0.8761118877540771
dev_recall_macro_tok: 0.719215480228104
dev_f-score_macro_tok: 0.7789820440237429
dev_precision_micro_tok: 0.8899125693334586
dev_recall_micro_tok: 0.8899125693334586
dev_f-score_micro_tok: 0.8899125693334586
dev_time: 8.503380298614502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.6383    0.7710    0.6984       428
           P     0.6386    0.8356    0.7239       444

   micro avg     0.6385    0.6385    0.6385      1101
   macro avg     0.6478    0.5384    0.4799      1101
weighted avg     0.6443    0.6385    0.5670      1101

F1-macro sent:  0.4798521722491446
F1-micro sent:  0.6385104450499546
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8912    0.9809    0.9339     16205
           N     0.8144    0.5482    0.6553      1857
           P     0.9228    0.6286    0.7478      3212

   micro avg     0.8899    0.8899    0.8899     21274
   macro avg     0.8761    0.7192    0.7790     21274
weighted avg     0.8892    0.8899    0.8815     21274

F1-macro tok:  0.7789820440237429
F1-micro tok:  0.8899125693334586
**************************************************
Best epoch: 8
**************************************************

EPOCH: 11
Learning rate: 1.000000
train_cost_sum: 331580.4783935547
train_cost_avg: 38.80857659100593
train_count_sent: 8544.0
train_total_correct_sent: 5505.0
train_accuracy_sent: 0.644311797752809
train_count_tok: 163566.0
train_total_correct_tok: 143694.0
train_accuracy_tok: 0.8785077583360845
train_label=O_precision_sent: 0.46601941747572817
train_label=O_recall_sent: 0.029556650246305417
train_label=O_f-score_sent: 0.05558772437753329
train_label=N_precision_sent: 0.609919261822376
train_label=N_recall_sent: 0.7987915407854985
train_label=N_f-score_sent: 0.6916939175931982
train_label=P_precision_sent: 0.6850949829517778
train_label=P_recall_sent: 0.779224376731302
train_label=P_f-score_sent: 0.7291342664593053
train_precision_macro_sent: 0.5870112207499607
train_recall_macro_sent: 0.5358575225877019
train_f-score_macro_sent: 0.4921386361433456
train_precision_micro_sent: 0.644311797752809
train_recall_micro_sent: 0.644311797752809
train_f-score_micro_sent: 0.644311797752809
train_label=O_precision_tok: 0.8894190351174761
train_label=O_recall_tok: 0.9699228771100228
train_label=O_f-score_tok: 0.9279281705257569
train_label=N_precision_tok: 0.7643979057591623
train_label=N_recall_tok: 0.5654133220673144
train_label=N_f-score_tok: 0.650018213461772
train_label=P_precision_tok: 0.8624205280943926
train_label=P_recall_tok: 0.6018707279050246
train_label=P_f-score_tok: 0.7089650626235993
train_precision_macro_tok: 0.8387458229903437
train_recall_macro_tok: 0.7124023090274539
train_f-score_macro_tok: 0.7623038155370429
train_precision_micro_tok: 0.8785077583360845
train_recall_micro_tok: 0.8785077583360845
train_f-score_micro_tok: 0.8785077583360845
train_time: 145.86456489562988
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4660    0.0296    0.0556      1624
           N     0.6099    0.7988    0.6917      3310
           P     0.6851    0.7792    0.7291      3610

   micro avg     0.6443    0.6443    0.6443      8544
   macro avg     0.5870    0.5359    0.4921      8544
weighted avg     0.6143    0.6443    0.5866      8544

F1-macro sent:  0.4921386361433456
F1-micro sent:  0.644311797752809
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8894    0.9699    0.9279    124347
           N     0.7644    0.5654    0.6500     14202
           P     0.8624    0.6019    0.7090     25017

   micro avg     0.8785    0.8785    0.8785    163566
   macro avg     0.8387    0.7124    0.7623    163566
weighted avg     0.8744    0.8785    0.8703    163566

F1-macro tok:  0.7623038155370429
F1-micro tok:  0.8785077583360845
**************************************************
dev_cost_sum: 44195.60559082031
dev_cost_avg: 40.14133114515923
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18942.0
dev_accuracy_tok: 0.890382626680455
dev_label=O_precision_sent: 0.6
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.025641025641025637
dev_label=N_precision_sent: 0.5915492957746479
dev_label=N_recall_sent: 0.883177570093458
dev_label=N_f-score_sent: 0.7085285848172446
dev_label=P_precision_sent: 0.7067833698030634
dev_label=P_recall_sent: 0.7274774774774775
dev_label=P_f-score_sent: 0.7169811320754716
dev_precision_macro_sent: 0.6327775551925704
dev_recall_macro_sent: 0.5412518280840527
dev_f-score_macro_sent: 0.4837169141779139
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.8924278170992024
dev_label=O_recall_tok: 0.9803764270286949
dev_label=O_f-score_tok: 0.9343370482547712
dev_label=N_precision_tok: 0.7862815884476534
dev_label=N_recall_tok: 0.5864297253634895
dev_label=N_f-score_tok: 0.6718075262183837
dev_label=P_precision_tok: 0.9420220412074748
dev_label=P_recall_tok: 0.612079701120797
dev_label=P_f-score_tok: 0.7420267975089639
dev_precision_macro_tok: 0.8735771489181102
dev_recall_macro_tok: 0.7262952845043271
dev_f-score_macro_tok: 0.7827237906607062
dev_precision_micro_tok: 0.890382626680455
dev_recall_micro_tok: 0.890382626680455
dev_f-score_micro_tok: 0.890382626680455
dev_time: 8.304231405258179
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6000    0.0131    0.0256       229
           N     0.5915    0.8832    0.7085       428
           P     0.7068    0.7275    0.7170       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.6328    0.5413    0.4837      1101
weighted avg     0.6398    0.6394    0.5699      1101

F1-macro sent:  0.4837169141779139
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8924    0.9804    0.9343     16205
           N     0.7863    0.5864    0.6718      1857
           P     0.9420    0.6121    0.7420      3212

   micro avg     0.8904    0.8904    0.8904     21274
   macro avg     0.8736    0.7263    0.7827     21274
weighted avg     0.8907    0.8904    0.8824     21274

F1-macro tok:  0.7827237906607062
F1-micro tok:  0.890382626680455
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 1.000000
train_cost_sum: 328989.50762939453
train_cost_avg: 38.505326267485316
train_count_sent: 8544.0
train_total_correct_sent: 5538.0
train_accuracy_sent: 0.6481741573033708
train_count_tok: 163566.0
train_total_correct_tok: 143992.0
train_accuracy_tok: 0.8803296528618417
train_label=O_precision_sent: 0.45045045045045046
train_label=O_recall_sent: 0.03078817733990148
train_label=O_f-score_sent: 0.05763688760806917
train_label=N_precision_sent: 0.6223776223776224
train_label=N_recall_sent: 0.7797583081570997
train_label=N_f-score_sent: 0.69223548343838
train_label=P_precision_sent: 0.6782547830144657
train_label=P_recall_sent: 0.8052631578947368
train_label=P_f-score_sent: 0.736322188449848
train_precision_macro_sent: 0.5836942852808461
train_recall_macro_sent: 0.5386032144639127
train_f-score_macro_sent: 0.4953981864987657
train_precision_micro_sent: 0.6481741573033708
train_recall_micro_sent: 0.6481741573033708
train_f-score_micro_sent: 0.6481741573033708
train_label=O_precision_tok: 0.8911528942410698
train_label=O_recall_tok: 0.9700435072820414
train_label=O_f-score_tok: 0.9289262308338018
train_label=N_precision_tok: 0.7696639759714661
train_label=N_recall_tok: 0.5773834671173074
train_label=N_f-score_tok: 0.6598004505954296
train_label=P_precision_tok: 0.8640428319188928
train_label=P_recall_tok: 0.6063876563936523
train_label=P_f-score_tok: 0.7126415182975526
train_precision_macro_tok: 0.8416199007104762
train_recall_macro_tok: 0.7179382102643337
train_f-score_macro_tok: 0.7671227332422613
train_precision_micro_tok: 0.8803296528618417
train_recall_micro_tok: 0.8803296528618417
train_f-score_micro_tok: 0.8803296528618416
train_time: 146.2890384197235
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4505    0.0308    0.0576      1624
           N     0.6224    0.7798    0.6922      3310
           P     0.6783    0.8053    0.7363      3610

   micro avg     0.6482    0.6482    0.6482      8544
   macro avg     0.5837    0.5386    0.4954      8544
weighted avg     0.6133    0.6482    0.5902      8544

F1-macro sent:  0.4953981864987657
F1-micro sent:  0.6481741573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8912    0.9700    0.9289    124347
           N     0.7697    0.5774    0.6598     14202
           P     0.8640    0.6064    0.7126     25017

   micro avg     0.8803    0.8803    0.8803    163566
   macro avg     0.8416    0.7179    0.7671    163566
weighted avg     0.8765    0.8803    0.8725    163566

F1-macro tok:  0.7671227332422613
F1-micro tok:  0.8803296528618416
**************************************************
dev_cost_sum: 43943.503356933594
dev_cost_avg: 39.91235545588882
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 18969.0
dev_accuracy_tok: 0.8916517815173451
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09599999999999999
dev_label=N_precision_sent: 0.6680584551148225
dev_label=N_recall_sent: 0.7476635514018691
dev_label=N_f-score_sent: 0.7056229327453142
dev_label=P_precision_sent: 0.6339434276206323
dev_label=P_recall_sent: 0.8581081081081081
dev_label=P_f-score_sent: 0.7291866028708134
dev_precision_macro_sent: 0.6244768180546755
dev_recall_macro_sent: 0.5527244687449561
dev_f-score_macro_sent: 0.5102698452053759
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.8943423870167925
dev_label=O_recall_tok: 0.979389077445233
dev_label=O_f-score_tok: 0.9349356425436658
dev_label=N_precision_tok: 0.8330550918196995
dev_label=N_recall_tok: 0.5374259558427571
dev_label=N_f-score_tok: 0.6533551554828151
dev_label=P_precision_tok: 0.9012875536480687
dev_label=P_recall_tok: 0.6537982565379825
dev_label=P_f-score_tok: 0.7578491519307109
dev_precision_macro_tok: 0.8762283441615203
dev_recall_macro_tok: 0.7235377632753242
dev_f-score_macro_tok: 0.7820466499857307
dev_precision_micro_tok: 0.8916517815173451
dev_recall_micro_tok: 0.8916517815173451
dev_f-score_micro_tok: 0.8916517815173451
dev_time: 8.385348081588745
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0524    0.0960       229
           N     0.6681    0.7477    0.7056       428
           P     0.6339    0.8581    0.7292       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.6245    0.5527    0.5103      1101
weighted avg     0.6342    0.6476    0.5883      1101

F1-macro sent:  0.5102698452053759
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8943    0.9794    0.9349     16205
           N     0.8331    0.5374    0.6534      1857
           P     0.9013    0.6538    0.7578      3212

   micro avg     0.8917    0.8917    0.8917     21274
   macro avg     0.8762    0.7235    0.7820     21274
weighted avg     0.8900    0.8917    0.8836     21274

F1-macro tok:  0.7820466499857307
F1-micro tok:  0.8916517815173451
**************************************************
Best epoch: 12
**************************************************

EPOCH: 13
Learning rate: 1.000000
train_cost_sum: 326608.9041748047
train_cost_avg: 38.22669758600242
train_count_sent: 8544.0
train_total_correct_sent: 5581.0
train_accuracy_sent: 0.6532069288389513
train_count_tok: 163566.0
train_total_correct_tok: 144427.0
train_accuracy_tok: 0.8829891297702457
train_label=O_precision_sent: 0.37872340425531914
train_label=O_recall_sent: 0.05480295566502463
train_label=O_f-score_sent: 0.09575040344271114
train_label=N_precision_sent: 0.6248517903723025
train_label=N_recall_sent: 0.7960725075528701
train_label=N_f-score_sent: 0.7001461405606483
train_label=P_precision_sent: 0.6981915933528837
train_label=P_recall_sent: 0.7914127423822714
train_label=P_f-score_sent: 0.7418852246169827
train_precision_macro_sent: 0.5672555959935018
train_recall_macro_sent: 0.5474294018667221
train_f-score_macro_sent: 0.5125939228734474
train_precision_micro_sent: 0.6532069288389513
train_recall_micro_sent: 0.6532069288389513
train_f-score_micro_sent: 0.6532069288389513
train_label=O_precision_tok: 0.8935100514605161
train_label=O_recall_tok: 0.9704536498669047
train_label=O_f-score_tok: 0.9303937517829469
train_label=N_precision_tok: 0.7773503471570651
train_label=N_recall_tok: 0.583368539642304
train_label=N_f-score_tok: 0.666532582461786
train_label=P_precision_tok: 0.8664650198846132
train_label=P_recall_tok: 0.6183395291201983
train_label=P_f-score_tok: 0.7216701656169817
train_precision_macro_tok: 0.8457751395007315
train_recall_macro_tok: 0.7240539062098023
train_f-score_macro_tok: 0.772865499953905
train_precision_micro_tok: 0.8829891297702457
train_recall_micro_tok: 0.8829891297702457
train_f-score_micro_tok: 0.8829891297702457
train_time: 146.1150724887848
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3787    0.0548    0.0958      1624
           N     0.6249    0.7961    0.7001      3310
           P     0.6982    0.7914    0.7419      3610

   micro avg     0.6532    0.6532    0.6532      8544
   macro avg     0.5673    0.5474    0.5126      8544
weighted avg     0.6091    0.6532    0.6029      8544

F1-macro sent:  0.5125939228734474
F1-micro sent:  0.6532069288389513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9705    0.9304    124347
           N     0.7774    0.5834    0.6665     14202
           P     0.8665    0.6183    0.7217     25017

   micro avg     0.8830    0.8830    0.8830    163566
   macro avg     0.8458    0.7241    0.7729    163566
weighted avg     0.8793    0.8830    0.8756    163566

F1-macro tok:  0.772865499953905
F1-micro tok:  0.8829891297702457
**************************************************
dev_cost_sum: 43764.16003417969
dev_cost_avg: 39.74946415456829
dev_count_sent: 1101.0
dev_total_correct_sent: 707.0
dev_accuracy_sent: 0.6421435059037239
dev_count_tok: 21274.0
dev_total_correct_tok: 19021.0
dev_accuracy_tok: 0.894096079721726
dev_label=O_precision_sent: 1.0
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02586206896551724
dev_label=N_precision_sent: 0.627906976744186
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7112462006079028
dev_label=P_precision_sent: 0.6549165120593692
dev_label=P_recall_sent: 0.795045045045045
dev_label=P_f-score_sent: 0.7182095625635808
dev_precision_macro_sent: 0.7609411629345185
dev_recall_macro_sent: 0.5427463132233976
dev_f-score_macro_sent: 0.4851059440456669
dev_precision_micro_sent: 0.6421435059037239
dev_recall_micro_sent: 0.6421435059037239
dev_f-score_micro_sent: 0.6421435059037239
dev_label=O_precision_tok: 0.8984454782707364
dev_label=O_recall_tok: 0.97722925023141
dev_label=O_f-score_tok: 0.9361827909313943
dev_label=N_precision_tok: 0.8104477611940298
dev_label=N_recall_tok: 0.5848142164781907
dev_label=N_f-score_tok: 0.6793869252424147
dev_label=P_precision_tok: 0.9094454072790294
dev_label=P_recall_tok: 0.6534869240348692
dev_label=P_f-score_tok: 0.7605072463768117
dev_precision_macro_tok: 0.8727795489145986
dev_recall_macro_tok: 0.7385101302481566
dev_f-score_macro_tok: 0.7920256541835403
dev_precision_micro_tok: 0.894096079721726
dev_recall_micro_tok: 0.894096079721726
dev_f-score_micro_tok: 0.894096079721726
dev_time: 8.43639087677002
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0131    0.0259       229
           N     0.6279    0.8201    0.7112       428
           P     0.6549    0.7950    0.7182       444

   micro avg     0.6421    0.6421    0.6421      1101
   macro avg     0.7609    0.5427    0.4851      1101
weighted avg     0.7162    0.6421    0.5715      1101

F1-macro sent:  0.4851059440456669
F1-micro sent:  0.6421435059037239
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8984    0.9772    0.9362     16205
           N     0.8104    0.5848    0.6794      1857
           P     0.9094    0.6535    0.7605      3212

   micro avg     0.8941    0.8941    0.8941     21274
   macro avg     0.8728    0.7385    0.7920     21274
weighted avg     0.8924    0.8941    0.8872     21274

F1-macro tok:  0.7920256541835403
F1-micro tok:  0.894096079721726
**************************************************
Best epoch: 12
**************************************************

EPOCH: 14
Learning rate: 1.000000
train_cost_sum: 324499.2305908203
train_cost_avg: 37.97977886128515
train_count_sent: 8544.0
train_total_correct_sent: 5582.0
train_accuracy_sent: 0.6533239700374532
train_count_tok: 163566.0
train_total_correct_tok: 144711.0
train_accuracy_tok: 0.8847254319357324
train_label=O_precision_sent: 0.4146341463414634
train_label=O_recall_sent: 0.03140394088669951
train_label=O_f-score_sent: 0.05838580423583287
train_label=N_precision_sent: 0.6238488783943329
train_label=N_recall_sent: 0.7981873111782477
train_label=N_f-score_sent: 0.7003313452617628
train_label=P_precision_sent: 0.690157668418538
train_label=P_recall_sent: 0.8002770083102493
train_label=P_f-score_sent: 0.7411493073370959
train_precision_macro_sent: 0.5762135643847781
train_recall_macro_sent: 0.5432894201250655
train_f-score_macro_sent: 0.49995548561156383
train_precision_micro_sent: 0.6533239700374532
train_recall_micro_sent: 0.6533239700374532
train_f-score_micro_sent: 0.6533239700374532
train_label=O_precision_tok: 0.8950507962149225
train_label=O_recall_tok: 0.9713784811857141
train_label=O_f-score_tok: 0.9316539271417442
train_label=N_precision_tok: 0.7784218399401646
train_label=N_recall_tok: 0.5862554569778904
train_label=N_f-score_tok: 0.6688087396578039
train_label=P_precision_tok: 0.8704168759417378
train_label=P_recall_tok: 0.6234560498860775
train_label=P_f-score_tok: 0.7265231973169368
train_precision_macro_tok: 0.8479631706989417
train_recall_macro_tok: 0.7270299960165607
train_f-score_macro_tok: 0.7756619547054949
train_precision_micro_tok: 0.8847254319357324
train_recall_micro_tok: 0.8847254319357324
train_f-score_micro_tok: 0.8847254319357324
train_time: 145.01271963119507
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4146    0.0314    0.0584      1624
           N     0.6238    0.7982    0.7003      3310
           P     0.6902    0.8003    0.7411      3610

   micro avg     0.6533    0.6533    0.6533      8544
   macro avg     0.5762    0.5433    0.5000      8544
weighted avg     0.6121    0.6533    0.5956      8544

F1-macro sent:  0.49995548561156383
F1-micro sent:  0.6533239700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8951    0.9714    0.9317    124347
           N     0.7784    0.5863    0.6688     14202
           P     0.8704    0.6235    0.7265     25017

   micro avg     0.8847    0.8847    0.8847    163566
   macro avg     0.8480    0.7270    0.7757    163566
weighted avg     0.8812    0.8847    0.8775    163566

F1-macro tok:  0.7756619547054949
F1-micro tok:  0.8847254319357324
**************************************************
dev_cost_sum: 43513.525939941406
dev_cost_avg: 39.521821925469034
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19012.0
dev_accuracy_tok: 0.8936730281094294
dev_label=O_precision_sent: 0.5555555555555556
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.08097165991902834
dev_label=N_precision_sent: 0.6282722513089005
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7192807192807192
dev_label=P_precision_sent: 0.6803921568627451
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7274633123689727
dev_precision_macro_sent: 0.6214066545757337
dev_recall_macro_sent: 0.5554403830431256
dev_f-score_macro_sent: 0.5092385638562401
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8985022126404175
dev_label=O_recall_tok: 0.9772909595803764
dev_label=O_f-score_tok: 0.9362419083089473
dev_label=N_precision_tok: 0.7939882697947214
dev_label=N_recall_tok: 0.5831987075928917
dev_label=N_f-score_tok: 0.6724619683328158
dev_label=P_precision_tok: 0.9159369527145359
dev_label=P_recall_tok: 0.651307596513076
dev_label=P_f-score_tok: 0.7612809315866085
dev_precision_macro_tok: 0.8694758117165583
dev_recall_macro_tok: 0.7372657545621147
dev_f-score_macro_tok: 0.7899949360761238
dev_precision_micro_tok: 0.8936730281094294
dev_recall_micro_tok: 0.8936730281094294
dev_f-score_micro_tok: 0.8936730281094294
dev_time: 8.439107179641724
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5556    0.0437    0.0810       229
           N     0.6283    0.8411    0.7193       428
           P     0.6804    0.7815    0.7275       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.6214    0.5554    0.5092      1101
weighted avg     0.6342    0.6512    0.5898      1101

F1-macro sent:  0.5092385638562401
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8985    0.9773    0.9362     16205
           N     0.7940    0.5832    0.6725      1857
           P     0.9159    0.6513    0.7613      3212

   micro avg     0.8937    0.8937    0.8937     21274
   macro avg     0.8695    0.7373    0.7900     21274
weighted avg     0.8920    0.8937    0.8868     21274

F1-macro tok:  0.7899949360761238
F1-micro tok:  0.8936730281094294
**************************************************
Best epoch: 12
**************************************************

EPOCH: 15
Learning rate: 1.000000
train_cost_sum: 322225.14361572266
train_cost_avg: 37.71361699622222
train_count_sent: 8544.0
train_total_correct_sent: 5613.0
train_accuracy_sent: 0.6569522471910112
train_count_tok: 163566.0
train_total_correct_tok: 144926.0
train_accuracy_tok: 0.886039886039886
train_label=O_precision_sent: 0.39603960396039606
train_label=O_recall_sent: 0.04926108374384237
train_label=O_f-score_sent: 0.08762322015334063
train_label=N_precision_sent: 0.6264274061990212
train_label=N_recall_sent: 0.8120845921450152
train_label=N_f-score_sent: 0.7072753585054598
train_label=P_precision_sent: 0.7022957294495187
train_label=P_recall_sent: 0.7880886426592798
train_label=P_f-score_sent: 0.7427228821302702
train_precision_macro_sent: 0.5749209132029786
train_recall_macro_sent: 0.5498114395160458
train_f-score_macro_sent: 0.5125404869296902
train_precision_micro_sent: 0.6569522471910112
train_recall_micro_sent: 0.6569522471910112
train_f-score_micro_sent: 0.6569522471910112
train_label=O_precision_tok: 0.8966223892011493
train_label=O_recall_tok: 0.971137220841677
train_label=O_f-score_tok: 0.9323934092067266
train_label=N_precision_tok: 0.7766152716593245
train_label=N_recall_tok: 0.5958315730178848
train_label=N_f-score_tok: 0.6743166786198104
train_label=P_precision_tok: 0.8730891100116738
train_label=P_recall_tok: 0.6278130871007714
train_label=P_f-score_tok: 0.7304097102729851
train_precision_macro_tok: 0.8487755902907158
train_recall_macro_tok: 0.731593960320111
train_f-score_macro_tok: 0.7790399326998406
train_precision_micro_tok: 0.886039886039886
train_recall_micro_tok: 0.886039886039886
train_f-score_micro_tok: 0.886039886039886
train_time: 145.18972373008728
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3960    0.0493    0.0876      1624
           N     0.6264    0.8121    0.7073      3310
           P     0.7023    0.7881    0.7427      3610

   micro avg     0.6570    0.6570    0.6570      8544
   macro avg     0.5749    0.5498    0.5125      8544
weighted avg     0.6147    0.6570    0.6045      8544

F1-macro sent:  0.5125404869296902
F1-micro sent:  0.6569522471910112
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8966    0.9711    0.9324    124347
           N     0.7766    0.5958    0.6743     14202
           P     0.8731    0.6278    0.7304     25017

   micro avg     0.8860    0.8860    0.8860    163566
   macro avg     0.8488    0.7316    0.7790    163566
weighted avg     0.8826    0.8860    0.8791    163566

F1-macro tok:  0.7790399326998406
F1-micro tok:  0.886039886039886
**************************************************
dev_cost_sum: 43398.75158691406
dev_cost_avg: 39.41757637321895
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19034.0
dev_accuracy_tok: 0.8947071542728213
dev_label=O_precision_sent: 0.875
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05907172995780591
dev_label=N_precision_sent: 0.6666666666666666
dev_label=N_recall_sent: 0.7663551401869159
dev_label=N_f-score_sent: 0.7130434782608696
dev_label=P_precision_sent: 0.6356073211314476
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7311004784688995
dev_precision_macro_sent: 0.7257579959327046
dev_recall_macro_sent: 0.5524277287122653
dev_f-score_macro_sent: 0.501071895562525
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.8985663285544285
dev_label=O_recall_tok: 0.9785251465597038
dev_label=O_f-score_tok: 0.9368427271653079
dev_label=N_precision_tok: 0.8053293856402665
dev_label=N_recall_tok: 0.5858912224017232
dev_label=N_f-score_tok: 0.6783042394014962
dev_label=P_precision_tok: 0.9178383128295254
dev_label=P_recall_tok: 0.650373599003736
dev_label=P_f-score_tok: 0.7612973760932944
dev_precision_macro_tok: 0.8739113423414069
dev_recall_macro_tok: 0.7382633226550542
dev_f-score_macro_tok: 0.792148114220033
dev_precision_micro_tok: 0.8947071542728213
dev_recall_micro_tok: 0.8947071542728213
dev_f-score_micro_tok: 0.8947071542728212
dev_time: 8.40372109413147
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8750    0.0306    0.0591       229
           N     0.6667    0.7664    0.7130       428
           P     0.6356    0.8604    0.7311       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.7258    0.5524    0.5011      1101
weighted avg     0.6975    0.6512    0.5843      1101

F1-macro sent:  0.501071895562525
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8986    0.9785    0.9368     16205
           N     0.8053    0.5859    0.6783      1857
           P     0.9178    0.6504    0.7613      3212

   micro avg     0.8947    0.8947    0.8947     21274
   macro avg     0.8739    0.7383    0.7921     21274
weighted avg     0.8933    0.8947    0.8878     21274

F1-macro tok:  0.792148114220033
F1-micro tok:  0.8947071542728212
**************************************************
Best epoch: 12
**************************************************

EPOCH: 16
Learning rate: 1.000000
train_cost_sum: 320418.09552001953
train_cost_avg: 37.5021179213506
train_count_sent: 8544.0
train_total_correct_sent: 5628.0
train_accuracy_sent: 0.6587078651685393
train_count_tok: 163566.0
train_total_correct_tok: 145312.0
train_accuracy_tok: 0.8883997896873433
train_label=O_precision_sent: 0.47297297297297297
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.07900677200902935
train_label=N_precision_sent: 0.6247968423496634
train_label=N_recall_sent: 0.8129909365558913
train_label=N_f-score_sent: 0.7065773926742812
train_label=P_precision_sent: 0.7011494252873564
train_label=P_recall_sent: 0.7941828254847645
train_label=P_f-score_sent: 0.7447720483179635
train_precision_macro_sent: 0.5996397468699975
train_recall_macro_sent: 0.5500924034388394
train_f-score_macro_sent: 0.5101187376670914
train_precision_micro_sent: 0.6587078651685393
train_recall_micro_sent: 0.6587078651685393
train_f-score_micro_sent: 0.6587078651685393
train_label=O_precision_tok: 0.8983865813509315
train_label=O_recall_tok: 0.9721665983095692
train_label=O_f-score_tok: 0.9338215414088511
train_label=N_precision_tok: 0.7866789159393661
train_label=N_recall_tok: 0.6029432474299394
train_label=N_f-score_tok: 0.6826643281380794
train_label=P_precision_tok: 0.8753448846705661
train_label=P_recall_tok: 0.6340888196026702
train_label=P_f-score_tok: 0.7354366118825194
train_precision_macro_tok: 0.8534701273202879
train_recall_macro_tok: 0.7363995551140595
train_f-score_macro_tok: 0.7839741604764833
train_precision_micro_tok: 0.8883997896873433
train_recall_micro_tok: 0.8883997896873433
train_f-score_micro_tok: 0.8883997896873433
train_time: 145.38191413879395
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4730    0.0431    0.0790      1624
           N     0.6248    0.8130    0.7066      3310
           P     0.7011    0.7942    0.7448      3610

   micro avg     0.6587    0.6587    0.6587      8544
   macro avg     0.5996    0.5501    0.5101      8544
weighted avg     0.6282    0.6587    0.6034      8544

F1-macro sent:  0.5101187376670914
F1-micro sent:  0.6587078651685393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8984    0.9722    0.9338    124347
           N     0.7867    0.6029    0.6827     14202
           P     0.8753    0.6341    0.7354     25017

   micro avg     0.8884    0.8884    0.8884    163566
   macro avg     0.8535    0.7364    0.7840    163566
weighted avg     0.8852    0.8884    0.8817    163566

F1-macro tok:  0.7839741604764833
F1-micro tok:  0.8883997896873433
**************************************************
dev_cost_sum: 43232.329345703125
dev_cost_avg: 39.266420840783944
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19019.0
dev_accuracy_tok: 0.8940020682523268
dev_label=O_precision_sent: 0.5217391304347826
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09523809523809523
dev_label=N_precision_sent: 0.6302083333333334
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7231075697211155
dev_label=P_precision_sent: 0.6872509960159362
dev_label=P_recall_sent: 0.777027027027027
dev_label=P_f-score_sent: 0.7293868921775898
dev_precision_macro_sent: 0.6130661532613507
dev_recall_macro_sent: 0.5591865382911377
dev_f-score_macro_sent: 0.5159108523789335
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.8904040966269621
dev_label=O_recall_tok: 0.9871644554149954
dev_label=O_f-score_tok: 0.936291006994235
dev_label=N_precision_tok: 0.8533674339300937
dev_label=N_recall_tok: 0.539041464728056
dev_label=N_f-score_tok: 0.6607260726072607
dev_label=P_precision_tok: 0.9466042154566745
dev_label=P_recall_tok: 0.6292029887920298
dev_label=P_f-score_tok: 0.755937909107911
dev_precision_macro_tok: 0.8967919153379101
dev_recall_macro_tok: 0.7184696363116938
dev_f-score_macro_tok: 0.7843183295698023
dev_precision_micro_tok: 0.8940020682523268
dev_recall_micro_tok: 0.8940020682523268
dev_f-score_micro_tok: 0.8940020682523268
dev_time: 8.431794881820679
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5217    0.0524    0.0952       229
           N     0.6302    0.8481    0.7231       428
           P     0.6873    0.7770    0.7294       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.6131    0.5592    0.5159      1101
weighted avg     0.6307    0.6540    0.5950      1101

F1-macro sent:  0.5159108523789335
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8904    0.9872    0.9363     16205
           N     0.8534    0.5390    0.6607      1857
           P     0.9466    0.6292    0.7559      3212

   micro avg     0.8940    0.8940    0.8940     21274
   macro avg     0.8968    0.7185    0.7843     21274
weighted avg     0.8957    0.8940    0.8850     21274

F1-macro tok:  0.7843183295698023
F1-micro tok:  0.8940020682523268
**************************************************
Best epoch: 16
**************************************************

EPOCH: 17
Learning rate: 1.000000
train_cost_sum: 318296.27868652344
train_cost_avg: 37.25377793615677
train_count_sent: 8544.0
train_total_correct_sent: 5686.0
train_accuracy_sent: 0.665496254681648
train_count_tok: 163566.0
train_total_correct_tok: 145523.0
train_accuracy_tok: 0.8896897888314197
train_label=O_precision_sent: 0.4915254237288136
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.0966129927817879
train_label=N_precision_sent: 0.6430484538592647
train_label=N_recall_sent: 0.7978851963746224
train_label=N_f-score_sent: 0.7121477686396117
train_label=P_precision_sent: 0.6943661971830986
train_label=P_recall_sent: 0.8193905817174515
train_label=P_f-score_sent: 0.7517153748411689
train_precision_macro_sent: 0.6096466915903923
train_recall_macro_sent: 0.5569490688878341
train_f-score_macro_sent: 0.5201587120875228
train_precision_micro_sent: 0.665496254681648
train_recall_micro_sent: 0.665496254681648
train_f-score_micro_sent: 0.665496254681648
train_label=O_precision_tok: 0.8998287671232876
train_label=O_recall_tok: 0.9719977160687431
train_label=O_f-score_tok: 0.9345219915953715
train_label=N_precision_tok: 0.7866326251481718
train_label=N_recall_tok: 0.607449654978172
train_label=N_f-score_tok: 0.6855258452858675
train_label=P_precision_tok: 0.8770173423053778
train_label=P_recall_tok: 0.6408042531078867
train_label=P_f-score_tok: 0.740530303030303
train_precision_macro_tok: 0.8544929115256124
train_recall_macro_tok: 0.7400838747182673
train_f-score_macro_tok: 0.786859379970514
train_precision_micro_tok: 0.8896897888314197
train_recall_micro_tok: 0.8896897888314197
train_f-score_micro_tok: 0.8896897888314197
train_time: 146.15770483016968
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4915    0.0536    0.0966      1624
           N     0.6430    0.7979    0.7121      3310
           P     0.6944    0.8194    0.7517      3610

   micro avg     0.6655    0.6655    0.6655      8544
   macro avg     0.6096    0.5569    0.5202      8544
weighted avg     0.6359    0.6655    0.6119      8544

F1-macro sent:  0.5201587120875228
F1-micro sent:  0.665496254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8998    0.9720    0.9345    124347
           N     0.7866    0.6074    0.6855     14202
           P     0.8770    0.6408    0.7405     25017

   micro avg     0.8897    0.8897    0.8897    163566
   macro avg     0.8545    0.7401    0.7869    163566
weighted avg     0.8865    0.8897    0.8832    163566

F1-macro tok:  0.786859379970514
F1-micro tok:  0.8896897888314197
**************************************************
dev_cost_sum: 43162.431884765625
dev_cost_avg: 39.20293540850647
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19045.0
dev_accuracy_tok: 0.8952242173545173
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.034042553191489355
dev_label=N_precision_sent: 0.6496212121212122
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.7175732217573222
dev_label=P_precision_sent: 0.6631393298059964
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7438180019782393
dev_precision_macro_sent: 0.6598090695312918
dev_recall_macro_sent: 0.5552386549713407
dev_f-score_macro_sent: 0.49847792564235033
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.8931186762815138
dev_label=O_recall_tok: 0.985930268435668
dev_label=O_f-score_tok: 0.9372323575995775
dev_label=N_precision_tok: 0.8446443172526574
dev_label=N_recall_tok: 0.5562735595045772
dev_label=N_f-score_tok: 0.6707792207792208
dev_label=P_precision_tok: 0.9412580943570767
dev_label=P_recall_tok: 0.6335616438356164
dev_label=P_f-score_tok: 0.7573502046892444
dev_precision_macro_tok: 0.8930070292970825
dev_recall_macro_tok: 0.7252551572586206
dev_f-score_macro_tok: 0.7884539276893475
dev_precision_micro_tok: 0.8952242173545173
dev_recall_micro_tok: 0.8952242173545173
dev_f-score_micro_tok: 0.8952242173545172
dev_time: 8.29969048500061
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0175    0.0340       229
           N     0.6496    0.8014    0.7176       428
           P     0.6631    0.8468    0.7438       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6598    0.5552    0.4985      1101
weighted avg     0.6586    0.6567    0.5860      1101

F1-macro sent:  0.49847792564235033
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8931    0.9859    0.9372     16205
           N     0.8446    0.5563    0.6708      1857
           P     0.9413    0.6336    0.7574      3212

   micro avg     0.8952    0.8952    0.8952     21274
   macro avg     0.8930    0.7253    0.7885     21274
weighted avg     0.8962    0.8952    0.8868     21274

F1-macro tok:  0.7884539276893475
F1-micro tok:  0.8952242173545172
**************************************************
Best epoch: 16
**************************************************

EPOCH: 18
Learning rate: 1.000000
train_cost_sum: 316422.22479248047
train_cost_avg: 37.03443642234088
train_count_sent: 8544.0
train_total_correct_sent: 5687.0
train_accuracy_sent: 0.6656132958801498
train_count_tok: 163566.0
train_total_correct_tok: 145874.0
train_accuracy_tok: 0.8918357115782009
train_label=O_precision_sent: 0.4805194805194805
train_label=O_recall_sent: 0.04556650246305419
train_label=O_f-score_sent: 0.08323959505061868
train_label=N_precision_sent: 0.6444012630556231
train_label=N_recall_sent: 0.8015105740181269
train_label=N_f-score_sent: 0.7144203581526861
train_label=P_precision_sent: 0.6927217411654575
train_label=P_recall_sent: 0.8199445983379502
train_label=P_f-score_sent: 0.750983128250666
train_precision_macro_sent: 0.6058808282468537
train_recall_macro_sent: 0.5556738916063771
train_f-score_macro_sent: 0.516214360484657
train_precision_micro_sent: 0.6656132958801498
train_recall_micro_sent: 0.6656132958801498
train_f-score_micro_sent: 0.6656132958801498
train_label=O_precision_tok: 0.9019027231839846
train_label=O_recall_tok: 0.9724319846880102
train_label=O_f-score_tok: 0.9358403826358845
train_label=N_precision_tok: 0.7899774266365689
train_label=N_recall_tok: 0.6160399943669905
train_label=N_f-score_tok: 0.6922498714246152
train_label=P_precision_tok: 0.8798045602605863
train_label=P_recall_tok: 0.6477994963424871
train_label=P_f-score_tok: 0.7461841287381724
train_precision_macro_tok: 0.8572282366937133
train_recall_macro_tok: 0.7454238251324959
train_f-score_macro_tok: 0.791424794266224
train_precision_micro_tok: 0.8918357115782009
train_recall_micro_tok: 0.8918357115782009
train_f-score_micro_tok: 0.8918357115782009
train_time: 146.96656680107117
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4805    0.0456    0.0832      1624
           N     0.6444    0.8015    0.7144      3310
           P     0.6927    0.8199    0.7510      3610

   micro avg     0.6656    0.6656    0.6656      8544
   macro avg     0.6059    0.5557    0.5162      8544
weighted avg     0.6337    0.6656    0.6099      8544

F1-macro sent:  0.516214360484657
F1-micro sent:  0.6656132958801498
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9019    0.9724    0.9358    124347
           N     0.7900    0.6160    0.6922     14202
           P     0.8798    0.6478    0.7462     25017

   micro avg     0.8918    0.8918    0.8918    163566
   macro avg     0.8572    0.7454    0.7914    163566
weighted avg     0.8888    0.8918    0.8857    163566

F1-macro tok:  0.791424794266224
F1-micro tok:  0.8918357115782009
**************************************************
dev_cost_sum: 42902.35144042969
dev_cost_avg: 38.96671338821952
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19099.0
dev_accuracy_tok: 0.8977625270282974
dev_label=O_precision_sent: 0.8888888888888888
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06722689075630252
dev_label=N_precision_sent: 0.698237885462555
dev_label=N_recall_sent: 0.7406542056074766
dev_label=N_f-score_sent: 0.7188208616780046
dev_label=P_precision_sent: 0.6285266457680251
dev_label=P_recall_sent: 0.9031531531531531
dev_label=P_f-score_sent: 0.7412199630314233
dev_precision_macro_sent: 0.738551140039823
dev_recall_macro_sent: 0.5595806188590745
dev_f-score_macro_sent: 0.5090892384885768
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9002437227228929
dev_label=O_recall_tok: 0.9801295896328294
dev_label=O_f-score_tok: 0.938489718742614
dev_label=N_precision_tok: 0.8295719844357977
dev_label=N_recall_tok: 0.5740441572428648
dev_label=N_f-score_tok: 0.6785486950986633
dev_label=P_precision_tok: 0.9164535379369139
dev_label=P_recall_tok: 0.6693648816936488
dev_label=P_f-score_tok: 0.7736595897804965
dev_precision_macro_tok: 0.8820897483652015
dev_recall_macro_tok: 0.7411795428564476
dev_f-score_macro_tok: 0.7968993345405911
dev_precision_micro_tok: 0.8977625270282974
dev_recall_micro_tok: 0.8977625270282974
dev_f-score_micro_tok: 0.8977625270282974
dev_time: 8.288340330123901
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8889    0.0349    0.0672       229
           N     0.6982    0.7407    0.7188       428
           P     0.6285    0.9032    0.7412       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.7386    0.5596    0.5091      1101
weighted avg     0.7098    0.6594    0.5923      1101

F1-macro sent:  0.5090892384885768
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9002    0.9801    0.9385     16205
           N     0.8296    0.5740    0.6785      1857
           P     0.9165    0.6694    0.7737      3212

   micro avg     0.8978    0.8978    0.8978     21274
   macro avg     0.8821    0.7412    0.7969     21274
weighted avg     0.8965    0.8978    0.8909     21274

F1-macro tok:  0.7968993345405911
F1-micro tok:  0.8977625270282974
**************************************************
Best epoch: 16
**************************************************

EPOCH: 19
Learning rate: 1.000000
train_cost_sum: 314779.38415527344
train_cost_avg: 36.84215638521459
train_count_sent: 8544.0
train_total_correct_sent: 5713.0
train_accuracy_sent: 0.6686563670411985
train_count_tok: 163566.0
train_total_correct_tok: 146091.0
train_accuracy_tok: 0.8931623931623932
train_label=O_precision_sent: 0.3983739837398374
train_label=O_recall_sent: 0.0603448275862069
train_label=O_f-score_sent: 0.10481283422459894
train_label=N_precision_sent: 0.6526237989652623
train_label=N_recall_sent: 0.8003021148036253
train_label=N_f-score_sent: 0.7189577961731578
train_label=P_precision_sent: 0.6996933238971456
train_label=P_recall_sent: 0.821606648199446
train_label=P_f-score_sent: 0.7557650656134539
train_precision_macro_sent: 0.5835637022007485
train_recall_macro_sent: 0.5607511968630927
train_f-score_macro_sent: 0.5265118986704036
train_precision_micro_sent: 0.6686563670411985
train_recall_micro_sent: 0.6686563670411985
train_f-score_micro_sent: 0.6686563670411985
train_label=O_precision_tok: 0.9034861562605089
train_label=O_recall_tok: 0.9722791864701199
train_label=O_f-score_tok: 0.9366211913449695
train_label=N_precision_tok: 0.790989069581445
train_label=N_recall_tok: 0.6267427122940431
train_label=N_f-score_tok: 0.6993517972893342
train_label=P_precision_tok: 0.8806357444048005
train_label=P_recall_tok: 0.6511572130950953
train_label=P_f-score_tok: 0.7487073422957601
train_precision_macro_tok: 0.8583703234155848
train_recall_macro_tok: 0.7500597039530862
train_f-score_macro_tok: 0.7948934436433546
train_precision_micro_tok: 0.8931623931623932
train_recall_micro_tok: 0.8931623931623932
train_f-score_micro_tok: 0.8931623931623932
train_time: 145.3545958995819
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3984    0.0603    0.1048      1624
           N     0.6526    0.8003    0.7190      3310
           P     0.6997    0.8216    0.7558      3610

   micro avg     0.6687    0.6687    0.6687      8544
   macro avg     0.5836    0.5608    0.5265      8544
weighted avg     0.6242    0.6687    0.6178      8544

F1-macro sent:  0.5265118986704036
F1-micro sent:  0.6686563670411985
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9035    0.9723    0.9366    124347
           N     0.7910    0.6267    0.6994     14202
           P     0.8806    0.6512    0.7487     25017

   micro avg     0.8932    0.8932    0.8932    163566
   macro avg     0.8584    0.7501    0.7949    163566
weighted avg     0.8902    0.8932    0.8873    163566

F1-macro tok:  0.7948934436433546
F1-micro tok:  0.8931623931623932
**************************************************
dev_cost_sum: 42820.638916015625
dev_cost_avg: 38.892496744791664
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19067.0
dev_accuracy_tok: 0.8962583435179092
dev_label=O_precision_sent: 0.7272727272727273
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06666666666666667
dev_label=N_precision_sent: 0.6603415559772297
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7287958115183247
dev_label=P_precision_sent: 0.6642984014209592
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7428003972194637
dev_precision_macro_sent: 0.6839708948903054
dev_recall_macro_sent: 0.5634536507694896
dev_f-score_macro_sent: 0.512754291801485
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.9068802581537397
dev_label=O_recall_tok: 0.9711817340327059
dev_label=O_f-score_tok: 0.9379302124616347
dev_label=N_precision_tok: 0.8207407407407408
dev_label=N_recall_tok: 0.596661281637049
dev_label=N_f-score_tok: 0.6909884627377612
dev_label=P_precision_tok: 0.8642023346303502
dev_label=P_recall_tok: 0.6914694894146949
dev_label=P_f-score_tok: 0.7682462815634729
dev_precision_macro_tok: 0.8639411111749435
dev_recall_macro_tok: 0.7531041683614833
dev_f-score_macro_tok: 0.7990549855876229
dev_precision_micro_tok: 0.8962583435179092
dev_recall_micro_tok: 0.8962583435179092
dev_f-score_micro_tok: 0.8962583435179092
dev_time: 8.234529256820679
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7273    0.0349    0.0667       229
           N     0.6603    0.8131    0.7288       428
           P     0.6643    0.8423    0.7428       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.6840    0.5635    0.5128      1101
weighted avg     0.6759    0.6630    0.5967      1101

F1-macro sent:  0.512754291801485
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9069    0.9712    0.9379     16205
           N     0.8207    0.5967    0.6910      1857
           P     0.8642    0.6915    0.7682      3212

   micro avg     0.8963    0.8963    0.8963     21274
   macro avg     0.8639    0.7531    0.7991     21274
weighted avg     0.8929    0.8963    0.8908     21274

F1-macro tok:  0.7990549855876229
F1-micro tok:  0.8962583435179092
**************************************************
Best epoch: 16
**************************************************

EPOCH: 20
Learning rate: 1.000000
train_cost_sum: 312885.99822998047
train_cost_avg: 36.620552227291725
train_count_sent: 8544.0
train_total_correct_sent: 5700.0
train_accuracy_sent: 0.6671348314606742
train_count_tok: 163566.0
train_total_correct_tok: 146446.0
train_accuracy_tok: 0.8953327708692516
train_label=O_precision_sent: 0.4523809523809524
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.08482142857142858
train_label=N_precision_sent: 0.6390070921985815
train_label=N_recall_sent: 0.8166163141993957
train_label=N_f-score_sent: 0.716976127320955
train_label=P_precision_sent: 0.7045344910757356
train_label=P_recall_sent: 0.8091412742382271
train_label=P_f-score_sent: 0.7532233109850438
train_precision_macro_sent: 0.5986408452184232
train_recall_macro_sent: 0.5575185393314244
train_f-score_macro_sent: 0.5183402889591425
train_precision_micro_sent: 0.6671348314606742
train_recall_micro_sent: 0.6671348314606742
train_f-score_micro_sent: 0.6671348314606742
train_label=O_precision_tok: 0.9055980710766328
train_label=O_recall_tok: 0.9725928249173683
train_label=O_f-score_tok: 0.937900602187729
train_label=N_precision_tok: 0.7960468002127282
train_label=N_recall_tok: 0.6323757217293339
train_label=N_f-score_tok: 0.7048344059017423
train_label=P_precision_tok: 0.8819511153805102
train_label=P_recall_tok: 0.6605907982571851
train_label=P_f-score_tok: 0.7553879556622101
train_precision_macro_tok: 0.8611986622232903
train_recall_macro_tok: 0.7551864483012958
train_f-score_macro_tok: 0.7993743212505605
train_precision_micro_tok: 0.8953327708692516
train_recall_micro_tok: 0.8953327708692516
train_f-score_micro_tok: 0.8953327708692517
train_time: 146.15339493751526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4524    0.0468    0.0848      1624
           N     0.6390    0.8166    0.7170      3310
           P     0.7045    0.8091    0.7532      3610

   micro avg     0.6671    0.6671    0.6671      8544
   macro avg     0.5986    0.5575    0.5183      8544
weighted avg     0.6312    0.6671    0.6121      8544

F1-macro sent:  0.5183402889591425
F1-micro sent:  0.6671348314606742
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9056    0.9726    0.9379    124347
           N     0.7960    0.6324    0.7048     14202
           P     0.8820    0.6606    0.7554     25017

   micro avg     0.8953    0.8953    0.8953    163566
   macro avg     0.8612    0.7552    0.7994    163566
weighted avg     0.8925    0.8953    0.8897    163566

F1-macro tok:  0.7993743212505605
F1-micro tok:  0.8953327708692517
**************************************************
dev_cost_sum: 42632.84680175781
dev_cost_avg: 38.72193170005251
dev_count_sent: 1101.0
dev_total_correct_sent: 720.0
dev_accuracy_sent: 0.6539509536784741
dev_count_tok: 21274.0
dev_total_correct_tok: 19138.0
dev_accuracy_tok: 0.8995957506815832
dev_label=O_precision_sent: 0.8888888888888888
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06722689075630252
dev_label=N_precision_sent: 0.7077625570776256
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.7159353348729792
dev_label=P_precision_sent: 0.6146788990825688
dev_label=P_recall_sent: 0.9054054054054054
dev_label=P_f-score_sent: 0.73224043715847
dev_precision_macro_sent: 0.7371101150163611
dev_recall_macro_sent: 0.5548796562141867
dev_f-score_macro_sent: 0.5051342209292505
dev_precision_micro_sent: 0.6539509536784741
dev_recall_micro_sent: 0.6539509536784741
dev_f-score_micro_sent: 0.6539509536784741
dev_label=O_precision_tok: 0.9074042162100063
dev_label=O_recall_tok: 0.9748225856217216
dev_label=O_f-score_tok: 0.9399059915511394
dev_label=N_precision_tok: 0.7916666666666666
dev_label=N_recall_tok: 0.6241249326871298
dev_label=N_f-score_tok: 0.6979825353809093
dev_label=P_precision_tok: 0.9087880049979176
dev_label=P_recall_tok: 0.6793275217932753
dev_label=P_f-score_tok: 0.7774808480313559
dev_precision_macro_tok: 0.8692862959581968
dev_recall_macro_tok: 0.7594250133673756
dev_f-score_macro_tok: 0.8051231249878015
dev_precision_micro_tok: 0.8995957506815832
dev_recall_micro_tok: 0.8995957506815832
dev_f-score_micro_tok: 0.8995957506815832
dev_time: 8.393730163574219
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8889    0.0349    0.0672       229
           N     0.7078    0.7243    0.7159       428
           P     0.6147    0.9054    0.7322       444

   micro avg     0.6540    0.6540    0.6540      1101
   macro avg     0.7371    0.5549    0.5051      1101
weighted avg     0.7079    0.6540    0.5876      1101

F1-macro sent:  0.5051342209292505
F1-micro sent:  0.6539509536784741
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9748    0.9399     16205
           N     0.7917    0.6241    0.6980      1857
           P     0.9088    0.6793    0.7775      3212

   micro avg     0.8996    0.8996    0.8996     21274
   macro avg     0.8693    0.7594    0.8051     21274
weighted avg     0.8975    0.8996    0.8943     21274

F1-macro tok:  0.8051231249878015
F1-micro tok:  0.8995957506815832
**************************************************
Best epoch: 16
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 311117.3220214844
train_cost_avg: 36.41354424408759
train_count_sent: 8544.0
train_total_correct_sent: 5775.0
train_accuracy_sent: 0.6759129213483146
train_count_tok: 163566.0
train_total_correct_tok: 146577.0
train_accuracy_tok: 0.8961336708117824
train_label=O_precision_sent: 0.43724696356275305
train_label=O_recall_sent: 0.0665024630541872
train_label=O_f-score_sent: 0.11544628540887228
train_label=N_precision_sent: 0.6461138672336404
train_label=N_recall_sent: 0.8262839879154078
train_label=N_f-score_sent: 0.7251756595519023
train_label=P_precision_sent: 0.7214566929133859
train_label=P_recall_sent: 0.8121883656509695
train_label=P_f-score_sent: 0.764138649986969
train_precision_macro_sent: 0.6016058412365931
train_recall_macro_sent: 0.5683249388735215
train_f-score_macro_sent: 0.5349201983159145
train_precision_micro_sent: 0.6759129213483146
train_recall_micro_sent: 0.6759129213483146
train_f-score_micro_sent: 0.6759129213483146
train_label=O_precision_tok: 0.9065372906012388
train_label=O_recall_tok: 0.9722309344013125
train_label=O_f-score_tok: 0.9382355794416096
train_label=N_precision_tok: 0.8013432308236126
train_label=N_recall_tok: 0.6385016194902127
train_label=N_f-score_tok: 0.7107140057998276
train_label=P_precision_tok: 0.8794727927164937
train_label=P_recall_tok: 0.6641483791022105
train_label=P_f-score_tok: 0.7567924571272404
train_precision_macro_tok: 0.8624511047137817
train_recall_macro_tok: 0.7582936443312452
train_f-score_macro_tok: 0.8019140141228925
train_precision_micro_tok: 0.8961336708117824
train_recall_micro_tok: 0.8961336708117824
train_f-score_micro_tok: 0.8961336708117824
train_time: 146.48492550849915
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4372    0.0665    0.1154      1624
           N     0.6461    0.8263    0.7252      3310
           P     0.7215    0.8122    0.7641      3610

   micro avg     0.6759    0.6759    0.6759      8544
   macro avg     0.6016    0.5683    0.5349      8544
weighted avg     0.6382    0.6759    0.6257      8544

F1-macro sent:  0.5349201983159145
F1-micro sent:  0.6759129213483146
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9065    0.9722    0.9382    124347
           N     0.8013    0.6385    0.7107     14202
           P     0.8795    0.6641    0.7568     25017

   micro avg     0.8961    0.8961    0.8961    163566
   macro avg     0.8625    0.7583    0.8019    163566
weighted avg     0.8933    0.8961    0.8907    163566

F1-macro tok:  0.8019140141228925
F1-micro tok:  0.8961336708117824
**************************************************
dev_cost_sum: 42554.322998046875
dev_cost_avg: 38.65061126071469
dev_count_sent: 1101.0
dev_total_correct_sent: 732.0
dev_accuracy_sent: 0.6648501362397821
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.09836065573770492
dev_label=N_precision_sent: 0.6718446601941748
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.733828207847296
dev_label=P_precision_sent: 0.6549912434325744
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7369458128078817
dev_precision_macro_sent: 0.7089453012089164
dev_recall_macro_sent: 0.5677184346735014
dev_f-score_macro_sent: 0.5230448921309608
dev_precision_micro_sent: 0.6648501362397821
dev_recall_micro_sent: 0.6648501362397821
dev_f-score_micro_sent: 0.6648501362397821
dev_label=O_precision_tok: 0.9041564513370204
dev_label=O_recall_tok: 0.9785868559086701
dev_label=O_f-score_tok: 0.939900426742532
dev_label=N_precision_tok: 0.8244958924570575
dev_label=N_recall_tok: 0.5945072697899838
dev_label=N_f-score_tok: 0.690863579474343
dev_label=P_precision_tok: 0.9131886477462438
dev_label=P_recall_tok: 0.6811955168119551
dev_label=P_f-score_tok: 0.7803138373751782
dev_precision_macro_tok: 0.8806136638467739
dev_recall_macro_tok: 0.7514298808368697
dev_f-score_macro_tok: 0.8036926145306844
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 8.315692901611328
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0524    0.0984       229
           N     0.6718    0.8084    0.7338       428
           P     0.6550    0.8423    0.7369       444

   micro avg     0.6649    0.6649    0.6649      1101
   macro avg     0.7089    0.5677    0.5230      1101
weighted avg     0.6917    0.6649    0.6029      1101

F1-macro sent:  0.5230448921309608
F1-micro sent:  0.6648501362397821
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9786    0.9399     16205
           N     0.8245    0.5945    0.6909      1857
           P     0.9132    0.6812    0.7803      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8806    0.7514    0.8037     21274
weighted avg     0.8986    0.9002    0.8941     21274

F1-macro tok:  0.8036926145306844
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 21
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 309119.8123779297
train_cost_avg: 36.179753321386904
train_count_sent: 8544.0
train_total_correct_sent: 5762.0
train_accuracy_sent: 0.6743913857677902
train_count_tok: 163566.0
train_total_correct_tok: 147032.0
train_accuracy_tok: 0.8989154225205728
train_label=O_precision_sent: 0.41630901287553645
train_label=O_recall_sent: 0.05972906403940887
train_label=O_f-score_sent: 0.10446957458266021
train_label=N_precision_sent: 0.6495215311004785
train_label=N_recall_sent: 0.8202416918429003
train_label=N_f-score_sent: 0.7249666221628839
train_label=P_precision_sent: 0.7141128056160736
train_label=P_recall_sent: 0.817174515235457
train_label=P_f-score_sent: 0.7621754295310684
train_precision_macro_sent: 0.5933144498640295
train_recall_macro_sent: 0.5657150903725888
train_f-score_macro_sent: 0.5305372087588709
train_precision_micro_sent: 0.6743913857677902
train_recall_micro_sent: 0.6743913857677902
train_f-score_micro_sent: 0.6743913857677902
train_label=O_precision_tok: 0.9091653581168905
train_label=O_recall_tok: 0.973155765720122
train_label=O_f-score_tok: 0.9400728696503345
train_label=N_precision_tok: 0.7995990237099023
train_label=N_recall_tok: 0.6458949443740318
train_label=N_f-score_tok: 0.71457505647737
train_label=P_precision_tok: 0.8870755461963674
train_label=P_recall_tok: 0.6735419914458168
train_label=P_f-score_tok: 0.7657002635644823
train_precision_macro_tok: 0.8652799760077201
train_recall_macro_tok: 0.7641975671799902
train_f-score_macro_tok: 0.8067827298973956
train_precision_micro_tok: 0.8989154225205728
train_recall_micro_tok: 0.8989154225205728
train_f-score_micro_tok: 0.8989154225205728
train_time: 146.14424085617065
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4163    0.0597    0.1045      1624
           N     0.6495    0.8202    0.7250      3310
           P     0.7141    0.8172    0.7622      3610

   micro avg     0.6744    0.6744    0.6744      8544
   macro avg     0.5933    0.5657    0.5305      8544
weighted avg     0.6325    0.6744    0.6227      8544

F1-macro sent:  0.5305372087588709
F1-micro sent:  0.6743913857677902
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9092    0.9732    0.9401    124347
           N     0.7996    0.6459    0.7146     14202
           P     0.8871    0.6735    0.7657     25017

   micro avg     0.8989    0.8989    0.8989    163566
   macro avg     0.8653    0.7642    0.8068    163566
weighted avg     0.8963    0.8989    0.8938    163566

F1-macro tok:  0.8067827298973956
F1-micro tok:  0.8989154225205728
**************************************************
dev_cost_sum: 42483.15380859375
dev_cost_avg: 38.58597076166553
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19117.0
dev_accuracy_tok: 0.8986086302528908
dev_label=O_precision_sent: 0.4418604651162791
dev_label=O_recall_sent: 0.08296943231441048
dev_label=O_f-score_sent: 0.13970588235294118
dev_label=N_precision_sent: 0.6931106471816284
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7320837927232635
dev_label=P_precision_sent: 0.6459412780656304
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7311827956989249
dev_precision_macro_sent: 0.5936374634545126
dev_recall_macro_sent: 0.567004236412064
dev_f-score_macro_sent: 0.5343241569250431
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9026750142287991
dev_label=O_recall_tok: 0.9787102746066029
dev_label=O_f-score_tok: 0.9391561806069577
dev_label=N_precision_tok: 0.8308880308880309
dev_label=N_recall_tok: 0.5794291868605277
dev_label=N_f-score_tok: 0.682741116751269
dev_label=P_precision_tok: 0.9053549190535491
dev_label=P_recall_tok: 0.6790161892901619
dev_label=P_f-score_tok: 0.7760185020458993
dev_precision_macro_tok: 0.8796393213901265
dev_recall_macro_tok: 0.7457185502524308
dev_f-score_macro_tok: 0.7993052664680419
dev_precision_micro_tok: 0.8986086302528908
dev_recall_micro_tok: 0.8986086302528908
dev_f-score_micro_tok: 0.8986086302528908
dev_time: 8.40683364868164
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4419    0.0830    0.1397       229
           N     0.6931    0.7757    0.7321       428
           P     0.6459    0.8423    0.7312       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.5936    0.5670    0.5343      1101
weighted avg     0.6218    0.6585    0.6085      1101

F1-macro sent:  0.5343241569250431
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9027    0.9787    0.9392     16205
           N     0.8309    0.5794    0.6827      1857
           P     0.9054    0.6790    0.7760      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8796    0.7457    0.7993     21274
weighted avg     0.8968    0.8986    0.8921     21274

F1-macro tok:  0.7993052664680419
F1-micro tok:  0.8986086302528908
**************************************************
Best epoch: 22
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 307753.0844116211
train_cost_avg: 36.01978984218412
train_count_sent: 8544.0
train_total_correct_sent: 5820.0
train_accuracy_sent: 0.6811797752808989
train_count_tok: 163566.0
train_total_correct_tok: 147229.0
train_accuracy_tok: 0.9001198293043786
train_label=O_precision_sent: 0.45161290322580644
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.09281767955801103
train_label=N_precision_sent: 0.6513173510562544
train_label=N_recall_sent: 0.8290030211480363
train_label=N_f-score_sent: 0.7294962116177056
train_label=P_precision_sent: 0.7218335343787696
train_label=P_recall_sent: 0.8288088642659279
train_label=P_f-score_sent: 0.7716312056737589
train_precision_macro_sent: 0.6082545962202769
train_recall_macro_sent: 0.5698453411149996
train_f-score_macro_sent: 0.5313150322831585
train_precision_micro_sent: 0.6811797752808989
train_recall_micro_sent: 0.6811797752808989
train_f-score_micro_sent: 0.6811797752808989
train_label=O_precision_tok: 0.9103706155860181
train_label=O_recall_tok: 0.9730914296283787
train_label=O_f-score_tok: 0.9406866956126269
train_label=N_precision_tok: 0.8082108376098113
train_label=N_recall_tok: 0.6542740459090269
train_label=N_f-score_tok: 0.7231409782481809
train_label=P_precision_tok: 0.8841555729574524
train_label=P_recall_tok: 0.6769796538353919
train_label=P_f-score_tok: 0.7668206103413929
train_precision_macro_tok: 0.8675790087177605
train_recall_macro_tok: 0.7681150431242658
train_f-score_macro_tok: 0.8102160947340669
train_precision_micro_tok: 0.9001198293043786
train_recall_micro_tok: 0.9001198293043786
train_f-score_micro_tok: 0.9001198293043786
train_time: 146.0062608718872
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4516    0.0517    0.0928      1624
           N     0.6513    0.8290    0.7295      3310
           P     0.7218    0.8288    0.7716      3610

   micro avg     0.6812    0.6812    0.6812      8544
   macro avg     0.6083    0.5698    0.5313      8544
weighted avg     0.6432    0.6812    0.6263      8544

F1-macro sent:  0.5313150322831585
F1-micro sent:  0.6811797752808989
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9104    0.9731    0.9407    124347
           N     0.8082    0.6543    0.7231     14202
           P     0.8842    0.6770    0.7668     25017

   micro avg     0.9001    0.9001    0.9001    163566
   macro avg     0.8676    0.7681    0.8102    163566
weighted avg     0.8975    0.9001    0.8952    163566

F1-macro tok:  0.8102160947340669
F1-micro tok:  0.9001198293043786
**************************************************
dev_cost_sum: 42421.33483886719
dev_cost_avg: 38.52982274193205
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19106.0
dev_accuracy_tok: 0.8980915671711949
dev_label=O_precision_sent: 0.7777777777777778
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.058823529411764705
dev_label=N_precision_sent: 0.6412078152753108
dev_label=N_recall_sent: 0.8434579439252337
dev_label=N_f-score_sent: 0.7285570131180626
dev_label=P_precision_sent: 0.6862003780718336
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7461459403905446
dev_precision_macro_sent: 0.7017286570416408
dev_recall_macro_sent: 0.5638643990274402
dev_f-score_macro_sent: 0.5111754943067907
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9088126588126588
dev_label=O_recall_tok: 0.9711200246837396
dev_label=O_f-score_tok: 0.9389338026908506
dev_label=N_precision_tok: 0.7506188118811881
dev_label=N_recall_tok: 0.6532040926225094
dev_label=N_f-score_tok: 0.6985315289375179
dev_label=P_precision_tok: 0.9205807002561913
dev_label=P_recall_tok: 0.6712328767123288
dev_label=P_f-score_tok: 0.776377385667987
dev_precision_macro_tok: 0.860004056983346
dev_recall_macro_tok: 0.7651856646728593
dev_f-score_macro_tok: 0.8046142390987852
dev_precision_micro_tok: 0.8980915671711949
dev_recall_micro_tok: 0.8980915671711949
dev_f-score_micro_tok: 0.8980915671711949
dev_time: 8.137717247009277
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7778    0.0306    0.0588       229
           N     0.6412    0.8435    0.7286       428
           P     0.6862    0.8176    0.7461       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.7017    0.5639    0.5112      1101
weighted avg     0.6878    0.6639    0.5964      1101

F1-macro sent:  0.5111754943067907
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9711    0.9389     16205
           N     0.7506    0.6532    0.6985      1857
           P     0.9206    0.6712    0.7764      3212

   micro avg     0.8981    0.8981    0.8981     21274
   macro avg     0.8600    0.7652    0.8046     21274
weighted avg     0.8968    0.8981    0.8934     21274

F1-macro tok:  0.8046142390987852
F1-micro tok:  0.8980915671711949
**************************************************
Best epoch: 22
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 306398.4514770508
train_cost_avg: 35.861241979991895
train_count_sent: 8544.0
train_total_correct_sent: 5804.0
train_accuracy_sent: 0.6793071161048689
train_count_tok: 163566.0
train_total_correct_tok: 147503.0
train_accuracy_tok: 0.9017949940696722
train_label=O_precision_sent: 0.4765957446808511
train_label=O_recall_sent: 0.06896551724137931
train_label=O_f-score_sent: 0.12049488972565894
train_label=N_precision_sent: 0.6585605502333579
train_label=N_recall_sent: 0.8099697885196374
train_label=N_f-score_sent: 0.7264598292914239
train_label=P_precision_sent: 0.7104766399244927
train_label=P_recall_sent: 0.8340720221606648
train_label=P_f-score_sent: 0.7673292558613659
train_precision_macro_sent: 0.6152109782795673
train_recall_macro_sent: 0.5710024426405605
train_f-score_macro_sent: 0.5380946582928162
train_precision_micro_sent: 0.6793071161048689
train_recall_micro_sent: 0.6793071161048689
train_f-score_micro_sent: 0.6793071161048689
train_label=O_precision_tok: 0.9120759039594857
train_label=O_recall_tok: 0.9733005219265443
train_label=O_f-score_tok: 0.9416941266179326
train_label=N_precision_tok: 0.8079242032730405
train_label=N_recall_tok: 0.6604703562878468
train_label=N_f-score_tok: 0.7267937393460405
train_label=P_precision_tok: 0.8875506177966982
train_label=P_recall_tok: 0.6833753047927409
train_label=P_f-score_tok: 0.7721944940039297
train_precision_macro_tok: 0.8691835750097415
train_recall_macro_tok: 0.7723820610023774
train_f-score_macro_tok: 0.8135607866559676
train_precision_micro_tok: 0.9017949940696722
train_recall_micro_tok: 0.9017949940696722
train_f-score_micro_tok: 0.9017949940696722
train_time: 145.79905486106873
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4766    0.0690    0.1205      1624
           N     0.6586    0.8100    0.7265      3310
           P     0.7105    0.8341    0.7673      3610

   micro avg     0.6793    0.6793    0.6793      8544
   macro avg     0.6152    0.5710    0.5381      8544
weighted avg     0.6459    0.6793    0.6285      8544

F1-macro sent:  0.5380946582928162
F1-micro sent:  0.6793071161048689
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9121    0.9733    0.9417    124347
           N     0.8079    0.6605    0.7268     14202
           P     0.8876    0.6834    0.7722     25017

   micro avg     0.9018    0.9018    0.9018    163566
   macro avg     0.8692    0.7724    0.8136    163566
weighted avg     0.8993    0.9018    0.8971    163566

F1-macro tok:  0.8135607866559676
F1-micro tok:  0.9017949940696722
**************************************************
dev_cost_sum: 42280.482849121094
dev_cost_avg: 38.40189177940154
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19150.0
dev_accuracy_tok: 0.9001598194979787
dev_label=O_precision_sent: 0.8
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06694560669456066
dev_label=N_precision_sent: 0.6089030206677265
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7246925260170292
dev_label=P_precision_sent: 0.7272727272727273
dev_label=P_recall_sent: 0.7567567567567568
dev_label=P_f-score_sent: 0.7417218543046358
dev_precision_macro_sent: 0.7120585826468181
dev_recall_macro_sent: 0.5621836892191543
dev_f-score_macro_sent: 0.5111199956720752
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9118978525827046
dev_label=O_recall_tok: 0.9695772909595803
dev_label=O_f-score_tok: 0.9398534469866906
dev_label=N_precision_tok: 0.7947686116700201
dev_label=N_recall_tok: 0.6381260096930533
dev_label=N_f-score_tok: 0.7078853046594982
dev_label=P_precision_tok: 0.882491186839013
dev_label=P_recall_tok: 0.7014321295143213
dev_label=P_f-score_tok: 0.7816131830008674
dev_precision_macro_tok: 0.8630525503639125
dev_recall_macro_tok: 0.7697118100556516
dev_f-score_macro_tok: 0.8097839782156854
dev_precision_micro_tok: 0.9001598194979787
dev_recall_micro_tok: 0.9001598194979787
dev_f-score_micro_tok: 0.9001598194979787
dev_time: 8.483049392700195
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.8000    0.0349    0.0669       229
           N     0.6089    0.8949    0.7247       428
           P     0.7273    0.7568    0.7417       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.7121    0.5622    0.5111      1101
weighted avg     0.6964    0.6603    0.5948      1101

F1-macro sent:  0.5111199956720752
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9696    0.9399     16205
           N     0.7948    0.6381    0.7079      1857
           P     0.8825    0.7014    0.7816      3212

   micro avg     0.9002    0.9002    0.9002     21274
   macro avg     0.8631    0.7697    0.8098     21274
weighted avg     0.8972    0.9002    0.8957     21274

F1-macro tok:  0.8097839782156854
F1-micro tok:  0.9001598194979787
**************************************************
Best epoch: 22
**************************************************

EPOCH: 25
Learning rate: 0.900000
train_cost_sum: 305147.25799560547
train_cost_avg: 35.71480079536581
train_count_sent: 8544.0
train_total_correct_sent: 5862.0
train_accuracy_sent: 0.6860955056179775
train_count_tok: 163566.0
train_total_correct_tok: 147689.0
train_accuracy_tok: 0.9029321497132656
train_label=O_precision_sent: 0.5298507462686567
train_label=O_recall_sent: 0.0874384236453202
train_label=O_f-score_sent: 0.15010570824524314
train_label=N_precision_sent: 0.6581032412965186
train_label=N_recall_sent: 0.8280966767371601
train_label=N_f-score_sent: 0.7333779264214046
train_label=P_precision_sent: 0.7246412065190951
train_label=P_recall_sent: 0.8252077562326869
train_label=P_f-score_sent: 0.7716617018520916
train_precision_macro_sent: 0.6375317313614235
train_recall_macro_sent: 0.5802476188717224
train_f-score_macro_sent: 0.5517151121729131
train_precision_micro_sent: 0.6860955056179775
train_recall_micro_sent: 0.6860955056179775
train_f-score_micro_sent: 0.6860955056179775
train_label=O_precision_tok: 0.9140596663039535
train_label=O_recall_tok: 0.9727858331925981
train_label=O_f-score_tok: 0.9425088533327098
train_label=N_precision_tok: 0.8093725860441164
train_label=N_recall_tok: 0.6639909871849036
train_label=N_f-score_tok: 0.7295091478745215
train_label=P_precision_tok: 0.8833954747433475
train_label=P_recall_tok: 0.6913698684894272
train_label=P_f-score_tok: 0.7756749484258678
train_precision_macro_tok: 0.8689425756971391
train_recall_macro_tok: 0.7760488962889763
train_f-score_macro_tok: 0.8158976498776997
train_precision_micro_tok: 0.9029321497132656
train_recall_micro_tok: 0.9029321497132656
train_f-score_micro_tok: 0.9029321497132657
train_time: 146.5337107181549
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5299    0.0874    0.1501      1624
           N     0.6581    0.8281    0.7334      3310
           P     0.7246    0.8252    0.7717      3610

   micro avg     0.6861    0.6861    0.6861      8544
   macro avg     0.6375    0.5802    0.5517      8544
weighted avg     0.6618    0.6861    0.6387      8544

F1-macro sent:  0.5517151121729131
F1-micro sent:  0.6860955056179775
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9141    0.9728    0.9425    124347
           N     0.8094    0.6640    0.7295     14202
           P     0.8834    0.6914    0.7757     25017

   micro avg     0.9029    0.9029    0.9029    163566
   macro avg     0.8689    0.7760    0.8159    163566
weighted avg     0.9003    0.9029    0.8985    163566

F1-macro tok:  0.8158976498776997
F1-micro tok:  0.9029321497132657
**************************************************
dev_cost_sum: 42190.37225341797
dev_cost_avg: 38.32004745996183
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=O_precision_sent: 0.46875
dev_label=O_recall_sent: 0.13100436681222707
dev_label=O_f-score_sent: 0.20477815699658702
dev_label=N_precision_sent: 0.7019867549668874
dev_label=N_recall_sent: 0.7429906542056075
dev_label=N_f-score_sent: 0.7219069239500567
dev_label=P_precision_sent: 0.6558219178082192
dev_label=P_recall_sent: 0.8626126126126126
dev_label=P_f-score_sent: 0.745136186770428
dev_precision_macro_sent: 0.6088528909250356
dev_recall_macro_sent: 0.578869211210149
dev_f-score_macro_sent: 0.5572737559056906
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.909420498359901
dev_label=O_recall_tok: 0.9751928417155199
dev_label=O_f-score_tok: 0.9411589542016556
dev_label=N_precision_tok: 0.7890094979647219
dev_label=N_recall_tok: 0.626278944534195
dev_label=N_f-score_tok: 0.698288802161513
dev_label=P_precision_tok: 0.9141560049525381
dev_label=P_recall_tok: 0.6896014943960149
dev_label=P_f-score_tok: 0.7861579414374446
dev_precision_macro_tok: 0.8708620004257203
dev_recall_macro_tok: 0.7636910935485766
dev_f-score_macro_tok: 0.8085352326002044
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 8.431764602661133
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4688    0.1310    0.2048       229
           N     0.7020    0.7430    0.7219       428
           P     0.6558    0.8626    0.7451       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.6089    0.5789    0.5573      1101
weighted avg     0.6349    0.6639    0.6237      1101

F1-macro sent:  0.5572737559056906
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9094    0.9752    0.9412     16205
           N     0.7890    0.6263    0.6983      1857
           P     0.9142    0.6896    0.7862      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8709    0.7637    0.8085     21274
weighted avg     0.8996    0.9016    0.8966     21274

F1-macro tok:  0.8085352326002044
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 25
**************************************************

EPOCH: 26
Learning rate: 0.900000
train_cost_sum: 303608.39904785156
train_cost_avg: 35.53469089979536
train_count_sent: 8544.0
train_total_correct_sent: 5814.0
train_accuracy_sent: 0.6804775280898876
train_count_tok: 163566.0
train_total_correct_tok: 147955.0
train_accuracy_tok: 0.9045584045584045
train_label=O_precision_sent: 0.3917525773195876
train_label=O_recall_sent: 0.09359605911330049
train_label=O_f-score_sent: 0.15109343936381708
train_label=N_precision_sent: 0.6619546673165976
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.732766761095373
train_label=P_precision_sent: 0.7268689859363434
train_label=P_recall_sent: 0.8160664819944599
train_label=P_f-score_sent: 0.7688894688764191
train_precision_macro_sent: 0.5935254101908428
train_recall_macro_sent: 0.5767354492514287
train_f-score_macro_sent: 0.5509165564452031
train_precision_micro_sent: 0.6804775280898876
train_recall_micro_sent: 0.6804775280898876
train_f-score_micro_sent: 0.6804775280898876
train_label=O_precision_tok: 0.9154176560444048
train_label=O_recall_tok: 0.9735096142247098
train_label=O_f-score_tok: 0.9435703568018395
train_label=N_precision_tok: 0.8120467536899582
train_label=N_recall_tok: 0.6701872975637234
train_label=N_f-score_tok: 0.734328588512132
train_label=P_precision_tok: 0.8866221247513643
train_label=P_recall_tok: 0.6948874765159692
train_label=P_f-score_tok: 0.7791323054858372
train_precision_macro_tok: 0.8713621781619091
train_recall_macro_tok: 0.7795281294348008
train_f-score_macro_tok: 0.8190104169332696
train_precision_micro_tok: 0.9045584045584045
train_recall_micro_tok: 0.9045584045584045
train_f-score_micro_tok: 0.9045584045584045
train_time: 146.45860385894775
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3918    0.0936    0.1511      1624
           N     0.6620    0.8205    0.7328      3310
           P     0.7269    0.8161    0.7689      3610

   micro avg     0.6805    0.6805    0.6805      8544
   macro avg     0.5935    0.5767    0.5509      8544
weighted avg     0.6380    0.6805    0.6375      8544

F1-macro sent:  0.5509165564452031
F1-micro sent:  0.6804775280898876
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9154    0.9735    0.9436    124347
           N     0.8120    0.6702    0.7343     14202
           P     0.8866    0.6949    0.7791     25017

   micro avg     0.9046    0.9046    0.9046    163566
   macro avg     0.8714    0.7795    0.8190    163566
weighted avg     0.9020    0.9046    0.9003    163566

F1-macro tok:  0.8190104169332696
F1-micro tok:  0.9045584045584045
**************************************************
dev_cost_sum: 42046.71270751953
dev_cost_avg: 38.18956649184335
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19152.0
dev_accuracy_tok: 0.900253830967378
dev_label=O_precision_sent: 0.38461538461538464
dev_label=O_recall_sent: 0.06550218340611354
dev_label=O_f-score_sent: 0.1119402985074627
dev_label=N_precision_sent: 0.6371527777777778
dev_label=N_recall_sent: 0.8574766355140186
dev_label=N_f-score_sent: 0.7310756972111553
dev_label=P_precision_sent: 0.7181069958847737
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7505376344086022
dev_precision_macro_sent: 0.5799583860926454
dev_recall_macro_sent: 0.5696716183187228
dev_f-score_macro_sent: 0.5311845433757401
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.910130530206769
dev_label=O_recall_tok: 0.9724159210120333
dev_label=O_f-score_tok: 0.9402428473403145
dev_label=N_precision_tok: 0.7993031358885018
dev_label=N_recall_tok: 0.6176628971459343
dev_label=N_f-score_tok: 0.6968408262454435
dev_label=P_precision_tok: 0.8899009900990099
dev_label=P_recall_tok: 0.6995641344956414
dev_label=P_f-score_tok: 0.7833362384521527
dev_precision_macro_tok: 0.8664448853980935
dev_recall_macro_tok: 0.7632143175512031
dev_f-score_macro_tok: 0.8068066373459702
dev_precision_micro_tok: 0.900253830967378
dev_recall_micro_tok: 0.900253830967378
dev_f-score_micro_tok: 0.900253830967378
dev_time: 8.377964496612549
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.0655    0.1119       229
           N     0.6372    0.8575    0.7311       428
           P     0.7181    0.7860    0.7505       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.5800    0.5697    0.5312      1101
weighted avg     0.6173    0.6639    0.6101      1101

F1-macro sent:  0.5311845433757401
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9101    0.9724    0.9402     16205
           N     0.7993    0.6177    0.6968      1857
           P     0.8899    0.6996    0.7833      3212

   micro avg     0.9003    0.9003    0.9003     21274
   macro avg     0.8664    0.7632    0.8068     21274
weighted avg     0.8974    0.9003    0.8953     21274

F1-macro tok:  0.8068066373459702
F1-micro tok:  0.900253830967378
**************************************************
Best epoch: 25
**************************************************

EPOCH: 27
Learning rate: 0.900000
train_cost_sum: 302253.2377319336
train_cost_avg: 35.37608119521695
train_count_sent: 8544.0
train_total_correct_sent: 5891.0
train_accuracy_sent: 0.6894897003745318
train_count_tok: 163566.0
train_total_correct_tok: 148048.0
train_accuracy_tok: 0.9051269823802013
train_label=O_precision_sent: 0.4742857142857143
train_label=O_recall_sent: 0.1022167487684729
train_label=O_f-score_sent: 0.16818642350557245
train_label=N_precision_sent: 0.6680518210706429
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.7385488447507095
train_label=P_precision_sent: 0.7292225201072386
train_label=P_recall_sent: 0.8288088642659279
train_label=P_f-score_sent: 0.7758330092052379
train_precision_macro_sent: 0.6238533518211986
train_recall_macro_sent: 0.5855684571141859
train_f-score_macro_sent: 0.5608560924871733
train_precision_micro_sent: 0.6894897003745318
train_recall_micro_sent: 0.6894897003745318
train_f-score_micro_sent: 0.6894897003745318
train_label=O_precision_tok: 0.9167361669219222
train_label=O_recall_tok: 0.9723756906077348
train_label=O_f-score_tok: 0.9437365605035885
train_label=N_precision_tok: 0.8128699475731439
train_label=N_recall_tok: 0.6768764962681313
train_label=N_f-score_tok: 0.7386660519440604
train_label=P_precision_tok: 0.8829487050287211
train_label=P_recall_tok: 0.7004436982851661
train_label=P_f-score_tok: 0.7811782537948867
train_precision_macro_tok: 0.8708516065079291
train_recall_macro_tok: 0.783231961720344
train_f-score_macro_tok: 0.8211936220808451
train_precision_micro_tok: 0.9051269823802013
train_recall_micro_tok: 0.9051269823802013
train_f-score_micro_tok: 0.9051269823802013
train_time: 145.8564784526825
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4743    0.1022    0.1682      1624
           N     0.6681    0.8257    0.7385      3310
           P     0.7292    0.8288    0.7758      3610

   micro avg     0.6895    0.6895    0.6895      8544
   macro avg     0.6239    0.5856    0.5609      8544
weighted avg     0.6571    0.6895    0.6459      8544

F1-macro sent:  0.5608560924871733
F1-micro sent:  0.6894897003745318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9167    0.9724    0.9437    124347
           N     0.8129    0.6769    0.7387     14202
           P     0.8829    0.7004    0.7812     25017

   micro avg     0.9051    0.9051    0.9051    163566
   macro avg     0.8709    0.7832    0.8212    163566
weighted avg     0.9026    0.9051    0.9011    163566

F1-macro tok:  0.8211936220808451
F1-micro tok:  0.9051269823802013
**************************************************
dev_cost_sum: 42090.19348144531
dev_cost_avg: 38.22905856625369
dev_count_sent: 1101.0
dev_total_correct_sent: 738.0
dev_accuracy_sent: 0.670299727520436
dev_count_tok: 21274.0
dev_total_correct_tok: 19189.0
dev_accuracy_tok: 0.9019930431512645
dev_label=O_precision_sent: 0.7857142857142857
dev_label=O_recall_sent: 0.048034934497816595
dev_label=O_f-score_sent: 0.09053497942386832
dev_label=N_precision_sent: 0.6266666666666667
dev_label=N_recall_sent: 0.8785046728971962
dev_label=N_f-score_sent: 0.7315175097276264
dev_label=P_precision_sent: 0.7207392197125256
dev_label=P_recall_sent: 0.7905405405405406
dev_label=P_f-score_sent: 0.7540279269602578
dev_precision_macro_sent: 0.7110400573644927
dev_recall_macro_sent: 0.5723600493118511
dev_f-score_macro_sent: 0.5253601387039175
dev_precision_micro_sent: 0.670299727520436
dev_recall_micro_sent: 0.670299727520436
dev_f-score_micro_sent: 0.670299727520436
dev_label=O_precision_tok: 0.9073734829402336
dev_label=O_recall_tok: 0.9780931811169392
dev_label=O_f-score_tok: 0.9414070620378344
dev_label=N_precision_tok: 0.8005559416261293
dev_label=N_recall_tok: 0.6203554119547657
dev_label=N_f-score_tok: 0.6990291262135923
dev_label=P_precision_tok: 0.9239543726235742
dev_label=P_recall_tok: 0.6808841843088418
dev_label=P_f-score_tok: 0.7840114715898906
dev_precision_macro_tok: 0.8772945990633124
dev_recall_macro_tok: 0.7597775924601823
dev_f-score_macro_tok: 0.8081492199471058
dev_precision_micro_tok: 0.9019930431512645
dev_recall_micro_tok: 0.9019930431512645
dev_f-score_micro_tok: 0.9019930431512645
dev_time: 8.210046529769897
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7857    0.0480    0.0905       229
           N     0.6267    0.8785    0.7315       428
           P     0.7207    0.7905    0.7540       444

   micro avg     0.6703    0.6703    0.6703      1101
   macro avg     0.7110    0.5724    0.5254      1101
weighted avg     0.6977    0.6703    0.6073      1101

F1-macro sent:  0.5253601387039175
F1-micro sent:  0.670299727520436
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9781    0.9414     16205
           N     0.8006    0.6204    0.6990      1857
           P     0.9240    0.6809    0.7840      3212

   micro avg     0.9020    0.9020    0.9020     21274
   macro avg     0.8773    0.7598    0.8081     21274
weighted avg     0.9006    0.9020    0.8965     21274

F1-macro tok:  0.8081492199471058
F1-micro tok:  0.9019930431512645
**************************************************
Best epoch: 25
**************************************************

EPOCH: 28
Learning rate: 0.900000
train_cost_sum: 300362.5656738281
train_cost_avg: 35.15479467156228
train_count_sent: 8544.0
train_total_correct_sent: 5923.0
train_accuracy_sent: 0.6932350187265918
train_count_tok: 163566.0
train_total_correct_tok: 148504.0
train_accuracy_tok: 0.9079148478290109
train_label=O_precision_sent: 0.4784172661870504
train_label=O_recall_sent: 0.08189655172413793
train_label=O_f-score_sent: 0.1398527865404837
train_label=N_precision_sent: 0.6745953898970083
train_label=N_recall_sent: 0.8311178247734139
train_label=N_f-score_sent: 0.7447211694639956
train_label=P_precision_sent: 0.7256446991404012
train_label=P_recall_sent: 0.8418282548476455
train_label=P_f-score_sent: 0.7794306232367273
train_precision_macro_sent: 0.6262191184081533
train_recall_macro_sent: 0.5849475437817324
train_f-score_macro_sent: 0.5546681930804022
train_precision_micro_sent: 0.6932350187265918
train_recall_micro_sent: 0.6932350187265918
train_f-score_micro_sent: 0.6932350187265918
train_label=O_precision_tok: 0.919333515681984
train_label=O_recall_tok: 0.9730753456054428
train_label=O_f-score_tok: 0.9454413333177061
train_label=N_precision_tok: 0.8178697035672416
train_label=N_recall_tok: 0.6877200394310661
train_label=N_f-score_tok: 0.7471695226438189
train_label=P_precision_tok: 0.8865453818472611
train_label=P_recall_tok: 0.7090378542591038
train_label=P_f-score_tok: 0.787917823431427
train_precision_macro_tok: 0.8745828670321621
train_recall_macro_tok: 0.7899444130985375
train_f-score_macro_tok: 0.826842893130984
train_precision_micro_tok: 0.9079148478290109
train_recall_micro_tok: 0.9079148478290109
train_f-score_micro_tok: 0.9079148478290109
train_time: 167.52828574180603
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4784    0.0819    0.1399      1624
           N     0.6746    0.8311    0.7447      3310
           P     0.7256    0.8418    0.7794      3610

   micro avg     0.6932    0.6932    0.6932      8544
   macro avg     0.6262    0.5849    0.5547      8544
weighted avg     0.6589    0.6932    0.6444      8544

F1-macro sent:  0.5546681930804022
F1-micro sent:  0.6932350187265918
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9193    0.9731    0.9454    124347
           N     0.8179    0.6877    0.7472     14202
           P     0.8865    0.7090    0.7879     25017

   micro avg     0.9079    0.9079    0.9079    163566
   macro avg     0.8746    0.7899    0.8268    163566
weighted avg     0.9055    0.9079    0.9041    163566

F1-macro tok:  0.826842893130984
F1-micro tok:  0.9079148478290109
**************************************************
dev_cost_sum: 42108.10467529297
dev_cost_avg: 38.24532668055674
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19197.0
dev_accuracy_tok: 0.9023690890288615
dev_label=O_precision_sent: 0.38461538461538464
dev_label=O_recall_sent: 0.15283842794759825
dev_label=O_f-score_sent: 0.21875
dev_label=N_precision_sent: 0.6524953789279113
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7285861713106295
dev_label=P_precision_sent: 0.7313432835820896
dev_label=P_recall_sent: 0.7725225225225225
dev_label=P_f-score_sent: 0.7513691128148959
dev_precision_macro_sent: 0.5894846823751285
dev_recall_macro_sent: 0.5833757685367692
dev_f-score_macro_sent: 0.5662350947085085
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9072855262404853
dev_label=O_recall_tok: 0.9782783091638383
dev_label=O_f-score_tok: 0.9414454540055822
dev_label=N_precision_tok: 0.8186416184971098
dev_label=N_recall_tok: 0.6101238556812062
dev_label=N_f-score_tok: 0.6991669237889541
dev_label=P_precision_tok: 0.9147703764997931
dev_label=P_recall_tok: 0.6883561643835616
dev_label=P_f-score_tok: 0.7855747024338249
dev_precision_macro_tok: 0.8802325070791294
dev_recall_macro_tok: 0.7589194430762021
dev_f-score_macro_tok: 0.8087290267427871
dev_precision_micro_tok: 0.9023690890288615
dev_recall_micro_tok: 0.9023690890288615
dev_f-score_micro_tok: 0.9023690890288615
dev_time: 11.733083724975586
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.1528    0.2188       229
           N     0.6525    0.8248    0.7286       428
           P     0.7313    0.7725    0.7514       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.5895    0.5834    0.5662      1101
weighted avg     0.6286    0.6639    0.6317      1101

F1-macro sent:  0.5662350947085085
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9073    0.9783    0.9414     16205
           N     0.8186    0.6101    0.6992      1857
           P     0.9148    0.6884    0.7856      3212

   micro avg     0.9024    0.9024    0.9024     21274
   macro avg     0.8802    0.7589    0.8087     21274
weighted avg     0.9007    0.9024    0.8968     21274

F1-macro tok:  0.8087290267427871
F1-micro tok:  0.9023690890288615
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.900000
train_cost_sum: 299551.6160888672
train_cost_avg: 35.05988016021386
train_count_sent: 8544.0
train_total_correct_sent: 5859.0
train_accuracy_sent: 0.6857443820224719
train_count_tok: 163566.0
train_total_correct_tok: 148773.0
train_accuracy_tok: 0.9095594438942078
train_label=O_precision_sent: 0.44126074498567336
train_label=O_recall_sent: 0.09482758620689655
train_label=O_f-score_sent: 0.1561074505828687
train_label=N_precision_sent: 0.6672384219554031
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7368421052631579
train_label=P_precision_sent: 0.7248420029168692
train_label=P_recall_sent: 0.8260387811634349
train_label=P_f-score_sent: 0.7721387881926464
train_precision_macro_sent: 0.6111137232859819
train_recall_macro_sent: 0.5811749925474116
train_f-score_macro_sent: 0.555029448012891
train_precision_micro_sent: 0.6857443820224719
train_recall_micro_sent: 0.6857443820224719
train_f-score_micro_sent: 0.6857443820224719
train_label=O_precision_tok: 0.9208714112875611
train_label=O_recall_tok: 0.973244227846269
train_label=O_f-score_tok: 0.9463337582008554
train_label=N_precision_tok: 0.8228379513014273
train_label=N_recall_tok: 0.6900436558231235
train_label=N_f-score_tok: 0.7506127450980393
train_label=P_precision_tok: 0.8871374215545782
train_label=P_recall_tok: 0.7176320102330416
train_label=P_f-score_tok: 0.7934326247403545
train_precision_macro_tok: 0.8769489280478556
train_recall_macro_tok: 0.7936399646341448
train_f-score_macro_tok: 0.8301263760130831
train_precision_micro_tok: 0.9095594438942078
train_recall_micro_tok: 0.9095594438942078
train_f-score_micro_tok: 0.9095594438942078
train_time: 198.79645228385925
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4413    0.0948    0.1561      1624
           N     0.6672    0.8227    0.7368      3310
           P     0.7248    0.8260    0.7721      3610

   micro avg     0.6857    0.6857    0.6857      8544
   macro avg     0.6111    0.5812    0.5550      8544
weighted avg     0.6486    0.6857    0.6414      8544

F1-macro sent:  0.555029448012891
F1-micro sent:  0.6857443820224719
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9209    0.9732    0.9463    124347
           N     0.8228    0.6900    0.7506     14202
           P     0.8871    0.7176    0.7934     25017

   micro avg     0.9096    0.9096    0.9096    163566
   macro avg     0.8769    0.7936    0.8301    163566
weighted avg     0.9072    0.9096    0.9060    163566

F1-macro tok:  0.8301263760130831
F1-micro tok:  0.9095594438942078
**************************************************
dev_cost_sum: 42044.63818359375
dev_cost_avg: 38.18768227392711
dev_count_sent: 1101.0
dev_total_correct_sent: 708.0
dev_accuracy_sent: 0.6430517711171662
dev_count_tok: 21274.0
dev_total_correct_tok: 19084.0
dev_accuracy_tok: 0.8970574410078029
dev_label=O_precision_sent: 0.47368421052631576
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07258064516129031
dev_label=N_precision_sent: 0.7410256410256411
dev_label=N_recall_sent: 0.6752336448598131
dev_label=N_f-score_sent: 0.7066014669926651
dev_label=P_precision_sent: 0.5924855491329479
dev_label=P_recall_sent: 0.9234234234234234
dev_label=P_f-score_sent: 0.7218309859154929
dev_precision_macro_sent: 0.6023984668949682
dev_recall_macro_sent: 0.5459861261089682
dev_f-score_macro_sent: 0.5003376993564829
dev_precision_micro_sent: 0.6430517711171662
dev_recall_micro_sent: 0.6430517711171662
dev_f-score_micro_sent: 0.6430517711171662
dev_label=O_precision_tok: 0.9180830972615676
dev_label=O_recall_tok: 0.9599506325208269
dev_label=O_f-score_tok: 0.9385501825092764
dev_label=N_precision_tok: 0.7618741976893453
dev_label=N_recall_tok: 0.6392030156165859
dev_label=N_f-score_tok: 0.6951683748169839
dev_label=P_precision_tok: 0.8445165945165946
dev_label=P_recall_tok: 0.7288293897882939
dev_label=P_f-score_tok: 0.7824197860962567
dev_precision_macro_tok: 0.8414912964891692
dev_recall_macro_tok: 0.7759943459752355
dev_f-score_macro_tok: 0.8053794478075057
dev_precision_micro_tok: 0.8970574410078029
dev_recall_micro_tok: 0.8970574410078029
dev_f-score_micro_tok: 0.8970574410078029
dev_time: 11.869791746139526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4737    0.0393    0.0726       229
           N     0.7410    0.6752    0.7066       428
           P     0.5925    0.9234    0.7218       444

   micro avg     0.6431    0.6431    0.6431      1101
   macro avg     0.6024    0.5460    0.5003      1101
weighted avg     0.6255    0.6431    0.5809      1101

F1-macro sent:  0.5003376993564829
F1-micro sent:  0.6430517711171662
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9181    0.9600    0.9386     16205
           N     0.7619    0.6392    0.6952      1857
           P     0.8445    0.7288    0.7824      3212

   micro avg     0.8971    0.8971    0.8971     21274
   macro avg     0.8415    0.7760    0.8054     21274
weighted avg     0.8933    0.8971    0.8937     21274

F1-macro tok:  0.8053794478075057
F1-micro tok:  0.8970574410078029
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.900000
train_cost_sum: 298196.82037353516
train_cost_avg: 34.90131324596619
train_count_sent: 8544.0
train_total_correct_sent: 5936.0
train_accuracy_sent: 0.6947565543071161
train_count_tok: 163566.0
train_total_correct_tok: 148932.0
train_accuracy_tok: 0.9105315285572796
train_label=O_precision_sent: 0.44476744186046513
train_label=O_recall_sent: 0.09421182266009852
train_label=O_f-score_sent: 0.15548780487804878
train_label=N_precision_sent: 0.6740196078431373
train_label=N_recall_sent: 0.8308157099697885
train_label=N_f-score_sent: 0.7442489851150204
train_label=P_precision_sent: 0.7361650485436894
train_label=P_recall_sent: 0.8401662049861496
train_label=P_f-score_sent: 0.7847347994825355
train_precision_macro_sent: 0.6183173660824305
train_recall_macro_sent: 0.5883979125386789
train_f-score_macro_sent: 0.5614905298252015
train_precision_micro_sent: 0.6947565543071161
train_recall_micro_sent: 0.6947565543071161
train_f-score_micro_sent: 0.6947565543071161
train_label=O_precision_tok: 0.9225958018061997
train_label=O_recall_tok: 0.9727295391123227
train_label=O_f-score_tok: 0.9469996202794273
train_label=N_precision_tok: 0.822658060244952
train_label=N_recall_tok: 0.6999718349528236
train_label=N_f-score_tok: 0.7563722133455071
train_label=P_precision_tok: 0.8850230640887231
train_label=P_recall_tok: 0.7209097813486829
train_label=P_f-score_tok: 0.7945809009802841
train_precision_macro_tok: 0.8767589753799583
train_recall_macro_tok: 0.7978703851379431
train_f-score_macro_tok: 0.8326509115350729
train_precision_micro_tok: 0.9105315285572796
train_recall_micro_tok: 0.9105315285572796
train_f-score_micro_tok: 0.9105315285572796
train_time: 198.52485632896423
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4448    0.0942    0.1555      1624
           N     0.6740    0.8308    0.7442      3310
           P     0.7362    0.8402    0.7847      3610

   micro avg     0.6948    0.6948    0.6948      8544
   macro avg     0.6183    0.5884    0.5615      8544
weighted avg     0.6567    0.6948    0.6494      8544

F1-macro sent:  0.5614905298252015
F1-micro sent:  0.6947565543071161
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9226    0.9727    0.9470    124347
           N     0.8227    0.7000    0.7564     14202
           P     0.8850    0.7209    0.7946     25017

   micro avg     0.9105    0.9105    0.9105    163566
   macro avg     0.8768    0.7979    0.8327    163566
weighted avg     0.9082    0.9105    0.9071    163566

F1-macro tok:  0.8326509115350729
F1-micro tok:  0.9105315285572796
**************************************************
dev_cost_sum: 42054.70458984375
dev_cost_avg: 38.196825240548364
dev_count_sent: 1101.0
dev_total_correct_sent: 742.0
dev_accuracy_sent: 0.6739327883742052
dev_count_tok: 21274.0
dev_total_correct_tok: 19190.0
dev_accuracy_tok: 0.9020400488859641
dev_label=O_precision_sent: 0.4426229508196721
dev_label=O_recall_sent: 0.11790393013100436
dev_label=O_f-score_sent: 0.18620689655172415
dev_label=N_precision_sent: 0.6451048951048951
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.738
dev_label=P_precision_sent: 0.7393162393162394
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7587719298245615
dev_precision_macro_sent: 0.6090146950802688
dev_recall_macro_sent: 0.5864442473735213
dev_f-score_macro_sent: 0.5609929421254286
dev_precision_micro_sent: 0.6739327883742052
dev_recall_micro_sent: 0.6739327883742052
dev_f-score_micro_sent: 0.6739327883742052
dev_label=O_precision_tok: 0.9095613177715173
dev_label=O_recall_tok: 0.9762419006479481
dev_label=O_f-score_tok: 0.9417227215905709
dev_label=N_precision_tok: 0.8192419825072886
dev_label=N_recall_tok: 0.6052773290253096
dev_label=N_f-score_tok: 0.6961907711365748
dev_label=P_precision_tok: 0.895177361498605
dev_label=P_recall_tok: 0.699252801992528
dev_label=P_f-score_tok: 0.7851774165355707
dev_precision_macro_tok: 0.8746602205924704
dev_recall_macro_tok: 0.7602573438885952
dev_f-score_macro_tok: 0.8076969697542388
dev_precision_micro_tok: 0.9020400488859641
dev_recall_micro_tok: 0.9020400488859641
dev_f-score_micro_tok: 0.9020400488859641
dev_time: 11.828201055526733
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4426    0.1179    0.1862       229
           N     0.6451    0.8621    0.7380       428
           P     0.7393    0.7793    0.7588       444

   micro avg     0.6739    0.6739    0.6739      1101
   macro avg     0.6090    0.5864    0.5610      1101
weighted avg     0.6410    0.6739    0.6316      1101

F1-macro sent:  0.5609929421254286
F1-micro sent:  0.6739327883742052
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9096    0.9762    0.9417     16205
           N     0.8192    0.6053    0.6962      1857
           P     0.8952    0.6993    0.7852      3212

   micro avg     0.9020    0.9020    0.9020     21274
   macro avg     0.8747    0.7603    0.8077     21274
weighted avg     0.8995    0.9020    0.8967     21274

F1-macro tok:  0.8076969697542388
F1-micro tok:  0.9020400488859641
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.900000
train_cost_sum: 296782.4694824219
train_cost_avg: 34.7357759225681
train_count_sent: 8544.0
train_total_correct_sent: 5921.0
train_accuracy_sent: 0.693000936329588
train_count_tok: 163566.0
train_total_correct_tok: 149199.0
train_accuracy_tok: 0.912163897142438
train_label=O_precision_sent: 0.423841059602649
train_label=O_recall_sent: 0.11822660098522167
train_label=O_f-score_sent: 0.18488204140587383
train_label=N_precision_sent: 0.6816143497757847
train_label=N_recall_sent: 0.8265861027190332
train_label=N_f-score_sent: 0.7471327143637355
train_label=P_precision_sent: 0.7341182241844494
train_label=P_recall_sent: 0.8290858725761773
train_label=P_f-score_sent: 0.7787173149473137
train_precision_macro_sent: 0.6131912111876278
train_recall_macro_sent: 0.5912995254268107
train_f-score_macro_sent: 0.5702440235723077
train_precision_micro_sent: 0.693000936329588
train_recall_micro_sent: 0.693000936329588
train_f-score_micro_sent: 0.693000936329588
train_label=O_precision_tok: 0.9242567825754681
train_label=O_recall_tok: 0.9725928249173683
train_label=O_f-score_tok: 0.9478089475973462
train_label=N_precision_tok: 0.8252864157119476
train_label=N_recall_tok: 0.7101112519363469
train_label=N_f-score_tok: 0.7633790023465294
train_label=P_precision_tok: 0.8867583918813428
train_label=P_recall_tok: 0.7265059759363632
train_label=P_f-score_tok: 0.7986729066420583
train_precision_macro_tok: 0.8787671967229195
train_recall_macro_tok: 0.8030700175966928
train_f-score_macro_tok: 0.8366202855286446
train_precision_micro_tok: 0.912163897142438
train_recall_micro_tok: 0.912163897142438
train_f-score_micro_tok: 0.912163897142438
train_time: 198.88405060768127
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4238    0.1182    0.1849      1624
           N     0.6816    0.8266    0.7471      3310
           P     0.7341    0.8291    0.7787      3610

   micro avg     0.6930    0.6930    0.6930      8544
   macro avg     0.6132    0.5913    0.5702      8544
weighted avg     0.6548    0.6930    0.6536      8544

F1-macro sent:  0.5702440235723077
F1-micro sent:  0.693000936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9243    0.9726    0.9478    124347
           N     0.8253    0.7101    0.7634     14202
           P     0.8868    0.7265    0.7987     25017

   micro avg     0.9122    0.9122    0.9122    163566
   macro avg     0.8788    0.8031    0.8366    163566
weighted avg     0.9099    0.9122    0.9090    163566

F1-macro tok:  0.8366202855286446
F1-micro tok:  0.912163897142438
**************************************************
dev_cost_sum: 41947.61706542969
dev_cost_avg: 38.099561367329414
dev_count_sent: 1101.0
dev_total_correct_sent: 730.0
dev_accuracy_sent: 0.6630336058128974
dev_count_tok: 21274.0
dev_total_correct_tok: 19202.0
dev_accuracy_tok: 0.9026041177023597
dev_label=O_precision_sent: 0.75
dev_label=O_recall_sent: 0.039301310043668124
dev_label=O_f-score_sent: 0.07468879668049792
dev_label=N_precision_sent: 0.5984732824427481
dev_label=N_recall_sent: 0.9158878504672897
dev_label=N_f-score_sent: 0.723915050784857
dev_label=P_precision_sent: 0.7580645161290323
dev_label=P_recall_sent: 0.740990990990991
dev_label=P_f-score_sent: 0.7494305239179956
dev_precision_macro_sent: 0.7021792661905936
dev_recall_macro_sent: 0.565393383833983
dev_f-score_macro_sent: 0.5160114571277835
dev_precision_micro_sent: 0.6630336058128974
dev_recall_micro_sent: 0.6630336058128974
dev_f-score_micro_sent: 0.6630336058128974
dev_label=O_precision_tok: 0.911890455280795
dev_label=O_recall_tok: 0.9739586547361926
dev_label=O_f-score_tok: 0.9419031420642736
dev_label=N_precision_tok: 0.7887323943661971
dev_label=N_recall_tok: 0.6332794830371568
dev_label=N_f-score_tok: 0.7025089605734767
dev_label=P_precision_tok: 0.9062626262626262
dev_label=P_recall_tok: 0.6983188044831881
dev_label=P_f-score_tok: 0.7888165992614735
dev_precision_macro_tok: 0.8689618253032062
dev_recall_macro_tok: 0.7685189807521792
dev_f-score_macro_tok: 0.8110762339664079
dev_precision_micro_tok: 0.9026041177023597
dev_recall_micro_tok: 0.9026041177023597
dev_f-score_micro_tok: 0.9026041177023597
dev_time: 11.737962484359741
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.7500    0.0393    0.0747       229
           N     0.5985    0.9159    0.7239       428
           P     0.7581    0.7410    0.7494       444

   micro avg     0.6630    0.6630    0.6630      1101
   macro avg     0.7022    0.5654    0.5160      1101
weighted avg     0.6943    0.6630    0.5992      1101

F1-macro sent:  0.5160114571277835
F1-micro sent:  0.6630336058128974
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9119    0.9740    0.9419     16205
           N     0.7887    0.6333    0.7025      1857
           P     0.9063    0.6983    0.7888      3212

   micro avg     0.9026    0.9026    0.9026     21274
   macro avg     0.8690    0.7685    0.8111     21274
weighted avg     0.9003    0.9026    0.8979     21274

F1-macro tok:  0.8110762339664079
F1-micro tok:  0.9026041177023597
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.900000
train_cost_sum: 295683.1040649414
train_cost_avg: 34.607104876514676
train_count_sent: 8544.0
train_total_correct_sent: 5958.0
train_accuracy_sent: 0.6973314606741573
train_count_tok: 163566.0
train_total_correct_tok: 149404.0
train_accuracy_tok: 0.9134172138463984
train_label=O_precision_sent: 0.48955223880597015
train_label=O_recall_sent: 0.10098522167487685
train_label=O_f-score_sent: 0.1674323634507402
train_label=N_precision_sent: 0.677173110071411
train_label=N_recall_sent: 0.8308157099697885
train_label=N_f-score_sent: 0.7461674128340795
train_label=P_precision_sent: 0.733847637415622
train_label=P_recall_sent: 0.843213296398892
train_label=P_f-score_sent: 0.7847383346223252
train_precision_macro_sent: 0.6335243287643344
train_recall_macro_sent: 0.5916714093478525
train_f-score_macro_sent: 0.566112703635715
train_precision_micro_sent: 0.6973314606741573
train_recall_micro_sent: 0.6973314606741573
train_f-score_micro_sent: 0.6973314606741573
train_label=O_precision_tok: 0.9257952693240689
train_label=O_recall_tok: 0.9729386314104884
train_label=O_f-score_tok: 0.9487816928470039
train_label=N_precision_tok: 0.8294776424425734
train_label=N_recall_tok: 0.7144768342486973
train_label=N_f-score_tok: 0.7676943446188765
train_label=P_precision_tok: 0.884816500435751
train_label=P_recall_tok: 0.7305032577847064
train_label=P_f-score_tok: 0.8002890236692868
train_precision_macro_tok: 0.8800298040674644
train_recall_macro_tok: 0.8059729078146307
train_f-score_macro_tok: 0.8389216870450557
train_precision_micro_tok: 0.9134172138463984
train_recall_micro_tok: 0.9134172138463984
train_f-score_micro_tok: 0.9134172138463984
train_time: 198.69978189468384
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4896    0.1010    0.1674      1624
           N     0.6772    0.8308    0.7462      3310
           P     0.7338    0.8432    0.7847      3610

   micro avg     0.6973    0.6973    0.6973      8544
   macro avg     0.6335    0.5917    0.5661      8544
weighted avg     0.6655    0.6973    0.6525      8544

F1-macro sent:  0.566112703635715
F1-micro sent:  0.6973314606741573
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9258    0.9729    0.9488    124347
           N     0.8295    0.7145    0.7677     14202
           P     0.8848    0.7305    0.8003     25017

   micro avg     0.9134    0.9134    0.9134    163566
   macro avg     0.8800    0.8060    0.8389    163566
weighted avg     0.9112    0.9134    0.9103    163566

F1-macro tok:  0.8389216870450557
F1-micro tok:  0.9134172138463984
**************************************************
dev_cost_sum: 41898.618225097656
dev_cost_avg: 38.05505742515682
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=O_precision_sent: 0.3333333333333333
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.09701492537313432
dev_label=N_precision_sent: 0.680327868852459
dev_label=N_recall_sent: 0.7757009345794392
dev_label=N_f-score_sent: 0.7248908296943232
dev_label=P_precision_sent: 0.6655052264808362
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.75049115913556
dev_precision_macro_sent: 0.5597221428888761
dev_recall_macro_sent: 0.5642766179639215
dev_f-score_macro_sent: 0.5241323047343391
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9105906783571758
dev_label=O_recall_tok: 0.9741437827830917
dev_label=O_f-score_tok: 0.9412957276169464
dev_label=N_precision_tok: 0.8098290598290598
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6973321067157314
dev_label=P_precision_tok: 0.8910812943962115
dev_label=P_recall_tok: 0.702988792029888
dev_label=P_f-score_tok: 0.7859380438565959
dev_precision_macro_tok: 0.870500344194149
dev_recall_macro_tok: 0.7631368141137503
dev_f-score_macro_tok: 0.8081886260630912
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 11.742534399032593
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0568    0.0970       229
           N     0.6803    0.7757    0.7249       428
           P     0.6655    0.8604    0.7505       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.5597    0.5643    0.5241      1101
weighted avg     0.6022    0.6603    0.6046      1101

F1-macro sent:  0.5241323047343391
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9106    0.9741    0.9413     16205
           N     0.8098    0.6123    0.6973      1857
           P     0.8911    0.7030    0.7859      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8705    0.7631    0.8082     21274
weighted avg     0.8988    0.9016    0.8965     21274

F1-macro tok:  0.8081886260630912
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.810000
train_cost_sum: 293583.2014770508
train_cost_avg: 34.361329760890776
train_count_sent: 8544.0
train_total_correct_sent: 5982.0
train_accuracy_sent: 0.7001404494382022
train_count_tok: 163566.0
train_total_correct_tok: 149856.0
train_accuracy_tok: 0.9161806243351308
train_label=O_precision_sent: 0.4475703324808184
train_label=O_recall_sent: 0.10775862068965517
train_label=O_f-score_sent: 0.173697270471464
train_label=N_precision_sent: 0.6809242871189773
train_label=N_recall_sent: 0.8368580060422961
train_label=N_f-score_sent: 0.7508809975603145
train_label=P_precision_sent: 0.7434516523867809
train_label=P_recall_sent: 0.8412742382271469
train_label=P_f-score_sent: 0.789343729694607
train_precision_macro_sent: 0.6239820906621922
train_recall_macro_sent: 0.595296954986366
train_f-score_macro_sent: 0.5713073325754618
train_precision_micro_sent: 0.7001404494382022
train_recall_micro_sent: 0.7001404494382022
train_f-score_micro_sent: 0.7001404494382022
train_label=O_precision_tok: 0.9285248267233638
train_label=O_recall_tok: 0.9728501692843414
train_label=O_f-score_tok: 0.9501708361151474
train_label=N_precision_tok: 0.8348527632109721
train_label=N_recall_tok: 0.7286297704548655
train_label=N_f-score_tok: 0.7781328721284355
train_label=P_precision_tok: 0.8874473381846036
train_label=P_recall_tok: 0.7409761362273654
train_label=P_f-score_tok: 0.8076244417819409
train_precision_macro_tok: 0.8836083093729798
train_recall_macro_tok: 0.8141520253221907
train_f-score_macro_tok: 0.8453093833418412
train_precision_micro_tok: 0.9161806243351308
train_recall_micro_tok: 0.9161806243351308
train_f-score_micro_tok: 0.9161806243351308
train_time: 198.35654640197754
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4476    0.1078    0.1737      1624
           N     0.6809    0.8369    0.7509      3310
           P     0.7435    0.8413    0.7893      3610

   micro avg     0.7001    0.7001    0.7001      8544
   macro avg     0.6240    0.5953    0.5713      8544
weighted avg     0.6630    0.7001    0.6574      8544

F1-macro sent:  0.5713073325754618
F1-micro sent:  0.7001404494382022
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9285    0.9729    0.9502    124347
           N     0.8349    0.7286    0.7781     14202
           P     0.8874    0.7410    0.8076     25017

   micro avg     0.9162    0.9162    0.9162    163566
   macro avg     0.8836    0.8142    0.8453    163566
weighted avg     0.9141    0.9162    0.9134    163566

F1-macro tok:  0.8453093833418412
F1-micro tok:  0.9161806243351308
**************************************************
dev_cost_sum: 42008.074157714844
dev_cost_avg: 38.1544724411579
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19194.0
dev_accuracy_tok: 0.9022280718247626
dev_label=O_precision_sent: 0.5294117647058824
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.13688212927756654
dev_label=N_precision_sent: 0.70020964360587
dev_label=N_recall_sent: 0.780373831775701
dev_label=N_f-score_sent: 0.7381215469613259
dev_label=P_precision_sent: 0.6593220338983051
dev_label=P_recall_sent: 0.8761261261261262
dev_label=P_f-score_sent: 0.7524177949709866
dev_precision_macro_sent: 0.6296478140700191
dev_recall_macro_sent: 0.5783675259963877
dev_f-score_macro_sent: 0.5424738237366263
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9099384243540312
dev_label=O_recall_tok: 0.9757482258562172
dev_label=O_f-score_tok: 0.9416949556309927
dev_label=N_precision_tok: 0.806064880112835
dev_label=N_recall_tok: 0.6155088852988692
dev_label=N_f-score_tok: 0.6980152671755724
dev_label=P_precision_tok: 0.9031867688584106
dev_label=P_recall_tok: 0.6970734744707348
dev_label=P_f-score_tok: 0.7868564399929714
dev_precision_macro_tok: 0.8730633577750923
dev_recall_macro_tok: 0.7627768618752736
dev_f-score_macro_tok: 0.8088555542665121
dev_precision_micro_tok: 0.9022280718247626
dev_recall_micro_tok: 0.9022280718247626
dev_f-score_micro_tok: 0.9022280718247626
dev_time: 11.757360458374023
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5294    0.0786    0.1369       229
           N     0.7002    0.7804    0.7381       428
           P     0.6593    0.8761    0.7524       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6296    0.5784    0.5425      1101
weighted avg     0.6482    0.6730    0.6188      1101

F1-macro sent:  0.5424738237366263
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9099    0.9757    0.9417     16205
           N     0.8061    0.6155    0.6980      1857
           P     0.9032    0.6971    0.7869      3212

   micro avg     0.9022    0.9022    0.9022     21274
   macro avg     0.8731    0.7628    0.8089     21274
weighted avg     0.8999    0.9022    0.8970     21274

F1-macro tok:  0.8088555542665121
F1-micro tok:  0.9022280718247626
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.729000
train_cost_sum: 292720.0651855469
train_cost_avg: 34.260307254862695
train_count_sent: 8544.0
train_total_correct_sent: 6003.0
train_accuracy_sent: 0.7025983146067416
train_count_tok: 163566.0
train_total_correct_tok: 150040.0
train_accuracy_tok: 0.9173055524986855
train_label=O_precision_sent: 0.46798029556650245
train_label=O_recall_sent: 0.11699507389162561
train_label=O_f-score_sent: 0.18719211822660095
train_label=N_precision_sent: 0.6767554479418886
train_label=N_recall_sent: 0.8444108761329305
train_label=N_f-score_sent: 0.7513440860215054
train_label=P_precision_sent: 0.7529940119760479
train_label=P_recall_sent: 0.83601108033241
train_label=P_f-score_sent: 0.7923339459175636
train_precision_macro_sent: 0.6325765851614796
train_recall_macro_sent: 0.5991390101189887
train_f-score_macro_sent: 0.57695671672189
train_precision_micro_sent: 0.7025983146067416
train_recall_micro_sent: 0.7025983146067416
train_f-score_micro_sent: 0.7025983146067416
train_label=O_precision_tok: 0.929669198688162
train_label=O_recall_tok: 0.973421152098563
train_label=O_f-score_tok: 0.9510422477666121
train_label=N_precision_tok: 0.8320032245062475
train_label=N_recall_tok: 0.7267286297704548
train_label=N_f-score_tok: 0.7758108768369226
train_label=P_precision_tok: 0.8909932258372293
train_label=P_recall_tok: 0.7465723308150458
train_label=P_f-score_tok: 0.8124143630787968
train_precision_macro_tok: 0.8842218830105463
train_recall_macro_tok: 0.8155740375613544
train_f-score_macro_tok: 0.8464224958941106
train_precision_micro_tok: 0.9173055524986855
train_recall_micro_tok: 0.9173055524986855
train_f-score_micro_tok: 0.9173055524986855
train_time: 198.10142469406128
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4680    0.1170    0.1872      1624
           N     0.6768    0.8444    0.7513      3310
           P     0.7530    0.8360    0.7923      3610

   micro avg     0.7026    0.7026    0.7026      8544
   macro avg     0.6326    0.5991    0.5770      8544
weighted avg     0.6693    0.7026    0.6614      8544

F1-macro sent:  0.57695671672189
F1-micro sent:  0.7025983146067416
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9297    0.9734    0.9510    124347
           N     0.8320    0.7267    0.7758     14202
           P     0.8910    0.7466    0.8124     25017

   micro avg     0.9173    0.9173    0.9173    163566
   macro avg     0.8842    0.8156    0.8464    163566
weighted avg     0.9153    0.9173    0.9146    163566

F1-macro tok:  0.8464224958941106
F1-micro tok:  0.9173055524986855
**************************************************
dev_cost_sum: 42008.08917236328
dev_cost_avg: 38.15448607844076
dev_count_sent: 1101.0
dev_total_correct_sent: 741.0
dev_accuracy_sent: 0.6730245231607629
dev_count_tok: 21274.0
dev_total_correct_tok: 19111.0
dev_accuracy_tok: 0.8983265958446931
dev_label=O_precision_sent: 0.5882352941176471
dev_label=O_recall_sent: 0.08733624454148471
dev_label=O_f-score_sent: 0.1520912547528517
dev_label=N_precision_sent: 0.643979057591623
dev_label=N_recall_sent: 0.8621495327102804
dev_label=N_f-score_sent: 0.7372627372627374
dev_label=P_precision_sent: 0.7125506072874493
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7505330490405118
dev_precision_macro_sent: 0.6482549863322399
dev_recall_macro_sent: 0.580759523348186
dev_f-score_macro_sent: 0.546629013685367
dev_precision_micro_sent: 0.6730245231607629
dev_recall_micro_sent: 0.6730245231607629
dev_f-score_micro_sent: 0.6730245231607629
dev_label=O_precision_tok: 0.9147554411420548
dev_label=O_recall_tok: 0.9648256710891701
dev_label=O_f-score_tok: 0.9391236447728024
dev_label=N_precision_tok: 0.790994623655914
dev_label=N_recall_tok: 0.633817985998923
dev_label=N_f-score_tok: 0.7037369207772797
dev_label=P_precision_tok: 0.8533778767631774
dev_label=P_recall_tok: 0.7157534246575342
dev_label=P_f-score_tok: 0.7785303081611921
dev_precision_macro_tok: 0.8530426471870488
dev_recall_macro_tok: 0.771465693915209
dev_f-score_macro_tok: 0.8071302912370913
dev_precision_micro_tok: 0.8983265958446931
dev_recall_micro_tok: 0.8983265958446931
dev_f-score_micro_tok: 0.8983265958446931
dev_time: 11.785958528518677
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5882    0.0873    0.1521       229
           N     0.6440    0.8621    0.7373       428
           P     0.7126    0.7928    0.7505       444

   micro avg     0.6730    0.6730    0.6730      1101
   macro avg     0.6483    0.5808    0.5466      1101
weighted avg     0.6600    0.6730    0.6209      1101

F1-macro sent:  0.546629013685367
F1-micro sent:  0.6730245231607629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9148    0.9648    0.9391     16205
           N     0.7910    0.6338    0.7037      1857
           P     0.8534    0.7158    0.7785      3212

   micro avg     0.8983    0.8983    0.8983     21274
   macro avg     0.8530    0.7715    0.8071     21274
weighted avg     0.8947    0.8983    0.8943     21274

F1-macro tok:  0.8071302912370913
F1-micro tok:  0.8983265958446931
**************************************************
Best epoch: 28
**************************************************

EPOCH: 35
Learning rate: 0.656100
train_cost_sum: 291486.9528808594
train_cost_avg: 34.11598231283467
train_count_sent: 8544.0
train_total_correct_sent: 5998.0
train_accuracy_sent: 0.7020131086142322
train_count_tok: 163566.0
train_total_correct_tok: 150426.0
train_accuracy_tok: 0.9196654561461428
train_label=O_precision_sent: 0.43655913978494626
train_label=O_recall_sent: 0.125
train_label=O_f-score_sent: 0.19435136428913358
train_label=N_precision_sent: 0.6909182137481185
train_label=N_recall_sent: 0.83202416918429
train_label=N_f-score_sent: 0.7549342105263158
train_label=P_precision_sent: 0.7429758123625703
train_label=P_recall_sent: 0.842382271468144
train_label=P_f-score_sent: 0.789562508113722
train_precision_macro_sent: 0.6234843886318783
train_recall_macro_sent: 0.5998021468841447
train_f-score_macro_sent: 0.5796160276430572
train_precision_micro_sent: 0.7020131086142322
train_recall_micro_sent: 0.7020131086142322
train_f-score_micro_sent: 0.7020131086142322
train_label=O_precision_tok: 0.932039657003864
train_label=O_recall_tok: 0.9737669585916829
train_label=O_f-score_tok: 0.9524465018229299
train_label=N_precision_tok: 0.8359399936163422
train_label=N_recall_tok: 0.7376425855513308
train_label=N_f-score_tok: 0.783721104211865
train_label=P_precision_tok: 0.8932291666666666
train_label=P_recall_tok: 0.7540872206899308
train_label=P_f-score_tok: 0.8177818236989834
train_precision_macro_tok: 0.8870696057622909
train_recall_macro_tok: 0.8218322549443148
train_f-score_macro_tok: 0.8513164765779261
train_precision_micro_tok: 0.9196654561461428
train_recall_micro_tok: 0.9196654561461428
train_f-score_micro_tok: 0.9196654561461428
train_time: 198.24921131134033
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4366    0.1250    0.1944      1624
           N     0.6909    0.8320    0.7549      3310
           P     0.7430    0.8424    0.7896      3610

   micro avg     0.7020    0.7020    0.7020      8544
   macro avg     0.6235    0.5998    0.5796      8544
weighted avg     0.6646    0.7020    0.6630      8544

F1-macro sent:  0.5796160276430572
F1-micro sent:  0.7020131086142322
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9320    0.9738    0.9524    124347
           N     0.8359    0.7376    0.7837     14202
           P     0.8932    0.7541    0.8178     25017

   micro avg     0.9197    0.9197    0.9197    163566
   macro avg     0.8871    0.8218    0.8513    163566
weighted avg     0.9178    0.9197    0.9172    163566

F1-macro tok:  0.8513164765779261
F1-micro tok:  0.9196654561461428
**************************************************
dev_cost_sum: 41983.885986328125
dev_cost_avg: 38.13250316651056
dev_count_sent: 1101.0
dev_total_correct_sent: 736.0
dev_accuracy_sent: 0.6684831970935513
dev_count_tok: 21274.0
dev_total_correct_tok: 19145.0
dev_accuracy_tok: 0.8999247908244806
dev_label=O_precision_sent: 0.5833333333333334
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05809128630705394
dev_label=N_precision_sent: 0.6756238003838771
dev_label=N_recall_sent: 0.822429906542056
dev_label=N_f-score_sent: 0.7418335089567966
dev_label=P_precision_sent: 0.6637323943661971
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7450592885375494
dev_precision_macro_sent: 0.640896509361136
dev_recall_macro_sent: 0.5673655637435583
dev_f-score_macro_sent: 0.5149946946004667
dev_precision_micro_sent: 0.6684831970935513
dev_recall_micro_sent: 0.6684831970935513
dev_f-score_micro_sent: 0.6684831970935513
dev_label=O_precision_tok: 0.9174543533141549
dev_label=O_recall_tok: 0.964331996297439
dev_label=O_f-score_tok: 0.940309284553824
dev_label=N_precision_tok: 0.7776332899869961
dev_label=N_recall_tok: 0.6440495422724825
dev_label=N_f-score_tok: 0.7045655375552283
dev_label=P_precision_tok: 0.8590455049944506
dev_label=P_recall_tok: 0.7229140722291407
dev_label=P_f-score_tok: 0.7851225697379544
dev_precision_macro_tok: 0.851377716098534
dev_recall_macro_tok: 0.7770985369330208
dev_f-score_macro_tok: 0.8099991306156689
dev_precision_micro_tok: 0.8999247908244806
dev_recall_micro_tok: 0.8999247908244806
dev_f-score_micro_tok: 0.8999247908244806
dev_time: 11.916319608688354
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5833    0.0306    0.0581       229
           N     0.6756    0.8224    0.7418       428
           P     0.6637    0.8491    0.7451       444

   micro avg     0.6685    0.6685    0.6685      1101
   macro avg     0.6409    0.5674    0.5150      1101
weighted avg     0.6516    0.6685    0.6009      1101

F1-macro sent:  0.5149946946004667
F1-micro sent:  0.6684831970935513
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9175    0.9643    0.9403     16205
           N     0.7776    0.6440    0.7046      1857
           P     0.8590    0.7229    0.7851      3212

   micro avg     0.8999    0.8999    0.8999     21274
   macro avg     0.8514    0.7771    0.8100     21274
weighted avg     0.8964    0.8999    0.8963     21274

F1-macro tok:  0.8099991306156689
F1-micro tok:  0.8999247908244806
**************************************************
Best epoch: 28
**************************************************

test0_cost_sum: 42108.10467529297
test0_cost_avg: 38.24532668055674
test0_count_sent: 1101.0
test0_total_correct_sent: 731.0
test0_accuracy_sent: 0.6639418710263397
test0_count_tok: 21274.0
test0_total_correct_tok: 19197.0
test0_accuracy_tok: 0.9023690890288615
test0_label=O_precision_sent: 0.38461538461538464
test0_label=O_recall_sent: 0.15283842794759825
test0_label=O_f-score_sent: 0.21875
test0_label=N_precision_sent: 0.6524953789279113
test0_label=N_recall_sent: 0.8247663551401869
test0_label=N_f-score_sent: 0.7285861713106295
test0_label=P_precision_sent: 0.7313432835820896
test0_label=P_recall_sent: 0.7725225225225225
test0_label=P_f-score_sent: 0.7513691128148959
test0_precision_macro_sent: 0.5894846823751285
test0_recall_macro_sent: 0.5833757685367692
test0_f-score_macro_sent: 0.5662350947085085
test0_precision_micro_sent: 0.6639418710263397
test0_recall_micro_sent: 0.6639418710263397
test0_f-score_micro_sent: 0.6639418710263397
test0_label=O_precision_tok: 0.9072855262404853
test0_label=O_recall_tok: 0.9782783091638383
test0_label=O_f-score_tok: 0.9414454540055822
test0_label=N_precision_tok: 0.8186416184971098
test0_label=N_recall_tok: 0.6101238556812062
test0_label=N_f-score_tok: 0.6991669237889541
test0_label=P_precision_tok: 0.9147703764997931
test0_label=P_recall_tok: 0.6883561643835616
test0_label=P_f-score_tok: 0.7855747024338249
test0_precision_macro_tok: 0.8802325070791294
test0_recall_macro_tok: 0.7589194430762021
test0_f-score_macro_tok: 0.8087290267427871
test0_precision_micro_tok: 0.9023690890288615
test0_recall_micro_tok: 0.9023690890288615
test0_f-score_micro_tok: 0.9023690890288615
test0_time: 11.802994012832642
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3846    0.1528    0.2188       229
           N     0.6525    0.8248    0.7286       428
           P     0.7313    0.7725    0.7514       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.5895    0.5834    0.5662      1101
weighted avg     0.6286    0.6639    0.6317      1101

F1-macro sent:  0.5662350947085085
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9073    0.9783    0.9414     16205
           N     0.8186    0.6101    0.6992      1857
           P     0.9148    0.6884    0.7856      3212

   micro avg     0.9024    0.9024    0.9024     21274
   macro avg     0.8802    0.7589    0.8087     21274
weighted avg     0.9007    0.9024    0.8968     21274

F1-macro tok:  0.8087290267427871
F1-micro tok:  0.9023690890288615
**************************************************
test1_cost_sum: 81504.56042098999
test1_cost_avg: 36.87989159320814
test1_count_sent: 2210.0
test1_total_correct_sent: 1513.0
test1_accuracy_sent: 0.6846153846153846
test1_count_tok: 42405.0
test1_total_correct_tok: 37953.0
test1_accuracy_tok: 0.8950123806154935
test1_label=O_precision_sent: 0.2647058823529412
test1_label=O_recall_sent: 0.11568123393316196
test1_label=O_f-score_sent: 0.16100178890876568
test1_label=N_precision_sent: 0.687442713107241
test1_label=N_recall_sent: 0.8223684210526315
test1_label=N_f-score_sent: 0.7488766849725412
test1_label=P_precision_sent: 0.7565858798735511
test1_label=P_recall_sent: 0.7898789878987899
test1_label=P_f-score_sent: 0.7728740581270183
test1_precision_macro_sent: 0.5695781584445778
test1_recall_macro_sent: 0.5759762142948611
test1_f-score_macro_sent: 0.5609175106694417
test1_precision_micro_sent: 0.6846153846153846
test1_recall_micro_sent: 0.6846153846153846
test1_f-score_micro_sent: 0.6846153846153846
test1_label=O_precision_tok: 0.8977360542660064
test1_label=O_recall_tok: 0.9802487655478468
test1_label=O_f-score_tok: 0.9371797361698313
test1_label=N_precision_tok: 0.8229802513464991
test1_label=N_recall_tok: 0.6095744680851064
test1_label=N_f-score_tok: 0.7003819709702063
test1_label=P_precision_tok: 0.9175389873958556
test1_label=P_recall_tok: 0.6461561606739883
test1_label=P_f-score_tok: 0.75829802259887
test1_precision_macro_tok: 0.879418431002787
test1_recall_macro_tok: 0.7453264647689805
test1_f-score_macro_tok: 0.798619909912969
test1_precision_micro_tok: 0.8950123806154935
test1_recall_micro_tok: 0.8950123806154935
test1_f-score_micro_tok: 0.8950123806154935
test1_time: 23.876181840896606
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2647    0.1157    0.1610       389
           N     0.6874    0.8224    0.7489       912
           P     0.7566    0.7899    0.7729       909

   micro avg     0.6846    0.6846    0.6846      2210
   macro avg     0.5696    0.5760    0.5609      2210
weighted avg     0.6415    0.6846    0.6553      2210

F1-macro sent:  0.5609175106694417
F1-micro sent:  0.6846153846153846
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8977    0.9802    0.9372     31998
           N     0.8230    0.6096    0.7004      3760
           P     0.9175    0.6462    0.7583      6647

   micro avg     0.8950    0.8950    0.8950     42405
   macro avg     0.8794    0.7453    0.7986     42405
weighted avg     0.8942    0.8950    0.8881     42405

F1-macro tok:  0.798619909912969
F1-micro tok:  0.8950123806154935
**************************************************
