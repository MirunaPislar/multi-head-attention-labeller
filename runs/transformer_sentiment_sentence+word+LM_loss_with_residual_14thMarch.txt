debug_mode: False
shrink_input: False
model_type: transformer
sentence_label: specified
path_train: ../mltagger/data/SST_complete/stanford_sentiment.train.complete.tsv
path_dev: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv
path_test: ../mltagger/data/SST_complete/stanford_sentiment.dev.complete.tsv:../mltagger/data/SST_complete/stanford_sentiment.test.complete.tsv
default_label: O
model_selector: dev_f-score_macro_sent:high
preload_vectors: ../mltagger/glove/glove.6B.300d.txt
word_embedding_size: 300
emb_initial_zero: False
train_embeddings: True
char_embedding_size: 100
word_recurrent_size: 300
char_recurrent_size: 100
hidden_layer_size: 50
char_hidden_layer_size: 50
lowercase: True
replace_digits: True
min_word_freq: -1.0
singletons_prob: 0.1
allowed_word_length: -1.0
max_train_sent_length: -1.0
vocab_include_devtest: True
vocab_only_embedded: False
initializer: glorot
opt_strategy: adadelta
learning_rate: 1.0
clip: 0.0
batch_equal_size: False
max_batch_size: 32
epochs: 200
stop_if_no_improvement_for_epochs: 7
learning_rate_decay: 0.9
dropout_input: 0.5
dropout_word_lstm: 0.5
dropout_attention: 0.5
masking_attention: False
residual_connection: True
tf_per_process_gpu_memory_fraction: 1.0
tf_allow_growth: True
lmcost_max_vocab_size: 7500
lmcost_hidden_layer_size: 50
lmcost_lstm_gamma: 0.1
lmcost_joint_lstm_gamma: 0.0
lmcost_char_gamma: 0.0
lmcost_joint_char_gamma: 0.1
char_integration_method: concat
save: None
load: None
garbage_collection: False
lstm_use_peepholes: False
whidden_layer_size: 200
attention_evidence_size: 100
attention_activation: soft
attention_objective_weight: 0.0
sentence_objective_weight: 1.0
sentence_objective_persistent: True
word_objective_weight: 1.0
sentence_composition: attention
random_seed: 100
{'P': 2, 'N': 1, 'O': 0}
{'P': 2, 'N': 1, 'O': 0}
Total number of words: 19335
Total number of chars: 99
Total number of singletons: 8487
Notwork built.
2019-03-14 21:15:50.762477: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 21:15:50.909295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 489c:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-03-14 21:15:50.909341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-14 21:15:51.198084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 21:15:51.198138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-14 21:15:51.198150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-14 21:15:51.198405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 489c:00:00.0, compute capability: 3.7)
n_preloaded_embeddings: 17568
Parameter count: 9033759.
Parameter count without word embeddings: 3233259.
EPOCH: 0
Learning rate: 1.000000
train_cost_sum: 430783.54455566406
train_cost_avg: 50.419422349679785
train_count_sent: 8544.0
train_total_correct_sent: 3816.0
train_accuracy_sent: 0.44662921348314605
train_count_tok: 163566.0
train_total_correct_tok: 125419.0
train_accuracy_tok: 0.7667791594830221
train_label=O_precision_sent: 0.25669642857142855
train_label=O_recall_sent: 0.0708128078817734
train_label=O_f-score_sent: 0.11100386100386099
train_label=N_precision_sent: 0.43713986380303826
train_label=N_recall_sent: 0.5042296072507553
train_label=N_f-score_sent: 0.46829405162738497
train_label=P_precision_sent: 0.4749883122954652
train_label=P_recall_sent: 0.5628808864265928
train_label=P_f-score_sent: 0.515212981744422
train_precision_macro_sent: 0.389608201556644
train_recall_macro_sent: 0.3793077671863738
train_f-score_macro_sent: 0.36483696479188926
train_precision_micro_sent: 0.44662921348314605
train_recall_micro_sent: 0.44662921348314605
train_f-score_micro_sent: 0.446629213483146
train_label=O_precision_tok: 0.793519848568245
train_label=O_recall_tok: 0.9507024697017218
train_label=O_f-score_tok: 0.8650288118540199
train_label=N_precision_tok: 0.4846837049120899
train_label=N_recall_tok: 0.18828334037459513
train_label=N_f-score_tok: 0.27121050763223287
train_label=P_precision_tok: 0.49917318928453314
train_label=P_recall_tok: 0.18099692209297677
train_label=P_f-score_tok: 0.2656653367754048
train_precision_macro_tok: 0.592458914254956
train_recall_macro_tok: 0.4399942440564312
train_f-score_macro_tok: 0.4673015520872192
train_precision_micro_tok: 0.7667791594830221
train_recall_micro_tok: 0.7667791594830221
train_f-score_micro_tok: 0.7667791594830221
train_time: 53.53229999542236
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2567    0.0708    0.1110      1624
           N     0.4371    0.5042    0.4683      3310
           P     0.4750    0.5629    0.5152      3610

   micro avg     0.4466    0.4466    0.4466      8544
   macro avg     0.3896    0.3793    0.3648      8544
weighted avg     0.4188    0.4466    0.4202      8544

F1-macro sent:  0.36483696479188926
F1-micro sent:  0.446629213483146
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.7935    0.9507    0.8650    124347
           N     0.4847    0.1883    0.2712     14202
           P     0.4992    0.1810    0.2657     25017

   micro avg     0.7668    0.7668    0.7668    163566
   macro avg     0.5925    0.4400    0.4673    163566
weighted avg     0.7217    0.7668    0.7218    163566

F1-macro tok:  0.4673015520872192
F1-micro tok:  0.7667791594830221
**************************************************
dev_cost_sum: 51105.58190917969
dev_cost_avg: 46.41742226083532
dev_count_sent: 1101.0
dev_total_correct_sent: 583.0
dev_accuracy_sent: 0.5295186194368756
dev_count_tok: 21274.0
dev_total_correct_tok: 17343.0
dev_accuracy_tok: 0.8152204568957413
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5147347740667977
dev_label=N_recall_sent: 0.6121495327102804
dev_label=N_f-score_sent: 0.5592315901814301
dev_label=P_precision_sent: 0.5422297297297297
dev_label=P_recall_sent: 0.722972972972973
dev_label=P_f-score_sent: 0.6196911196911198
dev_precision_macro_sent: 0.35232150126550915
dev_recall_macro_sent: 0.4450408352277511
dev_f-score_macro_sent: 0.3929742366241833
dev_precision_micro_sent: 0.5295186194368756
dev_recall_micro_sent: 0.5295186194368756
dev_f-score_micro_sent: 0.5295186194368756
dev_label=O_precision_tok: 0.8427995805044985
dev_label=O_recall_tok: 0.9422400493674792
dev_label=O_f-score_tok: 0.8897500145679156
dev_label=N_precision_tok: 0.6337914308811641
dev_label=N_recall_tok: 0.42218632202477113
dev_label=N_f-score_tok: 0.5067873303167421
dev_label=P_precision_tok: 0.671875
dev_label=P_recall_tok: 0.4016189290161893
dev_label=P_f-score_tok: 0.5027279812938426
dev_precision_macro_tok: 0.7161553371285542
dev_recall_macro_tok: 0.5886817668028131
dev_f-score_macro_tok: 0.6330884420595001
dev_precision_micro_tok: 0.8152204568957413
dev_recall_micro_tok: 0.8152204568957413
dev_f-score_micro_tok: 0.8152204568957413
dev_time: 2.909949541091919
**************************************************
Sentence pred: 
/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5147    0.6121    0.5592       428
           P     0.5422    0.7230    0.6197       444

   micro avg     0.5295    0.5295    0.5295      1101
   macro avg     0.3523    0.4450    0.3930      1101
weighted avg     0.4188    0.5295    0.4673      1101

/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
F1-macro sent:  0.3929742366241833
F1-micro sent:  0.5295186194368756
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8428    0.9422    0.8898     16205
           N     0.6338    0.4222    0.5068      1857
           P     0.6719    0.4016    0.5027      3212

   micro avg     0.8152    0.8152    0.8152     21274
   macro avg     0.7162    0.5887    0.6331     21274
weighted avg     0.7987    0.8152    0.7979     21274

F1-macro tok:  0.6330884420595001
F1-micro tok:  0.8152204568957413
**************************************************
Best epoch: 0
**************************************************

EPOCH: 1
Learning rate: 1.000000
train_cost_sum: 381780.4255371094
train_cost_avg: 44.684038569418234
train_count_sent: 8544.0
train_total_correct_sent: 4257.0
train_accuracy_sent: 0.4982443820224719
train_count_tok: 163566.0
train_total_correct_tok: 131258.0
train_accuracy_tok: 0.8024772874558282
train_label=O_precision_sent: 0.17518248175182483
train_label=O_recall_sent: 0.014778325123152709
train_label=O_f-score_sent: 0.0272572402044293
train_label=N_precision_sent: 0.47485406376290973
train_label=N_recall_sent: 0.6389728096676737
train_label=N_f-score_sent: 0.5448222565687789
train_label=P_precision_sent: 0.5357955982797875
train_label=P_recall_sent: 0.5867036011080332
train_label=P_f-score_sent: 0.5600952003173343
train_precision_macro_sent: 0.3952773812648407
train_recall_macro_sent: 0.4134849119662865
train_f-score_macro_sent: 0.37739156569684756
train_precision_micro_sent: 0.4982443820224719
train_recall_micro_sent: 0.4982443820224719
train_f-score_micro_sent: 0.4982443820224719
train_label=O_precision_tok: 0.8259034334314047
train_label=O_recall_tok: 0.9504129572888771
train_label=O_f-score_tok: 0.883794495961711
train_label=N_precision_tok: 0.6235955056179775
train_label=N_recall_tok: 0.3517110266159696
train_label=N_f-score_tok: 0.4497568881685575
train_label=P_precision_tok: 0.6484794993179812
train_label=P_recall_tok: 0.3230603189830915
train_label=P_f-score_tok: 0.4312700106723586
train_precision_macro_tok: 0.6993261461224544
train_recall_macro_tok: 0.5417281009626461
train_f-score_macro_tok: 0.5882737982675423
train_precision_micro_tok: 0.8024772874558282
train_recall_micro_tok: 0.8024772874558282
train_f-score_micro_tok: 0.8024772874558282
train_time: 52.100260496139526
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1752    0.0148    0.0273      1624
           N     0.4749    0.6390    0.5448      3310
           P     0.5358    0.5867    0.5601      3610

   micro avg     0.4982    0.4982    0.4982      8544
   macro avg     0.3953    0.4135    0.3774      8544
weighted avg     0.4436    0.4982    0.4529      8544

F1-macro sent:  0.37739156569684756
F1-micro sent:  0.4982443820224719
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8259    0.9504    0.8838    124347
           N     0.6236    0.3517    0.4498     14202
           P     0.6485    0.3231    0.4313     25017

   micro avg     0.8025    0.8025    0.8025    163566
   macro avg     0.6993    0.5417    0.5883    163566
weighted avg     0.7812    0.8025    0.7769    163566

F1-macro tok:  0.5882737982675423
F1-micro tok:  0.8024772874558282
**************************************************
dev_cost_sum: 49360.60546875
dev_cost_avg: 44.832520861716624
dev_count_sent: 1101.0
dev_total_correct_sent: 659.0
dev_accuracy_sent: 0.5985467756584922
dev_count_tok: 21274.0
dev_total_correct_tok: 17675.0
dev_accuracy_tok: 0.8308263608160196
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5634266886326195
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.6608695652173913
dev_label=P_precision_sent: 0.6417004048582996
dev_label=P_recall_sent: 0.713963963963964
dev_label=P_f-score_sent: 0.67590618336887
dev_precision_macro_sent: 0.4017090311636397
dev_recall_macro_sent: 0.5043431281749039
dev_f-score_macro_sent: 0.44559191619542043
dev_precision_micro_sent: 0.5985467756584922
dev_recall_micro_sent: 0.5985467756584922
dev_f-score_micro_sent: 0.5985467756584922
dev_label=O_precision_tok: 0.837170965168838
dev_label=O_recall_tok: 0.9714902807775379
dev_label=O_f-score_tok: 0.8993430448443303
dev_label=N_precision_tok: 0.7211191335740073
dev_label=N_recall_tok: 0.43026386645126546
dev_label=N_f-score_tok: 0.5389544688026982
dev_label=P_precision_tok: 0.8324761204996326
dev_label=P_recall_tok: 0.3527397260273973
dev_label=P_f-score_tok: 0.4955171659741964
dev_precision_macro_tok: 0.7969220730808261
dev_recall_macro_tok: 0.5848312910854002
dev_f-score_macro_tok: 0.6446048932070749
dev_precision_micro_tok: 0.8308263608160196
dev_recall_micro_tok: 0.8308263608160196
dev_f-score_micro_tok: 0.8308263608160196
dev_time: 2.4973909854888916
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5634    0.7991    0.6609       428
           P     0.6417    0.7140    0.6759       444

   micro avg     0.5985    0.5985    0.5985      1101
   macro avg     0.4017    0.5043    0.4456      1101
weighted avg     0.4778    0.5985    0.5295      1101

F1-macro sent:  0.44559191619542043
F1-micro sent:  0.5985467756584922
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8372    0.9715    0.8993     16205
           N     0.7211    0.4303    0.5390      1857
           P     0.8325    0.3527    0.4955      3212

   micro avg     0.8308    0.8308    0.8308     21274
   macro avg     0.7969    0.5848    0.6446     21274
weighted avg     0.8263    0.8308    0.8069     21274

F1-macro tok:  0.6446048932070749
F1-micro tok:  0.8308263608160196
**************************************************
Best epoch: 1
**************************************************

EPOCH: 2
Learning rate: 1.000000
train_cost_sum: 371473.47790527344
train_cost_avg: 43.477701065692116
train_count_sent: 8544.0
train_total_correct_sent: 4460.0
train_accuracy_sent: 0.522003745318352
train_count_tok: 163566.0
train_total_correct_tok: 134602.0
train_accuracy_tok: 0.8229216340804324
train_label=O_precision_sent: 0.25
train_label=O_recall_sent: 0.011699507389162561
train_label=O_f-score_sent: 0.022352941176470586
train_label=N_precision_sent: 0.5086614173228347
train_label=N_recall_sent: 0.5854984894259819
train_label=N_f-score_sent: 0.5443820224719101
train_label=P_precision_sent: 0.5373550880206097
train_label=P_recall_sent: 0.6933518005540166
train_label=P_f-score_sent: 0.6054668601838412
train_precision_macro_sent: 0.4320055017811481
train_recall_macro_sent: 0.4301832657897204
train_f-score_macro_sent: 0.3907339412774073
train_precision_micro_sent: 0.522003745318352
train_recall_micro_sent: 0.522003745318352
train_f-score_micro_sent: 0.522003745318352
train_label=O_precision_tok: 0.8437987283459241
train_label=O_recall_tok: 0.953050737050351
train_label=O_f-score_tok: 0.8951033633692606
train_label=N_precision_tok: 0.6652115513767629
train_label=N_recall_tok: 0.4184621884241656
train_label=N_f-score_tok: 0.5137448132780082
train_label=P_precision_tok: 0.7155445893549525
train_label=P_recall_tok: 0.40572410760682737
train_label=P_f-score_tok: 0.5178307229222999
train_precision_macro_tok: 0.7415182896925465
train_recall_macro_tok: 0.592412344360448
train_f-score_macro_tok: 0.6422262998565228
train_precision_micro_tok: 0.8229216340804324
train_recall_micro_tok: 0.8229216340804324
train_f-score_micro_tok: 0.8229216340804323
train_time: 51.900168657302856
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2500    0.0117    0.0224      1624
           N     0.5087    0.5855    0.5444      3310
           P     0.5374    0.6934    0.6055      3610

   micro avg     0.5220    0.5220    0.5220      8544
   macro avg     0.4320    0.4302    0.3907      8544
weighted avg     0.4716    0.5220    0.4710      8544

F1-macro sent:  0.3907339412774073
F1-micro sent:  0.522003745318352
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8438    0.9531    0.8951    124347
           N     0.6652    0.4185    0.5137     14202
           P     0.7155    0.4057    0.5178     25017

   micro avg     0.8229    0.8229    0.8229    163566
   macro avg     0.7415    0.5924    0.6422    163566
weighted avg     0.8087    0.8229    0.8043    163566

F1-macro tok:  0.6422262998565228
F1-micro tok:  0.8229216340804323
**************************************************
dev_cost_sum: 48572.66418457031
dev_cost_avg: 44.116861203061134
dev_count_sent: 1101.0
dev_total_correct_sent: 630.0
dev_accuracy_sent: 0.5722070844686649
dev_count_tok: 21274.0
dev_total_correct_tok: 18098.0
dev_accuracy_tok: 0.8507097865939645
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5615942028985508
dev_label=N_recall_sent: 0.7242990654205608
dev_label=N_f-score_sent: 0.6326530612244898
dev_label=P_precision_sent: 0.5828779599271403
dev_label=P_recall_sent: 0.7207207207207207
dev_label=P_f-score_sent: 0.6445115810674723
dev_precision_macro_sent: 0.381490720941897
dev_recall_macro_sent: 0.4816732620470938
dev_f-score_macro_sent: 0.4257215474306541
dev_precision_micro_sent: 0.5722070844686649
dev_recall_micro_sent: 0.5722070844686649
dev_f-score_micro_sent: 0.5722070844686649
dev_label=O_precision_tok: 0.869929676511955
dev_label=O_recall_tok: 0.9542116630669546
dev_label=O_f-score_tok: 0.9101236021188935
dev_label=N_precision_tok: 0.763671875
dev_label=N_recall_tok: 0.4211093161012386
dev_label=N_f-score_tok: 0.5428670600485943
dev_label=P_precision_tok: 0.7486868686868687
dev_label=P_recall_tok: 0.5768991282689913
dev_label=P_f-score_tok: 0.6516616845436962
dev_precision_macro_tok: 0.7940961400662746
dev_recall_macro_tok: 0.6507400358123948
dev_f-score_macro_tok: 0.7015507822370614
dev_precision_micro_tok: 0.8507097865939645
dev_recall_micro_tok: 0.8507097865939645
dev_f-score_micro_tok: 0.8507097865939646
dev_time: 2.5038483142852783
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5616    0.7243    0.6327       428
           P     0.5829    0.7207    0.6445       444

   micro avg     0.5722    0.5722    0.5722      1101
   macro avg     0.3815    0.4817    0.4257      1101
weighted avg     0.4534    0.5722    0.5058      1101

F1-macro sent:  0.4257215474306541
F1-micro sent:  0.5722070844686649
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8699    0.9542    0.9101     16205
           N     0.7637    0.4211    0.5429      1857
           P     0.7487    0.5769    0.6517      3212

   micro avg     0.8507    0.8507    0.8507     21274
   macro avg     0.7941    0.6507    0.7016     21274
weighted avg     0.8423    0.8507    0.8390     21274

F1-macro tok:  0.7015507822370614
F1-micro tok:  0.8507097865939646
**************************************************
Best epoch: 1
**************************************************

EPOCH: 3
Learning rate: 1.000000
train_cost_sum: 364006.7834472656
train_cost_avg: 42.60379019747959
train_count_sent: 8544.0
train_total_correct_sent: 4839.0
train_accuracy_sent: 0.5663623595505618
train_count_tok: 163566.0
train_total_correct_tok: 136714.0
train_accuracy_tok: 0.835833853001235
train_label=O_precision_sent: 0.16
train_label=O_recall_sent: 0.0049261083743842365
train_label=O_f-score_sent: 0.00955794504181601
train_label=N_precision_sent: 0.5540821632865315
train_label=N_recall_sent: 0.6438066465256798
train_label=N_f-score_sent: 0.5955841252096142
train_label=P_precision_sent: 0.580895008605852
train_label=P_recall_sent: 0.7479224376731302
train_label=P_f-score_sent: 0.6539113586824897
train_precision_macro_sent: 0.4316590572974612
train_recall_macro_sent: 0.46555173085773144
train_f-score_macro_sent: 0.41968447631130673
train_precision_micro_sent: 0.5663623595505618
train_recall_micro_sent: 0.5663623595505618
train_f-score_micro_sent: 0.5663623595505618
train_label=O_precision_tok: 0.8559934768804479
train_label=O_recall_tok: 0.9539996944035642
train_label=O_f-score_tok: 0.9023432003073049
train_label=N_precision_tok: 0.6801149670002129
train_label=N_recall_tok: 0.44986621602591187
train_label=N_f-score_tok: 0.541532463129344
train_label=P_precision_tok: 0.7504490633820888
train_label=P_recall_tok: 0.46760203061917893
train_label=P_f-score_tok: 0.5761851988671347
train_precision_macro_tok: 0.7621858357542498
train_recall_macro_tok: 0.6238226470162184
train_f-score_macro_tok: 0.6733536207679279
train_precision_micro_tok: 0.835833853001235
train_recall_micro_tok: 0.835833853001235
train_f-score_micro_tok: 0.835833853001235
train_time: 52.22014498710632
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1600    0.0049    0.0096      1624
           N     0.5541    0.6438    0.5956      3310
           P     0.5809    0.7479    0.6539      3610

   micro avg     0.5664    0.5664    0.5664      8544
   macro avg     0.4317    0.4656    0.4197      8544
weighted avg     0.4905    0.5664    0.5088      8544

F1-macro sent:  0.41968447631130673
F1-micro sent:  0.5663623595505618
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8560    0.9540    0.9023    124347
           N     0.6801    0.4499    0.5415     14202
           P     0.7504    0.4676    0.5762     25017

   micro avg     0.8358    0.8358    0.8358    163566
   macro avg     0.7622    0.6238    0.6734    163566
weighted avg     0.8246    0.8358    0.8211    163566

F1-macro tok:  0.6733536207679279
F1-micro tok:  0.835833853001235
**************************************************
dev_cost_sum: 47690.681884765625
dev_cost_avg: 43.31578736127668
dev_count_sent: 1101.0
dev_total_correct_sent: 649.0
dev_accuracy_sent: 0.5894641235240691
dev_count_tok: 21274.0
dev_total_correct_tok: 18271.0
dev_accuracy_tok: 0.8588417786970011
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5168393782383419
dev_label=N_recall_sent: 0.9322429906542056
dev_label=N_f-score_sent: 0.665
dev_label=P_precision_sent: 0.7598784194528876
dev_label=P_recall_sent: 0.5630630630630631
dev_label=P_f-score_sent: 0.6468305304010349
dev_precision_macro_sent: 0.42557259923040985
dev_recall_macro_sent: 0.49843535123908955
dev_f-score_macro_sent: 0.4372768434670116
dev_precision_micro_sent: 0.5894641235240691
dev_recall_micro_sent: 0.5894641235240691
dev_f-score_micro_sent: 0.5894641235240691
dev_label=O_precision_tok: 0.8673074798364822
dev_label=O_recall_tok: 0.9688367787719839
dev_label=O_f-score_tok: 0.9152651062465385
dev_label=N_precision_tok: 0.783756345177665
dev_label=N_recall_tok: 0.4157242864835757
dev_label=N_f-score_tok: 0.5432793807178043
dev_label=P_precision_tok: 0.8225880201188843
dev_label=P_recall_tok: 0.5600871731008717
dev_label=P_f-score_tok: 0.6664197073532135
dev_precision_macro_tok: 0.8245506150443438
dev_recall_macro_tok: 0.6482160794521438
dev_f-score_macro_tok: 0.7083213981058522
dev_precision_micro_tok: 0.8588417786970011
dev_recall_micro_tok: 0.8588417786970011
dev_f-score_micro_tok: 0.8588417786970011
dev_time: 2.4897751808166504
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5168    0.9322    0.6650       428
           P     0.7599    0.5631    0.6468       444

   micro avg     0.5895    0.5895    0.5895      1101
   macro avg     0.4256    0.4984    0.4373      1101
weighted avg     0.5074    0.5895    0.5194      1101

F1-macro sent:  0.4372768434670116
F1-micro sent:  0.5894641235240691
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8673    0.9688    0.9153     16205
           N     0.7838    0.4157    0.5433      1857
           P     0.8226    0.5601    0.6664      3212

   micro avg     0.8588    0.8588    0.8588     21274
   macro avg     0.8246    0.6482    0.7083     21274
weighted avg     0.8533    0.8588    0.8452     21274

F1-macro tok:  0.7083213981058522
F1-micro tok:  0.8588417786970011
**************************************************
Best epoch: 1
**************************************************

EPOCH: 4
Learning rate: 1.000000
train_cost_sum: 358135.7969970703
train_cost_avg: 41.916642906960476
train_count_sent: 8544.0
train_total_correct_sent: 4981.0
train_accuracy_sent: 0.5829822097378277
train_count_tok: 163566.0
train_total_correct_tok: 138488.0
train_accuracy_tok: 0.8466796277955076
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5367268041237113
train_label=N_recall_sent: 0.7549848942598187
train_label=N_f-score_sent: 0.6274165202108963
train_label=P_precision_sent: 0.6387030365414308
train_label=P_recall_sent: 0.6875346260387811
train_label=P_f-score_sent: 0.6622198505869796
train_precision_macro_sent: 0.3918099468883807
train_recall_macro_sent: 0.4808398400995333
train_f-score_macro_sent: 0.42987879026595865
train_precision_micro_sent: 0.5829822097378277
train_recall_micro_sent: 0.5829822097378277
train_f-score_micro_sent: 0.5829822097378277
train_label=O_precision_tok: 0.8649506705607137
train_label=O_recall_tok: 0.9574577593347648
train_label=O_f-score_tok: 0.9088563434900933
train_label=N_precision_tok: 0.6987376683992786
train_label=N_recall_tok: 0.4638079143782566
train_label=N_f-score_tok: 0.5575352321300097
train_label=P_precision_tok: 0.7787546231734676
train_label=P_recall_tok: 0.5134108806011912
train_label=P_f-score_tok: 0.6188388340158999
train_precision_macro_tok: 0.7808143207111534
train_recall_macro_tok: 0.6448921847714042
train_f-score_macro_tok: 0.6950768032120008
train_precision_micro_tok: 0.8466796277955076
train_recall_micro_tok: 0.8466796277955076
train_f-score_micro_tok: 0.8466796277955075
train_time: 52.042240858078
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5367    0.7550    0.6274      3310
           P     0.6387    0.6875    0.6622      3610

   micro avg     0.5830    0.5830    0.5830      8544
   macro avg     0.3918    0.4808    0.4299      8544
weighted avg     0.4778    0.5830    0.5229      8544

F1-macro sent:  0.42987879026595865
F1-micro sent:  0.5829822097378277
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8650    0.9575    0.9089    124347
           N     0.6987    0.4638    0.5575     14202
           P     0.7788    0.5134    0.6188     25017

   micro avg     0.8467    0.8467    0.8467    163566
   macro avg     0.7808    0.6449    0.6951    163566
weighted avg     0.8373    0.8467    0.8340    163566

F1-macro tok:  0.6950768032120008
F1-micro tok:  0.8466796277955075
**************************************************
dev_cost_sum: 46982.54150390625
dev_cost_avg: 42.67260808710831
dev_count_sent: 1101.0
dev_total_correct_sent: 679.0
dev_accuracy_sent: 0.6167120799273388
dev_count_tok: 21274.0
dev_total_correct_tok: 18461.0
dev_accuracy_tok: 0.8677728682899314
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6227180527383367
dev_label=N_recall_sent: 0.7172897196261683
dev_label=N_f-score_sent: 0.6666666666666666
dev_label=P_precision_sent: 0.6118421052631579
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7072243346007604
dev_precision_macro_sent: 0.4115200526671649
dev_recall_macro_sent: 0.5183758524880021
dev_f-score_macro_sent: 0.4579636670891423
dev_precision_micro_sent: 0.6167120799273388
dev_recall_micro_sent: 0.6167120799273388
dev_f-score_micro_sent: 0.6167120799273388
dev_label=O_precision_tok: 0.8811322882598398
dev_label=O_recall_tok: 0.9642702869484727
dev_label=O_f-score_tok: 0.9208285453313297
dev_label=N_precision_tok: 0.7301943198804185
dev_label=N_recall_tok: 0.526117393645665
dev_label=N_f-score_tok: 0.6115805946791862
dev_label=P_precision_tok: 0.8437783832879201
dev_label=P_recall_tok: 0.5784557907845579
dev_label=P_f-score_tok: 0.6863686738086442
dev_precision_macro_tok: 0.8183683304760594
dev_recall_macro_tok: 0.6896144904595651
dev_f-score_macro_tok: 0.7395926046063868
dev_precision_micro_tok: 0.8677728682899314
dev_recall_micro_tok: 0.8677728682899314
dev_f-score_micro_tok: 0.8677728682899314
dev_time: 2.4867844581604004
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6227    0.7173    0.6667       428
           P     0.6118    0.8378    0.7072       444

   micro avg     0.6167    0.6167    0.6167      1101
   macro avg     0.4115    0.5184    0.4580      1101
weighted avg     0.4888    0.6167    0.5444      1101

F1-macro sent:  0.4579636670891423
F1-micro sent:  0.6167120799273388
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8811    0.9643    0.9208     16205
           N     0.7302    0.5261    0.6116      1857
           P     0.8438    0.5785    0.6864      3212

   micro avg     0.8678    0.8678    0.8678     21274
   macro avg     0.8184    0.6896    0.7396     21274
weighted avg     0.8623    0.8678    0.8584     21274

F1-macro tok:  0.7395926046063868
F1-micro tok:  0.8677728682899314
**************************************************
Best epoch: 4
**************************************************

EPOCH: 5
Learning rate: 1.000000
train_cost_sum: 353314.31298828125
train_cost_avg: 41.352330640014195
train_count_sent: 8544.0
train_total_correct_sent: 5013.0
train_accuracy_sent: 0.5867275280898876
train_count_tok: 163566.0
train_total_correct_tok: 139773.0
train_accuracy_tok: 0.8545357837203331
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5624082232011748
train_label=N_recall_sent: 0.6942598187311179
train_label=N_f-score_sent: 0.6214169821525148
train_label=P_precision_sent: 0.6094276094276094
train_label=P_recall_sent: 0.7520775623268698
train_label=P_f-score_sent: 0.6732796032238065
train_precision_macro_sent: 0.3906119442095948
train_recall_macro_sent: 0.48211246035266253
train_f-score_macro_sent: 0.4315655284587738
train_precision_micro_sent: 0.5867275280898876
train_recall_micro_sent: 0.5867275280898876
train_f-score_micro_sent: 0.5867275280898876
train_label=O_precision_tok: 0.8710221054935434
train_label=O_recall_tok: 0.9601437911650462
train_label=O_f-score_tok: 0.9134142003006691
train_label=N_precision_tok: 0.7168469860896445
train_label=N_recall_tok: 0.48986058301647656
train_label=N_f-score_tok: 0.5820052704228886
train_label=P_precision_tok: 0.7995354654279078
train_label=P_recall_tok: 0.5366350881400648
train_label=P_f-score_tok: 0.6422215843857636
train_precision_macro_tok: 0.7958015190036986
train_recall_macro_tok: 0.6622131541071958
train_f-score_macro_tok: 0.7125470183697739
train_precision_micro_tok: 0.8545357837203331
train_recall_micro_tok: 0.8545357837203331
train_f-score_micro_tok: 0.8545357837203331
train_time: 51.94692349433899
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5624    0.6943    0.6214      3310
           P     0.6094    0.7521    0.6733      3610

   micro avg     0.5867    0.5867    0.5867      8544
   macro avg     0.3906    0.4821    0.4316      8544
weighted avg     0.4754    0.5867    0.5252      8544

F1-macro sent:  0.4315655284587738
F1-micro sent:  0.5867275280898876
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8710    0.9601    0.9134    124347
           N     0.7168    0.4899    0.5820     14202
           P     0.7995    0.5366    0.6422     25017

   micro avg     0.8545    0.8545    0.8545    163566
   macro avg     0.7958    0.6622    0.7125    163566
weighted avg     0.8467    0.8545    0.8432    163566

F1-macro tok:  0.7125470183697739
F1-micro tok:  0.8545357837203331
**************************************************
dev_cost_sum: 46530.863708496094
dev_cost_avg: 42.262364857852944
dev_count_sent: 1101.0
dev_total_correct_sent: 669.0
dev_accuracy_sent: 0.6076294277929155
dev_count_tok: 21274.0
dev_total_correct_tok: 18545.0
dev_accuracy_tok: 0.8717213500047005
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5463623395149786
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.6784765279007972
dev_label=P_precision_sent: 0.715
dev_label=P_recall_sent: 0.6441441441441441
dev_label=P_f-score_sent: 0.6777251184834123
dev_precision_macro_sent: 0.4204541131716595
dev_recall_macro_sent: 0.5130013190760855
dev_f-score_macro_sent: 0.45206721546140316
dev_precision_micro_sent: 0.6076294277929155
dev_recall_micro_sent: 0.6076294277929155
dev_f-score_micro_sent: 0.6076294277929155
dev_label=O_precision_tok: 0.8773773773773774
dev_label=O_recall_tok: 0.9735883986423943
dev_label=O_f-score_tok: 0.9229824202182116
dev_label=N_precision_tok: 0.7666139240506329
dev_label=N_recall_tok: 0.5218093699515347
dev_label=N_f-score_tok: 0.6209548221723806
dev_label=P_precision_tok: 0.8870808678500987
dev_label=P_recall_tok: 0.5600871731008717
dev_label=P_f-score_tok: 0.6866412213740458
dev_precision_macro_tok: 0.843690723092703
dev_recall_macro_tok: 0.6851616472316002
dev_f-score_macro_tok: 0.7435261545882126
dev_precision_micro_tok: 0.8717213500047005
dev_recall_micro_tok: 0.8717213500047005
dev_f-score_micro_tok: 0.8717213500047005
dev_time: 2.5188145637512207
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5464    0.8949    0.6785       428
           P     0.7150    0.6441    0.6777       444

   micro avg     0.6076    0.6076    0.6076      1101
   macro avg     0.4205    0.5130    0.4521      1101
weighted avg     0.5007    0.6076    0.5371      1101

F1-macro sent:  0.45206721546140316
F1-micro sent:  0.6076294277929155
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8774    0.9736    0.9230     16205
           N     0.7666    0.5218    0.6210      1857
           P     0.8871    0.5601    0.6866      3212

   micro avg     0.8717    0.8717    0.8717     21274
   macro avg     0.8437    0.6852    0.7435     21274
weighted avg     0.8692    0.8717    0.8609     21274

F1-macro tok:  0.7435261545882126
F1-micro tok:  0.8717213500047005
**************************************************
Best epoch: 4
**************************************************

EPOCH: 6
Learning rate: 1.000000
train_cost_sum: 349082.1153564453
train_cost_avg: 40.85698915688732
train_count_sent: 8544.0
train_total_correct_sent: 5091.0
train_accuracy_sent: 0.5958567415730337
train_count_tok: 163566.0
train_total_correct_tok: 140656.0
train_accuracy_tok: 0.8599342161573921
train_label=O_precision_sent: 1.0
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012307692307692308
train_label=N_precision_sent: 0.5586717522997532
train_label=N_recall_sent: 0.7522658610271903
train_label=N_f-score_sent: 0.6411741985322518
train_label=P_precision_sent: 0.6363191385217817
train_label=P_recall_sent: 0.7202216066481995
train_label=P_f-score_sent: 0.6756756756756757
train_precision_macro_sent: 0.7316636302738448
train_recall_macro_sent: 0.49103441040739587
train_f-score_macro_sent: 0.4393602144795656
train_precision_micro_sent: 0.5958567415730337
train_recall_micro_sent: 0.5958567415730337
train_f-score_micro_sent: 0.5958567415730337
train_label=O_precision_tok: 0.8752780053845254
train_label=O_recall_tok: 0.9621462520205554
train_label=O_f-score_tok: 0.9166586856168712
train_label=N_precision_tok: 0.7231900110764273
train_label=N_recall_tok: 0.5057034220532319
train_label=N_f-score_tok: 0.5952015911821986
train_label=P_precision_tok: 0.8163096713282587
train_label=P_recall_tok: 0.5529839708997881
train_label=P_f-score_tok: 0.6593270422266705
train_precision_macro_tok: 0.8049258959297371
train_recall_macro_tok: 0.6736112149911918
train_f-score_macro_tok: 0.7237291063419135
train_precision_micro_tok: 0.8599342161573921
train_recall_micro_tok: 0.8599342161573921
train_f-score_micro_tok: 0.8599342161573921
train_time: 72.65402960777283
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0006    0.0012      1624
           N     0.5587    0.7523    0.6412      3310
           P     0.6363    0.7202    0.6757      3610

   micro avg     0.5959    0.5959    0.5959      8544
   macro avg     0.7317    0.4910    0.4394      8544
weighted avg     0.6754    0.5959    0.5341      8544

F1-macro sent:  0.4393602144795656
F1-micro sent:  0.5958567415730337
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8753    0.9621    0.9167    124347
           N     0.7232    0.5057    0.5952     14202
           P     0.8163    0.5530    0.6593     25017

   micro avg     0.8599    0.8599    0.8599    163566
   macro avg     0.8049    0.6736    0.7237    163566
weighted avg     0.8531    0.8599    0.8494    163566

F1-macro tok:  0.7237291063419135
F1-micro tok:  0.8599342161573921
**************************************************
dev_cost_sum: 46139.71594238281
dev_cost_avg: 41.907098948576575
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18616.0
dev_accuracy_tok: 0.8750587571683746
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5917065390749602
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7033175355450237
dev_label=P_precision_sent: 0.6962025316455697
dev_label=P_recall_sent: 0.7432432432432432
dev_label=P_f-score_sent: 0.7189542483660132
dev_precision_macro_sent: 0.42930302357350997
dev_recall_macro_sent: 0.5366885577165951
dev_f-score_macro_sent: 0.47409059463701225
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8805554006580047
dev_label=O_recall_tok: 0.9744523295279235
dev_label=O_f-score_tok: 0.925127423985002
dev_label=N_precision_tok: 0.8142989786443825
dev_label=N_recall_tok: 0.47226709746903606
dev_label=N_f-score_tok: 0.5978186775732788
dev_label=P_precision_tok: 0.8604240282685512
dev_label=P_recall_tok: 0.6064757160647571
dev_label=P_f-score_tok: 0.7114682249817383
dev_precision_macro_tok: 0.8517594691903128
dev_recall_macro_tok: 0.6843983810205723
dev_f-score_macro_tok: 0.7448047755133397
dev_precision_micro_tok: 0.8750587571683746
dev_recall_micro_tok: 0.8750587571683746
dev_f-score_micro_tok: 0.8750587571683746
dev_time: 5.1332786083221436
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5917    0.8668    0.7033       428
           P     0.6962    0.7432    0.7190       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4293    0.5367    0.4741      1101
weighted avg     0.5108    0.6367    0.5633      1101

F1-macro sent:  0.47409059463701225
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8806    0.9745    0.9251     16205
           N     0.8143    0.4723    0.5978      1857
           P     0.8604    0.6065    0.7115      3212

   micro avg     0.8751    0.8751    0.8751     21274
   macro avg     0.8518    0.6844    0.7448     21274
weighted avg     0.8717    0.8751    0.8643     21274

F1-macro tok:  0.7448047755133397
F1-micro tok:  0.8750587571683746
**************************************************
Best epoch: 6
**************************************************

EPOCH: 7
Learning rate: 1.000000
train_cost_sum: 345407.9600830078
train_cost_avg: 40.42696162020223
train_count_sent: 8544.0
train_total_correct_sent: 5161.0
train_accuracy_sent: 0.6040496254681648
train_count_tok: 163566.0
train_total_correct_tok: 141394.0
train_accuracy_tok: 0.8644461562916499
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5673967035448182
train_label=N_recall_sent: 0.759214501510574
train_label=N_f-score_sent: 0.6494379118749192
train_label=P_precision_sent: 0.6438123024556285
train_label=P_recall_sent: 0.7335180055401662
train_label=P_f-score_sent: 0.6857438819111743
train_precision_macro_sent: 0.4037363353334822
train_recall_macro_sent: 0.4975775023502467
train_f-score_macro_sent: 0.44506059792869784
train_precision_micro_sent: 0.6040496254681648
train_recall_micro_sent: 0.6040496254681648
train_f-score_micro_sent: 0.6040496254681648
train_label=O_precision_tok: 0.878938141380651
train_label=O_recall_tok: 0.9636179401191826
train_label=O_f-score_tok: 0.9193321927004611
train_label=N_precision_tok: 0.7357518089007831
train_label=N_recall_tok: 0.5226728629770455
train_label=N_f-score_tok: 0.6111728623770121
train_label=P_precision_tok: 0.8249562682215743
train_label=P_recall_tok: 0.5655354359035856
train_label=P_f-score_tok: 0.671046078687125
train_precision_macro_tok: 0.8132154061676694
train_recall_macro_tok: 0.6839420796666046
train_f-score_macro_tok: 0.7338503779215326
train_precision_micro_tok: 0.8644461562916499
train_recall_micro_tok: 0.8644461562916499
train_f-score_micro_tok: 0.8644461562916498
train_time: 96.54193592071533
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5674    0.7592    0.6494      3310
           P     0.6438    0.7335    0.6857      3610

   micro avg     0.6040    0.6040    0.6040      8544
   macro avg     0.4037    0.4976    0.4451      8544
weighted avg     0.4918    0.6040    0.5413      8544

F1-macro sent:  0.44506059792869784
F1-micro sent:  0.6040496254681648
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8789    0.9636    0.9193    124347
           N     0.7358    0.5227    0.6112     14202
           P     0.8250    0.5655    0.6710     25017

   micro avg     0.8644    0.8644    0.8644    163566
   macro avg     0.8132    0.6839    0.7339    163566
weighted avg     0.8582    0.8644    0.8546    163566

F1-macro tok:  0.7338503779215326
F1-micro tok:  0.8644461562916498
**************************************************
dev_cost_sum: 45631.34814453125
dev_cost_avg: 41.445366162153725
dev_count_sent: 1101.0
dev_total_correct_sent: 678.0
dev_accuracy_sent: 0.6158038147138964
dev_count_tok: 21274.0
dev_total_correct_tok: 18751.0
dev_accuracy_tok: 0.881404531352825
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5383561643835616
dev_label=N_recall_sent: 0.9182242990654206
dev_label=N_f-score_sent: 0.6787564766839379
dev_label=P_precision_sent: 0.7681940700808625
dev_label=P_recall_sent: 0.6418918918918919
dev_label=P_f-score_sent: 0.6993865030674846
dev_precision_macro_sent: 0.4355167448214747
dev_recall_macro_sent: 0.5200387303191042
dev_f-score_macro_sent: 0.4593809932504742
dev_precision_micro_sent: 0.6158038147138964
dev_recall_micro_sent: 0.6158038147138964
dev_f-score_micro_sent: 0.6158038147138964
dev_label=O_precision_tok: 0.8885759351059036
dev_label=O_recall_tok: 0.9734032705954953
dev_label=O_f-score_tok: 0.9290573372206026
dev_label=N_precision_tok: 0.7663690476190477
dev_label=N_recall_tok: 0.5546580506192784
dev_label=N_f-score_tok: 0.6435488909715714
dev_label=P_precision_tok: 0.8939393939393939
dev_label=P_recall_tok: 0.6061643835616438
dev_label=P_f-score_tok: 0.7224489795918367
dev_precision_macro_tok: 0.8496281255547817
dev_recall_macro_tok: 0.7114085682588058
dev_f-score_macro_tok: 0.7650184025946704
dev_precision_micro_tok: 0.881404531352825
dev_recall_micro_tok: 0.881404531352825
dev_f-score_micro_tok: 0.881404531352825
dev_time: 5.090165376663208
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5384    0.9182    0.6788       428
           P     0.7682    0.6419    0.6994       444

   micro avg     0.6158    0.6158    0.6158      1101
   macro avg     0.4355    0.5200    0.4594      1101
weighted avg     0.5191    0.6158    0.5459      1101

F1-macro sent:  0.4593809932504742
F1-micro sent:  0.6158038147138964
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8886    0.9734    0.9291     16205
           N     0.7664    0.5547    0.6435      1857
           P     0.8939    0.6062    0.7224      3212

   micro avg     0.8814    0.8814    0.8814     21274
   macro avg     0.8496    0.7114    0.7650     21274
weighted avg     0.8787    0.8814    0.8729     21274

F1-macro tok:  0.7650184025946704
F1-micro tok:  0.881404531352825
**************************************************
Best epoch: 6
**************************************************

EPOCH: 8
Learning rate: 1.000000
train_cost_sum: 341968.1075439453
train_cost_avg: 40.024357156360644
train_count_sent: 8544.0
train_total_correct_sent: 5245.0
train_accuracy_sent: 0.6138810861423221
train_count_tok: 163566.0
train_total_correct_tok: 141940.0
train_accuracy_tok: 0.8677842583421983
train_label=O_precision_sent: 0.2857142857142857
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002452483139178418
train_label=N_precision_sent: 0.57860765329645
train_label=N_recall_sent: 0.7583081570996979
train_label=N_f-score_sent: 0.6563807531380753
train_label=P_precision_sent: 0.6508692545844249
train_label=P_recall_sent: 0.7570637119113574
train_label=P_f-score_sent: 0.6999615827890896
train_precision_macro_sent: 0.5050637311983869
train_recall_macro_sent: 0.5055344653682171
train_f-score_macro_sent: 0.45293160635544777
train_precision_micro_sent: 0.6138810861423221
train_recall_micro_sent: 0.6138810861423221
train_f-score_micro_sent: 0.6138810861423221
train_label=O_precision_tok: 0.8811080535681526
train_label=O_recall_tok: 0.9656284429861597
train_label=O_f-score_tok: 0.921434107634812
train_label=N_precision_tok: 0.7414523598384077
train_label=N_recall_tok: 0.5298549500070413
train_label=N_f-score_tok: 0.618044433493491
train_label=P_precision_tok: 0.8366584995916463
train_label=P_recall_tok: 0.5732901626893713
train_label=P_f-score_tok: 0.6803766692758367
train_precision_macro_tok: 0.8197396376660689
train_recall_macro_tok: 0.689591185227524
train_f-score_macro_tok: 0.7399517368013799
train_precision_micro_tok: 0.8677842583421983
train_recall_micro_tok: 0.8677842583421983
train_f-score_micro_tok: 0.8677842583421983
train_time: 96.88954639434814
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2857    0.0012    0.0025      1624
           N     0.5786    0.7583    0.6564      3310
           P     0.6509    0.7571    0.7000      3610

   micro avg     0.6139    0.6139    0.6139      8544
   macro avg     0.5051    0.5055    0.4529      8544
weighted avg     0.5535    0.6139    0.5505      8544

F1-macro sent:  0.45293160635544777
F1-micro sent:  0.6138810861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8811    0.9656    0.9214    124347
           N     0.7415    0.5299    0.6180     14202
           P     0.8367    0.5733    0.6804     25017

   micro avg     0.8678    0.8678    0.8678    163566
   macro avg     0.8197    0.6896    0.7400    163566
weighted avg     0.8622    0.8678    0.8582    163566

F1-macro tok:  0.7399517368013799
F1-micro tok:  0.8677842583421983
**************************************************
dev_cost_sum: 45262.66369628906
dev_cost_avg: 41.11050290307817
dev_count_sent: 1101.0
dev_total_correct_sent: 688.0
dev_accuracy_sent: 0.6248864668483197
dev_count_tok: 21274.0
dev_total_correct_tok: 18788.0
dev_accuracy_tok: 0.8831437435367114
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5777777777777777
dev_label=N_recall_sent: 0.8504672897196262
dev_label=N_f-score_sent: 0.6880907372400755
dev_label=P_precision_sent: 0.6878980891719745
dev_label=P_recall_sent: 0.7297297297297297
dev_label=P_f-score_sent: 0.7081967213114754
dev_precision_macro_sent: 0.42189195564991744
dev_recall_macro_sent: 0.526732339816452
dev_f-score_macro_sent: 0.465429152850517
dev_precision_micro_sent: 0.6248864668483197
dev_recall_micro_sent: 0.6248864668483197
dev_f-score_micro_sent: 0.6248864668483197
dev_label=O_precision_tok: 0.8907529797209512
dev_label=O_recall_tok: 0.9730947238506634
dev_label=O_f-score_tok: 0.9301049899728678
dev_label=N_precision_tok: 0.765659543109801
dev_label=N_recall_tok: 0.559504577275175
dev_label=N_f-score_tok: 0.6465463596764157
dev_label=P_precision_tok: 0.8943089430894309
dev_label=P_recall_tok: 0.6164383561643836
dev_label=P_f-score_tok: 0.7298193881312202
dev_precision_macro_tok: 0.8502404886400611
dev_recall_macro_tok: 0.7163458857634074
dev_f-score_macro_tok: 0.768823579260168
dev_precision_micro_tok: 0.8831437435367114
dev_recall_micro_tok: 0.8831437435367114
dev_f-score_micro_tok: 0.8831437435367114
dev_time: 5.1762964725494385
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5778    0.8505    0.6881       428
           P     0.6879    0.7297    0.7082       444

   micro avg     0.6249    0.6249    0.6249      1101
   macro avg     0.4219    0.5267    0.4654      1101
weighted avg     0.5020    0.6249    0.5531      1101

F1-macro sent:  0.465429152850517
F1-micro sent:  0.6248864668483197
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8908    0.9731    0.9301     16205
           N     0.7657    0.5595    0.6465      1857
           P     0.8943    0.6164    0.7298      3212

   micro avg     0.8831    0.8831    0.8831     21274
   macro avg     0.8502    0.7163    0.7688     21274
weighted avg     0.8804    0.8831    0.8751     21274

F1-macro tok:  0.768823579260168
F1-micro tok:  0.8831437435367114
**************************************************
Best epoch: 6
**************************************************

EPOCH: 9
Learning rate: 1.000000
train_cost_sum: 338729.6358642578
train_cost_avg: 39.645322549655646
train_count_sent: 8544.0
train_total_correct_sent: 5269.0
train_accuracy_sent: 0.6166900749063671
train_count_tok: 163566.0
train_total_correct_tok: 142313.0
train_accuracy_tok: 0.8700646833694043
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5709281961471103
train_label=N_recall_sent: 0.7879154078549849
train_label=N_f-score_sent: 0.6620969789286621
train_label=P_precision_sent: 0.6692655935613682
train_label=P_recall_sent: 0.7371191135734072
train_label=P_f-score_sent: 0.7015554969680992
train_precision_macro_sent: 0.41339792990282614
train_recall_macro_sent: 0.5083448404761307
train_f-score_macro_sent: 0.4545508252989204
train_precision_micro_sent: 0.6166900749063671
train_recall_micro_sent: 0.6166900749063671
train_f-score_micro_sent: 0.6166900749063671
train_label=O_precision_tok: 0.8835672876018952
train_label=O_recall_tok: 0.9658294932728574
train_label=O_f-score_tok: 0.9228688559232493
train_label=N_precision_tok: 0.7456787725771995
train_label=N_recall_tok: 0.5406984931699761
train_label=N_f-score_tok: 0.6268571428571428
train_label=P_precision_tok: 0.8380996309963099
train_label=P_recall_tok: 0.5810448894751569
train_label=P_f-score_tok: 0.6862916361747834
train_precision_macro_tok: 0.822448563725135
train_recall_macro_tok: 0.6958576253059968
train_f-score_macro_tok: 0.7453392116517251
train_precision_micro_tok: 0.8700646833694043
train_recall_micro_tok: 0.8700646833694043
train_f-score_micro_tok: 0.8700646833694043
train_time: 96.47732019424438
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5709    0.7879    0.6621      3310
           P     0.6693    0.7371    0.7016      3610

   micro avg     0.6167    0.6167    0.6167      8544
   macro avg     0.4134    0.5083    0.4546      8544
weighted avg     0.5040    0.6167    0.5529      8544

F1-macro sent:  0.4545508252989204
F1-micro sent:  0.6166900749063671
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8836    0.9658    0.9229    124347
           N     0.7457    0.5407    0.6269     14202
           P     0.8381    0.5810    0.6863     25017

   micro avg     0.8701    0.8701    0.8701    163566
   macro avg     0.8224    0.6959    0.7453    163566
weighted avg     0.8646    0.8701    0.8610    163566

F1-macro tok:  0.7453392116517251
F1-micro tok:  0.8700646833694043
**************************************************
dev_cost_sum: 45032.31652832031
dev_cost_avg: 40.901286583397194
dev_count_sent: 1101.0
dev_total_correct_sent: 687.0
dev_accuracy_sent: 0.6239782016348774
dev_count_tok: 21274.0
dev_total_correct_tok: 18806.0
dev_accuracy_tok: 0.8839898467613049
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5808477237048666
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.6948356807511737
dev_label=P_precision_sent: 0.6831896551724138
dev_label=P_recall_sent: 0.713963963963964
dev_label=P_f-score_sent: 0.698237885462555
dev_precision_macro_sent: 0.4213457929590934
dev_recall_macro_sent: 0.5261499817574584
dev_f-score_macro_sent: 0.46435785540457625
dev_precision_micro_sent: 0.6239782016348774
dev_recall_micro_sent: 0.6239782016348774
dev_f-score_micro_sent: 0.6239782016348774
dev_label=O_precision_tok: 0.8818458137607074
dev_label=O_recall_tok: 0.9846960814563407
dev_label=O_f-score_tok: 0.9304373177842566
dev_label=N_precision_tok: 0.8408463661453542
dev_label=N_recall_tok: 0.4921917070543888
dev_label=N_f-score_tok: 0.6209239130434783
dev_label=P_precision_tok: 0.9249521988527725
dev_label=P_recall_tok: 0.6024283935242839
dev_label=P_f-score_tok: 0.7296380090497737
dev_precision_macro_tok: 0.8825481262529445
dev_recall_macro_tok: 0.693105394011671
dev_f-score_macro_tok: 0.7603330799591695
dev_precision_micro_tok: 0.8839898467613049
dev_recall_micro_tok: 0.8839898467613049
dev_f-score_micro_tok: 0.8839898467613049
dev_time: 5.190263271331787
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5808    0.8645    0.6948       428
           P     0.6832    0.7140    0.6982       444

   micro avg     0.6240    0.6240    0.6240      1101
   macro avg     0.4213    0.5261    0.4644      1101
weighted avg     0.5013    0.6240    0.5517      1101

F1-macro sent:  0.46435785540457625
F1-micro sent:  0.6239782016348774
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8818    0.9847    0.9304     16205
           N     0.8408    0.4922    0.6209      1857
           P     0.9250    0.6024    0.7296      3212

   micro avg     0.8840    0.8840    0.8840     21274
   macro avg     0.8825    0.6931    0.7603     21274
weighted avg     0.8848    0.8840    0.8731     21274

F1-macro tok:  0.7603330799591695
F1-micro tok:  0.8839898467613049
**************************************************
Best epoch: 6
**************************************************

EPOCH: 10
Learning rate: 1.000000
train_cost_sum: 335866.1622314453
train_cost_avg: 39.310178163792756
train_count_sent: 8544.0
train_total_correct_sent: 5234.0
train_accuracy_sent: 0.6125936329588015
train_count_tok: 163566.0
train_total_correct_tok: 142977.0
train_accuracy_tok: 0.8741242067422325
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5680122860903906
train_label=N_recall_sent: 0.7821752265861027
train_label=N_f-score_sent: 0.6581087951194713
train_label=P_precision_sent: 0.6637390213299874
train_label=P_recall_sent: 0.7326869806094183
train_label=P_f-score_sent: 0.6965108624094799
train_precision_macro_sent: 0.410583769140126
train_recall_macro_sent: 0.5049540690651737
train_f-score_macro_sent: 0.45153988584298377
train_precision_micro_sent: 0.6125936329588015
train_recall_micro_sent: 0.6125936329588015
train_f-score_micro_sent: 0.6125936329588015
train_label=O_precision_tok: 0.8862816416086233
train_label=O_recall_tok: 0.9680410464265322
train_label=O_f-score_tok: 0.9253589068475776
train_label=N_precision_tok: 0.7538058760787356
train_label=N_recall_tok: 0.5473876918743839
train_label=N_f-score_tok: 0.634223944523761
train_label=P_precision_tok: 0.8505878979065099
train_label=P_recall_tok: 0.5927968981092857
train_label=P_f-score_tok: 0.6986714406859513
train_precision_macro_tok: 0.8302251385312897
train_recall_macro_tok: 0.7027418788034007
train_f-score_macro_tok: 0.7527514306857633
train_precision_micro_tok: 0.8741242067422325
train_recall_micro_tok: 0.8741242067422325
train_f-score_micro_tok: 0.8741242067422325
train_time: 96.24361801147461
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5680    0.7822    0.6581      3310
           P     0.6637    0.7327    0.6965      3610

   micro avg     0.6126    0.6126    0.6126      8544
   macro avg     0.4106    0.5050    0.4515      8544
weighted avg     0.5005    0.6126    0.5492      8544

F1-macro sent:  0.45153988584298377
F1-micro sent:  0.6125936329588015
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8863    0.9680    0.9254    124347
           N     0.7538    0.5474    0.6342     14202
           P     0.8506    0.5928    0.6987     25017

   micro avg     0.8741    0.8741    0.8741    163566
   macro avg     0.8302    0.7027    0.7528    163566
weighted avg     0.8693    0.8741    0.8654    163566

F1-macro tok:  0.7527514306857633
F1-micro tok:  0.8741242067422325
**************************************************
dev_cost_sum: 44625.966552734375
dev_cost_avg: 40.53221303608935
dev_count_sent: 1101.0
dev_total_correct_sent: 655.0
dev_accuracy_sent: 0.594913714804723
dev_count_tok: 21274.0
dev_total_correct_tok: 18902.0
dev_accuracy_tok: 0.8885023972924697
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.513715710723192
dev_label=N_recall_sent: 0.9626168224299065
dev_label=N_f-score_sent: 0.6699186991869919
dev_label=P_precision_sent: 0.8127090301003345
dev_label=P_recall_sent: 0.5472972972972973
dev_label=P_f-score_sent: 0.6541049798115747
dev_precision_macro_sent: 0.4421415802745088
dev_recall_macro_sent: 0.5033047065757347
dev_f-score_macro_sent: 0.44134122633285555
dev_precision_micro_sent: 0.594913714804723
dev_recall_micro_sent: 0.594913714804723
dev_f-score_micro_sent: 0.594913714804723
dev_label=O_precision_tok: 0.8962033936779978
dev_label=O_recall_tok: 0.9745140388768898
dev_label=O_f-score_tok: 0.9337196239579022
dev_label=N_precision_tok: 0.7631759069130732
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.67209162145871
dev_label=P_precision_tok: 0.9101277372262774
dev_label=P_recall_tok: 0.6211083437110835
dev_label=P_f-score_tok: 0.7383419689119172
dev_precision_macro_tok: 0.8565023459391162
dev_recall_macro_tok: 0.7320177283191288
dev_f-score_macro_tok: 0.7813844047761765
dev_precision_micro_tok: 0.8885023972924697
dev_recall_micro_tok: 0.8885023972924697
dev_f-score_micro_tok: 0.8885023972924697
dev_time: 5.104698657989502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5137    0.9626    0.6699       428
           P     0.8127    0.5473    0.6541       444

   micro avg     0.5949    0.5949    0.5949      1101
   macro avg     0.4421    0.5033    0.4413      1101
weighted avg     0.5274    0.5949    0.5242      1101

F1-macro sent:  0.44134122633285555
F1-micro sent:  0.594913714804723
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8962    0.9745    0.9337     16205
           N     0.7632    0.6004    0.6721      1857
           P     0.9101    0.6211    0.7383      3212

   micro avg     0.8885    0.8885    0.8885     21274
   macro avg     0.8565    0.7320    0.7814     21274
weighted avg     0.8867    0.8885    0.8814     21274

F1-macro tok:  0.7813844047761765
F1-micro tok:  0.8885023972924697
**************************************************
Best epoch: 6
**************************************************

EPOCH: 11
Learning rate: 0.900000
train_cost_sum: 333032.6671142578
train_cost_avg: 38.97854249932793
train_count_sent: 8544.0
train_total_correct_sent: 5297.0
train_accuracy_sent: 0.6199672284644194
train_count_tok: 163566.0
train_total_correct_tok: 143271.0
train_accuracy_tok: 0.8759216463079124
train_label=O_precision_sent: 1.0
train_label=O_recall_sent: 0.0006157635467980296
train_label=O_f-score_sent: 0.0012307692307692308
train_label=N_precision_sent: 0.5759825327510917
train_label=N_recall_sent: 0.7969788519637462
train_label=N_f-score_sent: 0.6686945500633713
train_label=P_precision_sent: 0.6707040121120363
train_label=P_recall_sent: 0.7362880886426593
train_label=P_f-score_sent: 0.701967516175888
train_precision_macro_sent: 0.748895514954376
train_recall_macro_sent: 0.5112942347177345
train_f-score_macro_sent: 0.4572976118233429
train_precision_micro_sent: 0.6199672284644194
train_recall_micro_sent: 0.6199672284644194
train_f-score_micro_sent: 0.6199672284644194
train_label=O_precision_tok: 0.8883777597282729
train_label=O_recall_tok: 0.9675585257384577
train_label=O_f-score_tok: 0.9262790778244417
train_label=N_precision_tok: 0.758479809976247
train_label=N_recall_tok: 0.5621039290240811
train_label=N_f-score_tok: 0.6456909451207182
train_label=P_precision_tok: 0.8503208222133893
train_label=P_recall_tok: 0.5985929567893832
train_label=P_f-score_tok: 0.702589847048888
train_precision_macro_tok: 0.8323927973059697
train_recall_macro_tok: 0.7094184705173073
train_f-score_macro_tok: 0.7581866233313493
train_precision_micro_tok: 0.8759216463079124
train_recall_micro_tok: 0.8759216463079124
train_f-score_micro_tok: 0.8759216463079124
train_time: 97.33000946044922
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     1.0000    0.0006    0.0012      1624
           N     0.5760    0.7970    0.6687      3310
           P     0.6707    0.7363    0.7020      3610

   micro avg     0.6200    0.6200    0.6200      8544
   macro avg     0.7489    0.5113    0.4573      8544
weighted avg     0.6966    0.6200    0.5559      8544

F1-macro sent:  0.4572976118233429
F1-micro sent:  0.6199672284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8884    0.9676    0.9263    124347
           N     0.7585    0.5621    0.6457     14202
           P     0.8503    0.5986    0.7026     25017

   micro avg     0.8759    0.8759    0.8759    163566
   macro avg     0.8324    0.7094    0.7582    163566
weighted avg     0.8713    0.8759    0.8677    163566

F1-macro tok:  0.7581866233313493
F1-micro tok:  0.8759216463079124
**************************************************
dev_cost_sum: 44384.81164550781
dev_cost_avg: 40.31318042280455
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 18915.0
dev_accuracy_tok: 0.8891134718435649
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6341463414634146
dev_label=N_recall_sent: 0.7897196261682243
dev_label=N_f-score_sent: 0.7034339229968782
dev_label=P_precision_sent: 0.6408450704225352
dev_label=P_recall_sent: 0.8198198198198198
dev_label=P_f-score_sent: 0.7193675889328064
dev_precision_macro_sent: 0.4249971372953166
dev_recall_macro_sent: 0.5365131486626814
dev_f-score_macro_sent: 0.4742671706432282
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8880409959338272
dev_label=O_recall_tok: 0.9838321505708115
dev_label=O_f-score_tok: 0.9334855670706717
dev_label=N_precision_tok: 0.8212244897959183
dev_label=N_recall_tok: 0.5417339795368874
dev_label=N_f-score_tok: 0.6528228423101881
dev_label=P_precision_tok: 0.9379770992366412
dev_label=P_recall_tok: 0.612079701120797
dev_label=P_f-score_tok: 0.7407686510926903
dev_precision_macro_tok: 0.8824141949887956
dev_recall_macro_tok: 0.7125486104094986
dev_f-score_macro_tok: 0.7756923534911833
dev_precision_micro_tok: 0.8891134718435649
dev_recall_micro_tok: 0.8891134718435649
dev_f-score_micro_tok: 0.8891134718435649
dev_time: 5.073693752288818
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6341    0.7897    0.7034       428
           P     0.6408    0.8198    0.7194       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.4250    0.5365    0.4743      1101
weighted avg     0.5049    0.6376    0.5636      1101

F1-macro sent:  0.4742671706432282
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8880    0.9838    0.9335     16205
           N     0.8212    0.5417    0.6528      1857
           P     0.9380    0.6121    0.7408      3212

   micro avg     0.8891    0.8891    0.8891     21274
   macro avg     0.8824    0.7125    0.7757     21274
weighted avg     0.8897    0.8891    0.8799     21274

F1-macro tok:  0.7756923534911833
F1-micro tok:  0.8891134718435649
**************************************************
Best epoch: 11
**************************************************

EPOCH: 12
Learning rate: 0.900000
train_cost_sum: 331032.5708618164
train_cost_avg: 38.74444883682308
train_count_sent: 8544.0
train_total_correct_sent: 5335.0
train_accuracy_sent: 0.6244147940074907
train_count_tok: 163566.0
train_total_correct_tok: 143630.0
train_accuracy_tok: 0.8781164789748481
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.5897376898297285
train_label=N_recall_sent: 0.7743202416918429
train_label=N_f-score_sent: 0.6695402298850576
train_label=P_precision_sent: 0.6607866507747319
train_label=P_recall_sent: 0.7678670360110803
train_label=P_f-score_sent: 0.7103139013452915
train_precision_macro_sent: 0.41684144686815344
train_recall_macro_sent: 0.5140624259009744
train_f-score_macro_sent: 0.4599513770767831
train_precision_micro_sent: 0.6244147940074907
train_recall_micro_sent: 0.6244147940074907
train_f-score_micro_sent: 0.6244147940074907
train_label=O_precision_tok: 0.8895787499815435
train_label=O_recall_tok: 0.9690382558485529
train_label=O_f-score_tok: 0.9276099784065497
train_label=N_precision_tok: 0.7614382193474746
train_label=N_recall_tok: 0.563653006618786
train_label=N_f-score_tok: 0.6477847461056039
train_label=P_precision_tok: 0.8595942951304051
train_label=P_recall_tok: 0.6047087980173482
train_label=P_f-score_tok: 0.7099680871034354
train_precision_macro_tok: 0.8368704214864744
train_recall_macro_tok: 0.712466686828229
train_f-score_macro_tok: 0.7617876038718631
train_precision_micro_tok: 0.8781164789748481
train_recall_micro_tok: 0.8781164789748481
train_f-score_micro_tok: 0.8781164789748481
train_time: 97.33851051330566
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.5897    0.7743    0.6695      3310
           P     0.6608    0.7679    0.7103      3610

   micro avg     0.6244    0.6244    0.6244      8544
   macro avg     0.4168    0.5141    0.4600      8544
weighted avg     0.5077    0.6244    0.5595      8544

F1-macro sent:  0.4599513770767831
F1-micro sent:  0.6244147940074907
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8896    0.9690    0.9276    124347
           N     0.7614    0.5637    0.6478     14202
           P     0.8596    0.6047    0.7100     25017

   micro avg     0.8781    0.8781    0.8781    163566
   macro avg     0.8369    0.7125    0.7618    163566
weighted avg     0.8739    0.8781    0.8700    163566

F1-macro tok:  0.7617876038718631
F1-micro tok:  0.8781164789748481
**************************************************
dev_cost_sum: 44094.861755371094
dev_cost_avg: 40.04982902395195
dev_count_sent: 1101.0
dev_total_correct_sent: 701.0
dev_accuracy_sent: 0.6366939146230699
dev_count_tok: 21274.0
dev_total_correct_tok: 18981.0
dev_accuracy_tok: 0.8922158503337407
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6256983240223464
dev_label=N_recall_sent: 0.7850467289719626
dev_label=N_f-score_sent: 0.6963730569948188
dev_label=P_precision_sent: 0.6483126110124334
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7249255213505462
dev_precision_macro_sent: 0.42467031167825997
dev_recall_macro_sent: 0.5357062670146783
dev_f-score_macro_sent: 0.4737661927817884
dev_precision_micro_sent: 0.6366939146230699
dev_recall_micro_sent: 0.6366939146230699
dev_f-score_micro_sent: 0.6366939146230699
dev_label=O_precision_tok: 0.8952891396332863
dev_label=O_recall_tok: 0.9792656587473002
dev_label=O_f-score_tok: 0.9353964043619216
dev_label=N_precision_tok: 0.8341503267973857
dev_label=N_recall_tok: 0.5498115239633818
dev_label=N_f-score_tok: 0.6627718273287895
dev_label=P_precision_tok: 0.8993548387096775
dev_label=P_recall_tok: 0.6509962640099627
dev_label=P_f-score_tok: 0.7552826440310637
dev_precision_macro_tok: 0.8762647683801165
dev_recall_macro_tok: 0.7266911489068816
dev_f-score_macro_tok: 0.7844836252405916
dev_precision_micro_tok: 0.8922158503337407
dev_recall_micro_tok: 0.8922158503337407
dev_f-score_micro_tok: 0.8922158503337407
dev_time: 4.924881219863892
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6257    0.7850    0.6964       428
           P     0.6483    0.8221    0.7249       444

   micro avg     0.6367    0.6367    0.6367      1101
   macro avg     0.4247    0.5357    0.4738      1101
weighted avg     0.5047    0.6367    0.5630      1101

F1-macro sent:  0.4737661927817884
F1-micro sent:  0.6366939146230699
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8953    0.9793    0.9354     16205
           N     0.8342    0.5498    0.6628      1857
           P     0.8994    0.6510    0.7553      3212

   micro avg     0.8922    0.8922    0.8922     21274
   macro avg     0.8763    0.7267    0.7845     21274
weighted avg     0.8906    0.8922    0.8844     21274

F1-macro tok:  0.7844836252405916
F1-micro tok:  0.8922158503337407
**************************************************
Best epoch: 11
**************************************************

EPOCH: 13
Learning rate: 0.900000
train_cost_sum: 328733.9061279297
train_cost_avg: 38.475410361414994
train_count_sent: 8544.0
train_total_correct_sent: 5406.0
train_accuracy_sent: 0.6327247191011236
train_count_tok: 163566.0
train_total_correct_tok: 143996.0
train_accuracy_tok: 0.880354107821919
train_label=O_precision_sent: 0.35714285714285715
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006105006105006106
train_label=N_precision_sent: 0.6092507829438689
train_label=N_recall_sent: 0.7640483383685801
train_label=N_f-score_sent: 0.6779252110977081
train_label=P_precision_sent: 0.6558575017127198
train_label=P_recall_sent: 0.7955678670360111
train_label=P_f-score_sent: 0.7189886093378396
train_precision_macro_sent: 0.5407503805998153
train_recall_macro_sent: 0.5208983410461938
train_f-score_macro_sent: 0.46767294218018457
train_precision_micro_sent: 0.6327247191011236
train_recall_micro_sent: 0.6327247191011236
train_f-score_micro_sent: 0.6327247191011236
train_label=O_precision_tok: 0.8918027208368163
train_label=O_recall_tok: 0.9694886084907557
train_label=O_f-score_tok: 0.9290244522706782
train_label=N_precision_tok: 0.7630074060185619
train_label=N_recall_tok: 0.5730882974228981
train_label=N_f-score_tok: 0.6545498411677187
train_label=P_precision_tok: 0.8636568848758465
train_label=P_recall_tok: 0.6117440140704321
train_label=P_f-score_tok: 0.7161943982965581
train_precision_macro_tok: 0.8394890039104083
train_recall_macro_tok: 0.7181069733280286
train_f-score_macro_tok: 0.7665895639116517
train_precision_micro_tok: 0.880354107821919
train_recall_micro_tok: 0.880354107821919
train_f-score_micro_tok: 0.880354107821919
train_time: 96.2212553024292
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3571    0.0031    0.0061      1624
           N     0.6093    0.7640    0.6779      3310
           P     0.6559    0.7956    0.7190      3610

   micro avg     0.6327    0.6327    0.6327      8544
   macro avg     0.5408    0.5209    0.4677      8544
weighted avg     0.5810    0.6327    0.5676      8544

F1-macro sent:  0.46767294218018457
F1-micro sent:  0.6327247191011236
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8918    0.9695    0.9290    124347
           N     0.7630    0.5731    0.6545     14202
           P     0.8637    0.6117    0.7162     25017

   micro avg     0.8804    0.8804    0.8804    163566
   macro avg     0.8395    0.7181    0.7666    163566
weighted avg     0.8763    0.8804    0.8726    163566

F1-macro tok:  0.7665895639116517
F1-micro tok:  0.880354107821919
**************************************************
dev_cost_sum: 43935.943420410156
dev_cost_avg: 39.905489028528756
dev_count_sent: 1101.0
dev_total_correct_sent: 678.0
dev_accuracy_sent: 0.6158038147138964
dev_count_tok: 21274.0
dev_total_correct_tok: 18987.0
dev_accuracy_tok: 0.8924978847419385
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6682242990654206
dev_label=N_recall_sent: 0.6682242990654206
dev_label=N_f-score_sent: 0.6682242990654206
dev_label=P_precision_sent: 0.5824665676077266
dev_label=P_recall_sent: 0.8828828828828829
dev_label=P_f-score_sent: 0.7018800358102059
dev_precision_macro_sent: 0.4168969555577157
dev_recall_macro_sent: 0.5170357273161011
dev_f-score_macro_sent: 0.4567014449585421
dev_precision_micro_sent: 0.6158038147138964
dev_recall_micro_sent: 0.6158038147138964
dev_f-score_micro_sent: 0.6158038147138964
dev_label=O_precision_tok: 0.8948346758294373
dev_label=O_recall_tok: 0.9803147176797284
dev_label=O_f-score_tok: 0.9356263619765594
dev_label=N_precision_tok: 0.8204527712724434
dev_label=N_recall_tok: 0.5659666128163705
dev_label=N_f-score_tok: 0.6698534098151689
dev_label=P_precision_tok: 0.9151785714285714
dev_label=P_recall_tok: 0.6382316313823163
dev_label=P_f-score_tok: 0.7520176082171681
dev_precision_macro_tok: 0.8768220061768174
dev_recall_macro_tok: 0.7281709872928052
dev_f-score_macro_tok: 0.7858324600029655
dev_precision_micro_tok: 0.8924978847419385
dev_recall_micro_tok: 0.8924978847419385
dev_f-score_micro_tok: 0.8924978847419385
dev_time: 5.1771533489227295
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6682    0.6682    0.6682       428
           P     0.5825    0.8829    0.7019       444

   micro avg     0.6158    0.6158    0.6158      1101
   macro avg     0.4169    0.5170    0.4567      1101
weighted avg     0.4947    0.6158    0.5428      1101

F1-macro sent:  0.4567014449585421
F1-micro sent:  0.6158038147138964
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8948    0.9803    0.9356     16205
           N     0.8205    0.5660    0.6699      1857
           P     0.9152    0.6382    0.7520      3212

   micro avg     0.8925    0.8925    0.8925     21274
   macro avg     0.8768    0.7282    0.7858     21274
weighted avg     0.8914    0.8925    0.8847     21274

F1-macro tok:  0.7858324600029655
F1-micro tok:  0.8924978847419385
**************************************************
Best epoch: 11
**************************************************

EPOCH: 14
Learning rate: 0.900000
train_cost_sum: 326760.2854003906
train_cost_avg: 38.24441542607568
train_count_sent: 8544.0
train_total_correct_sent: 5357.0
train_accuracy_sent: 0.6269897003745318
train_count_tok: 163566.0
train_total_correct_tok: 144291.0
train_accuracy_tok: 0.8821576611276182
train_label=O_precision_sent: 0.3
train_label=O_recall_sent: 0.0018472906403940886
train_label=O_f-score_sent: 0.003671970624235006
train_label=N_precision_sent: 0.600908656145385
train_label=N_recall_sent: 0.759214501510574
train_label=N_f-score_sent: 0.6708489054991992
train_label=P_precision_sent: 0.6528033088235294
train_label=P_recall_sent: 0.7869806094182825
train_label=P_f-score_sent: 0.7136397889977393
train_precision_macro_sent: 0.5179039883229715
train_recall_macro_sent: 0.5160141338564169
train_f-score_macro_sent: 0.4627202217070578
train_precision_micro_sent: 0.6269897003745318
train_recall_micro_sent: 0.6269897003745318
train_f-score_micro_sent: 0.6269897003745318
train_label=O_precision_tok: 0.8934743300924828
train_label=O_recall_tok: 0.9696172806742422
train_label=O_f-score_tok: 0.929989856956084
train_label=N_precision_tok: 0.7707358172626849
train_label=N_recall_tok: 0.5797070835093648
train_label=N_f-score_tok: 0.6617103359588491
train_label=P_precision_tok: 0.8633779264214047
train_label=P_recall_tok: 0.6191389854898669
train_label=P_f-score_tok: 0.7211397443955583
train_precision_macro_tok: 0.8425293579255242
train_recall_macro_tok: 0.7228211165578248
train_f-score_macro_tok: 0.7709466457701639
train_precision_micro_tok: 0.8821576611276182
train_recall_micro_tok: 0.8821576611276182
train_f-score_micro_tok: 0.8821576611276182
train_time: 97.072026014328
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3000    0.0018    0.0037      1624
           N     0.6009    0.7592    0.6708      3310
           P     0.6528    0.7870    0.7136      3610

   micro avg     0.6270    0.6270    0.6270      8544
   macro avg     0.5179    0.5160    0.4627      8544
weighted avg     0.5656    0.6270    0.5621      8544

F1-macro sent:  0.4627202217070578
F1-micro sent:  0.6269897003745318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8935    0.9696    0.9300    124347
           N     0.7707    0.5797    0.6617     14202
           P     0.8634    0.6191    0.7211     25017

   micro avg     0.8822    0.8822    0.8822    163566
   macro avg     0.8425    0.7228    0.7709    163566
weighted avg     0.8782    0.8822    0.8748    163566

F1-macro tok:  0.7709466457701639
F1-micro tok:  0.8821576611276182
**************************************************
dev_cost_sum: 43694.776123046875
dev_cost_avg: 39.686445161713785
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 18986.0
dev_accuracy_tok: 0.8924508790072389
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6134020618556701
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7069306930693069
dev_label=P_precision_sent: 0.6698841698841699
dev_label=P_recall_sent: 0.7815315315315315
dev_label=P_f-score_sent: 0.7214137214137214
dev_precision_macro_sent: 0.42776207724661336
dev_recall_macro_sent: 0.5385478936880806
dev_f-score_macro_sent: 0.47611480482767615
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.9005190804859963
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.9359141569836376
dev_label=N_precision_tok: 0.771978021978022
dev_label=N_recall_tok: 0.6052773290253096
dev_label=N_f-score_tok: 0.6785390884394809
dev_label=P_precision_tok: 0.9073021425448186
dev_label=P_recall_tok: 0.6460149439601495
dev_label=P_f-score_tok: 0.7546826695762867
dev_precision_macro_tok: 0.8599330816696122
dev_recall_macro_tok: 0.7418325883725055
dev_f-score_macro_tok: 0.7897119716664683
dev_precision_micro_tok: 0.8924508790072389
dev_recall_micro_tok: 0.8924508790072389
dev_f-score_micro_tok: 0.8924508790072389
dev_time: 4.9923255443573
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6134    0.8341    0.7069       428
           P     0.6699    0.7815    0.7214       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.4278    0.5385    0.4761      1101
weighted avg     0.5086    0.6394    0.5657      1101

F1-macro sent:  0.47611480482767615
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9005    0.9742    0.9359     16205
           N     0.7720    0.6053    0.6785      1857
           P     0.9073    0.6460    0.7547      3212

   micro avg     0.8925    0.8925    0.8925     21274
   macro avg     0.8599    0.7418    0.7897     21274
weighted avg     0.8903    0.8925    0.8861     21274

F1-macro tok:  0.7897119716664683
F1-micro tok:  0.8924508790072389
**************************************************
Best epoch: 14
**************************************************

EPOCH: 15
Learning rate: 0.900000
train_cost_sum: 324917.5712890625
train_cost_avg: 38.028741957989524
train_count_sent: 8544.0
train_total_correct_sent: 5388.0
train_accuracy_sent: 0.6306179775280899
train_count_tok: 163566.0
train_total_correct_tok: 144597.0
train_accuracy_tok: 0.88402846557353
train_label=O_precision_sent: 0.16
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014125956444967627
train_label=N_precision_sent: 0.6091086215294691
train_label=N_recall_sent: 0.7555891238670694
train_label=N_f-score_sent: 0.6744875943905071
train_label=P_precision_sent: 0.6589502635801054
train_label=P_recall_sent: 0.796398891966759
train_label=P_f-score_sent: 0.7211839959864543
train_precision_macro_sent: 0.47601962836985817
train_recall_macro_sent: 0.5197923927984682
train_f-score_macro_sent: 0.4699325156073097
train_precision_micro_sent: 0.6306179775280899
train_recall_micro_sent: 0.6306179775280899
train_f-score_micro_sent: 0.6306179775280899
train_label=O_precision_tok: 0.8949800134973784
train_label=O_recall_tok: 0.97050994394718
train_label=O_f-score_tok: 0.9312159513557727
train_label=N_precision_tok: 0.7764269141531323
train_label=N_recall_tok: 0.5890719616955359
train_label=N_f-score_tok: 0.6698963046002322
train_label=P_precision_tok: 0.8663509749303622
train_label=P_recall_tok: 0.6216173002358396
train_label=P_f-score_tok: 0.723857844392208
train_precision_macro_tok: 0.8459193008602911
train_recall_macro_tok: 0.7270664019595184
train_f-score_macro_tok: 0.7749900334494043
train_precision_micro_tok: 0.88402846557353
train_recall_micro_tok: 0.88402846557353
train_f-score_micro_tok: 0.88402846557353
train_time: 97.38954472541809
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.1600    0.0074    0.0141      1624
           N     0.6091    0.7556    0.6745      3310
           P     0.6590    0.7964    0.7212      3610

   micro avg     0.6306    0.6306    0.6306      8544
   macro avg     0.4760    0.5198    0.4699      8544
weighted avg     0.5448    0.6306    0.5687      8544

F1-macro sent:  0.4699325156073097
F1-micro sent:  0.6306179775280899
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8950    0.9705    0.9312    124347
           N     0.7764    0.5891    0.6699     14202
           P     0.8664    0.6216    0.7239     25017

   micro avg     0.8840    0.8840    0.8840    163566
   macro avg     0.8459    0.7271    0.7750    163566
weighted avg     0.8803    0.8840    0.8768    163566

F1-macro tok:  0.7749900334494043
F1-micro tok:  0.88402846557353
**************************************************
dev_cost_sum: 43618.00537109375
dev_cost_avg: 39.61671695830495
dev_count_sent: 1101.0
dev_total_correct_sent: 697.0
dev_accuracy_sent: 0.6330608537693007
dev_count_tok: 21274.0
dev_total_correct_tok: 19001.0
dev_accuracy_tok: 0.8931559650277334
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6441351888667992
dev_label=N_recall_sent: 0.7570093457943925
dev_label=N_f-score_sent: 0.6960257787325457
dev_label=P_precision_sent: 0.6247906197654941
dev_label=P_recall_sent: 0.8400900900900901
dev_label=P_f-score_sent: 0.7166186359269933
dev_precision_macro_sent: 0.4229752695440978
dev_recall_macro_sent: 0.5323664786281609
dev_f-score_macro_sent: 0.47088147155317966
dev_precision_micro_sent: 0.6330608537693007
dev_recall_micro_sent: 0.6330608537693007
dev_f-score_micro_sent: 0.6330608537693007
dev_label=O_precision_tok: 0.8989996589746504
dev_label=O_recall_tok: 0.9760567726010491
dev_label=O_f-score_tok: 0.9359448504393622
dev_label=N_precision_tok: 0.8084784254352763
dev_label=N_recall_tok: 0.5751211631663974
dev_label=N_f-score_tok: 0.672120830711139
dev_label=P_precision_tok: 0.8969902501059771
dev_label=P_recall_tok: 0.6587795765877957
dev_label=P_f-score_tok: 0.7596481780649794
dev_precision_macro_tok: 0.8681561115053013
dev_recall_macro_tok: 0.736652504118414
dev_f-score_macro_tok: 0.7892379530718269
dev_precision_micro_tok: 0.8931559650277334
dev_recall_micro_tok: 0.8931559650277334
dev_f-score_micro_tok: 0.8931559650277334
dev_time: 5.127264976501465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6441    0.7570    0.6960       428
           P     0.6248    0.8401    0.7166       444

   micro avg     0.6331    0.6331    0.6331      1101
   macro avg     0.4230    0.5324    0.4709      1101
weighted avg     0.5024    0.6331    0.5596      1101

F1-macro sent:  0.47088147155317966
F1-micro sent:  0.6330608537693007
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8990    0.9761    0.9359     16205
           N     0.8085    0.5751    0.6721      1857
           P     0.8970    0.6588    0.7596      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8682    0.7367    0.7892     21274
weighted avg     0.8908    0.8932    0.8863     21274

F1-macro tok:  0.7892379530718269
F1-micro tok:  0.8931559650277334
**************************************************
Best epoch: 14
**************************************************

EPOCH: 16
Learning rate: 0.900000
train_cost_sum: 322983.8980102539
train_cost_avg: 37.80242251992672
train_count_sent: 8544.0
train_total_correct_sent: 5459.0
train_accuracy_sent: 0.6389279026217228
train_count_tok: 163566.0
train_total_correct_tok: 144822.0
train_accuracy_tok: 0.8854040570778768
train_label=O_precision_sent: 0.2222222222222222
train_label=O_recall_sent: 0.0012315270935960591
train_label=O_f-score_sent: 0.002449479485609308
train_label=N_precision_sent: 0.5895953757225434
train_label=N_recall_sent: 0.83202416918429
train_label=N_f-score_sent: 0.6901390803157499
train_label=P_precision_sent: 0.6995341614906833
train_label=P_recall_sent: 0.7487534626038781
train_label=P_f-score_sent: 0.7233074658817232
train_precision_macro_sent: 0.5037839198118162
train_recall_macro_sent: 0.5273363862939214
train_f-score_macro_sent: 0.4719653418943608
train_precision_micro_sent: 0.6389279026217228
train_recall_micro_sent: 0.6389279026217228
train_f-score_micro_sent: 0.6389279026217228
train_label=O_precision_tok: 0.8966862612495449
train_label=O_recall_tok: 0.970341061706354
train_label=O_f-score_tok: 0.9320608092449828
train_label=N_precision_tok: 0.7754595588235295
train_label=N_recall_tok: 0.5940712575693564
train_label=N_f-score_tok: 0.6727533689498445
train_label=P_precision_tok: 0.8676413793103448
train_label=P_recall_tok: 0.6286125434704402
train_label=P_f-score_tok: 0.7290343516758612
train_precision_macro_tok: 0.8465957331278063
train_recall_macro_tok: 0.7310082875820502
train_f-score_macro_tok: 0.7779495099568962
train_precision_micro_tok: 0.8854040570778768
train_recall_micro_tok: 0.8854040570778768
train_f-score_micro_tok: 0.8854040570778768
train_time: 96.50813102722168
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2222    0.0012    0.0024      1624
           N     0.5896    0.8320    0.6901      3310
           P     0.6995    0.7488    0.7233      3610

   micro avg     0.6389    0.6389    0.6389      8544
   macro avg     0.5038    0.5273    0.4720      8544
weighted avg     0.5662    0.6389    0.5734      8544

F1-macro sent:  0.4719653418943608
F1-micro sent:  0.6389279026217228
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8967    0.9703    0.9321    124347
           N     0.7755    0.5941    0.6728     14202
           P     0.8676    0.6286    0.7290     25017

   micro avg     0.8854    0.8854    0.8854    163566
   macro avg     0.8466    0.7310    0.7779    163566
weighted avg     0.8817    0.8854    0.8785    163566

F1-macro tok:  0.7779495099568962
F1-micro tok:  0.8854040570778768
**************************************************
dev_cost_sum: 43343.013671875
dev_cost_avg: 39.366951563919166
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 19047.0
dev_accuracy_tok: 0.8953182288239165
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5812220566318927
dev_label=N_recall_sent: 0.9112149532710281
dev_label=N_f-score_sent: 0.7097361237488626
dev_label=P_precision_sent: 0.7209302325581395
dev_label=P_recall_sent: 0.6981981981981982
dev_label=P_f-score_sent: 0.7093821510297482
dev_precision_macro_sent: 0.4340507630633441
dev_recall_macro_sent: 0.5364710504897421
dev_f-score_macro_sent: 0.4730394249262036
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.895944653805051
dev_label=O_recall_tok: 0.9829682196852824
dev_label=O_f-score_tok: 0.9374411487758946
dev_label=N_precision_tok: 0.8230293663060279
dev_label=N_recall_tok: 0.5735056542810986
dev_label=N_f-score_tok: 0.6759758806728023
dev_label=P_precision_tok: 0.9327578373466606
dev_label=P_recall_tok: 0.6391656288916563
dev_label=P_f-score_tok: 0.758544245335304
dev_precision_macro_tok: 0.8839106191525797
dev_recall_macro_tok: 0.7318798342860124
dev_f-score_macro_tok: 0.7906537582613336
dev_precision_micro_tok: 0.8953182288239165
dev_recall_micro_tok: 0.8953182288239165
dev_f-score_micro_tok: 0.8953182288239167
dev_time: 5.106011867523193
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5812    0.9112    0.7097       428
           P     0.7209    0.6982    0.7094       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.4341    0.5365    0.4730      1101
weighted avg     0.5167    0.6358    0.5620      1101

F1-macro sent:  0.4730394249262036
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8959    0.9830    0.9374     16205
           N     0.8230    0.5735    0.6760      1857
           P     0.9328    0.6392    0.7585      3212

   micro avg     0.8953    0.8953    0.8953     21274
   macro avg     0.8839    0.7319    0.7907     21274
weighted avg     0.8951    0.8953    0.8876     21274

F1-macro tok:  0.7906537582613336
F1-micro tok:  0.8953182288239167
**************************************************
Best epoch: 14
**************************************************

EPOCH: 17
Learning rate: 0.900000
train_cost_sum: 321160.03173828125
train_cost_avg: 37.5889550255479
train_count_sent: 8544.0
train_total_correct_sent: 5432.0
train_accuracy_sent: 0.6357677902621723
train_count_tok: 163566.0
train_total_correct_tok: 144996.0
train_accuracy_tok: 0.8864678478412384
train_label=O_precision_sent: 0.275
train_label=O_recall_sent: 0.013546798029556651
train_label=O_f-score_sent: 0.025821596244131457
train_label=N_precision_sent: 0.603641456582633
train_label=N_recall_sent: 0.7812688821752266
train_label=N_f-score_sent: 0.6810639978930735
train_label=P_precision_sent: 0.6755980861244019
train_label=P_recall_sent: 0.7822714681440444
train_label=P_f-score_sent: 0.7250320924261873
train_precision_macro_sent: 0.5180798475690116
train_recall_macro_sent: 0.5256957161162759
train_f-score_macro_sent: 0.47730589552113073
train_precision_micro_sent: 0.6357677902621723
train_recall_micro_sent: 0.6357677902621723
train_f-score_micro_sent: 0.6357677902621723
train_label=O_precision_tok: 0.8976121401472885
train_label=O_recall_tok: 0.9703973557866293
train_label=O_f-score_tok: 0.932586744571581
train_label=N_precision_tok: 0.779276798825257
train_label=N_recall_tok: 0.5978735389381777
train_label=N_f-score_tok: 0.6766276197306558
train_label=P_precision_tok: 0.8683662280701754
train_label=P_recall_tok: 0.6331294719590679
train_label=P_f-score_tok: 0.7323207804517188
train_precision_macro_tok: 0.8484183890142404
train_recall_macro_tok: 0.7338001222279583
train_f-score_macro_tok: 0.7805117149179851
train_precision_micro_tok: 0.8864678478412384
train_recall_micro_tok: 0.8864678478412384
train_f-score_micro_tok: 0.8864678478412384
train_time: 97.67689514160156
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2750    0.0135    0.0258      1624
           N     0.6036    0.7813    0.6811      3310
           P     0.6756    0.7823    0.7250      3610

   micro avg     0.6358    0.6358    0.6358      8544
   macro avg     0.5181    0.5257    0.4773      8544
weighted avg     0.5716    0.6358    0.5751      8544

F1-macro sent:  0.47730589552113073
F1-micro sent:  0.6357677902621723
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8976    0.9704    0.9326    124347
           N     0.7793    0.5979    0.6766     14202
           P     0.8684    0.6331    0.7323     25017

   micro avg     0.8865    0.8865    0.8865    163566
   macro avg     0.8484    0.7338    0.7805    163566
weighted avg     0.8829    0.8865    0.8797    163566

F1-macro tok:  0.7805117149179851
F1-micro tok:  0.8864678478412384
**************************************************
dev_cost_sum: 43283.55944824219
dev_cost_avg: 39.31295136080126
dev_count_sent: 1101.0
dev_total_correct_sent: 702.0
dev_accuracy_sent: 0.6376021798365122
dev_count_tok: 21274.0
dev_total_correct_tok: 19001.0
dev_accuracy_tok: 0.8931559650277334
dev_label=O_precision_sent: 0.6666666666666666
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017241379310344827
dev_label=N_precision_sent: 0.5955056179775281
dev_label=N_recall_sent: 0.866822429906542
dev_label=N_f-score_sent: 0.7059942911512845
dev_label=P_precision_sent: 0.6926315789473684
dev_label=P_recall_sent: 0.740990990990991
dev_label=P_f-score_sent: 0.7159956474428727
dev_precision_macro_sent: 0.6516012878638544
dev_recall_macro_sent: 0.5388490151172272
dev_f-score_macro_sent: 0.4797437726348341
dev_precision_micro_sent: 0.6376021798365122
dev_recall_micro_sent: 0.6376021798365122
dev_f-score_micro_sent: 0.6376021798365122
dev_label=O_precision_tok: 0.8942783273381295
dev_label=O_recall_tok: 0.9818574514038877
dev_label=O_f-score_tok: 0.9360237668029533
dev_label=N_precision_tok: 0.8183962264150944
dev_label=N_recall_tok: 0.5605815831987075
dev_label=N_f-score_tok: 0.6653883029721955
dev_label=P_precision_tok: 0.9271493212669684
dev_label=P_recall_tok: 0.637920298879203
dev_label=P_f-score_tok: 0.7558096643305054
dev_precision_macro_tok: 0.8799412916733974
dev_recall_macro_tok: 0.7267864444939328
dev_f-score_macro_tok: 0.7857405780352181
dev_precision_micro_tok: 0.8931559650277334
dev_recall_micro_tok: 0.8931559650277334
dev_f-score_micro_tok: 0.8931559650277334
dev_time: 5.106132745742798
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6667    0.0087    0.0172       229
           N     0.5955    0.8668    0.7060       428
           P     0.6926    0.7410    0.7160       444

   micro avg     0.6376    0.6376    0.6376      1101
   macro avg     0.6516    0.5388    0.4797      1101
weighted avg     0.6495    0.6376    0.5668      1101

F1-macro sent:  0.4797437726348341
F1-micro sent:  0.6376021798365122
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8943    0.9819    0.9360     16205
           N     0.8184    0.5606    0.6654      1857
           P     0.9271    0.6379    0.7558      3212

   micro avg     0.8932    0.8932    0.8932     21274
   macro avg     0.8799    0.7268    0.7857     21274
weighted avg     0.8926    0.8932    0.8852     21274

F1-macro tok:  0.7857405780352181
F1-micro tok:  0.8931559650277334
**************************************************
Best epoch: 17
**************************************************

EPOCH: 18
Learning rate: 0.900000
train_cost_sum: 319276.96447753906
train_cost_avg: 37.368558576491
train_count_sent: 8544.0
train_total_correct_sent: 5474.0
train_accuracy_sent: 0.6406835205992509
train_count_tok: 163566.0
train_total_correct_tok: 145360.0
train_accuracy_tok: 0.8886932492082706
train_label=O_precision_sent: 0.3448275862068966
train_label=O_recall_sent: 0.006157635467980296
train_label=O_f-score_sent: 0.012099213551119177
train_label=N_precision_sent: 0.613142174432497
train_label=N_recall_sent: 0.775226586102719
train_label=N_f-score_sent: 0.6847231487658438
train_label=P_precision_sent: 0.669284064665127
train_label=P_recall_sent: 0.8027700831024931
train_label=P_f-score_sent: 0.7299748110831235
train_precision_macro_sent: 0.5424179417681735
train_recall_macro_sent: 0.5280514348910641
train_f-score_macro_sent: 0.4755990578000288
train_precision_micro_sent: 0.6406835205992509
train_recall_micro_sent: 0.6406835205992509
train_f-score_micro_sent: 0.6406835205992509
train_label=O_precision_tok: 0.8991248306964145
train_label=O_recall_tok: 0.9716277835412194
train_label=O_f-score_tok: 0.9339713436481769
train_label=N_precision_tok: 0.7839325018341893
train_label=N_recall_tok: 0.6018870581608224
train_label=N_f-score_tok: 0.6809527602963434
train_label=P_precision_tok: 0.874507874015748
train_label=P_recall_tok: 0.6392852860055163
train_label=P_f-score_tok: 0.7386214063041218
train_precision_macro_tok: 0.8525217355154506
train_recall_macro_tok: 0.737600042569186
train_f-score_macro_tok: 0.7845151700828806
train_precision_micro_tok: 0.8886932492082706
train_recall_micro_tok: 0.8886932492082706
train_f-score_micro_tok: 0.8886932492082706
train_time: 97.21964693069458
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3448    0.0062    0.0121      1624
           N     0.6131    0.7752    0.6847      3310
           P     0.6693    0.8028    0.7300      3610

   micro avg     0.6407    0.6407    0.6407      8544
   macro avg     0.5424    0.5281    0.4756      8544
weighted avg     0.5859    0.6407    0.5760      8544

F1-macro sent:  0.4755990578000288
F1-micro sent:  0.6406835205992509
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8991    0.9716    0.9340    124347
           N     0.7839    0.6019    0.6810     14202
           P     0.8745    0.6393    0.7386     25017

   micro avg     0.8887    0.8887    0.8887    163566
   macro avg     0.8525    0.7376    0.7845    163566
weighted avg     0.8854    0.8887    0.8821    163566

F1-macro tok:  0.7845151700828806
F1-micro tok:  0.8886932492082706
**************************************************
dev_cost_sum: 43033.914611816406
dev_cost_avg: 39.086207640160225
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 19062.0
dev_accuracy_tok: 0.896023314844411
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6147260273972602
dev_label=N_recall_sent: 0.8387850467289719
dev_label=N_f-score_sent: 0.7094861660079052
dev_label=P_precision_sent: 0.6692456479690522
dev_label=P_recall_sent: 0.7792792792792793
dev_label=P_f-score_sent: 0.7200832466181063
dev_precision_macro_sent: 0.4279905584554375
dev_recall_macro_sent: 0.5393547753360838
dev_f-score_macro_sent: 0.4765231375420038
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.9022749301556531
dev_label=O_recall_tok: 0.97655044739278
dev_label=O_f-score_tok: 0.9379445234708393
dev_label=N_precision_tok: 0.8141916605705926
dev_label=N_recall_tok: 0.5993537964458805
dev_label=N_f-score_tok: 0.6904466501240695
dev_label=P_precision_tok: 0.8969594594594594
dev_label=P_recall_tok: 0.6612702366127023
dev_label=P_f-score_tok: 0.7612903225806451
dev_precision_macro_tok: 0.8711420167285683
dev_recall_macro_tok: 0.7457248268171209
dev_f-score_macro_tok: 0.7965604987251846
dev_precision_micro_tok: 0.896023314844411
dev_recall_micro_tok: 0.896023314844411
dev_f-score_micro_tok: 0.896023314844411
dev_time: 5.032834053039551
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6147    0.8388    0.7095       428
           P     0.6692    0.7793    0.7201       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.4280    0.5394    0.4765      1101
weighted avg     0.5089    0.6403    0.5662      1101

F1-macro sent:  0.4765231375420038
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9023    0.9766    0.9379     16205
           N     0.8142    0.5994    0.6904      1857
           P     0.8970    0.6613    0.7613      3212

   micro avg     0.8960    0.8960    0.8960     21274
   macro avg     0.8711    0.7457    0.7966     21274
weighted avg     0.8938    0.8960    0.8897     21274

F1-macro tok:  0.7965604987251846
F1-micro tok:  0.896023314844411
**************************************************
Best epoch: 17
**************************************************

EPOCH: 19
Learning rate: 0.900000
train_cost_sum: 317739.1602783203
train_cost_avg: 37.18857212995322
train_count_sent: 8544.0
train_total_correct_sent: 5454.0
train_accuracy_sent: 0.6383426966292135
train_count_tok: 163566.0
train_total_correct_tok: 145617.0
train_accuracy_tok: 0.8902644803932358
train_label=O_precision_sent: 0.27631578947368424
train_label=O_recall_sent: 0.02586206896551724
train_label=O_f-score_sent: 0.0472972972972973
train_label=N_precision_sent: 0.6155705996131529
train_label=N_recall_sent: 0.7691842900302115
train_label=N_f-score_sent: 0.6838571044856299
train_label=P_precision_sent: 0.6734022556390977
train_label=P_recall_sent: 0.7939058171745152
train_label=P_f-score_sent: 0.7287058225273328
train_precision_macro_sent: 0.5217628815753116
train_recall_macro_sent: 0.5296507253900814
train_f-score_macro_sent: 0.4866200747700867
train_precision_micro_sent: 0.6383426966292135
train_recall_micro_sent: 0.6383426966292135
train_f-score_micro_sent: 0.6383426966292135
train_label=O_precision_tok: 0.9009486024520479
train_label=O_recall_tok: 0.9715554054380081
train_label=O_f-score_tok: 0.9349208130351844
train_label=N_precision_tok: 0.7881202462875769
train_label=N_recall_tok: 0.6128714265596394
train_label=N_f-score_tok: 0.6895349758377564
train_label=P_precision_tok: 0.8737384698860553
train_label=P_recall_tok: 0.6436822960386936
train_label=P_f-score_tok: 0.7412709738301838
train_precision_macro_tok: 0.85426910620856
train_recall_macro_tok: 0.7427030426787805
train_f-score_macro_tok: 0.7885755875677082
train_precision_micro_tok: 0.8902644803932358
train_recall_micro_tok: 0.8902644803932358
train_f-score_micro_tok: 0.8902644803932358
train_time: 97.1041612625122
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2763    0.0259    0.0473      1624
           N     0.6156    0.7692    0.6839      3310
           P     0.6734    0.7939    0.7287      3610

   micro avg     0.6383    0.6383    0.6383      8544
   macro avg     0.5218    0.5297    0.4866      8544
weighted avg     0.5755    0.6383    0.5818      8544

F1-macro sent:  0.4866200747700867
F1-micro sent:  0.6383426966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9009    0.9716    0.9349    124347
           N     0.7881    0.6129    0.6895     14202
           P     0.8737    0.6437    0.7413     25017

   micro avg     0.8903    0.8903    0.8903    163566
   macro avg     0.8543    0.7427    0.7886    163566
weighted avg     0.8870    0.8903    0.8840    163566

F1-macro tok:  0.7885755875677082
F1-micro tok:  0.8902644803932358
**************************************************
dev_cost_sum: 42897.47839355469
dev_cost_avg: 38.96228736925948
dev_count_sent: 1101.0
dev_total_correct_sent: 713.0
dev_accuracy_sent: 0.6475930971843779
dev_count_tok: 21274.0
dev_total_correct_tok: 19058.0
dev_accuracy_tok: 0.8958352919056125
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6219512195121951
dev_label=N_recall_sent: 0.8341121495327103
dev_label=N_f-score_sent: 0.7125748502994012
dev_label=P_precision_sent: 0.6755218216318786
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.733264675592173
dev_precision_macro_sent: 0.4324910137146912
dev_recall_macro_sent: 0.5453046504448373
dev_f-score_macro_sent: 0.48194650863052474
dev_precision_micro_sent: 0.6475930971843779
dev_recall_micro_sent: 0.6475930971843779
dev_f-score_micro_sent: 0.6475930971843779
dev_label=O_precision_tok: 0.9047509754418178
dev_label=O_recall_tok: 0.973033014501697
dev_label=O_f-score_tok: 0.9376505218089377
dev_label=N_precision_tok: 0.8072463768115942
dev_label=N_recall_tok: 0.5998922994076468
dev_label=N_f-score_tok: 0.6882916280506642
dev_label=P_precision_tok: 0.8824006488240065
dev_label=P_recall_tok: 0.6774595267745953
dev_label=P_f-score_tok: 0.7664670658682634
dev_precision_macro_tok: 0.8647993336924729
dev_recall_macro_tok: 0.7501282802279796
dev_f-score_macro_tok: 0.797469738575955
dev_precision_micro_tok: 0.8958352919056125
dev_recall_micro_tok: 0.8958352919056125
dev_f-score_micro_tok: 0.8958352919056125
dev_time: 5.250668048858643
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6220    0.8341    0.7126       428
           P     0.6755    0.8018    0.7333       444

   micro avg     0.6476    0.6476    0.6476      1101
   macro avg     0.4325    0.5453    0.4819      1101
weighted avg     0.5142    0.6476    0.5727      1101

F1-macro sent:  0.48194650863052474
F1-micro sent:  0.6475930971843779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9048    0.9730    0.9377     16205
           N     0.8072    0.5999    0.6883      1857
           P     0.8824    0.6775    0.7665      3212

   micro avg     0.8958    0.8958    0.8958     21274
   macro avg     0.8648    0.7501    0.7975     21274
weighted avg     0.8929    0.8958    0.8900     21274

F1-macro tok:  0.797469738575955
F1-micro tok:  0.8958352919056125
**************************************************
Best epoch: 19
**************************************************

EPOCH: 20
Learning rate: 0.900000
train_cost_sum: 315951.0602416992
train_cost_avg: 36.979290758625844
train_count_sent: 8544.0
train_total_correct_sent: 5531.0
train_accuracy_sent: 0.6473548689138576
train_count_tok: 163566.0
train_total_correct_tok: 145835.0
train_accuracy_tok: 0.8915972757174474
train_label=O_precision_sent: 0.4444444444444444
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.0145366444579043
train_label=N_precision_sent: 0.623828969493154
train_label=N_recall_sent: 0.7845921450151058
train_label=N_f-score_sent: 0.6950354609929078
train_label=P_precision_sent: 0.6711070280202113
train_label=P_recall_sent: 0.8094182825484765
train_label=P_f-score_sent: 0.7338021094927172
train_precision_macro_sent: 0.5797934806526032
train_recall_macro_sent: 0.5337998633750529
train_f-score_macro_sent: 0.4811247383145097
train_precision_micro_sent: 0.6473548689138576
train_recall_micro_sent: 0.6473548689138576
train_f-score_micro_sent: 0.6473548689138576
train_label=O_precision_tok: 0.9025937159163915
train_label=O_recall_tok: 0.971659951587091
train_label=O_f-score_tok: 0.9358542885801812
train_label=N_precision_tok: 0.790185819953094
train_label=N_recall_tok: 0.6168145331643431
train_label=N_f-score_tok: 0.6928187282505537
train_label=P_precision_tok: 0.8729186808464926
train_label=P_recall_tok: 0.6496382459927249
train_label=P_f-score_tok: 0.7449066116649476
train_precision_macro_tok: 0.8552327389053259
train_recall_macro_tok: 0.7460375769147197
train_f-score_macro_tok: 0.7911932094985609
train_precision_micro_tok: 0.8915972757174474
train_recall_micro_tok: 0.8915972757174474
train_f-score_micro_tok: 0.8915972757174474
train_time: 97.74395155906677
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4444    0.0074    0.0145      1624
           N     0.6238    0.7846    0.6950      3310
           P     0.6711    0.8094    0.7338      3610

   micro avg     0.6474    0.6474    0.6474      8544
   macro avg     0.5798    0.5338    0.4811      8544
weighted avg     0.6097    0.6474    0.5821      8544

F1-macro sent:  0.4811247383145097
F1-micro sent:  0.6473548689138576
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9026    0.9717    0.9359    124347
           N     0.7902    0.6168    0.6928     14202
           P     0.8729    0.6496    0.7449     25017

   micro avg     0.8916    0.8916    0.8916    163566
   macro avg     0.8552    0.7460    0.7912    163566
weighted avg     0.8883    0.8916    0.8855    163566

F1-macro tok:  0.7911932094985609
F1-micro tok:  0.8915972757174474
**************************************************
dev_cost_sum: 42728.11181640625
dev_cost_avg: 38.80845759891576
dev_count_sent: 1101.0
dev_total_correct_sent: 715.0
dev_accuracy_sent: 0.6494096276112625
dev_count_tok: 21274.0
dev_total_correct_tok: 19094.0
dev_accuracy_tok: 0.8975274983547993
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6031496062992125
dev_label=N_recall_sent: 0.8948598130841121
dev_label=N_f-score_sent: 0.7206020696142991
dev_label=P_precision_sent: 0.7124463519313304
dev_label=P_recall_sent: 0.7477477477477478
dev_label=P_f-score_sent: 0.7296703296703295
dev_precision_macro_sent: 0.4385319860768477
dev_recall_macro_sent: 0.54753585361062
dev_f-score_macro_sent: 0.48342413309487614
dev_precision_micro_sent: 0.6494096276112625
dev_recall_micro_sent: 0.6494096276112625
dev_f-score_micro_sent: 0.6494096276112625
dev_label=O_precision_tok: 0.9036715582709987
dev_label=O_recall_tok: 0.9766121567417464
dev_label=O_f-score_tok: 0.9387270893884573
dev_label=N_precision_tok: 0.8007168458781362
dev_label=N_recall_tok: 0.6015078082929456
dev_label=N_f-score_tok: 0.6869618696186962
dev_label=P_precision_tok: 0.9091293322062552
dev_label=P_recall_tok: 0.6696762141967622
dev_label=P_f-score_tok: 0.7712441735389028
dev_precision_macro_tok: 0.87117257878513
dev_recall_macro_tok: 0.7492653930771515
dev_f-score_macro_tok: 0.7989777108486855
dev_precision_micro_tok: 0.8975274983547993
dev_recall_micro_tok: 0.8975274983547993
dev_f-score_micro_tok: 0.8975274983547993
dev_time: 5.190911769866943
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6031    0.8949    0.7206       428
           P     0.7124    0.7477    0.7297       444

   micro avg     0.6494    0.6494    0.6494      1101
   macro avg     0.4385    0.5475    0.4834      1101
weighted avg     0.5218    0.6494    0.5744      1101

F1-macro sent:  0.48342413309487614
F1-micro sent:  0.6494096276112625
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9037    0.9766    0.9387     16205
           N     0.8007    0.6015    0.6870      1857
           P     0.9091    0.6697    0.7712      3212

   micro avg     0.8975    0.8975    0.8975     21274
   macro avg     0.8712    0.7493    0.7990     21274
weighted avg     0.8955    0.8975    0.8915     21274

F1-macro tok:  0.7989777108486855
F1-micro tok:  0.8975274983547993
**************************************************
Best epoch: 20
**************************************************

EPOCH: 21
Learning rate: 0.900000
train_cost_sum: 314217.89489746094
train_cost_avg: 36.776439009534286
train_count_sent: 8544.0
train_total_correct_sent: 5538.0
train_accuracy_sent: 0.6481741573033708
train_count_tok: 163566.0
train_total_correct_tok: 146129.0
train_accuracy_tok: 0.8933947152831273
train_label=O_precision_sent: 0.3333333333333333
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010902483343428224
train_label=N_precision_sent: 0.6168376865671642
train_label=N_recall_sent: 0.7990936555891238
train_label=N_f-score_sent: 0.696235851539879
train_label=P_precision_sent: 0.6819579096713171
train_label=P_recall_sent: 0.7988919667590028
train_label=P_f-score_sent: 0.7358081387932134
train_precision_macro_sent: 0.5440429765239382
train_recall_macro_sent: 0.5345091647564363
train_f-score_macro_sent: 0.4809821578921736
train_precision_micro_sent: 0.6481741573033708
train_recall_micro_sent: 0.6481741573033708
train_f-score_micro_sent: 0.6481741573033708
train_label=O_precision_tok: 0.9042403567046713
train_label=O_recall_tok: 0.9720218421031468
train_label=O_f-score_tok: 0.9369067689862992
train_label=N_precision_tok: 0.7899649941656943
train_label=N_recall_tok: 0.6197014504999296
train_label=N_f-score_tok: 0.6945507635244447
train_label=P_precision_tok: 0.8775390520872207
train_label=P_recall_tok: 0.6579525922372786
train_label=P_f-score_tok: 0.7520445926805865
train_precision_macro_tok: 0.8572481343191954
train_recall_macro_tok: 0.7498919616134517
train_f-score_macro_tok: 0.7945007083971101
train_precision_micro_tok: 0.8933947152831273
train_recall_micro_tok: 0.8933947152831273
train_f-score_micro_tok: 0.8933947152831273
train_time: 97.61379432678223
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0055    0.0109      1624
           N     0.6168    0.7991    0.6962      3310
           P     0.6820    0.7989    0.7358      3610

   micro avg     0.6482    0.6482    0.6482      8544
   macro avg     0.5440    0.5345    0.4810      8544
weighted avg     0.5905    0.6482    0.5827      8544

F1-macro sent:  0.4809821578921736
F1-micro sent:  0.6481741573033708
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9042    0.9720    0.9369    124347
           N     0.7900    0.6197    0.6946     14202
           P     0.8775    0.6580    0.7520     25017

   micro avg     0.8934    0.8934    0.8934    163566
   macro avg     0.8572    0.7499    0.7945    163566
weighted avg     0.8902    0.8934    0.8876    163566

F1-macro tok:  0.7945007083971101
F1-micro tok:  0.8933947152831273
**************************************************
dev_cost_sum: 42688.84405517578
dev_cost_avg: 38.772792057380364
dev_count_sent: 1101.0
dev_total_correct_sent: 710.0
dev_accuracy_sent: 0.6448683015440508
dev_count_tok: 21274.0
dev_total_correct_tok: 19103.0
dev_accuracy_tok: 0.897950549967096
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.5953488372093023
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7157502329916122
dev_label=P_precision_sent: 0.7149122807017544
dev_label=P_recall_sent: 0.7342342342342343
dev_label=P_f-score_sent: 0.7244444444444444
dev_precision_macro_sent: 0.4367537059703522
dev_recall_macro_sent: 0.5438101653054924
dev_f-score_macro_sent: 0.4800648924786855
dev_precision_micro_sent: 0.6448683015440508
dev_recall_micro_sent: 0.6448683015440508
dev_f-score_micro_sent: 0.6448683015440508
dev_label=O_precision_tok: 0.8988878225032462
dev_label=O_recall_tok: 0.9825362542425178
dev_label=O_f-score_tok: 0.9388525266819978
dev_label=N_precision_tok: 0.8271604938271605
dev_label=N_recall_tok: 0.5772751750134626
dev_label=N_f-score_tok: 0.679987313669521
dev_label=P_precision_tok: 0.9311258278145695
dev_label=P_recall_tok: 0.6566002490660025
dev_label=P_f-score_tok: 0.7701296330107722
dev_precision_macro_tok: 0.8857247147149921
dev_recall_macro_tok: 0.7388038927739943
dev_f-score_macro_tok: 0.7963231577874303
dev_precision_micro_tok: 0.897950549967096
dev_recall_micro_tok: 0.897950549967096
dev_f-score_micro_tok: 0.8979505499670959
dev_time: 5.138280391693115
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.5953    0.8972    0.7158       428
           P     0.7149    0.7342    0.7244       444

   micro avg     0.6449    0.6449    0.6449      1101
   macro avg     0.4368    0.5438    0.4801      1101
weighted avg     0.5197    0.6449    0.5704      1101

F1-macro sent:  0.4800648924786855
F1-micro sent:  0.6448683015440508
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.8989    0.9825    0.9389     16205
           N     0.8272    0.5773    0.6800      1857
           P     0.9311    0.6566    0.7701      3212

   micro avg     0.8980    0.8980    0.8980     21274
   macro avg     0.8857    0.7388    0.7963     21274
weighted avg     0.8975    0.8980    0.8908     21274

F1-macro tok:  0.7963231577874303
F1-micro tok:  0.8979505499670959
**************************************************
Best epoch: 20
**************************************************

EPOCH: 22
Learning rate: 0.900000
train_cost_sum: 312661.19763183594
train_cost_avg: 36.59424129586095
train_count_sent: 8544.0
train_total_correct_sent: 5560.0
train_accuracy_sent: 0.650749063670412
train_count_tok: 163566.0
train_total_correct_tok: 146384.0
train_accuracy_tok: 0.8949537189880538
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6206978400189889
train_label=N_recall_sent: 0.7900302114803626
train_label=N_f-score_sent: 0.6952013824272232
train_label=P_precision_sent: 0.6801385681293303
train_label=P_recall_sent: 0.8157894736842105
train_label=P_f-score_sent: 0.7418136020151134
train_precision_macro_sent: 0.43361213604943966
train_recall_macro_sent: 0.535273228388191
train_f-score_macro_sent: 0.4790049948141122
train_precision_micro_sent: 0.650749063670412
train_recall_micro_sent: 0.650749063670412
train_f-score_micro_sent: 0.650749063670412
train_label=O_precision_tok: 0.9058480496507061
train_label=O_recall_tok: 0.9718851279081924
train_label=O_f-score_tok: 0.9377053759519551
train_label=N_precision_tok: 0.7929109437306159
train_label=N_recall_tok: 0.6300521053372764
train_label=N_f-score_tok: 0.7021618864519167
train_label=P_precision_tok: 0.8789548995707245
train_label=P_recall_tok: 0.6629491945477075
train_label=P_f-score_tok: 0.7558219022011575
train_precision_macro_tok: 0.8592379643173488
train_recall_macro_tok: 0.7549621425977254
train_f-score_macro_tok: 0.798563054868343
train_precision_micro_tok: 0.8949537189880538
train_recall_micro_tok: 0.8949537189880538
train_f-score_micro_tok: 0.8949537189880538
train_time: 97.05692529678345
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6207    0.7900    0.6952      3310
           P     0.6801    0.8158    0.7418      3610

   micro avg     0.6507    0.6507    0.6507      8544
   macro avg     0.4336    0.5353    0.4790      8544
weighted avg     0.5278    0.6507    0.5828      8544

F1-macro sent:  0.4790049948141122
F1-micro sent:  0.650749063670412
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9058    0.9719    0.9377    124347
           N     0.7929    0.6301    0.7022     14202
           P     0.8790    0.6629    0.7558     25017

   micro avg     0.8950    0.8950    0.8950    163566
   macro avg     0.8592    0.7550    0.7986    163566
weighted avg     0.8919    0.8950    0.8894    163566

F1-macro tok:  0.798563054868343
F1-micro tok:  0.8949537189880538
**************************************************
dev_cost_sum: 42676.23352050781
dev_cost_avg: 38.76133834741854
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 19097.0
dev_accuracy_tok: 0.8976685155588982
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6211849192100538
dev_label=N_recall_sent: 0.8084112149532711
dev_label=N_f-score_sent: 0.7025380710659898
dev_label=P_precision_sent: 0.6580882352941176
dev_label=P_recall_sent: 0.8063063063063063
dev_label=P_f-score_sent: 0.7246963562753035
dev_precision_macro_sent: 0.42642438483472384
dev_recall_macro_sent: 0.5382391737531925
dev_f-score_macro_sent: 0.47574480911376443
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.9011918274687855
dev_label=O_recall_tok: 0.9798827522369639
dev_label=O_f-score_tok: 0.9388913525498891
dev_label=N_precision_tok: 0.8417670682730923
dev_label=N_recall_tok: 0.5643511039310716
dev_label=N_f-score_tok: 0.675693101225016
dev_label=P_precision_tok: 0.9007887090078871
dev_label=P_recall_tok: 0.6755915317559154
dev_label=P_f-score_tok: 0.7721046077210462
dev_precision_macro_tok: 0.8812492015832549
dev_recall_macro_tok: 0.7399417959746503
dev_f-score_macro_tok: 0.7955630204986504
dev_precision_micro_tok: 0.8976685155588982
dev_recall_micro_tok: 0.8976685155588982
dev_f-score_micro_tok: 0.8976685155588982
dev_time: 5.125373601913452
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6212    0.8084    0.7025       428
           P     0.6581    0.8063    0.7247       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.4264    0.5382    0.4757      1101
weighted avg     0.5069    0.6394    0.5654      1101

F1-macro sent:  0.47574480911376443
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9012    0.9799    0.9389     16205
           N     0.8418    0.5644    0.6757      1857
           P     0.9008    0.6756    0.7721      3212

   micro avg     0.8977    0.8977    0.8977     21274
   macro avg     0.8812    0.7399    0.7956     21274
weighted avg     0.8959    0.8977    0.8907     21274

F1-macro tok:  0.7955630204986504
F1-micro tok:  0.8976685155588982
**************************************************
Best epoch: 20
**************************************************

EPOCH: 23
Learning rate: 0.900000
train_cost_sum: 311559.4243774414
train_cost_avg: 36.4652884336893
train_count_sent: 8544.0
train_total_correct_sent: 5515.0
train_accuracy_sent: 0.6454822097378277
train_count_tok: 163566.0
train_total_correct_tok: 146504.0
train_accuracy_tok: 0.8956873677903721
train_label=O_precision_sent: 0.2903225806451613
train_label=O_recall_sent: 0.02770935960591133
train_label=O_f-score_sent: 0.050590219224283306
train_label=N_precision_sent: 0.6189448441247002
train_label=N_recall_sent: 0.7797583081570997
train_label=N_f-score_sent: 0.6901069518716577
train_label=P_precision_sent: 0.6847594216639014
train_label=P_recall_sent: 0.8002770083102493
train_label=P_f-score_sent: 0.7380252905862817
train_precision_macro_sent: 0.5313422821445877
train_recall_macro_sent: 0.5359148920244201
train_f-score_macro_sent: 0.49290748722740757
train_precision_micro_sent: 0.6454822097378277
train_recall_micro_sent: 0.6454822097378277
train_f-score_micro_sent: 0.6454822097378277
train_label=O_precision_tok: 0.9063209902459871
train_label=O_recall_tok: 0.9721665983095692
train_label=O_f-score_tok: 0.9380897690588528
train_label=N_precision_tok: 0.7968046606055257
train_label=N_recall_tok: 0.6356147021546261
train_label=N_f-score_tok: 0.7071403391954879
train_label=P_precision_tok: 0.8798790835808231
train_label=P_recall_tok: 0.6631890314586082
train_label=P_f-score_tok: 0.7563193763818294
train_precision_macro_tok: 0.8610015781441119
train_recall_macro_tok: 0.7569901106409346
train_f-score_macro_tok: 0.8005164948787235
train_precision_micro_tok: 0.8956873677903721
train_recall_micro_tok: 0.8956873677903721
train_f-score_micro_tok: 0.8956873677903721
train_time: 97.62973070144653
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2903    0.0277    0.0506      1624
           N     0.6189    0.7798    0.6901      3310
           P     0.6848    0.8003    0.7380      3610

   micro avg     0.6455    0.6455    0.6455      8544
   macro avg     0.5313    0.5359    0.4929      8544
weighted avg     0.5843    0.6455    0.5888      8544

F1-macro sent:  0.49290748722740757
F1-micro sent:  0.6454822097378277
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9063    0.9722    0.9381    124347
           N     0.7968    0.6356    0.7071     14202
           P     0.8799    0.6632    0.7563     25017

   micro avg     0.8957    0.8957    0.8957    163566
   macro avg     0.8610    0.7570    0.8005    163566
weighted avg     0.8928    0.8957    0.8902    163566

F1-macro tok:  0.8005164948787235
F1-micro tok:  0.8956873677903721
**************************************************
dev_cost_sum: 42519.33093261719
dev_cost_avg: 38.618829184938406
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19117.0
dev_accuracy_tok: 0.8986086302528908
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6428571428571429
dev_label=N_recall_sent: 0.7990654205607477
dev_label=N_f-score_sent: 0.7125000000000001
dev_label=P_precision_sent: 0.6449912126537786
dev_label=P_recall_sent: 0.8265765765765766
dev_label=P_f-score_sent: 0.7245804540967423
dev_precision_macro_sent: 0.42928278517030716
dev_recall_macro_sent: 0.5418806657124414
dev_f-score_macro_sent: 0.47902681803224745
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.9073701167942005
dev_label=O_recall_tok: 0.9732181425485961
dev_label=O_f-score_tok: 0.9391413088786994
dev_label=N_precision_tok: 0.7988865692414753
dev_label=N_recall_tok: 0.6182014001077006
dev_label=N_f-score_tok: 0.6970248937462052
dev_label=P_precision_tok: 0.8949511400651465
dev_label=P_recall_tok: 0.6843088418430884
dev_label=P_f-score_tok: 0.7755822159491884
dev_precision_macro_tok: 0.8670692753669408
dev_recall_macro_tok: 0.7585761281664617
dev_f-score_macro_tok: 0.8039161395246976
dev_precision_micro_tok: 0.8986086302528908
dev_recall_micro_tok: 0.8986086302528908
dev_f-score_micro_tok: 0.8986086302528908
dev_time: 5.06506609916687
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6429    0.7991    0.7125       428
           P     0.6450    0.8266    0.7246       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.4293    0.5419    0.4790      1101
weighted avg     0.5100    0.6440    0.5692      1101

F1-macro sent:  0.47902681803224745
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9074    0.9732    0.9391     16205
           N     0.7989    0.6182    0.6970      1857
           P     0.8950    0.6843    0.7756      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8671    0.7586    0.8039     21274
weighted avg     0.8960    0.8986    0.8933     21274

F1-macro tok:  0.8039161395246976
F1-micro tok:  0.8986086302528908
**************************************************
Best epoch: 20
**************************************************

EPOCH: 24
Learning rate: 0.900000
train_cost_sum: 309868.0842285156
train_cost_avg: 36.267331955584694
train_count_sent: 8544.0
train_total_correct_sent: 5654.0
train_accuracy_sent: 0.661750936329588
train_count_tok: 163566.0
train_total_correct_tok: 146706.0
train_accuracy_tok: 0.8969223432742746
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.6275830044114232
train_label=N_recall_sent: 0.8166163141993957
train_label=N_f-score_sent: 0.709728239464356
train_label=P_precision_sent: 0.696483360868539
train_label=P_recall_sent: 0.8174515235457064
train_label=P_f-score_sent: 0.7521345737224419
train_precision_macro_sent: 0.44135545509332075
train_recall_macro_sent: 0.5446892792483674
train_f-score_macro_sent: 0.4872876043955993
train_precision_micro_sent: 0.661750936329588
train_recall_micro_sent: 0.661750936329588
train_f-score_micro_sent: 0.661750936329588
train_label=O_precision_tok: 0.9081944788918701
train_label=O_recall_tok: 0.9717805817591096
train_label=O_f-score_tok: 0.9389121989121989
train_label=N_precision_tok: 0.7923902609302731
train_label=N_recall_tok: 0.6393465709055063
train_label=N_f-score_tok: 0.7076887104945248
train_label=P_precision_tok: 0.8810748399286239
train_label=P_recall_tok: 0.6710636766998441
train_label=P_f-score_tok: 0.761861541603322
train_precision_macro_tok: 0.8605531932502557
train_recall_macro_tok: 0.7607302764548199
train_f-score_macro_tok: 0.8028208170033485
train_precision_micro_tok: 0.8969223432742746
train_recall_micro_tok: 0.8969223432742746
train_f-score_micro_tok: 0.8969223432742746
train_time: 97.18462920188904
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6276    0.8166    0.7097      3310
           P     0.6965    0.8175    0.7521      3610

   micro avg     0.6618    0.6618    0.6618      8544
   macro avg     0.4414    0.5447    0.4873      8544
weighted avg     0.5374    0.6618    0.5927      8544

F1-macro sent:  0.4872876043955993
F1-micro sent:  0.661750936329588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9082    0.9718    0.9389    124347
           N     0.7924    0.6393    0.7077     14202
           P     0.8811    0.6711    0.7619     25017

   micro avg     0.8969    0.8969    0.8969    163566
   macro avg     0.8606    0.7607    0.8028    163566
weighted avg     0.8940    0.8969    0.8918    163566

F1-macro tok:  0.8028208170033485
F1-micro tok:  0.8969223432742746
**************************************************
dev_cost_sum: 42393.351135253906
dev_cost_avg: 38.504406117396826
dev_count_sent: 1101.0
dev_total_correct_sent: 709.0
dev_accuracy_sent: 0.6439600363306085
dev_count_tok: 21274.0
dev_total_correct_tok: 19113.0
dev_accuracy_tok: 0.8984206073140923
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6153846153846154
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7107601184600199
dev_label=P_precision_sent: 0.6763565891472868
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7270833333333333
dev_precision_macro_sent: 0.43058040151063404
dev_recall_macro_sent: 0.5423858437877129
dev_f-score_macro_sent: 0.47928115059778437
dev_precision_micro_sent: 0.6439600363306085
dev_recall_micro_sent: 0.6439600363306085
dev_f-score_micro_sent: 0.6439600363306085
dev_label=O_precision_tok: 0.9125953531706749
dev_label=O_recall_tok: 0.9671089170009256
dev_label=O_f-score_tok: 0.939061657379112
dev_label=N_precision_tok: 0.7813525935653316
dev_label=N_recall_tok: 0.6408185245018848
dev_label=N_f-score_tok: 0.7041420118343195
dev_label=P_precision_tok: 0.8731574864235842
dev_label=P_recall_tok: 0.7008094645080947
dev_label=P_f-score_tok: 0.7775474956822108
dev_precision_macro_tok: 0.8557018110531969
dev_recall_macro_tok: 0.7695789686703017
dev_f-score_macro_tok: 0.806917054965214
dev_precision_micro_tok: 0.8984206073140923
dev_recall_micro_tok: 0.8984206073140923
dev_f-score_micro_tok: 0.8984206073140923
dev_time: 5.077905654907227
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6154    0.8411    0.7108       428
           P     0.6764    0.7860    0.7271       444

   micro avg     0.6440    0.6440    0.6440      1101
   macro avg     0.4306    0.5424    0.4793      1101
weighted avg     0.5120    0.6440    0.5695      1101

F1-macro sent:  0.47928115059778437
F1-micro sent:  0.6439600363306085
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9126    0.9671    0.9391     16205
           N     0.7814    0.6408    0.7041      1857
           P     0.8732    0.7008    0.7775      3212

   micro avg     0.8984    0.8984    0.8984     21274
   macro avg     0.8557    0.7696    0.8069     21274
weighted avg     0.8952    0.8984    0.8942     21274

F1-macro tok:  0.806917054965214
F1-micro tok:  0.8984206073140923
**************************************************
Best epoch: 20
**************************************************

EPOCH: 25
Learning rate: 0.810000
train_cost_sum: 308140.4723510742
train_cost_avg: 36.065130190902885
train_count_sent: 8544.0
train_total_correct_sent: 5620.0
train_accuracy_sent: 0.6577715355805244
train_count_tok: 163566.0
train_total_correct_tok: 147073.0
train_accuracy_tok: 0.8991660858613648
train_label=O_precision_sent: 0.0
train_label=O_recall_sent: 0.0
train_label=O_f-score_sent: 0.0
train_label=N_precision_sent: 0.630377941526028
train_label=N_recall_sent: 0.8012084592145015
train_label=N_f-score_sent: 0.705600638552614
train_label=P_precision_sent: 0.6843440166013374
train_label=P_recall_sent: 0.8221606648199447
train_label=P_f-score_sent: 0.7469485340380018
train_precision_macro_sent: 0.4382406527091218
train_recall_macro_sent: 0.5411230413448154
train_f-score_macro_sent: 0.4841830575302053
train_precision_micro_sent: 0.6577715355805244
train_recall_micro_sent: 0.6577715355805244
train_f-score_micro_sent: 0.6577715355805244
train_label=O_precision_tok: 0.9103272738226125
train_label=O_recall_tok: 0.9721665983095692
train_label=O_f-score_tok: 0.9402312350033639
train_label=N_precision_tok: 0.8006953498478923
train_label=N_recall_tok: 0.648641036473736
train_label=N_f-score_tok: 0.7166919516085114
train_label=P_precision_tok: 0.8810401204131416
train_label=P_recall_tok: 0.6785385937562457
train_label=P_f-score_tok: 0.7666425797127631
train_precision_macro_tok: 0.8640209146945489
train_recall_macro_tok: 0.7664487428465169
train_f-score_macro_tok: 0.8078552554415461
train_precision_micro_tok: 0.8991660858613648
train_recall_micro_tok: 0.8991660858613648
train_f-score_micro_tok: 0.8991660858613648
train_time: 96.53028202056885
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000      1624
           N     0.6304    0.8012    0.7056      3310
           P     0.6843    0.8222    0.7469      3610

   micro avg     0.6578    0.6578    0.6578      8544
   macro avg     0.4382    0.5411    0.4842      8544
weighted avg     0.5334    0.6578    0.5890      8544

F1-macro sent:  0.4841830575302053
F1-micro sent:  0.6577715355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9103    0.9722    0.9402    124347
           N     0.8007    0.6486    0.7167     14202
           P     0.8810    0.6785    0.7666     25017

   micro avg     0.8992    0.8992    0.8992    163566
   macro avg     0.8640    0.7664    0.8079    163566
weighted avg     0.8963    0.8992    0.8943    163566

F1-macro tok:  0.8078552554415461
F1-micro tok:  0.8991660858613648
**************************************************
dev_cost_sum: 42262.19580078125
dev_cost_avg: 38.38528228953792
dev_count_sent: 1101.0
dev_total_correct_sent: 700.0
dev_accuracy_sent: 0.6357856494096276
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.684931506849315
dev_label=N_recall_sent: 0.7009345794392523
dev_label=N_f-score_sent: 0.6928406466512702
dev_label=P_precision_sent: 0.6033182503770739
dev_label=P_recall_sent: 0.9009009009009009
dev_label=P_f-score_sent: 0.7226738934056007
dev_precision_macro_sent: 0.42941658574212965
dev_recall_macro_sent: 0.5339451601133844
dev_f-score_macro_sent: 0.471838180018957
dev_precision_micro_sent: 0.6357856494096276
dev_recall_micro_sent: 0.6357856494096276
dev_f-score_micro_sent: 0.6357856494096276
dev_label=O_precision_tok: 0.9039326162426726
dev_label=O_recall_tok: 0.9801295896328294
dev_label=O_f-score_tok: 0.9404902889625769
dev_label=N_precision_tok: 0.8318250377073907
dev_label=N_recall_tok: 0.5939687668282175
dev_label=N_f-score_tok: 0.6930568645931511
dev_label=P_precision_tok: 0.918805216659655
dev_label=P_recall_tok: 0.6799501867995019
dev_label=P_f-score_tok: 0.7815351583467526
dev_precision_macro_tok: 0.8848542902032395
dev_recall_macro_tok: 0.7513495144201828
dev_f-score_macro_tok: 0.8050274373008269
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 5.1173858642578125
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6849    0.7009    0.6928       428
           P     0.6033    0.9009    0.7227       444

   micro avg     0.6358    0.6358    0.6358      1101
   macro avg     0.4294    0.5339    0.4718      1101
weighted avg     0.5096    0.6358    0.5608      1101

F1-macro sent:  0.471838180018957
F1-micro sent:  0.6357856494096276
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9039    0.9801    0.9405     16205
           N     0.8318    0.5940    0.6931      1857
           P     0.9188    0.6800    0.7815      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8849    0.7513    0.8050     21274
weighted avg     0.8999    0.9011    0.8949     21274

F1-macro tok:  0.8050274373008269
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 20
**************************************************

EPOCH: 26
Learning rate: 0.729000
train_cost_sum: 306722.1857910156
train_cost_avg: 35.89913223209452
train_count_sent: 8544.0
train_total_correct_sent: 5598.0
train_accuracy_sent: 0.6551966292134831
train_count_tok: 163566.0
train_total_correct_tok: 147331.0
train_accuracy_tok: 0.9007434307863492
train_label=O_precision_sent: 0.42857142857142855
train_label=O_recall_sent: 0.003694581280788177
train_label=O_f-score_sent: 0.007326007326007325
train_label=N_precision_sent: 0.6353510895883777
train_label=N_recall_sent: 0.7927492447129909
train_label=N_f-score_sent: 0.7053763440860216
train_label=P_precision_sent: 0.6745454545454546
train_label=P_recall_sent: 0.8221606648199447
train_label=P_f-score_sent: 0.7410736579275905
train_precision_macro_sent: 0.5794893242350869
train_recall_macro_sent: 0.5395348302712413
train_f-score_macro_sent: 0.48459200311320644
train_precision_micro_sent: 0.6551966292134831
train_recall_micro_sent: 0.6551966292134831
train_f-score_micro_sent: 0.6551966292134831
train_label=O_precision_tok: 0.911523502276359
train_label=O_recall_tok: 0.9725204468141572
train_label=O_f-score_tok: 0.9410345699667335
train_label=N_precision_tok: 0.8090482806530045
train_label=N_recall_tok: 0.6560343613575553
train_label=N_f-score_tok: 0.7245508982035929
train_label=P_precision_tok: 0.8814363842740687
train_label=P_recall_tok: 0.6828956309709397
train_label=P_f-score_tok: 0.7695668821369851
train_precision_macro_tok: 0.8673360557344774
train_recall_macro_tok: 0.7704834797142174
train_f-score_macro_tok: 0.8117174501024372
train_precision_micro_tok: 0.9007434307863492
train_recall_micro_tok: 0.9007434307863492
train_f-score_micro_tok: 0.9007434307863492
train_time: 97.8640570640564
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4286    0.0037    0.0073      1624
           N     0.6354    0.7927    0.7054      3310
           P     0.6745    0.8222    0.7411      3610

   micro avg     0.6552    0.6552    0.6552      8544
   macro avg     0.5795    0.5395    0.4846      8544
weighted avg     0.6126    0.6552    0.5878      8544

F1-macro sent:  0.48459200311320644
F1-micro sent:  0.6551966292134831
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9115    0.9725    0.9410    124347
           N     0.8090    0.6560    0.7246     14202
           P     0.8814    0.6829    0.7696     25017

   micro avg     0.9007    0.9007    0.9007    163566
   macro avg     0.8673    0.7705    0.8117    163566
weighted avg     0.8980    0.9007    0.8960    163566

F1-macro tok:  0.8117174501024372
F1-micro tok:  0.9007434307863492
**************************************************
dev_cost_sum: 42165.18542480469
dev_cost_avg: 38.29717113969545
dev_count_sent: 1101.0
dev_total_correct_sent: 717.0
dev_accuracy_sent: 0.6512261580381471
dev_count_tok: 21274.0
dev_total_correct_tok: 19135.0
dev_accuracy_tok: 0.8994547334774843
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6595744680851063
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7216931216931216
dev_label=P_precision_sent: 0.6438356164383562
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.7315175097276265
dev_precision_macro_sent: 0.4344700281744875
dev_recall_macro_sent: 0.5478586062698212
dev_f-score_macro_sent: 0.484403543806916
dev_precision_micro_sent: 0.6512261580381471
dev_recall_micro_sent: 0.6512261580381471
dev_f-score_micro_sent: 0.6512261580381471
dev_label=O_precision_tok: 0.9069714023199724
dev_label=O_recall_tok: 0.9746374575748226
dev_label=O_f-score_tok: 0.9395877331271008
dev_label=N_precision_tok: 0.8222713864306784
dev_label=N_recall_tok: 0.600430802369413
dev_label=N_f-score_tok: 0.6940553999377529
dev_label=P_precision_tok: 0.8889776357827476
dev_label=P_recall_tok: 0.6930261519302615
dev_label=P_f-score_tok: 0.7788663400979706
dev_precision_macro_tok: 0.8727401415111328
dev_recall_macro_tok: 0.7560314706248324
dev_f-score_macro_tok: 0.804169824387608
dev_precision_micro_tok: 0.8994547334774843
dev_recall_micro_tok: 0.8994547334774843
dev_f-score_micro_tok: 0.8994547334774842
dev_time: 5.19518780708313
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6596    0.7967    0.7217       428
           P     0.6438    0.8468    0.7315       444

   micro avg     0.6512    0.6512    0.6512      1101
   macro avg     0.4345    0.5479    0.4844      1101
weighted avg     0.5160    0.6512    0.5755      1101

F1-macro sent:  0.484403543806916
F1-micro sent:  0.6512261580381471
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9070    0.9746    0.9396     16205
           N     0.8223    0.6004    0.6941      1857
           P     0.8890    0.6930    0.7789      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8727    0.7560    0.8042     21274
weighted avg     0.8969    0.8995    0.8939     21274

F1-macro tok:  0.804169824387608
F1-micro tok:  0.8994547334774842
**************************************************
Best epoch: 26
**************************************************

EPOCH: 27
Learning rate: 0.729000
train_cost_sum: 305624.7172241211
train_cost_avg: 35.77068319570706
train_count_sent: 8544.0
train_total_correct_sent: 5662.0
train_accuracy_sent: 0.662687265917603
train_count_tok: 163566.0
train_total_correct_tok: 147498.0
train_accuracy_tok: 0.9017644253695756
train_label=O_precision_sent: 0.5
train_label=O_recall_sent: 0.010467980295566502
train_label=O_f-score_sent: 0.020506634499396863
train_label=N_precision_sent: 0.6248858447488584
train_label=N_recall_sent: 0.8268882175226586
train_label=N_f-score_sent: 0.7118335500650194
train_label=P_precision_sent: 0.7041162227602905
train_label=P_recall_sent: 0.8055401662049861
train_label=P_f-score_sent: 0.7514211886304909
train_precision_macro_sent: 0.609667355836383
train_recall_macro_sent: 0.5476321213410704
train_f-score_macro_sent: 0.4945871243983024
train_precision_micro_sent: 0.662687265917603
train_recall_micro_sent: 0.662687265917603
train_f-score_micro_sent: 0.662687265917603
train_label=O_precision_tok: 0.9132422161275943
train_label=O_recall_tok: 0.9720700941719543
train_label=O_f-score_tok: 0.9417383445524806
train_label=N_precision_tok: 0.8044372108960082
train_label=N_recall_tok: 0.6612448950851992
train_label=N_f-score_tok: 0.7258463441026434
train_label=P_precision_tok: 0.8821602252367545
train_label=P_recall_tok: 0.688851580924971
train_label=P_f-score_tok: 0.773612856886335
train_precision_macro_tok: 0.866613217420119
train_recall_macro_tok: 0.7740555233940415
train_f-score_macro_tok: 0.8137325151804863
train_precision_micro_tok: 0.9017644253695756
train_recall_micro_tok: 0.9017644253695756
train_f-score_micro_tok: 0.9017644253695756
train_time: 97.8003306388855
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0105    0.0205      1624
           N     0.6249    0.8269    0.7118      3310
           P     0.7041    0.8055    0.7514      3610

   micro avg     0.6627    0.6627    0.6627      8544
   macro avg     0.6097    0.5476    0.4946      8544
weighted avg     0.6346    0.6627    0.5972      8544

F1-macro sent:  0.4945871243983024
F1-micro sent:  0.662687265917603
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9132    0.9721    0.9417    124347
           N     0.8044    0.6612    0.7258     14202
           P     0.8822    0.6889    0.7736     25017

   micro avg     0.9018    0.9018    0.9018    163566
   macro avg     0.8666    0.7741    0.8137    163566
weighted avg     0.8990    0.9018    0.8973    163566

F1-macro tok:  0.8137325151804863
F1-micro tok:  0.9017644253695756
**************************************************
dev_cost_sum: 42126.092529296875
dev_cost_avg: 38.26166442261297
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19187.0
dev_accuracy_tok: 0.9018990316818651
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6541353383458647
dev_label=N_recall_sent: 0.8130841121495327
dev_label=N_f-score_sent: 0.7249999999999999
dev_label=P_precision_sent: 0.6596119929453262
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7398615232443125
dev_precision_macro_sent: 0.43791577709706364
dev_recall_macro_sent: 0.5518088181639583
dev_f-score_macro_sent: 0.48828717441477076
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9088453359388471
dev_label=O_recall_tok: 0.9758099352051836
dev_label=O_f-score_tok: 0.9411379597666943
dev_label=N_precision_tok: 0.7937584803256446
dev_label=N_recall_tok: 0.630048465266559
dev_label=N_f-score_tok: 0.7024917442209547
dev_label=P_precision_tok: 0.9179508538109121
dev_label=P_recall_tok: 0.6861768368617683
dev_label=P_f-score_tok: 0.7853197933368965
dev_precision_macro_tok: 0.873518223358468
dev_recall_macro_tok: 0.7640117457778369
dev_f-score_macro_tok: 0.8096498324415151
dev_precision_micro_tok: 0.9018990316818651
dev_recall_micro_tok: 0.9018990316818651
dev_f-score_micro_tok: 0.9018990316818651
dev_time: 5.067709684371948
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6541    0.8131    0.7250       428
           P     0.6596    0.8423    0.7399       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.4379    0.5518    0.4883      1101
weighted avg     0.5203    0.6558    0.5802      1101

F1-macro sent:  0.48828717441477076
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9758    0.9411     16205
           N     0.7938    0.6300    0.7025      1857
           P     0.9180    0.6862    0.7853      3212

   micro avg     0.9019    0.9019    0.9019     21274
   macro avg     0.8735    0.7640    0.8096     21274
weighted avg     0.9002    0.9019    0.8968     21274

F1-macro tok:  0.8096498324415151
F1-micro tok:  0.9018990316818651
**************************************************
Best epoch: 27
**************************************************

EPOCH: 28
Learning rate: 0.729000
train_cost_sum: 303952.4613647461
train_cost_avg: 35.574960365724024
train_count_sent: 8544.0
train_total_correct_sent: 5694.0
train_accuracy_sent: 0.6664325842696629
train_count_tok: 163566.0
train_total_correct_tok: 147891.0
train_accuracy_tok: 0.9041671251971681
train_label=O_precision_sent: 0.30434782608695654
train_label=O_recall_sent: 0.004310344827586207
train_label=O_f-score_sent: 0.008500303582270795
train_label=N_precision_sent: 0.6288050885960926
train_label=N_recall_sent: 0.8362537764350453
train_label=N_f-score_sent: 0.7178423236514523
train_label=P_precision_sent: 0.708667152221413
train_label=P_recall_sent: 0.8085872576177285
train_label=P_f-score_sent: 0.7553370423081899
train_precision_macro_sent: 0.5472733556348207
train_recall_macro_sent: 0.5497171262934534
train_f-score_macro_sent: 0.49389322318063766
train_precision_micro_sent: 0.6664325842696629
train_recall_micro_sent: 0.6664325842696629
train_f-score_micro_sent: 0.6664325842696629
train_label=O_precision_tok: 0.9150762204343355
train_label=O_recall_tok: 0.9732201018118651
train_label=O_f-score_tok: 0.9432529862234259
train_label=N_precision_tok: 0.8121076618797833
train_label=N_recall_tok: 0.6649767638360794
train_label=N_f-score_tok: 0.731214432271302
train_label=P_precision_tok: 0.8852658845040378
train_label=P_recall_tok: 0.6967262261662069
train_label=P_f-score_tok: 0.7797611058918267
train_precision_macro_tok: 0.8708165889393854
train_recall_macro_tok: 0.7783076972713839
train_f-score_macro_tok: 0.8180761747955182
train_precision_micro_tok: 0.9041671251971681
train_recall_micro_tok: 0.9041671251971681
train_f-score_micro_tok: 0.9041671251971681
train_time: 96.67134213447571
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3043    0.0043    0.0085      1624
           N     0.6288    0.8363    0.7178      3310
           P     0.7087    0.8086    0.7553      3610

   micro avg     0.6664    0.6664    0.6664      8544
   macro avg     0.5473    0.5497    0.4939      8544
weighted avg     0.6009    0.6664    0.5989      8544

F1-macro sent:  0.49389322318063766
F1-micro sent:  0.6664325842696629
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9151    0.9732    0.9433    124347
           N     0.8121    0.6650    0.7312     14202
           P     0.8853    0.6967    0.7798     25017

   micro avg     0.9042    0.9042    0.9042    163566
   macro avg     0.8708    0.7783    0.8181    163566
weighted avg     0.9016    0.9042    0.8998    163566

F1-macro tok:  0.8180761747955182
F1-micro tok:  0.9041671251971681
**************************************************
dev_cost_sum: 42128.196228027344
dev_cost_avg: 38.26357513898941
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19160.0
dev_accuracy_tok: 0.9006298768449751
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.026200873362445413
dev_label=O_f-score_sent: 0.049792531120331954
dev_label=N_precision_sent: 0.6673189823874756
dev_label=N_recall_sent: 0.7967289719626168
dev_label=N_f-score_sent: 0.7263045793397231
dev_label=P_precision_sent: 0.6505190311418685
dev_label=P_recall_sent: 0.8468468468468469
dev_label=P_f-score_sent: 0.735812133072407
dev_precision_macro_sent: 0.6059460045097814
dev_recall_macro_sent: 0.5565922307239697
dev_f-score_macro_sent: 0.503969747844154
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9087612249597052
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.9403460702266432
dev_label=N_precision_tok: 0.8046709129511678
dev_label=N_recall_tok: 0.6122778675282714
dev_label=N_f-score_tok: 0.6954128440366973
dev_label=P_precision_tok: 0.8983527521092808
dev_label=P_recall_tok: 0.6961394769613948
dev_label=P_f-score_tok: 0.7844237853008243
dev_precision_macro_tok: 0.8705949633400513
dev_recall_macro_tok: 0.7608742788739081
dev_f-score_macro_tok: 0.8067275665213883
dev_precision_micro_tok: 0.9006298768449751
dev_recall_micro_tok: 0.9006298768449751
dev_f-score_micro_tok: 0.9006298768449751
dev_time: 5.034081697463989
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0262    0.0498       229
           N     0.6673    0.7967    0.7263       428
           P     0.6505    0.8468    0.7358       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.6059    0.5566    0.5040      1101
weighted avg     0.6257    0.6567    0.5894      1101

F1-macro sent:  0.503969747844154
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9742    0.9403     16205
           N     0.8047    0.6123    0.6954      1857
           P     0.8984    0.6961    0.7844      3212

   micro avg     0.9006    0.9006    0.9006     21274
   macro avg     0.8706    0.7609    0.8067     21274
weighted avg     0.8981    0.9006    0.8954     21274

F1-macro tok:  0.8067275665213883
F1-micro tok:  0.9006298768449751
**************************************************
Best epoch: 28
**************************************************

EPOCH: 29
Learning rate: 0.729000
train_cost_sum: 303341.8770751953
train_cost_avg: 35.50349684868859
train_count_sent: 8544.0
train_total_correct_sent: 5696.0
train_accuracy_sent: 0.6666666666666666
train_count_tok: 163566.0
train_total_correct_tok: 147954.0
train_accuracy_tok: 0.9045522908183853
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014510278113663845
train_label=N_precision_sent: 0.6384234127920698
train_label=N_recall_sent: 0.8172205438066465
train_label=N_f-score_sent: 0.7168411289254009
train_label=P_precision_sent: 0.6965162497077391
train_label=P_recall_sent: 0.8252077562326869
train_label=P_f-score_sent: 0.7554203119056675
train_precision_macro_sent: 0.5783132208332696
train_recall_macro_sent: 0.5499391542003033
train_f-score_macro_sent: 0.49559057298157744
train_precision_micro_sent: 0.6666666666666666
train_recall_micro_sent: 0.6666666666666666
train_f-score_micro_sent: 0.6666666666666666
train_label=O_precision_tok: 0.9157094505061825
train_label=O_recall_tok: 0.9725606568714967
train_label=O_f-score_tok: 0.9432792281232695
train_label=N_precision_tok: 0.8130793434815886
train_label=N_recall_tok: 0.6732150401351922
train_label=N_f-score_tok: 0.7365663880436039
train_label=P_precision_tok: 0.8843971631205674
train_label=P_recall_tok: 0.697845465083743
train_label=P_f-score_tok: 0.7801237795205219
train_precision_macro_tok: 0.8710619857027795
train_recall_macro_tok: 0.781207054030144
train_f-score_macro_tok: 0.8199897985624651
train_precision_micro_tok: 0.9045522908183853
train_recall_micro_tok: 0.9045522908183853
train_f-score_micro_tok: 0.9045522908183853
train_time: 97.31607627868652
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0074    0.0145      1624
           N     0.6384    0.8172    0.7168      3310
           P     0.6965    0.8252    0.7554      3610

   micro avg     0.6667    0.6667    0.6667      8544
   macro avg     0.5783    0.5499    0.4956      8544
weighted avg     0.6177    0.6667    0.5996      8544

F1-macro sent:  0.49559057298157744
F1-micro sent:  0.6666666666666666
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9157    0.9726    0.9433    124347
           N     0.8131    0.6732    0.7366     14202
           P     0.8844    0.6978    0.7801     25017

   micro avg     0.9046    0.9046    0.9046    163566
   macro avg     0.8711    0.7812    0.8200    163566
weighted avg     0.9020    0.9046    0.9004    163566

F1-macro tok:  0.8199897985624651
F1-micro tok:  0.9045522908183853
**************************************************
dev_cost_sum: 42028.52868652344
dev_cost_avg: 38.1730505781321
dev_count_sent: 1101.0
dev_total_correct_sent: 705.0
dev_accuracy_sent: 0.6403269754768393
dev_count_tok: 21274.0
dev_total_correct_tok: 19140.0
dev_accuracy_tok: 0.8996897621509824
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6716101694915254
dev_label=N_recall_sent: 0.7406542056074766
dev_label=N_f-score_sent: 0.7044444444444444
dev_label=P_precision_sent: 0.6168521462639109
dev_label=P_recall_sent: 0.8738738738738738
dev_label=P_f-score_sent: 0.7232059645852749
dev_precision_macro_sent: 0.4294874385851455
dev_recall_macro_sent: 0.5381760264937835
dev_f-score_macro_sent: 0.4758834696765731
dev_precision_micro_sent: 0.6403269754768393
dev_recall_micro_sent: 0.6403269754768393
dev_f-score_micro_sent: 0.6403269754768393
dev_label=O_precision_tok: 0.9122735717603344
dev_label=O_recall_tok: 0.9696390003085468
dev_label=O_f-score_tok: 0.9400819647611356
dev_label=N_precision_tok: 0.7685364281108962
dev_label=N_recall_tok: 0.6418955304254174
dev_label=N_f-score_tok: 0.6995305164319249
dev_label=P_precision_tok: 0.8943577430972389
dev_label=P_recall_tok: 0.6958281444582815
dev_label=P_f-score_tok: 0.7827000525302048
dev_precision_macro_tok: 0.8583892476561564
dev_recall_macro_tok: 0.7691208917307485
dev_f-score_macro_tok: 0.8074375112410884
dev_precision_micro_tok: 0.8996897621509824
dev_recall_micro_tok: 0.8996897621509824
dev_f-score_micro_tok: 0.8996897621509824
dev_time: 5.141259431838989
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6716    0.7407    0.7044       428
           P     0.6169    0.8739    0.7232       444

   micro avg     0.6403    0.6403    0.6403      1101
   macro avg     0.4295    0.5382    0.4759      1101
weighted avg     0.5098    0.6403    0.5655      1101

F1-macro sent:  0.4758834696765731
F1-micro sent:  0.6403269754768393
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9696    0.9401     16205
           N     0.7685    0.6419    0.6995      1857
           P     0.8944    0.6958    0.7827      3212

   micro avg     0.8997    0.8997    0.8997     21274
   macro avg     0.8584    0.7691    0.8074     21274
weighted avg     0.8970    0.8997    0.8953     21274

F1-macro tok:  0.8074375112410884
F1-micro tok:  0.8996897621509824
**************************************************
Best epoch: 28
**************************************************

EPOCH: 30
Learning rate: 0.729000
train_cost_sum: 301887.6635131836
train_cost_avg: 35.33329395051306
train_count_sent: 8544.0
train_total_correct_sent: 5689.0
train_accuracy_sent: 0.6658473782771536
train_count_tok: 163566.0
train_total_correct_tok: 148195.0
train_accuracy_tok: 0.9060257021630412
train_label=O_precision_sent: 0.3
train_label=O_recall_sent: 0.005541871921182266
train_label=O_f-score_sent: 0.010882708585247884
train_label=N_precision_sent: 0.6312629877626414
train_label=N_recall_sent: 0.8259818731117825
train_label=N_f-score_sent: 0.7156131396414083
train_label=P_precision_sent: 0.7042792254362897
train_label=P_recall_sent: 0.8160664819944599
train_label=P_f-score_sent: 0.7560631335814192
train_precision_macro_sent: 0.545180737732977
train_recall_macro_sent: 0.5491967423424748
train_f-score_macro_sent: 0.49418632726935846
train_precision_micro_sent: 0.6658473782771536
train_recall_micro_sent: 0.6658473782771536
train_f-score_micro_sent: 0.6658473782771536
train_label=O_precision_tok: 0.9177356830198985
train_label=O_recall_tok: 0.972882337330213
train_label=O_f-score_tok: 0.9445047352107618
train_label=N_precision_tok: 0.8119029503761941
train_label=N_recall_tok: 0.676242782706661
train_label=N_f-score_tok: 0.7378894395144252
train_label=P_precision_tok: 0.8844261472035345
train_label=P_recall_tok: 0.7041611704041252
train_label=P_f-score_tok: 0.784065872927562
train_precision_macro_tok: 0.8713549268665424
train_recall_macro_tok: 0.784428763480333
train_f-score_macro_tok: 0.822153349217583
train_precision_micro_tok: 0.9060257021630412
train_recall_micro_tok: 0.9060257021630412
train_f-score_micro_tok: 0.9060257021630412
train_time: 97.56318497657776
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3000    0.0055    0.0109      1624
           N     0.6313    0.8260    0.7156      3310
           P     0.7043    0.8161    0.7561      3610

   micro avg     0.6658    0.6658    0.6658      8544
   macro avg     0.5452    0.5492    0.4942      8544
weighted avg     0.5991    0.6658    0.5988      8544

F1-macro sent:  0.49418632726935846
F1-micro sent:  0.6658473782771536
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9177    0.9729    0.9445    124347
           N     0.8119    0.6762    0.7379     14202
           P     0.8844    0.7042    0.7841     25017

   micro avg     0.9060    0.9060    0.9060    163566
   macro avg     0.8714    0.7844    0.8222    163566
weighted avg     0.9035    0.9060    0.9020    163566

F1-macro tok:  0.822153349217583
F1-micro tok:  0.9060257021630412
**************************************************
dev_cost_sum: 42098.74645996094
dev_cost_avg: 38.23682693911075
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19191.0
dev_accuracy_tok: 0.9020870546206637
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6228668941979523
dev_label=N_recall_sent: 0.852803738317757
dev_label=N_f-score_sent: 0.7199211045364892
dev_label=P_precision_sent: 0.6912621359223301
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7424400417101147
dev_precision_macro_sent: 0.4380430100400941
dev_recall_macro_sent: 0.551535180039853
dev_f-score_macro_sent: 0.48745371541553456
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9106113033448674
dev_label=O_recall_tok: 0.9743906201789572
dev_label=O_f-score_tok: 0.9414219704874051
dev_label=N_precision_tok: 0.8093903293622985
dev_label=N_recall_tok: 0.6219709208400647
dev_label=N_f-score_tok: 0.7034104750304506
dev_label=P_precision_tok: 0.8958915037893898
dev_label=P_recall_tok: 0.699252801992528
dev_label=P_f-score_tok: 0.7854520020982689
dev_precision_macro_tok: 0.8719643788321852
dev_recall_macro_tok: 0.7652047810038499
dev_f-score_macro_tok: 0.8100948158720415
dev_precision_micro_tok: 0.9020870546206637
dev_recall_micro_tok: 0.9020870546206637
dev_f-score_micro_tok: 0.9020870546206639
dev_time: 5.133851051330566
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6229    0.8528    0.7199       428
           P     0.6913    0.8018    0.7424       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.4380    0.5515    0.4875      1101
weighted avg     0.5209    0.6549    0.5793      1101

F1-macro sent:  0.48745371541553456
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9106    0.9744    0.9414     16205
           N     0.8094    0.6220    0.7034      1857
           P     0.8959    0.6993    0.7855      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8720    0.7652    0.8101     21274
weighted avg     0.8996    0.9021    0.8971     21274

F1-macro tok:  0.8100948158720415
F1-micro tok:  0.9020870546206639
**************************************************
Best epoch: 28
**************************************************

EPOCH: 31
Learning rate: 0.729000
train_cost_sum: 300968.9595336914
train_cost_avg: 35.225767735684855
train_count_sent: 8544.0
train_total_correct_sent: 5682.0
train_accuracy_sent: 0.6650280898876404
train_count_tok: 163566.0
train_total_correct_tok: 148359.0
train_accuracy_tok: 0.9070283555262096
train_label=O_precision_sent: 0.3157894736842105
train_label=O_recall_sent: 0.007389162561576354
train_label=O_f-score_sent: 0.014440433212996389
train_label=N_precision_sent: 0.6283783783783784
train_label=N_recall_sent: 0.8429003021148036
train_label=N_f-score_sent: 0.72
train_label=P_precision_sent: 0.7083128381701919
train_label=P_recall_sent: 0.7977839335180056
train_label=P_f-score_sent: 0.7503908285565399
train_precision_macro_sent: 0.5508268967442603
train_recall_macro_sent: 0.5493577993981286
train_f-score_macro_sent: 0.49494375392317874
train_precision_micro_sent: 0.6650280898876404
train_recall_micro_sent: 0.6650280898876404
train_f-score_micro_sent: 0.6650280898876404
train_label=O_precision_tok: 0.918753228600079
train_label=O_recall_tok: 0.9726089089403042
train_label=O_f-score_tok: 0.944914310715946
train_label=N_precision_tok: 0.8127107215104518
train_label=N_recall_tok: 0.6789184621884242
train_label=N_f-score_tok: 0.7398143175017264
train_label=P_precision_tok: 0.8858766071962524
train_label=P_recall_tok: 0.7105568213614742
train_label=P_f-score_tok: 0.7885899341215092
train_precision_macro_tok: 0.8724468524355945
train_recall_macro_tok: 0.7873613974967343
train_f-score_macro_tok: 0.8244395207797272
train_precision_micro_tok: 0.9070283555262096
train_recall_micro_tok: 0.9070283555262096
train_f-score_micro_tok: 0.9070283555262096
train_time: 97.93844699859619
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3158    0.0074    0.0144      1624
           N     0.6284    0.8429    0.7200      3310
           P     0.7083    0.7978    0.7504      3610

   micro avg     0.6650    0.6650    0.6650      8544
   macro avg     0.5508    0.5494    0.4949      8544
weighted avg     0.6027    0.6650    0.5987      8544

F1-macro sent:  0.49494375392317874
F1-micro sent:  0.6650280898876404
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9188    0.9726    0.9449    124347
           N     0.8127    0.6789    0.7398     14202
           P     0.8859    0.7106    0.7886     25017

   micro avg     0.9070    0.9070    0.9070    163566
   macro avg     0.8724    0.7874    0.8244    163566
weighted avg     0.9045    0.9070    0.9032    163566

F1-macro tok:  0.8244395207797272
F1-micro tok:  0.9070283555262096
**************************************************
dev_cost_sum: 41964.428161621094
dev_cost_avg: 38.1148303011999
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19186.0
dev_accuracy_tok: 0.9018520259471655
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6247906197654941
dev_label=N_recall_sent: 0.8714953271028038
dev_label=N_f-score_sent: 0.7278048780487806
dev_label=P_precision_sent: 0.6984126984126984
dev_label=P_recall_sent: 0.7927927927927928
dev_label=P_f-score_sent: 0.7426160337552742
dev_precision_macro_sent: 0.4410677727260642
dev_recall_macro_sent: 0.5547627066318656
dev_f-score_macro_sent: 0.49014030393468494
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9061107938320959
dev_label=O_recall_tok: 0.9790805307004011
dev_label=O_f-score_tok: 0.9411834495031884
dev_label=N_precision_tok: 0.8354912414318355
dev_label=N_recall_tok: 0.5907377490576198
dev_label=N_f-score_tok: 0.6921135646687696
dev_label=P_precision_tok: 0.9069767441860465
dev_label=P_recall_tok: 0.6920921544209215
dev_label=P_f-score_tok: 0.7850962387427158
dev_precision_macro_tok: 0.8828595931499926
dev_recall_macro_tok: 0.7539701447263142
dev_f-score_macro_tok: 0.8061310843048913
dev_precision_micro_tok: 0.9018520259471655
dev_recall_micro_tok: 0.9018520259471655
dev_f-score_micro_tok: 0.9018520259471655
dev_time: 5.110393047332764
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6248    0.8715    0.7278       428
           P     0.6984    0.7928    0.7426       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.4411    0.5548    0.4901      1101
weighted avg     0.5245    0.6585    0.5824      1101

F1-macro sent:  0.49014030393468494
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9061    0.9791    0.9412     16205
           N     0.8355    0.5907    0.6921      1857
           P     0.9070    0.6921    0.7851      3212

   micro avg     0.9019    0.9019    0.9019     21274
   macro avg     0.8829    0.7540    0.8061     21274
weighted avg     0.9001    0.9019    0.8959     21274

F1-macro tok:  0.8061310843048913
F1-micro tok:  0.9018520259471655
**************************************************
Best epoch: 28
**************************************************

EPOCH: 32
Learning rate: 0.729000
train_cost_sum: 299831.6275024414
train_cost_avg: 35.09265303165279
train_count_sent: 8544.0
train_total_correct_sent: 5705.0
train_accuracy_sent: 0.6677200374531835
train_count_tok: 163566.0
train_total_correct_tok: 148563.0
train_accuracy_tok: 0.9082755584901507
train_label=O_precision_sent: 0.29411764705882354
train_label=O_recall_sent: 0.003078817733990148
train_label=O_f-score_sent: 0.006093845216331505
train_label=N_precision_sent: 0.6441527446300715
train_label=N_recall_sent: 0.8154078549848942
train_label=N_f-score_sent: 0.7197333333333332
train_label=P_precision_sent: 0.6919529628775651
train_label=P_recall_sent: 0.8313019390581717
train_label=P_f-score_sent: 0.7552535548005537
train_precision_macro_sent: 0.5434077848554867
train_recall_macro_sent: 0.5499295372590187
train_f-score_macro_sent: 0.4936935777834061
train_precision_micro_sent: 0.6677200374531835
train_recall_micro_sent: 0.6677200374531835
train_f-score_micro_sent: 0.6677200374531835
train_label=O_precision_tok: 0.9204634556679684
train_label=O_recall_tok: 0.9723837326192027
train_label=O_f-score_tok: 0.9457115146964507
train_label=N_precision_tok: 0.8143582909969185
train_label=N_recall_tok: 0.6884945782284185
train_label=N_f-score_tok: 0.7461559006448167
train_label=P_precision_tok: 0.8848400831765522
train_label=P_recall_tok: 0.7143942119358836
train_label=P_f-score_tok: 0.7905341147849165
train_precision_macro_tok: 0.8732206099471463
train_recall_macro_tok: 0.7917575075945016
train_f-score_macro_tok: 0.827467176708728
train_precision_micro_tok: 0.9082755584901507
train_recall_micro_tok: 0.9082755584901507
train_f-score_micro_tok: 0.9082755584901507
train_time: 97.41761016845703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2941    0.0031    0.0061      1624
           N     0.6442    0.8154    0.7197      3310
           P     0.6920    0.8313    0.7553      3610

   micro avg     0.6677    0.6677    0.6677      8544
   macro avg     0.5434    0.5499    0.4937      8544
weighted avg     0.5978    0.6677    0.5991      8544

F1-macro sent:  0.4936935777834061
F1-micro sent:  0.6677200374531835
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9205    0.9724    0.9457    124347
           N     0.8144    0.6885    0.7462     14202
           P     0.8848    0.7144    0.7905     25017

   micro avg     0.9083    0.9083    0.9083    163566
   macro avg     0.8732    0.7918    0.8275    163566
weighted avg     0.9058    0.9083    0.9047    163566

F1-macro tok:  0.827467176708728
F1-micro tok:  0.9082755584901507
**************************************************
dev_cost_sum: 41968.83331298828
dev_cost_avg: 38.11883134694667
dev_count_sent: 1101.0
dev_total_correct_sent: 726.0
dev_accuracy_sent: 0.659400544959128
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6496350364963503
dev_label=N_recall_sent: 0.8317757009345794
dev_label=N_f-score_sent: 0.7295081967213114
dev_label=P_precision_sent: 0.6690777576853526
dev_label=P_recall_sent: 0.8333333333333334
dev_label=P_f-score_sent: 0.7422266800401205
dev_precision_macro_sent: 0.43957093139390097
dev_recall_macro_sent: 0.5550363447559709
dev_f-score_macro_sent: 0.49057829225381067
dev_precision_micro_sent: 0.659400544959128
dev_recall_micro_sent: 0.659400544959128
dev_f-score_micro_sent: 0.659400544959128
dev_label=O_precision_tok: 0.9123529070778506
dev_label=O_recall_tok: 0.9712434433816723
dev_label=O_f-score_tok: 0.9408775705404112
dev_label=N_precision_tok: 0.8068102849200834
dev_label=N_recall_tok: 0.6252019386106623
dev_label=N_f-score_tok: 0.7044902912621359
dev_label=P_precision_tok: 0.8792569659442725
dev_label=P_recall_tok: 0.7073474470734745
dev_label=P_f-score_tok: 0.7839889579020015
dev_precision_macro_tok: 0.8661400526474021
dev_recall_macro_tok: 0.7679309430219364
dev_f-score_macro_tok: 0.8097856065681829
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 5.011877059936523
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6496    0.8318    0.7295       428
           P     0.6691    0.8333    0.7422       444

   micro avg     0.6594    0.6594    0.6594      1101
   macro avg     0.4396    0.5550    0.4906      1101
weighted avg     0.5224    0.6594    0.5829      1101

F1-macro sent:  0.49057829225381067
F1-micro sent:  0.659400544959128
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9124    0.9712    0.9409     16205
           N     0.8068    0.6252    0.7045      1857
           P     0.8793    0.7073    0.7840      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8661    0.7679    0.8098     21274
weighted avg     0.8981    0.9012    0.8966     21274

F1-macro tok:  0.8097856065681829
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 28
**************************************************

EPOCH: 33
Learning rate: 0.656100
train_cost_sum: 298555.82830810547
train_cost_avg: 34.94333196489998
train_count_sent: 8544.0
train_total_correct_sent: 5702.0
train_accuracy_sent: 0.6673689138576779
train_count_tok: 163566.0
train_total_correct_tok: 148756.0
train_accuracy_tok: 0.9094555103138794
train_label=O_precision_sent: 0.34810126582278483
train_label=O_recall_sent: 0.033866995073891626
train_label=O_f-score_sent: 0.0617283950617284
train_label=N_precision_sent: 0.6411347517730497
train_label=N_recall_sent: 0.8193353474320242
train_label=N_f-score_sent: 0.7193633952254643
train_label=P_precision_sent: 0.7062078922040423
train_label=P_recall_sent: 0.8130193905817175
train_label=P_f-score_sent: 0.7558588720061807
train_precision_macro_sent: 0.5651479699332923
train_recall_macro_sent: 0.5554072443625445
train_f-score_macro_sent: 0.5123168874311245
train_precision_micro_sent: 0.6673689138576779
train_recall_micro_sent: 0.6673689138576779
train_f-score_micro_sent: 0.6673689138576779
train_label=O_precision_tok: 0.9212333983185086
train_label=O_recall_tok: 0.9728340852614056
train_label=O_f-score_tok: 0.9463308547713947
train_label=N_precision_tok: 0.8210262828535669
train_label=N_recall_tok: 0.6928601605407689
train_label=N_f-score_tok: 0.7515179287432696
train_label=P_precision_tok: 0.8854408209581134
train_label=P_recall_tok: 0.7173921733221409
train_label=P_f-score_tok: 0.7926069867067084
train_precision_macro_tok: 0.8759001673767296
train_recall_macro_tok: 0.7943621397081051
train_f-score_macro_tok: 0.8301519234071243
train_precision_micro_tok: 0.9094555103138794
train_recall_micro_tok: 0.9094555103138794
train_f-score_micro_tok: 0.9094555103138794
train_time: 97.91168093681335
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3481    0.0339    0.0617      1624
           N     0.6411    0.8193    0.7194      3310
           P     0.7062    0.8130    0.7559      3610

   micro avg     0.6674    0.6674    0.6674      8544
   macro avg     0.5651    0.5554    0.5123      8544
weighted avg     0.6129    0.6674    0.6098      8544

F1-macro sent:  0.5123168874311245
F1-micro sent:  0.6673689138576779
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9212    0.9728    0.9463    124347
           N     0.8210    0.6929    0.7515     14202
           P     0.8854    0.7174    0.7926     25017

   micro avg     0.9095    0.9095    0.9095    163566
   macro avg     0.8759    0.7944    0.8302    163566
weighted avg     0.9071    0.9095    0.9059    163566

F1-macro tok:  0.8301519234071243
F1-micro tok:  0.9094555103138794
**************************************************
dev_cost_sum: 41917.40270996094
dev_cost_avg: 38.07211871931057
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19217.0
dev_accuracy_tok: 0.9033092037228542
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6429872495446266
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.722620266120778
dev_label=P_precision_sent: 0.6684782608695652
dev_label=P_recall_sent: 0.831081081081081
dev_label=P_f-score_sent: 0.7409638554216869
dev_precision_macro_sent: 0.437155170138064
dev_recall_macro_sent: 0.5519491454070894
dev_f-score_macro_sent: 0.48786137384748834
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.912332408691632
dev_label=O_recall_tok: 0.974205492132058
dev_label=O_f-score_tok: 0.9422543197349965
dev_label=N_precision_tok: 0.8002717391304348
dev_label=N_recall_tok: 0.6343564889606893
dev_label=N_f-score_tok: 0.707720036046861
dev_label=P_precision_tok: 0.9015212169735789
dev_label=P_recall_tok: 0.701120797011208
dev_label=P_f-score_tok: 0.7887915936952714
dev_precision_macro_tok: 0.8713751215985486
dev_recall_macro_tok: 0.7698942593679852
dev_f-score_macro_tok: 0.812921983159043
dev_precision_micro_tok: 0.9033092037228542
dev_recall_micro_tok: 0.9033092037228542
dev_f-score_micro_tok: 0.9033092037228542
dev_time: 5.243578910827637
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6430    0.8248    0.7226       428
           P     0.6685    0.8311    0.7410       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.4372    0.5519    0.4879      1101
weighted avg     0.5195    0.6558    0.5797      1101

F1-macro sent:  0.48786137384748834
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9123    0.9742    0.9423     16205
           N     0.8003    0.6344    0.7077      1857
           P     0.9015    0.7011    0.7888      3212

   micro avg     0.9033    0.9033    0.9033     21274
   macro avg     0.8714    0.7699    0.8129     21274
weighted avg     0.9009    0.9033    0.8986     21274

F1-macro tok:  0.812921983159043
F1-micro tok:  0.9033092037228542
**************************************************
Best epoch: 28
**************************************************

EPOCH: 34
Learning rate: 0.590490
train_cost_sum: 297654.6036376953
train_cost_avg: 34.837851549355726
train_count_sent: 8544.0
train_total_correct_sent: 5709.0
train_accuracy_sent: 0.668188202247191
train_count_tok: 163566.0
train_total_correct_tok: 149011.0
train_accuracy_tok: 0.9110145140188058
train_label=O_precision_sent: 0.34523809523809523
train_label=O_recall_sent: 0.03571428571428571
train_label=O_f-score_sent: 0.06473214285714286
train_label=N_precision_sent: 0.6386672923510089
train_label=N_recall_sent: 0.8223564954682779
train_label=N_f-score_sent: 0.7189646064447967
train_label=P_precision_sent: 0.7119591638308216
train_label=P_recall_sent: 0.8113573407202216
train_label=P_f-score_sent: 0.758415328845158
train_precision_macro_sent: 0.5652881838066419
train_recall_macro_sent: 0.5564760406342617
train_f-score_macro_sent: 0.5140373593823658
train_precision_micro_sent: 0.668188202247191
train_recall_micro_sent: 0.668188202247191
train_f-score_micro_sent: 0.668188202247191
train_label=O_precision_tok: 0.9230945331339092
train_label=O_recall_tok: 0.9728099592270019
train_label=O_f-score_tok: 0.9473004138751954
train_label=N_precision_tok: 0.8204958129508333
train_label=N_recall_tok: 0.6968032671454725
train_label=N_f-score_tok: 0.7536077371206641
train_label=P_precision_tok: 0.8870045452323934
train_label=P_recall_tok: 0.7254666826557941
train_label=P_f-score_tok: 0.7981441576146708
train_precision_macro_tok: 0.8768649637723787
train_recall_macro_tok: 0.7983599696760896
train_f-score_macro_tok: 0.8330174362035101
train_precision_micro_tok: 0.9110145140188058
train_recall_micro_tok: 0.9110145140188058
train_f-score_micro_tok: 0.9110145140188058
train_time: 96.28787302970886
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3452    0.0357    0.0647      1624
           N     0.6387    0.8224    0.7190      3310
           P     0.7120    0.8114    0.7584      3610

   micro avg     0.6682    0.6682    0.6682      8544
   macro avg     0.5653    0.5565    0.5140      8544
weighted avg     0.6139    0.6682    0.6113      8544

F1-macro sent:  0.5140373593823658
F1-micro sent:  0.668188202247191
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9231    0.9728    0.9473    124347
           N     0.8205    0.6968    0.7536     14202
           P     0.8870    0.7255    0.7981     25017

   micro avg     0.9110    0.9110    0.9110    163566
   macro avg     0.8769    0.7984    0.8330    163566
weighted avg     0.9087    0.9110    0.9077    163566

F1-macro tok:  0.8330174362035101
F1-micro tok:  0.9110145140188058
**************************************************
dev_cost_sum: 41941.071838378906
dev_cost_avg: 38.09361656528511
dev_count_sent: 1101.0
dev_total_correct_sent: 719.0
dev_accuracy_sent: 0.6530426884650318
dev_count_tok: 21274.0
dev_total_correct_tok: 19184.0
dev_accuracy_tok: 0.9017580144777663
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.03056768558951965
dev_label=O_f-score_sent: 0.05761316872427984
dev_label=N_precision_sent: 0.6156405990016639
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7191448007774538
dev_label=P_precision_sent: 0.7037037037037037
dev_label=P_recall_sent: 0.7702702702702703
dev_label=P_f-score_sent: 0.735483870967742
dev_precision_macro_sent: 0.6064481009017891
dev_recall_macro_sent: 0.555107979056067
dev_f-score_macro_sent: 0.5040806134898252
dev_precision_micro_sent: 0.6530426884650318
dev_recall_micro_sent: 0.6530426884650318
dev_f-score_micro_sent: 0.6530426884650318
dev_label=O_precision_tok: 0.9114450867052023
dev_label=O_recall_tok: 0.973033014501697
dev_label=O_f-score_tok: 0.9412326518430084
dev_label=N_precision_tok: 0.8060941828254847
dev_label=N_recall_tok: 0.6268174474959612
dev_label=N_f-score_tok: 0.7052408361102697
dev_label=P_precision_tok: 0.8901185770750988
dev_label=P_recall_tok: 0.701120797011208
dev_label=P_f-score_tok: 0.7843956809474052
dev_precision_macro_tok: 0.8692192822019287
dev_recall_macro_tok: 0.7669904196696221
dev_f-score_macro_tok: 0.8102897229668944
dev_precision_micro_tok: 0.9017580144777663
dev_recall_micro_tok: 0.9017580144777663
dev_f-score_micro_tok: 0.9017580144777663
dev_time: 5.177165508270264
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0306    0.0576       229
           N     0.6156    0.8645    0.7191       428
           P     0.7037    0.7703    0.7355       444

   micro avg     0.6530    0.6530    0.6530      1101
   macro avg     0.6064    0.5551    0.5041      1101
weighted avg     0.6271    0.6530    0.5881      1101

F1-macro sent:  0.5040806134898252
F1-micro sent:  0.6530426884650318
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9114    0.9730    0.9412     16205
           N     0.8061    0.6268    0.7052      1857
           P     0.8901    0.7011    0.7844      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8692    0.7670    0.8103     21274
weighted avg     0.8990    0.9018    0.8970     21274

F1-macro tok:  0.8102897229668944
F1-micro tok:  0.9017580144777663
**************************************************
Best epoch: 34
**************************************************

EPOCH: 35
Learning rate: 0.590490
train_cost_sum: 296589.3411254883
train_cost_avg: 34.7131719482079
train_count_sent: 8544.0
train_total_correct_sent: 5752.0
train_accuracy_sent: 0.6732209737827716
train_count_tok: 163566.0
train_total_correct_tok: 149256.0
train_accuracy_tok: 0.9125123803235391
train_label=O_precision_sent: 0.3467741935483871
train_label=O_recall_sent: 0.02647783251231527
train_label=O_f-score_sent: 0.049199084668192214
train_label=N_precision_sent: 0.6401488718306583
train_label=N_recall_sent: 0.8314199395770393
train_label=N_f-score_sent: 0.7233539229859378
train_label=P_precision_sent: 0.7175442853676293
train_label=P_recall_sent: 0.8191135734072023
train_label=P_f-score_sent: 0.764972189884879
train_precision_macro_sent: 0.5681557835822248
train_recall_macro_sent: 0.5590037818321857
train_f-score_macro_sent: 0.5125083991796697
train_precision_micro_sent: 0.6732209737827716
train_recall_micro_sent: 0.6732209737827716
train_f-score_micro_sent: 0.6732209737827716
train_label=O_precision_tok: 0.9245636291382631
train_label=O_recall_tok: 0.9729305893990204
train_label=O_f-score_tok: 0.9481306744932386
train_label=N_precision_tok: 0.8229303547963206
train_label=N_recall_tok: 0.7055344317701732
train_label=N_f-score_tok: 0.7597240124346045
train_label=P_precision_tok: 0.8888401986561496
train_label=P_recall_tok: 0.7297038014150378
train_label=P_f-score_tok: 0.8014487981560751
train_precision_macro_tok: 0.8787780608635778
train_recall_macro_tok: 0.8027229408614104
train_f-score_macro_tok: 0.8364344950279728
train_precision_micro_tok: 0.9125123803235391
train_recall_micro_tok: 0.9125123803235391
train_f-score_micro_tok: 0.9125123803235391
train_time: 95.64746809005737
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3468    0.0265    0.0492      1624
           N     0.6401    0.8314    0.7234      3310
           P     0.7175    0.8191    0.7650      3610

   micro avg     0.6732    0.6732    0.6732      8544
   macro avg     0.5682    0.5590    0.5125      8544
weighted avg     0.6171    0.6732    0.6128      8544

F1-macro sent:  0.5125083991796697
F1-micro sent:  0.6732209737827716
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9246    0.9729    0.9481    124347
           N     0.8229    0.7055    0.7597     14202
           P     0.8888    0.7297    0.8014     25017

   micro avg     0.9125    0.9125    0.9125    163566
   macro avg     0.8788    0.8027    0.8364    163566
weighted avg     0.9103    0.9125    0.9093    163566

F1-macro tok:  0.8364344950279728
F1-micro tok:  0.9125123803235391
**************************************************
dev_cost_sum: 41927.759765625
dev_cost_avg: 38.081525672683924
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19184.0
dev_accuracy_tok: 0.9017580144777663
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6371841155234657
dev_label=N_recall_sent: 0.8247663551401869
dev_label=N_f-score_sent: 0.7189409368635438
dev_label=P_precision_sent: 0.6648351648351648
dev_label=P_recall_sent: 0.8175675675675675
dev_label=P_f-score_sent: 0.7333333333333334
dev_precision_macro_sent: 0.4340064267862102
dev_recall_macro_sent: 0.5474446409025848
dev_f-score_macro_sent: 0.48409142339895905
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9161067944149092
dev_label=O_recall_tok: 0.9676643011416229
dev_label=O_f-score_tok: 0.9411800012004082
dev_label=N_precision_tok: 0.7966442953020134
dev_label=N_recall_tok: 0.6392030156165859
dev_label=N_f-score_tok: 0.7092919031968928
dev_label=P_precision_tok: 0.8683914510686164
dev_label=P_recall_tok: 0.7210460772104608
dev_label=P_f-score_tok: 0.7878890967851675
dev_precision_macro_tok: 0.8603808469285129
dev_recall_macro_tok: 0.77597113132289
dev_f-score_macro_tok: 0.8127870003941563
dev_precision_micro_tok: 0.9017580144777663
dev_recall_micro_tok: 0.9017580144777663
dev_f-score_micro_tok: 0.9017580144777663
dev_time: 5.085999250411987
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6372    0.8248    0.7189       428
           P     0.6648    0.8176    0.7333       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.4340    0.5474    0.4841      1101
weighted avg     0.5158    0.6503    0.5752      1101

F1-macro sent:  0.48409142339895905
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9161    0.9677    0.9412     16205
           N     0.7966    0.6392    0.7093      1857
           P     0.8684    0.7210    0.7879      3212

   micro avg     0.9018    0.9018    0.9018     21274
   macro avg     0.8604    0.7760    0.8128     21274
weighted avg     0.8985    0.9018    0.8978     21274

F1-macro tok:  0.8127870003941563
F1-micro tok:  0.9017580144777663
**************************************************
Best epoch: 34
**************************************************

EPOCH: 36
Learning rate: 0.590490
train_cost_sum: 295771.0263671875
train_cost_avg: 34.6173954081446
train_count_sent: 8544.0
train_total_correct_sent: 5725.0
train_accuracy_sent: 0.670060861423221
train_count_tok: 163566.0
train_total_correct_tok: 149447.0
train_accuracy_tok: 0.9136801046672292
train_label=O_precision_sent: 0.36666666666666664
train_label=O_recall_sent: 0.0067733990147783255
train_label=O_f-score_sent: 0.013301088270858527
train_label=N_precision_sent: 0.6293944205035156
train_label=N_recall_sent: 0.8383685800604229
train_label=N_f-score_sent: 0.7190050524679362
train_label=P_precision_sent: 0.7159561510353227
train_label=P_recall_sent: 0.8141274238227146
train_label=P_f-score_sent: 0.761892417368762
train_precision_macro_sent: 0.5706724127351683
train_recall_macro_sent: 0.553089800965972
train_f-score_macro_sent: 0.49806618603585223
train_precision_micro_sent: 0.670060861423221
train_recall_micro_sent: 0.670060861423221
train_f-score_micro_sent: 0.670060861423221
train_label=O_precision_tok: 0.926289512374418
train_label=O_recall_tok: 0.9728099592270019
train_label=O_f-score_tok: 0.9489799520669651
train_label=N_precision_tok: 0.8246662844975842
train_label=N_recall_tok: 0.70905506266723
train_label=N_f-score_tok: 0.7625033127626547
train_label=P_precision_tok: 0.8867215720271637
train_label=P_recall_tok: 0.735939561098453
train_label=P_f-score_tok: 0.8043250327653998
train_precision_macro_tok: 0.8792257896330553
train_recall_macro_tok: 0.8059348609975617
train_f-score_macro_tok: 0.8386027658650065
train_precision_micro_tok: 0.9136801046672292
train_recall_micro_tok: 0.9136801046672292
train_f-score_micro_tok: 0.9136801046672292
train_time: 97.53790998458862
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3667    0.0068    0.0133      1624
           N     0.6294    0.8384    0.7190      3310
           P     0.7160    0.8141    0.7619      3610

   micro avg     0.6701    0.6701    0.6701      8544
   macro avg     0.5707    0.5531    0.4981      8544
weighted avg     0.6160    0.6701    0.6030      8544

F1-macro sent:  0.49806618603585223
F1-micro sent:  0.670060861423221
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9263    0.9728    0.9490    124347
           N     0.8247    0.7091    0.7625     14202
           P     0.8867    0.7359    0.8043     25017

   micro avg     0.9137    0.9137    0.9137    163566
   macro avg     0.8792    0.8059    0.8386    163566
weighted avg     0.9114    0.9137    0.9107    163566

F1-macro tok:  0.8386027658650065
F1-micro tok:  0.9136801046672292
**************************************************
dev_cost_sum: 42023.11053466797
dev_cost_avg: 38.16812945928063
dev_count_sent: 1101.0
dev_total_correct_sent: 723.0
dev_accuracy_sent: 0.6566757493188011
dev_count_tok: 21274.0
dev_total_correct_tok: 19167.0
dev_accuracy_tok: 0.9009589169878726
dev_label=O_precision_sent: 0.0
dev_label=O_recall_sent: 0.0
dev_label=O_f-score_sent: 0.0
dev_label=N_precision_sent: 0.6487985212569316
dev_label=N_recall_sent: 0.8200934579439252
dev_label=N_f-score_sent: 0.7244582043343654
dev_label=P_precision_sent: 0.6654740608228981
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7417746759720838
dev_precision_macro_sent: 0.4380908606932765
dev_recall_macro_sent: 0.5526437652605877
dev_f-score_macro_sent: 0.4887442934354831
dev_precision_micro_sent: 0.6566757493188011
dev_recall_micro_sent: 0.6566757493188011
dev_f-score_micro_sent: 0.6566757493188011
dev_label=O_precision_tok: 0.9087668870365048
dev_label=O_recall_tok: 0.9755013884603517
dev_label=O_f-score_tok: 0.940952380952381
dev_label=N_precision_tok: 0.8276643990929705
dev_label=N_recall_tok: 0.5896607431340872
dev_label=N_f-score_tok: 0.6886792452830189
dev_label=P_precision_tok: 0.8857589984350548
dev_label=P_recall_tok: 0.7048567870485679
dev_label=P_f-score_tok: 0.7850208044382803
dev_precision_macro_tok: 0.8740634281881766
dev_recall_macro_tok: 0.7566729728810023
dev_f-score_macro_tok: 0.8048841435578934
dev_precision_micro_tok: 0.9009589169878726
dev_recall_micro_tok: 0.9009589169878726
dev_f-score_micro_tok: 0.9009589169878726
dev_time: 5.08558988571167
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.0000    0.0000    0.0000       229
           N     0.6488    0.8201    0.7245       428
           P     0.6655    0.8378    0.7418       444

   micro avg     0.6567    0.6567    0.6567      1101
   macro avg     0.4381    0.5526    0.4887      1101
weighted avg     0.5206    0.6567    0.5808      1101

F1-macro sent:  0.4887442934354831
F1-micro sent:  0.6566757493188011
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9088    0.9755    0.9410     16205
           N     0.8277    0.5897    0.6887      1857
           P     0.8858    0.7049    0.7850      3212

   micro avg     0.9010    0.9010    0.9010     21274
   macro avg     0.8741    0.7567    0.8049     21274
weighted avg     0.8982    0.9010    0.8954     21274

F1-macro tok:  0.8048841435578934
F1-micro tok:  0.9009589169878726
**************************************************
Best epoch: 34
**************************************************

EPOCH: 37
Learning rate: 0.590490
train_cost_sum: 294946.6516113281
train_cost_avg: 34.52090959870414
train_count_sent: 8544.0
train_total_correct_sent: 5721.0
train_accuracy_sent: 0.6695926966292135
train_count_tok: 163566.0
train_total_correct_tok: 149579.0
train_accuracy_tok: 0.9144871183497792
train_label=O_precision_sent: 0.31092436974789917
train_label=O_recall_sent: 0.022783251231527094
train_label=O_f-score_sent: 0.04245553643144005
train_label=N_precision_sent: 0.6454437869822485
train_label=N_recall_sent: 0.8238670694864049
train_label=N_f-score_sent: 0.7238221632382216
train_label=P_precision_sent: 0.704047619047619
train_label=P_recall_sent: 0.8191135734072023
train_label=P_f-score_sent: 0.7572343149807939
train_precision_macro_sent: 0.5534719252592556
train_recall_macro_sent: 0.5552546313750447
train_f-score_macro_sent: 0.5078373382168185
train_precision_micro_sent: 0.6695926966292135
train_recall_micro_sent: 0.6695926966292135
train_f-score_micro_sent: 0.6695926966292135
train_label=O_precision_tok: 0.9270705615497793
train_label=O_recall_tok: 0.9729145053760847
train_label=O_f-score_tok: 0.949439458804048
train_label=N_precision_tok: 0.8241874037448326
train_label=N_recall_tok: 0.7159554992254612
train_label=N_f-score_tok: 0.76626851049399
train_label=P_precision_tok: 0.8890175083200694
train_label=P_recall_tok: 0.7367789902866051
train_label=P_f-score_tok: 0.8057704918032788
train_precision_macro_tok: 0.8800918245382271
train_recall_macro_tok: 0.8085496649627171
train_f-score_macro_tok: 0.8404928203671056
train_precision_micro_tok: 0.9144871183497792
train_recall_micro_tok: 0.9144871183497792
train_f-score_micro_tok: 0.9144871183497792
train_time: 96.7816481590271
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3109    0.0228    0.0425      1624
           N     0.6454    0.8239    0.7238      3310
           P     0.7040    0.8191    0.7572      3610

   micro avg     0.6696    0.6696    0.6696      8544
   macro avg     0.5535    0.5553    0.5078      8544
weighted avg     0.6066    0.6696    0.6084      8544

F1-macro sent:  0.5078373382168185
F1-micro sent:  0.6695926966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9271    0.9729    0.9494    124347
           N     0.8242    0.7160    0.7663     14202
           P     0.8890    0.7368    0.8058     25017

   micro avg     0.9145    0.9145    0.9145    163566
   macro avg     0.8801    0.8085    0.8405    163566
weighted avg     0.9123    0.9145    0.9116    163566

F1-macro tok:  0.8404928203671056
F1-micro tok:  0.9144871183497792
**************************************************
dev_cost_sum: 41874.004333496094
dev_cost_avg: 38.03270148364768
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19170.0
dev_accuracy_tok: 0.9010999341919714
dev_label=O_precision_sent: 0.3333333333333333
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017021276595744678
dev_label=N_precision_sent: 0.6431159420289855
dev_label=N_recall_sent: 0.8294392523364486
dev_label=N_f-score_sent: 0.7244897959183673
dev_label=P_precision_sent: 0.6721915285451197
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7396149949341438
dev_precision_macro_sent: 0.5495469346358128
dev_recall_macro_sent: 0.5534149829542231
dev_f-score_macro_sent: 0.4937086891494186
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9160720552111358
dev_label=O_recall_tok: 0.9665535328602283
dev_label=O_f-score_tok: 0.940635978740654
dev_label=N_precision_tok: 0.7787096774193548
dev_label=N_recall_tok: 0.6499730748519117
dev_label=N_f-score_tok: 0.7085412386263575
dev_label=P_precision_tok: 0.8758568164508759
dev_label=P_recall_tok: 0.7160647571606475
dev_label=P_f-score_tok: 0.7879410757108599
dev_precision_macro_tok: 0.8568795163604555
dev_recall_macro_tok: 0.777530454957596
dev_f-score_macro_tok: 0.8123727643592904
dev_precision_micro_tok: 0.9010999341919714
dev_recall_micro_tok: 0.9010999341919714
dev_f-score_micro_tok: 0.9010999341919714
dev_time: 5.1338050365448
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3333    0.0087    0.0170       229
           N     0.6431    0.8294    0.7245       428
           P     0.6722    0.8221    0.7396       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.5495    0.5534    0.4937      1101
weighted avg     0.5904    0.6558    0.5834      1101

F1-macro sent:  0.4937086891494186
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9161    0.9666    0.9406     16205
           N     0.7787    0.6500    0.7085      1857
           P     0.8759    0.7161    0.7879      3212

   micro avg     0.9011    0.9011    0.9011     21274
   macro avg     0.8569    0.7775    0.8124     21274
weighted avg     0.8980    0.9011    0.8973     21274

F1-macro tok:  0.8123727643592904
F1-micro tok:  0.9010999341919714
**************************************************
Best epoch: 34
**************************************************

EPOCH: 38
Learning rate: 0.590490
train_cost_sum: 294130.9165649414
train_cost_avg: 34.42543499121505
train_count_sent: 8544.0
train_total_correct_sent: 5721.0
train_accuracy_sent: 0.6695926966292135
train_count_tok: 163566.0
train_total_correct_tok: 149822.0
train_accuracy_tok: 0.9159727571744739
train_label=O_precision_sent: 0.33175355450236965
train_label=O_recall_sent: 0.04310344827586207
train_label=O_f-score_sent: 0.0762942779291553
train_label=N_precision_sent: 0.6561719140429785
train_label=N_recall_sent: 0.7933534743202417
train_label=N_f-score_sent: 0.7182713347921226
train_label=P_precision_sent: 0.6984530131609328
train_label=P_recall_sent: 0.8379501385041551
train_label=P_f-score_sent: 0.7618687822692356
train_precision_macro_sent: 0.5621261605687603
train_recall_macro_sent: 0.5581356870334196
train_f-score_macro_sent: 0.5188114649968378
train_precision_micro_sent: 0.6695926966292135
train_recall_micro_sent: 0.6695926966292135
train_f-score_micro_sent: 0.6695926966292135
train_label=O_precision_tok: 0.928242799742355
train_label=O_recall_tok: 0.9735176562361778
train_label=O_f-score_tok: 0.9503413029569122
train_label=N_precision_tok: 0.829823562891292
train_label=N_recall_tok: 0.7186311787072244
train_label=N_f-score_tok: 0.770235085468473
train_label=P_precision_tok: 0.890050347638456
train_label=P_recall_tok: 0.7419754566894512
train_label=P_f-score_tok: 0.8092954307638648
train_precision_macro_tok: 0.882705570090701
train_recall_macro_tok: 0.8113747638776179
train_f-score_macro_tok: 0.8432906063964166
train_precision_micro_tok: 0.9159727571744739
train_recall_micro_tok: 0.9159727571744739
train_f-score_micro_tok: 0.9159727571744739
train_time: 97.59623837471008
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3318    0.0431    0.0763      1624
           N     0.6562    0.7934    0.7183      3310
           P     0.6985    0.8380    0.7619      3610

   micro avg     0.6696    0.6696    0.6696      8544
   macro avg     0.5621    0.5581    0.5188      8544
weighted avg     0.6124    0.6696    0.6147      8544

F1-macro sent:  0.5188114649968378
F1-micro sent:  0.6695926966292135
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9282    0.9735    0.9503    124347
           N     0.8298    0.7186    0.7702     14202
           P     0.8901    0.7420    0.8093     25017

   micro avg     0.9160    0.9160    0.9160    163566
   macro avg     0.8827    0.8114    0.8433    163566
weighted avg     0.9139    0.9160    0.9131    163566

F1-macro tok:  0.8432906063964166
F1-micro tok:  0.9159727571744739
**************************************************
dev_cost_sum: 41887.875549316406
dev_cost_avg: 38.04530022644542
dev_count_sent: 1101.0
dev_total_correct_sent: 704.0
dev_accuracy_sent: 0.6394187102633969
dev_count_tok: 21274.0
dev_total_correct_tok: 19191.0
dev_accuracy_tok: 0.9020870546206637
dev_label=O_precision_sent: 0.26666666666666666
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.03278688524590164
dev_label=N_precision_sent: 0.659919028340081
dev_label=N_recall_sent: 0.7616822429906542
dev_label=N_f-score_sent: 0.7071583514099783
dev_label=P_precision_sent: 0.6317567567567568
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.722007722007722
dev_precision_macro_sent: 0.5194474839211681
dev_recall_macro_sent: 0.5404972780804312
dev_f-score_macro_sent: 0.4873176528878673
dev_precision_micro_sent: 0.6394187102633969
dev_recall_micro_sent: 0.6394187102633969
dev_f-score_micro_sent: 0.6394187102633969
dev_label=O_precision_tok: 0.9159516722115216
dev_label=O_recall_tok: 0.9684048133292193
dev_label=O_f-score_tok: 0.9414481972523847
dev_label=N_precision_tok: 0.7895778364116095
dev_label=N_recall_tok: 0.6445880452342488
dev_label=N_f-score_tok: 0.70975392825378
dev_label=P_precision_tok: 0.8765714285714286
dev_label=P_recall_tok: 0.7163760896637609
dev_label=P_f-score_tok: 0.7884187082405345
dev_precision_macro_tok: 0.8607003123981866
dev_recall_macro_tok: 0.776456316075743
dev_f-score_macro_tok: 0.813206944582233
dev_precision_micro_tok: 0.9020870546206637
dev_recall_micro_tok: 0.9020870546206637
dev_f-score_micro_tok: 0.9020870546206639
dev_time: 5.135483741760254
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.2667    0.0175    0.0328       229
           N     0.6599    0.7617    0.7072       428
           P     0.6318    0.8423    0.7220       444

   micro avg     0.6394    0.6394    0.6394      1101
   macro avg     0.5194    0.5405    0.4873      1101
weighted avg     0.5668    0.6394    0.5729      1101

F1-macro sent:  0.4873176528878673
F1-micro sent:  0.6394187102633969
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9160    0.9684    0.9414     16205
           N     0.7896    0.6446    0.7098      1857
           P     0.8766    0.7164    0.7884      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8607    0.7765    0.8132     21274
weighted avg     0.8990    0.9021    0.8981     21274

F1-macro tok:  0.813206944582233
F1-micro tok:  0.9020870546206639
**************************************************
Best epoch: 34
**************************************************

EPOCH: 39
Learning rate: 0.531441
train_cost_sum: 293054.4440307617
train_cost_avg: 34.299443355660316
train_count_sent: 8544.0
train_total_correct_sent: 5767.0
train_accuracy_sent: 0.6749765917602997
train_count_tok: 163566.0
train_total_correct_tok: 150012.0
train_accuracy_tok: 0.9171343677781446
train_label=O_precision_sent: 0.3697478991596639
train_label=O_recall_sent: 0.027093596059113302
train_label=O_f-score_sent: 0.05048766494549627
train_label=N_precision_sent: 0.6458431188351339
train_label=N_recall_sent: 0.8308157099697885
train_label=N_f-score_sent: 0.7267441860465116
train_label=P_precision_sent: 0.7134629229661628
train_label=P_recall_sent: 0.8235457063711912
train_label=P_f-score_sent: 0.7645621705027645
train_precision_macro_sent: 0.5763513136536536
train_recall_macro_sent: 0.5604850041333643
train_f-score_macro_sent: 0.5139313404982575
train_precision_micro_sent: 0.6749765917602997
train_recall_micro_sent: 0.6749765917602997
train_f-score_micro_sent: 0.6749765917602997
train_label=O_precision_tok: 0.9298346745371118
train_label=O_recall_tok: 0.9729064633646167
train_label=O_f-score_tok: 0.9508830672734562
train_label=N_precision_tok: 0.8285437520180821
train_label=N_recall_tok: 0.7227151105478101
train_label=N_f-score_tok: 0.7720195562241443
train_label=P_precision_tok: 0.8907977789378767
train_label=P_recall_tok: 0.7502898029340048
train_label=P_f-score_tok: 0.8145287276514495
train_precision_macro_tok: 0.8830587351643567
train_recall_macro_tok: 0.815303792282144
train_f-score_macro_tok: 0.8458104503830167
train_precision_micro_tok: 0.9171343677781446
train_recall_micro_tok: 0.9171343677781446
train_f-score_micro_tok: 0.9171343677781446
train_time: 97.59803438186646
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3697    0.0271    0.0505      1624
           N     0.6458    0.8308    0.7267      3310
           P     0.7135    0.8235    0.7646      3610

   micro avg     0.6750    0.6750    0.6750      8544
   macro avg     0.5764    0.5605    0.5139      8544
weighted avg     0.6219    0.6750    0.6142      8544

F1-macro sent:  0.5139313404982575
F1-micro sent:  0.6749765917602997
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9298    0.9729    0.9509    124347
           N     0.8285    0.7227    0.7720     14202
           P     0.8908    0.7503    0.8145     25017

   micro avg     0.9171    0.9171    0.9171    163566
   macro avg     0.8831    0.8153    0.8458    163566
weighted avg     0.9151    0.9171    0.9145    163566

F1-macro tok:  0.8458104503830167
F1-micro tok:  0.9171343677781446
**************************************************
dev_cost_sum: 41884.37139892578
dev_cost_avg: 38.042117528542946
dev_count_sent: 1101.0
dev_total_correct_sent: 716.0
dev_accuracy_sent: 0.6503178928247049
dev_count_tok: 21274.0
dev_total_correct_tok: 19175.0
dev_accuracy_tok: 0.9013349628654695
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02553191489361702
dev_label=N_precision_sent: 0.6673387096774194
dev_label=N_recall_sent: 0.7733644859813084
dev_label=N_f-score_sent: 0.7164502164502163
dev_label=P_precision_sent: 0.6377295492487479
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7325023969319272
dev_precision_macro_sent: 0.6016894196420558
dev_recall_macro_sent: 0.5489417610076305
dev_f-score_macro_sent: 0.49149484275858685
dev_precision_micro_sent: 0.6503178928247049
dev_recall_micro_sent: 0.6503178928247049
dev_f-score_micro_sent: 0.6503178928247049
dev_label=O_precision_tok: 0.9144204459451593
dev_label=O_recall_tok: 0.9692687442147485
dev_label=O_f-score_tok: 0.9410460727338087
dev_label=N_precision_tok: 0.8078541374474053
dev_label=N_recall_tok: 0.6203554119547657
dev_label=N_f-score_tok: 0.7017971367651538
dev_label=P_precision_tok: 0.8670909771621116
dev_label=P_recall_tok: 0.7210460772104608
dev_label=P_f-score_tok: 0.7873533911269761
dev_precision_macro_tok: 0.8631218535182255
dev_recall_macro_tok: 0.7702234111266583
dev_f-score_macro_tok: 0.8100655335419796
dev_precision_micro_tok: 0.9013349628654695
dev_recall_micro_tok: 0.9013349628654695
dev_f-score_micro_tok: 0.9013349628654695
dev_time: 5.026696681976318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0131    0.0255       229
           N     0.6673    0.7734    0.7165       428
           P     0.6377    0.8604    0.7325       444

   micro avg     0.6503    0.6503    0.6503      1101
   macro avg     0.6017    0.5489    0.4915      1101
weighted avg     0.6206    0.6503    0.5792      1101

F1-macro sent:  0.49149484275858685
F1-micro sent:  0.6503178928247049
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9144    0.9693    0.9410     16205
           N     0.8079    0.6204    0.7018      1857
           P     0.8671    0.7210    0.7874      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8631    0.7702    0.8101     21274
weighted avg     0.8980    0.9013    0.8970     21274

F1-macro tok:  0.8100655335419796
F1-micro tok:  0.9013349628654695
**************************************************
Best epoch: 34
**************************************************

EPOCH: 40
Learning rate: 0.478297
train_cost_sum: 292161.09454345703
train_cost_avg: 34.19488466098514
train_count_sent: 8544.0
train_total_correct_sent: 5762.0
train_accuracy_sent: 0.6743913857677902
train_count_tok: 163566.0
train_total_correct_tok: 150179.0
train_accuracy_tok: 0.918155362361371
train_label=O_precision_sent: 0.3625
train_label=O_recall_sent: 0.05357142857142857
train_label=O_f-score_sent: 0.09334763948497854
train_label=N_precision_sent: 0.6510242972844211
train_label=N_recall_sent: 0.8256797583081571
train_label=N_f-score_sent: 0.728023441662227
train_label=P_precision_sent: 0.7165124208475402
train_label=P_recall_sent: 0.8149584487534626
train_label=P_f-score_sent: 0.7625712804561948
train_precision_macro_sent: 0.5766789060439871
train_recall_macro_sent: 0.5647365452110161
train_f-score_macro_sent: 0.5279807872011334
train_precision_micro_sent: 0.6743913857677902
train_recall_micro_sent: 0.6743913857677902
train_f-score_micro_sent: 0.6743913857677902
train_label=O_precision_tok: 0.9305576917161401
train_label=O_recall_tok: 0.9731316396857181
train_label=O_f-score_tok: 0.9513686056065066
train_label=N_precision_tok: 0.8331587851446065
train_label=N_recall_tok: 0.7282072947472187
train_label=N_f-score_tok: 0.7771557392447869
train_label=P_precision_tok: 0.8917459866458304
train_label=P_recall_tok: 0.7527281448614942
train_label=P_f-score_tok: 0.8163610352451554
train_precision_macro_tok: 0.8851541545021924
train_recall_macro_tok: 0.8180223597648103
train_f-score_macro_tok: 0.8482951266988162
train_precision_micro_tok: 0.918155362361371
train_recall_micro_tok: 0.918155362361371
train_f-score_micro_tok: 0.918155362361371
train_time: 97.62186527252197
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3625    0.0536    0.0933      1624
           N     0.6510    0.8257    0.7280      3310
           P     0.7165    0.8150    0.7626      3610

   micro avg     0.6744    0.6744    0.6744      8544
   macro avg     0.5767    0.5647    0.5280      8544
weighted avg     0.6239    0.6744    0.6220      8544

F1-macro sent:  0.5279807872011334
F1-micro sent:  0.6743913857677902
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9306    0.9731    0.9514    124347
           N     0.8332    0.7282    0.7772     14202
           P     0.8917    0.7527    0.8164     25017

   micro avg     0.9182    0.9182    0.9182    163566
   macro avg     0.8852    0.8180    0.8483    163566
weighted avg     0.9162    0.9182    0.9156    163566

F1-macro tok:  0.8482951266988162
F1-micro tok:  0.918155362361371
**************************************************
dev_cost_sum: 41845.129821777344
dev_cost_avg: 38.00647576909841
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.40625
dev_label=O_recall_sent: 0.056768558951965066
dev_label=O_f-score_sent: 0.0996168582375479
dev_label=N_precision_sent: 0.6705653021442495
dev_label=N_recall_sent: 0.8037383177570093
dev_label=N_f-score_sent: 0.7311370882040382
dev_label=P_precision_sent: 0.6690647482014388
dev_label=P_recall_sent: 0.8378378378378378
dev_label=P_f-score_sent: 0.7439999999999999
dev_precision_macro_sent: 0.581960016781896
dev_recall_macro_sent: 0.5661149048489375
dev_f-score_macro_sent: 0.5249179821471953
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9146767617938264
dev_label=O_recall_tok: 0.9691453255168158
dev_label=O_f-score_tok: 0.941123595505618
dev_label=N_precision_tok: 0.7927076299797434
dev_label=N_recall_tok: 0.6322024771136241
dev_label=N_f-score_tok: 0.7034152186938286
dev_label=P_precision_tok: 0.8741898589401449
dev_label=P_recall_tok: 0.7138854296388543
dev_label=P_f-score_tok: 0.7859468723221936
dev_precision_macro_tok: 0.8605247502379049
dev_recall_macro_tok: 0.7717444107564314
dev_f-score_macro_tok: 0.8101618955072135
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 5.083809852600098
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4062    0.0568    0.0996       229
           N     0.6706    0.8037    0.7311       428
           P     0.6691    0.8378    0.7440       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5820    0.5661    0.5249      1101
weighted avg     0.6150    0.6621    0.6050      1101

F1-macro sent:  0.5249179821471953
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9691    0.9411     16205
           N     0.7927    0.6322    0.7034      1857
           P     0.8742    0.7139    0.7859      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8605    0.7717    0.8102     21274
weighted avg     0.8979    0.9012    0.8969     21274

F1-macro tok:  0.8101618955072135
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 40
**************************************************

EPOCH: 41
Learning rate: 0.478297
train_cost_sum: 291232.2111816406
train_cost_avg: 34.0861670390497
train_count_sent: 8544.0
train_total_correct_sent: 5792.0
train_accuracy_sent: 0.6779026217228464
train_count_tok: 163566.0
train_total_correct_tok: 150351.0
train_accuracy_tok: 0.9192069256446939
train_label=O_precision_sent: 0.4
train_label=O_recall_sent: 0.029556650246305417
train_label=O_f-score_sent: 0.055045871559633024
train_label=N_precision_sent: 0.645616470043951
train_label=N_recall_sent: 0.843202416918429
train_label=N_f-score_sent: 0.7312983099698677
train_label=P_precision_sent: 0.7200682760302365
train_label=P_recall_sent: 0.818005540166205
train_label=P_f-score_sent: 0.7659188172740241
train_precision_macro_sent: 0.5885615820247292
train_recall_macro_sent: 0.5635882024436465
train_f-score_macro_sent: 0.5174209996011749
train_precision_micro_sent: 0.6779026217228464
train_recall_micro_sent: 0.6779026217228464
train_f-score_micro_sent: 0.6779026217228464
train_label=O_precision_tok: 0.9318162578976936
train_label=O_recall_tok: 0.9737508745687471
train_label=O_f-score_tok: 0.9523221518738448
train_label=N_precision_tok: 0.8334679373283799
train_label=N_recall_tok: 0.7266582171525138
train_label=N_f-score_tok: 0.7764068612699367
train_label=P_precision_tok: 0.8920483969681277
train_label=P_recall_tok: 0.7574049646240556
train_label=P_f-score_tok: 0.8192312681049764
train_precision_macro_tok: 0.8857775307314003
train_recall_macro_tok: 0.8192713521151055
train_f-score_macro_tok: 0.849320093749586
train_precision_micro_tok: 0.9192069256446939
train_recall_micro_tok: 0.9192069256446939
train_f-score_micro_tok: 0.9192069256446939
train_time: 96.99491691589355
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0296    0.0550      1624
           N     0.6456    0.8432    0.7313      3310
           P     0.7201    0.8180    0.7659      3610

   micro avg     0.6779    0.6779    0.6779      8544
   macro avg     0.5886    0.5636    0.5174      8544
weighted avg     0.6304    0.6779    0.6174      8544

F1-macro sent:  0.5174209996011749
F1-micro sent:  0.6779026217228464
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9318    0.9738    0.9523    124347
           N     0.8335    0.7267    0.7764     14202
           P     0.8920    0.7574    0.8192     25017

   micro avg     0.9192    0.9192    0.9192    163566
   macro avg     0.8858    0.8193    0.8493    163566
weighted avg     0.9172    0.9192    0.9167    163566

F1-macro tok:  0.849320093749586
F1-micro tok:  0.9192069256446939
**************************************************
dev_cost_sum: 42012.05145263672
dev_cost_avg: 38.15808487977904
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19117.0
dev_accuracy_tok: 0.8986086302528908
dev_label=O_precision_sent: 0.38095238095238093
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.064
dev_label=N_precision_sent: 0.6731898238747553
dev_label=N_recall_sent: 0.8037383177570093
dev_label=N_f-score_sent: 0.7326943556975506
dev_label=P_precision_sent: 0.6625659050966608
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7443237907206318
dev_precision_macro_sent: 0.5722360366412657
dev_recall_macro_sent: 0.562590638224234
dev_f-score_macro_sent: 0.5136727154727274
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9177759453410296
dev_label=O_recall_tok: 0.9615550755939525
dev_label=O_f-score_tok: 0.939155591718651
dev_label=N_precision_tok: 0.7839262187088274
dev_label=N_recall_tok: 0.6408185245018848
dev_label=N_f-score_tok: 0.7051851851851852
dev_label=P_precision_tok: 0.8441324694024478
dev_label=P_recall_tok: 0.7300747198007472
dev_label=P_f-score_tok: 0.7829716193656093
dev_precision_macro_tok: 0.8486115444841015
dev_recall_macro_tok: 0.7774827732988615
dev_f-score_macro_tok: 0.8091041320898151
dev_precision_micro_tok: 0.8986086302528908
dev_recall_micro_tok: 0.8986086302528908
dev_f-score_micro_tok: 0.8986086302528908
dev_time: 5.101191282272339
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3810    0.0349    0.0640       229
           N     0.6732    0.8037    0.7327       428
           P     0.6626    0.8491    0.7443       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.5722    0.5626    0.5137      1101
weighted avg     0.6081    0.6621    0.5983      1101

F1-macro sent:  0.5136727154727274
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9178    0.9616    0.9392     16205
           N     0.7839    0.6408    0.7052      1857
           P     0.8441    0.7301    0.7830      3212

   micro avg     0.8986    0.8986    0.8986     21274
   macro avg     0.8486    0.7775    0.8091     21274
weighted avg     0.8950    0.8986    0.8952     21274

F1-macro tok:  0.8091041320898151
F1-micro tok:  0.8986086302528908
**************************************************
Best epoch: 40
**************************************************

EPOCH: 42
Learning rate: 0.478297
train_cost_sum: 290516.2657470703
train_cost_avg: 34.00237192732565
train_count_sent: 8544.0
train_total_correct_sent: 5844.0
train_accuracy_sent: 0.6839887640449438
train_count_tok: 163566.0
train_total_correct_tok: 150703.0
train_accuracy_tok: 0.9213589621314944
train_label=O_precision_sent: 0.4126984126984127
train_label=O_recall_sent: 0.03201970443349754
train_label=O_f-score_sent: 0.05942857142857143
train_label=N_precision_sent: 0.6484988452655889
train_label=N_recall_sent: 0.8483383685800604
train_label=N_f-score_sent: 0.7350785340314135
train_label=P_precision_sent: 0.7299412915851272
train_label=P_recall_sent: 0.8265927977839335
train_label=P_f-score_sent: 0.7752663029358274
train_precision_macro_sent: 0.597046183183043
train_recall_macro_sent: 0.5689836235991638
train_f-score_macro_sent: 0.5232578027986041
train_precision_micro_sent: 0.6839887640449438
train_recall_micro_sent: 0.6839887640449438
train_f-score_micro_sent: 0.6839887640449438
train_label=O_precision_tok: 0.9344298990397975
train_label=O_recall_tok: 0.9735739503164531
train_label=O_f-score_tok: 0.9536003907003856
train_label=N_precision_tok: 0.8384781048097631
train_label=N_recall_tok: 0.7401774397972116
train_label=N_f-score_tok: 0.7862672500841468
train_label=P_precision_tok: 0.8908862292180878
train_label=P_recall_tok: 0.7646800175880402
train_label=P_f-score_tok: 0.8229726822972683
train_precision_macro_tok: 0.8879314110225495
train_recall_macro_tok: 0.826143802567235
train_f-score_macro_tok: 0.8542801076939336
train_precision_micro_tok: 0.9213589621314944
train_recall_micro_tok: 0.9213589621314944
train_f-score_micro_tok: 0.9213589621314944
train_time: 94.84942507743835
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4127    0.0320    0.0594      1624
           N     0.6485    0.8483    0.7351      3310
           P     0.7299    0.8266    0.7753      3610

   micro avg     0.6840    0.6840    0.6840      8544
   macro avg     0.5970    0.5690    0.5233      8544
weighted avg     0.6381    0.6840    0.6236      8544

F1-macro sent:  0.5232578027986041
F1-micro sent:  0.6839887640449438
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9344    0.9736    0.9536    124347
           N     0.8385    0.7402    0.7863     14202
           P     0.8909    0.7647    0.8230     25017

   micro avg     0.9214    0.9214    0.9214    163566
   macro avg     0.8879    0.8261    0.8543    163566
weighted avg     0.9194    0.9214    0.9191    163566

F1-macro tok:  0.8542801076939336
F1-micro tok:  0.9213589621314944
**************************************************
dev_cost_sum: 42020.07067871094
dev_cost_avg: 38.16536846386098
dev_count_sent: 1101.0
dev_total_correct_sent: 722.0
dev_accuracy_sent: 0.6557674841053588
dev_count_tok: 21274.0
dev_total_correct_tok: 19172.0
dev_accuracy_tok: 0.9011939456613707
dev_label=O_precision_sent: 0.42105263157894735
dev_label=O_recall_sent: 0.034934497816593885
dev_label=O_f-score_sent: 0.06451612903225806
dev_label=N_precision_sent: 0.6451016635859519
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7203302373581012
dev_label=P_precision_sent: 0.6746765249537893
dev_label=P_recall_sent: 0.8220720720720721
dev_label=P_f-score_sent: 0.7411167512690356
dev_precision_macro_sent: 0.5802769400395628
dev_recall_macro_sent: 0.5574757102121098
dev_f-score_macro_sent: 0.5086543725531317
dev_precision_micro_sent: 0.6557674841053588
dev_recall_micro_sent: 0.6557674841053588
dev_f-score_micro_sent: 0.6557674841053588
dev_label=O_precision_tok: 0.9132733081614871
dev_label=O_recall_tok: 0.9701943844492441
dev_label=O_f-score_tok: 0.9408737283064034
dev_label=N_precision_tok: 0.8253968253968254
dev_label=N_recall_tok: 0.6160473882606354
dev_label=N_f-score_tok: 0.7055195806352144
dev_label=P_precision_tok: 0.8627010849233071
dev_label=P_recall_tok: 0.7179327521793275
dev_label=P_f-score_tok: 0.7836873406966866
dev_precision_macro_tok: 0.8671237394938731
dev_recall_macro_tok: 0.7680581749630689
dev_f-score_macro_tok: 0.8100268832127681
dev_precision_micro_tok: 0.9011939456613707
dev_recall_micro_tok: 0.9011939456613707
dev_f-score_micro_tok: 0.9011939456613707
dev_time: 3.4808034896850586
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4211    0.0349    0.0645       229
           N     0.6451    0.8154    0.7203       428
           P     0.6747    0.8221    0.7411       444

   micro avg     0.6558    0.6558    0.6558      1101
   macro avg     0.5803    0.5575    0.5087      1101
weighted avg     0.6104    0.6558    0.5923      1101

F1-macro sent:  0.5086543725531317
F1-micro sent:  0.6557674841053588
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9133    0.9702    0.9409     16205
           N     0.8254    0.6160    0.7055      1857
           P     0.8627    0.7179    0.7837      3212

   micro avg     0.9012    0.9012    0.9012     21274
   macro avg     0.8671    0.7681    0.8100     21274
weighted avg     0.8980    0.9012    0.8966     21274

F1-macro tok:  0.8100268832127681
F1-micro tok:  0.9011939456613707
**************************************************
Best epoch: 40
**************************************************

EPOCH: 43
Learning rate: 0.478297
train_cost_sum: 290015.47857666016
train_cost_avg: 33.94375919670648
train_count_sent: 8544.0
train_total_correct_sent: 5829.0
train_accuracy_sent: 0.6822331460674157
train_count_tok: 163566.0
train_total_correct_tok: 150684.0
train_accuracy_tok: 0.9212428010711272
train_label=O_precision_sent: 0.4200913242009132
train_label=O_recall_sent: 0.05665024630541872
train_label=O_f-score_sent: 0.09983722192078133
train_label=N_precision_sent: 0.6589034449296458
train_label=N_recall_sent: 0.8205438066465257
train_label=N_f-score_sent: 0.7308934337997847
train_label=P_precision_sent: 0.7187723054960742
train_label=P_recall_sent: 0.8368421052631579
train_label=P_f-score_sent: 0.7733265071035453
train_precision_macro_sent: 0.599255691542211
train_recall_macro_sent: 0.5713453860717008
train_f-score_macro_sent: 0.5346857209413705
train_precision_micro_sent: 0.6822331460674157
train_recall_micro_sent: 0.6822331460674157
train_f-score_micro_sent: 0.6822331460674157
train_label=O_precision_tok: 0.9343975052681142
train_label=O_recall_tok: 0.9735176562361778
train_label=O_f-score_tok: 0.9535565183142969
train_label=N_precision_tok: 0.8380998157494192
train_label=N_recall_tok: 0.736656808900155
train_label=N_f-score_tok: 0.7841109237399287
train_label=P_precision_tok: 0.8902926149558755
train_label=P_recall_tok: 0.7661989846904105
train_label=P_f-score_tok: 0.8235976539841451
train_precision_macro_tok: 0.8875966453244697
train_recall_macro_tok: 0.8254578166089145
train_f-score_macro_tok: 0.8537550320127902
train_precision_micro_tok: 0.9212428010711272
train_recall_micro_tok: 0.9212428010711272
train_f-score_micro_tok: 0.9212428010711271
train_time: 51.98486256599426
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4201    0.0567    0.0998      1624
           N     0.6589    0.8205    0.7309      3310
           P     0.7188    0.8368    0.7733      3610

   micro avg     0.6822    0.6822    0.6822      8544
   macro avg     0.5993    0.5713    0.5347      8544
weighted avg     0.6388    0.6822    0.6289      8544

F1-macro sent:  0.5346857209413705
F1-micro sent:  0.6822331460674157
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9344    0.9735    0.9536    124347
           N     0.8381    0.7367    0.7841     14202
           P     0.8903    0.7662    0.8236     25017

   micro avg     0.9212    0.9212    0.9212    163566
   macro avg     0.8876    0.8255    0.8538    163566
weighted avg     0.9193    0.9212    0.9190    163566

F1-macro tok:  0.8537550320127902
F1-micro tok:  0.9212428010711271
**************************************************
dev_cost_sum: 41895.690856933594
dev_cost_avg: 38.05239859848646
dev_count_sent: 1101.0
dev_total_correct_sent: 724.0
dev_accuracy_sent: 0.6575840145322435
dev_count_tok: 21274.0
dev_total_correct_tok: 19191.0
dev_accuracy_tok: 0.9020870546206637
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.004366812227074236
dev_label=O_f-score_sent: 0.008658008658008658
dev_label=N_precision_sent: 0.676829268292683
dev_label=N_recall_sent: 0.7780373831775701
dev_label=N_f-score_sent: 0.7239130434782609
dev_label=P_precision_sent: 0.642504118616145
dev_label=P_recall_sent: 0.8783783783783784
dev_label=P_f-score_sent: 0.7421503330161751
dev_precision_macro_sent: 0.6064444623029427
dev_recall_macro_sent: 0.5535941912610075
dev_f-score_macro_sent: 0.49157379505081494
dev_precision_micro_sent: 0.6575840145322435
dev_recall_micro_sent: 0.6575840145322435
dev_f-score_micro_sent: 0.6575840145322435
dev_label=O_precision_tok: 0.9147995111447361
dev_label=O_recall_tok: 0.9700092564023449
dev_label=O_f-score_tok: 0.9415957829160178
dev_label=N_precision_tok: 0.7970027247956403
dev_label=N_recall_tok: 0.630048465266559
dev_label=N_f-score_tok: 0.7037593984962405
dev_label=P_precision_tok: 0.8776210446054137
dev_label=P_recall_tok: 0.7166874221668742
dev_label=P_f-score_tok: 0.789031705227078
dev_precision_macro_tok: 0.8631410935152634
dev_recall_macro_tok: 0.7722483812785926
dev_f-score_macro_tok: 0.8114622955464453
dev_precision_micro_tok: 0.9020870546206637
dev_recall_micro_tok: 0.9020870546206637
dev_f-score_micro_tok: 0.9020870546206639
dev_time: 2.5068633556365967
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0044    0.0087       229
           N     0.6768    0.7780    0.7239       428
           P     0.6425    0.8784    0.7422       444

   micro avg     0.6576    0.6576    0.6576      1101
   macro avg     0.6064    0.5536    0.4916      1101
weighted avg     0.6262    0.6576    0.5825      1101

F1-macro sent:  0.49157379505081494
F1-micro sent:  0.6575840145322435
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9148    0.9700    0.9416     16205
           N     0.7970    0.6300    0.7038      1857
           P     0.8776    0.7167    0.7890      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8631    0.7722    0.8115     21274
weighted avg     0.8989    0.9021    0.8978     21274

F1-macro tok:  0.8114622955464453
F1-micro tok:  0.9020870546206639
**************************************************
Best epoch: 40
**************************************************

EPOCH: 44
Learning rate: 0.478297
train_cost_sum: 289122.06158447266
train_cost_avg: 33.839192601178915
train_count_sent: 8544.0
train_total_correct_sent: 5849.0
train_accuracy_sent: 0.6845739700374532
train_count_tok: 163566.0
train_total_correct_tok: 150900.0
train_accuracy_tok: 0.9225633689153002
train_label=O_precision_sent: 0.391304347826087
train_label=O_recall_sent: 0.03879310344827586
train_label=O_f-score_sent: 0.07058823529411765
train_label=N_precision_sent: 0.6682208588957055
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7374407582938388
train_label=P_precision_sent: 0.7110027855153204
train_label=P_recall_sent: 0.8484764542936288
train_label=P_f-score_sent: 0.7736802222783532
train_precision_macro_sent: 0.5901759974123709
train_recall_macro_sent: 0.5699760560046027
train_f-score_macro_sent: 0.5272364052887699
train_precision_micro_sent: 0.6845739700374532
train_recall_micro_sent: 0.6845739700374532
train_f-score_micro_sent: 0.6845739700374532
train_label=O_precision_tok: 0.9359437486946633
train_label=O_recall_tok: 0.9730512195710391
train_label=O_f-score_tok: 0.9541368324764217
train_label=N_precision_tok: 0.8400505768926821
train_label=N_recall_tok: 0.7484861287142656
train_label=N_f-score_tok: 0.7916294310396187
train_label=P_precision_tok: 0.890871273399584
train_label=P_recall_tok: 0.7704361034496542
train_label=P_f-score_tok: 0.8262882620252079
train_precision_macro_tok: 0.8889551996623098
train_recall_macro_tok: 0.8306578172449863
train_f-score_macro_tok: 0.8573515085137494
train_precision_micro_tok: 0.9225633689153002
train_recall_micro_tok: 0.9225633689153002
train_f-score_micro_tok: 0.9225633689153002
train_time: 51.38927173614502
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3913    0.0388    0.0706      1624
           N     0.6682    0.8227    0.7374      3310
           P     0.7110    0.8485    0.7737      3610

   micro avg     0.6846    0.6846    0.6846      8544
   macro avg     0.5902    0.5700    0.5272      8544
weighted avg     0.6337    0.6846    0.6260      8544

F1-macro sent:  0.5272364052887699
F1-micro sent:  0.6845739700374532
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9359    0.9731    0.9541    124347
           N     0.8401    0.7485    0.7916     14202
           P     0.8909    0.7704    0.8263     25017

   micro avg     0.9226    0.9226    0.9226    163566
   macro avg     0.8890    0.8307    0.8574    163566
weighted avg     0.9207    0.9226    0.9205    163566

F1-macro tok:  0.8573515085137494
F1-micro tok:  0.9225633689153002
**************************************************
dev_cost_sum: 41999.124450683594
dev_cost_avg: 38.14634373359091
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19192.0
dev_accuracy_tok: 0.9021340603553634
dev_label=O_precision_sent: 0.3673469387755102
dev_label=O_recall_sent: 0.07860262008733625
dev_label=O_f-score_sent: 0.12949640287769784
dev_label=N_precision_sent: 0.6498194945848376
dev_label=N_recall_sent: 0.8411214953271028
dev_label=N_f-score_sent: 0.7331975560081467
dev_label=P_precision_sent: 0.7008032128514057
dev_label=P_recall_sent: 0.786036036036036
dev_label=P_f-score_sent: 0.7409766454352442
dev_precision_macro_sent: 0.5726565487372511
dev_recall_macro_sent: 0.5685867171501583
dev_f-score_macro_sent: 0.5345568681070296
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9151575147033133
dev_label=O_recall_tok: 0.9698241283554458
dev_label=O_f-score_tok: 0.9416981245131524
dev_label=N_precision_tok: 0.8021978021978022
dev_label=N_recall_tok: 0.6289714593430263
dev_label=N_f-score_tok: 0.7051011168125565
dev_label=P_precision_tok: 0.8725897920604915
dev_label=P_recall_tok: 0.7185554171855542
dev_label=P_f-score_tok: 0.788116783336179
dev_precision_macro_tok: 0.8633150363205356
dev_recall_macro_tok: 0.772450334961342
dev_f-score_macro_tok: 0.811638674887296
dev_precision_micro_tok: 0.9021340603553634
dev_recall_micro_tok: 0.9021340603553634
dev_f-score_micro_tok: 0.9021340603553635
dev_time: 2.5053188800811768
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3673    0.0786    0.1295       229
           N     0.6498    0.8411    0.7332       428
           P     0.7008    0.7860    0.7410       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.5727    0.5686    0.5346      1101
weighted avg     0.6116    0.6603    0.6108      1101

F1-macro sent:  0.5345568681070296
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9152    0.9698    0.9417     16205
           N     0.8022    0.6290    0.7051      1857
           P     0.8726    0.7186    0.7881      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8633    0.7725    0.8116     21274
weighted avg     0.8989    0.9021    0.8979     21274

F1-macro tok:  0.811638674887296
F1-micro tok:  0.9021340603553635
**************************************************
Best epoch: 44
**************************************************

EPOCH: 45
Learning rate: 0.478297
train_cost_sum: 288796.3966064453
train_cost_avg: 33.80107638184051
train_count_sent: 8544.0
train_total_correct_sent: 5840.0
train_accuracy_sent: 0.6835205992509363
train_count_tok: 163566.0
train_total_correct_tok: 150828.0
train_accuracy_tok: 0.9221231796339092
train_label=O_precision_sent: 0.375
train_label=O_recall_sent: 0.07573891625615764
train_label=O_f-score_sent: 0.12602459016393444
train_label=N_precision_sent: 0.6639843940502317
train_label=N_recall_sent: 0.8226586102719033
train_label=N_f-score_sent: 0.7348535960059371
train_label=P_precision_sent: 0.7275820170109356
train_label=P_recall_sent: 0.8293628808864266
train_label=P_f-score_sent: 0.7751456310679611
train_precision_macro_sent: 0.5888554703537224
train_recall_macro_sent: 0.5759201358048293
train_f-score_macro_sent: 0.5453412724126109
train_precision_micro_sent: 0.6835205992509363
train_recall_micro_sent: 0.6835205992509363
train_f-score_micro_sent: 0.6835205992509363
train_label=O_precision_tok: 0.9354170531132133
train_label=O_recall_tok: 0.9733085639380121
train_label=O_f-score_tok: 0.9539867024525974
train_label=N_precision_tok: 0.8396861874950472
train_label=N_recall_tok: 0.746092099704267
train_label=N_f-score_tok: 0.7901271391819844
train_label=P_precision_tok: 0.8905996382692575
train_label=P_recall_tok: 0.767638006155814
train_label=P_f-score_tok: 0.8245598969514812
train_precision_macro_tok: 0.888567626292506
train_recall_macro_tok: 0.8290128899326977
train_f-score_macro_tok: 0.8562245795286877
train_precision_micro_tok: 0.9221231796339092
train_recall_micro_tok: 0.9221231796339092
train_f-score_micro_tok: 0.9221231796339092
train_time: 51.831788301467896
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3750    0.0757    0.1260      1624
           N     0.6640    0.8227    0.7349      3310
           P     0.7276    0.8294    0.7751      3610

   micro avg     0.6835    0.6835    0.6835      8544
   macro avg     0.5889    0.5759    0.5453      8544
weighted avg     0.6359    0.6835    0.6362      8544

F1-macro sent:  0.5453412724126109
F1-micro sent:  0.6835205992509363
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9354    0.9733    0.9540    124347
           N     0.8397    0.7461    0.7901     14202
           P     0.8906    0.7676    0.8246     25017

   micro avg     0.9221    0.9221    0.9221    163566
   macro avg     0.8886    0.8290    0.8562    163566
weighted avg     0.9203    0.9221    0.9200    163566

F1-macro tok:  0.8562245795286877
F1-micro tok:  0.9221231796339092
**************************************************
dev_cost_sum: 41930.64001464844
dev_cost_avg: 38.08414170267796
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19177.0
dev_accuracy_tok: 0.9014289743348689
dev_label=O_precision_sent: 0.5714285714285714
dev_label=O_recall_sent: 0.017467248908296942
dev_label=O_f-score_sent: 0.033898305084745756
dev_label=N_precision_sent: 0.6078125
dev_label=N_recall_sent: 0.9088785046728972
dev_label=N_f-score_sent: 0.7284644194756554
dev_label=P_precision_sent: 0.73568281938326
dev_label=P_recall_sent: 0.7522522522522522
dev_label=P_f-score_sent: 0.7438752783964365
dev_precision_macro_sent: 0.6383079636039438
dev_recall_macro_sent: 0.5595326686111488
dev_f-score_macro_sent: 0.5020793343189459
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9169641289718532
dev_label=O_recall_tok: 0.9669854983029929
dev_label=O_f-score_tok: 0.9413107466810836
dev_label=N_precision_tok: 0.7945113788487282
dev_label=N_recall_tok: 0.6392030156165859
dev_label=N_f-score_tok: 0.7084452402267979
dev_label=P_precision_tok: 0.8621330360460795
dev_label=P_recall_tok: 0.7222914072229141
dev_label=P_f-score_tok: 0.7860409961036761
dev_precision_macro_tok: 0.8578695146222204
dev_recall_macro_tok: 0.7761599737141642
dev_f-score_macro_tok: 0.8119323276705191
dev_precision_micro_tok: 0.9014289743348689
dev_recall_micro_tok: 0.9014289743348689
dev_f-score_micro_tok: 0.9014289743348689
dev_time: 2.492290496826172
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5714    0.0175    0.0339       229
           N     0.6078    0.9089    0.7285       428
           P     0.7357    0.7523    0.7439       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.6383    0.5595    0.5021      1101
weighted avg     0.6518    0.6603    0.5902      1101

F1-macro sent:  0.5020793343189459
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9170    0.9670    0.9413     16205
           N     0.7945    0.6392    0.7084      1857
           P     0.8621    0.7223    0.7860      3212

   micro avg     0.9014    0.9014    0.9014     21274
   macro avg     0.8579    0.7762    0.8119     21274
weighted avg     0.8980    0.9014    0.8975     21274

F1-macro tok:  0.8119323276705191
F1-micro tok:  0.9014289743348689
**************************************************
Best epoch: 44
**************************************************

EPOCH: 46
Learning rate: 0.478297
train_cost_sum: 287940.9053955078
train_cost_avg: 33.700948665204564
train_count_sent: 8544.0
train_total_correct_sent: 5831.0
train_accuracy_sent: 0.6824672284644194
train_count_tok: 163566.0
train_total_correct_tok: 151256.0
train_accuracy_tok: 0.9247398603621779
train_label=O_precision_sent: 0.38578680203045684
train_label=O_recall_sent: 0.046798029556650245
train_label=O_f-score_sent: 0.08347062053816584
train_label=N_precision_sent: 0.6425186188219364
train_label=N_recall_sent: 0.8601208459214501
train_label=N_f-score_sent: 0.7355638806355768
train_label=P_precision_sent: 0.7425944841675178
train_label=P_recall_sent: 0.8055401662049861
train_label=P_f-score_sent: 0.7727876694127026
train_precision_macro_sent: 0.5902999683399703
train_recall_macro_sent: 0.5708196805610288
train_f-score_macro_sent: 0.5306073901954816
train_precision_micro_sent: 0.6824672284644194
train_recall_micro_sent: 0.6824672284644194
train_f-score_micro_sent: 0.6824672284644194
train_label=O_precision_tok: 0.9373756762823242
train_label=O_recall_tok: 0.9739519248554448
train_label=O_f-score_tok: 0.9553138286543665
train_label=N_precision_tok: 0.842055260866123
train_label=N_recall_tok: 0.7489086044219124
train_label=N_f-score_tok: 0.7927551895054599
train_label=P_precision_tok: 0.8976812661023187
train_label=P_recall_tok: 0.7799496342487109
train_label=P_f-score_tok: 0.8346844052788056
train_precision_macro_tok: 0.892370734416922
train_recall_macro_tok: 0.8342700545086895
train_f-score_macro_tok: 0.8609178078128773
train_precision_micro_tok: 0.9247398603621779
train_recall_micro_tok: 0.9247398603621779
train_f-score_micro_tok: 0.9247398603621779
train_time: 91.14384865760803
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3858    0.0468    0.0835      1624
           N     0.6425    0.8601    0.7356      3310
           P     0.7426    0.8055    0.7728      3610

   micro avg     0.6825    0.6825    0.6825      8544
   macro avg     0.5903    0.5708    0.5306      8544
weighted avg     0.6360    0.6825    0.6273      8544

F1-macro sent:  0.5306073901954816
F1-micro sent:  0.6824672284644194
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9374    0.9740    0.9553    124347
           N     0.8421    0.7489    0.7928     14202
           P     0.8977    0.7799    0.8347     25017

   micro avg     0.9247    0.9247    0.9247    163566
   macro avg     0.8924    0.8343    0.8609    163566
weighted avg     0.9230    0.9247    0.9227    163566

F1-macro tok:  0.8609178078128773
F1-micro tok:  0.9247398603621779
**************************************************
dev_cost_sum: 42000.71105957031
dev_cost_avg: 38.147784795250054
dev_count_sent: 1101.0
dev_total_correct_sent: 728.0
dev_accuracy_sent: 0.6612170753860127
dev_count_tok: 21274.0
dev_total_correct_tok: 19182.0
dev_accuracy_tok: 0.901664003008367
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.6423611111111112
dev_label=N_recall_sent: 0.8644859813084113
dev_label=N_f-score_sent: 0.7370517928286853
dev_label=P_precision_sent: 0.6846153846153846
dev_label=P_recall_sent: 0.8018018018018018
dev_label=P_f-score_sent: 0.7385892116182573
dev_precision_macro_sent: 0.5756588319088319
dev_recall_macro_sent: 0.5583404691881205
dev_f-score_macro_sent: 0.4975783405136533
dev_precision_micro_sent: 0.6612170753860127
dev_recall_micro_sent: 0.6612170753860127
dev_f-score_micro_sent: 0.6612170753860127
dev_label=O_precision_tok: 0.9141860465116279
dev_label=O_recall_tok: 0.9703178031471767
dev_label=O_f-score_tok: 0.9414159556952552
dev_label=N_precision_tok: 0.795822102425876
dev_label=N_recall_tok: 0.6359719978459881
dev_label=N_f-score_tok: 0.7069739598922478
dev_label=P_precision_tok: 0.8791505791505791
dev_label=P_recall_tok: 0.708904109589041
dev_label=P_f-score_tok: 0.7849017580144778
dev_precision_macro_tok: 0.8630529093626943
dev_recall_macro_tok: 0.7717313035274019
dev_f-score_macro_tok: 0.8110972245339937
dev_precision_micro_tok: 0.901664003008367
dev_recall_micro_tok: 0.901664003008367
dev_f-score_micro_tok: 0.901664003008367
dev_time: 5.152696847915649
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.6424    0.8645    0.7371       428
           P     0.6846    0.8018    0.7386       444

   micro avg     0.6612    0.6612    0.6612      1101
   macro avg     0.5757    0.5583    0.4976      1101
weighted avg     0.6090    0.6612    0.5879      1101

F1-macro sent:  0.4975783405136533
F1-micro sent:  0.6612170753860127
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9142    0.9703    0.9414     16205
           N     0.7958    0.6360    0.7070      1857
           P     0.8792    0.7089    0.7849      3212

   micro avg     0.9017    0.9017    0.9017     21274
   macro avg     0.8631    0.7717    0.8111     21274
weighted avg     0.8986    0.9017    0.8973     21274

F1-macro tok:  0.8110972245339937
F1-micro tok:  0.901664003008367
**************************************************
Best epoch: 44
**************************************************

EPOCH: 47
Learning rate: 0.478297
train_cost_sum: 286934.84631347656
train_cost_avg: 33.583198304479936
train_count_sent: 8544.0
train_total_correct_sent: 5868.0
train_accuracy_sent: 0.6867977528089888
train_count_tok: 163566.0
train_total_correct_tok: 151475.0
train_accuracy_tok: 0.9260787694264089
train_label=O_precision_sent: 0.4097560975609756
train_label=O_recall_sent: 0.05172413793103448
train_label=O_f-score_sent: 0.09185347184253691
train_label=N_precision_sent: 0.6608757734412185
train_label=N_recall_sent: 0.8389728096676737
train_label=N_f-score_sent: 0.7393503727369543
train_label=P_precision_sent: 0.7268552090887116
train_label=P_recall_sent: 0.8329639889196676
train_label=P_f-score_sent: 0.776300503420679
train_precision_macro_sent: 0.5991623600303019
train_recall_macro_sent: 0.5745536455061253
train_f-score_macro_sent: 0.5358347826667234
train_precision_micro_sent: 0.6867977528089888
train_recall_micro_sent: 0.6867977528089888
train_f-score_micro_sent: 0.6867977528089888
train_label=O_precision_tok: 0.9397768997290814
train_label=O_recall_tok: 0.973590034339389
train_label=O_f-score_tok: 0.9563846931681728
train_label=N_precision_tok: 0.8419040187280531
train_label=N_recall_tok: 0.759681734966906
train_label=N_f-score_tok: 0.798682311137432
train_label=P_precision_tok: 0.8948016415868673
train_label=P_recall_tok: 0.7843866171003717
train_label=P_f-score_tok: 0.8359639593584254
train_precision_macro_tok: 0.8921608533480007
train_recall_macro_tok: 0.8392194621355555
train_f-score_macro_tok: 0.8636769878880101
train_precision_micro_tok: 0.9260787694264089
train_recall_micro_tok: 0.9260787694264089
train_f-score_micro_tok: 0.9260787694264089
train_time: 95.78986668586731
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4098    0.0517    0.0919      1624
           N     0.6609    0.8390    0.7394      3310
           P     0.7269    0.8330    0.7763      3610

   micro avg     0.6868    0.6868    0.6868      8544
   macro avg     0.5992    0.5746    0.5358      8544
weighted avg     0.6410    0.6868    0.6319      8544

F1-macro sent:  0.5358347826667234
F1-micro sent:  0.6867977528089888
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9398    0.9736    0.9564    124347
           N     0.8419    0.7597    0.7987     14202
           P     0.8948    0.7844    0.8360     25017

   micro avg     0.9261    0.9261    0.9261    163566
   macro avg     0.8922    0.8392    0.8637    163566
weighted avg     0.9244    0.9261    0.9243    163566

F1-macro tok:  0.8636769878880101
F1-micro tok:  0.9260787694264089
**************************************************
dev_cost_sum: 42045.72247314453
dev_cost_avg: 38.188667096407386
dev_count_sent: 1101.0
dev_total_correct_sent: 729.0
dev_accuracy_sent: 0.662125340599455
dev_count_tok: 21274.0
dev_total_correct_tok: 19181.0
dev_accuracy_tok: 0.9016169972736674
dev_label=O_precision_sent: 0.631578947368421
dev_label=O_recall_sent: 0.05240174672489083
dev_label=O_f-score_sent: 0.0967741935483871
dev_label=N_precision_sent: 0.6836734693877551
dev_label=N_recall_sent: 0.7827102803738317
dev_label=N_f-score_sent: 0.7298474945533768
dev_label=P_precision_sent: 0.6452702702702703
dev_label=P_recall_sent: 0.8603603603603603
dev_label=P_f-score_sent: 0.7374517374517374
dev_precision_macro_sent: 0.6535075623421488
dev_recall_macro_sent: 0.565157462486361
dev_f-score_macro_sent: 0.5213578085178338
dev_precision_micro_sent: 0.662125340599455
dev_recall_micro_sent: 0.662125340599455
dev_f-score_micro_sent: 0.662125340599455
dev_label=O_precision_tok: 0.9150992837593898
dev_label=O_recall_tok: 0.9697624190064795
dev_label=O_f-score_tok: 0.9416382048055605
dev_label=N_precision_tok: 0.8030199039121483
dev_label=N_recall_tok: 0.630048465266559
dev_label=N_f-score_tok: 0.7060953530476766
dev_label=P_precision_tok: 0.8683812405446294
dev_label=P_recall_tok: 0.7148194271481942
dev_label=P_f-score_tok: 0.7841530054644809
dev_precision_macro_tok: 0.8621668094053891
dev_recall_macro_tok: 0.771543437140411
dev_f-score_macro_tok: 0.8106288544392393
dev_precision_micro_tok: 0.9016169972736674
dev_recall_micro_tok: 0.9016169972736674
dev_f-score_micro_tok: 0.9016169972736674
dev_time: 5.094324588775635
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.6316    0.0524    0.0968       229
           N     0.6837    0.7827    0.7298       428
           P     0.6453    0.8604    0.7375       444

   micro avg     0.6621    0.6621    0.6621      1101
   macro avg     0.6535    0.5652    0.5214      1101
weighted avg     0.6574    0.6621    0.6012      1101

F1-macro sent:  0.5213578085178338
F1-micro sent:  0.662125340599455
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9151    0.9698    0.9416     16205
           N     0.8030    0.6300    0.7061      1857
           P     0.8684    0.7148    0.7842      3212

   micro avg     0.9016    0.9016    0.9016     21274
   macro avg     0.8622    0.7715    0.8106     21274
weighted avg     0.8983    0.9016    0.8973     21274

F1-macro tok:  0.8106288544392393
F1-micro tok:  0.9016169972736674
**************************************************
Best epoch: 44
**************************************************

EPOCH: 48
Learning rate: 0.478297
train_cost_sum: 286353.33489990234
train_cost_avg: 33.51513751169269
train_count_sent: 8544.0
train_total_correct_sent: 5881.0
train_accuracy_sent: 0.6883192883895131
train_count_tok: 163566.0
train_total_correct_tok: 151464.0
train_accuracy_tok: 0.9260115182861964
train_label=O_precision_sent: 0.4153225806451613
train_label=O_recall_sent: 0.06342364532019705
train_label=O_f-score_sent: 0.11004273504273505
train_label=N_precision_sent: 0.6679490262082232
train_label=N_recall_sent: 0.8392749244712991
train_label=N_f-score_sent: 0.7438746820190119
train_label=P_precision_sent: 0.7251631617113851
train_label=P_recall_sent: 0.8310249307479224
train_label=P_f-score_sent: 0.774493352265393
train_precision_macro_sent: 0.6028115895215899
train_recall_macro_sent: 0.5779078335131396
train_f-score_macro_sent: 0.5428035897757133
train_precision_micro_sent: 0.6883192883895131
train_recall_micro_sent: 0.6883192883895131
train_f-score_micro_sent: 0.6883192883895131
train_label=O_precision_tok: 0.9397071155697736
train_label=O_recall_tok: 0.9732683538806727
train_label=O_f-score_tok: 0.956193335571928
train_label=N_precision_tok: 0.8427132932636016
train_label=N_recall_tok: 0.760174623292494
train_label=N_f-score_tok: 0.7993188464813239
train_label=P_precision_tok: 0.8942959894387035
train_label=P_recall_tok: 0.7852660191070072
train_label=P_f-score_tok: 0.8362421249787161
train_precision_macro_tok: 0.8922387994240263
train_recall_macro_tok: 0.8395696654267245
train_f-score_macro_tok: 0.8639181023439894
train_precision_micro_tok: 0.9260115182861964
train_recall_micro_tok: 0.9260115182861964
train_f-score_micro_tok: 0.9260115182861964
train_time: 95.93502593040466
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4153    0.0634    0.1100      1624
           N     0.6679    0.8393    0.7439      3310
           P     0.7252    0.8310    0.7745      3610

   micro avg     0.6883    0.6883    0.6883      8544
   macro avg     0.6028    0.5779    0.5428      8544
weighted avg     0.6441    0.6883    0.6363      8544

F1-macro sent:  0.5428035897757133
F1-micro sent:  0.6883192883895131
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9397    0.9733    0.9562    124347
           N     0.8427    0.7602    0.7993     14202
           P     0.8943    0.7853    0.8362     25017

   micro avg     0.9260    0.9260    0.9260    163566
   macro avg     0.8922    0.8396    0.8639    163566
weighted avg     0.9243    0.9260    0.9242    163566

F1-macro tok:  0.8639181023439894
F1-micro tok:  0.9260115182861964
**************************************************
dev_cost_sum: 42128.702880859375
dev_cost_avg: 38.26403531413204
dev_count_sent: 1101.0
dev_total_correct_sent: 731.0
dev_accuracy_sent: 0.6639418710263397
dev_count_tok: 21274.0
dev_total_correct_tok: 19135.0
dev_accuracy_tok: 0.8994547334774843
dev_label=O_precision_sent: 0.35714285714285715
dev_label=O_recall_sent: 0.021834061135371178
dev_label=O_f-score_sent: 0.0411522633744856
dev_label=N_precision_sent: 0.6647619047619048
dev_label=N_recall_sent: 0.8154205607476636
dev_label=N_f-score_sent: 0.7324239244491081
dev_label=P_precision_sent: 0.6708185053380783
dev_label=P_recall_sent: 0.8490990990990991
dev_label=P_f-score_sent: 0.7495029821073558
dev_precision_macro_sent: 0.5642410890809467
dev_recall_macro_sent: 0.5621179069940446
dev_f-score_macro_sent: 0.5076930566436498
dev_precision_micro_sent: 0.6639418710263397
dev_recall_micro_sent: 0.6639418710263397
dev_f-score_micro_sent: 0.6639418710263397
dev_label=O_precision_tok: 0.9135852792173761
dev_label=O_recall_tok: 0.968157975933354
dev_label=O_f-score_tok: 0.940080292408173
dev_label=N_precision_tok: 0.814418272662384
dev_label=N_recall_tok: 0.6144318793753366
dev_label=N_f-score_tok: 0.7004297114794353
dev_label=P_precision_tok: 0.8537037037037037
dev_label=P_recall_tok: 0.7176214196762142
dev_label=P_f-score_tok: 0.7797699594046007
dev_precision_macro_tok: 0.8605690851944879
dev_recall_macro_tok: 0.7667370916616348
dev_f-score_macro_tok: 0.8067599877640697
dev_precision_micro_tok: 0.8994547334774843
dev_recall_micro_tok: 0.8994547334774843
dev_f-score_micro_tok: 0.8994547334774842
dev_time: 5.070311069488525
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3571    0.0218    0.0412       229
           N     0.6648    0.8154    0.7324       428
           P     0.6708    0.8491    0.7495       444

   micro avg     0.6639    0.6639    0.6639      1101
   macro avg     0.5642    0.5621    0.5077      1101
weighted avg     0.6032    0.6639    0.5955      1101

F1-macro sent:  0.5076930566436498
F1-micro sent:  0.6639418710263397
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9136    0.9682    0.9401     16205
           N     0.8144    0.6144    0.7004      1857
           P     0.8537    0.7176    0.7798      3212

   micro avg     0.8995    0.8995    0.8995     21274
   macro avg     0.8606    0.7667    0.8068     21274
weighted avg     0.8959    0.8995    0.8950     21274

F1-macro tok:  0.8067599877640697
F1-micro tok:  0.8994547334774842
**************************************************
Best epoch: 44
**************************************************

EPOCH: 49
Learning rate: 0.430467
train_cost_sum: 285748.38037109375
train_cost_avg: 33.444332908601794
train_count_sent: 8544.0
train_total_correct_sent: 5887.0
train_accuracy_sent: 0.6890215355805244
train_count_tok: 163566.0
train_total_correct_tok: 151596.0
train_accuracy_tok: 0.9268185319687465
train_label=O_precision_sent: 0.40476190476190477
train_label=O_recall_sent: 0.04187192118226601
train_label=O_f-score_sent: 0.07589285714285714
train_label=N_precision_sent: 0.6552686671318911
train_label=N_recall_sent: 0.8510574018126889
train_label=N_f-score_sent: 0.7404389538704167
train_label=P_precision_sent: 0.7363257297032132
train_label=P_recall_sent: 0.8315789473684211
train_label=P_f-score_sent: 0.7810589306621569
train_precision_macro_sent: 0.5987854338656696
train_recall_macro_sent: 0.5748360901211252
train_f-score_macro_sent: 0.5324635805584769
train_precision_micro_sent: 0.6890215355805244
train_recall_micro_sent: 0.6890215355805244
train_f-score_micro_sent: 0.6890215355805244
train_label=O_precision_tok: 0.9410515837526344
train_label=O_recall_tok: 0.9731396816971861
train_label=O_f-score_tok: 0.9568266820593515
train_label=N_precision_tok: 0.8410662936193363
train_label=N_recall_tok: 0.7620053513589635
train_label=N_f-score_tok: 0.7995862425652961
train_label=P_precision_tok: 0.8939489869753979
train_label=P_recall_tok: 0.7901427029619859
train_label=P_f-score_tok: 0.8388465700524094
train_precision_macro_tok: 0.8920222881157894
train_recall_macro_tok: 0.8417625786727118
train_f-score_macro_tok: 0.8650864982256857
train_precision_micro_tok: 0.9268185319687465
train_recall_micro_tok: 0.9268185319687465
train_f-score_micro_tok: 0.9268185319687465
train_time: 97.01585626602173
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4048    0.0419    0.0759      1624
           N     0.6553    0.8511    0.7404      3310
           P     0.7363    0.8316    0.7811      3610

   micro avg     0.6890    0.6890    0.6890      8544
   macro avg     0.5988    0.5748    0.5325      8544
weighted avg     0.6419    0.6890    0.6313      8544

F1-macro sent:  0.5324635805584769
F1-micro sent:  0.6890215355805244
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9411    0.9731    0.9568    124347
           N     0.8411    0.7620    0.7996     14202
           P     0.8939    0.7901    0.8388     25017

   micro avg     0.9268    0.9268    0.9268    163566
   macro avg     0.8920    0.8418    0.8651    163566
weighted avg     0.9252    0.9268    0.9251    163566

F1-macro tok:  0.8650864982256857
F1-micro tok:  0.9268185319687465
**************************************************
dev_cost_sum: 42074.967529296875
dev_cost_avg: 38.21522936357572
dev_count_sent: 1101.0
dev_total_correct_sent: 721.0
dev_accuracy_sent: 0.6548592188919165
dev_count_tok: 21274.0
dev_total_correct_tok: 19201.0
dev_accuracy_tok: 0.9025571119676601
dev_label=O_precision_sent: 0.5
dev_label=O_recall_sent: 0.013100436681222707
dev_label=O_f-score_sent: 0.02553191489361702
dev_label=N_precision_sent: 0.6237113402061856
dev_label=N_recall_sent: 0.8481308411214953
dev_label=N_f-score_sent: 0.7188118811881187
dev_label=P_precision_sent: 0.6920077972709552
dev_label=P_recall_sent: 0.7995495495495496
dev_label=P_f-score_sent: 0.741901776384535
dev_precision_macro_sent: 0.6052397124923803
dev_recall_macro_sent: 0.5535936091174225
dev_f-score_macro_sent: 0.49541519082209023
dev_precision_micro_sent: 0.6548592188919165
dev_recall_micro_sent: 0.6548592188919165
dev_f-score_micro_sent: 0.6548592188919165
dev_label=O_precision_tok: 0.9147093023255813
dev_label=O_recall_tok: 0.9708731872878741
dev_label=O_f-score_tok: 0.9419547971860499
dev_label=N_precision_tok: 0.801765105227427
dev_label=N_recall_tok: 0.6359719978459881
dev_label=N_f-score_tok: 0.7093093093093094
dev_label=P_precision_tok: 0.8792772010765091
dev_label=P_recall_tok: 0.7120174346201743
dev_label=P_f-score_tok: 0.7868570445553071
dev_precision_macro_tok: 0.8652505362098392
dev_recall_macro_tok: 0.772954206584679
dev_f-score_macro_tok: 0.8127070503502222
dev_precision_micro_tok: 0.9025571119676601
dev_recall_micro_tok: 0.9025571119676601
dev_f-score_micro_tok: 0.9025571119676601
dev_time: 5.129591941833496
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5000    0.0131    0.0255       229
           N     0.6237    0.8481    0.7188       428
           P     0.6920    0.7995    0.7419       444

   micro avg     0.6549    0.6549    0.6549      1101
   macro avg     0.6052    0.5536    0.4954      1101
weighted avg     0.6255    0.6549    0.5839      1101

F1-macro sent:  0.49541519082209023
F1-micro sent:  0.6548592188919165
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9147    0.9709    0.9420     16205
           N     0.8018    0.6360    0.7093      1857
           P     0.8793    0.7120    0.7869      3212

   micro avg     0.9026    0.9026    0.9026     21274
   macro avg     0.8653    0.7730    0.8127     21274
weighted avg     0.8995    0.9026    0.8982     21274

F1-macro tok:  0.8127070503502222
F1-micro tok:  0.9025571119676601
**************************************************
Best epoch: 44
**************************************************

EPOCH: 50
Learning rate: 0.387420
train_cost_sum: 284907.89654541016
train_cost_avg: 33.345961674322346
train_count_sent: 8544.0
train_total_correct_sent: 5859.0
train_accuracy_sent: 0.6857443820224719
train_count_tok: 163566.0
train_total_correct_tok: 151904.0
train_accuracy_tok: 0.9287015638946969
train_label=O_precision_sent: 0.39819004524886875
train_label=O_recall_sent: 0.054187192118226604
train_label=O_f-score_sent: 0.0953929539295393
train_label=N_precision_sent: 0.6562205466540999
train_label=N_recall_sent: 0.8413897280966768
train_label=N_f-score_sent: 0.737357691289383
train_label=P_precision_sent: 0.7320421671978427
train_label=P_recall_sent: 0.8271468144044322
train_label=P_f-score_sent: 0.7766939784107166
train_precision_macro_sent: 0.5954842530336037
train_recall_macro_sent: 0.5742412448731119
train_f-score_macro_sent: 0.5364815412098797
train_precision_micro_sent: 0.6857443820224719
train_recall_micro_sent: 0.6857443820224719
train_f-score_micro_sent: 0.6857443820224719
train_label=O_precision_tok: 0.9422318351214882
train_label=O_recall_tok: 0.9739358408325091
train_label=O_f-score_tok: 0.9578215582217512
train_label=N_precision_tok: 0.8490831057354663
train_label=N_recall_tok: 0.7661596958174905
train_label=N_f-score_tok: 0.8054928378428399
train_label=P_precision_tok: 0.8963546354635463
train_label=P_recall_tok: 0.7961386257345006
train_label=P_f-score_tok: 0.8432796324914791
train_precision_macro_tok: 0.8958898587735002
train_recall_macro_tok: 0.8454113874615001
train_f-score_macro_tok: 0.8688646761853568
train_precision_micro_tok: 0.9287015638946969
train_recall_micro_tok: 0.9287015638946969
train_f-score_micro_tok: 0.9287015638946969
train_time: 96.75014996528625
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3982    0.0542    0.0954      1624
           N     0.6562    0.8414    0.7374      3310
           P     0.7320    0.8271    0.7767      3610

   micro avg     0.6857    0.6857    0.6857      8544
   macro avg     0.5955    0.5742    0.5365      8544
weighted avg     0.6392    0.6857    0.6320      8544

F1-macro sent:  0.5364815412098797
F1-micro sent:  0.6857443820224719
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9422    0.9739    0.9578    124347
           N     0.8491    0.7662    0.8055     14202
           P     0.8964    0.7961    0.8433     25017

   micro avg     0.9287    0.9287    0.9287    163566
   macro avg     0.8959    0.8454    0.8689    163566
weighted avg     0.9271    0.9287    0.9271    163566

F1-macro tok:  0.8688646761853568
F1-micro tok:  0.9287015638946969
**************************************************
dev_cost_sum: 42179.49792480469
dev_cost_avg: 38.31017068556284
dev_count_sent: 1101.0
dev_total_correct_sent: 725.0
dev_accuracy_sent: 0.6584922797456857
dev_count_tok: 21274.0
dev_total_correct_tok: 19174.0
dev_accuracy_tok: 0.9012879571307699
dev_label=O_precision_sent: 0.4
dev_label=O_recall_sent: 0.008733624454148471
dev_label=O_f-score_sent: 0.017094017094017092
dev_label=N_precision_sent: 0.6134185303514377
dev_label=N_recall_sent: 0.897196261682243
dev_label=N_f-score_sent: 0.7286527514231499
dev_label=P_precision_sent: 0.7212765957446808
dev_label=P_recall_sent: 0.7635135135135135
dev_label=P_f-score_sent: 0.7417943107221007
dev_precision_macro_sent: 0.5782317086987061
dev_recall_macro_sent: 0.556481133216635
dev_f-score_macro_sent: 0.49584702641308925
dev_precision_micro_sent: 0.6584922797456857
dev_recall_micro_sent: 0.6584922797456857
dev_f-score_micro_sent: 0.6584922797456857
dev_label=O_precision_tok: 0.9135386403253922
dev_label=O_recall_tok: 0.9701943844492441
dev_label=O_f-score_tok: 0.9410145144396229
dev_label=N_precision_tok: 0.8198847262247838
dev_label=N_recall_tok: 0.6128163704900377
dev_label=N_f-score_tok: 0.701386748844376
dev_label=P_precision_tok: 0.8647234678624813
dev_label=P_recall_tok: 0.7204234122042341
dev_label=P_f-score_tok: 0.7860054347826088
dev_precision_macro_tok: 0.8660489448042191
dev_recall_macro_tok: 0.7678113890478387
dev_f-score_macro_tok: 0.809468899355536
dev_precision_micro_tok: 0.9012879571307699
dev_recall_micro_tok: 0.9012879571307699
dev_f-score_micro_tok: 0.9012879571307699
dev_time: 5.0946385860443115
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.4000    0.0087    0.0171       229
           N     0.6134    0.8972    0.7287       428
           P     0.7213    0.7635    0.7418       444

   micro avg     0.6585    0.6585    0.6585      1101
   macro avg     0.5782    0.5565    0.4958      1101
weighted avg     0.6125    0.6585    0.5860      1101

F1-macro sent:  0.49584702641308925
F1-micro sent:  0.6584922797456857
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9135    0.9702    0.9410     16205
           N     0.8199    0.6128    0.7014      1857
           P     0.8647    0.7204    0.7860      3212

   micro avg     0.9013    0.9013    0.9013     21274
   macro avg     0.8660    0.7678    0.8095     21274
weighted avg     0.8980    0.9013    0.8967     21274

F1-macro tok:  0.809468899355536
F1-micro tok:  0.9012879571307699
**************************************************
Best epoch: 44
**************************************************

EPOCH: 51
Learning rate: 0.348678
train_cost_sum: 284422.0979614258
train_cost_avg: 33.28910322582231
train_count_sent: 8544.0
train_total_correct_sent: 5897.0
train_accuracy_sent: 0.690191947565543
train_count_tok: 163566.0
train_total_correct_tok: 152112.0
train_accuracy_tok: 0.9299732218187153
train_label=O_precision_sent: 0.5168539325842697
train_label=O_recall_sent: 0.05665024630541872
train_label=O_f-score_sent: 0.1021087680355161
train_label=N_precision_sent: 0.6582633053221288
train_label=N_recall_sent: 0.851963746223565
train_label=N_f-score_sent: 0.7426915986304977
train_label=P_precision_sent: 0.7312591866731994
train_label=P_recall_sent: 0.8268698060941828
train_label=P_f-score_sent: 0.7761310452418096
train_precision_macro_sent: 0.6354588081931993
train_recall_macro_sent: 0.5784945995410555
train_f-score_macro_sent: 0.5403104706359412
train_precision_micro_sent: 0.690191947565543
train_recall_micro_sent: 0.690191947565543
train_f-score_micro_sent: 0.690191947565543
train_label=O_precision_tok: 0.9431188519486988
train_label=O_recall_tok: 0.9745872437614096
train_label=O_f-score_tok: 0.9585948592604897
train_label=N_precision_tok: 0.8527143858555962
train_label=N_recall_tok: 0.7708773412195465
train_label=N_f-score_tok: 0.8097333678488222
train_label=P_precision_tok: 0.8986100490306329
train_label=P_recall_tok: 0.7985369948435064
train_label=P_f-score_tok: 0.845623095157467
train_precision_macro_tok: 0.8981477622783093
train_recall_macro_tok: 0.8480005266081543
train_f-score_macro_tok: 0.8713171074222595
train_precision_micro_tok: 0.9299732218187153
train_recall_micro_tok: 0.9299732218187153
train_f-score_micro_tok: 0.9299732218187153
train_time: 97.05384063720703
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.5169    0.0567    0.1021      1624
           N     0.6583    0.8520    0.7427      3310
           P     0.7313    0.8269    0.7761      3610

   micro avg     0.6902    0.6902    0.6902      8544
   macro avg     0.6355    0.5785    0.5403      8544
weighted avg     0.6622    0.6902    0.6351      8544

F1-macro sent:  0.5403104706359412
F1-micro sent:  0.690191947565543
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9431    0.9746    0.9586    124347
           N     0.8527    0.7709    0.8097     14202
           P     0.8986    0.7985    0.8456     25017

   micro avg     0.9300    0.9300    0.9300    163566
   macro avg     0.8981    0.8480    0.8713    163566
weighted avg     0.9285    0.9300    0.9284    163566

F1-macro tok:  0.8713171074222595
F1-micro tok:  0.9299732218187153
**************************************************
dev_cost_sum: 42033.334228515625
dev_cost_avg: 38.177415284755334
dev_count_sent: 1101.0
dev_total_correct_sent: 727.0
dev_accuracy_sent: 0.6603088101725704
dev_count_tok: 21274.0
dev_total_correct_tok: 19155.0
dev_accuracy_tok: 0.900394848171477
dev_label=O_precision_sent: 0.3448275862068966
dev_label=O_recall_sent: 0.043668122270742356
dev_label=O_f-score_sent: 0.07751937984496124
dev_label=N_precision_sent: 0.6634429400386848
dev_label=N_recall_sent: 0.8014018691588785
dev_label=N_f-score_sent: 0.725925925925926
dev_label=P_precision_sent: 0.6738738738738739
dev_label=P_recall_sent: 0.8423423423423423
dev_label=P_f-score_sent: 0.7487487487487489
dev_precision_macro_sent: 0.5607148000398184
dev_recall_macro_sent: 0.5624707779239877
dev_f-score_macro_sent: 0.517398018173212
dev_precision_micro_sent: 0.6603088101725704
dev_recall_micro_sent: 0.6603088101725704
dev_f-score_micro_sent: 0.6603088101725704
dev_label=O_precision_tok: 0.9178894236412725
dev_label=O_recall_tok: 0.9650725084850355
dev_label=O_f-score_tok: 0.9408898113888637
dev_label=N_precision_tok: 0.7784237726098191
dev_label=N_recall_tok: 0.6488960689283791
dev_label=N_f-score_tok: 0.7077826725403819
dev_label=P_precision_tok: 0.8597470238095238
dev_label=P_recall_tok: 0.7194894146948941
dev_label=P_f-score_tok: 0.7833898305084745
dev_precision_macro_tok: 0.8520200733535385
dev_recall_macro_tok: 0.7778193307027697
dev_f-score_macro_tok: 0.8106874381459067
dev_precision_micro_tok: 0.900394848171477
dev_recall_micro_tok: 0.900394848171477
dev_f-score_micro_tok: 0.900394848171477
dev_time: 5.042090892791748
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3448    0.0437    0.0775       229
           N     0.6634    0.8014    0.7259       428
           P     0.6739    0.8423    0.7487       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.5607    0.5625    0.5174      1101
weighted avg     0.6014    0.6603    0.6003      1101

F1-macro sent:  0.517398018173212
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9179    0.9651    0.9409     16205
           N     0.7784    0.6489    0.7078      1857
           P     0.8597    0.7195    0.7834      3212

   micro avg     0.9004    0.9004    0.9004     21274
   macro avg     0.8520    0.7778    0.8107     21274
weighted avg     0.8969    0.9004    0.8968     21274

F1-macro tok:  0.8106874381459067
F1-micro tok:  0.900394848171477
**************************************************
Best epoch: 44
**************************************************

test0_cost_sum: 41999.12432861328
test0_cost_avg: 38.146343622718696
test0_count_sent: 1101.0
test0_total_correct_sent: 727.0
test0_accuracy_sent: 0.6603088101725704
test0_count_tok: 21274.0
test0_total_correct_tok: 19192.0
test0_accuracy_tok: 0.9021340603553634
test0_label=O_precision_sent: 0.3673469387755102
test0_label=O_recall_sent: 0.07860262008733625
test0_label=O_f-score_sent: 0.12949640287769784
test0_label=N_precision_sent: 0.6498194945848376
test0_label=N_recall_sent: 0.8411214953271028
test0_label=N_f-score_sent: 0.7331975560081467
test0_label=P_precision_sent: 0.7008032128514057
test0_label=P_recall_sent: 0.786036036036036
test0_label=P_f-score_sent: 0.7409766454352442
test0_precision_macro_sent: 0.5726565487372511
test0_recall_macro_sent: 0.5685867171501583
test0_f-score_macro_sent: 0.5345568681070296
test0_precision_micro_sent: 0.6603088101725704
test0_recall_micro_sent: 0.6603088101725704
test0_f-score_micro_sent: 0.6603088101725704
test0_label=O_precision_tok: 0.9151575147033133
test0_label=O_recall_tok: 0.9698241283554458
test0_label=O_f-score_tok: 0.9416981245131524
test0_label=N_precision_tok: 0.8021978021978022
test0_label=N_recall_tok: 0.6289714593430263
test0_label=N_f-score_tok: 0.7051011168125565
test0_label=P_precision_tok: 0.8725897920604915
test0_label=P_recall_tok: 0.7185554171855542
test0_label=P_f-score_tok: 0.788116783336179
test0_precision_macro_tok: 0.8633150363205356
test0_recall_macro_tok: 0.772450334961342
test0_f-score_macro_tok: 0.811638674887296
test0_precision_micro_tok: 0.9021340603553634
test0_recall_micro_tok: 0.9021340603553634
test0_f-score_micro_tok: 0.9021340603553635
test0_time: 5.1349921226501465
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3673    0.0786    0.1295       229
           N     0.6498    0.8411    0.7332       428
           P     0.7008    0.7860    0.7410       444

   micro avg     0.6603    0.6603    0.6603      1101
   macro avg     0.5727    0.5686    0.5346      1101
weighted avg     0.6116    0.6603    0.6108      1101

F1-macro sent:  0.5345568681070296
F1-micro sent:  0.6603088101725704
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9152    0.9698    0.9417     16205
           N     0.8022    0.6290    0.7051      1857
           P     0.8726    0.7186    0.7881      3212

   micro avg     0.9021    0.9021    0.9021     21274
   macro avg     0.8633    0.7725    0.8116     21274
weighted avg     0.8989    0.9021    0.8979     21274

F1-macro tok:  0.811638674887296
F1-micro tok:  0.9021340603553635
**************************************************
test1_cost_sum: 81301.38913345337
test1_cost_avg: 36.78795888391555
test1_count_sent: 2210.0
test1_total_correct_sent: 1538.0
test1_accuracy_sent: 0.6959276018099547
test1_count_tok: 42405.0
test1_total_correct_tok: 37979.0
test1_accuracy_tok: 0.8956255158589789
test1_label=O_precision_sent: 0.3063063063063063
test1_label=O_recall_sent: 0.08740359897172237
test1_label=O_f-score_sent: 0.136
test1_label=N_precision_sent: 0.6858407079646017
test1_label=N_recall_sent: 0.8497807017543859
test1_label=N_f-score_sent: 0.7590597453476983
test1_label=P_precision_sent: 0.7523219814241486
test1_label=P_recall_sent: 0.801980198019802
test1_label=P_f-score_sent: 0.7763578274760384
test1_precision_macro_sent: 0.5814896652316855
test1_recall_macro_sent: 0.5797214995819701
test1_f-score_macro_sent: 0.5571391909412456
test1_precision_micro_sent: 0.6959276018099547
test1_recall_micro_sent: 0.6959276018099547
test1_f-score_micro_sent: 0.6959276018099547
test1_label=O_precision_tok: 0.9067893123083662
test1_label=O_recall_tok: 0.9704669041815114
test1_label=O_f-score_tok: 0.9375481182917441
test1_label=N_precision_tok: 0.797400866377874
test1_label=N_recall_tok: 0.636436170212766
test1_label=N_f-score_tok: 0.7078834491939062
test1_label=P_precision_tok: 0.8786586547780577
test1_label=P_recall_tok: 0.6819617872724537
test1_label=P_f-score_tok: 0.7679146196849059
test1_precision_macro_tok: 0.860949611154766
test1_recall_macro_tok: 0.7629549538889103
test1_f-score_macro_tok: 0.804448729056852
test1_precision_micro_tok: 0.8956255158589789
test1_recall_micro_tok: 0.8956255158589789
test1_f-score_micro_tok: 0.8956255158589789
test1_time: 10.434167385101318
**************************************************
Sentence pred: 
              precision    recall  f1-score   support

           O     0.3063    0.0874    0.1360       389
           N     0.6858    0.8498    0.7591       912
           P     0.7523    0.8020    0.7764       909

   micro avg     0.6959    0.6959    0.6959      2210
   macro avg     0.5815    0.5797    0.5571      2210
weighted avg     0.6464    0.6959    0.6565      2210

F1-macro sent:  0.5571391909412456
F1-micro sent:  0.6959276018099547
**************************************************
Token pred: 
              precision    recall  f1-score   support

           O     0.9068    0.9705    0.9375     31998
           N     0.7974    0.6364    0.7079      3760
           P     0.8787    0.6820    0.7679      6647

   micro avg     0.8956    0.8956    0.8956     42405
   macro avg     0.8609    0.7630    0.8044     42405
weighted avg     0.8927    0.8956    0.8906     42405

F1-macro tok:  0.804448729056852
F1-micro tok:  0.8956255158589789
**************************************************
