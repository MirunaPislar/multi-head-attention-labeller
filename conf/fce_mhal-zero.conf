[config]
load_pretrained_model = False
model_type = attention
sentence_label = specified
default_label = c
token_labels_available = True
plot_token_scores = False
plot_predictions_html = False
conll03_eval = False
to_write_filename = runs/final_fce/fce_mhal_zero.txt
path_train = ../data/fce_finegrained/fce.train.dense_labels.tsv
path_dev = ../data/fce_finegrained/fce.dev.dense_labels.tsv
path_test = ../data/fce_finegrained/fce.dev.dense_labels.tsv:../data/fce_finegrained/fce.test.dense_labels.tsv
model_selector = f-score_non_default_micro_sent:high
model_selector_ratio = 1.0
preload_vectors = ../glove/glove.6B.300d.txt
word_embedding_size = 300
emb_initial_zero = False
train_embeddings = True
char_embedding_size = 100
word_recurrent_size = 300
char_recurrent_size = 100
hidden_layer_size = 50
char_hidden_layer_size = 50
lowercase = True
replace_digits = True
min_word_freq = -1
singletons_prob = 0.1
allowed_word_length = -1
max_train_sent_length = -1
vocab_include_devtest = True
vocab_only_embedded = False
initializer = glorot
opt_strategy = adadelta
learning_rate = 1.0
clip = 0.0
batch_equal_size = False
max_batch_size = 32
epochs = 200
stop_if_no_improvement_for_epochs = 9
learning_rate_decay = 0.9
dropout_input = 0.5
dropout_word_lstm = 0.5
tf_per_process_gpu_memory_fraction = 1.0
tf_allow_growth = True
lmcost_max_vocab_size = 7500
lmcost_hidden_layer_size = 50
lmcost_lstm_gamma = 0.1
lmcost_joint_lstm_gamma = 0.0
lmcost_char_gamma = 0.0
lmcost_joint_char_gamma = 0.1
char_integration_method = concat
save = models/final_fce/fce_mhal_zero
garbage_collection = False
lstm_use_peepholes = False
whidden_layer_size = 400
attention_evidence_size = 200
attention_activation = soft
enable_label_smoothing = True
smoothing_epsilon = 0.15
sentence_objective_weights_non_default = 1.0
sentence_objective_weight = 1.0
word_objective_weight = 0.0
type1_attention_objective_weight = 0.0
type2_attention_objective_weight = 0.0
type3_attention_objective_weight = 0.01
type4_attention_objective_weight = 0.0
type5_attention_objective_weight = 0.01
type6_attention_objective_weight = 0.0 
type7_attention_objective_weight = 0.0
regularize_queries = 0.5
regularize_keys = 0.0
regularize_values = 0.0
regularize_sentence_repr = 0.0
take_abs = False
random_seed = 6425
